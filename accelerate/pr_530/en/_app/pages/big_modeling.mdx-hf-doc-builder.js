import{S as ec,i as tc,s as ac,F as sc,e as n,w as $,k as c,c as i,a as r,x as k,d as a,m as h,b as _,g as d,G as t,y as P,P as nc,H as ic,I as lc,J as rc,q as w,o as y,B as x,v as oc,T as dc,U as cc,t as o,M as hc,h as s,L as pc}from"../chunks/vendor-hf-doc-builder.js";import{T as Oe}from"../chunks/Tip-hf-doc-builder.js";import{D as $t}from"../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../chunks/CodeBlock-hf-doc-builder.js";import{I as fe}from"../chunks/IconCopyLink-hf-doc-builder.js";const{window:mc}=dc;function fc(A){let p,v,m,u,b,f,g,U,E;u=new fe({props:{classNames:"text-smd"}});const C=A[4].default,G=sc(C,A,A[3],null);return{c(){p=n("div"),v=n("a"),m=n("span"),$(u.$$.fragment),f=c(),G&&G.c(),this.h()},l(j){p=i(j,"DIV",{class:!0});var I=r(p);v=i(I,"A",{id:!0,class:!0,href:!0});var O=r(v);m=i(O,"SPAN",{});var F=r(m);k(u.$$.fragment,F),F.forEach(a),O.forEach(a),f=h(I),G&&G.l(I),I.forEach(a),this.h()},h(){_(v,"id",A[0]),_(v,"class","header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(v,"href",b=`#${A[0]}`),_(p,"class","relative group rounded-md")},m(j,I){d(j,p,I),t(p,v),t(v,m),P(u,m,null),t(p,f),G&&G.m(p,null),A[5](p),g=!0,U||(E=nc(mc,"hashchange",A[2]),U=!0)},p(j,[I]){(!g||I&1)&&_(v,"id",j[0]),(!g||I&1&&b!==(b=`#${j[0]}`))&&_(v,"href",b),G&&G.p&&(!g||I&8)&&ic(G,C,j,j[3],g?rc(C,j[3],I,null):lc(j[3]),null)},i(j){g||(w(u.$$.fragment,j),w(G,j),g=!0)},o(j){y(u.$$.fragment,j),y(G,j),g=!1},d(j){j&&a(p),x(u),G&&G.d(j),A[5](null),U=!1,E()}}}const Zd="bg-yellow-50 dark:bg-[#494a3d]";function uc(A,p,v){let{$$slots:m={},$$scope:u}=p,{anchor:b}=p,f;function g(){const{hash:E}=window.location,C=E.substring(1);f&&f.classList.remove(...Zd.split(" ")),C===b&&f.classList.add(...Zd.split(" "))}oc(()=>{g()});function U(E){cc[E?"unshift":"push"](()=>{f=E,v(1,f)})}return A.$$set=E=>{"anchor"in E&&v(0,b=E.anchor),"$$scope"in E&&v(3,u=E.$$scope)},[b,f,g,u,m,U]}class _c extends ec{constructor(p){super();tc(this,p,uc,fc,ac,{anchor:0})}}function gc(A){let p,v;return{c(){p=n("p"),v=o("This API is quite new and still in its experimental stage. While we strive to provide a stable API, it\u2019s possible some small parts of the public API will change in the future.")},l(m){p=i(m,"P",{});var u=r(p);v=s(u,"This API is quite new and still in its experimental stage. While we strive to provide a stable API, it\u2019s possible some small parts of the public API will change in the future."),u.forEach(a)},m(m,u){d(m,p,u),t(p,v)},d(m){m&&a(p)}}}function vc(A){let p,v;return{c(){p=n("p"),v=o("You can\u2019t move a model initialized like this on CPU or another device directly, since it doesn\u2019t have any data. It\u2019s also very likely that a forward pass with that empty model will fail, as not all operations are supported on the meta device.")},l(m){p=i(m,"P",{});var u=r(p);v=s(u,"You can\u2019t move a model initialized like this on CPU or another device directly, since it doesn\u2019t have any data. It\u2019s also very likely that a forward pass with that empty model will fail, as not all operations are supported on the meta device."),u.forEach(a)},m(m,u){d(m,p,u),t(p,v)},d(m){m&&a(p)}}}function wc(A){let p,v,m,u,b;return{c(){p=n("p"),v=o("This only supports inference of your model, not training. Most of the computation happens behind "),m=n("code"),u=o("torch.no_grad()"),b=o(" context managers to avoid spending some GPU memory with intermediate activations.")},l(f){p=i(f,"P",{});var g=r(p);v=s(g,"This only supports inference of your model, not training. Most of the computation happens behind "),m=i(g,"CODE",{});var U=r(m);u=s(U,"torch.no_grad()"),U.forEach(a),b=s(g," context managers to avoid spending some GPU memory with intermediate activations."),g.forEach(a)},m(f,g){d(f,p,g),t(p,v),t(p,m),t(m,u),t(p,b)},d(f){f&&a(p)}}}function yc(A){let p,v,m,u,b;return{c(){p=n("p"),v=o("You can derive all sizes of the model (and thus compute a "),m=n("code"),u=o("device_map"),b=o(") on a model that is on the meta device.")},l(f){p=i(f,"P",{});var g=r(p);v=s(g,"You can derive all sizes of the model (and thus compute a "),m=i(g,"CODE",{});var U=r(m);u=s(U,"device_map"),U.forEach(a),b=s(g,") on a model that is on the meta device."),g.forEach(a)},m(f,g){d(f,p,g),t(p,v),t(p,m),t(m,u),t(p,b)},d(f){f&&a(p)}}}function bc(A){let p,v,m,u,b,f,g,U,E,C,G;return{c(){p=n("p"),v=o("When a first allocation happens in PyTorch, it loads CUDA kernels which take about 1-2GB of memory depending on the GPU. Therefore you always have less usable memory than the actual size of the GPU. To see how much memory is actually used do "),m=n("code"),u=o("torch.ones(1).cuda()"),b=o(" and look at the memory usage."),f=c(),g=n("p"),U=o("Therefore when you create memory maps with "),E=n("code"),C=o("max_memory"),G=o(" make sure to adjust the avaialble memory accordingly to avoid out-of-memory errors.")},l(j){p=i(j,"P",{});var I=r(p);v=s(I,"When a first allocation happens in PyTorch, it loads CUDA kernels which take about 1-2GB of memory depending on the GPU. Therefore you always have less usable memory than the actual size of the GPU. To see how much memory is actually used do "),m=i(I,"CODE",{});var O=r(m);u=s(O,"torch.ones(1).cuda()"),O.forEach(a),b=s(I," and look at the memory usage."),I.forEach(a),f=h(j),g=i(j,"P",{});var F=r(g);U=s(F,"Therefore when you create memory maps with "),E=i(F,"CODE",{});var ee=r(E);C=s(ee,"max_memory"),ee.forEach(a),G=s(F," make sure to adjust the avaialble memory accordingly to avoid out-of-memory errors."),F.forEach(a)},m(j,I){d(j,p,I),t(p,v),t(p,m),t(m,u),t(p,b),d(j,f,I),d(j,g,I),t(g,U),t(g,E),t(E,C),t(g,G)},d(j){j&&a(p),j&&a(f),j&&a(g)}}}function $c(A){let p,v,m,u,b;return{c(){p=n("p"),v=o(`All computation is done analyzing sizes and dtypes of the model parameters. As a result, the model can be on the
meta device (as it would if initialized within the `),m=n("code"),u=o("init_empty_weights"),b=o(" context manager).")},l(f){p=i(f,"P",{});var g=r(p);v=s(g,`All computation is done analyzing sizes and dtypes of the model parameters. As a result, the model can be on the
meta device (as it would if initialized within the `),m=i(g,"CODE",{});var U=r(m);u=s(U,"init_empty_weights"),U.forEach(a),b=s(g," context manager)."),g.forEach(a)},m(f,g){d(f,p,g),t(p,v),t(p,m),t(m,u),t(p,b)},d(f){f&&a(p)}}}function kc(A){let p,v,m,u,b;return u=new B({props:{code:`import torch.nn as nn
from accelerate import init_empty_weights

<h1 class="relative group">
	<a 
		id="initialize-a-model-with-100-billions-parameters-in-no-time-and-without-using-any-ram" 
		class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" 
		href="#initialize-a-model-with-100-billions-parameters-in-no-time-and-without-using-any-ram"
	>
		<span><IconCopyLink/></span>
	</a>
	<span>
		Initialize a model with 100 billions parameters in no time and without using any RAM.
	</span>
</h1>

with init_empty_weights():
    tst = nn.Sequential(*[nn.Linear(10000, 10000) for _ in range(1000)])`,highlighted:`<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> init_empty_weights

&lt;h1 id=&quot;initialize-a-model-with-100-billions-parameters-in-no-time-and-without-using-any-ram&quot;&gt;Initialize a model <span class="hljs-keyword">with</span> <span class="hljs-number">100</span> billions parameters <span class="hljs-keyword">in</span> <span class="hljs-keyword">no</span> <span class="hljs-type">time</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">without</span> <span class="hljs-keyword">using</span> <span class="hljs-keyword">any</span> RAM.&lt;/h1&gt;
<span class="hljs-keyword">with</span> init_empty_weights():
    tst = nn.Sequential(*[nn.Linear(<span class="hljs-number">10000</span>, <span class="hljs-number">10000</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>)])`}}),{c(){p=n("p"),v=o("Example:"),m=c(),$(u.$$.fragment)},l(f){p=i(f,"P",{});var g=r(p);v=s(g,"Example:"),g.forEach(a),m=h(f),k(u.$$.fragment,f)},m(f,g){d(f,p,g),t(p,v),d(f,m,g),P(u,f,g),b=!0},p:pc,i(f){b||(w(u.$$.fragment,f),b=!0)},o(f){y(u.$$.fragment,f),b=!1},d(f){f&&a(p),f&&a(m),x(u,f)}}}function Pc(A){let p,v,m,u,b,f,g,U;return{c(){p=n("p"),v=o(`Any model created under this context manager has no weights. As such you can\u2019t do something like
`),m=n("code"),u=o("model.to(some_device)"),b=o(" with it. To load weights inside your empty model, see "),f=n("a"),g=o("load_checkpoint_and_dispatch()"),U=o("."),this.h()},l(E){p=i(E,"P",{});var C=r(p);v=s(C,`Any model created under this context manager has no weights. As such you can\u2019t do something like
`),m=i(C,"CODE",{});var G=r(m);u=s(G,"model.to(some_device)"),G.forEach(a),b=s(C," with it. To load weights inside your empty model, see "),f=i(C,"A",{href:!0});var j=r(f);g=s(j,"load_checkpoint_and_dispatch()"),j.forEach(a),U=s(C,"."),C.forEach(a),this.h()},h(){_(f,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.load_checkpoint_and_dispatch")},m(E,C){d(E,p,C),t(p,v),t(p,m),t(m,u),t(p,b),t(p,f),t(f,g),t(p,U)},d(E){E&&a(p)}}}function xc(A){let p,v,m,u,b,f,g,U;return{c(){p=n("p"),v=o("Once loaded across devices, you still need to call "),m=n("a"),u=o("dispatch_model()"),b=o(` on your model to make it able to run. To
group the checkpoint loading and dispatch in one single call, use `),f=n("a"),g=o("load_checkpoint_and_dispatch()"),U=o("."),this.h()},l(E){p=i(E,"P",{});var C=r(p);v=s(C,"Once loaded across devices, you still need to call "),m=i(C,"A",{href:!0});var G=r(m);u=s(G,"dispatch_model()"),G.forEach(a),b=s(C,` on your model to make it able to run. To
group the checkpoint loading and dispatch in one single call, use `),f=i(C,"A",{href:!0});var j=r(f);g=s(j,"load_checkpoint_and_dispatch()"),j.forEach(a),U=s(C,"."),C.forEach(a),this.h()},h(){_(m,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.dispatch_model"),_(f,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.load_checkpoint_and_dispatch")},m(E,C){d(E,p,C),t(p,v),t(p,m),t(m,u),t(p,b),t(p,f),t(f,g),t(p,U)},d(E){E&&a(p)}}}function jc(A){let p,v,m,u,b,f,g,U,E,C,G,j,I,O,F,ee,Xs,$o,J,Xt,Zs,en,Zt,tn,an,ea,on,ko,kt,sn,Po,ue,xo,te,_e,ta,Re,nn,aa,ln,jo,ge,rn,Pt,dn,cn,Eo,Se,Ao,xt,hn,Uo,We,Co,jt,pn,Go,ve,Io,ae,we,oa,Fe,mn,sa,fn,To,Et,un,qo,At,_n,Lo,He,Do,Ut,gn,Mo,Ye,Bo,z,vn,na,wn,yn,ia,bn,$n,la,kn,Pn,ra,xn,jn,da,En,An,ca,Un,zo,oe,ye,ha,Je,Cn,pa,Gn,No,be,In,Ct,Tn,qn,Oo,$e,Ln,Ve,Dn,Mn,Ro,Ke,So,Gt,Bn,Wo,Qe,Fo,It,zn,Ho,Xe,Yo,ke,Nn,ma,On,Rn,Jo,V,fa,Sn,Wn,ua,Fn,Hn,_a,Yn,Vo,se,ga,Jn,Vn,va,Kn,Qn,Ko,K,Xn,wa,Zn,ei,ya,ti,ai,Qo,Ze,Xo,et,Zo,Pe,oi,ba,si,ni,es,tt,ts,ne,xe,$a,at,ii,ka,li,as,Tt,ri,os,ot,ss,qt,di,ns,Q,Pa,ci,hi,xa,pi,mi,ja,fi,is,Lt,ui,ls,je,rs,ie,Ee,Ea,st,_i,Aa,gi,ds,Ae,vi,Ua,wi,yi,cs,Ue,hs,T,bi,Ca,$i,ki,Dt,Pi,xi,Ga,ji,Ei,Ia,Ai,Ui,Ta,Ci,Gi,qa,Ii,Ti,La,qi,Li,Da,Di,Mi,ps,Mt,Bi,ms,nt,fs,Ce,us,Bt,zi,_s,it,gs,q,Ni,Ma,Oi,Ri,Ba,Si,Wi,za,Fi,Hi,Na,Yi,Ji,Oa,Vi,Ki,Ra,Qi,Xi,Sa,Zi,el,Wa,tl,al,vs,lt,ws,zt,ol,ys,rt,bs,Nt,sl,$s,dt,ks,le,Ge,Fa,ct,nl,Ha,il,Ps,Ot,ll,xs,L,Ya,rl,dl,X,Rt,cl,hl,Ja,pl,ml,St,fl,ul,_l,Z,Wt,gl,vl,Va,wl,yl,Ft,bl,$l,kl,Ie,Ht,Pl,xl,Yt,jl,El,Al,Ka,Ul,Cl,Qa,Gl,Il,Xa,Tl,js,re,Te,Za,ht,ql,eo,Ll,Es,de,pt,Dl,to,Ml,As,ce,mt,Bl,ao,zl,Us,he,ft,Nl,oo,Ol,Cs,R,ut,Rl,so,Sl,Wl,H,no,Fl,Hl,io,Yl,Jl,lo,Vl,Kl,ro,Ql,Xl,qe,Gs,S,_t,Zl,co,er,tr,Le,ar,De,Is,pe,gt,or,ho,sr,Ts,Y,vt,nr,po,ir,lr,Me,qs;return f=new fe({}),O=new B({props:{code:`import torch

my_model = ModelClass(...)
state_dict = torch.load(checkpoint_file)
my_model.load_state_dict(state_dict)`,highlighted:`<span class="hljs-keyword">import</span> torch

my_model = ModelClass(...)
state_dict = torch.load(checkpoint_file)
my_model.load_state_dict(state_dict)`}}),ue=new Oe({props:{warning:!0,$$slots:{default:[gc]},$$scope:{ctx:A}}}),Re=new fe({}),Se=new B({props:{code:`from accelerate import init_empty_weights

with init_empty_weights():
    my_model = ModelClass(...)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> init_empty_weights

<span class="hljs-keyword">with</span> init_empty_weights():
    my_model = ModelClass(...)`}}),We=new B({props:{code:`with init_empty_weights():
    model = nn.Sequential(*[nn.Linear(10000, 10000) for _ in range(1000)])`,highlighted:`<span class="hljs-keyword">with</span> init_empty_weights():
    model = nn.Sequential(*[nn.Linear(<span class="hljs-number">10000</span>, <span class="hljs-number">10000</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>)])`}}),ve=new Oe({props:{warning:!0,$$slots:{default:[vc]},$$scope:{ctx:A}}}),Fe=new fe({}),He=new B({props:{code:`first_state_dict.bin
index.json
second_state_dict.bin`,highlighted:`first_state_dict.bin
index.json
second_state_dict.bin`}}),Ye=new B({props:{code:`{
  "linear1.weight": "first_state_dict.bin",
  "linear1.bias": "first_state_dict.bin",
  "linear2.weight": "second_state_dict.bin",
  "linear2.bias": "second_state_dict.bin"
}`,highlighted:`<span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;linear1.weight&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;first_state_dict.bin&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;linear1.bias&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;first_state_dict.bin&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;linear2.weight&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;second_state_dict.bin&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;linear2.bias&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;second_state_dict.bin&quot;</span>
<span class="hljs-punctuation">}</span>`}}),Je=new fe({}),Ke=new B({props:{code:`git clone https://huggingface.co/sgugger/sharded-gpt-j-6B
cd sharded-gpt-j-6B
git-lfs install
git pull`,highlighted:`git <span class="hljs-built_in">clone</span> https://huggingface.co/sgugger/sharded-gpt-j-6B
<span class="hljs-built_in">cd</span> sharded-gpt-j-6B
git-lfs install
git pull`}}),Qe=new B({props:{code:`from accelerate import init_empty_weights
from transformers import AutoConfig, AutoModelForCausalLM

checkpoint = "EleutherAI/gpt-j-6B"
config = AutoConfig.from_pretrained(checkpoint)

with init_empty_weights():
    model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> init_empty_weights
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

checkpoint = <span class="hljs-string">&quot;EleutherAI/gpt-j-6B&quot;</span>
config = AutoConfig.from_pretrained(checkpoint)

<span class="hljs-keyword">with</span> init_empty_weights():
    model = AutoModelForCausalLM.from_config(config)`}}),Xe=new B({props:{code:`from accelerate import load_checkpoint_and_dispatch

model = load_checkpoint_and_dispatch(
    model, "sharded-gpt-j-6B", device_map="auto", no_split_module_classes=["GPTJBlock"]
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> load_checkpoint_and_dispatch

model = load_checkpoint_and_dispatch(
    model, <span class="hljs-string">&quot;sharded-gpt-j-6B&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>, no_split_module_classes=[<span class="hljs-string">&quot;GPTJBlock&quot;</span>]
)`}}),Ze=new B({props:{code:"model.hf_device_map",highlighted:"model.hf_device_map"}}),et=new B({props:{code:`{'transformer.wte': 0,
 'transformer.drop': 0,
 'transformer.h.0': 0,
 'transformer.h.1': 0,
 'transformer.h.2': 0,
 'transformer.h.3': 0,
 'transformer.h.4': 0,
 'transformer.h.5': 0,
 'transformer.h.6': 0,
 'transformer.h.7': 0,
 'transformer.h.8': 0,
 'transformer.h.9': 0,
 'transformer.h.10': 0,
 'transformer.h.11': 0,
 'transformer.h.12': 0,
 'transformer.h.13': 0,
 'transformer.h.14': 0,
 'transformer.h.15': 0,
 'transformer.h.16': 0,
 'transformer.h.17': 0,
 'transformer.h.18': 0,
 'transformer.h.19': 0,
 'transformer.h.20': 0,
 'transformer.h.21': 0,
 'transformer.h.22': 0,
 'transformer.h.23': 0,
 'transformer.h.24': 1,
 'transformer.h.25': 1,
 'transformer.h.26': 1,
 'transformer.h.27': 1,
 'transformer.ln_f': 1,
 'lm_head': 1}`,highlighted:`{<span class="hljs-string">&#x27;transformer.wte&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.drop&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.0&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.1&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.2&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.3&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.4&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.5&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.6&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.7&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.8&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.9&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.10&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.11&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.12&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.13&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.14&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.15&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.16&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.17&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.18&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.19&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.20&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.21&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.22&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.23&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;transformer.h.24&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;transformer.h.25&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;transformer.h.26&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;transformer.h.27&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;transformer.ln_f&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;lm_head&#x27;</span>: <span class="hljs-number">1</span>}`}}),tt=new B({props:{code:'model = load_checkpoint_and_dispatch(model, "sharded-gpt-j-6B", device_map=my_device_map)',highlighted:'model = load_checkpoint_and_dispatch(model, <span class="hljs-string">&quot;sharded-gpt-j-6B&quot;</span>, device_map=my_device_map)'}}),at=new fe({}),ot=new B({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(checkpoint)
inputs = tokenizer("Hello, my name is", return_tensors="pt")
inputs = inputs.to(0)
output = model.generate(inputs["input_ids"])
tokenizer.decode(output[0].tolist())`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(checkpoint)
inputs = tokenizer(<span class="hljs-string">&quot;Hello, my name is&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
inputs = inputs.to(<span class="hljs-number">0</span>)
output = model.generate(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])
tokenizer.decode(output[<span class="hljs-number">0</span>].tolist())`}}),je=new Oe({props:{warning:!0,$$slots:{default:[wc]},$$scope:{ctx:A}}}),st=new fe({}),Ue=new Oe({props:{$$slots:{default:[yc]},$$scope:{ctx:A}}}),nt=new B({props:{code:`from accelerate import infer_auto_device_map

device_map = infer_auto_device_map(my_model, max_memory={0: "10GiB", 1: "10GiB", "cpu": "30GiB"})`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> infer_auto_device_map

device_map = infer_auto_device_map(my_model, max_memory={<span class="hljs-number">0</span>: <span class="hljs-string">&quot;10GiB&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;10GiB&quot;</span>, <span class="hljs-string">&quot;cpu&quot;</span>: <span class="hljs-string">&quot;30GiB&quot;</span>})`}}),Ce=new Oe({props:{warning:!0,$$slots:{default:[bc]},$$scope:{ctx:A}}}),it=new B({props:{code:"    return {0: '30GIB', 1: '46GIB', 2: '46GIB', 3: '46GIB', 4: '46GIB', 5: '46GIB', 6: '46GIB', 7: '46GIB'}",highlighted:'    <span class="hljs-attribute">return</span> {<span class="hljs-number">0</span>: &#x27;<span class="hljs-number">30</span>GIB&#x27;, <span class="hljs-number">1</span>: &#x27;<span class="hljs-number">46</span>GIB&#x27;, <span class="hljs-number">2</span>: &#x27;<span class="hljs-number">46</span>GIB&#x27;, <span class="hljs-number">3</span>: &#x27;<span class="hljs-number">46</span>GIB&#x27;, <span class="hljs-number">4</span>: &#x27;<span class="hljs-number">46</span>GIB&#x27;, <span class="hljs-number">5</span>: &#x27;<span class="hljs-number">46</span>GIB&#x27;, <span class="hljs-number">6</span>: &#x27;<span class="hljs-number">46</span>GIB&#x27;, <span class="hljs-number">7</span>: &#x27;<span class="hljs-number">46</span>GIB&#x27;}'}}),lt=new B({props:{code:'device_map = {"block1": 0, "block2": 1}',highlighted:'device_map = {<span class="hljs-string">&quot;block1&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;block2&quot;</span>: <span class="hljs-number">1</span>}'}}),rt=new B({props:{code:'device_map = {"block1": 0, "block2.linear1": 0, "block2.linear2": 1, "block2.linear3": 1}',highlighted:'device_map = {<span class="hljs-string">&quot;block1&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;block2.linear1&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;block2.linear2&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;block2.linear3&quot;</span>: <span class="hljs-number">1</span>}'}}),dt=new B({props:{code:'device_map = {"block1": 0, "block2.linear1": 1, "block2.linear2": 1}',highlighted:'device_map = {<span class="hljs-string">&quot;block1&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;block2.linear1&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;block2.linear2&quot;</span>: <span class="hljs-number">1</span>}'}}),ct=new fe({}),ht=new fe({}),pt=new $t({props:{name:"accelerate.cpu_offload",anchor:"accelerate.cpu_offload",parameters:[{name:"model",val:": Module"},{name:"execution_device",val:": typing.Optional[torch.device] = None"},{name:"offload_buffers",val:": bool = False"},{name:"state_dict",val:": typing.Union[typing.Dict[str, torch.Tensor], NoneType] = None"},{name:"preload_module_classes",val:": typing.Optional[typing.List[str]] = None"}],parametersDescription:[{anchor:"accelerate.cpu_offload.model",description:`<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014;
The model to offload.`,name:"model"},{anchor:"accelerate.cpu_offload.execution_device",description:`<strong>execution_device</strong> (<code>torch.device</code>, <em>optional</em>) &#x2014;
The device on which the forward pass of the model will be executed (should be a GPU). Will default to the
model first parameter device.`,name:"execution_device"},{anchor:"accelerate.cpu_offload.offload_buffers",description:`<strong>offload_buffers</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to offload the buffers with the model parameters.`,name:"offload_buffers"},{anchor:"accelerate.cpu_offload.state_dict",description:`<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>, <em>optional</em>) &#x2014;
The state dict of the model that will be kept on CPU.`,name:"state_dict"},{anchor:"accelerate.cpu_offload.preload_module_classes",description:`<strong>preload_module_classes</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of classes whose instances should load all their weights (even in the submodules) at the beginning
of the forward. This should only be used for classes that have submodules which are registered but not
called directly during the forward, for instance if a <code>dense</code> linear layer is registered, but at forward,
<code>dense.weight</code> and <code>dense.bias</code> are used in some operations instead of calling <code>dense</code> directly.`,name:"preload_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/vr_530/src/accelerate/big_modeling.py#L88"}}),mt=new $t({props:{name:"accelerate.disk_offload",anchor:"accelerate.disk_offload",parameters:[{name:"model",val:": Module"},{name:"offload_dir",val:": typing.Union[str, os.PathLike]"},{name:"execution_device",val:": typing.Optional[torch.device] = None"},{name:"offload_buffers",val:": bool = False"},{name:"preload_module_classes",val:": typing.Optional[typing.List[str]] = None"}],parametersDescription:[{anchor:"accelerate.disk_offload.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to offload.",name:"model"},{anchor:"accelerate.disk_offload.offload_dir",description:`<strong>offload_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
The folder in which to offload the model weights (or where the model weights are already offloaded).`,name:"offload_dir"},{anchor:"accelerate.disk_offload.execution_device",description:`<strong>execution_device</strong> (<code>torch.device</code>, <em>optional</em>) &#x2014;
The device on which the forward pass of the model will be executed (should be a GPU). Will default to the
model&#x2019;s first parameter device.`,name:"execution_device"},{anchor:"accelerate.disk_offload.offload_buffers",description:`<strong>offload_buffers</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to offload the buffers with the model parameters.`,name:"offload_buffers"},{anchor:"accelerate.disk_offload.preload_module_classes",description:`<strong>preload_module_classes</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of classes whose instances should load all their weights (even in the submodules) at the beginning
of the forward. This should only be used for classes that have submodules which are registered but not
called directly during the forward, for instance if a <code>dense</code> linear layer is registered, but at forward,
<code>dense.weight</code> and <code>dense.bias</code> are used in some operations instead of calling <code>dense</code> directly.`,name:"preload_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/vr_530/src/accelerate/big_modeling.py#L132"}}),ft=new $t({props:{name:"accelerate.dispatch_model",anchor:"accelerate.dispatch_model",parameters:[{name:"model",val:": Module"},{name:"device_map",val:": typing.Dict[str, typing.Union[int, str, torch.device]]"},{name:"main_device",val:": typing.Optional[torch.device] = None"},{name:"state_dict",val:": typing.Union[typing.Dict[str, torch.Tensor], NoneType] = None"},{name:"offload_dir",val:": typing.Union[str, os.PathLike] = None"},{name:"offload_buffers",val:": bool = False"},{name:"preload_module_classes",val:": typing.Optional[typing.List[str]] = None"}],parametersDescription:[{anchor:"accelerate.dispatch_model.model",description:`<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014;
The model to dispatch.`,name:"model"},{anchor:"accelerate.dispatch_model.device_map",description:`<strong>device_map</strong> (<code>Dict[str, Union[str, int, torch.device]]</code>) &#x2014;
A dictionary mapping module names in the models <code>state_dict</code> to the device they should go to. Note that
<code>&quot;disk&quot;</code> is accepted even if it&#x2019;s not a proper value for <code>torch.device</code>.`,name:"device_map"},{anchor:"accelerate.dispatch_model.main_device",description:`<strong>main_device</strong> (<code>str</code>, <code>int</code> or <code>torch.device</code>, <em>optional</em>) &#x2014;
The main execution device. Will default to the first device in the <code>device_map</code> different from <code>&quot;cpu&quot;</code> or
<code>&quot;disk&quot;</code>.`,name:"main_device"},{anchor:"accelerate.dispatch_model.state_dict",description:`<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>, <em>optional</em>) &#x2014;
The state dict of the part of the model that will be kept on CPU.`,name:"state_dict"},{anchor:"accelerate.dispatch_model.offload_dir",description:`<strong>offload_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
The folder in which to offload the model weights (or where the model weights are already offloaded).`,name:"offload_dir"},{anchor:"accelerate.dispatch_model.offload_buffers",description:`<strong>offload_buffers</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to offload the buffers with the model parameters.`,name:"offload_buffers"},{anchor:"accelerate.dispatch_model.preload_module_classes",description:`<strong>preload_module_classes</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of classes whose instances should load all their weights (even in the submodules) at the beginning
of the forward. This should only be used for classes that have submodules which are registered but not
called directly during the forward, for instance if a <code>dense</code> linear layer is registered, but at forward,
<code>dense.weight</code> and <code>dense.bias</code> are used in some operations instead of calling <code>dense</code> directly.`,name:"preload_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/vr_530/src/accelerate/big_modeling.py#L176"}}),ut=new $t({props:{name:"accelerate.infer_auto_device_map",anchor:"accelerate.infer_auto_device_map",parameters:[{name:"model",val:": Module"},{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"},{name:"no_split_module_classes",val:": typing.Optional[typing.List[str]] = None"},{name:"dtype",val:": typing.Union[str, torch.dtype, NoneType] = None"}],parametersDescription:[{anchor:"accelerate.infer_auto_device_map.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to analyze.",name:"model"},{anchor:"accelerate.infer_auto_device_map.max_memory",description:`<strong>max_memory</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
A dictionary device identifier to maximum memory. Will default to the maximum memory available if unset.`,name:"max_memory"},{anchor:"accelerate.infer_auto_device_map.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of layer class names that should never be split across device (for instance any layer that has a
residual connection).`,name:"no_split_module_classes"},{anchor:"accelerate.infer_auto_device_map.dtype",description:`<strong>dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
If provided, the weights will be converted to that type when loaded.`,name:"dtype"}],source:"https://github.com/huggingface/accelerate/blob/vr_530/src/accelerate/utils/modeling.py#L329"}}),qe=new Oe({props:{$$slots:{default:[$c]},$$scope:{ctx:A}}}),_t=new $t({props:{name:"accelerate.init_empty_weights",anchor:"accelerate.init_empty_weights",parameters:[{name:"include_buffers",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.init_empty_weights.include_buffers",description:`<strong>include_buffers</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also put all buffers on the meta device while initializing.`,name:"include_buffers"}],source:"https://github.com/huggingface/accelerate/blob/vr_530/src/accelerate/big_modeling.py#L33"}}),Le=new _c({props:{anchor:"accelerate.init_empty_weights.example",$$slots:{default:[kc]},$$scope:{ctx:A}}}),De=new Oe({props:{warning:!0,$$slots:{default:[Pc]},$$scope:{ctx:A}}}),gt=new $t({props:{name:"accelerate.load_checkpoint_and_dispatch",anchor:"accelerate.load_checkpoint_and_dispatch",parameters:[{name:"model",val:": Module"},{name:"checkpoint",val:": typing.Union[str, os.PathLike]"},{name:"device_map",val:": typing.Union[str, typing.Dict[str, typing.Union[int, str, torch.device]], NoneType] = None"},{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"},{name:"no_split_module_classes",val:": typing.Optional[typing.List[str]] = None"},{name:"offload_folder",val:": typing.Union[str, os.PathLike, NoneType] = None"},{name:"offload_buffers",val:": bool = False"},{name:"dtype",val:": typing.Union[str, torch.dtype, NoneType] = None"},{name:"offload_state_dict",val:": typing.Optional[bool] = None"},{name:"preload_module_classes",val:": typing.Optional[typing.List[str]] = None"}],parametersDescription:[{anchor:"accelerate.load_checkpoint_and_dispatch.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model in which we want to load a checkpoint.",name:"model"},{anchor:"accelerate.load_checkpoint_and_dispatch.checkpoint",description:`<strong>checkpoint</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
The folder checkpoint to load. It can be:</p>
<ul>
<li>a path to a file containing a whole model state dict</li>
<li>a path to a <code>.json</code> file containing the index to a sharded checkpoint</li>
<li>a path to a folder containing a unique <code>.index.json</code> file and the shards of a checkpoint.</li>
</ul>`,name:"checkpoint"},{anchor:"accelerate.load_checkpoint_and_dispatch.device_map",description:`<strong>device_map</strong> (<code>Dict[str, Union[int, str, torch.device]]</code>, <em>optional</em>) &#x2014;
A map that specifies where each submodule should go. It doesn&#x2019;t need to be refined to each parameter/buffer
name, once a given module name is inside, every submodule of it will be sent to the same device.</p>
<p>To have Accelerate compute the most optimized <code>device_map</code> automatically, set <code>device_map=&quot;auto&quot;</code>.`,name:"device_map"},{anchor:"accelerate.load_checkpoint_and_dispatch.max_memory",description:`<strong>max_memory</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
A dictionary device identifier to maximum memory. Will default to the maximum memory available for each GPU
and the available CPU RAM if unset.`,name:"max_memory"},{anchor:"accelerate.load_checkpoint_and_dispatch.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of layer class names that should never be split across device (for instance any layer that has a
residual connection).`,name:"no_split_module_classes"},{anchor:"accelerate.load_checkpoint_and_dispatch.offload_folder",description:`<strong>offload_folder</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
If the <code>device_map</code> contains any value <code>&quot;disk&quot;</code>, the folder where we will offload weights.`,name:"offload_folder"},{anchor:"accelerate.load_checkpoint_and_dispatch.offload_buffers",description:`<strong>offload_buffers</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
In the layers that are offloaded on the CPU or the hard drive, whether or not to offload the buffers as
well as the parameters.`,name:"offload_buffers"},{anchor:"accelerate.load_checkpoint_and_dispatch.dtype",description:`<strong>dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
If provided, the weights will be converted to that type when loaded.`,name:"dtype"},{anchor:"accelerate.load_checkpoint_and_dispatch.offload_state_dict",description:`<strong>offload_state_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
If <code>True</code>, will temporarily offload the CPU state dict on the hard drive to avoig getting out of CPU RAM if
the weight of the CPU state dict + the biggest shard does not fit. Will default to <code>True</code> if the device map
picked contains <code>&quot;disk&quot;</code> values.`,name:"offload_state_dict"},{anchor:"accelerate.load_checkpoint_and_dispatch.preload_module_classes",description:`<strong>preload_module_classes</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of classes whose instances should load all their weights (even in the submodules) at the beginning
of the forward. This should only be used for classes that have submodules which are registered but not
called directly during the forward, for instance if a <code>dense</code> linear layer is registered, but at forward,
<code>dense.weight</code> and <code>dense.bias</code> are used in some operations instead of calling <code>dense</code> directly.`,name:"preload_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/vr_530/src/accelerate/big_modeling.py#L254"}}),vt=new $t({props:{name:"accelerate.load_checkpoint_in_model",anchor:"accelerate.load_checkpoint_in_model",parameters:[{name:"model",val:": Module"},{name:"checkpoint",val:": typing.Union[str, os.PathLike]"},{name:"device_map",val:": typing.Union[typing.Dict[str, typing.Union[int, str, torch.device]], NoneType] = None"},{name:"offload_folder",val:": typing.Union[str, os.PathLike, NoneType] = None"},{name:"dtype",val:": typing.Union[str, torch.dtype, NoneType] = None"},{name:"offload_state_dict",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.load_checkpoint_in_model.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model in which we want to load a checkpoint.",name:"model"},{anchor:"accelerate.load_checkpoint_in_model.checkpoint",description:`<strong>checkpoint</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
The folder checkpoint to load. It can be:<ul>
<li>a path to a file containing a whole model state dict</li>
<li>a path to a <code>.json</code> file containing the index to a sharded checkpoint</li>
<li>a path to a folder containing a unique <code>.index.json</code> file and the shards of a checkpoint.</li>
</ul>`,name:"checkpoint"},{anchor:"accelerate.load_checkpoint_in_model.device_map",description:`<strong>device_map</strong> (<code>Dict[str, Union[int, str, torch.device]]</code>, <em>optional</em>) &#x2014;
A map that specifies where each submodule should go. It doesn&#x2019;t need to be refined to each parameter/buffer
name, once a given module name is inside, every submodule of it will be sent to the same device.`,name:"device_map"},{anchor:"accelerate.load_checkpoint_in_model.offload_folder",description:`<strong>offload_folder</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
If the <code>device_map</code> contains any value <code>&quot;disk&quot;</code>, the folder where we will offload weights.`,name:"offload_folder"},{anchor:"accelerate.load_checkpoint_in_model.dtype",description:`<strong>dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
If provided, the weights will be converted to that type when loaded.`,name:"dtype"},{anchor:"accelerate.load_checkpoint_in_model.offload_state_dict",description:`<strong>offload_state_dict</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, will temporarily offload the CPU state dict on the hard drive to avoig getting out of CPU RAM if
the weight of the CPU state dict + the biggest shard does not fit.`,name:"offload_state_dict"}],source:"https://github.com/huggingface/accelerate/blob/vr_530/src/accelerate/utils/modeling.py#L493"}}),Me=new Oe({props:{warning:!0,$$slots:{default:[xc]},$$scope:{ctx:A}}}),{c(){p=n("meta"),v=c(),m=n("h1"),u=n("a"),b=n("span"),$(f.$$.fragment),g=c(),U=n("span"),E=o("Handling big models"),C=c(),G=n("p"),j=o("When loading a pretrained model in PyTorch, the usual workflow looks like this:"),I=c(),$(O.$$.fragment),F=c(),ee=n("p"),Xs=o("In plain English, those steps are:"),$o=c(),J=n("ol"),Xt=n("li"),Zs=o("Create the model with randomly initialized weights"),en=c(),Zt=n("li"),tn=o("Load the model weights (in a dictionary usually called a state dict) from the disk"),an=c(),ea=n("li"),on=o("Load those weights inside the model"),ko=c(),kt=n("p"),sn=o("While this works very well for regularly sized models, this workflow has some clear limitations when we deal with a huge model: in step 1, we load a full version of the model in RAM, and spend some time randomly initializing the weights (which will be discarded in step 3). In step 2, we load another full version of the model in RAM, with the pretrained weights. If you\u2019re loading a model with 6 billions parameters, this means you will need 24GB of RAM for each copy of the model, so 48GB in total (half of it to load the model in FP16)."),Po=c(),$(ue.$$.fragment),xo=c(),te=n("h2"),_e=n("a"),ta=n("span"),$(Re.$$.fragment),nn=c(),aa=n("span"),ln=o("Instantiating an empty model"),jo=c(),ge=n("p"),rn=o("The first tool \u{1F917} Accelerate introduces to help with big models is a context manager "),Pt=n("a"),dn=o("init_empty_weights()"),cn=o(" that helps you initialize a model without using any RAM, so that step 1 can be done on models of any size. Here is how it works:"),Eo=c(),$(Se.$$.fragment),Ao=c(),xt=n("p"),hn=o("For instance:"),Uo=c(),$(We.$$.fragment),Co=c(),jt=n("p"),pn=o("initializes an empty model with a bit more than 100B parameters. Behind the scenes, this relies on the meta device introduced in PyTorch 1.9. During the initialization under the context manager, each time a parameter is created, it is instantly moved on that device."),Go=c(),$(ve.$$.fragment),Io=c(),ae=n("h2"),we=n("a"),oa=n("span"),$(Fe.$$.fragment),mn=c(),sa=n("span"),fn=o("Sharded checkpoints"),To=c(),Et=n("p"),un=o("It\u2019s possible your model is so big that even a single copy won\u2019t fit in RAM. That doesn\u2019t mean it can\u2019t be loaded: if you have one or several GPUs, this is more memory available to store your model. In this case, it\u2019s better if your checkpoint is split in several smaller files that we call checkpoint shards."),qo=c(),At=n("p"),_n=o("\u{1F917} Accelerate will handle sharded checkpoints as long as you follow the following format: your checkpoint should be in a folder, with several files containing the partial state dicts, and there should be an index in the JSON format that contains a dictionary mapping parameter names to the file containing their weights. For instance we could have a folder containing:"),Lo=c(),$(He.$$.fragment),Do=c(),Ut=n("p"),gn=o("with index.json being the following file:"),Mo=c(),$(Ye.$$.fragment),Bo=c(),z=n("p"),vn=o("and "),na=n("code"),wn=o("first_state_dict.bin"),yn=o(" containing the weights for "),ia=n("code"),bn=o('"linear1.weight"'),$n=o(" and "),la=n("code"),kn=o('"linear1.bias"'),Pn=o(", "),ra=n("code"),xn=o("second_state_dict.bin"),jn=o(" the ones for "),da=n("code"),En=o('"linear2.weight"'),An=o(" and "),ca=n("code"),Un=o('"linear2.bias"'),zo=c(),oe=n("h2"),ye=n("a"),ha=n("span"),$(Je.$$.fragment),Cn=c(),pa=n("span"),Gn=o("Loading weights"),No=c(),be=n("p"),In=o("The second tool \u{1F917} Accelerate introduces is a function "),Ct=n("a"),Tn=o("load_checkpoint_and_dispatch()"),qn=o(", that will allow you to load a checkpoint inside your empty model. This supports full checkpoints (a single file containing the whole state dict) as well as sharded checkpoints. It will also automatically dispatch those weights across the devices you have available (GPUs, CPU RAM), so if you are loading a sharded checkpoint, the maximum RAM usage will be the size of the biggest shard."),Oo=c(),$e=n("p"),Ln=o("Here is how we can use this to load the "),Ve=n("a"),Dn=o("GPT-J-6B"),Mn=o(" model. You clone the sharded version of this model with:"),Ro=c(),$(Ke.$$.fragment),So=c(),Gt=n("p"),Bn=o("then we can initialize the model with"),Wo=c(),$(Qe.$$.fragment),Fo=c(),It=n("p"),zn=o("and load the checkpoint we just downloaded with:"),Ho=c(),$(Xe.$$.fragment),Yo=c(),ke=n("p"),Nn=o("By passing "),ma=n("code"),On=o('device_map="auto"'),Rn=o(", we tell \u{1F917} Accelerate to determine automatically where to put each layer of the model depending on the available resources:"),Jo=c(),V=n("ul"),fa=n("li"),Sn=o("first we use the maximum space available on the GPU(s)"),Wn=c(),ua=n("li"),Fn=o("if we still need space, we store the remaining weights on the CPU"),Hn=c(),_a=n("li"),Yn=o("if there is not enough RAM, we store the remaining weights on the hard drive as memory-mapped tensors"),Vo=c(),se=n("p"),ga=n("code"),Jn=o('no_split_module_classes=["GPTJBlock"]'),Vn=o(" indicates that the modules that are "),va=n("code"),Kn=o("GPTJBlock"),Qn=o(" should not be split on different devices. You should set here all blocks that include a residual connection of some kind."),Ko=c(),K=n("p"),Xn=o("You can see the "),wa=n("code"),Zn=o("device_map"),ei=o(" that \u{1F917} Accelerate picked by accessing the "),ya=n("code"),ti=o("hf_device_map"),ai=o(" attribute of your model:"),Qo=c(),$(Ze.$$.fragment),Xo=c(),$(et.$$.fragment),Zo=c(),Pe=n("p"),oi=o("You can also design your "),ba=n("code"),si=o("device_map"),ni=o(" yourself, if you prefer to explicitly decide where each layer should be. In this case, the command above becomes:"),es=c(),$(tt.$$.fragment),ts=c(),ne=n("h2"),xe=n("a"),$a=n("span"),$(at.$$.fragment),ii=c(),ka=n("span"),li=o("Run the model"),as=c(),Tt=n("p"),ri=o("Now that we have done this, our model lies across several devices, and maybe the hard drive. But it can still be used as a regular PyTorch model:"),os=c(),$(ot.$$.fragment),ss=c(),qt=n("p"),di=o("Behind the scenes, \u{1F917} Accelerate added hooks to the model, so that:"),ns=c(),Q=n("ul"),Pa=n("li"),ci=o("at each layer, the inputs are put on the right device (so even if your model is spread across several GPUs, it works)"),hi=c(),xa=n("li"),pi=o("for the weights offloaded on the CPU, they are put on a GPU just before the forward pass, and cleaned up just after"),mi=c(),ja=n("li"),fi=o("for the weights offloaded on the hard drive, they are loaded in RAM then put on a GPU just before the forward pass, and cleaned up just after"),is=c(),Lt=n("p"),ui=o("This way, you model can run for inference even if it doesn\u2019t fit on one of the GPUs or the CPU RAM!"),ls=c(),$(je.$$.fragment),rs=c(),ie=n("h2"),Ee=n("a"),Ea=n("span"),$(st.$$.fragment),_i=c(),Aa=n("span"),gi=o("Designing a device map"),ds=c(),Ae=n("p"),vi=o("You can let \u{1F917} Accelerate handle the device map computation by setting "),Ua=n("code"),wi=o('device_map="auto"'),yi=o(" or create one yourself, if you want more control over where each layer should go."),cs=c(),$(Ue.$$.fragment),hs=c(),T=n("p"),bi=o("First note that you can limit the memory used on each GPU by using the "),Ca=n("code"),$i=o("max_memory"),ki=o(" argument (available in "),Dt=n("a"),Pi=o("infer_auto_device_map()"),xi=o(" and in all functions using it). When setting "),Ga=n("code"),ji=o("max_memory"),Ei=o(", you should pass along a dictionary containing the GPU identifiers (for instance "),Ia=n("code"),Ai=o("0"),Ui=o(", "),Ta=n("code"),Ci=o("1"),Gi=o(" etc.) and the "),qa=n("code"),Ii=o('"cpu"'),Ti=o(" key for the maximum RAM you want used for CPU offload. The values can either be an integer (in bytes) or a string representing a number with its unit, such as "),La=n("code"),qi=o('"10GiB"'),Li=o(" or "),Da=n("code"),Di=o('"10GB"'),Mi=o("."),ps=c(),Mt=n("p"),Bi=o("Here is an example where we don\u2019t want to use more than 10GiB on each of two GPUs and no more than 30GiB of CPU RAM:"),ms=c(),$(nt.$$.fragment),fs=c(),$(Ce.$$.fragment),us=c(),Bt=n("p"),zi=o("Additionally, it\u2019s important to know that the first GPU consumes more memory than the rest of the GPUs for managing activations, therefore if you would like to optimize the maximum batch size and you have many GPUs. Give the first GPU less memory. For example, with BLOOM-176B on 8x80 A100 setup the close to ideal map is:"),_s=c(),$(it.$$.fragment),gs=c(),q=n("p"),Ni=o(`as you can see we gave the remaining 7 GPUs ~50% more memory than GPU 0.
If you opt to fully design the `),Ma=n("code"),Oi=o("device_map"),Ri=o(" yourself, it should be a dictionary with keys being module names of your model and values being a valid device identifier (for instance an integer for the GPUs) or "),Ba=n("code"),Si=o('"cpu"'),Wi=o(" for CPU offload, "),za=n("code"),Fi=o('"disk"'),Hi=o(" for disk offload. The keys need to cover the whole model, you can then define your device map as you wish: for instance if your model has two blocks (let\u2019s say "),Na=n("code"),Yi=o("block1"),Ji=o(" and "),Oa=n("code"),Vi=o("block2"),Ki=o(") which each contain three linear layers (let\u2019s say "),Ra=n("code"),Qi=o("linear1"),Xi=o(", "),Sa=n("code"),Zi=o("linear2"),el=o(" and "),Wa=n("code"),tl=o("linear3"),al=o("), a valid device map can be:"),vs=c(),$(lt.$$.fragment),ws=c(),zt=n("p"),ol=o("another one that is valid could be:"),ys=c(),$(rt.$$.fragment),bs=c(),Nt=n("p"),sl=o("On the other hand, this one is not valid as it does not cover every parameter of the model:"),$s=c(),$(dt.$$.fragment),ks=c(),le=n("h2"),Ge=n("a"),Fa=n("span"),$(ct.$$.fragment),nl=c(),Ha=n("span"),il=o("Limits and further development"),Ps=c(),Ot=n("p"),ll=o("We are aware of the current limitations in the API:"),xs=c(),L=n("ul"),Ya=n("li"),rl=o("While this could theoretically work on just one CPU with potential disk offload, you need at least one GPU to run this API. This will be fixed in further development."),dl=c(),X=n("li"),Rt=n("a"),cl=o("infer_auto_device_map()"),hl=o(" (or "),Ja=n("code"),pl=o('device_map="auto"'),ml=o(" in "),St=n("a"),fl=o("load_checkpoint_and_dispatch()"),ul=o(") tries to maximize GPU and CPU RAM it sees available when you execute it. While PyTorch is very good at managing GPU RAM efficiently (and giving it back when not needed), it\u2019s not entirely true with Python and CPU RAM. Therefore, an automatically computed device map might be too intense on the CPU. Move a few modules to the disk device if you get crashes due to lack of RAM."),_l=c(),Z=n("li"),Wt=n("a"),gl=o("infer_auto_device_map()"),vl=o(" (or "),Va=n("code"),wl=o('device_map="auto"'),yl=o(" in "),Ft=n("a"),bl=o("load_checkpoint_and_dispatch()"),$l=o(") attributes devices sequentially (to avoid moving things back and forth) so if your first layer is bigger than the size of the GPU you have, it will end up with everything on the CPU/Disk."),kl=c(),Ie=n("li"),Ht=n("a"),Pl=o("load_checkpoint_and_dispatch()"),xl=o(" and "),Yt=n("a"),jl=o("load_checkpoint_in_model()"),El=o(" do not perform any check on the correctness of your state dict compared to your model at the moment (this will be fixed in a future version), so you may get some weird errors if trying to load a checkpoint with mismatched or missing keys."),Al=c(),Ka=n("li"),Ul=o("The model parallelism used when your model is split on several GPUs is naive and not optimized, meaning that only one GPU works at a given time and the other sits idle."),Cl=c(),Qa=n("li"),Gl=o("When weights are offloaded on the CPU/hard drive, there is no pre-fetching (yet, we will work on this for future versions) which means the weights are put on the GPU when they are needed and not before."),Il=c(),Xa=n("li"),Tl=o("Hard-drive offloading might be very slow if the hardware you run on does not have fast communication between disk and CPU (like NVMes)."),js=c(),re=n("h2"),Te=n("a"),Za=n("span"),$(ht.$$.fragment),ql=c(),eo=n("span"),Ll=o("API doc"),Es=c(),de=n("div"),$(pt.$$.fragment),Dl=c(),to=n("p"),Ml=o(`Activates full CPU offload for a model. As a result, all parameters of the model will be offloaded and only one
copy of the state dict of the model will be kept. During the forward pass, parameters will be extracted from that
state dict and put on the execution device passed as they are needed, then offloaded again.`),As=c(),ce=n("div"),$(mt.$$.fragment),Bl=c(),ao=n("p"),zl=o(`Activates full disk offload for a model. As a result, all parameters of the model will be offloaded as
memory-mapped array in a given folder. During the forward pass, parameters will be accessed from that folder and
put on the execution device passed as they are needed, then offloaded again.`),Us=c(),he=n("div"),$(ft.$$.fragment),Nl=c(),oo=n("p"),Ol=o(`Dispatches a model according to a given device map. Layers of the model might be spread across GPUs, offloaded on
the CPU or even the disk.`),Cs=c(),R=n("div"),$(ut.$$.fragment),Rl=c(),so=n("p"),Sl=o(`Compute a device map for a given model giving priority to GPUs, then offload on CPU and finally offload to disk,
such that:`),Wl=c(),H=n("ul"),no=n("li"),Fl=o("we don\u2019t exceed the memory available of any of the GPU."),Hl=c(),io=n("li"),Yl=o(`if offload to the CPU is needed, there is always room left on GPU 0 to put back the layer offloaded on CPU that
has the largest size.`),Jl=c(),lo=n("li"),Vl=o("if offload to the CPU is needed,we don\u2019t exceed the RAM available on the CPU."),Kl=c(),ro=n("li"),Ql=o(`if offload to the disk is needed, there is always room left on the CPU to put back the layer offloaded on disk
that has the largest size.`),Xl=c(),$(qe.$$.fragment),Gs=c(),S=n("div"),$(_t.$$.fragment),Zl=c(),co=n("p"),er=o(`A context manager under which models are initialized with all parameters on the meta device, therefore creating an
empty model. Useful when just initializing the model would blow the available RAM.`),tr=c(),$(Le.$$.fragment),ar=c(),$(De.$$.fragment),Is=c(),pe=n("div"),$(gt.$$.fragment),or=c(),ho=n("p"),sr=o(`Loads a (potentially sharded) checkpoint inside a model, potentially sending weights to a given device as they are
loaded and adds the various hooks that will make this model run properly (even if split across devices).`),Ts=c(),Y=n("div"),$(vt.$$.fragment),nr=c(),po=n("p"),ir=o(`Loads a (potentially sharded) checkpoint inside a model, potentially sending weights to a given device as they are
loaded.`),lr=c(),$(Me.$$.fragment),this.h()},l(e){const l=hc('[data-svelte="svelte-1phssyn"]',document.head);p=i(l,"META",{name:!0,content:!0}),l.forEach(a),v=h(e),m=i(e,"H1",{class:!0});var wt=r(m);u=i(wt,"A",{id:!0,class:!0,href:!0});var mo=r(u);b=i(mo,"SPAN",{});var fo=r(b);k(f.$$.fragment,fo),fo.forEach(a),mo.forEach(a),g=h(wt),U=i(wt,"SPAN",{});var uo=r(U);E=s(uo,"Handling big models"),uo.forEach(a),wt.forEach(a),C=h(e),G=i(e,"P",{});var _o=r(G);j=s(_o,"When loading a pretrained model in PyTorch, the usual workflow looks like this:"),_o.forEach(a),I=h(e),k(O.$$.fragment,e),F=h(e),ee=i(e,"P",{});var go=r(ee);Xs=s(go,"In plain English, those steps are:"),go.forEach(a),$o=h(e),J=i(e,"OL",{});var me=r(J);Xt=i(me,"LI",{});var vo=r(Xt);Zs=s(vo,"Create the model with randomly initialized weights"),vo.forEach(a),en=h(me),Zt=i(me,"LI",{});var wo=r(Zt);tn=s(wo,"Load the model weights (in a dictionary usually called a state dict) from the disk"),wo.forEach(a),an=h(me),ea=i(me,"LI",{});var rr=r(ea);on=s(rr,"Load those weights inside the model"),rr.forEach(a),me.forEach(a),ko=h(e),kt=i(e,"P",{});var dr=r(kt);sn=s(dr,"While this works very well for regularly sized models, this workflow has some clear limitations when we deal with a huge model: in step 1, we load a full version of the model in RAM, and spend some time randomly initializing the weights (which will be discarded in step 3). In step 2, we load another full version of the model in RAM, with the pretrained weights. If you\u2019re loading a model with 6 billions parameters, this means you will need 24GB of RAM for each copy of the model, so 48GB in total (half of it to load the model in FP16)."),dr.forEach(a),Po=h(e),k(ue.$$.fragment,e),xo=h(e),te=i(e,"H2",{class:!0});var Ls=r(te);_e=i(Ls,"A",{id:!0,class:!0,href:!0});var cr=r(_e);ta=i(cr,"SPAN",{});var hr=r(ta);k(Re.$$.fragment,hr),hr.forEach(a),cr.forEach(a),nn=h(Ls),aa=i(Ls,"SPAN",{});var pr=r(aa);ln=s(pr,"Instantiating an empty model"),pr.forEach(a),Ls.forEach(a),jo=h(e),ge=i(e,"P",{});var Ds=r(ge);rn=s(Ds,"The first tool \u{1F917} Accelerate introduces to help with big models is a context manager "),Pt=i(Ds,"A",{href:!0});var mr=r(Pt);dn=s(mr,"init_empty_weights()"),mr.forEach(a),cn=s(Ds," that helps you initialize a model without using any RAM, so that step 1 can be done on models of any size. Here is how it works:"),Ds.forEach(a),Eo=h(e),k(Se.$$.fragment,e),Ao=h(e),xt=i(e,"P",{});var fr=r(xt);hn=s(fr,"For instance:"),fr.forEach(a),Uo=h(e),k(We.$$.fragment,e),Co=h(e),jt=i(e,"P",{});var ur=r(jt);pn=s(ur,"initializes an empty model with a bit more than 100B parameters. Behind the scenes, this relies on the meta device introduced in PyTorch 1.9. During the initialization under the context manager, each time a parameter is created, it is instantly moved on that device."),ur.forEach(a),Go=h(e),k(ve.$$.fragment,e),Io=h(e),ae=i(e,"H2",{class:!0});var Ms=r(ae);we=i(Ms,"A",{id:!0,class:!0,href:!0});var _r=r(we);oa=i(_r,"SPAN",{});var gr=r(oa);k(Fe.$$.fragment,gr),gr.forEach(a),_r.forEach(a),mn=h(Ms),sa=i(Ms,"SPAN",{});var vr=r(sa);fn=s(vr,"Sharded checkpoints"),vr.forEach(a),Ms.forEach(a),To=h(e),Et=i(e,"P",{});var wr=r(Et);un=s(wr,"It\u2019s possible your model is so big that even a single copy won\u2019t fit in RAM. That doesn\u2019t mean it can\u2019t be loaded: if you have one or several GPUs, this is more memory available to store your model. In this case, it\u2019s better if your checkpoint is split in several smaller files that we call checkpoint shards."),wr.forEach(a),qo=h(e),At=i(e,"P",{});var yr=r(At);_n=s(yr,"\u{1F917} Accelerate will handle sharded checkpoints as long as you follow the following format: your checkpoint should be in a folder, with several files containing the partial state dicts, and there should be an index in the JSON format that contains a dictionary mapping parameter names to the file containing their weights. For instance we could have a folder containing:"),yr.forEach(a),Lo=h(e),k(He.$$.fragment,e),Do=h(e),Ut=i(e,"P",{});var br=r(Ut);gn=s(br,"with index.json being the following file:"),br.forEach(a),Mo=h(e),k(Ye.$$.fragment,e),Bo=h(e),z=i(e,"P",{});var W=r(z);vn=s(W,"and "),na=i(W,"CODE",{});var $r=r(na);wn=s($r,"first_state_dict.bin"),$r.forEach(a),yn=s(W," containing the weights for "),ia=i(W,"CODE",{});var kr=r(ia);bn=s(kr,'"linear1.weight"'),kr.forEach(a),$n=s(W," and "),la=i(W,"CODE",{});var Pr=r(la);kn=s(Pr,'"linear1.bias"'),Pr.forEach(a),Pn=s(W,", "),ra=i(W,"CODE",{});var xr=r(ra);xn=s(xr,"second_state_dict.bin"),xr.forEach(a),jn=s(W," the ones for "),da=i(W,"CODE",{});var jr=r(da);En=s(jr,'"linear2.weight"'),jr.forEach(a),An=s(W," and "),ca=i(W,"CODE",{});var Er=r(ca);Un=s(Er,'"linear2.bias"'),Er.forEach(a),W.forEach(a),zo=h(e),oe=i(e,"H2",{class:!0});var Bs=r(oe);ye=i(Bs,"A",{id:!0,class:!0,href:!0});var Ar=r(ye);ha=i(Ar,"SPAN",{});var Ur=r(ha);k(Je.$$.fragment,Ur),Ur.forEach(a),Ar.forEach(a),Cn=h(Bs),pa=i(Bs,"SPAN",{});var Cr=r(pa);Gn=s(Cr,"Loading weights"),Cr.forEach(a),Bs.forEach(a),No=h(e),be=i(e,"P",{});var zs=r(be);In=s(zs,"The second tool \u{1F917} Accelerate introduces is a function "),Ct=i(zs,"A",{href:!0});var Gr=r(Ct);Tn=s(Gr,"load_checkpoint_and_dispatch()"),Gr.forEach(a),qn=s(zs,", that will allow you to load a checkpoint inside your empty model. This supports full checkpoints (a single file containing the whole state dict) as well as sharded checkpoints. It will also automatically dispatch those weights across the devices you have available (GPUs, CPU RAM), so if you are loading a sharded checkpoint, the maximum RAM usage will be the size of the biggest shard."),zs.forEach(a),Oo=h(e),$e=i(e,"P",{});var Ns=r($e);Ln=s(Ns,"Here is how we can use this to load the "),Ve=i(Ns,"A",{href:!0,rel:!0});var Ir=r(Ve);Dn=s(Ir,"GPT-J-6B"),Ir.forEach(a),Mn=s(Ns," model. You clone the sharded version of this model with:"),Ns.forEach(a),Ro=h(e),k(Ke.$$.fragment,e),So=h(e),Gt=i(e,"P",{});var Tr=r(Gt);Bn=s(Tr,"then we can initialize the model with"),Tr.forEach(a),Wo=h(e),k(Qe.$$.fragment,e),Fo=h(e),It=i(e,"P",{});var qr=r(It);zn=s(qr,"and load the checkpoint we just downloaded with:"),qr.forEach(a),Ho=h(e),k(Xe.$$.fragment,e),Yo=h(e),ke=i(e,"P",{});var Os=r(ke);Nn=s(Os,"By passing "),ma=i(Os,"CODE",{});var Lr=r(ma);On=s(Lr,'device_map="auto"'),Lr.forEach(a),Rn=s(Os,", we tell \u{1F917} Accelerate to determine automatically where to put each layer of the model depending on the available resources:"),Os.forEach(a),Jo=h(e),V=i(e,"UL",{});var Jt=r(V);fa=i(Jt,"LI",{});var Dr=r(fa);Sn=s(Dr,"first we use the maximum space available on the GPU(s)"),Dr.forEach(a),Wn=h(Jt),ua=i(Jt,"LI",{});var Mr=r(ua);Fn=s(Mr,"if we still need space, we store the remaining weights on the CPU"),Mr.forEach(a),Hn=h(Jt),_a=i(Jt,"LI",{});var Br=r(_a);Yn=s(Br,"if there is not enough RAM, we store the remaining weights on the hard drive as memory-mapped tensors"),Br.forEach(a),Jt.forEach(a),Vo=h(e),se=i(e,"P",{});var yo=r(se);ga=i(yo,"CODE",{});var zr=r(ga);Jn=s(zr,'no_split_module_classes=["GPTJBlock"]'),zr.forEach(a),Vn=s(yo," indicates that the modules that are "),va=i(yo,"CODE",{});var Nr=r(va);Kn=s(Nr,"GPTJBlock"),Nr.forEach(a),Qn=s(yo," should not be split on different devices. You should set here all blocks that include a residual connection of some kind."),yo.forEach(a),Ko=h(e),K=i(e,"P",{});var Vt=r(K);Xn=s(Vt,"You can see the "),wa=i(Vt,"CODE",{});var Or=r(wa);Zn=s(Or,"device_map"),Or.forEach(a),ei=s(Vt," that \u{1F917} Accelerate picked by accessing the "),ya=i(Vt,"CODE",{});var Rr=r(ya);ti=s(Rr,"hf_device_map"),Rr.forEach(a),ai=s(Vt," attribute of your model:"),Vt.forEach(a),Qo=h(e),k(Ze.$$.fragment,e),Xo=h(e),k(et.$$.fragment,e),Zo=h(e),Pe=i(e,"P",{});var Rs=r(Pe);oi=s(Rs,"You can also design your "),ba=i(Rs,"CODE",{});var Sr=r(ba);si=s(Sr,"device_map"),Sr.forEach(a),ni=s(Rs," yourself, if you prefer to explicitly decide where each layer should be. In this case, the command above becomes:"),Rs.forEach(a),es=h(e),k(tt.$$.fragment,e),ts=h(e),ne=i(e,"H2",{class:!0});var Ss=r(ne);xe=i(Ss,"A",{id:!0,class:!0,href:!0});var Wr=r(xe);$a=i(Wr,"SPAN",{});var Fr=r($a);k(at.$$.fragment,Fr),Fr.forEach(a),Wr.forEach(a),ii=h(Ss),ka=i(Ss,"SPAN",{});var Hr=r(ka);li=s(Hr,"Run the model"),Hr.forEach(a),Ss.forEach(a),as=h(e),Tt=i(e,"P",{});var Yr=r(Tt);ri=s(Yr,"Now that we have done this, our model lies across several devices, and maybe the hard drive. But it can still be used as a regular PyTorch model:"),Yr.forEach(a),os=h(e),k(ot.$$.fragment,e),ss=h(e),qt=i(e,"P",{});var Jr=r(qt);di=s(Jr,"Behind the scenes, \u{1F917} Accelerate added hooks to the model, so that:"),Jr.forEach(a),ns=h(e),Q=i(e,"UL",{});var Kt=r(Q);Pa=i(Kt,"LI",{});var Vr=r(Pa);ci=s(Vr,"at each layer, the inputs are put on the right device (so even if your model is spread across several GPUs, it works)"),Vr.forEach(a),hi=h(Kt),xa=i(Kt,"LI",{});var Kr=r(xa);pi=s(Kr,"for the weights offloaded on the CPU, they are put on a GPU just before the forward pass, and cleaned up just after"),Kr.forEach(a),mi=h(Kt),ja=i(Kt,"LI",{});var Qr=r(ja);fi=s(Qr,"for the weights offloaded on the hard drive, they are loaded in RAM then put on a GPU just before the forward pass, and cleaned up just after"),Qr.forEach(a),Kt.forEach(a),is=h(e),Lt=i(e,"P",{});var Xr=r(Lt);ui=s(Xr,"This way, you model can run for inference even if it doesn\u2019t fit on one of the GPUs or the CPU RAM!"),Xr.forEach(a),ls=h(e),k(je.$$.fragment,e),rs=h(e),ie=i(e,"H2",{class:!0});var Ws=r(ie);Ee=i(Ws,"A",{id:!0,class:!0,href:!0});var Zr=r(Ee);Ea=i(Zr,"SPAN",{});var ed=r(Ea);k(st.$$.fragment,ed),ed.forEach(a),Zr.forEach(a),_i=h(Ws),Aa=i(Ws,"SPAN",{});var td=r(Aa);gi=s(td,"Designing a device map"),td.forEach(a),Ws.forEach(a),ds=h(e),Ae=i(e,"P",{});var Fs=r(Ae);vi=s(Fs,"You can let \u{1F917} Accelerate handle the device map computation by setting "),Ua=i(Fs,"CODE",{});var ad=r(Ua);wi=s(ad,'device_map="auto"'),ad.forEach(a),yi=s(Fs," or create one yourself, if you want more control over where each layer should go."),Fs.forEach(a),cs=h(e),k(Ue.$$.fragment,e),hs=h(e),T=i(e,"P",{});var D=r(T);bi=s(D,"First note that you can limit the memory used on each GPU by using the "),Ca=i(D,"CODE",{});var od=r(Ca);$i=s(od,"max_memory"),od.forEach(a),ki=s(D," argument (available in "),Dt=i(D,"A",{href:!0});var sd=r(Dt);Pi=s(sd,"infer_auto_device_map()"),sd.forEach(a),xi=s(D," and in all functions using it). When setting "),Ga=i(D,"CODE",{});var nd=r(Ga);ji=s(nd,"max_memory"),nd.forEach(a),Ei=s(D,", you should pass along a dictionary containing the GPU identifiers (for instance "),Ia=i(D,"CODE",{});var id=r(Ia);Ai=s(id,"0"),id.forEach(a),Ui=s(D,", "),Ta=i(D,"CODE",{});var ld=r(Ta);Ci=s(ld,"1"),ld.forEach(a),Gi=s(D," etc.) and the "),qa=i(D,"CODE",{});var rd=r(qa);Ii=s(rd,'"cpu"'),rd.forEach(a),Ti=s(D," key for the maximum RAM you want used for CPU offload. The values can either be an integer (in bytes) or a string representing a number with its unit, such as "),La=i(D,"CODE",{});var dd=r(La);qi=s(dd,'"10GiB"'),dd.forEach(a),Li=s(D," or "),Da=i(D,"CODE",{});var cd=r(Da);Di=s(cd,'"10GB"'),cd.forEach(a),Mi=s(D,"."),D.forEach(a),ps=h(e),Mt=i(e,"P",{});var hd=r(Mt);Bi=s(hd,"Here is an example where we don\u2019t want to use more than 10GiB on each of two GPUs and no more than 30GiB of CPU RAM:"),hd.forEach(a),ms=h(e),k(nt.$$.fragment,e),fs=h(e),k(Ce.$$.fragment,e),us=h(e),Bt=i(e,"P",{});var pd=r(Bt);zi=s(pd,"Additionally, it\u2019s important to know that the first GPU consumes more memory than the rest of the GPUs for managing activations, therefore if you would like to optimize the maximum batch size and you have many GPUs. Give the first GPU less memory. For example, with BLOOM-176B on 8x80 A100 setup the close to ideal map is:"),pd.forEach(a),_s=h(e),k(it.$$.fragment,e),gs=h(e),q=i(e,"P",{});var M=r(q);Ni=s(M,`as you can see we gave the remaining 7 GPUs ~50% more memory than GPU 0.
If you opt to fully design the `),Ma=i(M,"CODE",{});var md=r(Ma);Oi=s(md,"device_map"),md.forEach(a),Ri=s(M," yourself, it should be a dictionary with keys being module names of your model and values being a valid device identifier (for instance an integer for the GPUs) or "),Ba=i(M,"CODE",{});var fd=r(Ba);Si=s(fd,'"cpu"'),fd.forEach(a),Wi=s(M," for CPU offload, "),za=i(M,"CODE",{});var ud=r(za);Fi=s(ud,'"disk"'),ud.forEach(a),Hi=s(M," for disk offload. The keys need to cover the whole model, you can then define your device map as you wish: for instance if your model has two blocks (let\u2019s say "),Na=i(M,"CODE",{});var _d=r(Na);Yi=s(_d,"block1"),_d.forEach(a),Ji=s(M," and "),Oa=i(M,"CODE",{});var gd=r(Oa);Vi=s(gd,"block2"),gd.forEach(a),Ki=s(M,") which each contain three linear layers (let\u2019s say "),Ra=i(M,"CODE",{});var vd=r(Ra);Qi=s(vd,"linear1"),vd.forEach(a),Xi=s(M,", "),Sa=i(M,"CODE",{});var wd=r(Sa);Zi=s(wd,"linear2"),wd.forEach(a),el=s(M," and "),Wa=i(M,"CODE",{});var yd=r(Wa);tl=s(yd,"linear3"),yd.forEach(a),al=s(M,"), a valid device map can be:"),M.forEach(a),vs=h(e),k(lt.$$.fragment,e),ws=h(e),zt=i(e,"P",{});var bd=r(zt);ol=s(bd,"another one that is valid could be:"),bd.forEach(a),ys=h(e),k(rt.$$.fragment,e),bs=h(e),Nt=i(e,"P",{});var $d=r(Nt);sl=s($d,"On the other hand, this one is not valid as it does not cover every parameter of the model:"),$d.forEach(a),$s=h(e),k(dt.$$.fragment,e),ks=h(e),le=i(e,"H2",{class:!0});var Hs=r(le);Ge=i(Hs,"A",{id:!0,class:!0,href:!0});var kd=r(Ge);Fa=i(kd,"SPAN",{});var Pd=r(Fa);k(ct.$$.fragment,Pd),Pd.forEach(a),kd.forEach(a),nl=h(Hs),Ha=i(Hs,"SPAN",{});var xd=r(Ha);il=s(xd,"Limits and further development"),xd.forEach(a),Hs.forEach(a),Ps=h(e),Ot=i(e,"P",{});var jd=r(Ot);ll=s(jd,"We are aware of the current limitations in the API:"),jd.forEach(a),xs=h(e),L=i(e,"UL",{});var N=r(L);Ya=i(N,"LI",{});var Ed=r(Ya);rl=s(Ed,"While this could theoretically work on just one CPU with potential disk offload, you need at least one GPU to run this API. This will be fixed in further development."),Ed.forEach(a),dl=h(N),X=i(N,"LI",{});var yt=r(X);Rt=i(yt,"A",{href:!0});var Ad=r(Rt);cl=s(Ad,"infer_auto_device_map()"),Ad.forEach(a),hl=s(yt," (or "),Ja=i(yt,"CODE",{});var Ud=r(Ja);pl=s(Ud,'device_map="auto"'),Ud.forEach(a),ml=s(yt," in "),St=i(yt,"A",{href:!0});var Cd=r(St);fl=s(Cd,"load_checkpoint_and_dispatch()"),Cd.forEach(a),ul=s(yt,") tries to maximize GPU and CPU RAM it sees available when you execute it. While PyTorch is very good at managing GPU RAM efficiently (and giving it back when not needed), it\u2019s not entirely true with Python and CPU RAM. Therefore, an automatically computed device map might be too intense on the CPU. Move a few modules to the disk device if you get crashes due to lack of RAM."),yt.forEach(a),_l=h(N),Z=i(N,"LI",{});var bt=r(Z);Wt=i(bt,"A",{href:!0});var Gd=r(Wt);gl=s(Gd,"infer_auto_device_map()"),Gd.forEach(a),vl=s(bt," (or "),Va=i(bt,"CODE",{});var Id=r(Va);wl=s(Id,'device_map="auto"'),Id.forEach(a),yl=s(bt," in "),Ft=i(bt,"A",{href:!0});var Td=r(Ft);bl=s(Td,"load_checkpoint_and_dispatch()"),Td.forEach(a),$l=s(bt,") attributes devices sequentially (to avoid moving things back and forth) so if your first layer is bigger than the size of the GPU you have, it will end up with everything on the CPU/Disk."),bt.forEach(a),kl=h(N),Ie=i(N,"LI",{});var bo=r(Ie);Ht=i(bo,"A",{href:!0});var qd=r(Ht);Pl=s(qd,"load_checkpoint_and_dispatch()"),qd.forEach(a),xl=s(bo," and "),Yt=i(bo,"A",{href:!0});var Ld=r(Yt);jl=s(Ld,"load_checkpoint_in_model()"),Ld.forEach(a),El=s(bo," do not perform any check on the correctness of your state dict compared to your model at the moment (this will be fixed in a future version), so you may get some weird errors if trying to load a checkpoint with mismatched or missing keys."),bo.forEach(a),Al=h(N),Ka=i(N,"LI",{});var Dd=r(Ka);Ul=s(Dd,"The model parallelism used when your model is split on several GPUs is naive and not optimized, meaning that only one GPU works at a given time and the other sits idle."),Dd.forEach(a),Cl=h(N),Qa=i(N,"LI",{});var Md=r(Qa);Gl=s(Md,"When weights are offloaded on the CPU/hard drive, there is no pre-fetching (yet, we will work on this for future versions) which means the weights are put on the GPU when they are needed and not before."),Md.forEach(a),Il=h(N),Xa=i(N,"LI",{});var Bd=r(Xa);Tl=s(Bd,"Hard-drive offloading might be very slow if the hardware you run on does not have fast communication between disk and CPU (like NVMes)."),Bd.forEach(a),N.forEach(a),js=h(e),re=i(e,"H2",{class:!0});var Ys=r(re);Te=i(Ys,"A",{id:!0,class:!0,href:!0});var zd=r(Te);Za=i(zd,"SPAN",{});var Nd=r(Za);k(ht.$$.fragment,Nd),Nd.forEach(a),zd.forEach(a),ql=h(Ys),eo=i(Ys,"SPAN",{});var Od=r(eo);Ll=s(Od,"API doc"),Od.forEach(a),Ys.forEach(a),Es=h(e),de=i(e,"DIV",{class:!0});var Js=r(de);k(pt.$$.fragment,Js),Dl=h(Js),to=i(Js,"P",{});var Rd=r(to);Ml=s(Rd,`Activates full CPU offload for a model. As a result, all parameters of the model will be offloaded and only one
copy of the state dict of the model will be kept. During the forward pass, parameters will be extracted from that
state dict and put on the execution device passed as they are needed, then offloaded again.`),Rd.forEach(a),Js.forEach(a),As=h(e),ce=i(e,"DIV",{class:!0});var Vs=r(ce);k(mt.$$.fragment,Vs),Bl=h(Vs),ao=i(Vs,"P",{});var Sd=r(ao);zl=s(Sd,`Activates full disk offload for a model. As a result, all parameters of the model will be offloaded as
memory-mapped array in a given folder. During the forward pass, parameters will be accessed from that folder and
put on the execution device passed as they are needed, then offloaded again.`),Sd.forEach(a),Vs.forEach(a),Us=h(e),he=i(e,"DIV",{class:!0});var Ks=r(he);k(ft.$$.fragment,Ks),Nl=h(Ks),oo=i(Ks,"P",{});var Wd=r(oo);Ol=s(Wd,`Dispatches a model according to a given device map. Layers of the model might be spread across GPUs, offloaded on
the CPU or even the disk.`),Wd.forEach(a),Ks.forEach(a),Cs=h(e),R=i(e,"DIV",{class:!0});var Be=r(R);k(ut.$$.fragment,Be),Rl=h(Be),so=i(Be,"P",{});var Fd=r(so);Sl=s(Fd,`Compute a device map for a given model giving priority to GPUs, then offload on CPU and finally offload to disk,
such that:`),Fd.forEach(a),Wl=h(Be),H=i(Be,"UL",{});var ze=r(H);no=i(ze,"LI",{});var Hd=r(no);Fl=s(Hd,"we don\u2019t exceed the memory available of any of the GPU."),Hd.forEach(a),Hl=h(ze),io=i(ze,"LI",{});var Yd=r(io);Yl=s(Yd,`if offload to the CPU is needed, there is always room left on GPU 0 to put back the layer offloaded on CPU that
has the largest size.`),Yd.forEach(a),Jl=h(ze),lo=i(ze,"LI",{});var Jd=r(lo);Vl=s(Jd,"if offload to the CPU is needed,we don\u2019t exceed the RAM available on the CPU."),Jd.forEach(a),Kl=h(ze),ro=i(ze,"LI",{});var Vd=r(ro);Ql=s(Vd,`if offload to the disk is needed, there is always room left on the CPU to put back the layer offloaded on disk
that has the largest size.`),Vd.forEach(a),ze.forEach(a),Xl=h(Be),k(qe.$$.fragment,Be),Be.forEach(a),Gs=h(e),S=i(e,"DIV",{class:!0});var Ne=r(S);k(_t.$$.fragment,Ne),Zl=h(Ne),co=i(Ne,"P",{});var Kd=r(co);er=s(Kd,`A context manager under which models are initialized with all parameters on the meta device, therefore creating an
empty model. Useful when just initializing the model would blow the available RAM.`),Kd.forEach(a),tr=h(Ne),k(Le.$$.fragment,Ne),ar=h(Ne),k(De.$$.fragment,Ne),Ne.forEach(a),Is=h(e),pe=i(e,"DIV",{class:!0});var Qs=r(pe);k(gt.$$.fragment,Qs),or=h(Qs),ho=i(Qs,"P",{});var Qd=r(ho);sr=s(Qd,`Loads a (potentially sharded) checkpoint inside a model, potentially sending weights to a given device as they are
loaded and adds the various hooks that will make this model run properly (even if split across devices).`),Qd.forEach(a),Qs.forEach(a),Ts=h(e),Y=i(e,"DIV",{class:!0});var Qt=r(Y);k(vt.$$.fragment,Qt),nr=h(Qt),po=i(Qt,"P",{});var Xd=r(po);ir=s(Xd,`Loads a (potentially sharded) checkpoint inside a model, potentially sending weights to a given device as they are
loaded.`),Xd.forEach(a),lr=h(Qt),k(Me.$$.fragment,Qt),Qt.forEach(a),this.h()},h(){_(p,"name","hf:doc:metadata"),_(p,"content",JSON.stringify(Ec)),_(u,"id","handling-big-models"),_(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(u,"href","#handling-big-models"),_(m,"class","relative group"),_(_e,"id","instantiating-an-empty-model"),_(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(_e,"href","#instantiating-an-empty-model"),_(te,"class","relative group"),_(Pt,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.init_empty_weights"),_(we,"id","sharded-checkpoints"),_(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(we,"href","#sharded-checkpoints"),_(ae,"class","relative group"),_(ye,"id","accelerate.cpu_offload"),_(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ye,"href","#accelerate.cpu_offload"),_(oe,"class","relative group"),_(Ct,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.load_checkpoint_and_dispatch"),_(Ve,"href","https://huggingface.co/EleutherAI/gpt-j-6B"),_(Ve,"rel","nofollow"),_(xe,"id","run-the-model"),_(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(xe,"href","#run-the-model"),_(ne,"class","relative group"),_(Ee,"id","designing-a-device-map"),_(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ee,"href","#designing-a-device-map"),_(ie,"class","relative group"),_(Dt,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.infer_auto_device_map"),_(Ge,"id","limits-and-further-development"),_(Ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ge,"href","#limits-and-further-development"),_(le,"class","relative group"),_(Rt,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.infer_auto_device_map"),_(St,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.load_checkpoint_and_dispatch"),_(Wt,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.infer_auto_device_map"),_(Ft,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.load_checkpoint_and_dispatch"),_(Ht,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.load_checkpoint_and_dispatch"),_(Yt,"href","/docs/accelerate/pr_530/en/big_modeling#accelerate.load_checkpoint_in_model"),_(Te,"id","api-doc"),_(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Te,"href","#api-doc"),_(re,"class","relative group"),_(de,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(he,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,l){t(document.head,p),d(e,v,l),d(e,m,l),t(m,u),t(u,b),P(f,b,null),t(m,g),t(m,U),t(U,E),d(e,C,l),d(e,G,l),t(G,j),d(e,I,l),P(O,e,l),d(e,F,l),d(e,ee,l),t(ee,Xs),d(e,$o,l),d(e,J,l),t(J,Xt),t(Xt,Zs),t(J,en),t(J,Zt),t(Zt,tn),t(J,an),t(J,ea),t(ea,on),d(e,ko,l),d(e,kt,l),t(kt,sn),d(e,Po,l),P(ue,e,l),d(e,xo,l),d(e,te,l),t(te,_e),t(_e,ta),P(Re,ta,null),t(te,nn),t(te,aa),t(aa,ln),d(e,jo,l),d(e,ge,l),t(ge,rn),t(ge,Pt),t(Pt,dn),t(ge,cn),d(e,Eo,l),P(Se,e,l),d(e,Ao,l),d(e,xt,l),t(xt,hn),d(e,Uo,l),P(We,e,l),d(e,Co,l),d(e,jt,l),t(jt,pn),d(e,Go,l),P(ve,e,l),d(e,Io,l),d(e,ae,l),t(ae,we),t(we,oa),P(Fe,oa,null),t(ae,mn),t(ae,sa),t(sa,fn),d(e,To,l),d(e,Et,l),t(Et,un),d(e,qo,l),d(e,At,l),t(At,_n),d(e,Lo,l),P(He,e,l),d(e,Do,l),d(e,Ut,l),t(Ut,gn),d(e,Mo,l),P(Ye,e,l),d(e,Bo,l),d(e,z,l),t(z,vn),t(z,na),t(na,wn),t(z,yn),t(z,ia),t(ia,bn),t(z,$n),t(z,la),t(la,kn),t(z,Pn),t(z,ra),t(ra,xn),t(z,jn),t(z,da),t(da,En),t(z,An),t(z,ca),t(ca,Un),d(e,zo,l),d(e,oe,l),t(oe,ye),t(ye,ha),P(Je,ha,null),t(oe,Cn),t(oe,pa),t(pa,Gn),d(e,No,l),d(e,be,l),t(be,In),t(be,Ct),t(Ct,Tn),t(be,qn),d(e,Oo,l),d(e,$e,l),t($e,Ln),t($e,Ve),t(Ve,Dn),t($e,Mn),d(e,Ro,l),P(Ke,e,l),d(e,So,l),d(e,Gt,l),t(Gt,Bn),d(e,Wo,l),P(Qe,e,l),d(e,Fo,l),d(e,It,l),t(It,zn),d(e,Ho,l),P(Xe,e,l),d(e,Yo,l),d(e,ke,l),t(ke,Nn),t(ke,ma),t(ma,On),t(ke,Rn),d(e,Jo,l),d(e,V,l),t(V,fa),t(fa,Sn),t(V,Wn),t(V,ua),t(ua,Fn),t(V,Hn),t(V,_a),t(_a,Yn),d(e,Vo,l),d(e,se,l),t(se,ga),t(ga,Jn),t(se,Vn),t(se,va),t(va,Kn),t(se,Qn),d(e,Ko,l),d(e,K,l),t(K,Xn),t(K,wa),t(wa,Zn),t(K,ei),t(K,ya),t(ya,ti),t(K,ai),d(e,Qo,l),P(Ze,e,l),d(e,Xo,l),P(et,e,l),d(e,Zo,l),d(e,Pe,l),t(Pe,oi),t(Pe,ba),t(ba,si),t(Pe,ni),d(e,es,l),P(tt,e,l),d(e,ts,l),d(e,ne,l),t(ne,xe),t(xe,$a),P(at,$a,null),t(ne,ii),t(ne,ka),t(ka,li),d(e,as,l),d(e,Tt,l),t(Tt,ri),d(e,os,l),P(ot,e,l),d(e,ss,l),d(e,qt,l),t(qt,di),d(e,ns,l),d(e,Q,l),t(Q,Pa),t(Pa,ci),t(Q,hi),t(Q,xa),t(xa,pi),t(Q,mi),t(Q,ja),t(ja,fi),d(e,is,l),d(e,Lt,l),t(Lt,ui),d(e,ls,l),P(je,e,l),d(e,rs,l),d(e,ie,l),t(ie,Ee),t(Ee,Ea),P(st,Ea,null),t(ie,_i),t(ie,Aa),t(Aa,gi),d(e,ds,l),d(e,Ae,l),t(Ae,vi),t(Ae,Ua),t(Ua,wi),t(Ae,yi),d(e,cs,l),P(Ue,e,l),d(e,hs,l),d(e,T,l),t(T,bi),t(T,Ca),t(Ca,$i),t(T,ki),t(T,Dt),t(Dt,Pi),t(T,xi),t(T,Ga),t(Ga,ji),t(T,Ei),t(T,Ia),t(Ia,Ai),t(T,Ui),t(T,Ta),t(Ta,Ci),t(T,Gi),t(T,qa),t(qa,Ii),t(T,Ti),t(T,La),t(La,qi),t(T,Li),t(T,Da),t(Da,Di),t(T,Mi),d(e,ps,l),d(e,Mt,l),t(Mt,Bi),d(e,ms,l),P(nt,e,l),d(e,fs,l),P(Ce,e,l),d(e,us,l),d(e,Bt,l),t(Bt,zi),d(e,_s,l),P(it,e,l),d(e,gs,l),d(e,q,l),t(q,Ni),t(q,Ma),t(Ma,Oi),t(q,Ri),t(q,Ba),t(Ba,Si),t(q,Wi),t(q,za),t(za,Fi),t(q,Hi),t(q,Na),t(Na,Yi),t(q,Ji),t(q,Oa),t(Oa,Vi),t(q,Ki),t(q,Ra),t(Ra,Qi),t(q,Xi),t(q,Sa),t(Sa,Zi),t(q,el),t(q,Wa),t(Wa,tl),t(q,al),d(e,vs,l),P(lt,e,l),d(e,ws,l),d(e,zt,l),t(zt,ol),d(e,ys,l),P(rt,e,l),d(e,bs,l),d(e,Nt,l),t(Nt,sl),d(e,$s,l),P(dt,e,l),d(e,ks,l),d(e,le,l),t(le,Ge),t(Ge,Fa),P(ct,Fa,null),t(le,nl),t(le,Ha),t(Ha,il),d(e,Ps,l),d(e,Ot,l),t(Ot,ll),d(e,xs,l),d(e,L,l),t(L,Ya),t(Ya,rl),t(L,dl),t(L,X),t(X,Rt),t(Rt,cl),t(X,hl),t(X,Ja),t(Ja,pl),t(X,ml),t(X,St),t(St,fl),t(X,ul),t(L,_l),t(L,Z),t(Z,Wt),t(Wt,gl),t(Z,vl),t(Z,Va),t(Va,wl),t(Z,yl),t(Z,Ft),t(Ft,bl),t(Z,$l),t(L,kl),t(L,Ie),t(Ie,Ht),t(Ht,Pl),t(Ie,xl),t(Ie,Yt),t(Yt,jl),t(Ie,El),t(L,Al),t(L,Ka),t(Ka,Ul),t(L,Cl),t(L,Qa),t(Qa,Gl),t(L,Il),t(L,Xa),t(Xa,Tl),d(e,js,l),d(e,re,l),t(re,Te),t(Te,Za),P(ht,Za,null),t(re,ql),t(re,eo),t(eo,Ll),d(e,Es,l),d(e,de,l),P(pt,de,null),t(de,Dl),t(de,to),t(to,Ml),d(e,As,l),d(e,ce,l),P(mt,ce,null),t(ce,Bl),t(ce,ao),t(ao,zl),d(e,Us,l),d(e,he,l),P(ft,he,null),t(he,Nl),t(he,oo),t(oo,Ol),d(e,Cs,l),d(e,R,l),P(ut,R,null),t(R,Rl),t(R,so),t(so,Sl),t(R,Wl),t(R,H),t(H,no),t(no,Fl),t(H,Hl),t(H,io),t(io,Yl),t(H,Jl),t(H,lo),t(lo,Vl),t(H,Kl),t(H,ro),t(ro,Ql),t(R,Xl),P(qe,R,null),d(e,Gs,l),d(e,S,l),P(_t,S,null),t(S,Zl),t(S,co),t(co,er),t(S,tr),P(Le,S,null),t(S,ar),P(De,S,null),d(e,Is,l),d(e,pe,l),P(gt,pe,null),t(pe,or),t(pe,ho),t(ho,sr),d(e,Ts,l),d(e,Y,l),P(vt,Y,null),t(Y,nr),t(Y,po),t(po,ir),t(Y,lr),P(Me,Y,null),qs=!0},p(e,[l]){const wt={};l&2&&(wt.$$scope={dirty:l,ctx:e}),ue.$set(wt);const mo={};l&2&&(mo.$$scope={dirty:l,ctx:e}),ve.$set(mo);const fo={};l&2&&(fo.$$scope={dirty:l,ctx:e}),je.$set(fo);const uo={};l&2&&(uo.$$scope={dirty:l,ctx:e}),Ue.$set(uo);const _o={};l&2&&(_o.$$scope={dirty:l,ctx:e}),Ce.$set(_o);const go={};l&2&&(go.$$scope={dirty:l,ctx:e}),qe.$set(go);const me={};l&2&&(me.$$scope={dirty:l,ctx:e}),Le.$set(me);const vo={};l&2&&(vo.$$scope={dirty:l,ctx:e}),De.$set(vo);const wo={};l&2&&(wo.$$scope={dirty:l,ctx:e}),Me.$set(wo)},i(e){qs||(w(f.$$.fragment,e),w(O.$$.fragment,e),w(ue.$$.fragment,e),w(Re.$$.fragment,e),w(Se.$$.fragment,e),w(We.$$.fragment,e),w(ve.$$.fragment,e),w(Fe.$$.fragment,e),w(He.$$.fragment,e),w(Ye.$$.fragment,e),w(Je.$$.fragment,e),w(Ke.$$.fragment,e),w(Qe.$$.fragment,e),w(Xe.$$.fragment,e),w(Ze.$$.fragment,e),w(et.$$.fragment,e),w(tt.$$.fragment,e),w(at.$$.fragment,e),w(ot.$$.fragment,e),w(je.$$.fragment,e),w(st.$$.fragment,e),w(Ue.$$.fragment,e),w(nt.$$.fragment,e),w(Ce.$$.fragment,e),w(it.$$.fragment,e),w(lt.$$.fragment,e),w(rt.$$.fragment,e),w(dt.$$.fragment,e),w(ct.$$.fragment,e),w(ht.$$.fragment,e),w(pt.$$.fragment,e),w(mt.$$.fragment,e),w(ft.$$.fragment,e),w(ut.$$.fragment,e),w(qe.$$.fragment,e),w(_t.$$.fragment,e),w(Le.$$.fragment,e),w(De.$$.fragment,e),w(gt.$$.fragment,e),w(vt.$$.fragment,e),w(Me.$$.fragment,e),qs=!0)},o(e){y(f.$$.fragment,e),y(O.$$.fragment,e),y(ue.$$.fragment,e),y(Re.$$.fragment,e),y(Se.$$.fragment,e),y(We.$$.fragment,e),y(ve.$$.fragment,e),y(Fe.$$.fragment,e),y(He.$$.fragment,e),y(Ye.$$.fragment,e),y(Je.$$.fragment,e),y(Ke.$$.fragment,e),y(Qe.$$.fragment,e),y(Xe.$$.fragment,e),y(Ze.$$.fragment,e),y(et.$$.fragment,e),y(tt.$$.fragment,e),y(at.$$.fragment,e),y(ot.$$.fragment,e),y(je.$$.fragment,e),y(st.$$.fragment,e),y(Ue.$$.fragment,e),y(nt.$$.fragment,e),y(Ce.$$.fragment,e),y(it.$$.fragment,e),y(lt.$$.fragment,e),y(rt.$$.fragment,e),y(dt.$$.fragment,e),y(ct.$$.fragment,e),y(ht.$$.fragment,e),y(pt.$$.fragment,e),y(mt.$$.fragment,e),y(ft.$$.fragment,e),y(ut.$$.fragment,e),y(qe.$$.fragment,e),y(_t.$$.fragment,e),y(Le.$$.fragment,e),y(De.$$.fragment,e),y(gt.$$.fragment,e),y(vt.$$.fragment,e),y(Me.$$.fragment,e),qs=!1},d(e){a(p),e&&a(v),e&&a(m),x(f),e&&a(C),e&&a(G),e&&a(I),x(O,e),e&&a(F),e&&a(ee),e&&a($o),e&&a(J),e&&a(ko),e&&a(kt),e&&a(Po),x(ue,e),e&&a(xo),e&&a(te),x(Re),e&&a(jo),e&&a(ge),e&&a(Eo),x(Se,e),e&&a(Ao),e&&a(xt),e&&a(Uo),x(We,e),e&&a(Co),e&&a(jt),e&&a(Go),x(ve,e),e&&a(Io),e&&a(ae),x(Fe),e&&a(To),e&&a(Et),e&&a(qo),e&&a(At),e&&a(Lo),x(He,e),e&&a(Do),e&&a(Ut),e&&a(Mo),x(Ye,e),e&&a(Bo),e&&a(z),e&&a(zo),e&&a(oe),x(Je),e&&a(No),e&&a(be),e&&a(Oo),e&&a($e),e&&a(Ro),x(Ke,e),e&&a(So),e&&a(Gt),e&&a(Wo),x(Qe,e),e&&a(Fo),e&&a(It),e&&a(Ho),x(Xe,e),e&&a(Yo),e&&a(ke),e&&a(Jo),e&&a(V),e&&a(Vo),e&&a(se),e&&a(Ko),e&&a(K),e&&a(Qo),x(Ze,e),e&&a(Xo),x(et,e),e&&a(Zo),e&&a(Pe),e&&a(es),x(tt,e),e&&a(ts),e&&a(ne),x(at),e&&a(as),e&&a(Tt),e&&a(os),x(ot,e),e&&a(ss),e&&a(qt),e&&a(ns),e&&a(Q),e&&a(is),e&&a(Lt),e&&a(ls),x(je,e),e&&a(rs),e&&a(ie),x(st),e&&a(ds),e&&a(Ae),e&&a(cs),x(Ue,e),e&&a(hs),e&&a(T),e&&a(ps),e&&a(Mt),e&&a(ms),x(nt,e),e&&a(fs),x(Ce,e),e&&a(us),e&&a(Bt),e&&a(_s),x(it,e),e&&a(gs),e&&a(q),e&&a(vs),x(lt,e),e&&a(ws),e&&a(zt),e&&a(ys),x(rt,e),e&&a(bs),e&&a(Nt),e&&a($s),x(dt,e),e&&a(ks),e&&a(le),x(ct),e&&a(Ps),e&&a(Ot),e&&a(xs),e&&a(L),e&&a(js),e&&a(re),x(ht),e&&a(Es),e&&a(de),x(pt),e&&a(As),e&&a(ce),x(mt),e&&a(Us),e&&a(he),x(ft),e&&a(Cs),e&&a(R),x(ut),x(qe),e&&a(Gs),e&&a(S),x(_t),x(Le),x(De),e&&a(Is),e&&a(pe),x(gt),e&&a(Ts),e&&a(Y),x(vt),x(Me)}}}const Ec={local:"initialize-a-model-with-100-billions-parameters-in-no-time-and-without-using-any-ram",title:"Initialize a model with 100 billions parameters in no time and without using any RAM."};function Ac(A){return oc(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class qc extends ec{constructor(p){super();tc(this,p,Ac,jc,ac,{})}}export{qc as default,Ec as metadata};
