import{S as cn,i as ln,s as dn,e as r,k as i,w as m,t as n,M as pn,c as o,d as a,m as d,a as s,x as g,h as c,b as p,F as t,g as h,y as _,q as v,o as b,B as $}from"../chunks/vendor-19e06bd2.js";import{T as Zo}from"../chunks/Tip-f0fa2d82.js";import{D as x}from"../chunks/Docstring-f53307d4.js";import{I as B}from"../chunks/IconCopyLink-3c713d38.js";function hn(G){let f,E,u,y,T;return{c(){f=r("p"),E=n("This does not support "),u=r("code"),y=n("BatchSampler"),T=n(" with varying batch size yet.")},l(w){f=o(w,"P",{});var D=s(f);E=c(D,"This does not support "),u=o(D,"CODE",{});var L=s(u);y=c(L,"BatchSampler"),L.forEach(a),T=c(D," with varying batch size yet."),D.forEach(a)},m(w,D){h(w,f,D),t(f,E),t(f,u),t(u,y),t(f,T)},d(w){w&&a(f)}}}function fn(G){let f,E,u,y,T;return{c(){f=r("p"),E=n("This does not support "),u=r("code"),y=n("BatchSampler"),T=n(" with varying batch size yet.")},l(w){f=o(w,"P",{});var D=s(f);E=c(D,"This does not support "),u=o(D,"CODE",{});var L=s(u);y=c(L,"BatchSampler"),L.forEach(a),T=c(D," with varying batch size yet."),D.forEach(a)},m(w,D){h(w,f,D),t(f,E),t(f,u),t(u,y),t(f,T)},d(w){w&&a(f)}}}function un(G){let f,E;return{c(){f=r("p"),E=n("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(u){f=o(u,"P",{});var y=s(f);E=c(y,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),y.forEach(a)},m(u,y){h(u,f,y),t(f,E)},d(u){u&&a(f)}}}function mn(G){let f,E,u,y,T,w,D,L,Ka,sa,F,se,it,Ee,Qa,dt,Ya,na,R,De,Za,pt,er,ca,V,ne,ht,Se,tr,ft,ar,la,ce,rr,ut,or,sr,ia,P,xe,nr,Te,cr,mt,lr,ir,dr,W,pr,gt,hr,fr,_t,ur,mr,gr,le,da,H,ie,vt,Pe,_r,bt,vr,pa,M,Ae,br,ze,$r,$t,yr,wr,ha,j,de,yt,Ie,Er,wt,Dr,fa,N,Le,Sr,k,xr,Et,Tr,Pr,Dt,Ar,zr,St,Ir,Lr,Nr,pe,ua,X,he,xt,Ne,kr,Tt,Or,ma,O,ke,Cr,S,Ur,Pt,qr,Br,At,Gr,Fr,zt,Rr,Vr,It,Wr,Hr,Lt,Mr,jr,Xr,fe,Oe,Jr,Nt,Kr,ga,J,ue,kt,Ce,Qr,Ot,Yr,_a,K,me,Ct,Ue,Zr,Ut,eo,va,Q,qe,to,Y,ao,Be,ro,oo,qt,so,no,ba,Z,ge,Bt,Ge,co,Gt,lo,$a,A,Fe,io,Ft,po,ho,Rt,fo,uo,z,Ze,Vt,mo,go,_o,et,Wt,vo,bo,$o,tt,Ht,yo,wo,Eo,at,Mt,Do,So,xo,rt,jt,To,Po,ya,ee,_e,Xt,Re,Ao,Jt,zo,wa,te,Ve,Io,Kt,Lo,Ea,ae,We,No,Qt,ko,Da,re,He,Oo,Yt,Co,Sa,oe,Me,Uo,C,qo,Zt,Bo,Go,ea,Fo,Ro,ta,Vo,Wo,xa,je,Xe,Ta,Je,Ke,Pa,U,Qe,Ho,aa,Mo,jo,ve,Aa;return w=new B({}),Ee=new B({}),De=new x({props:{name:"class accelerate.optimizer.AcceleratedOptimizer",anchor:"accelerate.optimizer.AcceleratedOptimizer",parameters:[{name:"optimizer",val:""},{name:"device_placement",val:" = True"},{name:"scaler",val:" = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/optimizer.py#L39",parametersDescription:[{anchor:"accelerate.optimizer.AcceleratedOptimizer.optimizer",description:`<strong>optimizer</strong> (<code>torch.optim.optimizer.Optimizer</code>) &#x2014;
The optimizer to wrap.`,name:"optimizer"},{anchor:"accelerate.optimizer.AcceleratedOptimizer.device_placement",description:`<strong>device_placement</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not the optimizer should handle device placement. If so, it will place the state dictionary of
<code>optimizer</code> on the right device.`,name:"device_placement"},{anchor:"accelerate.optimizer.AcceleratedOptimizer.scaler",description:`<strong>scaler</strong> (<code>torch.cuda.amp.grad_scaler.GradScaler</code>, <em>optional</em>) &#x2014;
The scaler to use in the step function if training with mixed precision.`,name:"scaler"}]}}),Se=new B({}),xe=new x({props:{name:"accelerate.data_loader.prepare_data_loader",anchor:"accelerate.data_loader.prepare_data_loader",parameters:[{name:"dataloader",val:": DataLoader"},{name:"device",val:": typing.Optional[torch.device] = None"},{name:"num_processes",val:": typing.Optional[int] = None"},{name:"process_index",val:": typing.Optional[int] = None"},{name:"split_batches",val:": bool = False"},{name:"put_on_device",val:": bool = False"},{name:"rng_types",val:": typing.Union[typing.List[typing.Union[str, accelerate.utils.RNGType]], NoneType] = None"},{name:"dispatch_batches",val:": typing.Optional[bool] = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/data_loader.py#L417",parametersDescription:[{anchor:"accelerate.data_loader.prepare_data_loader.dataloader",description:`<strong>dataloader</strong> (<code>torch.utils.data.dataloader.DataLoader</code>) &#x2014;
The data loader to split across several devices.`,name:"dataloader"},{anchor:"accelerate.data_loader.prepare_data_loader.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The target device for the returned <code>DataLoader</code>.`,name:"device"},{anchor:"accelerate.data_loader.prepare_data_loader.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The number of processes running concurrently. Will default to the value given by
<a href="/docs/accelerate/pr_271/en/internal#accelerate.state.AcceleratorState">AcceleratorState</a>.`,name:"num_processes"},{anchor:"accelerate.data_loader.prepare_data_loader.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The index of the current process. Will default to the value given by <a href="/docs/accelerate/pr_271/en/internal#accelerate.state.AcceleratorState">AcceleratorState</a>.`,name:"process_index"},{anchor:"accelerate.data_loader.prepare_data_loader.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the resulting <code>DataLoader</code> should split the batches of the original data loader across devices or
yield full batches (in which case it will yield batches starting at the <code>process_index</code>-th and advancing of
<code>num_processes</code> batches at each iteration).</p>
<p>Another way to see this is that the observed batch size will be the same as the initial <code>dataloader</code> if
this option is set to <code>True</code>, the batch size of the initial <code>dataloader</code> multiplied by <code>num_processes</code>
otherwise.</p>
<p>Setting this option to <code>True</code> requires that the batch size of the <code>dataloader</code> is a round multiple of
<code>batch_size</code>.`,name:"split_batches"},{anchor:"accelerate.data_loader.prepare_data_loader.put_on_device",description:`<strong>put_on_device</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to put the batches on <code>device</code> (only works if the batches are nested list, tuples or
dictionaries of tensors).`,name:"put_on_device"},{anchor:"accelerate.data_loader.prepare_data_loader.rng_types",description:`<strong>rng_types</strong> (list of <code>str</code> or <code>RNGType</code> &#x2014;
The list of random number generators to synchronize at the beginning of each iteration. Should be one or
several of:</p>
<ul>
<li><code>&quot;torch&quot;</code>: the base torch random number generator</li>
<li><code>&quot;cuda&quot;</code>: the CUDA random number generator (GPU only)</li>
<li><code>&quot;xla&quot;</code>: the XLA random number generator (TPU only)</li>
<li><code>&quot;generator&quot;</code>: the <code>torch.Generator</code> of the sampler (or batch sampler if there is no sampler in your
dataloader) or of the iterable dataset (if it exists) if the underlying dataset is of that type.</li>
</ul>`,name:"rng_types"},{anchor:"accelerate.data_loader.prepare_data_loader.dispatch_batches",description:`<strong>dispatch_batches</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
If set to <code>True</code>, the datalaoder prepared is only iterated through on the main process and then the batches
are split and broadcast to each process. Will default to <code>True</code> when the underlying dataset is an
<code>IterableDataset</code>, <code>False</code> otherwise.`,name:"dispatch_batches"}],returnDescription:`
<p>A new data loader that will yield the portion of the batches</p>
`,returnType:`
<p><code>torch.utils.data.dataloader.DataLoader</code></p>
`}}),le=new Zo({props:{warning:"&lcub;true}",$$slots:{default:[hn]},$$scope:{ctx:G}}}),Pe=new B({}),Ae=new x({props:{name:"class accelerate.data_loader.DataLoaderShard",anchor:"accelerate.data_loader.DataLoaderShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/data_loader.py#L270",parametersDescription:[{anchor:"accelerate.data_loader.DataLoaderShard.dataset",description:`<strong>dataset</strong> (<code>torch.utils.data.dataset.Dataset</code>) &#x2014;
The dataset to use to build this datalaoder.`,name:"dataset"},{anchor:"accelerate.data_loader.DataLoaderShard.device",description:`<strong>device</strong> (<code>torch.device</code>, <em>optional</em>) &#x2014;
If passed, the device to put all batches on.`,name:"device"},{anchor:"accelerate.data_loader.DataLoaderShard.rng_types",description:`<strong>rng_types</strong> (list of <code>str</code> or <code>RNGType</code> &#x2014;
The list of random number generators to synchronize at the beginning of each iteration. Should be one or
several of:</p>
<ul>
<li><code>&quot;torch&quot;</code>: the base torch random number generator</li>
<li><code>&quot;cuda&quot;</code>: the CUDA random number generator (GPU only)</li>
<li><code>&quot;xla&quot;</code>: the XLA random number generator (TPU only)</li>
<li><code>&quot;generator&quot;</code>: an optional <code>torch.Generator</code></li>
</ul>`,name:"rng_types"},{anchor:"accelerate.data_loader.DataLoaderShard.generator",description:`<strong>generator</strong> (<code>torch.Generator</code>, <em>optional</em>) &#x2014;
A random number generator to keep synchronized across processes.
kwargs &#x2014;
All other keyword arguments to pass to the regular <code>DataLoader</code> initialization.`,name:"generator"}]}}),Ie=new B({}),Le=new x({props:{name:"class accelerate.data_loader.BatchSamplerShard",anchor:"accelerate.data_loader.BatchSamplerShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/data_loader.py#L68",parametersDescription:[{anchor:"accelerate.data_loader.BatchSamplerShard.batch_sampler",description:`<strong>batch_sampler</strong> (<code>torch.utils.data.sampler.BatchSampler</code>) &#x2014;
The batch sampler to split in several shards.`,name:"batch_sampler"},{anchor:"accelerate.data_loader.BatchSamplerShard.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of processes running concurrently.`,name:"num_processes"},{anchor:"accelerate.data_loader.BatchSamplerShard.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The index of the current process.`,name:"process_index"},{anchor:"accelerate.data_loader.BatchSamplerShard.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the shards should be created by splitting a batch to give a piece of it on each process, or by
yielding different full batches on each process.</p>
<p>On two processes with a sampler of <code>[[0, 1, 2, 3], [4, 5, 6, 7]]</code>, this will result in:</p>
<ul>
<li>the sampler on process 0 to yield <code>[0, 1, 2, 3]</code> and the sampler on process 1 to yield <code>[4, 5, 6, 7]</code> if
this argument is set to <code>False</code>.</li>
<li>the sampler on process 0 to yield <code>[0, 1]</code> then <code>[4, 5]</code> and the sampler on process 1 to yield <code>[2, 3]</code>
then <code>[6, 7]</code> if this argument is set to <code>True</code>.</li>
</ul>`,name:"split_batches"}]}}),pe=new Zo({props:{warning:"&lcub;true}",$$slots:{default:[fn]},$$scope:{ctx:G}}}),Ne=new B({}),ke=new x({props:{name:"class accelerate.data_loader.IterableDatasetShard",anchor:"accelerate.data_loader.IterableDatasetShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/data_loader.py#L189",parametersDescription:[{anchor:"accelerate.data_loader.IterableDatasetShard.dataset",description:`<strong>dataset</strong> (<code>torch.utils.data.dataset.IterableDataset</code>) &#x2014;
The batch sampler to split in several shards.`,name:"dataset"},{anchor:"accelerate.data_loader.IterableDatasetShard.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The size of the batches per shard (if <code>split_batches=False</code>) or the size of the batches (if
<code>split_batches=True</code>).`,name:"batch_size"},{anchor:"accelerate.data_loader.IterableDatasetShard.drop_last",description:`<strong>drop_last</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to drop the last incomplete batch or complete the last batches by using the samples from the
beginning.`,name:"drop_last"},{anchor:"accelerate.data_loader.IterableDatasetShard.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of processes running concurrently.`,name:"num_processes"},{anchor:"accelerate.data_loader.IterableDatasetShard.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The index of the current process.`,name:"process_index"},{anchor:"accelerate.data_loader.IterableDatasetShard.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the shards should be created by splitting a batch to give a piece of it on each process, or by
yielding different full batches on each process.</p>
<p>On two processes with an iterable dataset yielding of <code>[0, 1, 2, 3, 4, 5, 6, 7]</code>, this will result in:</p>
<ul>
<li>the shard on process 0 to yield <code>[0, 1, 2, 3]</code> and the shard on process 1 to yield <code>[4, 5, 6, 7]</code> if this
argument is set to <code>False</code>.</li>
<li>the shard on process 0 to yield <code>[0, 1, 4, 5]</code> and the sampler on process 1 to yield <code>[2, 3, 6, 7]</code> if
this argument is set to <code>True</code>.</li>
</ul>`,name:"split_batches"}]}}),Oe=new x({props:{name:"reinforce_type",anchor:"None",parameters:[{name:"expected_type",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/torch/utils/data/_typing.py#L380"}}),Ce=new B({}),Ue=new B({}),qe=new x({props:{name:"class accelerate.state.AcceleratorState",anchor:"accelerate.state.AcceleratorState",parameters:[{name:"mixed_precision",val:": str = None"},{name:"cpu",val:": bool = False"},{name:"deepspeed_plugin",val:" = None"},{name:"_from_accelerator",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/state.py#L128",parametersDescription:[{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>device</strong> (<code>torch.device</code>) &#x2014; The device to use. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:`<strong>-</strong> <strong>distributed_type</strong> (<code>~accelerate.state.DistributedType</code>) &#x2014; The type of distributed environment currently &#x2014;
in use.`,name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>num_processes</strong> (<code>int</code>) &#x2014; The number of processes currently launched in parallel. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>process_index</strong> (<code>int</code>) &#x2014; The index of the current process. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>local_process_index</strong> (<code>int</code>) &#x2014; The index of the current process on the current server. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:`<strong>-</strong> <strong>mixed_precision</strong> (<code>str</code>) &#x2014; Whether or not the current script will use mixed precision. If you are using &#x2014;
mixed precision, define if you want to use FP16 or BF16 (bfloat16) as the floating point.`,name:"-"}]}}),Ge=new B({}),Fe=new x({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/state.py#L74"}}),Re=new B({}),Ve=new x({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/utils.py#L295",parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),We=new x({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/utils.py#L340",parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),He=new x({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/utils.py#L196",parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Me=new x({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/utils.py#L66",parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}]}}),Xe=new x({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/utils.py#L86"}}),Ke=new x({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/utils.py#L121"}}),Qe=new x({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/pr_271/src/accelerate/utils.py#L564"}}),ve=new Zo({props:{warning:"&lcub;true}",$$slots:{default:[un]},$$scope:{ctx:G}}}),{c(){f=r("meta"),E=i(),u=r("h1"),y=r("a"),T=r("span"),m(w.$$.fragment),D=i(),L=r("span"),Ka=n("Internals"),sa=i(),F=r("h2"),se=r("a"),it=r("span"),m(Ee.$$.fragment),Qa=i(),dt=r("span"),Ya=n("Optimizer"),na=i(),R=r("div"),m(De.$$.fragment),Za=i(),pt=r("p"),er=n("Internal wrapper around a torch optimizer."),ca=i(),V=r("h2"),ne=r("a"),ht=r("span"),m(Se.$$.fragment),tr=i(),ft=r("span"),ar=n("DataLoader"),la=i(),ce=r("p"),rr=n("The main work on your PyTorch "),ut=r("code"),or=n("DataLoader"),sr=n(" is done by the following function:"),ia=i(),P=r("div"),m(xe.$$.fragment),nr=i(),Te=r("p"),cr=n("Wraps a PyTorch "),mt=r("code"),lr=n("DataLoader"),ir=n(" to generate batches for one of the processes only."),dr=i(),W=r("p"),pr=n("Depending on the value of the "),gt=r("code"),hr=n("drop_last"),fr=n(" attribute of the "),_t=r("code"),ur=n("dataloader"),mr=n(` passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),gr=i(),m(le.$$.fragment),da=i(),H=r("h3"),ie=r("a"),vt=r("span"),m(Pe.$$.fragment),_r=i(),bt=r("span"),vr=n("BatchSamplerShard"),pa=i(),M=r("div"),m(Ae.$$.fragment),br=i(),ze=r("p"),$r=n("Subclass of a PyTorch "),$t=r("code"),yr=n("DataLoader"),wr=n(" that will deal with device placement and current distributed setup."),ha=i(),j=r("h3"),de=r("a"),yt=r("span"),m(Ie.$$.fragment),Er=i(),wt=r("span"),Dr=n("BatchSamplerShard"),fa=i(),N=r("div"),m(Le.$$.fragment),Sr=i(),k=r("p"),xr=n("Wraps a PyTorch "),Et=r("code"),Tr=n("BatchSampler"),Pr=n(` to generate batches for one of the processes only. Instances of this class will
always yield a number of batches that is a round multiple of `),Dt=r("code"),Ar=n("num_processes"),zr=n(` and that all have the same size.
Depending on the value of the `),St=r("code"),Ir=n("drop_last"),Lr=n(` attribute of the batch sampler passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),Nr=i(),m(pe.$$.fragment),ua=i(),X=r("h3"),he=r("a"),xt=r("span"),m(Ne.$$.fragment),kr=i(),Tt=r("span"),Or=n("IterableDatasetShard"),ma=i(),O=r("div"),m(ke.$$.fragment),Cr=i(),S=r("p"),Ur=n("Wraps a PyTorch "),Pt=r("code"),qr=n("IterableDataset"),Br=n(` to generate samples for one of the processes only. Instances of this class will
always yield a number of samples that is a round multiple of the actual batch size (depending of the value of
`),At=r("code"),Gr=n("split_batches"),Fr=n(", this is either "),zt=r("code"),Rr=n("batch_size"),Vr=n(" or "),It=r("code"),Wr=n("batch_size x num_processes"),Hr=n(`). Depending on the value of the
`),Lt=r("code"),Mr=n("drop_last"),jr=n(` attribute of the batch sampler passed, it will either stop the iteration at the first batch that would
be too small or loop with indices from the beginning.`),Xr=i(),fe=r("div"),m(Oe.$$.fragment),Jr=i(),Nt=r("p"),Kr=n(`Reinforce the type for DataPipe instance. And the \u2018expected_type\u2019 is required
to be a subtype of the original type hint to restrict the type requirement
of DataPipe instance.`),ga=i(),J=r("h2"),ue=r("a"),kt=r("span"),m(Ce.$$.fragment),Qr=i(),Ot=r("span"),Yr=n("Distributed Config"),_a=i(),K=r("h3"),me=r("a"),Ct=r("span"),m(Ue.$$.fragment),Zr=i(),Ut=r("span"),eo=n("AcceleratorState"),va=i(),Q=r("div"),m(qe.$$.fragment),to=i(),Y=r("p"),ao=n("This is a variation of a "),Be=r("a"),ro=n("singleton class"),oo=n(` in the sense that all
instance of `),qt=r("code"),so=n("AcceleratorState"),no=n(" share the same state, which is initialized on the first instantiation."),ba=i(),Z=r("h3"),ge=r("a"),Bt=r("span"),m(Ge.$$.fragment),co=i(),Gt=r("span"),lo=n("DistributedType"),$a=i(),A=r("div"),m(Fe.$$.fragment),io=i(),Ft=r("p"),po=n("Represents a type of distributed environment."),ho=i(),Rt=r("p"),fo=n("Values:"),uo=i(),z=r("ul"),Ze=r("li"),Vt=r("strong"),mo=n("NO"),go=n(" \u2014 Not a distributed environment, just a single process."),_o=i(),et=r("li"),Wt=r("strong"),vo=n("MULTI_CPU"),bo=n(" \u2014 Distributed on multiple CPU nodes."),$o=i(),tt=r("li"),Ht=r("strong"),yo=n("MULTI_GPU"),wo=n(" \u2014 Distributed on multiple GPUs."),Eo=i(),at=r("li"),Mt=r("strong"),Do=n("DEEPSPEED"),So=n(" \u2014 Using DeepSpeed."),xo=i(),rt=r("li"),jt=r("strong"),To=n("TPU"),Po=n(" \u2014 Distributed on TPUs."),ya=i(),ee=r("h2"),_e=r("a"),Xt=r("span"),m(Re.$$.fragment),Ao=i(),Jt=r("span"),zo=n("Utilities"),wa=i(),te=r("div"),m(Ve.$$.fragment),Io=i(),Kt=r("p"),Lo=n("Extract a model from its distributed containers."),Ea=i(),ae=r("div"),m(We.$$.fragment),No=i(),Qt=r("p"),ko=n("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),Da=i(),re=r("div"),m(He.$$.fragment),Oo=i(),Yt=r("p"),Co=n("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),Sa=i(),oe=r("div"),m(Me.$$.fragment),Uo=i(),C=r("p"),qo=n("Helper function for reproducible behavior to set the seed in "),Zt=r("code"),Bo=n("random"),Go=n(", "),ea=r("code"),Fo=n("numpy"),Ro=n(", "),ta=r("code"),Vo=n("torch"),Wo=n("."),xa=i(),je=r("div"),m(Xe.$$.fragment),Ta=i(),Je=r("div"),m(Ke.$$.fragment),Pa=i(),U=r("div"),m(Qe.$$.fragment),Ho=i(),aa=r("p"),Mo=n("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),jo=i(),m(ve.$$.fragment),this.h()},l(e){const l=pn('[data-svelte="svelte-1phssyn"]',document.head);f=o(l,"META",{name:!0,content:!0}),l.forEach(a),E=d(e),u=o(e,"H1",{class:!0});var Ye=s(u);y=o(Ye,"A",{id:!0,class:!0,href:!0});var ra=s(y);T=o(ra,"SPAN",{});var oa=s(T);g(w.$$.fragment,oa),oa.forEach(a),ra.forEach(a),D=d(Ye),L=o(Ye,"SPAN",{});var es=s(L);Ka=c(es,"Internals"),es.forEach(a),Ye.forEach(a),sa=d(e),F=o(e,"H2",{class:!0});var za=s(F);se=o(za,"A",{id:!0,class:!0,href:!0});var ts=s(se);it=o(ts,"SPAN",{});var as=s(it);g(Ee.$$.fragment,as),as.forEach(a),ts.forEach(a),Qa=d(za),dt=o(za,"SPAN",{});var rs=s(dt);Ya=c(rs,"Optimizer"),rs.forEach(a),za.forEach(a),na=d(e),R=o(e,"DIV",{class:!0});var Ia=s(R);g(De.$$.fragment,Ia),Za=d(Ia),pt=o(Ia,"P",{});var os=s(pt);er=c(os,"Internal wrapper around a torch optimizer."),os.forEach(a),Ia.forEach(a),ca=d(e),V=o(e,"H2",{class:!0});var La=s(V);ne=o(La,"A",{id:!0,class:!0,href:!0});var ss=s(ne);ht=o(ss,"SPAN",{});var ns=s(ht);g(Se.$$.fragment,ns),ns.forEach(a),ss.forEach(a),tr=d(La),ft=o(La,"SPAN",{});var cs=s(ft);ar=c(cs,"DataLoader"),cs.forEach(a),La.forEach(a),la=d(e),ce=o(e,"P",{});var Na=s(ce);rr=c(Na,"The main work on your PyTorch "),ut=o(Na,"CODE",{});var ls=s(ut);or=c(ls,"DataLoader"),ls.forEach(a),sr=c(Na," is done by the following function:"),Na.forEach(a),ia=d(e),P=o(e,"DIV",{class:!0});var be=s(P);g(xe.$$.fragment,be),nr=d(be),Te=o(be,"P",{});var ka=s(Te);cr=c(ka,"Wraps a PyTorch "),mt=o(ka,"CODE",{});var is=s(mt);lr=c(is,"DataLoader"),is.forEach(a),ir=c(ka," to generate batches for one of the processes only."),ka.forEach(a),dr=d(be),W=o(be,"P",{});var ot=s(W);pr=c(ot,"Depending on the value of the "),gt=o(ot,"CODE",{});var ds=s(gt);hr=c(ds,"drop_last"),ds.forEach(a),fr=c(ot," attribute of the "),_t=o(ot,"CODE",{});var ps=s(_t);ur=c(ps,"dataloader"),ps.forEach(a),mr=c(ot,` passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),ot.forEach(a),gr=d(be),g(le.$$.fragment,be),be.forEach(a),da=d(e),H=o(e,"H3",{class:!0});var Oa=s(H);ie=o(Oa,"A",{id:!0,class:!0,href:!0});var hs=s(ie);vt=o(hs,"SPAN",{});var fs=s(vt);g(Pe.$$.fragment,fs),fs.forEach(a),hs.forEach(a),_r=d(Oa),bt=o(Oa,"SPAN",{});var us=s(bt);vr=c(us,"BatchSamplerShard"),us.forEach(a),Oa.forEach(a),pa=d(e),M=o(e,"DIV",{class:!0});var Ca=s(M);g(Ae.$$.fragment,Ca),br=d(Ca),ze=o(Ca,"P",{});var Ua=s(ze);$r=c(Ua,"Subclass of a PyTorch "),$t=o(Ua,"CODE",{});var ms=s($t);yr=c(ms,"DataLoader"),ms.forEach(a),wr=c(Ua," that will deal with device placement and current distributed setup."),Ua.forEach(a),Ca.forEach(a),ha=d(e),j=o(e,"H3",{class:!0});var qa=s(j);de=o(qa,"A",{id:!0,class:!0,href:!0});var gs=s(de);yt=o(gs,"SPAN",{});var _s=s(yt);g(Ie.$$.fragment,_s),_s.forEach(a),gs.forEach(a),Er=d(qa),wt=o(qa,"SPAN",{});var vs=s(wt);Dr=c(vs,"BatchSamplerShard"),vs.forEach(a),qa.forEach(a),fa=d(e),N=o(e,"DIV",{class:!0});var st=s(N);g(Le.$$.fragment,st),Sr=d(st),k=o(st,"P",{});var $e=s(k);xr=c($e,"Wraps a PyTorch "),Et=o($e,"CODE",{});var bs=s(Et);Tr=c(bs,"BatchSampler"),bs.forEach(a),Pr=c($e,` to generate batches for one of the processes only. Instances of this class will
always yield a number of batches that is a round multiple of `),Dt=o($e,"CODE",{});var $s=s(Dt);Ar=c($s,"num_processes"),$s.forEach(a),zr=c($e,` and that all have the same size.
Depending on the value of the `),St=o($e,"CODE",{});var ys=s(St);Ir=c(ys,"drop_last"),ys.forEach(a),Lr=c($e,` attribute of the batch sampler passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),$e.forEach(a),Nr=d(st),g(pe.$$.fragment,st),st.forEach(a),ua=d(e),X=o(e,"H3",{class:!0});var Ba=s(X);he=o(Ba,"A",{id:!0,class:!0,href:!0});var ws=s(he);xt=o(ws,"SPAN",{});var Es=s(xt);g(Ne.$$.fragment,Es),Es.forEach(a),ws.forEach(a),kr=d(Ba),Tt=o(Ba,"SPAN",{});var Ds=s(Tt);Or=c(Ds,"IterableDatasetShard"),Ds.forEach(a),Ba.forEach(a),ma=d(e),O=o(e,"DIV",{class:!0});var nt=s(O);g(ke.$$.fragment,nt),Cr=d(nt),S=o(nt,"P",{});var I=s(S);Ur=c(I,"Wraps a PyTorch "),Pt=o(I,"CODE",{});var Ss=s(Pt);qr=c(Ss,"IterableDataset"),Ss.forEach(a),Br=c(I,` to generate samples for one of the processes only. Instances of this class will
always yield a number of samples that is a round multiple of the actual batch size (depending of the value of
`),At=o(I,"CODE",{});var xs=s(At);Gr=c(xs,"split_batches"),xs.forEach(a),Fr=c(I,", this is either "),zt=o(I,"CODE",{});var Ts=s(zt);Rr=c(Ts,"batch_size"),Ts.forEach(a),Vr=c(I," or "),It=o(I,"CODE",{});var Ps=s(It);Wr=c(Ps,"batch_size x num_processes"),Ps.forEach(a),Hr=c(I,`). Depending on the value of the
`),Lt=o(I,"CODE",{});var As=s(Lt);Mr=c(As,"drop_last"),As.forEach(a),jr=c(I,` attribute of the batch sampler passed, it will either stop the iteration at the first batch that would
be too small or loop with indices from the beginning.`),I.forEach(a),Xr=d(nt),fe=o(nt,"DIV",{class:!0});var Ga=s(fe);g(Oe.$$.fragment,Ga),Jr=d(Ga),Nt=o(Ga,"P",{});var zs=s(Nt);Kr=c(zs,`Reinforce the type for DataPipe instance. And the \u2018expected_type\u2019 is required
to be a subtype of the original type hint to restrict the type requirement
of DataPipe instance.`),zs.forEach(a),Ga.forEach(a),nt.forEach(a),ga=d(e),J=o(e,"H2",{class:!0});var Fa=s(J);ue=o(Fa,"A",{id:!0,class:!0,href:!0});var Is=s(ue);kt=o(Is,"SPAN",{});var Ls=s(kt);g(Ce.$$.fragment,Ls),Ls.forEach(a),Is.forEach(a),Qr=d(Fa),Ot=o(Fa,"SPAN",{});var Ns=s(Ot);Yr=c(Ns,"Distributed Config"),Ns.forEach(a),Fa.forEach(a),_a=d(e),K=o(e,"H3",{class:!0});var Ra=s(K);me=o(Ra,"A",{id:!0,class:!0,href:!0});var ks=s(me);Ct=o(ks,"SPAN",{});var Os=s(Ct);g(Ue.$$.fragment,Os),Os.forEach(a),ks.forEach(a),Zr=d(Ra),Ut=o(Ra,"SPAN",{});var Cs=s(Ut);eo=c(Cs,"AcceleratorState"),Cs.forEach(a),Ra.forEach(a),va=d(e),Q=o(e,"DIV",{class:!0});var Va=s(Q);g(qe.$$.fragment,Va),to=d(Va),Y=o(Va,"P",{});var ct=s(Y);ao=c(ct,"This is a variation of a "),Be=o(ct,"A",{href:!0,rel:!0});var Us=s(Be);ro=c(Us,"singleton class"),Us.forEach(a),oo=c(ct,` in the sense that all
instance of `),qt=o(ct,"CODE",{});var qs=s(qt);so=c(qs,"AcceleratorState"),qs.forEach(a),no=c(ct," share the same state, which is initialized on the first instantiation."),ct.forEach(a),Va.forEach(a),ba=d(e),Z=o(e,"H3",{class:!0});var Wa=s(Z);ge=o(Wa,"A",{id:!0,class:!0,href:!0});var Bs=s(ge);Bt=o(Bs,"SPAN",{});var Gs=s(Bt);g(Ge.$$.fragment,Gs),Gs.forEach(a),Bs.forEach(a),co=d(Wa),Gt=o(Wa,"SPAN",{});var Fs=s(Gt);lo=c(Fs,"DistributedType"),Fs.forEach(a),Wa.forEach(a),$a=d(e),A=o(e,"DIV",{class:!0});var ye=s(A);g(Fe.$$.fragment,ye),io=d(ye),Ft=o(ye,"P",{});var Rs=s(Ft);po=c(Rs,"Represents a type of distributed environment."),Rs.forEach(a),ho=d(ye),Rt=o(ye,"P",{});var Vs=s(Rt);fo=c(Vs,"Values:"),Vs.forEach(a),uo=d(ye),z=o(ye,"UL",{});var q=s(z);Ze=o(q,"LI",{});var Xo=s(Ze);Vt=o(Xo,"STRONG",{});var Ws=s(Vt);mo=c(Ws,"NO"),Ws.forEach(a),go=c(Xo," \u2014 Not a distributed environment, just a single process."),Xo.forEach(a),_o=d(q),et=o(q,"LI",{});var Jo=s(et);Wt=o(Jo,"STRONG",{});var Hs=s(Wt);vo=c(Hs,"MULTI_CPU"),Hs.forEach(a),bo=c(Jo," \u2014 Distributed on multiple CPU nodes."),Jo.forEach(a),$o=d(q),tt=o(q,"LI",{});var Ko=s(tt);Ht=o(Ko,"STRONG",{});var Ms=s(Ht);yo=c(Ms,"MULTI_GPU"),Ms.forEach(a),wo=c(Ko," \u2014 Distributed on multiple GPUs."),Ko.forEach(a),Eo=d(q),at=o(q,"LI",{});var Qo=s(at);Mt=o(Qo,"STRONG",{});var js=s(Mt);Do=c(js,"DEEPSPEED"),js.forEach(a),So=c(Qo," \u2014 Using DeepSpeed."),Qo.forEach(a),xo=d(q),rt=o(q,"LI",{});var Yo=s(rt);jt=o(Yo,"STRONG",{});var Xs=s(jt);To=c(Xs,"TPU"),Xs.forEach(a),Po=c(Yo," \u2014 Distributed on TPUs."),Yo.forEach(a),q.forEach(a),ye.forEach(a),ya=d(e),ee=o(e,"H2",{class:!0});var Ha=s(ee);_e=o(Ha,"A",{id:!0,class:!0,href:!0});var Js=s(_e);Xt=o(Js,"SPAN",{});var Ks=s(Xt);g(Re.$$.fragment,Ks),Ks.forEach(a),Js.forEach(a),Ao=d(Ha),Jt=o(Ha,"SPAN",{});var Qs=s(Jt);zo=c(Qs,"Utilities"),Qs.forEach(a),Ha.forEach(a),wa=d(e),te=o(e,"DIV",{class:!0});var Ma=s(te);g(Ve.$$.fragment,Ma),Io=d(Ma),Kt=o(Ma,"P",{});var Ys=s(Kt);Lo=c(Ys,"Extract a model from its distributed containers."),Ys.forEach(a),Ma.forEach(a),Ea=d(e),ae=o(e,"DIV",{class:!0});var ja=s(ae);g(We.$$.fragment,ja),No=d(ja),Qt=o(ja,"P",{});var Zs=s(Qt);ko=c(Zs,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),Zs.forEach(a),ja.forEach(a),Da=d(e),re=o(e,"DIV",{class:!0});var Xa=s(re);g(He.$$.fragment,Xa),Oo=d(Xa),Yt=o(Xa,"P",{});var en=s(Yt);Co=c(en,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),en.forEach(a),Xa.forEach(a),Sa=d(e),oe=o(e,"DIV",{class:!0});var Ja=s(oe);g(Me.$$.fragment,Ja),Uo=d(Ja),C=o(Ja,"P",{});var we=s(C);qo=c(we,"Helper function for reproducible behavior to set the seed in "),Zt=o(we,"CODE",{});var tn=s(Zt);Bo=c(tn,"random"),tn.forEach(a),Go=c(we,", "),ea=o(we,"CODE",{});var an=s(ea);Fo=c(an,"numpy"),an.forEach(a),Ro=c(we,", "),ta=o(we,"CODE",{});var rn=s(ta);Vo=c(rn,"torch"),rn.forEach(a),Wo=c(we,"."),we.forEach(a),Ja.forEach(a),xa=d(e),je=o(e,"DIV",{class:!0});var on=s(je);g(Xe.$$.fragment,on),on.forEach(a),Ta=d(e),Je=o(e,"DIV",{class:!0});var sn=s(Je);g(Ke.$$.fragment,sn),sn.forEach(a),Pa=d(e),U=o(e,"DIV",{class:!0});var lt=s(U);g(Qe.$$.fragment,lt),Ho=d(lt),aa=o(lt,"P",{});var nn=s(aa);Mo=c(nn,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),nn.forEach(a),jo=d(lt),g(ve.$$.fragment,lt),lt.forEach(a),this.h()},h(){p(f,"name","hf:doc:metadata"),p(f,"content",JSON.stringify(gn)),p(y,"id","internals"),p(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(y,"href","#internals"),p(u,"class","relative group"),p(se,"id","accelerate.optimizer.AcceleratedOptimizer"),p(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(se,"href","#accelerate.optimizer.AcceleratedOptimizer"),p(F,"class","relative group"),p(R,"class","docstring"),p(ne,"id","accelerate.data_loader.prepare_data_loader"),p(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ne,"href","#accelerate.data_loader.prepare_data_loader"),p(V,"class","relative group"),p(P,"class","docstring"),p(ie,"id","accelerate.data_loader.DataLoaderShard"),p(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ie,"href","#accelerate.data_loader.DataLoaderShard"),p(H,"class","relative group"),p(M,"class","docstring"),p(de,"id","accelerate.data_loader.BatchSamplerShard"),p(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(de,"href","#accelerate.data_loader.BatchSamplerShard"),p(j,"class","relative group"),p(N,"class","docstring"),p(he,"id","accelerate.data_loader.IterableDatasetShard"),p(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(he,"href","#accelerate.data_loader.IterableDatasetShard"),p(X,"class","relative group"),p(fe,"class","docstring"),p(O,"class","docstring"),p(ue,"id","distributed-config"),p(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ue,"href","#distributed-config"),p(J,"class","relative group"),p(me,"id","accelerate.state.AcceleratorState"),p(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(me,"href","#accelerate.state.AcceleratorState"),p(K,"class","relative group"),p(Be,"href","https://en.wikipedia.org/wiki/Singleton_pattern"),p(Be,"rel","nofollow"),p(Q,"class","docstring"),p(ge,"id","accelerate.DistributedType"),p(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ge,"href","#accelerate.DistributedType"),p(Z,"class","relative group"),p(A,"class","docstring"),p(_e,"id","accelerate.utils.extract_model_from_parallel"),p(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(_e,"href","#accelerate.utils.extract_model_from_parallel"),p(ee,"class","relative group"),p(te,"class","docstring"),p(ae,"class","docstring"),p(re,"class","docstring"),p(oe,"class","docstring"),p(je,"class","docstring"),p(Je,"class","docstring"),p(U,"class","docstring")},m(e,l){t(document.head,f),h(e,E,l),h(e,u,l),t(u,y),t(y,T),_(w,T,null),t(u,D),t(u,L),t(L,Ka),h(e,sa,l),h(e,F,l),t(F,se),t(se,it),_(Ee,it,null),t(F,Qa),t(F,dt),t(dt,Ya),h(e,na,l),h(e,R,l),_(De,R,null),t(R,Za),t(R,pt),t(pt,er),h(e,ca,l),h(e,V,l),t(V,ne),t(ne,ht),_(Se,ht,null),t(V,tr),t(V,ft),t(ft,ar),h(e,la,l),h(e,ce,l),t(ce,rr),t(ce,ut),t(ut,or),t(ce,sr),h(e,ia,l),h(e,P,l),_(xe,P,null),t(P,nr),t(P,Te),t(Te,cr),t(Te,mt),t(mt,lr),t(Te,ir),t(P,dr),t(P,W),t(W,pr),t(W,gt),t(gt,hr),t(W,fr),t(W,_t),t(_t,ur),t(W,mr),t(P,gr),_(le,P,null),h(e,da,l),h(e,H,l),t(H,ie),t(ie,vt),_(Pe,vt,null),t(H,_r),t(H,bt),t(bt,vr),h(e,pa,l),h(e,M,l),_(Ae,M,null),t(M,br),t(M,ze),t(ze,$r),t(ze,$t),t($t,yr),t(ze,wr),h(e,ha,l),h(e,j,l),t(j,de),t(de,yt),_(Ie,yt,null),t(j,Er),t(j,wt),t(wt,Dr),h(e,fa,l),h(e,N,l),_(Le,N,null),t(N,Sr),t(N,k),t(k,xr),t(k,Et),t(Et,Tr),t(k,Pr),t(k,Dt),t(Dt,Ar),t(k,zr),t(k,St),t(St,Ir),t(k,Lr),t(N,Nr),_(pe,N,null),h(e,ua,l),h(e,X,l),t(X,he),t(he,xt),_(Ne,xt,null),t(X,kr),t(X,Tt),t(Tt,Or),h(e,ma,l),h(e,O,l),_(ke,O,null),t(O,Cr),t(O,S),t(S,Ur),t(S,Pt),t(Pt,qr),t(S,Br),t(S,At),t(At,Gr),t(S,Fr),t(S,zt),t(zt,Rr),t(S,Vr),t(S,It),t(It,Wr),t(S,Hr),t(S,Lt),t(Lt,Mr),t(S,jr),t(O,Xr),t(O,fe),_(Oe,fe,null),t(fe,Jr),t(fe,Nt),t(Nt,Kr),h(e,ga,l),h(e,J,l),t(J,ue),t(ue,kt),_(Ce,kt,null),t(J,Qr),t(J,Ot),t(Ot,Yr),h(e,_a,l),h(e,K,l),t(K,me),t(me,Ct),_(Ue,Ct,null),t(K,Zr),t(K,Ut),t(Ut,eo),h(e,va,l),h(e,Q,l),_(qe,Q,null),t(Q,to),t(Q,Y),t(Y,ao),t(Y,Be),t(Be,ro),t(Y,oo),t(Y,qt),t(qt,so),t(Y,no),h(e,ba,l),h(e,Z,l),t(Z,ge),t(ge,Bt),_(Ge,Bt,null),t(Z,co),t(Z,Gt),t(Gt,lo),h(e,$a,l),h(e,A,l),_(Fe,A,null),t(A,io),t(A,Ft),t(Ft,po),t(A,ho),t(A,Rt),t(Rt,fo),t(A,uo),t(A,z),t(z,Ze),t(Ze,Vt),t(Vt,mo),t(Ze,go),t(z,_o),t(z,et),t(et,Wt),t(Wt,vo),t(et,bo),t(z,$o),t(z,tt),t(tt,Ht),t(Ht,yo),t(tt,wo),t(z,Eo),t(z,at),t(at,Mt),t(Mt,Do),t(at,So),t(z,xo),t(z,rt),t(rt,jt),t(jt,To),t(rt,Po),h(e,ya,l),h(e,ee,l),t(ee,_e),t(_e,Xt),_(Re,Xt,null),t(ee,Ao),t(ee,Jt),t(Jt,zo),h(e,wa,l),h(e,te,l),_(Ve,te,null),t(te,Io),t(te,Kt),t(Kt,Lo),h(e,Ea,l),h(e,ae,l),_(We,ae,null),t(ae,No),t(ae,Qt),t(Qt,ko),h(e,Da,l),h(e,re,l),_(He,re,null),t(re,Oo),t(re,Yt),t(Yt,Co),h(e,Sa,l),h(e,oe,l),_(Me,oe,null),t(oe,Uo),t(oe,C),t(C,qo),t(C,Zt),t(Zt,Bo),t(C,Go),t(C,ea),t(ea,Fo),t(C,Ro),t(C,ta),t(ta,Vo),t(C,Wo),h(e,xa,l),h(e,je,l),_(Xe,je,null),h(e,Ta,l),h(e,Je,l),_(Ke,Je,null),h(e,Pa,l),h(e,U,l),_(Qe,U,null),t(U,Ho),t(U,aa),t(aa,Mo),t(U,jo),_(ve,U,null),Aa=!0},p(e,[l]){const Ye={};l&2&&(Ye.$$scope={dirty:l,ctx:e}),le.$set(Ye);const ra={};l&2&&(ra.$$scope={dirty:l,ctx:e}),pe.$set(ra);const oa={};l&2&&(oa.$$scope={dirty:l,ctx:e}),ve.$set(oa)},i(e){Aa||(v(w.$$.fragment,e),v(Ee.$$.fragment,e),v(De.$$.fragment,e),v(Se.$$.fragment,e),v(xe.$$.fragment,e),v(le.$$.fragment,e),v(Pe.$$.fragment,e),v(Ae.$$.fragment,e),v(Ie.$$.fragment,e),v(Le.$$.fragment,e),v(pe.$$.fragment,e),v(Ne.$$.fragment,e),v(ke.$$.fragment,e),v(Oe.$$.fragment,e),v(Ce.$$.fragment,e),v(Ue.$$.fragment,e),v(qe.$$.fragment,e),v(Ge.$$.fragment,e),v(Fe.$$.fragment,e),v(Re.$$.fragment,e),v(Ve.$$.fragment,e),v(We.$$.fragment,e),v(He.$$.fragment,e),v(Me.$$.fragment,e),v(Xe.$$.fragment,e),v(Ke.$$.fragment,e),v(Qe.$$.fragment,e),v(ve.$$.fragment,e),Aa=!0)},o(e){b(w.$$.fragment,e),b(Ee.$$.fragment,e),b(De.$$.fragment,e),b(Se.$$.fragment,e),b(xe.$$.fragment,e),b(le.$$.fragment,e),b(Pe.$$.fragment,e),b(Ae.$$.fragment,e),b(Ie.$$.fragment,e),b(Le.$$.fragment,e),b(pe.$$.fragment,e),b(Ne.$$.fragment,e),b(ke.$$.fragment,e),b(Oe.$$.fragment,e),b(Ce.$$.fragment,e),b(Ue.$$.fragment,e),b(qe.$$.fragment,e),b(Ge.$$.fragment,e),b(Fe.$$.fragment,e),b(Re.$$.fragment,e),b(Ve.$$.fragment,e),b(We.$$.fragment,e),b(He.$$.fragment,e),b(Me.$$.fragment,e),b(Xe.$$.fragment,e),b(Ke.$$.fragment,e),b(Qe.$$.fragment,e),b(ve.$$.fragment,e),Aa=!1},d(e){a(f),e&&a(E),e&&a(u),$(w),e&&a(sa),e&&a(F),$(Ee),e&&a(na),e&&a(R),$(De),e&&a(ca),e&&a(V),$(Se),e&&a(la),e&&a(ce),e&&a(ia),e&&a(P),$(xe),$(le),e&&a(da),e&&a(H),$(Pe),e&&a(pa),e&&a(M),$(Ae),e&&a(ha),e&&a(j),$(Ie),e&&a(fa),e&&a(N),$(Le),$(pe),e&&a(ua),e&&a(X),$(Ne),e&&a(ma),e&&a(O),$(ke),$(Oe),e&&a(ga),e&&a(J),$(Ce),e&&a(_a),e&&a(K),$(Ue),e&&a(va),e&&a(Q),$(qe),e&&a(ba),e&&a(Z),$(Ge),e&&a($a),e&&a(A),$(Fe),e&&a(ya),e&&a(ee),$(Re),e&&a(wa),e&&a(te),$(Ve),e&&a(Ea),e&&a(ae),$(We),e&&a(Da),e&&a(re),$(He),e&&a(Sa),e&&a(oe),$(Me),e&&a(xa),e&&a(je),$(Xe),e&&a(Ta),e&&a(Je),$(Ke),e&&a(Pa),e&&a(U),$(Qe),$(ve)}}}const gn={local:"internals",sections:[{local:"accelerate.optimizer.AcceleratedOptimizer",title:"Optimizer"},{local:"accelerate.data_loader.prepare_data_loader",sections:[{local:"accelerate.data_loader.DataLoaderShard",title:"BatchSamplerShard"},{local:"accelerate.data_loader.BatchSamplerShard",title:"BatchSamplerShard"},{local:"accelerate.data_loader.IterableDatasetShard",title:"IterableDatasetShard"}],title:"DataLoader"},{local:"distributed-config",sections:[{local:"accelerate.state.AcceleratorState",title:"AcceleratorState"},{local:"accelerate.DistributedType",title:"DistributedType"}],title:"Distributed Config"},{local:"accelerate.utils.extract_model_from_parallel",title:"Utilities"}],title:"Internals"};function _n(G,f,E){let{fw:u}=f;return G.$$set=y=>{"fw"in y&&E(0,u=y.fw)},[u]}class wn extends cn{constructor(f){super();ln(this,f,_n,mn,dn,{fw:0})}}export{wn as default,gn as metadata};
