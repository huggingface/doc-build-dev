import{S as Mn,i as zn,s as Gn,e as a,k as l,w as m,t as c,M as Hn,c as s,d as r,m as n,a as o,x as f,h as d,b as u,G as t,g as p,y as h,q as v,o as g,B as _,v as qn}from"../chunks/vendor-hf-doc-builder.js";import{T as Fn}from"../chunks/Tip-hf-doc-builder.js";import{D as b}from"../chunks/Docstring-hf-doc-builder.js";import{I as _e}from"../chunks/IconCopyLink-hf-doc-builder.js";function Bn(Pr){let $,re;return{c(){$=a("p"),re=c("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(y){$=s(y,"P",{});var E=o($);re=d(E,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),E.forEach(r)},m(y,E){p(y,$,E),t($,re)},d(y){y&&r($)}}}function Wn(Pr){let $,re,y,E,wt,be,za,xt,Ga,Lr,U,ae,Tt,$e,Ha,Dt,qa,kr,rt,Fa,Nr,w,ye,Ba,Pt,Wa,ja,Lt,Ja,Ka,x,at,kt,Qa,Xa,Ya,st,Nt,Za,es,ts,ot,Ct,rs,as,ss,lt,Ut,os,ls,ns,nt,It,is,cs,Cr,T,Ee,ds,St,ps,us,Ot,ms,fs,P,it,At,hs,vs,gs,ct,Rt,_s,bs,$s,dt,Vt,ys,Es,ws,pt,Mt,xs,Ts,Ur,D,we,Ds,zt,Ps,Ls,Gt,ks,Ns,I,ut,Ht,Cs,Us,Is,mt,qt,Ss,Os,As,ft,Ft,Rs,Vs,Ir,S,se,Bt,xe,Ms,Wt,zs,Sr,oe,Gs,jt,Hs,qs,Or,O,Te,Fs,Jt,Bs,Ar,A,De,Ws,Kt,js,Rr,R,Pe,Js,Qt,Ks,Vr,V,Le,Qs,Xt,Xs,Mr,M,ke,Ys,Yt,Zs,zr,z,Ne,eo,Zt,to,Gr,G,le,er,Ce,ro,tr,ao,Hr,ht,so,qr,H,Ue,oo,rr,lo,Fr,q,Ie,no,ar,io,Br,F,Se,co,sr,po,Wr,B,Oe,uo,Ae,mo,or,fo,ho,jr,W,ne,lr,Re,vo,nr,go,Jr,j,Ve,_o,ir,bo,Kr,ie,$o,cr,yo,Eo,Qr,J,ce,dr,Me,wo,pr,xo,Xr,vt,To,Yr,K,ze,Do,ur,Po,Zr,L,Ge,Lo,mr,ko,No,He,fr,Co,Uo,gt,Io,hr,So,ea,Q,qe,Oo,vr,Ao,ta,X,de,gr,Fe,Ro,_r,Vo,ra,_t,Mo,aa,Y,Be,zo,br,Go,sa,Z,We,Ho,je,qo,$r,Fo,Bo,oa,k,Je,Wo,yr,jo,Jo,pe,la,ee,ue,Er,Ke,Ko,wr,Qo,na,bt,Xo,ia,te,Qe,Yo,N,Zo,xr,el,tl,Tr,rl,al,Dr,sl,ol,ca,Xe,Ye,da,Ze,et,pa;return be=new _e({}),$e=new _e({}),ye=new b({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/dataclasses.py#L104"}}),Ee=new b({props:{name:"class accelerate.utils.LoggerType",anchor:"accelerate.utils.LoggerType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/dataclasses.py#L181"}}),we=new b({props:{name:"class accelerate.utils.PrecisionType",anchor:"accelerate.utils.PrecisionType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/dataclasses.py#L198"}}),xe=new _e({}),Te=new b({props:{name:"accelerate.utils.broadcast",anchor:"accelerate.utils.broadcast",parameters:[{name:"tensor",val:""},{name:"from_process",val:": int = 0"}],parametersDescription:[{anchor:"accelerate.utils.broadcast.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.broadcast.from_process",description:`<strong>from_process</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The process from which to send the data`,name:"from_process"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L277",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors broadcasted to the proper device.</p>
`}}),De=new b({props:{name:"accelerate.utils.concatenate",anchor:"accelerate.utils.concatenate",parameters:[{name:"data",val:""},{name:"dim",val:" = 0"}],parametersDescription:[{anchor:"accelerate.utils.concatenate.data",description:`<strong>data</strong> (nested list/tuple/dictionary of lists of tensors <code>torch.Tensor</code>) &#x2014;
The data to concatenate.`,name:"data"},{anchor:"accelerate.utils.concatenate.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to concatenate.`,name:"dim"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L343",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors concatenated.</p>
`}}),Pe=new b({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L207",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Le=new b({props:{name:"accelerate.utils.pad_across_processes",anchor:"accelerate.utils.pad_across_processes",parameters:[{name:"tensor",val:""},{name:"dim",val:" = 0"},{name:"pad_index",val:" = 0"},{name:"pad_first",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.pad_across_processes.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.pad_across_processes.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to pad.`,name:"dim"},{anchor:"accelerate.utils.pad_across_processes.pad_index",description:`<strong>pad_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The value with which to pad.`,name:"pad_index"},{anchor:"accelerate.utils.pad_across_processes.pad_first",description:`<strong>pad_first</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to pad at the beginning or the end.`,name:"pad_first"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L365"}}),ke=new b({props:{name:"accelerate.utils.reduce",anchor:"accelerate.utils.reduce",parameters:[{name:"tensor",val:""},{name:"reduction",val:" = 'mean'"}],parametersDescription:[{anchor:"accelerate.utils.reduce.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to reduce.`,name:"tensor"},{anchor:"accelerate.utils.reduce.reduction",description:`<strong>reduction</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;mean&quot;</code>) &#x2014;
A reduction method. Can be of &#x201C;mean&#x201D;, &#x201C;sum&#x201D;, or &#x201C;none&#x201D;`,name:"reduction"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L411",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors reduced.</p>
`}}),Ne=new b({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""}],parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L106",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Ce=new _e({}),Ue=new b({props:{name:"accelerate.utils.get_max_memory",anchor:"accelerate.utils.get_max_memory",parameters:[{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/modeling.py#L272"}}),Ie=new b({props:{name:"accelerate.utils.is_bf16_available",anchor:"accelerate.utils.is_bf16_available",parameters:[{name:"ignore_tpu",val:" = False"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/imports.py#L76"}}),Se=new b({props:{name:"accelerate.utils.is_torch_version",anchor:"accelerate.utils.is_torch_version",parameters:[{name:"operation",val:": str"},{name:"version",val:": str"}],parametersDescription:[{anchor:"accelerate.utils.is_torch_version.operation",description:`<strong>operation</strong> (<code>str</code>) &#x2014;
A string representation of an operator, such as <code>&quot;&gt;&quot;</code> or <code>&quot;&lt;=&quot;</code>`,name:"operation"},{anchor:"accelerate.utils.is_torch_version.version",description:`<strong>version</strong> (<code>str</code>) &#x2014;
A string version of PyTorch`,name:"version"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/versions.py#L51"}}),Oe=new b({props:{name:"accelerate.utils.is_tpu_available",anchor:"accelerate.utils.is_tpu_available",parameters:[],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/imports.py#L59"}}),Re=new _e({}),Ve=new b({props:{name:"accelerate.utils.write_basic_config",anchor:"accelerate.utils.write_basic_config",parameters:[{name:"mixed_precision",val:" = 'no'"},{name:"save_location",val:": str = '/github/home/.cache/huggingface/accelerate/default_config.yaml'"}],parametersDescription:[{anchor:"accelerate.utils.write_basic_config.mixed_precision",description:`<strong>mixed_precision</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;no&#x201D;) &#x2014;
Mixed Precision to use. Should be one of &#x201C;no&#x201D;, &#x201C;fp16&#x201D;, or &#x201C;bf16&#x201D;`,name:"mixed_precision"},{anchor:"accelerate.utils.write_basic_config.save_location",description:`<strong>save_location</strong> (<code>str</code>, <em>optional</em>, defaults to <code>default_json_config_file</code>) &#x2014;
Optional custom save location. Should be passed to <code>--config_file</code> when using <code>accelerate launch</code>. Default
location is inside the huggingface cache folder (<code>~/.cache/huggingface</code>) but can be overriden by setting
the <code>HF_HOME</code> environmental variable, followed by <code>accelerate/default_config.yaml</code>.`,name:"save_location"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L117"}}),Me=new _e({}),ze=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Ge=new b({props:{name:"accelerate.utils.get_max_layer_size",anchor:"accelerate.utils.get_max_layer_size",parameters:[{name:"modules",val:": typing.List[typing.Tuple[str, torch.nn.modules.module.Module]]"},{name:"module_sizes",val:": typing.Dict[str, int]"},{name:"no_split_module_classes",val:": typing.List[str]"}],parametersDescription:[{anchor:"accelerate.utils.get_max_layer_size.modules",description:`<strong>modules</strong> (<code>List[Tuple[str, torch.nn.Module]]</code>) &#x2014;
The list of named modules where we want to determine the maximum layer size.`,name:"modules"},{anchor:"accelerate.utils.get_max_layer_size.module_sizes",description:`<strong>module_sizes</strong> (<code>Dict[str, int]</code>) &#x2014;
A dictionary mapping each layer name to its size (as generated by <code>compute_module_sizes</code>).`,name:"module_sizes"},{anchor:"accelerate.utils.get_max_layer_size.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>) &#x2014;
A list of class names for layers we don&#x2019;t want to be split.`,name:"no_split_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/modeling.py#L233",returnDescription:`
<p>The maximum size of a layer with the list of layer names realizing that maximum size.</p>
`,returnType:`
<p><code>Tuple[int, List[str]]</code></p>
`}}),qe=new b({props:{name:"accelerate.utils.offload_state_dict",anchor:"accelerate.utils.offload_state_dict",parameters:[{name:"save_dir",val:": typing.Union[str, os.PathLike]"},{name:"state_dict",val:": typing.Dict[str, torch.Tensor]"}],parametersDescription:[{anchor:"accelerate.utils.offload_state_dict.save_dir",description:"<strong>save_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014; The directory in which to offload the state dict.",name:"save_dir"},{anchor:"accelerate.utils.offload_state_dict.state_dict",description:"<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>) &#x2014; The dictionary of tensors to offload.",name:"state_dict"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/offload.py#L84"}}),Fe=new _e({}),Be=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),We=new b({props:{name:"accelerate.utils.save",anchor:"accelerate.utils.save",parameters:[{name:"obj",val:""},{name:"f",val:""}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L74"}}),Je=new b({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L54"}}),pe=new Fn({props:{warning:!0,$$slots:{default:[Bn]},$$scope:{ctx:Pr}}}),Ke=new _e({}),Qe=new b({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/random.py#L30"}}),Ye=new b({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.dataclasses.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/random.py#L50"}}),et=new b({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.dataclasses.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/random.py#L85"}}),{c(){$=a("meta"),re=l(),y=a("h1"),E=a("a"),wt=a("span"),m(be.$$.fragment),za=l(),xt=a("span"),Ga=c("Helpful Utilities"),Lr=l(),U=a("h2"),ae=a("a"),Tt=a("span"),m($e.$$.fragment),Ha=l(),Dt=a("span"),qa=c("Data Classes"),kr=l(),rt=a("p"),Fa=c("These are basic dataclasses used throughout Accelerate and can be passed in as parameters."),Nr=l(),w=a("div"),m(ye.$$.fragment),Ba=l(),Pt=a("p"),Wa=c("Represents a type of distributed environment."),ja=l(),Lt=a("p"),Ja=c("Values:"),Ka=l(),x=a("ul"),at=a("li"),kt=a("strong"),Qa=c("NO"),Xa=c(" \u2014 Not a distributed environment, just a single process."),Ya=l(),st=a("li"),Nt=a("strong"),Za=c("MULTI_CPU"),es=c(" \u2014 Distributed on multiple CPU nodes."),ts=l(),ot=a("li"),Ct=a("strong"),rs=c("MULTI_GPU"),as=c(" \u2014 Distributed on multiple GPUs."),ss=l(),lt=a("li"),Ut=a("strong"),os=c("DEEPSPEED"),ls=c(" \u2014 Using DeepSpeed."),ns=l(),nt=a("li"),It=a("strong"),is=c("TPU"),cs=c(" \u2014 Distributed on TPUs."),Cr=l(),T=a("div"),m(Ee.$$.fragment),ds=l(),St=a("p"),ps=c("Represents a type of supported experiment tracker"),us=l(),Ot=a("p"),ms=c("Values:"),fs=l(),P=a("ul"),it=a("li"),At=a("strong"),hs=c("ALL"),vs=c(" \u2014 all available trackers in the environment that are supported"),gs=l(),ct=a("li"),Rt=a("strong"),_s=c("TENSORBOARD"),bs=c(" \u2014 TensorBoard as an experiment tracker"),$s=l(),dt=a("li"),Vt=a("strong"),ys=c("WANDB"),Es=c(" \u2014 wandb as an experiment tracker"),ws=l(),pt=a("li"),Mt=a("strong"),xs=c("COMETML"),Ts=c(" \u2014 comet_ml as an experiment tracker"),Ur=l(),D=a("div"),m(we.$$.fragment),Ds=l(),zt=a("p"),Ps=c("Represents a type of precision used on floating point values"),Ls=l(),Gt=a("p"),ks=c("Values:"),Ns=l(),I=a("ul"),ut=a("li"),Ht=a("strong"),Cs=c("NO"),Us=c(" \u2014 using full precision (FP32)"),Is=l(),mt=a("li"),qt=a("strong"),Ss=c("FP16"),Os=c(" \u2014 using half precision"),As=l(),ft=a("li"),Ft=a("strong"),Rs=c("BF16"),Vs=c(" \u2014 using brain floating point precision"),Ir=l(),S=a("h2"),se=a("a"),Bt=a("span"),m(xe.$$.fragment),Ms=l(),Wt=a("span"),zs=c("Data Manipulation and Operations"),Sr=l(),oe=a("p"),Gs=c("These include data operations that mimic the same "),jt=a("code"),Hs=c("torch"),qs=c(" ops but can be used on distributed processes."),Or=l(),O=a("div"),m(Te.$$.fragment),Fs=l(),Jt=a("p"),Bs=c("Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Ar=l(),A=a("div"),m(De.$$.fragment),Ws=l(),Kt=a("p"),js=c("Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Rr=l(),R=a("div"),m(Pe.$$.fragment),Js=l(),Qt=a("p"),Ks=c("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),Vr=l(),V=a("div"),m(Le.$$.fragment),Qs=l(),Xt=a("p"),Xs=c(`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),Mr=l(),M=a("div"),m(ke.$$.fragment),Ys=l(),Yt=a("p"),Zs=c(`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),zr=l(),z=a("div"),m(Ne.$$.fragment),eo=l(),Zt=a("p"),to=c("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),Gr=l(),G=a("h2"),le=a("a"),er=a("span"),m(Ce.$$.fragment),ro=l(),tr=a("span"),ao=c("Environment Checks"),Hr=l(),ht=a("p"),so=c("These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),qr=l(),H=a("div"),m(Ue.$$.fragment),oo=l(),rr=a("p"),lo=c("Get the maximum memory available if nothing is passed, converts string to int otherwise."),Fr=l(),q=a("div"),m(Ie.$$.fragment),no=l(),ar=a("p"),io=c("Checks if bf16 is supported, optionally ignoring the TPU"),Br=l(),F=a("div"),m(Se.$$.fragment),co=l(),sr=a("p"),po=c("Compares the current PyTorch version to a given reference with an operation."),Wr=l(),B=a("div"),m(Oe.$$.fragment),uo=l(),Ae=a("p"),mo=c("Checks if "),or=a("code"),fo=c("torch_xla"),ho=c(" is installed and if a TPU is in the environment"),jr=l(),W=a("h2"),ne=a("a"),lr=a("span"),m(Re.$$.fragment),vo=l(),nr=a("span"),go=c("Environment Configuration"),Jr=l(),j=a("div"),m(Ve.$$.fragment),_o=l(),ir=a("p"),bo=c(`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),Kr=l(),ie=a("p"),$o=c("When setting up Accelerate for the first time, rather than running "),cr=a("code"),yo=c("accelerate config"),Eo=c(", this can be used as alternative for quick configuration."),Qr=l(),J=a("h2"),ce=a("a"),dr=a("span"),m(Me.$$.fragment),wo=l(),pr=a("span"),xo=c("Modeling"),Xr=l(),vt=a("p"),To=c("These utilities relate to interacting with PyTorch models"),Yr=l(),K=a("div"),m(ze.$$.fragment),Do=l(),ur=a("p"),Po=c("Extract a model from its distributed containers."),Zr=l(),L=a("div"),m(Ge.$$.fragment),Lo=l(),mr=a("p"),ko=c(`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),No=l(),He=a("ul"),fr=a("li"),Co=c("a module with no direct children (just parameters and buffers)"),Uo=l(),gt=a("li"),Io=c("a module whose class name is in the list "),hr=a("code"),So=c("no_split_module_classes"),ea=l(),Q=a("div"),m(qe.$$.fragment),Oo=l(),vr=a("p"),Ao=c("Offload a state dict in a given folder."),ta=l(),X=a("h2"),de=a("a"),gr=a("span"),m(Fe.$$.fragment),Ro=l(),_r=a("span"),Vo=c("Parallel"),ra=l(),_t=a("p"),Mo=c("These include general utilities that should be used when working in parallel."),aa=l(),Y=a("div"),m(Be.$$.fragment),zo=l(),br=a("p"),Go=c("Extract a model from its distributed containers."),sa=l(),Z=a("div"),m(We.$$.fragment),Ho=l(),je=a("p"),qo=c("Save the data to disk. Use in place of "),$r=a("code"),Fo=c("torch.save()"),Bo=c("."),oa=l(),k=a("div"),m(Je.$$.fragment),Wo=l(),yr=a("p"),jo=c("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),Jo=l(),m(pe.$$.fragment),la=l(),ee=a("h2"),ue=a("a"),Er=a("span"),m(Ke.$$.fragment),Ko=l(),wr=a("span"),Qo=c("Random"),na=l(),bt=a("p"),Xo=c("These utilities relate to setting and synchronizing of all the random states."),ia=l(),te=a("div"),m(Qe.$$.fragment),Yo=l(),N=a("p"),Zo=c("Helper function for reproducible behavior to set the seed in "),xr=a("code"),el=c("random"),tl=c(", "),Tr=a("code"),rl=c("numpy"),al=c(", "),Dr=a("code"),sl=c("torch"),ol=c("."),ca=l(),Xe=a("div"),m(Ye.$$.fragment),da=l(),Ze=a("div"),m(et.$$.fragment),this.h()},l(e){const i=Hn('[data-svelte="svelte-1phssyn"]',document.head);$=s(i,"META",{name:!0,content:!0}),i.forEach(r),re=n(e),y=s(e,"H1",{class:!0});var tt=o(y);E=s(tt,"A",{id:!0,class:!0,href:!0});var bl=o(E);wt=s(bl,"SPAN",{});var $l=o(wt);f(be.$$.fragment,$l),$l.forEach(r),bl.forEach(r),za=n(tt),xt=s(tt,"SPAN",{});var yl=o(xt);Ga=d(yl,"Helpful Utilities"),yl.forEach(r),tt.forEach(r),Lr=n(e),U=s(e,"H2",{class:!0});var ua=o(U);ae=s(ua,"A",{id:!0,class:!0,href:!0});var El=o(ae);Tt=s(El,"SPAN",{});var wl=o(Tt);f($e.$$.fragment,wl),wl.forEach(r),El.forEach(r),Ha=n(ua),Dt=s(ua,"SPAN",{});var xl=o(Dt);qa=d(xl,"Data Classes"),xl.forEach(r),ua.forEach(r),kr=n(e),rt=s(e,"P",{});var Tl=o(rt);Fa=d(Tl,"These are basic dataclasses used throughout Accelerate and can be passed in as parameters."),Tl.forEach(r),Nr=n(e),w=s(e,"DIV",{class:!0});var me=o(w);f(ye.$$.fragment,me),Ba=n(me),Pt=s(me,"P",{});var Dl=o(Pt);Wa=d(Dl,"Represents a type of distributed environment."),Dl.forEach(r),ja=n(me),Lt=s(me,"P",{});var Pl=o(Lt);Ja=d(Pl,"Values:"),Pl.forEach(r),Ka=n(me),x=s(me,"UL",{});var C=o(x);at=s(C,"LI",{});var ll=o(at);kt=s(ll,"STRONG",{});var Ll=o(kt);Qa=d(Ll,"NO"),Ll.forEach(r),Xa=d(ll," \u2014 Not a distributed environment, just a single process."),ll.forEach(r),Ya=n(C),st=s(C,"LI",{});var nl=o(st);Nt=s(nl,"STRONG",{});var kl=o(Nt);Za=d(kl,"MULTI_CPU"),kl.forEach(r),es=d(nl," \u2014 Distributed on multiple CPU nodes."),nl.forEach(r),ts=n(C),ot=s(C,"LI",{});var il=o(ot);Ct=s(il,"STRONG",{});var Nl=o(Ct);rs=d(Nl,"MULTI_GPU"),Nl.forEach(r),as=d(il," \u2014 Distributed on multiple GPUs."),il.forEach(r),ss=n(C),lt=s(C,"LI",{});var cl=o(lt);Ut=s(cl,"STRONG",{});var Cl=o(Ut);os=d(Cl,"DEEPSPEED"),Cl.forEach(r),ls=d(cl," \u2014 Using DeepSpeed."),cl.forEach(r),ns=n(C),nt=s(C,"LI",{});var dl=o(nt);It=s(dl,"STRONG",{});var Ul=o(It);is=d(Ul,"TPU"),Ul.forEach(r),cs=d(dl," \u2014 Distributed on TPUs."),dl.forEach(r),C.forEach(r),me.forEach(r),Cr=n(e),T=s(e,"DIV",{class:!0});var fe=o(T);f(Ee.$$.fragment,fe),ds=n(fe),St=s(fe,"P",{});var Il=o(St);ps=d(Il,"Represents a type of supported experiment tracker"),Il.forEach(r),us=n(fe),Ot=s(fe,"P",{});var Sl=o(Ot);ms=d(Sl,"Values:"),Sl.forEach(r),fs=n(fe),P=s(fe,"UL",{});var he=o(P);it=s(he,"LI",{});var pl=o(it);At=s(pl,"STRONG",{});var Ol=o(At);hs=d(Ol,"ALL"),Ol.forEach(r),vs=d(pl," \u2014 all available trackers in the environment that are supported"),pl.forEach(r),gs=n(he),ct=s(he,"LI",{});var ul=o(ct);Rt=s(ul,"STRONG",{});var Al=o(Rt);_s=d(Al,"TENSORBOARD"),Al.forEach(r),bs=d(ul," \u2014 TensorBoard as an experiment tracker"),ul.forEach(r),$s=n(he),dt=s(he,"LI",{});var ml=o(dt);Vt=s(ml,"STRONG",{});var Rl=o(Vt);ys=d(Rl,"WANDB"),Rl.forEach(r),Es=d(ml," \u2014 wandb as an experiment tracker"),ml.forEach(r),ws=n(he),pt=s(he,"LI",{});var fl=o(pt);Mt=s(fl,"STRONG",{});var Vl=o(Mt);xs=d(Vl,"COMETML"),Vl.forEach(r),Ts=d(fl," \u2014 comet_ml as an experiment tracker"),fl.forEach(r),he.forEach(r),fe.forEach(r),Ur=n(e),D=s(e,"DIV",{class:!0});var ve=o(D);f(we.$$.fragment,ve),Ds=n(ve),zt=s(ve,"P",{});var Ml=o(zt);Ps=d(Ml,"Represents a type of precision used on floating point values"),Ml.forEach(r),Ls=n(ve),Gt=s(ve,"P",{});var zl=o(Gt);ks=d(zl,"Values:"),zl.forEach(r),Ns=n(ve),I=s(ve,"UL",{});var $t=o(I);ut=s($t,"LI",{});var hl=o(ut);Ht=s(hl,"STRONG",{});var Gl=o(Ht);Cs=d(Gl,"NO"),Gl.forEach(r),Us=d(hl," \u2014 using full precision (FP32)"),hl.forEach(r),Is=n($t),mt=s($t,"LI",{});var vl=o(mt);qt=s(vl,"STRONG",{});var Hl=o(qt);Ss=d(Hl,"FP16"),Hl.forEach(r),Os=d(vl," \u2014 using half precision"),vl.forEach(r),As=n($t),ft=s($t,"LI",{});var gl=o(ft);Ft=s(gl,"STRONG",{});var ql=o(Ft);Rs=d(ql,"BF16"),ql.forEach(r),Vs=d(gl," \u2014 using brain floating point precision"),gl.forEach(r),$t.forEach(r),ve.forEach(r),Ir=n(e),S=s(e,"H2",{class:!0});var ma=o(S);se=s(ma,"A",{id:!0,class:!0,href:!0});var Fl=o(se);Bt=s(Fl,"SPAN",{});var Bl=o(Bt);f(xe.$$.fragment,Bl),Bl.forEach(r),Fl.forEach(r),Ms=n(ma),Wt=s(ma,"SPAN",{});var Wl=o(Wt);zs=d(Wl,"Data Manipulation and Operations"),Wl.forEach(r),ma.forEach(r),Sr=n(e),oe=s(e,"P",{});var fa=o(oe);Gs=d(fa,"These include data operations that mimic the same "),jt=s(fa,"CODE",{});var jl=o(jt);Hs=d(jl,"torch"),jl.forEach(r),qs=d(fa," ops but can be used on distributed processes."),fa.forEach(r),Or=n(e),O=s(e,"DIV",{class:!0});var ha=o(O);f(Te.$$.fragment,ha),Fs=n(ha),Jt=s(ha,"P",{});var Jl=o(Jt);Bs=d(Jl,"Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Jl.forEach(r),ha.forEach(r),Ar=n(e),A=s(e,"DIV",{class:!0});var va=o(A);f(De.$$.fragment,va),Ws=n(va),Kt=s(va,"P",{});var Kl=o(Kt);js=d(Kl,"Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Kl.forEach(r),va.forEach(r),Rr=n(e),R=s(e,"DIV",{class:!0});var ga=o(R);f(Pe.$$.fragment,ga),Js=n(ga),Qt=s(ga,"P",{});var Ql=o(Qt);Ks=d(Ql,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),Ql.forEach(r),ga.forEach(r),Vr=n(e),V=s(e,"DIV",{class:!0});var _a=o(V);f(Le.$$.fragment,_a),Qs=n(_a),Xt=s(_a,"P",{});var Xl=o(Xt);Xs=d(Xl,`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),Xl.forEach(r),_a.forEach(r),Mr=n(e),M=s(e,"DIV",{class:!0});var ba=o(M);f(ke.$$.fragment,ba),Ys=n(ba),Yt=s(ba,"P",{});var Yl=o(Yt);Zs=d(Yl,`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),Yl.forEach(r),ba.forEach(r),zr=n(e),z=s(e,"DIV",{class:!0});var $a=o(z);f(Ne.$$.fragment,$a),eo=n($a),Zt=s($a,"P",{});var Zl=o(Zt);to=d(Zl,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),Zl.forEach(r),$a.forEach(r),Gr=n(e),G=s(e,"H2",{class:!0});var ya=o(G);le=s(ya,"A",{id:!0,class:!0,href:!0});var en=o(le);er=s(en,"SPAN",{});var tn=o(er);f(Ce.$$.fragment,tn),tn.forEach(r),en.forEach(r),ro=n(ya),tr=s(ya,"SPAN",{});var rn=o(tr);ao=d(rn,"Environment Checks"),rn.forEach(r),ya.forEach(r),Hr=n(e),ht=s(e,"P",{});var an=o(ht);so=d(an,"These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),an.forEach(r),qr=n(e),H=s(e,"DIV",{class:!0});var Ea=o(H);f(Ue.$$.fragment,Ea),oo=n(Ea),rr=s(Ea,"P",{});var sn=o(rr);lo=d(sn,"Get the maximum memory available if nothing is passed, converts string to int otherwise."),sn.forEach(r),Ea.forEach(r),Fr=n(e),q=s(e,"DIV",{class:!0});var wa=o(q);f(Ie.$$.fragment,wa),no=n(wa),ar=s(wa,"P",{});var on=o(ar);io=d(on,"Checks if bf16 is supported, optionally ignoring the TPU"),on.forEach(r),wa.forEach(r),Br=n(e),F=s(e,"DIV",{class:!0});var xa=o(F);f(Se.$$.fragment,xa),co=n(xa),sr=s(xa,"P",{});var ln=o(sr);po=d(ln,"Compares the current PyTorch version to a given reference with an operation."),ln.forEach(r),xa.forEach(r),Wr=n(e),B=s(e,"DIV",{class:!0});var Ta=o(B);f(Oe.$$.fragment,Ta),uo=n(Ta),Ae=s(Ta,"P",{});var Da=o(Ae);mo=d(Da,"Checks if "),or=s(Da,"CODE",{});var nn=o(or);fo=d(nn,"torch_xla"),nn.forEach(r),ho=d(Da," is installed and if a TPU is in the environment"),Da.forEach(r),Ta.forEach(r),jr=n(e),W=s(e,"H2",{class:!0});var Pa=o(W);ne=s(Pa,"A",{id:!0,class:!0,href:!0});var cn=o(ne);lr=s(cn,"SPAN",{});var dn=o(lr);f(Re.$$.fragment,dn),dn.forEach(r),cn.forEach(r),vo=n(Pa),nr=s(Pa,"SPAN",{});var pn=o(nr);go=d(pn,"Environment Configuration"),pn.forEach(r),Pa.forEach(r),Jr=n(e),j=s(e,"DIV",{class:!0});var La=o(j);f(Ve.$$.fragment,La),_o=n(La),ir=s(La,"P",{});var un=o(ir);bo=d(un,`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),un.forEach(r),La.forEach(r),Kr=n(e),ie=s(e,"P",{});var ka=o(ie);$o=d(ka,"When setting up Accelerate for the first time, rather than running "),cr=s(ka,"CODE",{});var mn=o(cr);yo=d(mn,"accelerate config"),mn.forEach(r),Eo=d(ka,", this can be used as alternative for quick configuration."),ka.forEach(r),Qr=n(e),J=s(e,"H2",{class:!0});var Na=o(J);ce=s(Na,"A",{id:!0,class:!0,href:!0});var fn=o(ce);dr=s(fn,"SPAN",{});var hn=o(dr);f(Me.$$.fragment,hn),hn.forEach(r),fn.forEach(r),wo=n(Na),pr=s(Na,"SPAN",{});var vn=o(pr);xo=d(vn,"Modeling"),vn.forEach(r),Na.forEach(r),Xr=n(e),vt=s(e,"P",{});var gn=o(vt);To=d(gn,"These utilities relate to interacting with PyTorch models"),gn.forEach(r),Yr=n(e),K=s(e,"DIV",{class:!0});var Ca=o(K);f(ze.$$.fragment,Ca),Do=n(Ca),ur=s(Ca,"P",{});var _n=o(ur);Po=d(_n,"Extract a model from its distributed containers."),_n.forEach(r),Ca.forEach(r),Zr=n(e),L=s(e,"DIV",{class:!0});var yt=o(L);f(Ge.$$.fragment,yt),Lo=n(yt),mr=s(yt,"P",{});var bn=o(mr);ko=d(bn,`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),bn.forEach(r),No=n(yt),He=s(yt,"UL",{});var Ua=o(He);fr=s(Ua,"LI",{});var $n=o(fr);Co=d($n,"a module with no direct children (just parameters and buffers)"),$n.forEach(r),Uo=n(Ua),gt=s(Ua,"LI",{});var _l=o(gt);Io=d(_l,"a module whose class name is in the list "),hr=s(_l,"CODE",{});var yn=o(hr);So=d(yn,"no_split_module_classes"),yn.forEach(r),_l.forEach(r),Ua.forEach(r),yt.forEach(r),ea=n(e),Q=s(e,"DIV",{class:!0});var Ia=o(Q);f(qe.$$.fragment,Ia),Oo=n(Ia),vr=s(Ia,"P",{});var En=o(vr);Ao=d(En,"Offload a state dict in a given folder."),En.forEach(r),Ia.forEach(r),ta=n(e),X=s(e,"H2",{class:!0});var Sa=o(X);de=s(Sa,"A",{id:!0,class:!0,href:!0});var wn=o(de);gr=s(wn,"SPAN",{});var xn=o(gr);f(Fe.$$.fragment,xn),xn.forEach(r),wn.forEach(r),Ro=n(Sa),_r=s(Sa,"SPAN",{});var Tn=o(_r);Vo=d(Tn,"Parallel"),Tn.forEach(r),Sa.forEach(r),ra=n(e),_t=s(e,"P",{});var Dn=o(_t);Mo=d(Dn,"These include general utilities that should be used when working in parallel."),Dn.forEach(r),aa=n(e),Y=s(e,"DIV",{class:!0});var Oa=o(Y);f(Be.$$.fragment,Oa),zo=n(Oa),br=s(Oa,"P",{});var Pn=o(br);Go=d(Pn,"Extract a model from its distributed containers."),Pn.forEach(r),Oa.forEach(r),sa=n(e),Z=s(e,"DIV",{class:!0});var Aa=o(Z);f(We.$$.fragment,Aa),Ho=n(Aa),je=s(Aa,"P",{});var Ra=o(je);qo=d(Ra,"Save the data to disk. Use in place of "),$r=s(Ra,"CODE",{});var Ln=o($r);Fo=d(Ln,"torch.save()"),Ln.forEach(r),Bo=d(Ra,"."),Ra.forEach(r),Aa.forEach(r),oa=n(e),k=s(e,"DIV",{class:!0});var Et=o(k);f(Je.$$.fragment,Et),Wo=n(Et),yr=s(Et,"P",{});var kn=o(yr);jo=d(kn,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),kn.forEach(r),Jo=n(Et),f(pe.$$.fragment,Et),Et.forEach(r),la=n(e),ee=s(e,"H2",{class:!0});var Va=o(ee);ue=s(Va,"A",{id:!0,class:!0,href:!0});var Nn=o(ue);Er=s(Nn,"SPAN",{});var Cn=o(Er);f(Ke.$$.fragment,Cn),Cn.forEach(r),Nn.forEach(r),Ko=n(Va),wr=s(Va,"SPAN",{});var Un=o(wr);Qo=d(Un,"Random"),Un.forEach(r),Va.forEach(r),na=n(e),bt=s(e,"P",{});var In=o(bt);Xo=d(In,"These utilities relate to setting and synchronizing of all the random states."),In.forEach(r),ia=n(e),te=s(e,"DIV",{class:!0});var Ma=o(te);f(Qe.$$.fragment,Ma),Yo=n(Ma),N=s(Ma,"P",{});var ge=o(N);Zo=d(ge,"Helper function for reproducible behavior to set the seed in "),xr=s(ge,"CODE",{});var Sn=o(xr);el=d(Sn,"random"),Sn.forEach(r),tl=d(ge,", "),Tr=s(ge,"CODE",{});var On=o(Tr);rl=d(On,"numpy"),On.forEach(r),al=d(ge,", "),Dr=s(ge,"CODE",{});var An=o(Dr);sl=d(An,"torch"),An.forEach(r),ol=d(ge,"."),ge.forEach(r),Ma.forEach(r),ca=n(e),Xe=s(e,"DIV",{class:!0});var Rn=o(Xe);f(Ye.$$.fragment,Rn),Rn.forEach(r),da=n(e),Ze=s(e,"DIV",{class:!0});var Vn=o(Ze);f(et.$$.fragment,Vn),Vn.forEach(r),this.h()},h(){u($,"name","hf:doc:metadata"),u($,"content",JSON.stringify(jn)),u(E,"id","helpful-utilities"),u(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(E,"href","#helpful-utilities"),u(y,"class","relative group"),u(ae,"id","accelerate.DistributedType"),u(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ae,"href","#accelerate.DistributedType"),u(U,"class","relative group"),u(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(se,"id","accelerate.utils.broadcast"),u(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(se,"href","#accelerate.utils.broadcast"),u(S,"class","relative group"),u(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(le,"id","accelerate.utils.get_max_memory"),u(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(le,"href","#accelerate.utils.get_max_memory"),u(G,"class","relative group"),u(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ne,"id","accelerate.utils.write_basic_config"),u(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ne,"href","#accelerate.utils.write_basic_config"),u(W,"class","relative group"),u(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ce,"id","accelerate.utils.extract_model_from_parallel"),u(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ce,"href","#accelerate.utils.extract_model_from_parallel"),u(J,"class","relative group"),u(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(de,"id","accelerate.utils.extract_model_from_parallel"),u(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(de,"href","#accelerate.utils.extract_model_from_parallel"),u(X,"class","relative group"),u(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ue,"id","accelerate.utils.set_seed"),u(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ue,"href","#accelerate.utils.set_seed"),u(ee,"class","relative group"),u(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,i){t(document.head,$),p(e,re,i),p(e,y,i),t(y,E),t(E,wt),h(be,wt,null),t(y,za),t(y,xt),t(xt,Ga),p(e,Lr,i),p(e,U,i),t(U,ae),t(ae,Tt),h($e,Tt,null),t(U,Ha),t(U,Dt),t(Dt,qa),p(e,kr,i),p(e,rt,i),t(rt,Fa),p(e,Nr,i),p(e,w,i),h(ye,w,null),t(w,Ba),t(w,Pt),t(Pt,Wa),t(w,ja),t(w,Lt),t(Lt,Ja),t(w,Ka),t(w,x),t(x,at),t(at,kt),t(kt,Qa),t(at,Xa),t(x,Ya),t(x,st),t(st,Nt),t(Nt,Za),t(st,es),t(x,ts),t(x,ot),t(ot,Ct),t(Ct,rs),t(ot,as),t(x,ss),t(x,lt),t(lt,Ut),t(Ut,os),t(lt,ls),t(x,ns),t(x,nt),t(nt,It),t(It,is),t(nt,cs),p(e,Cr,i),p(e,T,i),h(Ee,T,null),t(T,ds),t(T,St),t(St,ps),t(T,us),t(T,Ot),t(Ot,ms),t(T,fs),t(T,P),t(P,it),t(it,At),t(At,hs),t(it,vs),t(P,gs),t(P,ct),t(ct,Rt),t(Rt,_s),t(ct,bs),t(P,$s),t(P,dt),t(dt,Vt),t(Vt,ys),t(dt,Es),t(P,ws),t(P,pt),t(pt,Mt),t(Mt,xs),t(pt,Ts),p(e,Ur,i),p(e,D,i),h(we,D,null),t(D,Ds),t(D,zt),t(zt,Ps),t(D,Ls),t(D,Gt),t(Gt,ks),t(D,Ns),t(D,I),t(I,ut),t(ut,Ht),t(Ht,Cs),t(ut,Us),t(I,Is),t(I,mt),t(mt,qt),t(qt,Ss),t(mt,Os),t(I,As),t(I,ft),t(ft,Ft),t(Ft,Rs),t(ft,Vs),p(e,Ir,i),p(e,S,i),t(S,se),t(se,Bt),h(xe,Bt,null),t(S,Ms),t(S,Wt),t(Wt,zs),p(e,Sr,i),p(e,oe,i),t(oe,Gs),t(oe,jt),t(jt,Hs),t(oe,qs),p(e,Or,i),p(e,O,i),h(Te,O,null),t(O,Fs),t(O,Jt),t(Jt,Bs),p(e,Ar,i),p(e,A,i),h(De,A,null),t(A,Ws),t(A,Kt),t(Kt,js),p(e,Rr,i),p(e,R,i),h(Pe,R,null),t(R,Js),t(R,Qt),t(Qt,Ks),p(e,Vr,i),p(e,V,i),h(Le,V,null),t(V,Qs),t(V,Xt),t(Xt,Xs),p(e,Mr,i),p(e,M,i),h(ke,M,null),t(M,Ys),t(M,Yt),t(Yt,Zs),p(e,zr,i),p(e,z,i),h(Ne,z,null),t(z,eo),t(z,Zt),t(Zt,to),p(e,Gr,i),p(e,G,i),t(G,le),t(le,er),h(Ce,er,null),t(G,ro),t(G,tr),t(tr,ao),p(e,Hr,i),p(e,ht,i),t(ht,so),p(e,qr,i),p(e,H,i),h(Ue,H,null),t(H,oo),t(H,rr),t(rr,lo),p(e,Fr,i),p(e,q,i),h(Ie,q,null),t(q,no),t(q,ar),t(ar,io),p(e,Br,i),p(e,F,i),h(Se,F,null),t(F,co),t(F,sr),t(sr,po),p(e,Wr,i),p(e,B,i),h(Oe,B,null),t(B,uo),t(B,Ae),t(Ae,mo),t(Ae,or),t(or,fo),t(Ae,ho),p(e,jr,i),p(e,W,i),t(W,ne),t(ne,lr),h(Re,lr,null),t(W,vo),t(W,nr),t(nr,go),p(e,Jr,i),p(e,j,i),h(Ve,j,null),t(j,_o),t(j,ir),t(ir,bo),p(e,Kr,i),p(e,ie,i),t(ie,$o),t(ie,cr),t(cr,yo),t(ie,Eo),p(e,Qr,i),p(e,J,i),t(J,ce),t(ce,dr),h(Me,dr,null),t(J,wo),t(J,pr),t(pr,xo),p(e,Xr,i),p(e,vt,i),t(vt,To),p(e,Yr,i),p(e,K,i),h(ze,K,null),t(K,Do),t(K,ur),t(ur,Po),p(e,Zr,i),p(e,L,i),h(Ge,L,null),t(L,Lo),t(L,mr),t(mr,ko),t(L,No),t(L,He),t(He,fr),t(fr,Co),t(He,Uo),t(He,gt),t(gt,Io),t(gt,hr),t(hr,So),p(e,ea,i),p(e,Q,i),h(qe,Q,null),t(Q,Oo),t(Q,vr),t(vr,Ao),p(e,ta,i),p(e,X,i),t(X,de),t(de,gr),h(Fe,gr,null),t(X,Ro),t(X,_r),t(_r,Vo),p(e,ra,i),p(e,_t,i),t(_t,Mo),p(e,aa,i),p(e,Y,i),h(Be,Y,null),t(Y,zo),t(Y,br),t(br,Go),p(e,sa,i),p(e,Z,i),h(We,Z,null),t(Z,Ho),t(Z,je),t(je,qo),t(je,$r),t($r,Fo),t(je,Bo),p(e,oa,i),p(e,k,i),h(Je,k,null),t(k,Wo),t(k,yr),t(yr,jo),t(k,Jo),h(pe,k,null),p(e,la,i),p(e,ee,i),t(ee,ue),t(ue,Er),h(Ke,Er,null),t(ee,Ko),t(ee,wr),t(wr,Qo),p(e,na,i),p(e,bt,i),t(bt,Xo),p(e,ia,i),p(e,te,i),h(Qe,te,null),t(te,Yo),t(te,N),t(N,Zo),t(N,xr),t(xr,el),t(N,tl),t(N,Tr),t(Tr,rl),t(N,al),t(N,Dr),t(Dr,sl),t(N,ol),p(e,ca,i),p(e,Xe,i),h(Ye,Xe,null),p(e,da,i),p(e,Ze,i),h(et,Ze,null),pa=!0},p(e,[i]){const tt={};i&2&&(tt.$$scope={dirty:i,ctx:e}),pe.$set(tt)},i(e){pa||(v(be.$$.fragment,e),v($e.$$.fragment,e),v(ye.$$.fragment,e),v(Ee.$$.fragment,e),v(we.$$.fragment,e),v(xe.$$.fragment,e),v(Te.$$.fragment,e),v(De.$$.fragment,e),v(Pe.$$.fragment,e),v(Le.$$.fragment,e),v(ke.$$.fragment,e),v(Ne.$$.fragment,e),v(Ce.$$.fragment,e),v(Ue.$$.fragment,e),v(Ie.$$.fragment,e),v(Se.$$.fragment,e),v(Oe.$$.fragment,e),v(Re.$$.fragment,e),v(Ve.$$.fragment,e),v(Me.$$.fragment,e),v(ze.$$.fragment,e),v(Ge.$$.fragment,e),v(qe.$$.fragment,e),v(Fe.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(Je.$$.fragment,e),v(pe.$$.fragment,e),v(Ke.$$.fragment,e),v(Qe.$$.fragment,e),v(Ye.$$.fragment,e),v(et.$$.fragment,e),pa=!0)},o(e){g(be.$$.fragment,e),g($e.$$.fragment,e),g(ye.$$.fragment,e),g(Ee.$$.fragment,e),g(we.$$.fragment,e),g(xe.$$.fragment,e),g(Te.$$.fragment,e),g(De.$$.fragment,e),g(Pe.$$.fragment,e),g(Le.$$.fragment,e),g(ke.$$.fragment,e),g(Ne.$$.fragment,e),g(Ce.$$.fragment,e),g(Ue.$$.fragment,e),g(Ie.$$.fragment,e),g(Se.$$.fragment,e),g(Oe.$$.fragment,e),g(Re.$$.fragment,e),g(Ve.$$.fragment,e),g(Me.$$.fragment,e),g(ze.$$.fragment,e),g(Ge.$$.fragment,e),g(qe.$$.fragment,e),g(Fe.$$.fragment,e),g(Be.$$.fragment,e),g(We.$$.fragment,e),g(Je.$$.fragment,e),g(pe.$$.fragment,e),g(Ke.$$.fragment,e),g(Qe.$$.fragment,e),g(Ye.$$.fragment,e),g(et.$$.fragment,e),pa=!1},d(e){r($),e&&r(re),e&&r(y),_(be),e&&r(Lr),e&&r(U),_($e),e&&r(kr),e&&r(rt),e&&r(Nr),e&&r(w),_(ye),e&&r(Cr),e&&r(T),_(Ee),e&&r(Ur),e&&r(D),_(we),e&&r(Ir),e&&r(S),_(xe),e&&r(Sr),e&&r(oe),e&&r(Or),e&&r(O),_(Te),e&&r(Ar),e&&r(A),_(De),e&&r(Rr),e&&r(R),_(Pe),e&&r(Vr),e&&r(V),_(Le),e&&r(Mr),e&&r(M),_(ke),e&&r(zr),e&&r(z),_(Ne),e&&r(Gr),e&&r(G),_(Ce),e&&r(Hr),e&&r(ht),e&&r(qr),e&&r(H),_(Ue),e&&r(Fr),e&&r(q),_(Ie),e&&r(Br),e&&r(F),_(Se),e&&r(Wr),e&&r(B),_(Oe),e&&r(jr),e&&r(W),_(Re),e&&r(Jr),e&&r(j),_(Ve),e&&r(Kr),e&&r(ie),e&&r(Qr),e&&r(J),_(Me),e&&r(Xr),e&&r(vt),e&&r(Yr),e&&r(K),_(ze),e&&r(Zr),e&&r(L),_(Ge),e&&r(ea),e&&r(Q),_(qe),e&&r(ta),e&&r(X),_(Fe),e&&r(ra),e&&r(_t),e&&r(aa),e&&r(Y),_(Be),e&&r(sa),e&&r(Z),_(We),e&&r(oa),e&&r(k),_(Je),_(pe),e&&r(la),e&&r(ee),_(Ke),e&&r(na),e&&r(bt),e&&r(ia),e&&r(te),_(Qe),e&&r(ca),e&&r(Xe),_(Ye),e&&r(da),e&&r(Ze),_(et)}}}const jn={local:"helpful-utilities",sections:[{local:"accelerate.DistributedType",title:"Data Classes"},{local:"accelerate.utils.broadcast",title:"Data Manipulation and Operations"},{local:"accelerate.utils.get_max_memory",title:"Environment Checks"},{local:"accelerate.utils.write_basic_config",title:"Environment Configuration"},{local:"accelerate.utils.extract_model_from_parallel",title:"Modeling"},{local:"accelerate.utils.extract_model_from_parallel",title:"Parallel"},{local:"accelerate.utils.set_seed",title:"Random"}],title:"Helpful Utilities"};function Jn(Pr){return qn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Zn extends Mn{constructor($){super();zn(this,$,Jn,Wn,Gn,{})}}export{Zn as default,jn as metadata};
