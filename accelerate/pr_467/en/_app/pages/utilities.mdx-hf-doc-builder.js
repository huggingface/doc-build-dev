import{S as pn,i as mn,s as un,e as a,k as l,w as u,t as i,M as fn,c as s,d as r,m as n,a as o,x as f,h as c,b as m,G as t,g as p,y as h,q as v,o as g,B as _,v as hn}from"../chunks/vendor-hf-doc-builder.js";import{T as vn}from"../chunks/Tip-hf-doc-builder.js";import{D as b}from"../chunks/Docstring-hf-doc-builder.js";import{I as ge}from"../chunks/IconCopyLink-hf-doc-builder.js";function gn($r){let $,re;return{c(){$=a("p"),re=i("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(y){$=s(y,"P",{});var E=o($);re=c(E,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),E.forEach(r)},m(y,E){p(y,$,E),t($,re)},d(y){y&&r($)}}}function _n($r){let $,re,y,E,gt,_e,Ta,_t,Pa,yr,U,ae,bt,be,La,$t,Na,Er,x,$e,ka,yt,Ca,Ua,Et,Ia,Sa,w,tt,xt,Oa,Ra,Aa,rt,wt,Va,Ma,Ga,at,Dt,za,Ha,qa,st,Tt,Fa,Ba,ja,ot,Pt,Wa,Ja,xr,D,ye,Ka,Lt,Qa,Xa,Nt,Ya,Za,P,lt,kt,es,ts,rs,nt,Ct,as,ss,os,it,Ut,ls,ns,is,ct,It,cs,ds,wr,T,Ee,ps,St,ms,us,Ot,fs,hs,I,dt,Rt,vs,gs,_s,pt,At,bs,$s,ys,mt,Vt,Es,xs,Dr,S,se,Mt,xe,ws,Gt,Ds,Tr,oe,Ts,zt,Ps,Ls,Pr,O,we,Ns,Ht,ks,Lr,R,De,Cs,qt,Us,Nr,A,Te,Is,Ft,Ss,kr,V,Pe,Os,Bt,Rs,Cr,M,Le,As,jt,Vs,Ur,G,Ne,Ms,Wt,Gs,Ir,z,le,Jt,ke,zs,Kt,Hs,Sr,H,Ce,qs,Qt,Fs,Or,q,Ue,Bs,Xt,js,Rr,F,Ie,Ws,Yt,Js,Ar,B,Se,Ks,Oe,Qs,Zt,Xs,Ys,Vr,j,ne,er,Re,Zs,tr,eo,Mr,W,Ae,to,rr,ro,Gr,J,ie,ar,Ve,ao,sr,so,zr,K,Me,oo,or,lo,Hr,L,Ge,no,lr,io,co,ze,nr,po,mo,ut,uo,ir,fo,qr,Q,He,ho,cr,vo,Fr,X,ce,dr,qe,go,pr,_o,Br,Y,Fe,bo,mr,$o,jr,Z,Be,yo,je,Eo,ur,xo,wo,Wr,N,We,Do,fr,To,Po,de,Jr,ee,pe,hr,Je,Lo,vr,No,Kr,te,Ke,ko,k,Co,gr,Uo,Io,_r,So,Oo,br,Ro,Ao,Qr,Qe,Xe,Xr,Ye,Ze,Yr;return _e=new ge({}),be=new ge({}),$e=new b({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/dataclasses.py#L104"}}),ye=new b({props:{name:"class accelerate.utils.LoggerType",anchor:"accelerate.utils.LoggerType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/dataclasses.py#L181"}}),Ee=new b({props:{name:"class accelerate.utils.PrecisionType",anchor:"accelerate.utils.PrecisionType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/dataclasses.py#L198"}}),xe=new ge({}),we=new b({props:{name:"accelerate.utils.broadcast",anchor:"accelerate.utils.broadcast",parameters:[{name:"tensor",val:""},{name:"from_process",val:": int = 0"}],parametersDescription:[{anchor:"accelerate.utils.broadcast.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.broadcast.from_process",description:`<strong>from_process</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The process from which to send the data`,name:"from_process"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L277",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors broadcasted to the proper device.</p>
`}}),De=new b({props:{name:"accelerate.utils.concatenate",anchor:"accelerate.utils.concatenate",parameters:[{name:"data",val:""},{name:"dim",val:" = 0"}],parametersDescription:[{anchor:"accelerate.utils.concatenate.data",description:`<strong>data</strong> (nested list/tuple/dictionary of lists of tensors <code>torch.Tensor</code>) &#x2014;
The data to concatenate.`,name:"data"},{anchor:"accelerate.utils.concatenate.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to concatenate.`,name:"dim"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L343",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors concatenated.</p>
`}}),Te=new b({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L207",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Pe=new b({props:{name:"accelerate.utils.pad_across_processes",anchor:"accelerate.utils.pad_across_processes",parameters:[{name:"tensor",val:""},{name:"dim",val:" = 0"},{name:"pad_index",val:" = 0"},{name:"pad_first",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.pad_across_processes.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.pad_across_processes.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to pad.`,name:"dim"},{anchor:"accelerate.utils.pad_across_processes.pad_index",description:`<strong>pad_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The value with which to pad.`,name:"pad_index"},{anchor:"accelerate.utils.pad_across_processes.pad_first",description:`<strong>pad_first</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to pad at the beginning or the end.`,name:"pad_first"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L365"}}),Le=new b({props:{name:"accelerate.utils.reduce",anchor:"accelerate.utils.reduce",parameters:[{name:"tensor",val:""},{name:"reduction",val:" = 'mean'"}],parametersDescription:[{anchor:"accelerate.utils.reduce.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to reduce.`,name:"tensor"},{anchor:"accelerate.utils.reduce.reduction",description:`<strong>reduction</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;mean&quot;</code>) &#x2014;
A reduction method. Can be of &#x201C;mean&#x201D;, &#x201C;sum&#x201D;, or &#x201C;none&#x201D;`,name:"reduction"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L411",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors reduced.</p>
`}}),Ne=new b({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""}],parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/operations.py#L106",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),ke=new ge({}),Ce=new b({props:{name:"accelerate.utils.get_max_memory",anchor:"accelerate.utils.get_max_memory",parameters:[{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/modeling.py#L272"}}),Ue=new b({props:{name:"accelerate.utils.is_bf16_available",anchor:"accelerate.utils.is_bf16_available",parameters:[{name:"ignore_tpu",val:" = False"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/imports.py#L76"}}),Ie=new b({props:{name:"accelerate.utils.is_torch_version",anchor:"accelerate.utils.is_torch_version",parameters:[{name:"operation",val:": str"},{name:"version",val:": str"}],parametersDescription:[{anchor:"accelerate.utils.is_torch_version.operation",description:`<strong>operation</strong> (<code>str</code>) &#x2014;
A string representation of an operator, such as <code>&quot;&gt;&quot;</code> or <code>&quot;&lt;=&quot;</code>`,name:"operation"},{anchor:"accelerate.utils.is_torch_version.version",description:`<strong>version</strong> (<code>str</code>) &#x2014;
A string version of PyTorch`,name:"version"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/versions.py#L51"}}),Se=new b({props:{name:"accelerate.utils.is_tpu_available",anchor:"accelerate.utils.is_tpu_available",parameters:[],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/imports.py#L59"}}),Re=new ge({}),Ae=new b({props:{name:"accelerate.utils.write_basic_config",anchor:"accelerate.utils.write_basic_config",parameters:[{name:"mixed_precision",val:" = 'no'"},{name:"save_location",val:": str = '/github/home/.cache/huggingface/accelerate/default_config.yaml'"}],parametersDescription:[{anchor:"accelerate.utils.write_basic_config.mixed_precision",description:`<strong>mixed_precision</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;no&#x201D;) &#x2014;
Mixed Precision to use. Should be one of &#x201C;no&#x201D;, &#x201C;fp16&#x201D;, or &#x201C;bf16&#x201D;`,name:"mixed_precision"},{anchor:"accelerate.utils.write_basic_config.save_location",description:`<strong>save_location</strong> (<code>str</code>, <em>optional</em>, defaults to <code>default_json_config_file</code>) &#x2014;
Optional custom save location. Should be passed to <code>--config_file</code> when using <code>accelerate launch</code>. Default
location is inside the huggingface cache folder (<code>~/.cache/huggingface</code>) but can be overriden by setting
the <code>HF_HOME</code> environmental variable, followed by <code>accelerate/default_config.yaml</code>.`,name:"save_location"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L117"}}),Ve=new ge({}),Me=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Ge=new b({props:{name:"accelerate.utils.get_max_layer_size",anchor:"accelerate.utils.get_max_layer_size",parameters:[{name:"modules",val:": typing.List[typing.Tuple[str, torch.nn.modules.module.Module]]"},{name:"module_sizes",val:": typing.Dict[str, int]"},{name:"no_split_module_classes",val:": typing.List[str]"}],parametersDescription:[{anchor:"accelerate.utils.get_max_layer_size.modules",description:`<strong>modules</strong> (<code>List[Tuple[str, torch.nn.Module]]</code>) &#x2014;
The list of named modules where we want to determine the maximum layer size.`,name:"modules"},{anchor:"accelerate.utils.get_max_layer_size.module_sizes",description:`<strong>module_sizes</strong> (<code>Dict[str, int]</code>) &#x2014;
A dictionary mapping each layer name to its size (as generated by <code>compute_module_sizes</code>).`,name:"module_sizes"},{anchor:"accelerate.utils.get_max_layer_size.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>) &#x2014;
A list of class names for layers we don&#x2019;t want to be split.`,name:"no_split_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/modeling.py#L233",returnDescription:`
<p>The maximum size of a layer with the list of layer names realizing that maximum size.</p>
`,returnType:`
<p><code>Tuple[int, List[str]]</code></p>
`}}),He=new b({props:{name:"accelerate.utils.offload_state_dict",anchor:"accelerate.utils.offload_state_dict",parameters:[{name:"save_dir",val:": typing.Union[str, os.PathLike]"},{name:"state_dict",val:": typing.Dict[str, torch.Tensor]"}],parametersDescription:[{anchor:"accelerate.utils.offload_state_dict.save_dir",description:"<strong>save_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014; The directory in which to offload the state dict.",name:"save_dir"},{anchor:"accelerate.utils.offload_state_dict.state_dict",description:"<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>) &#x2014; The dictionary of tensors to offload.",name:"state_dict"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/offload.py#L84"}}),qe=new ge({}),Fe=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Be=new b({props:{name:"accelerate.utils.save",anchor:"accelerate.utils.save",parameters:[{name:"obj",val:""},{name:"f",val:""}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L74"}}),We=new b({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/other.py#L54"}}),de=new vn({props:{warning:!0,$$slots:{default:[gn]},$$scope:{ctx:$r}}}),Je=new ge({}),Ke=new b({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/random.py#L30"}}),Xe=new b({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.dataclasses.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/random.py#L50"}}),Ze=new b({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.dataclasses.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/vr_467/src/accelerate/utils/random.py#L85"}}),{c(){$=a("meta"),re=l(),y=a("h1"),E=a("a"),gt=a("span"),u(_e.$$.fragment),Ta=l(),_t=a("span"),Pa=i("Helpful Utilities"),yr=l(),U=a("h2"),ae=a("a"),bt=a("span"),u(be.$$.fragment),La=l(),$t=a("span"),Na=i("Data Classes"),Er=l(),x=a("div"),u($e.$$.fragment),ka=l(),yt=a("p"),Ca=i("Represents a type of distributed environment."),Ua=l(),Et=a("p"),Ia=i("Values:"),Sa=l(),w=a("ul"),tt=a("li"),xt=a("strong"),Oa=i("NO"),Ra=i(" \u2014 Not a distributed environment, just a single process."),Aa=l(),rt=a("li"),wt=a("strong"),Va=i("MULTI_CPU"),Ma=i(" \u2014 Distributed on multiple CPU nodes."),Ga=l(),at=a("li"),Dt=a("strong"),za=i("MULTI_GPU"),Ha=i(" \u2014 Distributed on multiple GPUs."),qa=l(),st=a("li"),Tt=a("strong"),Fa=i("DEEPSPEED"),Ba=i(" \u2014 Using DeepSpeed."),ja=l(),ot=a("li"),Pt=a("strong"),Wa=i("TPU"),Ja=i(" \u2014 Distributed on TPUs."),xr=l(),D=a("div"),u(ye.$$.fragment),Ka=l(),Lt=a("p"),Qa=i("Represents a type of supported experiment tracker"),Xa=l(),Nt=a("p"),Ya=i("Values:"),Za=l(),P=a("ul"),lt=a("li"),kt=a("strong"),es=i("ALL"),ts=i(" \u2014 all available trackers in the environment that are supported"),rs=l(),nt=a("li"),Ct=a("strong"),as=i("TENSORBOARD"),ss=i(" \u2014 TensorBoard as an experiment tracker"),os=l(),it=a("li"),Ut=a("strong"),ls=i("WANDB"),ns=i(" \u2014 wandb as an experiment tracker"),is=l(),ct=a("li"),It=a("strong"),cs=i("COMETML"),ds=i(" \u2014 comet_ml as an experiment tracker"),wr=l(),T=a("div"),u(Ee.$$.fragment),ps=l(),St=a("p"),ms=i("Represents a type of precision used on floating point values"),us=l(),Ot=a("p"),fs=i("Values:"),hs=l(),I=a("ul"),dt=a("li"),Rt=a("strong"),vs=i("NO"),gs=i(" \u2014 using full precision (FP32)"),_s=l(),pt=a("li"),At=a("strong"),bs=i("FP16"),$s=i(" \u2014 using half precision"),ys=l(),mt=a("li"),Vt=a("strong"),Es=i("BF16"),xs=i(" \u2014 using brain floating point precision"),Dr=l(),S=a("h2"),se=a("a"),Mt=a("span"),u(xe.$$.fragment),ws=l(),Gt=a("span"),Ds=i("Data Manipulation and Operations"),Tr=l(),oe=a("p"),Ts=i("These include data operations that mimic the same "),zt=a("code"),Ps=i("torch"),Ls=i(" ops but can be used on distributed processes."),Pr=l(),O=a("div"),u(we.$$.fragment),Ns=l(),Ht=a("p"),ks=i("Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Lr=l(),R=a("div"),u(De.$$.fragment),Cs=l(),qt=a("p"),Us=i("Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Nr=l(),A=a("div"),u(Te.$$.fragment),Is=l(),Ft=a("p"),Ss=i("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),kr=l(),V=a("div"),u(Pe.$$.fragment),Os=l(),Bt=a("p"),Rs=i(`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),Cr=l(),M=a("div"),u(Le.$$.fragment),As=l(),jt=a("p"),Vs=i(`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),Ur=l(),G=a("div"),u(Ne.$$.fragment),Ms=l(),Wt=a("p"),Gs=i("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),Ir=l(),z=a("h2"),le=a("a"),Jt=a("span"),u(ke.$$.fragment),zs=l(),Kt=a("span"),Hs=i("Environment Checks"),Sr=l(),H=a("div"),u(Ce.$$.fragment),qs=l(),Qt=a("p"),Fs=i("Get the maximum memory available if nothing is passed, converts string to int otherwise."),Or=l(),q=a("div"),u(Ue.$$.fragment),Bs=l(),Xt=a("p"),js=i("Checks if bf16 is supported, optionally ignoring the TPU"),Rr=l(),F=a("div"),u(Ie.$$.fragment),Ws=l(),Yt=a("p"),Js=i("Compares the current PyTorch version to a given reference with an operation."),Ar=l(),B=a("div"),u(Se.$$.fragment),Ks=l(),Oe=a("p"),Qs=i("Checks if "),Zt=a("code"),Xs=i("torch_xla"),Ys=i(" is installed and if a TPU is in the environment"),Vr=l(),j=a("h2"),ne=a("a"),er=a("span"),u(Re.$$.fragment),Zs=l(),tr=a("span"),eo=i("Environment Configuration"),Mr=l(),W=a("div"),u(Ae.$$.fragment),to=l(),rr=a("p"),ro=i(`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),Gr=l(),J=a("h2"),ie=a("a"),ar=a("span"),u(Ve.$$.fragment),ao=l(),sr=a("span"),so=i("Modeling"),zr=l(),K=a("div"),u(Me.$$.fragment),oo=l(),or=a("p"),lo=i("Extract a model from its distributed containers."),Hr=l(),L=a("div"),u(Ge.$$.fragment),no=l(),lr=a("p"),io=i(`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),co=l(),ze=a("ul"),nr=a("li"),po=i("a module with no direct children (just parameters and buffers)"),mo=l(),ut=a("li"),uo=i("a module whose class name is in the list "),ir=a("code"),fo=i("no_split_module_classes"),qr=l(),Q=a("div"),u(He.$$.fragment),ho=l(),cr=a("p"),vo=i("Offload a state dict in a given folder."),Fr=l(),X=a("h2"),ce=a("a"),dr=a("span"),u(qe.$$.fragment),go=l(),pr=a("span"),_o=i("Parallel"),Br=l(),Y=a("div"),u(Fe.$$.fragment),bo=l(),mr=a("p"),$o=i("Extract a model from its distributed containers."),jr=l(),Z=a("div"),u(Be.$$.fragment),yo=l(),je=a("p"),Eo=i("Save the data to disk. Use in place of "),ur=a("code"),xo=i("torch.save()"),wo=i("."),Wr=l(),N=a("div"),u(We.$$.fragment),Do=l(),fr=a("p"),To=i("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),Po=l(),u(de.$$.fragment),Jr=l(),ee=a("h2"),pe=a("a"),hr=a("span"),u(Je.$$.fragment),Lo=l(),vr=a("span"),No=i("Random"),Kr=l(),te=a("div"),u(Ke.$$.fragment),ko=l(),k=a("p"),Co=i("Helper function for reproducible behavior to set the seed in "),gr=a("code"),Uo=i("random"),Io=i(", "),_r=a("code"),So=i("numpy"),Oo=i(", "),br=a("code"),Ro=i("torch"),Ao=i("."),Qr=l(),Qe=a("div"),u(Xe.$$.fragment),Xr=l(),Ye=a("div"),u(Ze.$$.fragment),this.h()},l(e){const d=fn('[data-svelte="svelte-1phssyn"]',document.head);$=s(d,"META",{name:!0,content:!0}),d.forEach(r),re=n(e),y=s(e,"H1",{class:!0});var et=o(y);E=s(et,"A",{id:!0,class:!0,href:!0});var Xo=o(E);gt=s(Xo,"SPAN",{});var Yo=o(gt);f(_e.$$.fragment,Yo),Yo.forEach(r),Xo.forEach(r),Ta=n(et),_t=s(et,"SPAN",{});var Zo=o(_t);Pa=c(Zo,"Helpful Utilities"),Zo.forEach(r),et.forEach(r),yr=n(e),U=s(e,"H2",{class:!0});var Zr=o(U);ae=s(Zr,"A",{id:!0,class:!0,href:!0});var el=o(ae);bt=s(el,"SPAN",{});var tl=o(bt);f(be.$$.fragment,tl),tl.forEach(r),el.forEach(r),La=n(Zr),$t=s(Zr,"SPAN",{});var rl=o($t);Na=c(rl,"Data Classes"),rl.forEach(r),Zr.forEach(r),Er=n(e),x=s(e,"DIV",{class:!0});var me=o(x);f($e.$$.fragment,me),ka=n(me),yt=s(me,"P",{});var al=o(yt);Ca=c(al,"Represents a type of distributed environment."),al.forEach(r),Ua=n(me),Et=s(me,"P",{});var sl=o(Et);Ia=c(sl,"Values:"),sl.forEach(r),Sa=n(me),w=s(me,"UL",{});var C=o(w);tt=s(C,"LI",{});var Vo=o(tt);xt=s(Vo,"STRONG",{});var ol=o(xt);Oa=c(ol,"NO"),ol.forEach(r),Ra=c(Vo," \u2014 Not a distributed environment, just a single process."),Vo.forEach(r),Aa=n(C),rt=s(C,"LI",{});var Mo=o(rt);wt=s(Mo,"STRONG",{});var ll=o(wt);Va=c(ll,"MULTI_CPU"),ll.forEach(r),Ma=c(Mo," \u2014 Distributed on multiple CPU nodes."),Mo.forEach(r),Ga=n(C),at=s(C,"LI",{});var Go=o(at);Dt=s(Go,"STRONG",{});var nl=o(Dt);za=c(nl,"MULTI_GPU"),nl.forEach(r),Ha=c(Go," \u2014 Distributed on multiple GPUs."),Go.forEach(r),qa=n(C),st=s(C,"LI",{});var zo=o(st);Tt=s(zo,"STRONG",{});var il=o(Tt);Fa=c(il,"DEEPSPEED"),il.forEach(r),Ba=c(zo," \u2014 Using DeepSpeed."),zo.forEach(r),ja=n(C),ot=s(C,"LI",{});var Ho=o(ot);Pt=s(Ho,"STRONG",{});var cl=o(Pt);Wa=c(cl,"TPU"),cl.forEach(r),Ja=c(Ho," \u2014 Distributed on TPUs."),Ho.forEach(r),C.forEach(r),me.forEach(r),xr=n(e),D=s(e,"DIV",{class:!0});var ue=o(D);f(ye.$$.fragment,ue),Ka=n(ue),Lt=s(ue,"P",{});var dl=o(Lt);Qa=c(dl,"Represents a type of supported experiment tracker"),dl.forEach(r),Xa=n(ue),Nt=s(ue,"P",{});var pl=o(Nt);Ya=c(pl,"Values:"),pl.forEach(r),Za=n(ue),P=s(ue,"UL",{});var fe=o(P);lt=s(fe,"LI",{});var qo=o(lt);kt=s(qo,"STRONG",{});var ml=o(kt);es=c(ml,"ALL"),ml.forEach(r),ts=c(qo," \u2014 all available trackers in the environment that are supported"),qo.forEach(r),rs=n(fe),nt=s(fe,"LI",{});var Fo=o(nt);Ct=s(Fo,"STRONG",{});var ul=o(Ct);as=c(ul,"TENSORBOARD"),ul.forEach(r),ss=c(Fo," \u2014 TensorBoard as an experiment tracker"),Fo.forEach(r),os=n(fe),it=s(fe,"LI",{});var Bo=o(it);Ut=s(Bo,"STRONG",{});var fl=o(Ut);ls=c(fl,"WANDB"),fl.forEach(r),ns=c(Bo," \u2014 wandb as an experiment tracker"),Bo.forEach(r),is=n(fe),ct=s(fe,"LI",{});var jo=o(ct);It=s(jo,"STRONG",{});var hl=o(It);cs=c(hl,"COMETML"),hl.forEach(r),ds=c(jo," \u2014 comet_ml as an experiment tracker"),jo.forEach(r),fe.forEach(r),ue.forEach(r),wr=n(e),T=s(e,"DIV",{class:!0});var he=o(T);f(Ee.$$.fragment,he),ps=n(he),St=s(he,"P",{});var vl=o(St);ms=c(vl,"Represents a type of precision used on floating point values"),vl.forEach(r),us=n(he),Ot=s(he,"P",{});var gl=o(Ot);fs=c(gl,"Values:"),gl.forEach(r),hs=n(he),I=s(he,"UL",{});var ft=o(I);dt=s(ft,"LI",{});var Wo=o(dt);Rt=s(Wo,"STRONG",{});var _l=o(Rt);vs=c(_l,"NO"),_l.forEach(r),gs=c(Wo," \u2014 using full precision (FP32)"),Wo.forEach(r),_s=n(ft),pt=s(ft,"LI",{});var Jo=o(pt);At=s(Jo,"STRONG",{});var bl=o(At);bs=c(bl,"FP16"),bl.forEach(r),$s=c(Jo," \u2014 using half precision"),Jo.forEach(r),ys=n(ft),mt=s(ft,"LI",{});var Ko=o(mt);Vt=s(Ko,"STRONG",{});var $l=o(Vt);Es=c($l,"BF16"),$l.forEach(r),xs=c(Ko," \u2014 using brain floating point precision"),Ko.forEach(r),ft.forEach(r),he.forEach(r),Dr=n(e),S=s(e,"H2",{class:!0});var ea=o(S);se=s(ea,"A",{id:!0,class:!0,href:!0});var yl=o(se);Mt=s(yl,"SPAN",{});var El=o(Mt);f(xe.$$.fragment,El),El.forEach(r),yl.forEach(r),ws=n(ea),Gt=s(ea,"SPAN",{});var xl=o(Gt);Ds=c(xl,"Data Manipulation and Operations"),xl.forEach(r),ea.forEach(r),Tr=n(e),oe=s(e,"P",{});var ta=o(oe);Ts=c(ta,"These include data operations that mimic the same "),zt=s(ta,"CODE",{});var wl=o(zt);Ps=c(wl,"torch"),wl.forEach(r),Ls=c(ta," ops but can be used on distributed processes."),ta.forEach(r),Pr=n(e),O=s(e,"DIV",{class:!0});var ra=o(O);f(we.$$.fragment,ra),Ns=n(ra),Ht=s(ra,"P",{});var Dl=o(Ht);ks=c(Dl,"Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Dl.forEach(r),ra.forEach(r),Lr=n(e),R=s(e,"DIV",{class:!0});var aa=o(R);f(De.$$.fragment,aa),Cs=n(aa),qt=s(aa,"P",{});var Tl=o(qt);Us=c(Tl,"Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Tl.forEach(r),aa.forEach(r),Nr=n(e),A=s(e,"DIV",{class:!0});var sa=o(A);f(Te.$$.fragment,sa),Is=n(sa),Ft=s(sa,"P",{});var Pl=o(Ft);Ss=c(Pl,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),Pl.forEach(r),sa.forEach(r),kr=n(e),V=s(e,"DIV",{class:!0});var oa=o(V);f(Pe.$$.fragment,oa),Os=n(oa),Bt=s(oa,"P",{});var Ll=o(Bt);Rs=c(Ll,`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),Ll.forEach(r),oa.forEach(r),Cr=n(e),M=s(e,"DIV",{class:!0});var la=o(M);f(Le.$$.fragment,la),As=n(la),jt=s(la,"P",{});var Nl=o(jt);Vs=c(Nl,`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),Nl.forEach(r),la.forEach(r),Ur=n(e),G=s(e,"DIV",{class:!0});var na=o(G);f(Ne.$$.fragment,na),Ms=n(na),Wt=s(na,"P",{});var kl=o(Wt);Gs=c(kl,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),kl.forEach(r),na.forEach(r),Ir=n(e),z=s(e,"H2",{class:!0});var ia=o(z);le=s(ia,"A",{id:!0,class:!0,href:!0});var Cl=o(le);Jt=s(Cl,"SPAN",{});var Ul=o(Jt);f(ke.$$.fragment,Ul),Ul.forEach(r),Cl.forEach(r),zs=n(ia),Kt=s(ia,"SPAN",{});var Il=o(Kt);Hs=c(Il,"Environment Checks"),Il.forEach(r),ia.forEach(r),Sr=n(e),H=s(e,"DIV",{class:!0});var ca=o(H);f(Ce.$$.fragment,ca),qs=n(ca),Qt=s(ca,"P",{});var Sl=o(Qt);Fs=c(Sl,"Get the maximum memory available if nothing is passed, converts string to int otherwise."),Sl.forEach(r),ca.forEach(r),Or=n(e),q=s(e,"DIV",{class:!0});var da=o(q);f(Ue.$$.fragment,da),Bs=n(da),Xt=s(da,"P",{});var Ol=o(Xt);js=c(Ol,"Checks if bf16 is supported, optionally ignoring the TPU"),Ol.forEach(r),da.forEach(r),Rr=n(e),F=s(e,"DIV",{class:!0});var pa=o(F);f(Ie.$$.fragment,pa),Ws=n(pa),Yt=s(pa,"P",{});var Rl=o(Yt);Js=c(Rl,"Compares the current PyTorch version to a given reference with an operation."),Rl.forEach(r),pa.forEach(r),Ar=n(e),B=s(e,"DIV",{class:!0});var ma=o(B);f(Se.$$.fragment,ma),Ks=n(ma),Oe=s(ma,"P",{});var ua=o(Oe);Qs=c(ua,"Checks if "),Zt=s(ua,"CODE",{});var Al=o(Zt);Xs=c(Al,"torch_xla"),Al.forEach(r),Ys=c(ua," is installed and if a TPU is in the environment"),ua.forEach(r),ma.forEach(r),Vr=n(e),j=s(e,"H2",{class:!0});var fa=o(j);ne=s(fa,"A",{id:!0,class:!0,href:!0});var Vl=o(ne);er=s(Vl,"SPAN",{});var Ml=o(er);f(Re.$$.fragment,Ml),Ml.forEach(r),Vl.forEach(r),Zs=n(fa),tr=s(fa,"SPAN",{});var Gl=o(tr);eo=c(Gl,"Environment Configuration"),Gl.forEach(r),fa.forEach(r),Mr=n(e),W=s(e,"DIV",{class:!0});var ha=o(W);f(Ae.$$.fragment,ha),to=n(ha),rr=s(ha,"P",{});var zl=o(rr);ro=c(zl,`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),zl.forEach(r),ha.forEach(r),Gr=n(e),J=s(e,"H2",{class:!0});var va=o(J);ie=s(va,"A",{id:!0,class:!0,href:!0});var Hl=o(ie);ar=s(Hl,"SPAN",{});var ql=o(ar);f(Ve.$$.fragment,ql),ql.forEach(r),Hl.forEach(r),ao=n(va),sr=s(va,"SPAN",{});var Fl=o(sr);so=c(Fl,"Modeling"),Fl.forEach(r),va.forEach(r),zr=n(e),K=s(e,"DIV",{class:!0});var ga=o(K);f(Me.$$.fragment,ga),oo=n(ga),or=s(ga,"P",{});var Bl=o(or);lo=c(Bl,"Extract a model from its distributed containers."),Bl.forEach(r),ga.forEach(r),Hr=n(e),L=s(e,"DIV",{class:!0});var ht=o(L);f(Ge.$$.fragment,ht),no=n(ht),lr=s(ht,"P",{});var jl=o(lr);io=c(jl,`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),jl.forEach(r),co=n(ht),ze=s(ht,"UL",{});var _a=o(ze);nr=s(_a,"LI",{});var Wl=o(nr);po=c(Wl,"a module with no direct children (just parameters and buffers)"),Wl.forEach(r),mo=n(_a),ut=s(_a,"LI",{});var Qo=o(ut);uo=c(Qo,"a module whose class name is in the list "),ir=s(Qo,"CODE",{});var Jl=o(ir);fo=c(Jl,"no_split_module_classes"),Jl.forEach(r),Qo.forEach(r),_a.forEach(r),ht.forEach(r),qr=n(e),Q=s(e,"DIV",{class:!0});var ba=o(Q);f(He.$$.fragment,ba),ho=n(ba),cr=s(ba,"P",{});var Kl=o(cr);vo=c(Kl,"Offload a state dict in a given folder."),Kl.forEach(r),ba.forEach(r),Fr=n(e),X=s(e,"H2",{class:!0});var $a=o(X);ce=s($a,"A",{id:!0,class:!0,href:!0});var Ql=o(ce);dr=s(Ql,"SPAN",{});var Xl=o(dr);f(qe.$$.fragment,Xl),Xl.forEach(r),Ql.forEach(r),go=n($a),pr=s($a,"SPAN",{});var Yl=o(pr);_o=c(Yl,"Parallel"),Yl.forEach(r),$a.forEach(r),Br=n(e),Y=s(e,"DIV",{class:!0});var ya=o(Y);f(Fe.$$.fragment,ya),bo=n(ya),mr=s(ya,"P",{});var Zl=o(mr);$o=c(Zl,"Extract a model from its distributed containers."),Zl.forEach(r),ya.forEach(r),jr=n(e),Z=s(e,"DIV",{class:!0});var Ea=o(Z);f(Be.$$.fragment,Ea),yo=n(Ea),je=s(Ea,"P",{});var xa=o(je);Eo=c(xa,"Save the data to disk. Use in place of "),ur=s(xa,"CODE",{});var en=o(ur);xo=c(en,"torch.save()"),en.forEach(r),wo=c(xa,"."),xa.forEach(r),Ea.forEach(r),Wr=n(e),N=s(e,"DIV",{class:!0});var vt=o(N);f(We.$$.fragment,vt),Do=n(vt),fr=s(vt,"P",{});var tn=o(fr);To=c(tn,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),tn.forEach(r),Po=n(vt),f(de.$$.fragment,vt),vt.forEach(r),Jr=n(e),ee=s(e,"H2",{class:!0});var wa=o(ee);pe=s(wa,"A",{id:!0,class:!0,href:!0});var rn=o(pe);hr=s(rn,"SPAN",{});var an=o(hr);f(Je.$$.fragment,an),an.forEach(r),rn.forEach(r),Lo=n(wa),vr=s(wa,"SPAN",{});var sn=o(vr);No=c(sn,"Random"),sn.forEach(r),wa.forEach(r),Kr=n(e),te=s(e,"DIV",{class:!0});var Da=o(te);f(Ke.$$.fragment,Da),ko=n(Da),k=s(Da,"P",{});var ve=o(k);Co=c(ve,"Helper function for reproducible behavior to set the seed in "),gr=s(ve,"CODE",{});var on=o(gr);Uo=c(on,"random"),on.forEach(r),Io=c(ve,", "),_r=s(ve,"CODE",{});var ln=o(_r);So=c(ln,"numpy"),ln.forEach(r),Oo=c(ve,", "),br=s(ve,"CODE",{});var nn=o(br);Ro=c(nn,"torch"),nn.forEach(r),Ao=c(ve,"."),ve.forEach(r),Da.forEach(r),Qr=n(e),Qe=s(e,"DIV",{class:!0});var cn=o(Qe);f(Xe.$$.fragment,cn),cn.forEach(r),Xr=n(e),Ye=s(e,"DIV",{class:!0});var dn=o(Ye);f(Ze.$$.fragment,dn),dn.forEach(r),this.h()},h(){m($,"name","hf:doc:metadata"),m($,"content",JSON.stringify(bn)),m(E,"id","helpful-utilities"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#helpful-utilities"),m(y,"class","relative group"),m(ae,"id","accelerate.DistributedType"),m(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ae,"href","#accelerate.DistributedType"),m(U,"class","relative group"),m(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(se,"id","accelerate.utils.broadcast"),m(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(se,"href","#accelerate.utils.broadcast"),m(S,"class","relative group"),m(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(le,"id","accelerate.utils.get_max_memory"),m(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(le,"href","#accelerate.utils.get_max_memory"),m(z,"class","relative group"),m(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ne,"id","accelerate.utils.write_basic_config"),m(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ne,"href","#accelerate.utils.write_basic_config"),m(j,"class","relative group"),m(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ie,"id","accelerate.utils.extract_model_from_parallel"),m(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ie,"href","#accelerate.utils.extract_model_from_parallel"),m(J,"class","relative group"),m(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ce,"id","accelerate.utils.extract_model_from_parallel"),m(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ce,"href","#accelerate.utils.extract_model_from_parallel"),m(X,"class","relative group"),m(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pe,"id","accelerate.utils.set_seed"),m(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(pe,"href","#accelerate.utils.set_seed"),m(ee,"class","relative group"),m(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,d){t(document.head,$),p(e,re,d),p(e,y,d),t(y,E),t(E,gt),h(_e,gt,null),t(y,Ta),t(y,_t),t(_t,Pa),p(e,yr,d),p(e,U,d),t(U,ae),t(ae,bt),h(be,bt,null),t(U,La),t(U,$t),t($t,Na),p(e,Er,d),p(e,x,d),h($e,x,null),t(x,ka),t(x,yt),t(yt,Ca),t(x,Ua),t(x,Et),t(Et,Ia),t(x,Sa),t(x,w),t(w,tt),t(tt,xt),t(xt,Oa),t(tt,Ra),t(w,Aa),t(w,rt),t(rt,wt),t(wt,Va),t(rt,Ma),t(w,Ga),t(w,at),t(at,Dt),t(Dt,za),t(at,Ha),t(w,qa),t(w,st),t(st,Tt),t(Tt,Fa),t(st,Ba),t(w,ja),t(w,ot),t(ot,Pt),t(Pt,Wa),t(ot,Ja),p(e,xr,d),p(e,D,d),h(ye,D,null),t(D,Ka),t(D,Lt),t(Lt,Qa),t(D,Xa),t(D,Nt),t(Nt,Ya),t(D,Za),t(D,P),t(P,lt),t(lt,kt),t(kt,es),t(lt,ts),t(P,rs),t(P,nt),t(nt,Ct),t(Ct,as),t(nt,ss),t(P,os),t(P,it),t(it,Ut),t(Ut,ls),t(it,ns),t(P,is),t(P,ct),t(ct,It),t(It,cs),t(ct,ds),p(e,wr,d),p(e,T,d),h(Ee,T,null),t(T,ps),t(T,St),t(St,ms),t(T,us),t(T,Ot),t(Ot,fs),t(T,hs),t(T,I),t(I,dt),t(dt,Rt),t(Rt,vs),t(dt,gs),t(I,_s),t(I,pt),t(pt,At),t(At,bs),t(pt,$s),t(I,ys),t(I,mt),t(mt,Vt),t(Vt,Es),t(mt,xs),p(e,Dr,d),p(e,S,d),t(S,se),t(se,Mt),h(xe,Mt,null),t(S,ws),t(S,Gt),t(Gt,Ds),p(e,Tr,d),p(e,oe,d),t(oe,Ts),t(oe,zt),t(zt,Ps),t(oe,Ls),p(e,Pr,d),p(e,O,d),h(we,O,null),t(O,Ns),t(O,Ht),t(Ht,ks),p(e,Lr,d),p(e,R,d),h(De,R,null),t(R,Cs),t(R,qt),t(qt,Us),p(e,Nr,d),p(e,A,d),h(Te,A,null),t(A,Is),t(A,Ft),t(Ft,Ss),p(e,kr,d),p(e,V,d),h(Pe,V,null),t(V,Os),t(V,Bt),t(Bt,Rs),p(e,Cr,d),p(e,M,d),h(Le,M,null),t(M,As),t(M,jt),t(jt,Vs),p(e,Ur,d),p(e,G,d),h(Ne,G,null),t(G,Ms),t(G,Wt),t(Wt,Gs),p(e,Ir,d),p(e,z,d),t(z,le),t(le,Jt),h(ke,Jt,null),t(z,zs),t(z,Kt),t(Kt,Hs),p(e,Sr,d),p(e,H,d),h(Ce,H,null),t(H,qs),t(H,Qt),t(Qt,Fs),p(e,Or,d),p(e,q,d),h(Ue,q,null),t(q,Bs),t(q,Xt),t(Xt,js),p(e,Rr,d),p(e,F,d),h(Ie,F,null),t(F,Ws),t(F,Yt),t(Yt,Js),p(e,Ar,d),p(e,B,d),h(Se,B,null),t(B,Ks),t(B,Oe),t(Oe,Qs),t(Oe,Zt),t(Zt,Xs),t(Oe,Ys),p(e,Vr,d),p(e,j,d),t(j,ne),t(ne,er),h(Re,er,null),t(j,Zs),t(j,tr),t(tr,eo),p(e,Mr,d),p(e,W,d),h(Ae,W,null),t(W,to),t(W,rr),t(rr,ro),p(e,Gr,d),p(e,J,d),t(J,ie),t(ie,ar),h(Ve,ar,null),t(J,ao),t(J,sr),t(sr,so),p(e,zr,d),p(e,K,d),h(Me,K,null),t(K,oo),t(K,or),t(or,lo),p(e,Hr,d),p(e,L,d),h(Ge,L,null),t(L,no),t(L,lr),t(lr,io),t(L,co),t(L,ze),t(ze,nr),t(nr,po),t(ze,mo),t(ze,ut),t(ut,uo),t(ut,ir),t(ir,fo),p(e,qr,d),p(e,Q,d),h(He,Q,null),t(Q,ho),t(Q,cr),t(cr,vo),p(e,Fr,d),p(e,X,d),t(X,ce),t(ce,dr),h(qe,dr,null),t(X,go),t(X,pr),t(pr,_o),p(e,Br,d),p(e,Y,d),h(Fe,Y,null),t(Y,bo),t(Y,mr),t(mr,$o),p(e,jr,d),p(e,Z,d),h(Be,Z,null),t(Z,yo),t(Z,je),t(je,Eo),t(je,ur),t(ur,xo),t(je,wo),p(e,Wr,d),p(e,N,d),h(We,N,null),t(N,Do),t(N,fr),t(fr,To),t(N,Po),h(de,N,null),p(e,Jr,d),p(e,ee,d),t(ee,pe),t(pe,hr),h(Je,hr,null),t(ee,Lo),t(ee,vr),t(vr,No),p(e,Kr,d),p(e,te,d),h(Ke,te,null),t(te,ko),t(te,k),t(k,Co),t(k,gr),t(gr,Uo),t(k,Io),t(k,_r),t(_r,So),t(k,Oo),t(k,br),t(br,Ro),t(k,Ao),p(e,Qr,d),p(e,Qe,d),h(Xe,Qe,null),p(e,Xr,d),p(e,Ye,d),h(Ze,Ye,null),Yr=!0},p(e,[d]){const et={};d&2&&(et.$$scope={dirty:d,ctx:e}),de.$set(et)},i(e){Yr||(v(_e.$$.fragment,e),v(be.$$.fragment,e),v($e.$$.fragment,e),v(ye.$$.fragment,e),v(Ee.$$.fragment,e),v(xe.$$.fragment,e),v(we.$$.fragment,e),v(De.$$.fragment,e),v(Te.$$.fragment,e),v(Pe.$$.fragment,e),v(Le.$$.fragment,e),v(Ne.$$.fragment,e),v(ke.$$.fragment,e),v(Ce.$$.fragment,e),v(Ue.$$.fragment,e),v(Ie.$$.fragment,e),v(Se.$$.fragment,e),v(Re.$$.fragment,e),v(Ae.$$.fragment,e),v(Ve.$$.fragment,e),v(Me.$$.fragment,e),v(Ge.$$.fragment,e),v(He.$$.fragment,e),v(qe.$$.fragment,e),v(Fe.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(de.$$.fragment,e),v(Je.$$.fragment,e),v(Ke.$$.fragment,e),v(Xe.$$.fragment,e),v(Ze.$$.fragment,e),Yr=!0)},o(e){g(_e.$$.fragment,e),g(be.$$.fragment,e),g($e.$$.fragment,e),g(ye.$$.fragment,e),g(Ee.$$.fragment,e),g(xe.$$.fragment,e),g(we.$$.fragment,e),g(De.$$.fragment,e),g(Te.$$.fragment,e),g(Pe.$$.fragment,e),g(Le.$$.fragment,e),g(Ne.$$.fragment,e),g(ke.$$.fragment,e),g(Ce.$$.fragment,e),g(Ue.$$.fragment,e),g(Ie.$$.fragment,e),g(Se.$$.fragment,e),g(Re.$$.fragment,e),g(Ae.$$.fragment,e),g(Ve.$$.fragment,e),g(Me.$$.fragment,e),g(Ge.$$.fragment,e),g(He.$$.fragment,e),g(qe.$$.fragment,e),g(Fe.$$.fragment,e),g(Be.$$.fragment,e),g(We.$$.fragment,e),g(de.$$.fragment,e),g(Je.$$.fragment,e),g(Ke.$$.fragment,e),g(Xe.$$.fragment,e),g(Ze.$$.fragment,e),Yr=!1},d(e){r($),e&&r(re),e&&r(y),_(_e),e&&r(yr),e&&r(U),_(be),e&&r(Er),e&&r(x),_($e),e&&r(xr),e&&r(D),_(ye),e&&r(wr),e&&r(T),_(Ee),e&&r(Dr),e&&r(S),_(xe),e&&r(Tr),e&&r(oe),e&&r(Pr),e&&r(O),_(we),e&&r(Lr),e&&r(R),_(De),e&&r(Nr),e&&r(A),_(Te),e&&r(kr),e&&r(V),_(Pe),e&&r(Cr),e&&r(M),_(Le),e&&r(Ur),e&&r(G),_(Ne),e&&r(Ir),e&&r(z),_(ke),e&&r(Sr),e&&r(H),_(Ce),e&&r(Or),e&&r(q),_(Ue),e&&r(Rr),e&&r(F),_(Ie),e&&r(Ar),e&&r(B),_(Se),e&&r(Vr),e&&r(j),_(Re),e&&r(Mr),e&&r(W),_(Ae),e&&r(Gr),e&&r(J),_(Ve),e&&r(zr),e&&r(K),_(Me),e&&r(Hr),e&&r(L),_(Ge),e&&r(qr),e&&r(Q),_(He),e&&r(Fr),e&&r(X),_(qe),e&&r(Br),e&&r(Y),_(Fe),e&&r(jr),e&&r(Z),_(Be),e&&r(Wr),e&&r(N),_(We),_(de),e&&r(Jr),e&&r(ee),_(Je),e&&r(Kr),e&&r(te),_(Ke),e&&r(Qr),e&&r(Qe),_(Xe),e&&r(Xr),e&&r(Ye),_(Ze)}}}const bn={local:"helpful-utilities",sections:[{local:"accelerate.DistributedType",title:"Data Classes"},{local:"accelerate.utils.broadcast",title:"Data Manipulation and Operations"},{local:"accelerate.utils.get_max_memory",title:"Environment Checks"},{local:"accelerate.utils.write_basic_config",title:"Environment Configuration"},{local:"accelerate.utils.extract_model_from_parallel",title:"Modeling"},{local:"accelerate.utils.extract_model_from_parallel",title:"Parallel"},{local:"accelerate.utils.set_seed",title:"Random"}],title:"Helpful Utilities"};function $n($r){return hn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Dn extends pn{constructor($){super();mn(this,$,$n,_n,un,{})}}export{Dn as default,bn as metadata};
