import{S as fe,i as me,s as de,e as i,k as L,w as Z,t as u,M as ge,c as l,d as t,m as U,a as c,x as ee,h,b as s,G as o,g,y as te,q as oe,o as ne,B as ae,v as be}from"../chunks/vendor-hf-doc-builder.js";import{T as _e}from"../chunks/Tip-hf-doc-builder.js";import{D as ve}from"../chunks/Docstring-hf-doc-builder.js";import{I as we}from"../chunks/IconCopyLink-hf-doc-builder.js";function $e(N){let n,w,r,f,b;return{c(){n=i("p"),w=u("Your "),r=i("code"),f=u("Accelerator"),b=u(` object should only be defined inside the training function. This is because the
initialization should be done inside the launcher only.`)},l(p){n=l(p,"P",{});var m=c(n);w=h(m,"Your "),r=l(m,"CODE",{});var $=c(r);f=h($,"Accelerator"),$.forEach(t),b=h(m,` object should only be defined inside the training function. This is because the
initialization should be done inside the launcher only.`),m.forEach(t)},m(p,m){g(p,n,m),o(n,w),o(n,r),o(r,f),o(n,b)},d(p){p&&t(n)}}}function ke(N){let n,w,r,f,b,p,m,$,z,S,d,O,y,Y,B,x,F,H,D,_,J,P,R,V,E,W,I,k,K,v,T,Q,G,X,M;return p=new we({}),k=new _e({props:{warning:!0,$$slots:{default:[$e]},$$scope:{ctx:N}}}),T=new ve({props:{name:"accelerate.notebook_launcher",anchor:"accelerate.notebook_launcher",parameters:[{name:"function",val:""},{name:"args",val:" = ()"},{name:"num_processes",val:" = None"},{name:"use_fp16",val:" = False"},{name:"mixed_precision",val:" = 'no'"},{name:"use_port",val:" = '29500'"}],parametersDescription:[{anchor:"accelerate.notebook_launcher.function",description:`<strong>function</strong> (<code>Callable</code>) &#x2014;
The training function to execute. If it accepts arguments, the first argument should be the index of the
process run.`,name:"function"},{anchor:"accelerate.notebook_launcher.args",description:`<strong>args</strong> (<code>Tuple</code>) &#x2014;
Tuple of arguments to pass to the function (it will receive <code>*args</code>).`,name:"args"},{anchor:"accelerate.notebook_launcher.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The number of processes to use for training. Will default to 8 in Colab/Kaggle if a TPU is available, to
the number of GPUs available otherwise.`,name:"num_processes"},{anchor:"accelerate.notebook_launcher.mixed_precision",description:`<strong>mixed_precision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;no&quot;</code>) &#x2014;
If <code>fp16</code> or <code>bf16</code>, will use mixed precision training on multi-GPU.`,name:"mixed_precision"},{anchor:"accelerate.notebook_launcher.use_port",description:`<strong>use_port</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;29500&quot;</code>) &#x2014;
The port to use to communicate between processes when launching a multi-GPU training.`,name:"use_port"}],source:"https://github.com/huggingface/accelerate/blob/vr_386/src/accelerate/launchers.py#L28"}}),{c(){n=i("meta"),w=L(),r=i("h1"),f=i("a"),b=i("span"),Z(p.$$.fragment),m=L(),$=i("span"),z=u("Notebook Launcher"),S=L(),d=i("p"),O=u("Launch your training function inside a notebook. Currently supports launching a training with TPUs on "),y=i("a"),Y=u(`Google
Colab`),B=u(" and "),x=i("a"),F=u("Kaggle kernels"),H=u(`, as well as training on
several GPUs (if the machine on which you are running your notebook has them).`),D=L(),_=i("p"),J=u("An example can be found in "),P=i("a"),R=u("this notebook"),V=u(`,
as well as `),E=i("a"),W=u("this notebook"),I=L(),Z(k.$$.fragment),K=L(),v=i("div"),Z(T.$$.fragment),Q=L(),G=i("p"),X=u(`Launches a training function, using several processes if it\u2019s possible in the current environment (TPU with
multiple cores for instance).`),this.h()},l(e){const a=ge('[data-svelte="svelte-1phssyn"]',document.head);n=l(a,"META",{name:!0,content:!0}),a.forEach(t),w=U(e),r=l(e,"H1",{class:!0});var A=c(r);f=l(A,"A",{id:!0,class:!0,href:!0});var re=c(f);b=l(re,"SPAN",{});var se=c(b);ee(p.$$.fragment,se),se.forEach(t),re.forEach(t),m=U(A),$=l(A,"SPAN",{});var ie=c($);z=h(ie,"Notebook Launcher"),ie.forEach(t),A.forEach(t),S=U(e),d=l(e,"P",{});var C=c(d);O=h(C,"Launch your training function inside a notebook. Currently supports launching a training with TPUs on "),y=l(C,"A",{href:!0,rel:!0});var le=c(y);Y=h(le,`Google
Colab`),le.forEach(t),B=h(C," and "),x=l(C,"A",{href:!0,rel:!0});var ce=c(x);F=h(ce,"Kaggle kernels"),ce.forEach(t),H=h(C,`, as well as training on
several GPUs (if the machine on which you are running your notebook has them).`),C.forEach(t),D=U(e),_=l(e,"P",{});var q=c(_);J=h(q,"An example can be found in "),P=l(q,"A",{href:!0,rel:!0});var ue=c(P);R=h(ue,"this notebook"),ue.forEach(t),V=h(q,`,
as well as `),E=l(q,"A",{href:!0,rel:!0});var he=c(E);W=h(he,"this notebook"),he.forEach(t),q.forEach(t),I=U(e),ee(k.$$.fragment,e),K=U(e),v=l(e,"DIV",{class:!0});var j=c(v);ee(T.$$.fragment,j),Q=U(j),G=l(j,"P",{});var pe=c(G);X=h(pe,`Launches a training function, using several processes if it\u2019s possible in the current environment (TPU with
multiple cores for instance).`),pe.forEach(t),j.forEach(t),this.h()},h(){s(n,"name","hf:doc:metadata"),s(n,"content",JSON.stringify(ye)),s(f,"id","accelerate.notebook_launcher"),s(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(f,"href","#accelerate.notebook_launcher"),s(r,"class","relative group"),s(y,"href","https://colab.research.google.com/"),s(y,"rel","nofollow"),s(x,"href","https://www.kaggle.com/code"),s(x,"rel","nofollow"),s(P,"href","https://github.com/huggingface/notebooks/blob/master/examples/accelerate/simple_nlp_example.ipynb"),s(P,"rel","nofollow"),s(E,"href","https://github.com/huggingface/accelerate/blob/master/main/examples/from_notebook.ipynb"),s(E,"rel","nofollow"),s(v,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,a){o(document.head,n),g(e,w,a),g(e,r,a),o(r,f),o(f,b),te(p,b,null),o(r,m),o(r,$),o($,z),g(e,S,a),g(e,d,a),o(d,O),o(d,y),o(y,Y),o(d,B),o(d,x),o(x,F),o(d,H),g(e,D,a),g(e,_,a),o(_,J),o(_,P),o(P,R),o(_,V),o(_,E),o(E,W),g(e,I,a),te(k,e,a),g(e,K,a),g(e,v,a),te(T,v,null),o(v,Q),o(v,G),o(G,X),M=!0},p(e,[a]){const A={};a&2&&(A.$$scope={dirty:a,ctx:e}),k.$set(A)},i(e){M||(oe(p.$$.fragment,e),oe(k.$$.fragment,e),oe(T.$$.fragment,e),M=!0)},o(e){ne(p.$$.fragment,e),ne(k.$$.fragment,e),ne(T.$$.fragment,e),M=!1},d(e){t(n),e&&t(w),e&&t(r),ae(p),e&&t(S),e&&t(d),e&&t(D),e&&t(_),e&&t(I),ae(k,e),e&&t(K),e&&t(v),ae(T)}}}const ye={local:"accelerate.notebook_launcher",title:"Notebook Launcher"};function xe(N){return be(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Le extends fe{constructor(n){super();me(this,n,xe,ke,de,{})}}export{Le as default,ye as metadata};
