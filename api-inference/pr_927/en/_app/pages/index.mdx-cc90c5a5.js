import{S as La,i as Na,s as Ga,e as a,k as f,w as Ee,t as n,M as Ra,c as o,d as r,m as h,a as l,x as be,h as i,b as s,N as Mr,f as It,F as e,g as c,y as $e,q as Pe,o as Ae,B as ke,v as Ha}from"../chunks/vendor-7c454903.js";import{T as Ua}from"../chunks/Tip-735285fc.js";import{I as Ge}from"../chunks/IconCopyLink-5457534b.js";function Ca(tt){let m,U,g,E,x,b,w,k,X,C,$,Y,q,y,P;return{c(){m=a("p"),U=n("Please note however, that these models will not allow you ("),g=a("a"),E=n("tracking issue"),x=n("):"),b=f(),w=a("ul"),k=a("li"),X=n("To get full optimization"),C=f(),$=a("li"),Y=n("To run private models"),q=f(),y=a("li"),P=n("To get access to GPU inference"),this.h()},l(v){m=o(v,"P",{});var _=l(m);U=i(_,"Please note however, that these models will not allow you ("),g=o(_,"A",{href:!0,rel:!0});var Ie=l(g);E=i(Ie,"tracking issue"),Ie.forEach(r),x=i(_,"):"),_.forEach(r),b=h(v),w=o(v,"UL",{});var A=l(w);k=o(A,"LI",{});var Te=l(k);X=i(Te,"To get full optimization"),Te.forEach(r),C=h(A),$=o(A,"LI",{});var Z=l($);Y=i(Z,"To run private models"),Z.forEach(r),q=h(A),y=o(A,"LI",{});var I=l(y);P=i(I,"To get access to GPU inference"),I.forEach(r),A.forEach(r),this.h()},h(){s(g,"href","https://github.com/huggingface/huggingface_hub/issues/85"),s(g,"rel","nofollow")},m(v,_){c(v,m,_),e(m,U),e(m,g),e(g,E),e(m,x),c(v,b,_),c(v,w,_),e(w,k),e(k,X),e(w,C),e(w,$),e($,Y),e(w,q),e(w,y),e(y,P)},d(v){v&&r(m),v&&r(b),v&&r(w)}}}function qa(tt){let m,U,g,E,x,b,w,k,X,C,$,Y,q,y,P,v,_,Ie,A,Te,Z,I,Fr,rt,B,zr,at,L,O,Re,ee,Tt,He,St,ot,p,te,xt,Ue,Lt,Nt,Gt,Se,Rt,Ce,Ht,Ut,qe,Ct,qt,re,Bt,Be,Ot,Mt,Ft,T,zt,Oe,jt,Qt,Me,Jt,Dt,ae,Kt,Vt,Wt,oe,Xt,Fe,Yt,Zt,er,le,tr,ze,rr,ar,or,xe,je,lr,nr,ir,Qe,sr,lt,N,M,Je,ne,fr,De,hr,nt,F,S,jr,it,G,z,Ke,ie,ur,Ve,cr,st,j,se,fe,pr,he,mr,dr,gr,R,Q,ue,vr,_r,ce,yr,wr,Er,Le,pe,br,$r,Pr,J,me,Ar,kr,de,Ir,Tr,Sr,We,ge,xr,ve,Lr,Nr,ft,D,ht,H,K,Xe,_e,Gr,Ye,Rr,ut,V,Hr,ye,Ur,Cr,ct;return b=new Ge({}),_=new Ge({}),ee=new Ge({}),ne=new Ge({}),ie=new Ge({}),D=new Ua({props:{warning:!0,$$slots:{default:[Ca]},$$scope:{ctx:tt}}}),_e=new Ge({}),{c(){m=a("meta"),U=f(),g=a("h1"),E=a("a"),x=a("span"),Ee(b.$$.fragment),w=f(),k=a("span"),X=n("\u{1F917} Accelerated Inference API"),C=f(),$=a("p"),Y=n(`Integrate into your apps over 20,000 pre-trained state of the art
models, or your own private models, via simple HTTP requests, with 2x to
10x faster inference than out of the box deployment, and scalability
built-in.`),q=f(),y=a("h2"),P=a("a"),v=a("span"),Ee(_.$$.fragment),Ie=f(),A=a("span"),Te=n("Hugging Face is trusted in production by over 5,000 companies"),Z=f(),I=a("img"),rt=f(),B=a("img"),at=f(),L=a("h2"),O=a("a"),Re=a("span"),Ee(ee.$$.fragment),Tt=f(),He=a("span"),St=n("Main features:"),ot=f(),p=a("ul"),te=a("li"),xt=n("Leverage "),Ue=a("strong"),Lt=n("20,000+ Transformer models"),Nt=n(" (T5, Blenderbot, Bart, GPT-2, Pegasus...)"),Gt=f(),Se=a("li"),Rt=n("Upload, manage and serve your "),Ce=a("strong"),Ht=n("own models privately"),Ut=f(),qe=a("li"),Ct=n("Run Classification, NER, Conversational, Summarization, Translation, Question-Answering, Embeddings Extraction tasks"),qt=f(),re=a("li"),Bt=n("Get up to "),Be=a("strong"),Ot=n("10x inference speedup"),Mt=n(" to reduce user latency"),Ft=f(),T=a("li"),zt=n("Accelerated inference on "),Oe=a("strong"),jt=n("CPU"),Qt=n(" and "),Me=a("strong"),Jt=n("GPU"),Dt=n(" (GPU requires a "),ae=a("a"),Kt=n("Startup or Enterprise plan"),Vt=n(")"),Wt=f(),oe=a("li"),Xt=n("Run "),Fe=a("strong"),Yt=n("large models"),Zt=n(" that are challenging to deploy in production"),er=f(),le=a("li"),tr=n("Scale to 1,000 requests per second with "),ze=a("strong"),rr=n("automatic scaling"),ar=n(" built-in"),or=f(),xe=a("li"),je=a("strong"),lr=n("Ship new NLP features faster"),nr=n(" as new models become available"),ir=f(),Qe=a("li"),sr=n("Build your business on a platform powered by the reference open source project in NLP"),lt=f(),N=a("h2"),M=a("a"),Je=a("span"),Ee(ne.$$.fragment),fr=f(),De=a("span"),hr=n("If you are looking for custom support from the Hugging Face team"),nt=f(),F=a("a"),S=a("img"),it=f(),G=a("h2"),z=a("a"),Ke=a("span"),Ee(ie.$$.fragment),ur=f(),Ve=a("span"),cr=n("Third-party library models:"),st=f(),j=a("ul"),se=a("li"),fe=a("p"),pr=n("The "),he=a("a"),mr=n("Hub"),dr=n(" now supports many new libraries:"),gr=f(),R=a("ul"),Q=a("li"),ue=a("a"),vr=n("SpaCy"),_r=n(", "),ce=a("a"),yr=n("AllenNLP"),wr=n(","),Er=f(),Le=a("li"),pe=a("a"),br=n("Speechbrain"),$r=n(","),Pr=f(),J=a("li"),me=a("a"),Ar=n("Timm"),kr=n(" and "),de=a("a"),Ir=n("many others"),Tr=n("\u2026"),Sr=f(),We=a("li"),ge=a("p"),xr=n("Those models are enabled on the API thanks to some docker integration "),ve=a("a"),Lr=n("api-inference-community"),Nr=n("."),ft=f(),Ee(D.$$.fragment),ht=f(),H=a("h2"),K=a("a"),Xe=a("span"),Ee(_e.$$.fragment),Gr=f(),Ye=a("span"),Rr=n("Community models:"),ut=f(),V=a("p"),Hr=n("Because community models are using external libraries, these are not currently supported by Inference API at this point in time. Please take a look at "),ye=a("a"),Ur=n("https://github.com/huggingface/api-inference-community/"),Cr=n(" for further definition and inference of community models."),this.h()},l(t){const u=Ra('[data-svelte="svelte-1phssyn"]',document.head);m=o(u,"META",{name:!0,content:!0}),u.forEach(r),U=h(t),g=o(t,"H1",{class:!0});var we=l(g);E=o(we,"A",{id:!0,class:!0,href:!0});var Qr=l(E);x=o(Qr,"SPAN",{});var Jr=l(x);be(b.$$.fragment,Jr),Jr.forEach(r),Qr.forEach(r),w=h(we),k=o(we,"SPAN",{});var Dr=l(k);X=i(Dr,"\u{1F917} Accelerated Inference API"),Dr.forEach(r),we.forEach(r),C=h(t),$=o(t,"P",{});var Kr=l($);Y=i(Kr,`Integrate into your apps over 20,000 pre-trained state of the art
models, or your own private models, via simple HTTP requests, with 2x to
10x faster inference than out of the box deployment, and scalability
built-in.`),Kr.forEach(r),q=h(t),y=o(t,"H2",{class:!0});var pt=l(y);P=o(pt,"A",{id:!0,class:!0,href:!0});var Vr=l(P);v=o(Vr,"SPAN",{});var Wr=l(v);be(_.$$.fragment,Wr),Wr.forEach(r),Vr.forEach(r),Ie=h(pt),A=o(pt,"SPAN",{});var Xr=l(A);Te=i(Xr,"Hugging Face is trusted in production by over 5,000 companies"),Xr.forEach(r),pt.forEach(r),Z=h(t),I=o(t,"IMG",{class:!0,src:!0,width:!0}),rt=h(t),B=o(t,"IMG",{class:!0,src:!0,width:!0}),at=h(t),L=o(t,"H2",{class:!0});var mt=l(L);O=o(mt,"A",{id:!0,class:!0,href:!0});var Yr=l(O);Re=o(Yr,"SPAN",{});var Zr=l(Re);be(ee.$$.fragment,Zr),Zr.forEach(r),Yr.forEach(r),Tt=h(mt),He=o(mt,"SPAN",{});var ea=l(He);St=i(ea,"Main features:"),ea.forEach(r),mt.forEach(r),ot=h(t),p=o(t,"UL",{});var d=l(p);te=o(d,"LI",{});var dt=l(te);xt=i(dt,"Leverage "),Ue=o(dt,"STRONG",{});var ta=l(Ue);Lt=i(ta,"20,000+ Transformer models"),ta.forEach(r),Nt=i(dt," (T5, Blenderbot, Bart, GPT-2, Pegasus...)"),dt.forEach(r),Gt=h(d),Se=o(d,"LI",{});var qr=l(Se);Rt=i(qr,"Upload, manage and serve your "),Ce=o(qr,"STRONG",{});var ra=l(Ce);Ht=i(ra,"own models privately"),ra.forEach(r),qr.forEach(r),Ut=h(d),qe=o(d,"LI",{});var aa=l(qe);Ct=i(aa,"Run Classification, NER, Conversational, Summarization, Translation, Question-Answering, Embeddings Extraction tasks"),aa.forEach(r),qt=h(d),re=o(d,"LI",{});var gt=l(re);Bt=i(gt,"Get up to "),Be=o(gt,"STRONG",{});var oa=l(Be);Ot=i(oa,"10x inference speedup"),oa.forEach(r),Mt=i(gt," to reduce user latency"),gt.forEach(r),Ft=h(d),T=o(d,"LI",{});var W=l(T);zt=i(W,"Accelerated inference on "),Oe=o(W,"STRONG",{});var la=l(Oe);jt=i(la,"CPU"),la.forEach(r),Qt=i(W," and "),Me=o(W,"STRONG",{});var na=l(Me);Jt=i(na,"GPU"),na.forEach(r),Dt=i(W," (GPU requires a "),ae=o(W,"A",{href:!0,rel:!0});var ia=l(ae);Kt=i(ia,"Startup or Enterprise plan"),ia.forEach(r),Vt=i(W,")"),W.forEach(r),Wt=h(d),oe=o(d,"LI",{});var vt=l(oe);Xt=i(vt,"Run "),Fe=o(vt,"STRONG",{});var sa=l(Fe);Yt=i(sa,"large models"),sa.forEach(r),Zt=i(vt," that are challenging to deploy in production"),vt.forEach(r),er=h(d),le=o(d,"LI",{});var _t=l(le);tr=i(_t,"Scale to 1,000 requests per second with "),ze=o(_t,"STRONG",{});var fa=l(ze);rr=i(fa,"automatic scaling"),fa.forEach(r),ar=i(_t," built-in"),_t.forEach(r),or=h(d),xe=o(d,"LI",{});var Br=l(xe);je=o(Br,"STRONG",{});var ha=l(je);lr=i(ha,"Ship new NLP features faster"),ha.forEach(r),nr=i(Br," as new models become available"),Br.forEach(r),ir=h(d),Qe=o(d,"LI",{});var ua=l(Qe);sr=i(ua,"Build your business on a platform powered by the reference open source project in NLP"),ua.forEach(r),d.forEach(r),lt=h(t),N=o(t,"H2",{class:!0});var yt=l(N);M=o(yt,"A",{id:!0,class:!0,href:!0});var ca=l(M);Je=o(ca,"SPAN",{});var pa=l(Je);be(ne.$$.fragment,pa),pa.forEach(r),ca.forEach(r),fr=h(yt),De=o(yt,"SPAN",{});var ma=l(De);hr=i(ma,"If you are looking for custom support from the Hugging Face team"),ma.forEach(r),yt.forEach(r),nt=h(t),F=o(t,"A",{target:!0,href:!0});var da=l(F);S=o(da,"IMG",{alt:!0,src:!0,style:!0}),da.forEach(r),it=h(t),G=o(t,"H2",{class:!0});var wt=l(G);z=o(wt,"A",{id:!0,class:!0,href:!0});var ga=l(z);Ke=o(ga,"SPAN",{});var va=l(Ke);be(ie.$$.fragment,va),va.forEach(r),ga.forEach(r),ur=h(wt),Ve=o(wt,"SPAN",{});var _a=l(Ve);cr=i(_a,"Third-party library models:"),_a.forEach(r),wt.forEach(r),st=h(t),j=o(t,"UL",{});var Et=l(j);se=o(Et,"LI",{});var bt=l(se);fe=o(bt,"P",{});var $t=l(fe);pr=i($t,"The "),he=o($t,"A",{href:!0,rel:!0});var ya=l(he);mr=i(ya,"Hub"),ya.forEach(r),dr=i($t," now supports many new libraries:"),$t.forEach(r),gr=h(bt),R=o(bt,"UL",{});var Ne=l(R);Q=o(Ne,"LI",{});var Ze=l(Q);ue=o(Ze,"A",{href:!0,rel:!0});var wa=l(ue);vr=i(wa,"SpaCy"),wa.forEach(r),_r=i(Ze,", "),ce=o(Ze,"A",{href:!0,rel:!0});var Ea=l(ce);yr=i(Ea,"AllenNLP"),Ea.forEach(r),wr=i(Ze,","),Ze.forEach(r),Er=h(Ne),Le=o(Ne,"LI",{});var Or=l(Le);pe=o(Or,"A",{href:!0,rel:!0});var ba=l(pe);br=i(ba,"Speechbrain"),ba.forEach(r),$r=i(Or,","),Or.forEach(r),Pr=h(Ne),J=o(Ne,"LI",{});var et=l(J);me=o(et,"A",{href:!0,rel:!0});var $a=l(me);Ar=i($a,"Timm"),$a.forEach(r),kr=i(et," and "),de=o(et,"A",{href:!0,rel:!0});var Pa=l(de);Ir=i(Pa,"many others"),Pa.forEach(r),Tr=i(et,"\u2026"),et.forEach(r),Ne.forEach(r),bt.forEach(r),Sr=h(Et),We=o(Et,"LI",{});var Aa=l(We);ge=o(Aa,"P",{});var Pt=l(ge);xr=i(Pt,"Those models are enabled on the API thanks to some docker integration "),ve=o(Pt,"A",{href:!0,rel:!0});var ka=l(ve);Lr=i(ka,"api-inference-community"),ka.forEach(r),Nr=i(Pt,"."),Pt.forEach(r),Aa.forEach(r),Et.forEach(r),ft=h(t),be(D.$$.fragment,t),ht=h(t),H=o(t,"H2",{class:!0});var At=l(H);K=o(At,"A",{id:!0,class:!0,href:!0});var Ia=l(K);Xe=o(Ia,"SPAN",{});var Ta=l(Xe);be(_e.$$.fragment,Ta),Ta.forEach(r),Ia.forEach(r),Gr=h(At),Ye=o(At,"SPAN",{});var Sa=l(Ye);Rr=i(Sa,"Community models:"),Sa.forEach(r),At.forEach(r),ut=h(t),V=o(t,"P",{});var kt=l(V);Hr=i(kt,"Because community models are using external libraries, these are not currently supported by Inference API at this point in time. Please take a look at "),ye=o(kt,"A",{href:!0,rel:!0});var xa=l(ye);Ur=i(xa,"https://github.com/huggingface/api-inference-community/"),xa.forEach(r),Cr=i(kt," for further definition and inference of community models."),kt.forEach(r),this.h()},h(){s(m,"name","hf:doc:metadata"),s(m,"content",JSON.stringify(Ba)),s(E,"id","accelerated-inference-api"),s(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(E,"href","#accelerated-inference-api"),s(g,"class","relative group"),s(P,"id","hugging-face-is-trusted-in-production-by-over-5,000-companies"),s(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(P,"href","#hugging-face-is-trusted-in-production-by-over-5,000-companies"),s(y,"class","relative group"),s(I,"class","block dark:hidden !shadow-none !border-0 !rounded-none"),Mr(I.src,Fr="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/inference-api/companies-light.png")||s(I,"src",Fr),s(I,"width","600"),s(B,"class","hidden dark:block !shadow-none !border-0 !rounded-none"),Mr(B.src,zr="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/inference-api/companies-dark.png")||s(B,"src",zr),s(B,"width","600"),s(O,"id","main-features:"),s(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(O,"href","#main-features:"),s(L,"class","relative group"),s(ae,"href","https://huggingface.co/pricing"),s(ae,"rel","nofollow"),s(M,"id","if-you-are-looking-for-custom-support-from-the-hugging-face-team"),s(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(M,"href","#if-you-are-looking-for-custom-support-from-the-hugging-face-team"),s(N,"class","relative group"),s(S,"alt","HuggingFace Expert Acceleration Program"),Mr(S.src,jr="https://huggingface.co/front/thumbnails/support.png")||s(S,"src",jr),It(S,"max-width","400px"),It(S,"border","1px solid #eee"),It(S,"border-radius","4px"),It(S,"box-shadow","0 1px 2px 0 rgba(0, 0, 0, 0.05)"),s(F,"target","_blank"),s(F,"href","https://huggingface.co/support"),s(z,"id","third-party-library-models:"),s(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(z,"href","#third-party-library-models:"),s(G,"class","relative group"),s(he,"href","https://huggingface.co"),s(he,"rel","nofollow"),s(ue,"href","https://spacy.io/"),s(ue,"rel","nofollow"),s(ce,"href","https://allennlp.org/"),s(ce,"rel","nofollow"),s(pe,"href","https://speechbrain.github.io/"),s(pe,"rel","nofollow"),s(me,"href","https://pypi.org/project/timm/"),s(me,"rel","nofollow"),s(de,"href","https://huggingface.co/docs/hub/libraries"),s(de,"rel","nofollow"),s(ve,"href","https://github.com/huggingface/huggingface_hub/tree/main/api-inference-community"),s(ve,"rel","nofollow"),s(K,"id","community-models:"),s(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(K,"href","#community-models:"),s(H,"class","relative group"),s(ye,"href","https://github.com/huggingface/api-inference-community/"),s(ye,"rel","nofollow")},m(t,u){e(document.head,m),c(t,U,u),c(t,g,u),e(g,E),e(E,x),$e(b,x,null),e(g,w),e(g,k),e(k,X),c(t,C,u),c(t,$,u),e($,Y),c(t,q,u),c(t,y,u),e(y,P),e(P,v),$e(_,v,null),e(y,Ie),e(y,A),e(A,Te),c(t,Z,u),c(t,I,u),c(t,rt,u),c(t,B,u),c(t,at,u),c(t,L,u),e(L,O),e(O,Re),$e(ee,Re,null),e(L,Tt),e(L,He),e(He,St),c(t,ot,u),c(t,p,u),e(p,te),e(te,xt),e(te,Ue),e(Ue,Lt),e(te,Nt),e(p,Gt),e(p,Se),e(Se,Rt),e(Se,Ce),e(Ce,Ht),e(p,Ut),e(p,qe),e(qe,Ct),e(p,qt),e(p,re),e(re,Bt),e(re,Be),e(Be,Ot),e(re,Mt),e(p,Ft),e(p,T),e(T,zt),e(T,Oe),e(Oe,jt),e(T,Qt),e(T,Me),e(Me,Jt),e(T,Dt),e(T,ae),e(ae,Kt),e(T,Vt),e(p,Wt),e(p,oe),e(oe,Xt),e(oe,Fe),e(Fe,Yt),e(oe,Zt),e(p,er),e(p,le),e(le,tr),e(le,ze),e(ze,rr),e(le,ar),e(p,or),e(p,xe),e(xe,je),e(je,lr),e(xe,nr),e(p,ir),e(p,Qe),e(Qe,sr),c(t,lt,u),c(t,N,u),e(N,M),e(M,Je),$e(ne,Je,null),e(N,fr),e(N,De),e(De,hr),c(t,nt,u),c(t,F,u),e(F,S),c(t,it,u),c(t,G,u),e(G,z),e(z,Ke),$e(ie,Ke,null),e(G,ur),e(G,Ve),e(Ve,cr),c(t,st,u),c(t,j,u),e(j,se),e(se,fe),e(fe,pr),e(fe,he),e(he,mr),e(fe,dr),e(se,gr),e(se,R),e(R,Q),e(Q,ue),e(ue,vr),e(Q,_r),e(Q,ce),e(ce,yr),e(Q,wr),e(R,Er),e(R,Le),e(Le,pe),e(pe,br),e(Le,$r),e(R,Pr),e(R,J),e(J,me),e(me,Ar),e(J,kr),e(J,de),e(de,Ir),e(J,Tr),e(j,Sr),e(j,We),e(We,ge),e(ge,xr),e(ge,ve),e(ve,Lr),e(ge,Nr),c(t,ft,u),$e(D,t,u),c(t,ht,u),c(t,H,u),e(H,K),e(K,Xe),$e(_e,Xe,null),e(H,Gr),e(H,Ye),e(Ye,Rr),c(t,ut,u),c(t,V,u),e(V,Hr),e(V,ye),e(ye,Ur),e(V,Cr),ct=!0},p(t,[u]){const we={};u&2&&(we.$$scope={dirty:u,ctx:t}),D.$set(we)},i(t){ct||(Pe(b.$$.fragment,t),Pe(_.$$.fragment,t),Pe(ee.$$.fragment,t),Pe(ne.$$.fragment,t),Pe(ie.$$.fragment,t),Pe(D.$$.fragment,t),Pe(_e.$$.fragment,t),ct=!0)},o(t){Ae(b.$$.fragment,t),Ae(_.$$.fragment,t),Ae(ee.$$.fragment,t),Ae(ne.$$.fragment,t),Ae(ie.$$.fragment,t),Ae(D.$$.fragment,t),Ae(_e.$$.fragment,t),ct=!1},d(t){r(m),t&&r(U),t&&r(g),ke(b),t&&r(C),t&&r($),t&&r(q),t&&r(y),ke(_),t&&r(Z),t&&r(I),t&&r(rt),t&&r(B),t&&r(at),t&&r(L),ke(ee),t&&r(ot),t&&r(p),t&&r(lt),t&&r(N),ke(ne),t&&r(nt),t&&r(F),t&&r(it),t&&r(G),ke(ie),t&&r(st),t&&r(j),t&&r(ft),ke(D,t),t&&r(ht),t&&r(H),ke(_e),t&&r(ut),t&&r(V)}}}const Ba={local:"accelerated-inference-api",title:"\u{1F917} Accelerated Inference API"};function Oa(tt){return Ha(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ja extends La{constructor(m){super();Na(this,m,Oa,qa,Ga,{})}}export{ja as default,Ba as metadata};
