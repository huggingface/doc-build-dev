import{S as fs,i as ds,s as cs,e as l,k as f,w as E,t as s,M as hs,c as i,d as a,m as d,a as o,x as $,h as r,b as c,G as e,g as p,y as w,q as x,o as b,B as A,v as us}from"../chunks/vendor-hf-doc-builder.js";import{T as ms}from"../chunks/Tip-hf-doc-builder.js";import{I as Tt}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ft}from"../chunks/CodeBlock-hf-doc-builder.js";function vs(It){let h,H,u,_,S;return{c(){h=l("p"),H=s("Eventually, you\u2019ll also be able to structure your repository to specify different dataset configurations. Stay tuned on this "),u=l("a"),_=s("issue"),S=s(" for the latest updates!"),this.h()},l(v){h=i(v,"P",{});var j=o(h);H=r(j,"Eventually, you\u2019ll also be able to structure your repository to specify different dataset configurations. Stay tuned on this "),u=i(j,"A",{href:!0,rel:!0});var N=o(u);_=r(N,"issue"),N.forEach(a),S=r(j," for the latest updates!"),j.forEach(a),this.h()},h(){c(u,"href","https://github.com/huggingface/datasets/issues/4578"),c(u,"rel","nofollow")},m(v,j){p(v,h,j),e(h,H),e(h,u),e(u,_),e(h,S)},d(v){v&&a(h)}}}function _s(It){let h,H,u,_,S,v,j,N,xe,Lt,it,be,qt,R,Ae,ot,je,De,Jt,T,ke,nt,Pe,Se,Ut,M,F,ut,z,Me,mt,ge,Bt,D,Ce,vt,Oe,He,_t,Ne,Re,Vt,k,Te,yt,Fe,Ie,pt,Le,qe,Yt,K,Gt,g,I,Et,Q,Je,$t,Ue,zt,L,Be,wt,Ve,Ye,Kt,q,W,Ge,xt,ze,Ke,Qe,X,We,bt,Xe,Ze,Qt,J,ta,At,ea,aa,Wt,Z,Xt,C,U,jt,tt,sa,Dt,ra,Zt,ft,la,te,et,ee,m,ia,kt,oa,na,Pt,pa,fa,St,da,ca,Mt,ha,ua,ae,dt,ma,se,at,re,B,le,O,V,gt,st,va,Ct,_a,ie,Y,ya,Ot,Ea,$a,oe,y,wa,Ht,xa,ba,Nt,Aa,ja,Rt,Da,ka,ne,rt,pe;return v=new Tt({}),z=new Tt({}),K=new Ft({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train.csv
\u2514\u2500\u2500 test.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 test.<span class="hljs-built_in">csv</span>`}}),Q=new Tt({}),Z=new Ft({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train.csv
    \u251C\u2500\u2500 test.csv
    \u2514\u2500\u2500 valid.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
    \u251C\u2500\u2500 test.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 valid.<span class="hljs-built_in">csv</span>`}}),tt=new Tt({}),et=new Ft({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train_0.csv
\u251C\u2500\u2500 train_1.csv
\u251C\u2500\u2500 train_2.csv
\u251C\u2500\u2500 train_3.csv
\u251C\u2500\u2500 test_0.csv
\u2514\u2500\u2500 test_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train_0.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_1.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_2.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_3.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 test_0.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 test_1.<span class="hljs-built_in">csv</span>`}}),at=new Ft({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.csv
    \u2502   \u251C\u2500\u2500 shard_1.csv
    \u2502   \u251C\u2500\u2500 shard_2.csv
    \u2502   \u2514\u2500\u2500 shard_3.csv
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.csv
        \u2514\u2500\u2500 shard_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.<span class="hljs-built_in">csv</span>
    \u2502   \u251C\u2500\u2500 shard_1.<span class="hljs-built_in">csv</span>
    \u2502   \u251C\u2500\u2500 shard_2.<span class="hljs-built_in">csv</span>
    \u2502   \u2514\u2500\u2500 shard_3.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.<span class="hljs-built_in">csv</span>
        \u2514\u2500\u2500 shard_1.<span class="hljs-built_in">csv</span>`}}),B=new ms({props:{$$slots:{default:[vs]},$$scope:{ctx:It}}}),st=new Tt({}),rt=new Ft({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train-00000-of-00003.csv
    \u251C\u2500\u2500 train-00001-of-00003.csv
    \u251C\u2500\u2500 train-00002-of-00003.csv
    \u251C\u2500\u2500 test-00000-of-00001.csv
    \u251C\u2500\u2500 random-00000-of-00003.csv
    \u251C\u2500\u2500 random-00001-of-00003.csv
    \u2514\u2500\u2500 random-00002-of-00003.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 train<span class="hljs-string">-00001</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 train<span class="hljs-string">-00002</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 test<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00001</span>.csv
    \u251C\u2500\u2500 random<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 random<span class="hljs-string">-00001</span>-of<span class="hljs-string">-00003</span>.csv
    \u2514\u2500\u2500 random<span class="hljs-string">-00002</span>-of<span class="hljs-string">-00003</span>.csv`}}),{c(){h=l("meta"),H=f(),u=l("h1"),_=l("a"),S=l("span"),E(v.$$.fragment),j=f(),N=l("span"),xe=s("Structure your repository"),Lt=f(),it=l("p"),be=s("To host and share your dataset, you can create a dataset repository on the Hugging Face Dataset Hub and upload your data files."),qt=f(),R=l("p"),Ae=s(`This guide will show you how to structure your dataset repository when you upload it.
A dataset with a supported structure and file format (text, JSON, JSON Lines, CSV, Parquet) can be loaded automatically with `),ot=l("a"),je=s("load_dataset()"),De=s(", and it\u2019ll have a preview on its dataset page on the Hub."),Jt=f(),T=l("p"),ke=s("For more flexibility over how to load and generate a dataset, you can also write a "),nt=l("a"),Pe=s("dataset loading script"),Se=s("."),Ut=f(),M=l("h2"),F=l("a"),ut=l("span"),E(z.$$.fragment),Me=f(),mt=l("span"),ge=s("Main use-case"),Bt=f(),D=l("p"),Ce=s("The simplest dataset structure has two files: "),vt=l("code"),Oe=s("train.csv"),He=s(" and "),_t=l("code"),Ne=s("test.csv"),Re=s("."),Vt=f(),k=l("p"),Te=s("Your repository will also contain a "),yt=l("code"),Fe=s("README.md"),Ie=s(" file, the "),pt=l("a"),Le=s("dataset card"),qe=s(" displayed on your dataset page."),Yt=f(),E(K.$$.fragment),Gt=f(),g=l("h2"),I=l("a"),Et=l("span"),E(Q.$$.fragment),Je=f(),$t=l("span"),Ue=s("Splits and file names"),zt=f(),L=l("p"),Be=s("\u{1F917} Datasets automatically infer a dataset\u2019s train, validation, and test splits from the file names. Files that contain "),wt=l("em"),Ve=s("train"),Ye=s(" in their names are considered part of the train split. The same idea applies to the test and validation split:"),Kt=f(),q=l("ul"),W=l("li"),Ge=s("All the files that contain "),xt=l("em"),ze=s("test"),Ke=s(" in their names are considered part of the test split."),Qe=f(),X=l("li"),We=s("All the files that contain "),bt=l("em"),Xe=s("valid"),Ze=s(" in their names are considered part of the validation split."),Qt=f(),J=l("p"),ta=s("Here is an example where all the files are placed into a directory named "),At=l("code"),ea=s("data"),aa=s(":"),Wt=f(),E(Z.$$.fragment),Xt=f(),C=l("h2"),U=l("a"),jt=l("span"),E(tt.$$.fragment),sa=f(),Dt=l("span"),ra=s("Multiple files per split"),Zt=f(),ft=l("p"),la=s(`If one of your splits comprises several files, \u{1F917} Datasets can still infer whether it is the train, validation, and test split from the file name.
For example, if your train and test splits span several files:`),te=f(),E(et.$$.fragment),ee=f(),m=l("p"),ia=s("Make sure all the files of your "),kt=l("code"),oa=s("train"),na=s(" set have "),Pt=l("em"),pa=s("train"),fa=s(` in their names (same for test and validation).
Even if you add a prefix or suffix to `),St=l("code"),da=s("train"),ca=s(" in the file name (like "),Mt=l("code"),ha=s("my_train_file_00001.csv"),ua=s(` for example),
\u{1F917} Datasets can still infer the appropriate split.`),ae=f(),dt=l("p"),ma=s("For convenience, you can also place your data files into different directories. In this case, the split name is inferred from the directory name."),se=f(),E(at.$$.fragment),re=f(),E(B.$$.fragment),le=f(),O=l("h2"),V=l("a"),gt=l("span"),E(st.$$.fragment),va=f(),Ct=l("span"),_a=s("Custom split names"),ie=f(),Y=l("p"),ya=s(`If you have other data files in addition to the traditional train, validation, and test sets, you must use a different structure.
Use this exact file name format for this structure type: `),Ot=l("code"),Ea=s("data/<split_name>-xxxxx-of-xxxxx.csv"),$a=s("."),oe=f(),y=l("p"),wa=s("Here is an example with three splits: "),Ht=l("code"),xa=s("train"),ba=s(", "),Nt=l("code"),Aa=s("test"),ja=s(", and "),Rt=l("code"),Da=s("random"),ka=s(":"),ne=f(),E(rt.$$.fragment),this.h()},l(t){const n=hs('[data-svelte="svelte-1phssyn"]',document.head);h=i(n,"META",{name:!0,content:!0}),n.forEach(a),H=d(t),u=i(t,"H1",{class:!0});var lt=o(u);_=i(lt,"A",{id:!0,class:!0,href:!0});var Pa=o(_);S=i(Pa,"SPAN",{});var Sa=o(S);$(v.$$.fragment,Sa),Sa.forEach(a),Pa.forEach(a),j=d(lt),N=i(lt,"SPAN",{});var Ma=o(N);xe=r(Ma,"Structure your repository"),Ma.forEach(a),lt.forEach(a),Lt=d(t),it=i(t,"P",{});var ga=o(it);be=r(ga,"To host and share your dataset, you can create a dataset repository on the Hugging Face Dataset Hub and upload your data files."),ga.forEach(a),qt=d(t),R=i(t,"P",{});var fe=o(R);Ae=r(fe,`This guide will show you how to structure your dataset repository when you upload it.
A dataset with a supported structure and file format (text, JSON, JSON Lines, CSV, Parquet) can be loaded automatically with `),ot=i(fe,"A",{href:!0});var Ca=o(ot);je=r(Ca,"load_dataset()"),Ca.forEach(a),De=r(fe,", and it\u2019ll have a preview on its dataset page on the Hub."),fe.forEach(a),Jt=d(t),T=i(t,"P",{});var de=o(T);ke=r(de,"For more flexibility over how to load and generate a dataset, you can also write a "),nt=i(de,"A",{href:!0});var Oa=o(nt);Pe=r(Oa,"dataset loading script"),Oa.forEach(a),Se=r(de,"."),de.forEach(a),Ut=d(t),M=i(t,"H2",{class:!0});var ce=o(M);F=i(ce,"A",{id:!0,class:!0,href:!0});var Ha=o(F);ut=i(Ha,"SPAN",{});var Na=o(ut);$(z.$$.fragment,Na),Na.forEach(a),Ha.forEach(a),Me=d(ce),mt=i(ce,"SPAN",{});var Ra=o(mt);ge=r(Ra,"Main use-case"),Ra.forEach(a),ce.forEach(a),Bt=d(t),D=i(t,"P",{});var ct=o(D);Ce=r(ct,"The simplest dataset structure has two files: "),vt=i(ct,"CODE",{});var Ta=o(vt);Oe=r(Ta,"train.csv"),Ta.forEach(a),He=r(ct," and "),_t=i(ct,"CODE",{});var Fa=o(_t);Ne=r(Fa,"test.csv"),Fa.forEach(a),Re=r(ct,"."),ct.forEach(a),Vt=d(t),k=i(t,"P",{});var ht=o(k);Te=r(ht,"Your repository will also contain a "),yt=i(ht,"CODE",{});var Ia=o(yt);Fe=r(Ia,"README.md"),Ia.forEach(a),Ie=r(ht," file, the "),pt=i(ht,"A",{href:!0});var La=o(pt);Le=r(La,"dataset card"),La.forEach(a),qe=r(ht," displayed on your dataset page."),ht.forEach(a),Yt=d(t),$(K.$$.fragment,t),Gt=d(t),g=i(t,"H2",{class:!0});var he=o(g);I=i(he,"A",{id:!0,class:!0,href:!0});var qa=o(I);Et=i(qa,"SPAN",{});var Ja=o(Et);$(Q.$$.fragment,Ja),Ja.forEach(a),qa.forEach(a),Je=d(he),$t=i(he,"SPAN",{});var Ua=o($t);Ue=r(Ua,"Splits and file names"),Ua.forEach(a),he.forEach(a),zt=d(t),L=i(t,"P",{});var ue=o(L);Be=r(ue,"\u{1F917} Datasets automatically infer a dataset\u2019s train, validation, and test splits from the file names. Files that contain "),wt=i(ue,"EM",{});var Ba=o(wt);Ve=r(Ba,"train"),Ba.forEach(a),Ye=r(ue," in their names are considered part of the train split. The same idea applies to the test and validation split:"),ue.forEach(a),Kt=d(t),q=i(t,"UL",{});var me=o(q);W=i(me,"LI",{});var ve=o(W);Ge=r(ve,"All the files that contain "),xt=i(ve,"EM",{});var Va=o(xt);ze=r(Va,"test"),Va.forEach(a),Ke=r(ve," in their names are considered part of the test split."),ve.forEach(a),Qe=d(me),X=i(me,"LI",{});var _e=o(X);We=r(_e,"All the files that contain "),bt=i(_e,"EM",{});var Ya=o(bt);Xe=r(Ya,"valid"),Ya.forEach(a),Ze=r(_e," in their names are considered part of the validation split."),_e.forEach(a),me.forEach(a),Qt=d(t),J=i(t,"P",{});var ye=o(J);ta=r(ye,"Here is an example where all the files are placed into a directory named "),At=i(ye,"CODE",{});var Ga=o(At);ea=r(Ga,"data"),Ga.forEach(a),aa=r(ye,":"),ye.forEach(a),Wt=d(t),$(Z.$$.fragment,t),Xt=d(t),C=i(t,"H2",{class:!0});var Ee=o(C);U=i(Ee,"A",{id:!0,class:!0,href:!0});var za=o(U);jt=i(za,"SPAN",{});var Ka=o(jt);$(tt.$$.fragment,Ka),Ka.forEach(a),za.forEach(a),sa=d(Ee),Dt=i(Ee,"SPAN",{});var Qa=o(Dt);ra=r(Qa,"Multiple files per split"),Qa.forEach(a),Ee.forEach(a),Zt=d(t),ft=i(t,"P",{});var Wa=o(ft);la=r(Wa,`If one of your splits comprises several files, \u{1F917} Datasets can still infer whether it is the train, validation, and test split from the file name.
For example, if your train and test splits span several files:`),Wa.forEach(a),te=d(t),$(et.$$.fragment,t),ee=d(t),m=i(t,"P",{});var P=o(m);ia=r(P,"Make sure all the files of your "),kt=i(P,"CODE",{});var Xa=o(kt);oa=r(Xa,"train"),Xa.forEach(a),na=r(P," set have "),Pt=i(P,"EM",{});var Za=o(Pt);pa=r(Za,"train"),Za.forEach(a),fa=r(P,` in their names (same for test and validation).
Even if you add a prefix or suffix to `),St=i(P,"CODE",{});var ts=o(St);da=r(ts,"train"),ts.forEach(a),ca=r(P," in the file name (like "),Mt=i(P,"CODE",{});var es=o(Mt);ha=r(es,"my_train_file_00001.csv"),es.forEach(a),ua=r(P,` for example),
\u{1F917} Datasets can still infer the appropriate split.`),P.forEach(a),ae=d(t),dt=i(t,"P",{});var as=o(dt);ma=r(as,"For convenience, you can also place your data files into different directories. In this case, the split name is inferred from the directory name."),as.forEach(a),se=d(t),$(at.$$.fragment,t),re=d(t),$(B.$$.fragment,t),le=d(t),O=i(t,"H2",{class:!0});var $e=o(O);V=i($e,"A",{id:!0,class:!0,href:!0});var ss=o(V);gt=i(ss,"SPAN",{});var rs=o(gt);$(st.$$.fragment,rs),rs.forEach(a),ss.forEach(a),va=d($e),Ct=i($e,"SPAN",{});var ls=o(Ct);_a=r(ls,"Custom split names"),ls.forEach(a),$e.forEach(a),ie=d(t),Y=i(t,"P",{});var we=o(Y);ya=r(we,`If you have other data files in addition to the traditional train, validation, and test sets, you must use a different structure.
Use this exact file name format for this structure type: `),Ot=i(we,"CODE",{});var is=o(Ot);Ea=r(is,"data/<split_name>-xxxxx-of-xxxxx.csv"),is.forEach(a),$a=r(we,"."),we.forEach(a),oe=d(t),y=i(t,"P",{});var G=o(y);wa=r(G,"Here is an example with three splits: "),Ht=i(G,"CODE",{});var os=o(Ht);xa=r(os,"train"),os.forEach(a),ba=r(G,", "),Nt=i(G,"CODE",{});var ns=o(Nt);Aa=r(ns,"test"),ns.forEach(a),ja=r(G,", and "),Rt=i(G,"CODE",{});var ps=o(Rt);Da=r(ps,"random"),ps.forEach(a),ka=r(G,":"),G.forEach(a),ne=d(t),$(rt.$$.fragment,t),this.h()},h(){c(h,"name","hf:doc:metadata"),c(h,"content",JSON.stringify(ys)),c(_,"id","structure-your-repository"),c(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_,"href","#structure-your-repository"),c(u,"class","relative group"),c(ot,"href","/docs/datasets/pr_4409/en/package_reference/loading_methods#datasets.load_dataset"),c(nt,"href","./dataset_script"),c(F,"id","main-usecase"),c(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F,"href","#main-usecase"),c(M,"class","relative group"),c(pt,"href","dataset_card"),c(I,"id","splits-and-file-names"),c(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I,"href","#splits-and-file-names"),c(g,"class","relative group"),c(U,"id","multiple-files-per-split"),c(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U,"href","#multiple-files-per-split"),c(C,"class","relative group"),c(V,"id","custom-split-names"),c(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V,"href","#custom-split-names"),c(O,"class","relative group")},m(t,n){e(document.head,h),p(t,H,n),p(t,u,n),e(u,_),e(_,S),w(v,S,null),e(u,j),e(u,N),e(N,xe),p(t,Lt,n),p(t,it,n),e(it,be),p(t,qt,n),p(t,R,n),e(R,Ae),e(R,ot),e(ot,je),e(R,De),p(t,Jt,n),p(t,T,n),e(T,ke),e(T,nt),e(nt,Pe),e(T,Se),p(t,Ut,n),p(t,M,n),e(M,F),e(F,ut),w(z,ut,null),e(M,Me),e(M,mt),e(mt,ge),p(t,Bt,n),p(t,D,n),e(D,Ce),e(D,vt),e(vt,Oe),e(D,He),e(D,_t),e(_t,Ne),e(D,Re),p(t,Vt,n),p(t,k,n),e(k,Te),e(k,yt),e(yt,Fe),e(k,Ie),e(k,pt),e(pt,Le),e(k,qe),p(t,Yt,n),w(K,t,n),p(t,Gt,n),p(t,g,n),e(g,I),e(I,Et),w(Q,Et,null),e(g,Je),e(g,$t),e($t,Ue),p(t,zt,n),p(t,L,n),e(L,Be),e(L,wt),e(wt,Ve),e(L,Ye),p(t,Kt,n),p(t,q,n),e(q,W),e(W,Ge),e(W,xt),e(xt,ze),e(W,Ke),e(q,Qe),e(q,X),e(X,We),e(X,bt),e(bt,Xe),e(X,Ze),p(t,Qt,n),p(t,J,n),e(J,ta),e(J,At),e(At,ea),e(J,aa),p(t,Wt,n),w(Z,t,n),p(t,Xt,n),p(t,C,n),e(C,U),e(U,jt),w(tt,jt,null),e(C,sa),e(C,Dt),e(Dt,ra),p(t,Zt,n),p(t,ft,n),e(ft,la),p(t,te,n),w(et,t,n),p(t,ee,n),p(t,m,n),e(m,ia),e(m,kt),e(kt,oa),e(m,na),e(m,Pt),e(Pt,pa),e(m,fa),e(m,St),e(St,da),e(m,ca),e(m,Mt),e(Mt,ha),e(m,ua),p(t,ae,n),p(t,dt,n),e(dt,ma),p(t,se,n),w(at,t,n),p(t,re,n),w(B,t,n),p(t,le,n),p(t,O,n),e(O,V),e(V,gt),w(st,gt,null),e(O,va),e(O,Ct),e(Ct,_a),p(t,ie,n),p(t,Y,n),e(Y,ya),e(Y,Ot),e(Ot,Ea),e(Y,$a),p(t,oe,n),p(t,y,n),e(y,wa),e(y,Ht),e(Ht,xa),e(y,ba),e(y,Nt),e(Nt,Aa),e(y,ja),e(y,Rt),e(Rt,Da),e(y,ka),p(t,ne,n),w(rt,t,n),pe=!0},p(t,[n]){const lt={};n&2&&(lt.$$scope={dirty:n,ctx:t}),B.$set(lt)},i(t){pe||(x(v.$$.fragment,t),x(z.$$.fragment,t),x(K.$$.fragment,t),x(Q.$$.fragment,t),x(Z.$$.fragment,t),x(tt.$$.fragment,t),x(et.$$.fragment,t),x(at.$$.fragment,t),x(B.$$.fragment,t),x(st.$$.fragment,t),x(rt.$$.fragment,t),pe=!0)},o(t){b(v.$$.fragment,t),b(z.$$.fragment,t),b(K.$$.fragment,t),b(Q.$$.fragment,t),b(Z.$$.fragment,t),b(tt.$$.fragment,t),b(et.$$.fragment,t),b(at.$$.fragment,t),b(B.$$.fragment,t),b(st.$$.fragment,t),b(rt.$$.fragment,t),pe=!1},d(t){a(h),t&&a(H),t&&a(u),A(v),t&&a(Lt),t&&a(it),t&&a(qt),t&&a(R),t&&a(Jt),t&&a(T),t&&a(Ut),t&&a(M),A(z),t&&a(Bt),t&&a(D),t&&a(Vt),t&&a(k),t&&a(Yt),A(K,t),t&&a(Gt),t&&a(g),A(Q),t&&a(zt),t&&a(L),t&&a(Kt),t&&a(q),t&&a(Qt),t&&a(J),t&&a(Wt),A(Z,t),t&&a(Xt),t&&a(C),A(tt),t&&a(Zt),t&&a(ft),t&&a(te),A(et,t),t&&a(ee),t&&a(m),t&&a(ae),t&&a(dt),t&&a(se),A(at,t),t&&a(re),A(B,t),t&&a(le),t&&a(O),A(st),t&&a(ie),t&&a(Y),t&&a(oe),t&&a(y),t&&a(ne),A(rt,t)}}}const ys={local:"structure-your-repository",sections:[{local:"main-usecase",title:"Main use-case"},{local:"splits-and-file-names",title:"Splits and file names"},{local:"multiple-files-per-split",title:"Multiple files per split"},{local:"custom-split-names",title:"Custom split names"}],title:"Structure your repository"};function Es(It){return us(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class As extends fs{constructor(h){super();ds(this,h,Es,_s,cs,{})}}export{As as default,ys as metadata};
