import{S as sl,i as al,s as tl,e as n,k as i,w as m,t as o,M as el,c as l,d as a,m as c,a as r,x as u,h,b as d,G as t,g as p,y as f,q as g,o as j,B as y,v as nl}from"../chunks/vendor-hf-doc-builder.js";import{T as ll}from"../chunks/Tip-hf-doc-builder.js";import{I as A}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as $}from"../chunks/CodeBlock-hf-doc-builder.js";function rl(ka){let _,F,b,w,S;return{c(){_=n("p"),F=o("A "),b=n("a"),w=o("Dataset"),S=o(" object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),this.h()},l(v){_=l(v,"P",{});var q=r(_);F=h(q,"A "),b=l(q,"A",{href:!0});var H=r(b);w=h(H,"Dataset"),H.forEach(a),S=h(q," object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),q.forEach(a),this.h()},h(){d(b,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset")},m(v,q){p(v,_,q),t(_,F),t(_,b),t(b,w),t(_,S)},d(v){v&&a(_)}}}function pl(ka){let _,F,b,w,S,v,q,H,xt,Ea,L,R,Ys,os,Pt,Gs,At,Da,T,M,Ws,hs,St,Js,Lt,qa,Ls,Tt,xa,Y,Ct,Ts,Nt,zt,Pa,is,Aa,G,Sa,W,Ot,Ks,It,Ut,La,cs,Ta,C,J,Qs,ds,Bt,Vs,Ft,Ca,Cs,Ht,Na,ms,za,Ns,Rt,Oa,us,Ia,N,K,Xs,fs,Mt,Zs,Yt,Ua,gs,zs,Gt,Wt,Ba,js,Fa,Q,Jt,sa,Kt,Qt,Ha,ys,Ra,x,Vt,Os,Xt,Zt,Is,se,ae,Ma,z,V,aa,_s,te,ta,ee,Ya,k,ne,ea,le,re,Us,pe,oe,na,he,ie,Ga,bs,Wa,O,X,la,vs,ce,ra,de,Ja,I,Z,pa,$s,me,oa,ue,Ka,P,fe,ha,ge,je,ia,ye,_e,Qa,E,be,ca,ve,$e,da,we,ke,ma,Ee,De,Va,ws,Xa,U,ss,ua,ks,qe,fa,xe,Za,Bs,Pe,st,Es,at,Fs,Ae,tt,Ds,et,as,Se,ga,Le,Te,nt,qs,lt,D,Ce,ja,Ne,ze,ya,Oe,Ie,_a,Ue,Be,rt,B,ts,ba,xs,Fe,va,He,pt,es,Re,$a,Me,Ye,ot,Ps,ht,ns,Ge,wa,We,Je,it,As,ct,Hs,Ke,dt;return v=new A({}),os=new A({}),hs=new A({}),is=new $({props:{code:`from datasets import Dataset
data = [[1, 2],[3, 4]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("pytorch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}`}}),G=new ll({props:{$$slots:{default:[rl]},$$scope:{ctx:ka}}}),cs=new $({props:{code:`import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ds = ds.with_format("pytorch", device=device)
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>, device=device)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)}`}}),ds=new A({}),ms=new $({props:{code:`from datasets import Dataset
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("pytorch")
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: [tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]), tensor([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]}`}}),us=new $({props:{code:`from datasets import Dataset, Features, Array2D
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
features = Features({"data": Array2D(shape=(2, 2), dtype='int32')})
ds = Dataset.from_dict({"data": data}, features=features)
ds = ds.with_format("pytorch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, Array2D
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: Array2D(shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=<span class="hljs-string">&#x27;int32&#x27;</span>)})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
          [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],
 
         [[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],
          [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]])}`}}),fs=new A({}),js=new $({props:{code:`from datasets import Dataset, Features, ClassLabel
data = [0, 0, 1]
features = Features({"data": ClassLabel(names=["negative", "positive"])})
ds = Dataset.from_dict({"data": data}, features=features) 
ds = ds.with_format("pytorch")  
ds[:3]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, ClassLabel
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: ClassLabel(names=[<span class="hljs-string">&quot;negative&quot;</span>, <span class="hljs-string">&quot;positive&quot;</span>])})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">3</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}`}}),ys=new $({props:{code:`from datasets import Dataset, Features 
text = ["foo", "bar"]
data = [0, 1] 
ds = Dataset.from_dict({"text": text, "data": data})  
ds = ds.with_format("pytorch", columns=["data"], output_all_columns=True) 
ds[:2]                                                                                                                                                     `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features 
<span class="hljs-meta">&gt;&gt;&gt; </span>text = [<span class="hljs-string">&quot;foo&quot;</span>, <span class="hljs-string">&quot;bar&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;text&quot;</span>: text, <span class="hljs-string">&quot;data&quot;</span>: data})  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>, columns=[<span class="hljs-string">&quot;data&quot;</span>], output_all_columns=<span class="hljs-literal">True</span>) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]                                                                                                                                                     
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;foo&#x27;</span>, <span class="hljs-string">&#x27;bar&#x27;</span>]}`}}),_s=new A({}),bs=new $({props:{code:`import numpy as np
from datasets import Dataset 
from torch.utils.data import DataLoader
data = np.random.rand(16)
label = np.random.randint(0, 2, size=16)
ds = Dataset.from_dict({"data": data, "label": label}).with_format("pytorch")
dataloader = DataLoader(ds, batch_size=4)
for batch in dataloader:
    print(batch)                                                                                            `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>label = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, size=<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data, <span class="hljs-string">&quot;label&quot;</span>: label}).with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> dataloader:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(batch)                                                                                            
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.0047</span>, <span class="hljs-number">0.4979</span>, <span class="hljs-number">0.6726</span>, <span class="hljs-number">0.8105</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.4832</span>, <span class="hljs-number">0.2723</span>, <span class="hljs-number">0.4259</span>, <span class="hljs-number">0.2224</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.5837</span>, <span class="hljs-number">0.3444</span>, <span class="hljs-number">0.4658</span>, <span class="hljs-number">0.6417</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.7022</span>, <span class="hljs-number">0.1225</span>, <span class="hljs-number">0.7228</span>, <span class="hljs-number">0.8259</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])}`}}),vs=new A({}),$s=new A({}),ws=new $({props:{code:`import numpy as np
from datasets import Dataset, load_from_disk
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).save_to_disk("my_dataset")
ds = load_from_disk("my_dataset").with_format("torch")
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_from_disk
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).save_to_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_from_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),ks=new A({}),Es=new $({props:{code:"batch = [dataset[idx] for idx in range(start, end)]",highlighted:'batch = [dataset[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end)]'}}),Ds=new $({props:{code:`batch = dataset[start:end]
# or
batch = dataset[list_of_indices]`,highlighted:`batch = dataset[start:end]
<span class="hljs-comment"># or</span>
batch = dataset[list_of_indices]`}}),qs=new $({props:{code:`from torch.utils.data.sampler import BatchSampler, RandomSampler
sampler = BatchSampler(RandomSampler(ds), batch_size=32, drop_last=False)
dataloader = DataLoader(ds, sampler=sampler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data.sampler <span class="hljs-keyword">import</span> BatchSampler, RandomSampler
<span class="hljs-meta">&gt;&gt;&gt; </span>sampler = BatchSampler(RandomSampler(ds), batch_size=<span class="hljs-number">32</span>, drop_last=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, sampler=sampler)`}}),xs=new A({}),Ps=new $({props:{code:`import numpy as np
from datasets import Dataset, load_dataset
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).push_to_hub("<username>/my_dataset")  # Upload to the Hugging Face Hub
ds = load_dataset("<username>/my_dataset", streaming=True, split="train").with_format("torch")
dataloader = DataLoader(ds, batch_size=32)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).push_to_hub(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)  <span class="hljs-comment"># Upload to the Hugging Face Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>)`}}),As=new $({props:{code:`ds = load_dataset("c4", "en", streaming=True, split="train").with_format("torch")
ds.n_shards
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;c4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds.n_shards
<span class="hljs-number">1024</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),{c(){_=n("meta"),F=i(),b=n("h1"),w=n("a"),S=n("span"),m(v.$$.fragment),q=i(),H=n("span"),xt=o("Use with PyTorch"),Ea=i(),L=n("h2"),R=n("a"),Ys=n("span"),m(os.$$.fragment),Pt=i(),Gs=n("span"),At=o("Tensors"),Da=i(),T=n("h3"),M=n("a"),Ws=n("span"),m(hs.$$.fragment),St=i(),Js=n("span"),Lt=o("Dataset format"),qa=i(),Ls=n("p"),Tt=o("By default, datasets return regular python objects: integers, floats, strings, lists, etc."),xa=i(),Y=n("p"),Ct=o("To get PyTorch tensors instead, you can set the format of the dataset to \u201Cpytorch\u201D using "),Ts=n("a"),Nt=o("Dataset.with_format()"),zt=o(":"),Pa=i(),m(is.$$.fragment),Aa=i(),m(G.$$.fragment),Sa=i(),W=n("p"),Ot=o("To load the data as tensors on a GPU, you can also specify the "),Ks=n("code"),It=o("device"),Ut=o(" argument:"),La=i(),m(cs.$$.fragment),Ta=i(),C=n("h3"),J=n("a"),Qs=n("span"),m(ds.$$.fragment),Bt=i(),Vs=n("span"),Ft=o("N-dimensional arrays"),Ca=i(),Cs=n("p"),Ht=o(`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of one single tensor:`),Na=i(),m(ms.$$.fragment),za=i(),Ns=n("p"),Rt=o("To get one single tensor, you must explicitly use the Array feature type and specify the shape of your tensors:"),Oa=i(),m(us.$$.fragment),Ia=i(),N=n("h3"),K=n("a"),Xs=n("span"),m(fs.$$.fragment),Mt=i(),Zs=n("span"),Yt=o("Other feature types"),Ua=i(),gs=n("p"),zs=n("a"),Gt=o("ClassLabel"),Wt=o(" data are properly converted to tensors:"),Ba=i(),m(js.$$.fragment),Fa=i(),Q=n("p"),Jt=o("However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),sa=n("code"),Kt=o("string"),Qt=o(` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),Ha=i(),m(ys.$$.fragment),Ra=i(),x=n("p"),Vt=o("The "),Os=n("a"),Xt=o("Image"),Zt=o(" and "),Is=n("a"),se=o("Audio"),ae=o(" feature types are not supported yet."),Ma=i(),z=n("h2"),V=n("a"),aa=n("span"),m(_s.$$.fragment),te=i(),ta=n("span"),ee=o("Data loading"),Ya=i(),k=n("p"),ne=o("Like "),ea=n("code"),le=o("torch.utils.data.Dataset"),re=o(" objects, a "),Us=n("a"),pe=o("Dataset"),oe=o(" can be passed directly to a PyTorch "),na=n("code"),he=o("DataLoader"),ie=o(":"),Ga=i(),m(bs.$$.fragment),Wa=i(),O=n("h3"),X=n("a"),la=n("span"),m(vs.$$.fragment),ce=i(),ra=n("span"),de=o("Optimize data loading"),Ja=i(),I=n("h4"),Z=n("a"),pa=n("span"),m($s.$$.fragment),me=i(),oa=n("span"),ue=o("Use multiple Workers"),Ka=i(),P=n("p"),fe=o("You can parallelize data loading the "),ha=n("code"),ge=o("num_workers"),je=o(" argument of a PyTorch "),ia=n("code"),ye=o("DataLoader"),_e=o(" and get a higher throughput."),Qa=i(),E=n("p"),be=o("Under the hood, the "),ca=n("code"),ve=o("DataLoader"),$e=o(" starts "),da=n("code"),we=o("num_workers"),ke=o(` processes.
Each process reloads the dataset passed to the `),ma=n("code"),Ee=o("DataLoader"),De=o(` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-map the dataset again from your disk.`),Va=i(),m(ws.$$.fragment),Xa=i(),U=n("h4"),ss=n("a"),ua=n("span"),m(ks.$$.fragment),qe=i(),fa=n("span"),xe=o("Use a BatchSampler"),Za=i(),Bs=n("p"),Pe=o("By default the pytorch data loader load batches of data from a dataset one by one like this:"),st=i(),m(Es.$$.fragment),at=i(),Fs=n("p"),Ae=o(`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),tt=i(),m(Ds.$$.fragment),et=i(),as=n("p"),Se=o("For the pytorch data loader to query batches using a list, you can use a "),ga=n("code"),Le=o("BatchSampler"),Te=o(":"),nt=i(),m(qs.$$.fragment),lt=i(),D=n("p"),Ce=o("Moreover, this is particularly useful if you used "),ja=n("code"),Ne=o("set_transform"),ze=o(` to apply a transform on-the-fly when examples are accessed.
You must use a `),ya=n("code"),Oe=o("BatchSampler"),Ie=o(" if you want the transform to be given full batches instead of receiving "),_a=n("code"),Ue=o("batch_size"),Be=o(" times one single element."),rt=i(),B=n("h3"),ts=n("a"),ba=n("span"),m(xs.$$.fragment),Fe=i(),va=n("span"),He=o("Stream data"),pt=i(),es=n("p"),Re=o(`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to \u201Cpytorch\u201D, and it inherits from `),$a=n("code"),Me=o("torch.utils.data.IterableDataset"),Ye=o(" so you can pass it to a DataLoader:"),ot=i(),m(Ps.$$.fragment),ht=i(),ns=n("p"),Ge=o("If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),wa=n("code"),We=o("num_workers"),Je=o(":"),it=i(),m(As.$$.fragment),ct=i(),Hs=n("p"),Ke=o("In this case each worker will be given a subset of the list of shards to stream from."),this.h()},l(s){const e=el('[data-svelte="svelte-1phssyn"]',document.head);_=l(e,"META",{name:!0,content:!0}),e.forEach(a),F=c(s),b=l(s,"H1",{class:!0});var Ss=r(b);w=l(Ss,"A",{id:!0,class:!0,href:!0});var Ve=r(w);S=l(Ve,"SPAN",{});var Xe=r(S);u(v.$$.fragment,Xe),Xe.forEach(a),Ve.forEach(a),q=c(Ss),H=l(Ss,"SPAN",{});var Ze=r(H);xt=h(Ze,"Use with PyTorch"),Ze.forEach(a),Ss.forEach(a),Ea=c(s),L=l(s,"H2",{class:!0});var mt=r(L);R=l(mt,"A",{id:!0,class:!0,href:!0});var sn=r(R);Ys=l(sn,"SPAN",{});var an=r(Ys);u(os.$$.fragment,an),an.forEach(a),sn.forEach(a),Pt=c(mt),Gs=l(mt,"SPAN",{});var tn=r(Gs);At=h(tn,"Tensors"),tn.forEach(a),mt.forEach(a),Da=c(s),T=l(s,"H3",{class:!0});var ut=r(T);M=l(ut,"A",{id:!0,class:!0,href:!0});var en=r(M);Ws=l(en,"SPAN",{});var nn=r(Ws);u(hs.$$.fragment,nn),nn.forEach(a),en.forEach(a),St=c(ut),Js=l(ut,"SPAN",{});var ln=r(Js);Lt=h(ln,"Dataset format"),ln.forEach(a),ut.forEach(a),qa=c(s),Ls=l(s,"P",{});var rn=r(Ls);Tt=h(rn,"By default, datasets return regular python objects: integers, floats, strings, lists, etc."),rn.forEach(a),xa=c(s),Y=l(s,"P",{});var ft=r(Y);Ct=h(ft,"To get PyTorch tensors instead, you can set the format of the dataset to \u201Cpytorch\u201D using "),Ts=l(ft,"A",{href:!0});var pn=r(Ts);Nt=h(pn,"Dataset.with_format()"),pn.forEach(a),zt=h(ft,":"),ft.forEach(a),Pa=c(s),u(is.$$.fragment,s),Aa=c(s),u(G.$$.fragment,s),Sa=c(s),W=l(s,"P",{});var gt=r(W);Ot=h(gt,"To load the data as tensors on a GPU, you can also specify the "),Ks=l(gt,"CODE",{});var on=r(Ks);It=h(on,"device"),on.forEach(a),Ut=h(gt," argument:"),gt.forEach(a),La=c(s),u(cs.$$.fragment,s),Ta=c(s),C=l(s,"H3",{class:!0});var jt=r(C);J=l(jt,"A",{id:!0,class:!0,href:!0});var hn=r(J);Qs=l(hn,"SPAN",{});var cn=r(Qs);u(ds.$$.fragment,cn),cn.forEach(a),hn.forEach(a),Bt=c(jt),Vs=l(jt,"SPAN",{});var dn=r(Vs);Ft=h(dn,"N-dimensional arrays"),dn.forEach(a),jt.forEach(a),Ca=c(s),Cs=l(s,"P",{});var mn=r(Cs);Ht=h(mn,`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of one single tensor:`),mn.forEach(a),Na=c(s),u(ms.$$.fragment,s),za=c(s),Ns=l(s,"P",{});var un=r(Ns);Rt=h(un,"To get one single tensor, you must explicitly use the Array feature type and specify the shape of your tensors:"),un.forEach(a),Oa=c(s),u(us.$$.fragment,s),Ia=c(s),N=l(s,"H3",{class:!0});var yt=r(N);K=l(yt,"A",{id:!0,class:!0,href:!0});var fn=r(K);Xs=l(fn,"SPAN",{});var gn=r(Xs);u(fs.$$.fragment,gn),gn.forEach(a),fn.forEach(a),Mt=c(yt),Zs=l(yt,"SPAN",{});var jn=r(Zs);Yt=h(jn,"Other feature types"),jn.forEach(a),yt.forEach(a),Ua=c(s),gs=l(s,"P",{});var Qe=r(gs);zs=l(Qe,"A",{href:!0});var yn=r(zs);Gt=h(yn,"ClassLabel"),yn.forEach(a),Wt=h(Qe," data are properly converted to tensors:"),Qe.forEach(a),Ba=c(s),u(js.$$.fragment,s),Fa=c(s),Q=l(s,"P",{});var _t=r(Q);Jt=h(_t,"However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),sa=l(_t,"CODE",{});var _n=r(sa);Kt=h(_n,"string"),_n.forEach(a),Qt=h(_t,` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),_t.forEach(a),Ha=c(s),u(ys.$$.fragment,s),Ra=c(s),x=l(s,"P",{});var Rs=r(x);Vt=h(Rs,"The "),Os=l(Rs,"A",{href:!0});var bn=r(Os);Xt=h(bn,"Image"),bn.forEach(a),Zt=h(Rs," and "),Is=l(Rs,"A",{href:!0});var vn=r(Is);se=h(vn,"Audio"),vn.forEach(a),ae=h(Rs," feature types are not supported yet."),Rs.forEach(a),Ma=c(s),z=l(s,"H2",{class:!0});var bt=r(z);V=l(bt,"A",{id:!0,class:!0,href:!0});var $n=r(V);aa=l($n,"SPAN",{});var wn=r(aa);u(_s.$$.fragment,wn),wn.forEach(a),$n.forEach(a),te=c(bt),ta=l(bt,"SPAN",{});var kn=r(ta);ee=h(kn,"Data loading"),kn.forEach(a),bt.forEach(a),Ya=c(s),k=l(s,"P",{});var ls=r(k);ne=h(ls,"Like "),ea=l(ls,"CODE",{});var En=r(ea);le=h(En,"torch.utils.data.Dataset"),En.forEach(a),re=h(ls," objects, a "),Us=l(ls,"A",{href:!0});var Dn=r(Us);pe=h(Dn,"Dataset"),Dn.forEach(a),oe=h(ls," can be passed directly to a PyTorch "),na=l(ls,"CODE",{});var qn=r(na);he=h(qn,"DataLoader"),qn.forEach(a),ie=h(ls,":"),ls.forEach(a),Ga=c(s),u(bs.$$.fragment,s),Wa=c(s),O=l(s,"H3",{class:!0});var vt=r(O);X=l(vt,"A",{id:!0,class:!0,href:!0});var xn=r(X);la=l(xn,"SPAN",{});var Pn=r(la);u(vs.$$.fragment,Pn),Pn.forEach(a),xn.forEach(a),ce=c(vt),ra=l(vt,"SPAN",{});var An=r(ra);de=h(An,"Optimize data loading"),An.forEach(a),vt.forEach(a),Ja=c(s),I=l(s,"H4",{class:!0});var $t=r(I);Z=l($t,"A",{id:!0,class:!0,href:!0});var Sn=r(Z);pa=l(Sn,"SPAN",{});var Ln=r(pa);u($s.$$.fragment,Ln),Ln.forEach(a),Sn.forEach(a),me=c($t),oa=l($t,"SPAN",{});var Tn=r(oa);ue=h(Tn,"Use multiple Workers"),Tn.forEach(a),$t.forEach(a),Ka=c(s),P=l(s,"P",{});var Ms=r(P);fe=h(Ms,"You can parallelize data loading the "),ha=l(Ms,"CODE",{});var Cn=r(ha);ge=h(Cn,"num_workers"),Cn.forEach(a),je=h(Ms," argument of a PyTorch "),ia=l(Ms,"CODE",{});var Nn=r(ia);ye=h(Nn,"DataLoader"),Nn.forEach(a),_e=h(Ms," and get a higher throughput."),Ms.forEach(a),Qa=c(s),E=l(s,"P",{});var rs=r(E);be=h(rs,"Under the hood, the "),ca=l(rs,"CODE",{});var zn=r(ca);ve=h(zn,"DataLoader"),zn.forEach(a),$e=h(rs," starts "),da=l(rs,"CODE",{});var On=r(da);we=h(On,"num_workers"),On.forEach(a),ke=h(rs,` processes.
Each process reloads the dataset passed to the `),ma=l(rs,"CODE",{});var In=r(ma);Ee=h(In,"DataLoader"),In.forEach(a),De=h(rs,` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-map the dataset again from your disk.`),rs.forEach(a),Va=c(s),u(ws.$$.fragment,s),Xa=c(s),U=l(s,"H4",{class:!0});var wt=r(U);ss=l(wt,"A",{id:!0,class:!0,href:!0});var Un=r(ss);ua=l(Un,"SPAN",{});var Bn=r(ua);u(ks.$$.fragment,Bn),Bn.forEach(a),Un.forEach(a),qe=c(wt),fa=l(wt,"SPAN",{});var Fn=r(fa);xe=h(Fn,"Use a BatchSampler"),Fn.forEach(a),wt.forEach(a),Za=c(s),Bs=l(s,"P",{});var Hn=r(Bs);Pe=h(Hn,"By default the pytorch data loader load batches of data from a dataset one by one like this:"),Hn.forEach(a),st=c(s),u(Es.$$.fragment,s),at=c(s),Fs=l(s,"P",{});var Rn=r(Fs);Ae=h(Rn,`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),Rn.forEach(a),tt=c(s),u(Ds.$$.fragment,s),et=c(s),as=l(s,"P",{});var kt=r(as);Se=h(kt,"For the pytorch data loader to query batches using a list, you can use a "),ga=l(kt,"CODE",{});var Mn=r(ga);Le=h(Mn,"BatchSampler"),Mn.forEach(a),Te=h(kt,":"),kt.forEach(a),nt=c(s),u(qs.$$.fragment,s),lt=c(s),D=l(s,"P",{});var ps=r(D);Ce=h(ps,"Moreover, this is particularly useful if you used "),ja=l(ps,"CODE",{});var Yn=r(ja);Ne=h(Yn,"set_transform"),Yn.forEach(a),ze=h(ps,` to apply a transform on-the-fly when examples are accessed.
You must use a `),ya=l(ps,"CODE",{});var Gn=r(ya);Oe=h(Gn,"BatchSampler"),Gn.forEach(a),Ie=h(ps," if you want the transform to be given full batches instead of receiving "),_a=l(ps,"CODE",{});var Wn=r(_a);Ue=h(Wn,"batch_size"),Wn.forEach(a),Be=h(ps," times one single element."),ps.forEach(a),rt=c(s),B=l(s,"H3",{class:!0});var Et=r(B);ts=l(Et,"A",{id:!0,class:!0,href:!0});var Jn=r(ts);ba=l(Jn,"SPAN",{});var Kn=r(ba);u(xs.$$.fragment,Kn),Kn.forEach(a),Jn.forEach(a),Fe=c(Et),va=l(Et,"SPAN",{});var Qn=r(va);He=h(Qn,"Stream data"),Qn.forEach(a),Et.forEach(a),pt=c(s),es=l(s,"P",{});var Dt=r(es);Re=h(Dt,`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to \u201Cpytorch\u201D, and it inherits from `),$a=l(Dt,"CODE",{});var Vn=r($a);Me=h(Vn,"torch.utils.data.IterableDataset"),Vn.forEach(a),Ye=h(Dt," so you can pass it to a DataLoader:"),Dt.forEach(a),ot=c(s),u(Ps.$$.fragment,s),ht=c(s),ns=l(s,"P",{});var qt=r(ns);Ge=h(qt,"If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),wa=l(qt,"CODE",{});var Xn=r(wa);We=h(Xn,"num_workers"),Xn.forEach(a),Je=h(qt,":"),qt.forEach(a),it=c(s),u(As.$$.fragment,s),ct=c(s),Hs=l(s,"P",{});var Zn=r(Hs);Ke=h(Zn,"In this case each worker will be given a subset of the list of shards to stream from."),Zn.forEach(a),this.h()},h(){d(_,"name","hf:doc:metadata"),d(_,"content",JSON.stringify(ol)),d(w,"id","use-with-pytorch"),d(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w,"href","#use-with-pytorch"),d(b,"class","relative group"),d(R,"id","tensors"),d(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(R,"href","#tensors"),d(L,"class","relative group"),d(M,"id","dataset-format"),d(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(M,"href","#dataset-format"),d(T,"class","relative group"),d(Ts,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset.with_format"),d(J,"id","ndimensional-arrays"),d(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J,"href","#ndimensional-arrays"),d(C,"class","relative group"),d(K,"id","other-feature-types"),d(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K,"href","#other-feature-types"),d(N,"class","relative group"),d(zs,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.ClassLabel"),d(Os,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Image"),d(Is,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Audio"),d(V,"id","data-loading"),d(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(V,"href","#data-loading"),d(z,"class","relative group"),d(Us,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset"),d(X,"id","optimize-data-loading"),d(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X,"href","#optimize-data-loading"),d(O,"class","relative group"),d(Z,"id","use-multiple-workers"),d(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Z,"href","#use-multiple-workers"),d(I,"class","relative group"),d(ss,"id","use-a-batchsampler"),d(ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ss,"href","#use-a-batchsampler"),d(U,"class","relative group"),d(ts,"id","stream-data"),d(ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ts,"href","#stream-data"),d(B,"class","relative group")},m(s,e){t(document.head,_),p(s,F,e),p(s,b,e),t(b,w),t(w,S),f(v,S,null),t(b,q),t(b,H),t(H,xt),p(s,Ea,e),p(s,L,e),t(L,R),t(R,Ys),f(os,Ys,null),t(L,Pt),t(L,Gs),t(Gs,At),p(s,Da,e),p(s,T,e),t(T,M),t(M,Ws),f(hs,Ws,null),t(T,St),t(T,Js),t(Js,Lt),p(s,qa,e),p(s,Ls,e),t(Ls,Tt),p(s,xa,e),p(s,Y,e),t(Y,Ct),t(Y,Ts),t(Ts,Nt),t(Y,zt),p(s,Pa,e),f(is,s,e),p(s,Aa,e),f(G,s,e),p(s,Sa,e),p(s,W,e),t(W,Ot),t(W,Ks),t(Ks,It),t(W,Ut),p(s,La,e),f(cs,s,e),p(s,Ta,e),p(s,C,e),t(C,J),t(J,Qs),f(ds,Qs,null),t(C,Bt),t(C,Vs),t(Vs,Ft),p(s,Ca,e),p(s,Cs,e),t(Cs,Ht),p(s,Na,e),f(ms,s,e),p(s,za,e),p(s,Ns,e),t(Ns,Rt),p(s,Oa,e),f(us,s,e),p(s,Ia,e),p(s,N,e),t(N,K),t(K,Xs),f(fs,Xs,null),t(N,Mt),t(N,Zs),t(Zs,Yt),p(s,Ua,e),p(s,gs,e),t(gs,zs),t(zs,Gt),t(gs,Wt),p(s,Ba,e),f(js,s,e),p(s,Fa,e),p(s,Q,e),t(Q,Jt),t(Q,sa),t(sa,Kt),t(Q,Qt),p(s,Ha,e),f(ys,s,e),p(s,Ra,e),p(s,x,e),t(x,Vt),t(x,Os),t(Os,Xt),t(x,Zt),t(x,Is),t(Is,se),t(x,ae),p(s,Ma,e),p(s,z,e),t(z,V),t(V,aa),f(_s,aa,null),t(z,te),t(z,ta),t(ta,ee),p(s,Ya,e),p(s,k,e),t(k,ne),t(k,ea),t(ea,le),t(k,re),t(k,Us),t(Us,pe),t(k,oe),t(k,na),t(na,he),t(k,ie),p(s,Ga,e),f(bs,s,e),p(s,Wa,e),p(s,O,e),t(O,X),t(X,la),f(vs,la,null),t(O,ce),t(O,ra),t(ra,de),p(s,Ja,e),p(s,I,e),t(I,Z),t(Z,pa),f($s,pa,null),t(I,me),t(I,oa),t(oa,ue),p(s,Ka,e),p(s,P,e),t(P,fe),t(P,ha),t(ha,ge),t(P,je),t(P,ia),t(ia,ye),t(P,_e),p(s,Qa,e),p(s,E,e),t(E,be),t(E,ca),t(ca,ve),t(E,$e),t(E,da),t(da,we),t(E,ke),t(E,ma),t(ma,Ee),t(E,De),p(s,Va,e),f(ws,s,e),p(s,Xa,e),p(s,U,e),t(U,ss),t(ss,ua),f(ks,ua,null),t(U,qe),t(U,fa),t(fa,xe),p(s,Za,e),p(s,Bs,e),t(Bs,Pe),p(s,st,e),f(Es,s,e),p(s,at,e),p(s,Fs,e),t(Fs,Ae),p(s,tt,e),f(Ds,s,e),p(s,et,e),p(s,as,e),t(as,Se),t(as,ga),t(ga,Le),t(as,Te),p(s,nt,e),f(qs,s,e),p(s,lt,e),p(s,D,e),t(D,Ce),t(D,ja),t(ja,Ne),t(D,ze),t(D,ya),t(ya,Oe),t(D,Ie),t(D,_a),t(_a,Ue),t(D,Be),p(s,rt,e),p(s,B,e),t(B,ts),t(ts,ba),f(xs,ba,null),t(B,Fe),t(B,va),t(va,He),p(s,pt,e),p(s,es,e),t(es,Re),t(es,$a),t($a,Me),t(es,Ye),p(s,ot,e),f(Ps,s,e),p(s,ht,e),p(s,ns,e),t(ns,Ge),t(ns,wa),t(wa,We),t(ns,Je),p(s,it,e),f(As,s,e),p(s,ct,e),p(s,Hs,e),t(Hs,Ke),dt=!0},p(s,[e]){const Ss={};e&2&&(Ss.$$scope={dirty:e,ctx:s}),G.$set(Ss)},i(s){dt||(g(v.$$.fragment,s),g(os.$$.fragment,s),g(hs.$$.fragment,s),g(is.$$.fragment,s),g(G.$$.fragment,s),g(cs.$$.fragment,s),g(ds.$$.fragment,s),g(ms.$$.fragment,s),g(us.$$.fragment,s),g(fs.$$.fragment,s),g(js.$$.fragment,s),g(ys.$$.fragment,s),g(_s.$$.fragment,s),g(bs.$$.fragment,s),g(vs.$$.fragment,s),g($s.$$.fragment,s),g(ws.$$.fragment,s),g(ks.$$.fragment,s),g(Es.$$.fragment,s),g(Ds.$$.fragment,s),g(qs.$$.fragment,s),g(xs.$$.fragment,s),g(Ps.$$.fragment,s),g(As.$$.fragment,s),dt=!0)},o(s){j(v.$$.fragment,s),j(os.$$.fragment,s),j(hs.$$.fragment,s),j(is.$$.fragment,s),j(G.$$.fragment,s),j(cs.$$.fragment,s),j(ds.$$.fragment,s),j(ms.$$.fragment,s),j(us.$$.fragment,s),j(fs.$$.fragment,s),j(js.$$.fragment,s),j(ys.$$.fragment,s),j(_s.$$.fragment,s),j(bs.$$.fragment,s),j(vs.$$.fragment,s),j($s.$$.fragment,s),j(ws.$$.fragment,s),j(ks.$$.fragment,s),j(Es.$$.fragment,s),j(Ds.$$.fragment,s),j(qs.$$.fragment,s),j(xs.$$.fragment,s),j(Ps.$$.fragment,s),j(As.$$.fragment,s),dt=!1},d(s){a(_),s&&a(F),s&&a(b),y(v),s&&a(Ea),s&&a(L),y(os),s&&a(Da),s&&a(T),y(hs),s&&a(qa),s&&a(Ls),s&&a(xa),s&&a(Y),s&&a(Pa),y(is,s),s&&a(Aa),y(G,s),s&&a(Sa),s&&a(W),s&&a(La),y(cs,s),s&&a(Ta),s&&a(C),y(ds),s&&a(Ca),s&&a(Cs),s&&a(Na),y(ms,s),s&&a(za),s&&a(Ns),s&&a(Oa),y(us,s),s&&a(Ia),s&&a(N),y(fs),s&&a(Ua),s&&a(gs),s&&a(Ba),y(js,s),s&&a(Fa),s&&a(Q),s&&a(Ha),y(ys,s),s&&a(Ra),s&&a(x),s&&a(Ma),s&&a(z),y(_s),s&&a(Ya),s&&a(k),s&&a(Ga),y(bs,s),s&&a(Wa),s&&a(O),y(vs),s&&a(Ja),s&&a(I),y($s),s&&a(Ka),s&&a(P),s&&a(Qa),s&&a(E),s&&a(Va),y(ws,s),s&&a(Xa),s&&a(U),y(ks),s&&a(Za),s&&a(Bs),s&&a(st),y(Es,s),s&&a(at),s&&a(Fs),s&&a(tt),y(Ds,s),s&&a(et),s&&a(as),s&&a(nt),y(qs,s),s&&a(lt),s&&a(D),s&&a(rt),s&&a(B),y(xs),s&&a(pt),s&&a(es),s&&a(ot),y(Ps,s),s&&a(ht),s&&a(ns),s&&a(it),y(As,s),s&&a(ct),s&&a(Hs)}}}const ol={local:"use-with-pytorch",sections:[{local:"tensors",sections:[{local:"dataset-format",title:"Dataset format"},{local:"ndimensional-arrays",title:"N-dimensional arrays"},{local:"other-feature-types",title:"Other feature types"}],title:"Tensors"},{local:"data-loading",sections:[{local:"optimize-data-loading",sections:[{local:"use-multiple-workers",title:"Use multiple Workers"},{local:"use-a-batchsampler",title:"Use a BatchSampler"}],title:"Optimize data loading"},{local:"stream-data",title:"Stream data"}],title:"Data loading"}],title:"Use with PyTorch"};function hl(ka){return nl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ul extends sl{constructor(_){super();al(this,_,hl,pl,tl,{})}}export{ul as default,ol as metadata};
