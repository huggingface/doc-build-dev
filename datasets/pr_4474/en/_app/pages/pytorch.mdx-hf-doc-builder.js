import{S as Fn,i as Hn,s as In,e as n,k as i,w as m,t as o,M as Rn,c as l,d as a,m as c,a as r,x as u,h,b as d,G as t,g as p,y as f,q as g,o as j,B as y,v as Mn}from"../chunks/vendor-hf-doc-builder.js";import{T as Yn}from"../chunks/Tip-hf-doc-builder.js";import{I as A}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as D}from"../chunks/CodeBlock-hf-doc-builder.js";function Gn(_a){let b,H,_,$,S;return{c(){b=n("p"),H=o("A "),_=n("a"),$=o("Dataset"),S=o(" object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),this.h()},l(v){b=l(v,"P",{});var x=r(b);H=h(x,"A "),_=l(x,"A",{href:!0});var I=r(_);$=h(I,"Dataset"),I.forEach(a),S=h(x," object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),x.forEach(a),this.h()},h(){d(_,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset")},m(v,x){p(v,b,x),t(b,H),t(b,_),t(_,$),t(b,S)},d(v){v&&a(b)}}}function Wn(_a){let b,H,_,$,S,v,x,I,_t,va,L,R,Is,ps,vt,Rs,$t,$a,T,M,Ms,os,wt,Ys,kt,wa,As,Et,ka,Y,Dt,Ss,xt,qt,Ea,hs,Da,G,xa,W,Pt,Gs,At,St,qa,is,Pa,N,J,Ws,cs,Lt,Js,Tt,Aa,Ls,Nt,Sa,ds,La,Ts,Ct,Ta,ms,Na,C,K,Ks,us,zt,Qs,Ot,Ca,fs,Ns,Ut,Bt,za,gs,Oa,Q,Ft,Vs,Ht,It,Ua,js,Ba,q,Rt,Cs,Mt,Yt,zs,Gt,Wt,Fa,z,V,Xs,ys,Jt,Zs,Kt,Ha,w,Qt,sa,Vt,Xt,Os,Zt,se,aa,ae,te,Ia,bs,Ra,O,X,ta,_s,ee,ea,ne,Ma,U,Z,na,vs,le,la,re,Ya,P,pe,ra,oe,he,pa,ie,ce,Ga,k,de,oa,me,ue,ha,fe,ge,ia,je,ye,Wa,$s,Ja,B,ss,ca,ws,be,da,_e,Ka,Us,ve,Qa,ks,Va,Bs,$e,Xa,Es,Za,as,we,ma,ke,Ee,st,Ds,at,E,De,ua,xe,qe,fa,Pe,Ae,ga,Se,Le,tt,F,ts,ja,xs,Te,ya,Ne,et,es,Ce,ba,ze,Oe,nt,qs,lt;return v=new A({}),ps=new A({}),os=new A({}),hs=new D({props:{code:`from datasets import Dataset
data = [[1, 2],[3, 4]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("pytorch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}`}}),G=new Yn({props:{$$slots:{default:[Gn]},$$scope:{ctx:_a}}}),is=new D({props:{code:`import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ds = ds.with_format("pytorch", device=device)
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>, device=device)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)}`}}),cs=new A({}),ds=new D({props:{code:`from datasets import Dataset
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("pytorch")
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: [tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]), tensor([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]}`}}),ms=new D({props:{code:`from datasets import Dataset, Features, Array2D
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
features = Features({"data": Array2D(shape=(2, 2), dtype='int32')})
ds = Dataset.from_dict({"data": data}, features=features)
ds = ds.with_format("pytorch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, Array2D
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: Array2D(shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=<span class="hljs-string">&#x27;int32&#x27;</span>)})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
          [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],
 
         [[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],
          [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]])}`}}),us=new A({}),gs=new D({props:{code:`from datasets import Dataset, Features, ClassLabel
data = [0, 0, 1]
features = Features({"data": ClassLabel(names=["negative", "positive"])})
ds = Dataset.from_dict({"data": data}, features=features) 
ds = ds.with_format("pytorch")  
ds[:3]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, ClassLabel
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: ClassLabel(names=[<span class="hljs-string">&quot;negative&quot;</span>, <span class="hljs-string">&quot;positive&quot;</span>])})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">3</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}`}}),js=new D({props:{code:`from datasets import Dataset, Features 
text = ["foo", "bar"]
data = [0, 1] 
ds = Dataset.from_dict({"text": text, "data": data})  
ds = ds.with_format("pytorch", columns=["data"], output_all_columns=True) 
ds[:2]                                                                                                                                                     `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features 
<span class="hljs-meta">&gt;&gt;&gt; </span>text = [<span class="hljs-string">&quot;foo&quot;</span>, <span class="hljs-string">&quot;bar&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;text&quot;</span>: text, <span class="hljs-string">&quot;data&quot;</span>: data})  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>, columns=[<span class="hljs-string">&quot;data&quot;</span>], output_all_columns=<span class="hljs-literal">True</span>) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]                                                                                                                                                     
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;foo&#x27;</span>, <span class="hljs-string">&#x27;bar&#x27;</span>]}`}}),ys=new A({}),bs=new D({props:{code:`import numpy as np
from datasets import Dataset 
from torch.utils.data import DataLoader
data = np.random.rand(16)
label = np.random.randint(0, 2, size=16)
ds = Dataset.from_dict({"data": data, "label": label}).with_format("pytorch")
dataloader = DataLoader(ds, batch_size=4)
for batch in dataloader:
    print(batch)                                                                                            `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>label = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, size=<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data, <span class="hljs-string">&quot;label&quot;</span>: label}).with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> dataloader:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(batch)                                                                                            
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.0047</span>, <span class="hljs-number">0.4979</span>, <span class="hljs-number">0.6726</span>, <span class="hljs-number">0.8105</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.4832</span>, <span class="hljs-number">0.2723</span>, <span class="hljs-number">0.4259</span>, <span class="hljs-number">0.2224</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.5837</span>, <span class="hljs-number">0.3444</span>, <span class="hljs-number">0.4658</span>, <span class="hljs-number">0.6417</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.7022</span>, <span class="hljs-number">0.1225</span>, <span class="hljs-number">0.7228</span>, <span class="hljs-number">0.8259</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])}`}}),_s=new A({}),vs=new A({}),$s=new D({props:{code:`import numpy as np
from datasets import Dataset, load_from_disk
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).save_to_disk("my_dataset")
ds = load_from_disk("my_dataset").with_format("torch")
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_from_disk
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).save_to_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_from_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),ws=new A({}),ks=new D({props:{code:"batch = [dataset[idx] for idx in range(start, end)]",highlighted:'batch = [dataset[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end)]'}}),Es=new D({props:{code:`batch = dataset[start:end]
# or
batch = dataset[list_of_indices]`,highlighted:`batch = dataset[start:end]
<span class="hljs-comment"># or</span>
batch = dataset[list_of_indices]`}}),Ds=new D({props:{code:`from torch.utils.data.sampler import BatchSampler, RandomSampler
sampler = BatchSampler(RandomSampler(ds), batch_size=32, drop_last=False)
dataloader = DataLoader(ds, sampler=sampler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data.sampler <span class="hljs-keyword">import</span> BatchSampler, RandomSampler
<span class="hljs-meta">&gt;&gt;&gt; </span>sampler = BatchSampler(RandomSampler(ds), batch_size=<span class="hljs-number">32</span>, drop_last=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, sampler=sampler)`}}),xs=new A({}),qs=new D({props:{code:`import numpy as np
from datasets import Dataset, load_dataset
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).push_to_hub("<username>/my_dataset")  # Upload to the Hugging Face Hub
ds = load_dataset("<username>/my_dataset", streaming=True, split="train").with_format("torch")
dataloader = DataLoader(ds, batch_size=32)
for batch in dataloader: 
    pass`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).push_to_hub(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)  <span class="hljs-comment"># Upload to the Hugging Face Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> dataloader: 
<span class="hljs-meta">... </span>    <span class="hljs-keyword">pass</span>`}}),{c(){b=n("meta"),H=i(),_=n("h1"),$=n("a"),S=n("span"),m(v.$$.fragment),x=i(),I=n("span"),_t=o("Use with PyTorch"),va=i(),L=n("h2"),R=n("a"),Is=n("span"),m(ps.$$.fragment),vt=i(),Rs=n("span"),$t=o("Tensors"),$a=i(),T=n("h3"),M=n("a"),Ms=n("span"),m(os.$$.fragment),wt=i(),Ys=n("span"),kt=o("Dataset format"),wa=i(),As=n("p"),Et=o("By default, datasets return regular python objects: integers, floats, strings, lists, etc."),ka=i(),Y=n("p"),Dt=o("To get PyTorch tensors instead, you can set the format of the dataset to \u201Cpytorch\u201D using "),Ss=n("a"),xt=o("Dataset.with_format()"),qt=o(":"),Ea=i(),m(hs.$$.fragment),Da=i(),m(G.$$.fragment),xa=i(),W=n("p"),Pt=o("To load the data as tensors on a GPU, you can also specify the "),Gs=n("code"),At=o("device"),St=o(" argument:"),qa=i(),m(is.$$.fragment),Pa=i(),N=n("h3"),J=n("a"),Ws=n("span"),m(cs.$$.fragment),Lt=i(),Js=n("span"),Tt=o("N-dimensional arrays"),Aa=i(),Ls=n("p"),Nt=o(`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of one single tensor:`),Sa=i(),m(ds.$$.fragment),La=i(),Ts=n("p"),Ct=o("To get one single tensor, you must explicitly use the Array feature type and specify the shape of your tensors:"),Ta=i(),m(ms.$$.fragment),Na=i(),C=n("h3"),K=n("a"),Ks=n("span"),m(us.$$.fragment),zt=i(),Qs=n("span"),Ot=o("Other feature types"),Ca=i(),fs=n("p"),Ns=n("a"),Ut=o("ClassLabel"),Bt=o(" data are properly converted to tensors:"),za=i(),m(gs.$$.fragment),Oa=i(),Q=n("p"),Ft=o("However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),Vs=n("code"),Ht=o("string"),It=o(` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),Ua=i(),m(js.$$.fragment),Ba=i(),q=n("p"),Rt=o("The "),Cs=n("a"),Mt=o("Image"),Yt=o(" and "),zs=n("a"),Gt=o("Audio"),Wt=o(" feature types are not supported yet."),Fa=i(),z=n("h2"),V=n("a"),Xs=n("span"),m(ys.$$.fragment),Jt=i(),Zs=n("span"),Kt=o("Data loading"),Ha=i(),w=n("p"),Qt=o("Like "),sa=n("code"),Vt=o("torch.utils.data.Dataset"),Xt=o(" objects, a "),Os=n("a"),Zt=o("Dataset"),se=o(" can be passed directly to a PyTorch "),aa=n("code"),ae=o("DataLoader"),te=o(":"),Ia=i(),m(bs.$$.fragment),Ra=i(),O=n("h3"),X=n("a"),ta=n("span"),m(_s.$$.fragment),ee=i(),ea=n("span"),ne=o("Optimize data loading"),Ma=i(),U=n("h4"),Z=n("a"),na=n("span"),m(vs.$$.fragment),le=i(),la=n("span"),re=o("Use multiple Workers"),Ya=i(),P=n("p"),pe=o("You can parallelize data loading the "),ra=n("code"),oe=o("num_workers"),he=o(" argument of a PyTorch "),pa=n("code"),ie=o("DataLoader"),ce=o(" and get a higher throughput."),Ga=i(),k=n("p"),de=o("Under the hood, the "),oa=n("code"),me=o("DataLoader"),ue=o(" starts "),ha=n("code"),fe=o("num_workers"),ge=o(` processes.
Each process reloads the dataset passed to the `),ia=n("code"),je=o("DataLoader"),ye=o(` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-map the dataset again from your disk.`),Wa=i(),m($s.$$.fragment),Ja=i(),B=n("h4"),ss=n("a"),ca=n("span"),m(ws.$$.fragment),be=i(),da=n("span"),_e=o("Use a BatchSampler"),Ka=i(),Us=n("p"),ve=o("By default the pytorch data loader load batches of data from a dataset one by one like this:"),Qa=i(),m(ks.$$.fragment),Va=i(),Bs=n("p"),$e=o(`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),Xa=i(),m(Es.$$.fragment),Za=i(),as=n("p"),we=o("For the pytorch data loader to query batches using a list, you can use a "),ma=n("code"),ke=o("BatchSampler"),Ee=o(":"),st=i(),m(Ds.$$.fragment),at=i(),E=n("p"),De=o("Moreover, this is particularly useful if you used "),ua=n("code"),xe=o("set_transform"),qe=o(` to apply a transform on-the-fly when examples are accessed.
You must use a `),fa=n("code"),Pe=o("BatchSampler"),Ae=o(" if you want the transform to be given full batches instead of receiving "),ga=n("code"),Se=o("batch_size"),Le=o(" times one single element."),tt=i(),F=n("h3"),ts=n("a"),ja=n("span"),m(xs.$$.fragment),Te=i(),ya=n("span"),Ne=o("Stream data"),et=i(),es=n("p"),Ce=o(`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to \u201Cpytorch\u201D, and it inherits from `),ba=n("code"),ze=o("torch.utils.data.IterableDataset"),Oe=o(" so you can pass it to a DataLoader:"),nt=i(),m(qs.$$.fragment),this.h()},l(s){const e=Rn('[data-svelte="svelte-1phssyn"]',document.head);b=l(e,"META",{name:!0,content:!0}),e.forEach(a),H=c(s),_=l(s,"H1",{class:!0});var Ps=r(_);$=l(Ps,"A",{id:!0,class:!0,href:!0});var Be=r($);S=l(Be,"SPAN",{});var Fe=r(S);u(v.$$.fragment,Fe),Fe.forEach(a),Be.forEach(a),x=c(Ps),I=l(Ps,"SPAN",{});var He=r(I);_t=h(He,"Use with PyTorch"),He.forEach(a),Ps.forEach(a),va=c(s),L=l(s,"H2",{class:!0});var rt=r(L);R=l(rt,"A",{id:!0,class:!0,href:!0});var Ie=r(R);Is=l(Ie,"SPAN",{});var Re=r(Is);u(ps.$$.fragment,Re),Re.forEach(a),Ie.forEach(a),vt=c(rt),Rs=l(rt,"SPAN",{});var Me=r(Rs);$t=h(Me,"Tensors"),Me.forEach(a),rt.forEach(a),$a=c(s),T=l(s,"H3",{class:!0});var pt=r(T);M=l(pt,"A",{id:!0,class:!0,href:!0});var Ye=r(M);Ms=l(Ye,"SPAN",{});var Ge=r(Ms);u(os.$$.fragment,Ge),Ge.forEach(a),Ye.forEach(a),wt=c(pt),Ys=l(pt,"SPAN",{});var We=r(Ys);kt=h(We,"Dataset format"),We.forEach(a),pt.forEach(a),wa=c(s),As=l(s,"P",{});var Je=r(As);Et=h(Je,"By default, datasets return regular python objects: integers, floats, strings, lists, etc."),Je.forEach(a),ka=c(s),Y=l(s,"P",{});var ot=r(Y);Dt=h(ot,"To get PyTorch tensors instead, you can set the format of the dataset to \u201Cpytorch\u201D using "),Ss=l(ot,"A",{href:!0});var Ke=r(Ss);xt=h(Ke,"Dataset.with_format()"),Ke.forEach(a),qt=h(ot,":"),ot.forEach(a),Ea=c(s),u(hs.$$.fragment,s),Da=c(s),u(G.$$.fragment,s),xa=c(s),W=l(s,"P",{});var ht=r(W);Pt=h(ht,"To load the data as tensors on a GPU, you can also specify the "),Gs=l(ht,"CODE",{});var Qe=r(Gs);At=h(Qe,"device"),Qe.forEach(a),St=h(ht," argument:"),ht.forEach(a),qa=c(s),u(is.$$.fragment,s),Pa=c(s),N=l(s,"H3",{class:!0});var it=r(N);J=l(it,"A",{id:!0,class:!0,href:!0});var Ve=r(J);Ws=l(Ve,"SPAN",{});var Xe=r(Ws);u(cs.$$.fragment,Xe),Xe.forEach(a),Ve.forEach(a),Lt=c(it),Js=l(it,"SPAN",{});var Ze=r(Js);Tt=h(Ze,"N-dimensional arrays"),Ze.forEach(a),it.forEach(a),Aa=c(s),Ls=l(s,"P",{});var sn=r(Ls);Nt=h(sn,`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of one single tensor:`),sn.forEach(a),Sa=c(s),u(ds.$$.fragment,s),La=c(s),Ts=l(s,"P",{});var an=r(Ts);Ct=h(an,"To get one single tensor, you must explicitly use the Array feature type and specify the shape of your tensors:"),an.forEach(a),Ta=c(s),u(ms.$$.fragment,s),Na=c(s),C=l(s,"H3",{class:!0});var ct=r(C);K=l(ct,"A",{id:!0,class:!0,href:!0});var tn=r(K);Ks=l(tn,"SPAN",{});var en=r(Ks);u(us.$$.fragment,en),en.forEach(a),tn.forEach(a),zt=c(ct),Qs=l(ct,"SPAN",{});var nn=r(Qs);Ot=h(nn,"Other feature types"),nn.forEach(a),ct.forEach(a),Ca=c(s),fs=l(s,"P",{});var Ue=r(fs);Ns=l(Ue,"A",{href:!0});var ln=r(Ns);Ut=h(ln,"ClassLabel"),ln.forEach(a),Bt=h(Ue," data are properly converted to tensors:"),Ue.forEach(a),za=c(s),u(gs.$$.fragment,s),Oa=c(s),Q=l(s,"P",{});var dt=r(Q);Ft=h(dt,"However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),Vs=l(dt,"CODE",{});var rn=r(Vs);Ht=h(rn,"string"),rn.forEach(a),It=h(dt,` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),dt.forEach(a),Ua=c(s),u(js.$$.fragment,s),Ba=c(s),q=l(s,"P",{});var Fs=r(q);Rt=h(Fs,"The "),Cs=l(Fs,"A",{href:!0});var pn=r(Cs);Mt=h(pn,"Image"),pn.forEach(a),Yt=h(Fs," and "),zs=l(Fs,"A",{href:!0});var on=r(zs);Gt=h(on,"Audio"),on.forEach(a),Wt=h(Fs," feature types are not supported yet."),Fs.forEach(a),Fa=c(s),z=l(s,"H2",{class:!0});var mt=r(z);V=l(mt,"A",{id:!0,class:!0,href:!0});var hn=r(V);Xs=l(hn,"SPAN",{});var cn=r(Xs);u(ys.$$.fragment,cn),cn.forEach(a),hn.forEach(a),Jt=c(mt),Zs=l(mt,"SPAN",{});var dn=r(Zs);Kt=h(dn,"Data loading"),dn.forEach(a),mt.forEach(a),Ha=c(s),w=l(s,"P",{});var ns=r(w);Qt=h(ns,"Like "),sa=l(ns,"CODE",{});var mn=r(sa);Vt=h(mn,"torch.utils.data.Dataset"),mn.forEach(a),Xt=h(ns," objects, a "),Os=l(ns,"A",{href:!0});var un=r(Os);Zt=h(un,"Dataset"),un.forEach(a),se=h(ns," can be passed directly to a PyTorch "),aa=l(ns,"CODE",{});var fn=r(aa);ae=h(fn,"DataLoader"),fn.forEach(a),te=h(ns,":"),ns.forEach(a),Ia=c(s),u(bs.$$.fragment,s),Ra=c(s),O=l(s,"H3",{class:!0});var ut=r(O);X=l(ut,"A",{id:!0,class:!0,href:!0});var gn=r(X);ta=l(gn,"SPAN",{});var jn=r(ta);u(_s.$$.fragment,jn),jn.forEach(a),gn.forEach(a),ee=c(ut),ea=l(ut,"SPAN",{});var yn=r(ea);ne=h(yn,"Optimize data loading"),yn.forEach(a),ut.forEach(a),Ma=c(s),U=l(s,"H4",{class:!0});var ft=r(U);Z=l(ft,"A",{id:!0,class:!0,href:!0});var bn=r(Z);na=l(bn,"SPAN",{});var _n=r(na);u(vs.$$.fragment,_n),_n.forEach(a),bn.forEach(a),le=c(ft),la=l(ft,"SPAN",{});var vn=r(la);re=h(vn,"Use multiple Workers"),vn.forEach(a),ft.forEach(a),Ya=c(s),P=l(s,"P",{});var Hs=r(P);pe=h(Hs,"You can parallelize data loading the "),ra=l(Hs,"CODE",{});var $n=r(ra);oe=h($n,"num_workers"),$n.forEach(a),he=h(Hs," argument of a PyTorch "),pa=l(Hs,"CODE",{});var wn=r(pa);ie=h(wn,"DataLoader"),wn.forEach(a),ce=h(Hs," and get a higher throughput."),Hs.forEach(a),Ga=c(s),k=l(s,"P",{});var ls=r(k);de=h(ls,"Under the hood, the "),oa=l(ls,"CODE",{});var kn=r(oa);me=h(kn,"DataLoader"),kn.forEach(a),ue=h(ls," starts "),ha=l(ls,"CODE",{});var En=r(ha);fe=h(En,"num_workers"),En.forEach(a),ge=h(ls,` processes.
Each process reloads the dataset passed to the `),ia=l(ls,"CODE",{});var Dn=r(ia);je=h(Dn,"DataLoader"),Dn.forEach(a),ye=h(ls,` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-map the dataset again from your disk.`),ls.forEach(a),Wa=c(s),u($s.$$.fragment,s),Ja=c(s),B=l(s,"H4",{class:!0});var gt=r(B);ss=l(gt,"A",{id:!0,class:!0,href:!0});var xn=r(ss);ca=l(xn,"SPAN",{});var qn=r(ca);u(ws.$$.fragment,qn),qn.forEach(a),xn.forEach(a),be=c(gt),da=l(gt,"SPAN",{});var Pn=r(da);_e=h(Pn,"Use a BatchSampler"),Pn.forEach(a),gt.forEach(a),Ka=c(s),Us=l(s,"P",{});var An=r(Us);ve=h(An,"By default the pytorch data loader load batches of data from a dataset one by one like this:"),An.forEach(a),Qa=c(s),u(ks.$$.fragment,s),Va=c(s),Bs=l(s,"P",{});var Sn=r(Bs);$e=h(Sn,`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),Sn.forEach(a),Xa=c(s),u(Es.$$.fragment,s),Za=c(s),as=l(s,"P",{});var jt=r(as);we=h(jt,"For the pytorch data loader to query batches using a list, you can use a "),ma=l(jt,"CODE",{});var Ln=r(ma);ke=h(Ln,"BatchSampler"),Ln.forEach(a),Ee=h(jt,":"),jt.forEach(a),st=c(s),u(Ds.$$.fragment,s),at=c(s),E=l(s,"P",{});var rs=r(E);De=h(rs,"Moreover, this is particularly useful if you used "),ua=l(rs,"CODE",{});var Tn=r(ua);xe=h(Tn,"set_transform"),Tn.forEach(a),qe=h(rs,` to apply a transform on-the-fly when examples are accessed.
You must use a `),fa=l(rs,"CODE",{});var Nn=r(fa);Pe=h(Nn,"BatchSampler"),Nn.forEach(a),Ae=h(rs," if you want the transform to be given full batches instead of receiving "),ga=l(rs,"CODE",{});var Cn=r(ga);Se=h(Cn,"batch_size"),Cn.forEach(a),Le=h(rs," times one single element."),rs.forEach(a),tt=c(s),F=l(s,"H3",{class:!0});var yt=r(F);ts=l(yt,"A",{id:!0,class:!0,href:!0});var zn=r(ts);ja=l(zn,"SPAN",{});var On=r(ja);u(xs.$$.fragment,On),On.forEach(a),zn.forEach(a),Te=c(yt),ya=l(yt,"SPAN",{});var Un=r(ya);Ne=h(Un,"Stream data"),Un.forEach(a),yt.forEach(a),et=c(s),es=l(s,"P",{});var bt=r(es);Ce=h(bt,`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to \u201Cpytorch\u201D, and it inherits from `),ba=l(bt,"CODE",{});var Bn=r(ba);ze=h(Bn,"torch.utils.data.IterableDataset"),Bn.forEach(a),Oe=h(bt," so you can pass it to a DataLoader:"),bt.forEach(a),nt=c(s),u(qs.$$.fragment,s),this.h()},h(){d(b,"name","hf:doc:metadata"),d(b,"content",JSON.stringify(Jn)),d($,"id","use-with-pytorch"),d($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($,"href","#use-with-pytorch"),d(_,"class","relative group"),d(R,"id","tensors"),d(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(R,"href","#tensors"),d(L,"class","relative group"),d(M,"id","dataset-format"),d(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(M,"href","#dataset-format"),d(T,"class","relative group"),d(Ss,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset.with_format"),d(J,"id","ndimensional-arrays"),d(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J,"href","#ndimensional-arrays"),d(N,"class","relative group"),d(K,"id","other-feature-types"),d(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K,"href","#other-feature-types"),d(C,"class","relative group"),d(Ns,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.ClassLabel"),d(Cs,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Image"),d(zs,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Audio"),d(V,"id","data-loading"),d(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(V,"href","#data-loading"),d(z,"class","relative group"),d(Os,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset"),d(X,"id","optimize-data-loading"),d(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X,"href","#optimize-data-loading"),d(O,"class","relative group"),d(Z,"id","use-multiple-workers"),d(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Z,"href","#use-multiple-workers"),d(U,"class","relative group"),d(ss,"id","use-a-batchsampler"),d(ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ss,"href","#use-a-batchsampler"),d(B,"class","relative group"),d(ts,"id","stream-data"),d(ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ts,"href","#stream-data"),d(F,"class","relative group")},m(s,e){t(document.head,b),p(s,H,e),p(s,_,e),t(_,$),t($,S),f(v,S,null),t(_,x),t(_,I),t(I,_t),p(s,va,e),p(s,L,e),t(L,R),t(R,Is),f(ps,Is,null),t(L,vt),t(L,Rs),t(Rs,$t),p(s,$a,e),p(s,T,e),t(T,M),t(M,Ms),f(os,Ms,null),t(T,wt),t(T,Ys),t(Ys,kt),p(s,wa,e),p(s,As,e),t(As,Et),p(s,ka,e),p(s,Y,e),t(Y,Dt),t(Y,Ss),t(Ss,xt),t(Y,qt),p(s,Ea,e),f(hs,s,e),p(s,Da,e),f(G,s,e),p(s,xa,e),p(s,W,e),t(W,Pt),t(W,Gs),t(Gs,At),t(W,St),p(s,qa,e),f(is,s,e),p(s,Pa,e),p(s,N,e),t(N,J),t(J,Ws),f(cs,Ws,null),t(N,Lt),t(N,Js),t(Js,Tt),p(s,Aa,e),p(s,Ls,e),t(Ls,Nt),p(s,Sa,e),f(ds,s,e),p(s,La,e),p(s,Ts,e),t(Ts,Ct),p(s,Ta,e),f(ms,s,e),p(s,Na,e),p(s,C,e),t(C,K),t(K,Ks),f(us,Ks,null),t(C,zt),t(C,Qs),t(Qs,Ot),p(s,Ca,e),p(s,fs,e),t(fs,Ns),t(Ns,Ut),t(fs,Bt),p(s,za,e),f(gs,s,e),p(s,Oa,e),p(s,Q,e),t(Q,Ft),t(Q,Vs),t(Vs,Ht),t(Q,It),p(s,Ua,e),f(js,s,e),p(s,Ba,e),p(s,q,e),t(q,Rt),t(q,Cs),t(Cs,Mt),t(q,Yt),t(q,zs),t(zs,Gt),t(q,Wt),p(s,Fa,e),p(s,z,e),t(z,V),t(V,Xs),f(ys,Xs,null),t(z,Jt),t(z,Zs),t(Zs,Kt),p(s,Ha,e),p(s,w,e),t(w,Qt),t(w,sa),t(sa,Vt),t(w,Xt),t(w,Os),t(Os,Zt),t(w,se),t(w,aa),t(aa,ae),t(w,te),p(s,Ia,e),f(bs,s,e),p(s,Ra,e),p(s,O,e),t(O,X),t(X,ta),f(_s,ta,null),t(O,ee),t(O,ea),t(ea,ne),p(s,Ma,e),p(s,U,e),t(U,Z),t(Z,na),f(vs,na,null),t(U,le),t(U,la),t(la,re),p(s,Ya,e),p(s,P,e),t(P,pe),t(P,ra),t(ra,oe),t(P,he),t(P,pa),t(pa,ie),t(P,ce),p(s,Ga,e),p(s,k,e),t(k,de),t(k,oa),t(oa,me),t(k,ue),t(k,ha),t(ha,fe),t(k,ge),t(k,ia),t(ia,je),t(k,ye),p(s,Wa,e),f($s,s,e),p(s,Ja,e),p(s,B,e),t(B,ss),t(ss,ca),f(ws,ca,null),t(B,be),t(B,da),t(da,_e),p(s,Ka,e),p(s,Us,e),t(Us,ve),p(s,Qa,e),f(ks,s,e),p(s,Va,e),p(s,Bs,e),t(Bs,$e),p(s,Xa,e),f(Es,s,e),p(s,Za,e),p(s,as,e),t(as,we),t(as,ma),t(ma,ke),t(as,Ee),p(s,st,e),f(Ds,s,e),p(s,at,e),p(s,E,e),t(E,De),t(E,ua),t(ua,xe),t(E,qe),t(E,fa),t(fa,Pe),t(E,Ae),t(E,ga),t(ga,Se),t(E,Le),p(s,tt,e),p(s,F,e),t(F,ts),t(ts,ja),f(xs,ja,null),t(F,Te),t(F,ya),t(ya,Ne),p(s,et,e),p(s,es,e),t(es,Ce),t(es,ba),t(ba,ze),t(es,Oe),p(s,nt,e),f(qs,s,e),lt=!0},p(s,[e]){const Ps={};e&2&&(Ps.$$scope={dirty:e,ctx:s}),G.$set(Ps)},i(s){lt||(g(v.$$.fragment,s),g(ps.$$.fragment,s),g(os.$$.fragment,s),g(hs.$$.fragment,s),g(G.$$.fragment,s),g(is.$$.fragment,s),g(cs.$$.fragment,s),g(ds.$$.fragment,s),g(ms.$$.fragment,s),g(us.$$.fragment,s),g(gs.$$.fragment,s),g(js.$$.fragment,s),g(ys.$$.fragment,s),g(bs.$$.fragment,s),g(_s.$$.fragment,s),g(vs.$$.fragment,s),g($s.$$.fragment,s),g(ws.$$.fragment,s),g(ks.$$.fragment,s),g(Es.$$.fragment,s),g(Ds.$$.fragment,s),g(xs.$$.fragment,s),g(qs.$$.fragment,s),lt=!0)},o(s){j(v.$$.fragment,s),j(ps.$$.fragment,s),j(os.$$.fragment,s),j(hs.$$.fragment,s),j(G.$$.fragment,s),j(is.$$.fragment,s),j(cs.$$.fragment,s),j(ds.$$.fragment,s),j(ms.$$.fragment,s),j(us.$$.fragment,s),j(gs.$$.fragment,s),j(js.$$.fragment,s),j(ys.$$.fragment,s),j(bs.$$.fragment,s),j(_s.$$.fragment,s),j(vs.$$.fragment,s),j($s.$$.fragment,s),j(ws.$$.fragment,s),j(ks.$$.fragment,s),j(Es.$$.fragment,s),j(Ds.$$.fragment,s),j(xs.$$.fragment,s),j(qs.$$.fragment,s),lt=!1},d(s){a(b),s&&a(H),s&&a(_),y(v),s&&a(va),s&&a(L),y(ps),s&&a($a),s&&a(T),y(os),s&&a(wa),s&&a(As),s&&a(ka),s&&a(Y),s&&a(Ea),y(hs,s),s&&a(Da),y(G,s),s&&a(xa),s&&a(W),s&&a(qa),y(is,s),s&&a(Pa),s&&a(N),y(cs),s&&a(Aa),s&&a(Ls),s&&a(Sa),y(ds,s),s&&a(La),s&&a(Ts),s&&a(Ta),y(ms,s),s&&a(Na),s&&a(C),y(us),s&&a(Ca),s&&a(fs),s&&a(za),y(gs,s),s&&a(Oa),s&&a(Q),s&&a(Ua),y(js,s),s&&a(Ba),s&&a(q),s&&a(Fa),s&&a(z),y(ys),s&&a(Ha),s&&a(w),s&&a(Ia),y(bs,s),s&&a(Ra),s&&a(O),y(_s),s&&a(Ma),s&&a(U),y(vs),s&&a(Ya),s&&a(P),s&&a(Ga),s&&a(k),s&&a(Wa),y($s,s),s&&a(Ja),s&&a(B),y(ws),s&&a(Ka),s&&a(Us),s&&a(Qa),y(ks,s),s&&a(Va),s&&a(Bs),s&&a(Xa),y(Es,s),s&&a(Za),s&&a(as),s&&a(st),y(Ds,s),s&&a(at),s&&a(E),s&&a(tt),s&&a(F),y(xs),s&&a(et),s&&a(es),s&&a(nt),y(qs,s)}}}const Jn={local:"use-with-pytorch",sections:[{local:"tensors",sections:[{local:"dataset-format",title:"Dataset format"},{local:"ndimensional-arrays",title:"N-dimensional arrays"},{local:"other-feature-types",title:"Other feature types"}],title:"Tensors"},{local:"data-loading",sections:[{local:"optimize-data-loading",sections:[{local:"use-multiple-workers",title:"Use multiple Workers"},{local:"use-a-batchsampler",title:"Use a BatchSampler"}],title:"Optimize data loading"},{local:"stream-data",title:"Stream data"}],title:"Data loading"}],title:"Use with PyTorch"};function Kn(_a){return Mn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class sl extends Fn{constructor(b){super();Hn(this,b,Kn,Wn,In,{})}}export{sl as default,Jn as metadata};
