import{S as kl,i as El,s as Dl,e as n,k as i,w as m,t as o,M as ql,c as l,d as a,m as c,a as r,x as u,h as p,b as d,G as t,g as h,y as f,q as g,o as j,B as _,v as xl}from"../chunks/vendor-hf-doc-builder.js";import{T as Pl}from"../chunks/Tip-hf-doc-builder.js";import{I as T}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as $}from"../chunks/CodeBlock-hf-doc-builder.js";function Al(Ta){let y,M,b,w,C;return{c(){y=n("p"),M=o("A "),b=n("a"),w=o("Dataset"),C=o(" object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),this.h()},l(v){y=l(v,"P",{});var x=r(y);M=p(x,"A "),b=l(x,"A",{href:!0});var Y=r(b);w=p(Y,"Dataset"),Y.forEach(a),C=p(x," object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),x.forEach(a),this.h()},h(){d(b,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset")},m(v,x){h(v,y,x),t(y,M),t(y,b),t(b,w),t(y,C)},d(v){v&&a(y)}}}function Sl(Ta){let y,M,b,w,C,v,x,Y,Nt,Ca,O,G,Ks,cs,zt,Qs,It,Oa,N,J,Vs,ds,Ut,Ws,Bt,Na,Os,Ft,za,P,Ht,Xs,Rt,Mt,Ns,Yt,Gt,Ia,ms,Ua,K,Ba,Q,Jt,Zs,Kt,Qt,Fa,us,Ha,z,V,sa,fs,Vt,aa,Wt,Ra,zs,Xt,Ma,gs,Ya,W,Zt,ta,se,ae,Ga,js,Ja,I,X,ea,_s,te,na,ee,Ka,ys,Is,ne,le,Qa,bs,Va,Z,re,la,oe,pe,Wa,vs,Xa,A,he,Us,ie,ce,Bs,de,me,Za,U,ss,ra,$s,ue,oa,fe,st,k,ge,pa,je,_e,Fs,ye,be,ha,ve,$e,at,ws,tt,B,as,ia,ks,we,ca,ke,et,F,ts,da,Es,Ee,ma,De,nt,S,qe,ua,xe,Pe,fa,Ae,Se,lt,E,Le,ga,Te,Ce,ja,Oe,Ne,_a,ze,Ie,rt,Ds,ot,H,es,ya,qs,Ue,ba,Be,pt,ns,Fe,va,He,Re,ht,xs,it,Hs,Me,ct,Ps,dt,L,Ye,$a,Ge,Je,wa,Ke,Qe,mt,As,ut,D,Ve,ka,We,Xe,Ea,Ze,sn,Da,an,tn,ft,R,ls,qa,Ss,en,xa,nn,gt,q,ln,Pa,rn,on,Aa,pn,hn,Sa,cn,dn,jt,Ls,_t,rs,mn,La,un,fn,yt,Ts,bt,Rs,gn,vt;return v=new T({}),cs=new T({}),ds=new T({}),ms=new $({props:{code:`from datasets import Dataset
data = [[1, 2],[3, 4]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("pytorch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}`}}),K=new Pl({props:{$$slots:{default:[Al]},$$scope:{ctx:Ta}}}),us=new $({props:{code:`import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ds = ds.with_format("pytorch", device=device)
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>, device=device)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)}`}}),fs=new T({}),gs=new $({props:{code:`from datasets import Dataset
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("pytorch")
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: [tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]), tensor([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]}`}}),js=new $({props:{code:`from datasets import Dataset, Features, Array2D
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
features = Features({"data": Array2D(shape=(2, 2), dtype='int32')})
ds = Dataset.from_dict({"data": data}, features=features)
ds = ds.with_format("pytorch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, Array2D
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: Array2D(shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=<span class="hljs-string">&#x27;int32&#x27;</span>)})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
          [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],
 
         [[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],
          [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]])}`}}),_s=new T({}),bs=new $({props:{code:`from datasets import Dataset, Features, ClassLabel
data = [0, 0, 1]
features = Features({"data": ClassLabel(names=["negative", "positive"])})
ds = Dataset.from_dict({"data": data}, features=features) 
ds = ds.with_format("pytorch")  
ds[:3]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, ClassLabel
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: ClassLabel(names=[<span class="hljs-string">&quot;negative&quot;</span>, <span class="hljs-string">&quot;positive&quot;</span>])})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">3</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}`}}),vs=new $({props:{code:`from datasets import Dataset, Features 
text = ["foo", "bar"]
data = [0, 1] 
ds = Dataset.from_dict({"text": text, "data": data})  
ds = ds.with_format("pytorch", columns=["data"], output_all_columns=True) 
ds[:2]                                                                                                                                                     `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features 
<span class="hljs-meta">&gt;&gt;&gt; </span>text = [<span class="hljs-string">&quot;foo&quot;</span>, <span class="hljs-string">&quot;bar&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;text&quot;</span>: text, <span class="hljs-string">&quot;data&quot;</span>: data})  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;pytorch&quot;</span>, columns=[<span class="hljs-string">&quot;data&quot;</span>], output_all_columns=<span class="hljs-literal">True</span>) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]                                                                                                                                                     
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;foo&#x27;</span>, <span class="hljs-string">&#x27;bar&#x27;</span>]}`}}),$s=new T({}),ws=new $({props:{code:`import numpy as np
from datasets import Dataset 
from torch.utils.data import DataLoader
data = np.random.rand(16)
label = np.random.randint(0, 2, size=16)
ds = Dataset.from_dict({"data": data, "label": label}).with_format("pytorch")
dataloader = DataLoader(ds, batch_size=4)
for batch in dataloader:
    print(batch)                                                                                            `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>label = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, size=<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data, <span class="hljs-string">&quot;label&quot;</span>: label}).with_format(<span class="hljs-string">&quot;pytorch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> dataloader:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(batch)                                                                                            
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.0047</span>, <span class="hljs-number">0.4979</span>, <span class="hljs-number">0.6726</span>, <span class="hljs-number">0.8105</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.4832</span>, <span class="hljs-number">0.2723</span>, <span class="hljs-number">0.4259</span>, <span class="hljs-number">0.2224</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.5837</span>, <span class="hljs-number">0.3444</span>, <span class="hljs-number">0.4658</span>, <span class="hljs-number">0.6417</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.7022</span>, <span class="hljs-number">0.1225</span>, <span class="hljs-number">0.7228</span>, <span class="hljs-number">0.8259</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])}`}}),ks=new T({}),Es=new T({}),Ds=new $({props:{code:`import numpy as np
from datasets import Dataset, load_from_disk
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).save_to_disk("my_dataset")
ds = load_from_disk("my_dataset").with_format("torch")
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_from_disk
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).save_to_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_from_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),qs=new T({}),xs=new $({props:{code:"batch = [dataset[idx] for idx in range(start, end)]",highlighted:'batch = [dataset[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end)]'}}),Ps=new $({props:{code:`batch = dataset[start:end]
# or
batch = dataset[list_of_indices]`,highlighted:`batch = dataset[start:end]
<span class="hljs-comment"># or</span>
batch = dataset[list_of_indices]`}}),As=new $({props:{code:`from torch.utils.data.sampler import BatchSampler, RandomSampler
sampler = BatchSampler(RandomSampler(ds), batch_size=32, drop_last=False)
dataloader = DataLoader(ds, sampler=sampler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data.sampler <span class="hljs-keyword">import</span> BatchSampler, RandomSampler
<span class="hljs-meta">&gt;&gt;&gt; </span>sampler = BatchSampler(RandomSampler(ds), batch_size=<span class="hljs-number">32</span>, drop_last=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, sampler=sampler)`}}),Ss=new T({}),Ls=new $({props:{code:`import numpy as np
from datasets import Dataset, load_dataset
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).push_to_hub("<username>/my_dataset")  # Upload to the Hugging Face Hub
ds = load_dataset("<username>/my_dataset", streaming=True, split="train").with_format("torch")
dataloader = DataLoader(ds, batch_size=32)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).push_to_hub(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)  <span class="hljs-comment"># Upload to the Hugging Face Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>)`}}),Ts=new $({props:{code:`ds = load_dataset("c4", "en", streaming=True, split="train").with_format("torch")
ds.n_shards
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;c4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds.n_shards
<span class="hljs-number">1024</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),{c(){y=n("meta"),M=i(),b=n("h1"),w=n("a"),C=n("span"),m(v.$$.fragment),x=i(),Y=n("span"),Nt=o("Use with PyTorch"),Ca=i(),O=n("h2"),G=n("a"),Ks=n("span"),m(cs.$$.fragment),zt=i(),Qs=n("span"),It=o("Tensors"),Oa=i(),N=n("h3"),J=n("a"),Vs=n("span"),m(ds.$$.fragment),Ut=i(),Ws=n("span"),Bt=o("Dataset format"),Na=i(),Os=n("p"),Ft=o("By default, datasets return regular python objects: integers, floats, strings, lists, etc."),za=i(),P=n("p"),Ht=o("To get PyTorch tensors instead, you can set the format of the dataset to "),Xs=n("code"),Rt=o("pytorch"),Mt=o(" using "),Ns=n("a"),Yt=o("Dataset.with_format()"),Gt=o(":"),Ia=i(),m(ms.$$.fragment),Ua=i(),m(K.$$.fragment),Ba=i(),Q=n("p"),Jt=o("To load the data as tensors on a GPU, specify the "),Zs=n("code"),Kt=o("device"),Qt=o(" argument:"),Fa=i(),m(us.$$.fragment),Ha=i(),z=n("h3"),V=n("a"),sa=n("span"),m(fs.$$.fragment),Vt=i(),aa=n("span"),Wt=o("N-dimensional arrays"),Ra=i(),zs=n("p"),Xt=o(`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of a single tensor:`),Ma=i(),m(gs.$$.fragment),Ya=i(),W=n("p"),Zt=o("To get a single tensor, you must explicitly use the "),ta=n("code"),se=o("Array"),ae=o(" feature type and specify the shape of your tensors:"),Ga=i(),m(js.$$.fragment),Ja=i(),I=n("h3"),X=n("a"),ea=n("span"),m(_s.$$.fragment),te=i(),na=n("span"),ee=o("Other feature types"),Ka=i(),ys=n("p"),Is=n("a"),ne=o("ClassLabel"),le=o(" data are properly converted to tensors:"),Qa=i(),m(bs.$$.fragment),Va=i(),Z=n("p"),re=o("However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),la=n("code"),oe=o("string"),pe=o(` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),Wa=i(),m(vs.$$.fragment),Xa=i(),A=n("p"),he=o("The "),Us=n("a"),ie=o("Image"),ce=o(" and "),Bs=n("a"),de=o("Audio"),me=o(" feature types are not supported yet."),Za=i(),U=n("h2"),ss=n("a"),ra=n("span"),m($s.$$.fragment),ue=i(),oa=n("span"),fe=o("Data loading"),st=i(),k=n("p"),ge=o("Like "),pa=n("code"),je=o("torch.utils.data.Dataset"),_e=o(" objects, a "),Fs=n("a"),ye=o("Dataset"),be=o(" can be passed directly to a PyTorch "),ha=n("code"),ve=o("DataLoader"),$e=o(":"),at=i(),m(ws.$$.fragment),tt=i(),B=n("h3"),as=n("a"),ia=n("span"),m(ks.$$.fragment),we=i(),ca=n("span"),ke=o("Optimize data loading"),et=i(),F=n("h4"),ts=n("a"),da=n("span"),m(Es.$$.fragment),Ee=i(),ma=n("span"),De=o("Use multiple workers"),nt=i(),S=n("p"),qe=o("You can parallelize data loading with the "),ua=n("code"),xe=o("num_workers"),Pe=o(" argument of a PyTorch "),fa=n("code"),Ae=o("DataLoader"),Se=o(" and get a higher throughput."),lt=i(),E=n("p"),Le=o("Under the hood, the "),ga=n("code"),Te=o("DataLoader"),Ce=o(" starts "),ja=n("code"),Oe=o("num_workers"),Ne=o(` processes.
Each process reloads the dataset passed to the `),_a=n("code"),ze=o("DataLoader"),Ie=o(` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-maps the dataset again from your disk.`),rt=i(),m(Ds.$$.fragment),ot=i(),H=n("h4"),es=n("a"),ya=n("span"),m(qs.$$.fragment),Ue=i(),ba=n("span"),Be=o("Use a BatchSampler"),pt=i(),ns=n("p"),Fe=o("By default, the PyTorch "),va=n("code"),He=o("DataLoader"),Re=o(" load batches of data from a dataset one by one like this:"),ht=i(),m(xs.$$.fragment),it=i(),Hs=n("p"),Me=o(`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),ct=i(),m(Ps.$$.fragment),dt=i(),L=n("p"),Ye=o("For the PyTorch "),$a=n("code"),Ge=o("DataLoader"),Je=o(" to query batches using a list, you can use a "),wa=n("code"),Ke=o("BatchSampler"),Qe=o(":"),mt=i(),m(As.$$.fragment),ut=i(),D=n("p"),Ve=o("Moreover, this is particularly useful if you used "),ka=n("code"),We=o("set_transform"),Xe=o(` to apply a transform on-the-fly when examples are accessed.
You must use a `),Ea=n("code"),Ze=o("BatchSampler"),sn=o(" if you want the transform to be given full batches instead of receiving "),Da=n("code"),an=o("batch_size"),tn=o(" times one single element."),ft=i(),R=n("h3"),ls=n("a"),qa=n("span"),m(Ss.$$.fragment),en=i(),xa=n("span"),nn=o("Stream data"),gt=i(),q=n("p"),ln=o(`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to `),Pa=n("code"),rn=o("pytorch"),on=o(", and it inherits from "),Aa=n("code"),pn=o("torch.utils.data.IterableDataset"),hn=o(" so you can pass it to a "),Sa=n("code"),cn=o("DataLoader"),dn=o(":"),jt=i(),m(Ls.$$.fragment),_t=i(),rs=n("p"),mn=o("If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),La=n("code"),un=o("num_workers"),fn=o(":"),yt=i(),m(Ts.$$.fragment),bt=i(),Rs=n("p"),gn=o("In this case each worker will be given a subset of the list of shards to stream from."),this.h()},l(s){const e=ql('[data-svelte="svelte-1phssyn"]',document.head);y=l(e,"META",{name:!0,content:!0}),e.forEach(a),M=c(s),b=l(s,"H1",{class:!0});var Cs=r(b);w=l(Cs,"A",{id:!0,class:!0,href:!0});var _n=r(w);C=l(_n,"SPAN",{});var yn=r(C);u(v.$$.fragment,yn),yn.forEach(a),_n.forEach(a),x=c(Cs),Y=l(Cs,"SPAN",{});var bn=r(Y);Nt=p(bn,"Use with PyTorch"),bn.forEach(a),Cs.forEach(a),Ca=c(s),O=l(s,"H2",{class:!0});var $t=r(O);G=l($t,"A",{id:!0,class:!0,href:!0});var vn=r(G);Ks=l(vn,"SPAN",{});var $n=r(Ks);u(cs.$$.fragment,$n),$n.forEach(a),vn.forEach(a),zt=c($t),Qs=l($t,"SPAN",{});var wn=r(Qs);It=p(wn,"Tensors"),wn.forEach(a),$t.forEach(a),Oa=c(s),N=l(s,"H3",{class:!0});var wt=r(N);J=l(wt,"A",{id:!0,class:!0,href:!0});var kn=r(J);Vs=l(kn,"SPAN",{});var En=r(Vs);u(ds.$$.fragment,En),En.forEach(a),kn.forEach(a),Ut=c(wt),Ws=l(wt,"SPAN",{});var Dn=r(Ws);Bt=p(Dn,"Dataset format"),Dn.forEach(a),wt.forEach(a),Na=c(s),Os=l(s,"P",{});var qn=r(Os);Ft=p(qn,"By default, datasets return regular python objects: integers, floats, strings, lists, etc."),qn.forEach(a),za=c(s),P=l(s,"P",{});var Ms=r(P);Ht=p(Ms,"To get PyTorch tensors instead, you can set the format of the dataset to "),Xs=l(Ms,"CODE",{});var xn=r(Xs);Rt=p(xn,"pytorch"),xn.forEach(a),Mt=p(Ms," using "),Ns=l(Ms,"A",{href:!0});var Pn=r(Ns);Yt=p(Pn,"Dataset.with_format()"),Pn.forEach(a),Gt=p(Ms,":"),Ms.forEach(a),Ia=c(s),u(ms.$$.fragment,s),Ua=c(s),u(K.$$.fragment,s),Ba=c(s),Q=l(s,"P",{});var kt=r(Q);Jt=p(kt,"To load the data as tensors on a GPU, specify the "),Zs=l(kt,"CODE",{});var An=r(Zs);Kt=p(An,"device"),An.forEach(a),Qt=p(kt," argument:"),kt.forEach(a),Fa=c(s),u(us.$$.fragment,s),Ha=c(s),z=l(s,"H3",{class:!0});var Et=r(z);V=l(Et,"A",{id:!0,class:!0,href:!0});var Sn=r(V);sa=l(Sn,"SPAN",{});var Ln=r(sa);u(fs.$$.fragment,Ln),Ln.forEach(a),Sn.forEach(a),Vt=c(Et),aa=l(Et,"SPAN",{});var Tn=r(aa);Wt=p(Tn,"N-dimensional arrays"),Tn.forEach(a),Et.forEach(a),Ra=c(s),zs=l(s,"P",{});var Cn=r(zs);Xt=p(Cn,`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of a single tensor:`),Cn.forEach(a),Ma=c(s),u(gs.$$.fragment,s),Ya=c(s),W=l(s,"P",{});var Dt=r(W);Zt=p(Dt,"To get a single tensor, you must explicitly use the "),ta=l(Dt,"CODE",{});var On=r(ta);se=p(On,"Array"),On.forEach(a),ae=p(Dt," feature type and specify the shape of your tensors:"),Dt.forEach(a),Ga=c(s),u(js.$$.fragment,s),Ja=c(s),I=l(s,"H3",{class:!0});var qt=r(I);X=l(qt,"A",{id:!0,class:!0,href:!0});var Nn=r(X);ea=l(Nn,"SPAN",{});var zn=r(ea);u(_s.$$.fragment,zn),zn.forEach(a),Nn.forEach(a),te=c(qt),na=l(qt,"SPAN",{});var In=r(na);ee=p(In,"Other feature types"),In.forEach(a),qt.forEach(a),Ka=c(s),ys=l(s,"P",{});var jn=r(ys);Is=l(jn,"A",{href:!0});var Un=r(Is);ne=p(Un,"ClassLabel"),Un.forEach(a),le=p(jn," data are properly converted to tensors:"),jn.forEach(a),Qa=c(s),u(bs.$$.fragment,s),Va=c(s),Z=l(s,"P",{});var xt=r(Z);re=p(xt,"However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),la=l(xt,"CODE",{});var Bn=r(la);oe=p(Bn,"string"),Bn.forEach(a),pe=p(xt,` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),xt.forEach(a),Wa=c(s),u(vs.$$.fragment,s),Xa=c(s),A=l(s,"P",{});var Ys=r(A);he=p(Ys,"The "),Us=l(Ys,"A",{href:!0});var Fn=r(Us);ie=p(Fn,"Image"),Fn.forEach(a),ce=p(Ys," and "),Bs=l(Ys,"A",{href:!0});var Hn=r(Bs);de=p(Hn,"Audio"),Hn.forEach(a),me=p(Ys," feature types are not supported yet."),Ys.forEach(a),Za=c(s),U=l(s,"H2",{class:!0});var Pt=r(U);ss=l(Pt,"A",{id:!0,class:!0,href:!0});var Rn=r(ss);ra=l(Rn,"SPAN",{});var Mn=r(ra);u($s.$$.fragment,Mn),Mn.forEach(a),Rn.forEach(a),ue=c(Pt),oa=l(Pt,"SPAN",{});var Yn=r(oa);fe=p(Yn,"Data loading"),Yn.forEach(a),Pt.forEach(a),st=c(s),k=l(s,"P",{});var os=r(k);ge=p(os,"Like "),pa=l(os,"CODE",{});var Gn=r(pa);je=p(Gn,"torch.utils.data.Dataset"),Gn.forEach(a),_e=p(os," objects, a "),Fs=l(os,"A",{href:!0});var Jn=r(Fs);ye=p(Jn,"Dataset"),Jn.forEach(a),be=p(os," can be passed directly to a PyTorch "),ha=l(os,"CODE",{});var Kn=r(ha);ve=p(Kn,"DataLoader"),Kn.forEach(a),$e=p(os,":"),os.forEach(a),at=c(s),u(ws.$$.fragment,s),tt=c(s),B=l(s,"H3",{class:!0});var At=r(B);as=l(At,"A",{id:!0,class:!0,href:!0});var Qn=r(as);ia=l(Qn,"SPAN",{});var Vn=r(ia);u(ks.$$.fragment,Vn),Vn.forEach(a),Qn.forEach(a),we=c(At),ca=l(At,"SPAN",{});var Wn=r(ca);ke=p(Wn,"Optimize data loading"),Wn.forEach(a),At.forEach(a),et=c(s),F=l(s,"H4",{class:!0});var St=r(F);ts=l(St,"A",{id:!0,class:!0,href:!0});var Xn=r(ts);da=l(Xn,"SPAN",{});var Zn=r(da);u(Es.$$.fragment,Zn),Zn.forEach(a),Xn.forEach(a),Ee=c(St),ma=l(St,"SPAN",{});var sl=r(ma);De=p(sl,"Use multiple workers"),sl.forEach(a),St.forEach(a),nt=c(s),S=l(s,"P",{});var Gs=r(S);qe=p(Gs,"You can parallelize data loading with the "),ua=l(Gs,"CODE",{});var al=r(ua);xe=p(al,"num_workers"),al.forEach(a),Pe=p(Gs," argument of a PyTorch "),fa=l(Gs,"CODE",{});var tl=r(fa);Ae=p(tl,"DataLoader"),tl.forEach(a),Se=p(Gs," and get a higher throughput."),Gs.forEach(a),lt=c(s),E=l(s,"P",{});var ps=r(E);Le=p(ps,"Under the hood, the "),ga=l(ps,"CODE",{});var el=r(ga);Te=p(el,"DataLoader"),el.forEach(a),Ce=p(ps," starts "),ja=l(ps,"CODE",{});var nl=r(ja);Oe=p(nl,"num_workers"),nl.forEach(a),Ne=p(ps,` processes.
Each process reloads the dataset passed to the `),_a=l(ps,"CODE",{});var ll=r(_a);ze=p(ll,"DataLoader"),ll.forEach(a),Ie=p(ps,` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-maps the dataset again from your disk.`),ps.forEach(a),rt=c(s),u(Ds.$$.fragment,s),ot=c(s),H=l(s,"H4",{class:!0});var Lt=r(H);es=l(Lt,"A",{id:!0,class:!0,href:!0});var rl=r(es);ya=l(rl,"SPAN",{});var ol=r(ya);u(qs.$$.fragment,ol),ol.forEach(a),rl.forEach(a),Ue=c(Lt),ba=l(Lt,"SPAN",{});var pl=r(ba);Be=p(pl,"Use a BatchSampler"),pl.forEach(a),Lt.forEach(a),pt=c(s),ns=l(s,"P",{});var Tt=r(ns);Fe=p(Tt,"By default, the PyTorch "),va=l(Tt,"CODE",{});var hl=r(va);He=p(hl,"DataLoader"),hl.forEach(a),Re=p(Tt," load batches of data from a dataset one by one like this:"),Tt.forEach(a),ht=c(s),u(xs.$$.fragment,s),it=c(s),Hs=l(s,"P",{});var il=r(Hs);Me=p(il,`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),il.forEach(a),ct=c(s),u(Ps.$$.fragment,s),dt=c(s),L=l(s,"P",{});var Js=r(L);Ye=p(Js,"For the PyTorch "),$a=l(Js,"CODE",{});var cl=r($a);Ge=p(cl,"DataLoader"),cl.forEach(a),Je=p(Js," to query batches using a list, you can use a "),wa=l(Js,"CODE",{});var dl=r(wa);Ke=p(dl,"BatchSampler"),dl.forEach(a),Qe=p(Js,":"),Js.forEach(a),mt=c(s),u(As.$$.fragment,s),ut=c(s),D=l(s,"P",{});var hs=r(D);Ve=p(hs,"Moreover, this is particularly useful if you used "),ka=l(hs,"CODE",{});var ml=r(ka);We=p(ml,"set_transform"),ml.forEach(a),Xe=p(hs,` to apply a transform on-the-fly when examples are accessed.
You must use a `),Ea=l(hs,"CODE",{});var ul=r(Ea);Ze=p(ul,"BatchSampler"),ul.forEach(a),sn=p(hs," if you want the transform to be given full batches instead of receiving "),Da=l(hs,"CODE",{});var fl=r(Da);an=p(fl,"batch_size"),fl.forEach(a),tn=p(hs," times one single element."),hs.forEach(a),ft=c(s),R=l(s,"H3",{class:!0});var Ct=r(R);ls=l(Ct,"A",{id:!0,class:!0,href:!0});var gl=r(ls);qa=l(gl,"SPAN",{});var jl=r(qa);u(Ss.$$.fragment,jl),jl.forEach(a),gl.forEach(a),en=c(Ct),xa=l(Ct,"SPAN",{});var _l=r(xa);nn=p(_l,"Stream data"),_l.forEach(a),Ct.forEach(a),gt=c(s),q=l(s,"P",{});var is=r(q);ln=p(is,`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to `),Pa=l(is,"CODE",{});var yl=r(Pa);rn=p(yl,"pytorch"),yl.forEach(a),on=p(is,", and it inherits from "),Aa=l(is,"CODE",{});var bl=r(Aa);pn=p(bl,"torch.utils.data.IterableDataset"),bl.forEach(a),hn=p(is," so you can pass it to a "),Sa=l(is,"CODE",{});var vl=r(Sa);cn=p(vl,"DataLoader"),vl.forEach(a),dn=p(is,":"),is.forEach(a),jt=c(s),u(Ls.$$.fragment,s),_t=c(s),rs=l(s,"P",{});var Ot=r(rs);mn=p(Ot,"If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),La=l(Ot,"CODE",{});var $l=r(La);un=p($l,"num_workers"),$l.forEach(a),fn=p(Ot,":"),Ot.forEach(a),yt=c(s),u(Ts.$$.fragment,s),bt=c(s),Rs=l(s,"P",{});var wl=r(Rs);gn=p(wl,"In this case each worker will be given a subset of the list of shards to stream from."),wl.forEach(a),this.h()},h(){d(y,"name","hf:doc:metadata"),d(y,"content",JSON.stringify(Ll)),d(w,"id","use-with-pytorch"),d(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w,"href","#use-with-pytorch"),d(b,"class","relative group"),d(G,"id","tensors"),d(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(G,"href","#tensors"),d(O,"class","relative group"),d(J,"id","dataset-format"),d(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J,"href","#dataset-format"),d(N,"class","relative group"),d(Ns,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset.with_format"),d(V,"id","ndimensional-arrays"),d(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(V,"href","#ndimensional-arrays"),d(z,"class","relative group"),d(X,"id","other-feature-types"),d(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X,"href","#other-feature-types"),d(I,"class","relative group"),d(Is,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.ClassLabel"),d(Us,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Image"),d(Bs,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Audio"),d(ss,"id","data-loading"),d(ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ss,"href","#data-loading"),d(U,"class","relative group"),d(Fs,"href","/docs/datasets/pr_4474/en/package_reference/main_classes#datasets.Dataset"),d(as,"id","optimize-data-loading"),d(as,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(as,"href","#optimize-data-loading"),d(B,"class","relative group"),d(ts,"id","use-multiple-workers"),d(ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ts,"href","#use-multiple-workers"),d(F,"class","relative group"),d(es,"id","use-a-batchsampler"),d(es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(es,"href","#use-a-batchsampler"),d(H,"class","relative group"),d(ls,"id","stream-data"),d(ls,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ls,"href","#stream-data"),d(R,"class","relative group")},m(s,e){t(document.head,y),h(s,M,e),h(s,b,e),t(b,w),t(w,C),f(v,C,null),t(b,x),t(b,Y),t(Y,Nt),h(s,Ca,e),h(s,O,e),t(O,G),t(G,Ks),f(cs,Ks,null),t(O,zt),t(O,Qs),t(Qs,It),h(s,Oa,e),h(s,N,e),t(N,J),t(J,Vs),f(ds,Vs,null),t(N,Ut),t(N,Ws),t(Ws,Bt),h(s,Na,e),h(s,Os,e),t(Os,Ft),h(s,za,e),h(s,P,e),t(P,Ht),t(P,Xs),t(Xs,Rt),t(P,Mt),t(P,Ns),t(Ns,Yt),t(P,Gt),h(s,Ia,e),f(ms,s,e),h(s,Ua,e),f(K,s,e),h(s,Ba,e),h(s,Q,e),t(Q,Jt),t(Q,Zs),t(Zs,Kt),t(Q,Qt),h(s,Fa,e),f(us,s,e),h(s,Ha,e),h(s,z,e),t(z,V),t(V,sa),f(fs,sa,null),t(z,Vt),t(z,aa),t(aa,Wt),h(s,Ra,e),h(s,zs,e),t(zs,Xt),h(s,Ma,e),f(gs,s,e),h(s,Ya,e),h(s,W,e),t(W,Zt),t(W,ta),t(ta,se),t(W,ae),h(s,Ga,e),f(js,s,e),h(s,Ja,e),h(s,I,e),t(I,X),t(X,ea),f(_s,ea,null),t(I,te),t(I,na),t(na,ee),h(s,Ka,e),h(s,ys,e),t(ys,Is),t(Is,ne),t(ys,le),h(s,Qa,e),f(bs,s,e),h(s,Va,e),h(s,Z,e),t(Z,re),t(Z,la),t(la,oe),t(Z,pe),h(s,Wa,e),f(vs,s,e),h(s,Xa,e),h(s,A,e),t(A,he),t(A,Us),t(Us,ie),t(A,ce),t(A,Bs),t(Bs,de),t(A,me),h(s,Za,e),h(s,U,e),t(U,ss),t(ss,ra),f($s,ra,null),t(U,ue),t(U,oa),t(oa,fe),h(s,st,e),h(s,k,e),t(k,ge),t(k,pa),t(pa,je),t(k,_e),t(k,Fs),t(Fs,ye),t(k,be),t(k,ha),t(ha,ve),t(k,$e),h(s,at,e),f(ws,s,e),h(s,tt,e),h(s,B,e),t(B,as),t(as,ia),f(ks,ia,null),t(B,we),t(B,ca),t(ca,ke),h(s,et,e),h(s,F,e),t(F,ts),t(ts,da),f(Es,da,null),t(F,Ee),t(F,ma),t(ma,De),h(s,nt,e),h(s,S,e),t(S,qe),t(S,ua),t(ua,xe),t(S,Pe),t(S,fa),t(fa,Ae),t(S,Se),h(s,lt,e),h(s,E,e),t(E,Le),t(E,ga),t(ga,Te),t(E,Ce),t(E,ja),t(ja,Oe),t(E,Ne),t(E,_a),t(_a,ze),t(E,Ie),h(s,rt,e),f(Ds,s,e),h(s,ot,e),h(s,H,e),t(H,es),t(es,ya),f(qs,ya,null),t(H,Ue),t(H,ba),t(ba,Be),h(s,pt,e),h(s,ns,e),t(ns,Fe),t(ns,va),t(va,He),t(ns,Re),h(s,ht,e),f(xs,s,e),h(s,it,e),h(s,Hs,e),t(Hs,Me),h(s,ct,e),f(Ps,s,e),h(s,dt,e),h(s,L,e),t(L,Ye),t(L,$a),t($a,Ge),t(L,Je),t(L,wa),t(wa,Ke),t(L,Qe),h(s,mt,e),f(As,s,e),h(s,ut,e),h(s,D,e),t(D,Ve),t(D,ka),t(ka,We),t(D,Xe),t(D,Ea),t(Ea,Ze),t(D,sn),t(D,Da),t(Da,an),t(D,tn),h(s,ft,e),h(s,R,e),t(R,ls),t(ls,qa),f(Ss,qa,null),t(R,en),t(R,xa),t(xa,nn),h(s,gt,e),h(s,q,e),t(q,ln),t(q,Pa),t(Pa,rn),t(q,on),t(q,Aa),t(Aa,pn),t(q,hn),t(q,Sa),t(Sa,cn),t(q,dn),h(s,jt,e),f(Ls,s,e),h(s,_t,e),h(s,rs,e),t(rs,mn),t(rs,La),t(La,un),t(rs,fn),h(s,yt,e),f(Ts,s,e),h(s,bt,e),h(s,Rs,e),t(Rs,gn),vt=!0},p(s,[e]){const Cs={};e&2&&(Cs.$$scope={dirty:e,ctx:s}),K.$set(Cs)},i(s){vt||(g(v.$$.fragment,s),g(cs.$$.fragment,s),g(ds.$$.fragment,s),g(ms.$$.fragment,s),g(K.$$.fragment,s),g(us.$$.fragment,s),g(fs.$$.fragment,s),g(gs.$$.fragment,s),g(js.$$.fragment,s),g(_s.$$.fragment,s),g(bs.$$.fragment,s),g(vs.$$.fragment,s),g($s.$$.fragment,s),g(ws.$$.fragment,s),g(ks.$$.fragment,s),g(Es.$$.fragment,s),g(Ds.$$.fragment,s),g(qs.$$.fragment,s),g(xs.$$.fragment,s),g(Ps.$$.fragment,s),g(As.$$.fragment,s),g(Ss.$$.fragment,s),g(Ls.$$.fragment,s),g(Ts.$$.fragment,s),vt=!0)},o(s){j(v.$$.fragment,s),j(cs.$$.fragment,s),j(ds.$$.fragment,s),j(ms.$$.fragment,s),j(K.$$.fragment,s),j(us.$$.fragment,s),j(fs.$$.fragment,s),j(gs.$$.fragment,s),j(js.$$.fragment,s),j(_s.$$.fragment,s),j(bs.$$.fragment,s),j(vs.$$.fragment,s),j($s.$$.fragment,s),j(ws.$$.fragment,s),j(ks.$$.fragment,s),j(Es.$$.fragment,s),j(Ds.$$.fragment,s),j(qs.$$.fragment,s),j(xs.$$.fragment,s),j(Ps.$$.fragment,s),j(As.$$.fragment,s),j(Ss.$$.fragment,s),j(Ls.$$.fragment,s),j(Ts.$$.fragment,s),vt=!1},d(s){a(y),s&&a(M),s&&a(b),_(v),s&&a(Ca),s&&a(O),_(cs),s&&a(Oa),s&&a(N),_(ds),s&&a(Na),s&&a(Os),s&&a(za),s&&a(P),s&&a(Ia),_(ms,s),s&&a(Ua),_(K,s),s&&a(Ba),s&&a(Q),s&&a(Fa),_(us,s),s&&a(Ha),s&&a(z),_(fs),s&&a(Ra),s&&a(zs),s&&a(Ma),_(gs,s),s&&a(Ya),s&&a(W),s&&a(Ga),_(js,s),s&&a(Ja),s&&a(I),_(_s),s&&a(Ka),s&&a(ys),s&&a(Qa),_(bs,s),s&&a(Va),s&&a(Z),s&&a(Wa),_(vs,s),s&&a(Xa),s&&a(A),s&&a(Za),s&&a(U),_($s),s&&a(st),s&&a(k),s&&a(at),_(ws,s),s&&a(tt),s&&a(B),_(ks),s&&a(et),s&&a(F),_(Es),s&&a(nt),s&&a(S),s&&a(lt),s&&a(E),s&&a(rt),_(Ds,s),s&&a(ot),s&&a(H),_(qs),s&&a(pt),s&&a(ns),s&&a(ht),_(xs,s),s&&a(it),s&&a(Hs),s&&a(ct),_(Ps,s),s&&a(dt),s&&a(L),s&&a(mt),_(As,s),s&&a(ut),s&&a(D),s&&a(ft),s&&a(R),_(Ss),s&&a(gt),s&&a(q),s&&a(jt),_(Ls,s),s&&a(_t),s&&a(rs),s&&a(yt),_(Ts,s),s&&a(bt),s&&a(Rs)}}}const Ll={local:"use-with-pytorch",sections:[{local:"tensors",sections:[{local:"dataset-format",title:"Dataset format"},{local:"ndimensional-arrays",title:"N-dimensional arrays"},{local:"other-feature-types",title:"Other feature types"}],title:"Tensors"},{local:"data-loading",sections:[{local:"optimize-data-loading",sections:[{local:"use-multiple-workers",title:"Use multiple workers"},{local:"use-a-batchsampler",title:"Use a BatchSampler"}],title:"Optimize data loading"},{local:"stream-data",title:"Stream data"}],title:"Data loading"}],title:"Use with PyTorch"};function Tl(Ta){return xl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Il extends kl{constructor(y){super();El(this,y,Tl,Sl,Dl,{})}}export{Il as default,Ll as metadata};
