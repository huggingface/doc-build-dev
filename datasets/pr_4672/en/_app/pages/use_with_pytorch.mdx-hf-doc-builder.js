import{S as zn,i as Nn,s as In,e as r,k as i,w as m,t as l,M as Un,c as o,d as a,m as d,a as p,x as u,h as n,b as c,G as t,g as h,y as f,q as g,o as j,B as _,v as Fn}from"../chunks/vendor-hf-doc-builder.js";import{T as Bn}from"../chunks/Tip-hf-doc-builder.js";import{I as M}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as $}from"../chunks/CodeBlock-hf-doc-builder.js";function Hn(Oa){let y,Y,b,k,O;return{c(){y=r("p"),Y=l("A "),b=r("a"),k=l("Dataset"),O=l(" object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),this.h()},l(w){y=o(w,"P",{});var P=p(y);Y=n(P,"A "),b=o(P,"A",{href:!0});var G=p(b);k=n(G,"Dataset"),G.forEach(a),O=n(P," object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),P.forEach(a),this.h()},h(){c(b,"href","/docs/datasets/pr_4672/en/package_reference/main_classes#datasets.Dataset")},m(w,P){h(w,y,P),t(y,Y),t(y,b),t(b,k),t(y,O)},d(w){w&&a(y)}}}function Rn(Oa){let y,Y,b,k,O,w,P,G,It,za,v,Ut,Js,Ft,Bt,Ks,Ht,Rt,Qs,Mt,Yt,Vs,Gt,Wt,Na,z,W,Xs,ds,Jt,Zs,Kt,Ia,Cs,Qt,Ua,T,Vt,sa,Xt,Zt,Os,se,ae,Fa,cs,Ba,J,Ha,K,te,aa,ee,le,Ra,ms,Ma,N,Q,ta,us,ne,ea,re,Ya,zs,oe,Ga,fs,Wa,V,pe,la,he,ie,Ja,gs,Ka,I,X,na,js,de,ra,ce,Qa,_s,Ns,me,ue,Va,ys,Xa,Z,fe,oa,ge,je,Za,bs,st,A,_e,Is,ye,be,Us,ve,we,at,U,ss,pa,vs,$e,ha,ke,tt,E,Ee,ia,De,qe,Fs,xe,Pe,da,Te,Ae,et,ws,lt,F,as,ca,$s,Le,ma,Se,nt,Bs,Ce,rt,B,ts,ua,ks,Oe,fa,ze,ot,L,Ne,ga,Ie,Ue,ja,Fe,Be,pt,D,He,_a,Re,Me,ya,Ye,Ge,ba,We,Je,ht,Es,it,H,es,va,Ds,Ke,wa,Qe,dt,ls,Ve,$a,Xe,Ze,ct,qs,mt,Hs,sl,ut,xs,ft,S,al,ka,tl,el,Ea,ll,nl,gt,Ps,jt,q,rl,Da,ol,pl,qa,hl,il,xa,dl,cl,_t,R,ns,Pa,Ts,ml,Ta,ul,yt,x,fl,Aa,gl,jl,La,_l,yl,Sa,bl,vl,bt,As,vt,rs,wl,Ca,$l,kl,wt,Ls,$t,Rs,El,kt;return w=new M({}),ds=new M({}),cs=new $({props:{code:`from datasets import Dataset
data = [[1, 2],[3, 4]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("torch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}`}}),J=new Bn({props:{$$slots:{default:[Hn]},$$scope:{ctx:Oa}}}),ms=new $({props:{code:`import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ds = ds.with_format("torch", device=device)
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>, device=device)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)}`}}),us=new M({}),fs=new $({props:{code:`from datasets import Dataset
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("torch")
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: [tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]), tensor([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]}`}}),gs=new $({props:{code:`from datasets import Dataset, Features, Array2D
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
features = Features({"data": Array2D(shape=(2, 2), dtype='int32')})
ds = Dataset.from_dict({"data": data}, features=features)
ds = ds.with_format("torch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, Array2D
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: Array2D(shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=<span class="hljs-string">&#x27;int32&#x27;</span>)})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
          [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],
 
         [[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],
          [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]])}`}}),js=new M({}),ys=new $({props:{code:`from datasets import Dataset, Features, ClassLabel
data = [0, 0, 1]
features = Features({"data": ClassLabel(names=["negative", "positive"])})
ds = Dataset.from_dict({"data": data}, features=features) 
ds = ds.with_format("torch")  
ds[:3]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, ClassLabel
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: ClassLabel(names=[<span class="hljs-string">&quot;negative&quot;</span>, <span class="hljs-string">&quot;positive&quot;</span>])})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">3</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}`}}),bs=new $({props:{code:`from datasets import Dataset, Features 
text = ["foo", "bar"]
data = [0, 1] 
ds = Dataset.from_dict({"text": text, "data": data})  
ds = ds.with_format("torch", columns=["data"], output_all_columns=True) 
ds[:2]                                                                                                                                                     `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features 
<span class="hljs-meta">&gt;&gt;&gt; </span>text = [<span class="hljs-string">&quot;foo&quot;</span>, <span class="hljs-string">&quot;bar&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;text&quot;</span>: text, <span class="hljs-string">&quot;data&quot;</span>: data})  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;data&quot;</span>], output_all_columns=<span class="hljs-literal">True</span>) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]                                                                                                                                                     
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;foo&#x27;</span>, <span class="hljs-string">&#x27;bar&#x27;</span>]}`}}),vs=new M({}),ws=new $({props:{code:`import numpy as np
from datasets import Dataset 
from torch.utils.data import DataLoader
data = np.random.rand(16)
label = np.random.randint(0, 2, size=16)
ds = Dataset.from_dict({"data": data, "label": label}).with_format("torch")
dataloader = DataLoader(ds, batch_size=4)
for batch in dataloader:
    print(batch)                                                                                            `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>label = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, size=<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data, <span class="hljs-string">&quot;label&quot;</span>: label}).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> dataloader:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(batch)                                                                                            
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.0047</span>, <span class="hljs-number">0.4979</span>, <span class="hljs-number">0.6726</span>, <span class="hljs-number">0.8105</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.4832</span>, <span class="hljs-number">0.2723</span>, <span class="hljs-number">0.4259</span>, <span class="hljs-number">0.2224</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.5837</span>, <span class="hljs-number">0.3444</span>, <span class="hljs-number">0.4658</span>, <span class="hljs-number">0.6417</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.7022</span>, <span class="hljs-number">0.1225</span>, <span class="hljs-number">0.7228</span>, <span class="hljs-number">0.8259</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])}`}}),$s=new M({}),ks=new M({}),Es=new $({props:{code:`import numpy as np
from datasets import Dataset, load_from_disk
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).save_to_disk("my_dataset")
ds = load_from_disk("my_dataset").with_format("torch")
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_from_disk
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).save_to_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_from_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),Ds=new M({}),qs=new $({props:{code:"batch = [dataset[idx] for idx in range(start, end)]",highlighted:'batch = [dataset[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end)]'}}),xs=new $({props:{code:`batch = dataset[start:end]
# or
batch = dataset[list_of_indices]`,highlighted:`batch = dataset[start:end]
<span class="hljs-comment"># or</span>
batch = dataset[list_of_indices]`}}),Ps=new $({props:{code:`from torch.utils.data.sampler import BatchSampler, RandomSampler
sampler = BatchSampler(RandomSampler(ds), batch_size=32, drop_last=False)
dataloader = DataLoader(ds, sampler=sampler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data.sampler <span class="hljs-keyword">import</span> BatchSampler, RandomSampler
<span class="hljs-meta">&gt;&gt;&gt; </span>sampler = BatchSampler(RandomSampler(ds), batch_size=<span class="hljs-number">32</span>, drop_last=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, sampler=sampler)`}}),Ts=new M({}),As=new $({props:{code:`import numpy as np
from datasets import Dataset, load_dataset
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).push_to_hub("<username>/my_dataset")  # Upload to the Hugging Face Hub
ds = load_dataset("<username>/my_dataset", streaming=True, split="train").with_format("torch")
dataloader = DataLoader(ds, batch_size=32)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).push_to_hub(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)  <span class="hljs-comment"># Upload to the Hugging Face Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>)`}}),Ls=new $({props:{code:`ds = load_dataset("c4", "en", streaming=True, split="train").with_format("torch")
ds.n_shards
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;c4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds.n_shards
<span class="hljs-number">1024</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),{c(){y=r("meta"),Y=i(),b=r("h1"),k=r("a"),O=r("span"),m(w.$$.fragment),P=i(),G=r("span"),It=l("Use with PyTorch"),za=i(),v=r("p"),Ut=l("This document is a quick introduction to using "),Js=r("code"),Ft=l("datasets"),Bt=l(` with PyTorch, with a particular focus on how to get
`),Ks=r("code"),Ht=l("torch.Tensor"),Rt=l(" objects out of our datasets, and how to use a PyTorch "),Qs=r("code"),Mt=l("DataLoader"),Yt=l(" and a Hugging Face "),Vs=r("code"),Gt=l("Dataset"),Wt=l(`
with the best performance.`),Na=i(),z=r("h2"),W=r("a"),Xs=r("span"),m(ds.$$.fragment),Jt=i(),Zs=r("span"),Kt=l("Dataset format"),Ia=i(),Cs=r("p"),Qt=l("By default, datasets return regular python objects: integers, floats, strings, lists, etc."),Ua=i(),T=r("p"),Vt=l("To get PyTorch tensors instead, you can set the format of the dataset to "),sa=r("code"),Xt=l("pytorch"),Zt=l(" using "),Os=r("a"),se=l("Dataset.with_format()"),ae=l(":"),Fa=i(),m(cs.$$.fragment),Ba=i(),m(J.$$.fragment),Ha=i(),K=r("p"),te=l("To load the data as tensors on a GPU, specify the "),aa=r("code"),ee=l("device"),le=l(" argument:"),Ra=i(),m(ms.$$.fragment),Ma=i(),N=r("h2"),Q=r("a"),ta=r("span"),m(us.$$.fragment),ne=i(),ea=r("span"),re=l("N-dimensional arrays"),Ya=i(),zs=r("p"),oe=l(`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of a single tensor:`),Ga=i(),m(fs.$$.fragment),Wa=i(),V=r("p"),pe=l("To get a single tensor, you must explicitly use the "),la=r("code"),he=l("Array"),ie=l(" feature type and specify the shape of your tensors:"),Ja=i(),m(gs.$$.fragment),Ka=i(),I=r("h2"),X=r("a"),na=r("span"),m(js.$$.fragment),de=i(),ra=r("span"),ce=l("Other feature types"),Qa=i(),_s=r("p"),Ns=r("a"),me=l("ClassLabel"),ue=l(" data are properly converted to tensors:"),Va=i(),m(ys.$$.fragment),Xa=i(),Z=r("p"),fe=l("However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),oa=r("code"),ge=l("string"),je=l(` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),Za=i(),m(bs.$$.fragment),st=i(),A=r("p"),_e=l("The "),Is=r("a"),ye=l("Image"),be=l(" and "),Us=r("a"),ve=l("Audio"),we=l(" feature types are not supported yet."),at=i(),U=r("h2"),ss=r("a"),pa=r("span"),m(vs.$$.fragment),$e=i(),ha=r("span"),ke=l("Data loading"),tt=i(),E=r("p"),Ee=l("Like "),ia=r("code"),De=l("torch.utils.data.Dataset"),qe=l(" objects, a "),Fs=r("a"),xe=l("Dataset"),Pe=l(" can be passed directly to a PyTorch "),da=r("code"),Te=l("DataLoader"),Ae=l(":"),et=i(),m(ws.$$.fragment),lt=i(),F=r("h3"),as=r("a"),ca=r("span"),m($s.$$.fragment),Le=i(),ma=r("span"),Se=l("Optimize data loading"),nt=i(),Bs=r("p"),Ce=l(`There are several ways you can increase the speed your data is loaded which can save you time, especially if you are working with large datasets.
PyTorch offers parallelized data loading, retrieving batches of indices instead of individually, and streaming to progressively download datasets.`),rt=i(),B=r("h4"),ts=r("a"),ua=r("span"),m(ks.$$.fragment),Oe=i(),fa=r("span"),ze=l("Use multiple Workers"),ot=i(),L=r("p"),Ne=l("You can parallelize data loading with the "),ga=r("code"),Ie=l("num_workers"),Ue=l(" argument of a PyTorch "),ja=r("code"),Fe=l("DataLoader"),Be=l(" and get a higher throughput."),pt=i(),D=r("p"),He=l("Under the hood, the "),_a=r("code"),Re=l("DataLoader"),Me=l(" starts "),ya=r("code"),Ye=l("num_workers"),Ge=l(` processes.
Each process reloads the dataset passed to the `),ba=r("code"),We=l("DataLoader"),Je=l(` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-maps the dataset again from your disk.`),ht=i(),m(Es.$$.fragment),it=i(),H=r("h4"),es=r("a"),va=r("span"),m(Ds.$$.fragment),Ke=i(),wa=r("span"),Qe=l("Use a BatchSampler"),dt=i(),ls=r("p"),Ve=l("By default, the PyTorch "),$a=r("code"),Xe=l("DataLoader"),Ze=l(" load batches of data from a dataset one by one like this:"),ct=i(),m(qs.$$.fragment),mt=i(),Hs=r("p"),sl=l(`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),ut=i(),m(xs.$$.fragment),ft=i(),S=r("p"),al=l("For the PyTorch "),ka=r("code"),tl=l("DataLoader"),el=l(" to query batches using a list, you can use a "),Ea=r("code"),ll=l("BatchSampler"),nl=l(":"),gt=i(),m(Ps.$$.fragment),jt=i(),q=r("p"),rl=l("Moreover, this is particularly useful if you used "),Da=r("code"),ol=l("set_transform"),pl=l(` to apply a transform on-the-fly when examples are accessed.
You must use a `),qa=r("code"),hl=l("BatchSampler"),il=l(" if you want the transform to be given full batches instead of receiving "),xa=r("code"),dl=l("batch_size"),cl=l(" times one single element."),_t=i(),R=r("h3"),ns=r("a"),Pa=r("span"),m(Ts.$$.fragment),ml=i(),Ta=r("span"),ul=l("Stream data"),yt=i(),x=r("p"),fl=l(`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to `),Aa=r("code"),gl=l("torch"),jl=l(", and it inherits from "),La=r("code"),_l=l("torch.utils.data.IterableDataset"),yl=l(" so you can pass it to a "),Sa=r("code"),bl=l("DataLoader"),vl=l(":"),bt=i(),m(As.$$.fragment),vt=i(),rs=r("p"),wl=l("If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),Ca=r("code"),$l=l("num_workers"),kl=l(":"),wt=i(),m(Ls.$$.fragment),$t=i(),Rs=r("p"),El=l("In this case each worker will be given a subset of the list of shards to stream from."),this.h()},l(s){const e=Un('[data-svelte="svelte-1phssyn"]',document.head);y=o(e,"META",{name:!0,content:!0}),e.forEach(a),Y=d(s),b=o(s,"H1",{class:!0});var Ss=p(b);k=o(Ss,"A",{id:!0,class:!0,href:!0});var ql=p(k);O=o(ql,"SPAN",{});var xl=p(O);u(w.$$.fragment,xl),xl.forEach(a),ql.forEach(a),P=d(Ss),G=o(Ss,"SPAN",{});var Pl=p(G);It=n(Pl,"Use with PyTorch"),Pl.forEach(a),Ss.forEach(a),za=d(s),v=o(s,"P",{});var C=p(v);Ut=n(C,"This document is a quick introduction to using "),Js=o(C,"CODE",{});var Tl=p(Js);Ft=n(Tl,"datasets"),Tl.forEach(a),Bt=n(C,` with PyTorch, with a particular focus on how to get
`),Ks=o(C,"CODE",{});var Al=p(Ks);Ht=n(Al,"torch.Tensor"),Al.forEach(a),Rt=n(C," objects out of our datasets, and how to use a PyTorch "),Qs=o(C,"CODE",{});var Ll=p(Qs);Mt=n(Ll,"DataLoader"),Ll.forEach(a),Yt=n(C," and a Hugging Face "),Vs=o(C,"CODE",{});var Sl=p(Vs);Gt=n(Sl,"Dataset"),Sl.forEach(a),Wt=n(C,`
with the best performance.`),C.forEach(a),Na=d(s),z=o(s,"H2",{class:!0});var Et=p(z);W=o(Et,"A",{id:!0,class:!0,href:!0});var Cl=p(W);Xs=o(Cl,"SPAN",{});var Ol=p(Xs);u(ds.$$.fragment,Ol),Ol.forEach(a),Cl.forEach(a),Jt=d(Et),Zs=o(Et,"SPAN",{});var zl=p(Zs);Kt=n(zl,"Dataset format"),zl.forEach(a),Et.forEach(a),Ia=d(s),Cs=o(s,"P",{});var Nl=p(Cs);Qt=n(Nl,"By default, datasets return regular python objects: integers, floats, strings, lists, etc."),Nl.forEach(a),Ua=d(s),T=o(s,"P",{});var Ms=p(T);Vt=n(Ms,"To get PyTorch tensors instead, you can set the format of the dataset to "),sa=o(Ms,"CODE",{});var Il=p(sa);Xt=n(Il,"pytorch"),Il.forEach(a),Zt=n(Ms," using "),Os=o(Ms,"A",{href:!0});var Ul=p(Os);se=n(Ul,"Dataset.with_format()"),Ul.forEach(a),ae=n(Ms,":"),Ms.forEach(a),Fa=d(s),u(cs.$$.fragment,s),Ba=d(s),u(J.$$.fragment,s),Ha=d(s),K=o(s,"P",{});var Dt=p(K);te=n(Dt,"To load the data as tensors on a GPU, specify the "),aa=o(Dt,"CODE",{});var Fl=p(aa);ee=n(Fl,"device"),Fl.forEach(a),le=n(Dt," argument:"),Dt.forEach(a),Ra=d(s),u(ms.$$.fragment,s),Ma=d(s),N=o(s,"H2",{class:!0});var qt=p(N);Q=o(qt,"A",{id:!0,class:!0,href:!0});var Bl=p(Q);ta=o(Bl,"SPAN",{});var Hl=p(ta);u(us.$$.fragment,Hl),Hl.forEach(a),Bl.forEach(a),ne=d(qt),ea=o(qt,"SPAN",{});var Rl=p(ea);re=n(Rl,"N-dimensional arrays"),Rl.forEach(a),qt.forEach(a),Ya=d(s),zs=o(s,"P",{});var Ml=p(zs);oe=n(Ml,`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of a single tensor:`),Ml.forEach(a),Ga=d(s),u(fs.$$.fragment,s),Wa=d(s),V=o(s,"P",{});var xt=p(V);pe=n(xt,"To get a single tensor, you must explicitly use the "),la=o(xt,"CODE",{});var Yl=p(la);he=n(Yl,"Array"),Yl.forEach(a),ie=n(xt," feature type and specify the shape of your tensors:"),xt.forEach(a),Ja=d(s),u(gs.$$.fragment,s),Ka=d(s),I=o(s,"H2",{class:!0});var Pt=p(I);X=o(Pt,"A",{id:!0,class:!0,href:!0});var Gl=p(X);na=o(Gl,"SPAN",{});var Wl=p(na);u(js.$$.fragment,Wl),Wl.forEach(a),Gl.forEach(a),de=d(Pt),ra=o(Pt,"SPAN",{});var Jl=p(ra);ce=n(Jl,"Other feature types"),Jl.forEach(a),Pt.forEach(a),Qa=d(s),_s=o(s,"P",{});var Dl=p(_s);Ns=o(Dl,"A",{href:!0});var Kl=p(Ns);me=n(Kl,"ClassLabel"),Kl.forEach(a),ue=n(Dl," data are properly converted to tensors:"),Dl.forEach(a),Va=d(s),u(ys.$$.fragment,s),Xa=d(s),Z=o(s,"P",{});var Tt=p(Z);fe=n(Tt,"However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),oa=o(Tt,"CODE",{});var Ql=p(oa);ge=n(Ql,"string"),Ql.forEach(a),je=n(Tt,` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),Tt.forEach(a),Za=d(s),u(bs.$$.fragment,s),st=d(s),A=o(s,"P",{});var Ys=p(A);_e=n(Ys,"The "),Is=o(Ys,"A",{href:!0});var Vl=p(Is);ye=n(Vl,"Image"),Vl.forEach(a),be=n(Ys," and "),Us=o(Ys,"A",{href:!0});var Xl=p(Us);ve=n(Xl,"Audio"),Xl.forEach(a),we=n(Ys," feature types are not supported yet."),Ys.forEach(a),at=d(s),U=o(s,"H2",{class:!0});var At=p(U);ss=o(At,"A",{id:!0,class:!0,href:!0});var Zl=p(ss);pa=o(Zl,"SPAN",{});var sn=p(pa);u(vs.$$.fragment,sn),sn.forEach(a),Zl.forEach(a),$e=d(At),ha=o(At,"SPAN",{});var an=p(ha);ke=n(an,"Data loading"),an.forEach(a),At.forEach(a),tt=d(s),E=o(s,"P",{});var os=p(E);Ee=n(os,"Like "),ia=o(os,"CODE",{});var tn=p(ia);De=n(tn,"torch.utils.data.Dataset"),tn.forEach(a),qe=n(os," objects, a "),Fs=o(os,"A",{href:!0});var en=p(Fs);xe=n(en,"Dataset"),en.forEach(a),Pe=n(os," can be passed directly to a PyTorch "),da=o(os,"CODE",{});var ln=p(da);Te=n(ln,"DataLoader"),ln.forEach(a),Ae=n(os,":"),os.forEach(a),et=d(s),u(ws.$$.fragment,s),lt=d(s),F=o(s,"H3",{class:!0});var Lt=p(F);as=o(Lt,"A",{id:!0,class:!0,href:!0});var nn=p(as);ca=o(nn,"SPAN",{});var rn=p(ca);u($s.$$.fragment,rn),rn.forEach(a),nn.forEach(a),Le=d(Lt),ma=o(Lt,"SPAN",{});var on=p(ma);Se=n(on,"Optimize data loading"),on.forEach(a),Lt.forEach(a),nt=d(s),Bs=o(s,"P",{});var pn=p(Bs);Ce=n(pn,`There are several ways you can increase the speed your data is loaded which can save you time, especially if you are working with large datasets.
PyTorch offers parallelized data loading, retrieving batches of indices instead of individually, and streaming to progressively download datasets.`),pn.forEach(a),rt=d(s),B=o(s,"H4",{class:!0});var St=p(B);ts=o(St,"A",{id:!0,class:!0,href:!0});var hn=p(ts);ua=o(hn,"SPAN",{});var dn=p(ua);u(ks.$$.fragment,dn),dn.forEach(a),hn.forEach(a),Oe=d(St),fa=o(St,"SPAN",{});var cn=p(fa);ze=n(cn,"Use multiple Workers"),cn.forEach(a),St.forEach(a),ot=d(s),L=o(s,"P",{});var Gs=p(L);Ne=n(Gs,"You can parallelize data loading with the "),ga=o(Gs,"CODE",{});var mn=p(ga);Ie=n(mn,"num_workers"),mn.forEach(a),Ue=n(Gs," argument of a PyTorch "),ja=o(Gs,"CODE",{});var un=p(ja);Fe=n(un,"DataLoader"),un.forEach(a),Be=n(Gs," and get a higher throughput."),Gs.forEach(a),pt=d(s),D=o(s,"P",{});var ps=p(D);He=n(ps,"Under the hood, the "),_a=o(ps,"CODE",{});var fn=p(_a);Re=n(fn,"DataLoader"),fn.forEach(a),Me=n(ps," starts "),ya=o(ps,"CODE",{});var gn=p(ya);Ye=n(gn,"num_workers"),gn.forEach(a),Ge=n(ps,` processes.
Each process reloads the dataset passed to the `),ba=o(ps,"CODE",{});var jn=p(ba);We=n(jn,"DataLoader"),jn.forEach(a),Je=n(ps,` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-maps the dataset again from your disk.`),ps.forEach(a),ht=d(s),u(Es.$$.fragment,s),it=d(s),H=o(s,"H4",{class:!0});var Ct=p(H);es=o(Ct,"A",{id:!0,class:!0,href:!0});var _n=p(es);va=o(_n,"SPAN",{});var yn=p(va);u(Ds.$$.fragment,yn),yn.forEach(a),_n.forEach(a),Ke=d(Ct),wa=o(Ct,"SPAN",{});var bn=p(wa);Qe=n(bn,"Use a BatchSampler"),bn.forEach(a),Ct.forEach(a),dt=d(s),ls=o(s,"P",{});var Ot=p(ls);Ve=n(Ot,"By default, the PyTorch "),$a=o(Ot,"CODE",{});var vn=p($a);Xe=n(vn,"DataLoader"),vn.forEach(a),Ze=n(Ot," load batches of data from a dataset one by one like this:"),Ot.forEach(a),ct=d(s),u(qs.$$.fragment,s),mt=d(s),Hs=o(s,"P",{});var wn=p(Hs);sl=n(wn,`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),wn.forEach(a),ut=d(s),u(xs.$$.fragment,s),ft=d(s),S=o(s,"P",{});var Ws=p(S);al=n(Ws,"For the PyTorch "),ka=o(Ws,"CODE",{});var $n=p(ka);tl=n($n,"DataLoader"),$n.forEach(a),el=n(Ws," to query batches using a list, you can use a "),Ea=o(Ws,"CODE",{});var kn=p(Ea);ll=n(kn,"BatchSampler"),kn.forEach(a),nl=n(Ws,":"),Ws.forEach(a),gt=d(s),u(Ps.$$.fragment,s),jt=d(s),q=o(s,"P",{});var hs=p(q);rl=n(hs,"Moreover, this is particularly useful if you used "),Da=o(hs,"CODE",{});var En=p(Da);ol=n(En,"set_transform"),En.forEach(a),pl=n(hs,` to apply a transform on-the-fly when examples are accessed.
You must use a `),qa=o(hs,"CODE",{});var Dn=p(qa);hl=n(Dn,"BatchSampler"),Dn.forEach(a),il=n(hs," if you want the transform to be given full batches instead of receiving "),xa=o(hs,"CODE",{});var qn=p(xa);dl=n(qn,"batch_size"),qn.forEach(a),cl=n(hs," times one single element."),hs.forEach(a),_t=d(s),R=o(s,"H3",{class:!0});var zt=p(R);ns=o(zt,"A",{id:!0,class:!0,href:!0});var xn=p(ns);Pa=o(xn,"SPAN",{});var Pn=p(Pa);u(Ts.$$.fragment,Pn),Pn.forEach(a),xn.forEach(a),ml=d(zt),Ta=o(zt,"SPAN",{});var Tn=p(Ta);ul=n(Tn,"Stream data"),Tn.forEach(a),zt.forEach(a),yt=d(s),x=o(s,"P",{});var is=p(x);fl=n(is,`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to `),Aa=o(is,"CODE",{});var An=p(Aa);gl=n(An,"torch"),An.forEach(a),jl=n(is,", and it inherits from "),La=o(is,"CODE",{});var Ln=p(La);_l=n(Ln,"torch.utils.data.IterableDataset"),Ln.forEach(a),yl=n(is," so you can pass it to a "),Sa=o(is,"CODE",{});var Sn=p(Sa);bl=n(Sn,"DataLoader"),Sn.forEach(a),vl=n(is,":"),is.forEach(a),bt=d(s),u(As.$$.fragment,s),vt=d(s),rs=o(s,"P",{});var Nt=p(rs);wl=n(Nt,"If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),Ca=o(Nt,"CODE",{});var Cn=p(Ca);$l=n(Cn,"num_workers"),Cn.forEach(a),kl=n(Nt,":"),Nt.forEach(a),wt=d(s),u(Ls.$$.fragment,s),$t=d(s),Rs=o(s,"P",{});var On=p(Rs);El=n(On,"In this case each worker will be given a subset of the list of shards to stream from."),On.forEach(a),this.h()},h(){c(y,"name","hf:doc:metadata"),c(y,"content",JSON.stringify(Mn)),c(k,"id","use-with-pytorch"),c(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k,"href","#use-with-pytorch"),c(b,"class","relative group"),c(W,"id","dataset-format"),c(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W,"href","#dataset-format"),c(z,"class","relative group"),c(Os,"href","/docs/datasets/pr_4672/en/package_reference/main_classes#datasets.Dataset.with_format"),c(Q,"id","ndimensional-arrays"),c(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q,"href","#ndimensional-arrays"),c(N,"class","relative group"),c(X,"id","other-feature-types"),c(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X,"href","#other-feature-types"),c(I,"class","relative group"),c(Ns,"href","/docs/datasets/pr_4672/en/package_reference/main_classes#datasets.ClassLabel"),c(Is,"href","/docs/datasets/pr_4672/en/package_reference/main_classes#datasets.Image"),c(Us,"href","/docs/datasets/pr_4672/en/package_reference/main_classes#datasets.Audio"),c(ss,"id","data-loading"),c(ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ss,"href","#data-loading"),c(U,"class","relative group"),c(Fs,"href","/docs/datasets/pr_4672/en/package_reference/main_classes#datasets.Dataset"),c(as,"id","optimize-data-loading"),c(as,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(as,"href","#optimize-data-loading"),c(F,"class","relative group"),c(ts,"id","use-multiple-workers"),c(ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ts,"href","#use-multiple-workers"),c(B,"class","relative group"),c(es,"id","use-a-batchsampler"),c(es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(es,"href","#use-a-batchsampler"),c(H,"class","relative group"),c(ns,"id","stream-data"),c(ns,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ns,"href","#stream-data"),c(R,"class","relative group")},m(s,e){t(document.head,y),h(s,Y,e),h(s,b,e),t(b,k),t(k,O),f(w,O,null),t(b,P),t(b,G),t(G,It),h(s,za,e),h(s,v,e),t(v,Ut),t(v,Js),t(Js,Ft),t(v,Bt),t(v,Ks),t(Ks,Ht),t(v,Rt),t(v,Qs),t(Qs,Mt),t(v,Yt),t(v,Vs),t(Vs,Gt),t(v,Wt),h(s,Na,e),h(s,z,e),t(z,W),t(W,Xs),f(ds,Xs,null),t(z,Jt),t(z,Zs),t(Zs,Kt),h(s,Ia,e),h(s,Cs,e),t(Cs,Qt),h(s,Ua,e),h(s,T,e),t(T,Vt),t(T,sa),t(sa,Xt),t(T,Zt),t(T,Os),t(Os,se),t(T,ae),h(s,Fa,e),f(cs,s,e),h(s,Ba,e),f(J,s,e),h(s,Ha,e),h(s,K,e),t(K,te),t(K,aa),t(aa,ee),t(K,le),h(s,Ra,e),f(ms,s,e),h(s,Ma,e),h(s,N,e),t(N,Q),t(Q,ta),f(us,ta,null),t(N,ne),t(N,ea),t(ea,re),h(s,Ya,e),h(s,zs,e),t(zs,oe),h(s,Ga,e),f(fs,s,e),h(s,Wa,e),h(s,V,e),t(V,pe),t(V,la),t(la,he),t(V,ie),h(s,Ja,e),f(gs,s,e),h(s,Ka,e),h(s,I,e),t(I,X),t(X,na),f(js,na,null),t(I,de),t(I,ra),t(ra,ce),h(s,Qa,e),h(s,_s,e),t(_s,Ns),t(Ns,me),t(_s,ue),h(s,Va,e),f(ys,s,e),h(s,Xa,e),h(s,Z,e),t(Z,fe),t(Z,oa),t(oa,ge),t(Z,je),h(s,Za,e),f(bs,s,e),h(s,st,e),h(s,A,e),t(A,_e),t(A,Is),t(Is,ye),t(A,be),t(A,Us),t(Us,ve),t(A,we),h(s,at,e),h(s,U,e),t(U,ss),t(ss,pa),f(vs,pa,null),t(U,$e),t(U,ha),t(ha,ke),h(s,tt,e),h(s,E,e),t(E,Ee),t(E,ia),t(ia,De),t(E,qe),t(E,Fs),t(Fs,xe),t(E,Pe),t(E,da),t(da,Te),t(E,Ae),h(s,et,e),f(ws,s,e),h(s,lt,e),h(s,F,e),t(F,as),t(as,ca),f($s,ca,null),t(F,Le),t(F,ma),t(ma,Se),h(s,nt,e),h(s,Bs,e),t(Bs,Ce),h(s,rt,e),h(s,B,e),t(B,ts),t(ts,ua),f(ks,ua,null),t(B,Oe),t(B,fa),t(fa,ze),h(s,ot,e),h(s,L,e),t(L,Ne),t(L,ga),t(ga,Ie),t(L,Ue),t(L,ja),t(ja,Fe),t(L,Be),h(s,pt,e),h(s,D,e),t(D,He),t(D,_a),t(_a,Re),t(D,Me),t(D,ya),t(ya,Ye),t(D,Ge),t(D,ba),t(ba,We),t(D,Je),h(s,ht,e),f(Es,s,e),h(s,it,e),h(s,H,e),t(H,es),t(es,va),f(Ds,va,null),t(H,Ke),t(H,wa),t(wa,Qe),h(s,dt,e),h(s,ls,e),t(ls,Ve),t(ls,$a),t($a,Xe),t(ls,Ze),h(s,ct,e),f(qs,s,e),h(s,mt,e),h(s,Hs,e),t(Hs,sl),h(s,ut,e),f(xs,s,e),h(s,ft,e),h(s,S,e),t(S,al),t(S,ka),t(ka,tl),t(S,el),t(S,Ea),t(Ea,ll),t(S,nl),h(s,gt,e),f(Ps,s,e),h(s,jt,e),h(s,q,e),t(q,rl),t(q,Da),t(Da,ol),t(q,pl),t(q,qa),t(qa,hl),t(q,il),t(q,xa),t(xa,dl),t(q,cl),h(s,_t,e),h(s,R,e),t(R,ns),t(ns,Pa),f(Ts,Pa,null),t(R,ml),t(R,Ta),t(Ta,ul),h(s,yt,e),h(s,x,e),t(x,fl),t(x,Aa),t(Aa,gl),t(x,jl),t(x,La),t(La,_l),t(x,yl),t(x,Sa),t(Sa,bl),t(x,vl),h(s,bt,e),f(As,s,e),h(s,vt,e),h(s,rs,e),t(rs,wl),t(rs,Ca),t(Ca,$l),t(rs,kl),h(s,wt,e),f(Ls,s,e),h(s,$t,e),h(s,Rs,e),t(Rs,El),kt=!0},p(s,[e]){const Ss={};e&2&&(Ss.$$scope={dirty:e,ctx:s}),J.$set(Ss)},i(s){kt||(g(w.$$.fragment,s),g(ds.$$.fragment,s),g(cs.$$.fragment,s),g(J.$$.fragment,s),g(ms.$$.fragment,s),g(us.$$.fragment,s),g(fs.$$.fragment,s),g(gs.$$.fragment,s),g(js.$$.fragment,s),g(ys.$$.fragment,s),g(bs.$$.fragment,s),g(vs.$$.fragment,s),g(ws.$$.fragment,s),g($s.$$.fragment,s),g(ks.$$.fragment,s),g(Es.$$.fragment,s),g(Ds.$$.fragment,s),g(qs.$$.fragment,s),g(xs.$$.fragment,s),g(Ps.$$.fragment,s),g(Ts.$$.fragment,s),g(As.$$.fragment,s),g(Ls.$$.fragment,s),kt=!0)},o(s){j(w.$$.fragment,s),j(ds.$$.fragment,s),j(cs.$$.fragment,s),j(J.$$.fragment,s),j(ms.$$.fragment,s),j(us.$$.fragment,s),j(fs.$$.fragment,s),j(gs.$$.fragment,s),j(js.$$.fragment,s),j(ys.$$.fragment,s),j(bs.$$.fragment,s),j(vs.$$.fragment,s),j(ws.$$.fragment,s),j($s.$$.fragment,s),j(ks.$$.fragment,s),j(Es.$$.fragment,s),j(Ds.$$.fragment,s),j(qs.$$.fragment,s),j(xs.$$.fragment,s),j(Ps.$$.fragment,s),j(Ts.$$.fragment,s),j(As.$$.fragment,s),j(Ls.$$.fragment,s),kt=!1},d(s){a(y),s&&a(Y),s&&a(b),_(w),s&&a(za),s&&a(v),s&&a(Na),s&&a(z),_(ds),s&&a(Ia),s&&a(Cs),s&&a(Ua),s&&a(T),s&&a(Fa),_(cs,s),s&&a(Ba),_(J,s),s&&a(Ha),s&&a(K),s&&a(Ra),_(ms,s),s&&a(Ma),s&&a(N),_(us),s&&a(Ya),s&&a(zs),s&&a(Ga),_(fs,s),s&&a(Wa),s&&a(V),s&&a(Ja),_(gs,s),s&&a(Ka),s&&a(I),_(js),s&&a(Qa),s&&a(_s),s&&a(Va),_(ys,s),s&&a(Xa),s&&a(Z),s&&a(Za),_(bs,s),s&&a(st),s&&a(A),s&&a(at),s&&a(U),_(vs),s&&a(tt),s&&a(E),s&&a(et),_(ws,s),s&&a(lt),s&&a(F),_($s),s&&a(nt),s&&a(Bs),s&&a(rt),s&&a(B),_(ks),s&&a(ot),s&&a(L),s&&a(pt),s&&a(D),s&&a(ht),_(Es,s),s&&a(it),s&&a(H),_(Ds),s&&a(dt),s&&a(ls),s&&a(ct),_(qs,s),s&&a(mt),s&&a(Hs),s&&a(ut),_(xs,s),s&&a(ft),s&&a(S),s&&a(gt),_(Ps,s),s&&a(jt),s&&a(q),s&&a(_t),s&&a(R),_(Ts),s&&a(yt),s&&a(x),s&&a(bt),_(As,s),s&&a(vt),s&&a(rs),s&&a(wt),_(Ls,s),s&&a($t),s&&a(Rs)}}}const Mn={local:"use-with-pytorch",sections:[{local:"dataset-format",title:"Dataset format"},{local:"ndimensional-arrays",title:"N-dimensional arrays"},{local:"other-feature-types",title:"Other feature types"},{local:"data-loading",sections:[{local:"optimize-data-loading",sections:[{local:"use-multiple-workers",title:"Use multiple Workers"},{local:"use-a-batchsampler",title:"Use a BatchSampler"}],title:"Optimize data loading"},{local:"stream-data",title:"Stream data"}],title:"Data loading"}],title:"Use with PyTorch"};function Yn(Oa){return Fn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Qn extends zn{constructor(y){super();Nn(this,y,Yn,Rn,In,{})}}export{Qn as default,Mn as metadata};
