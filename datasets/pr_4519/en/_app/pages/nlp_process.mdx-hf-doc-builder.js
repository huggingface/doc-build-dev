import{S as Ka,i as Qa,s as Va,e as l,k as m,w as P,t as p,M as Wa,c as t,d as a,m as i,a as r,x as T,h,b as c,G as n,g as o,y as q,L as Xa,q as z,o as L,B as N,v as Za}from"../chunks/vendor-hf-doc-builder.js";import{I as ka}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as cs}from"../chunks/CodeBlock-hf-doc-builder.js";function sn(xa){let f,ms,j,_,as,S,Fs,ns,Hs,is,J,Os,us,$,I,Bs,R,Us,Ys,Gs,es,Js,bs,v,Rs,M,Ks,Qs,fs,d,w,ls,D,Vs,ts,Ws,js,k,Xs,K,Zs,sa,ds,x,aa,C,na,ea,gs,F,_s,u,la,ps,ta,pa,rs,ra,ha,Q,oa,ca,$s,H,vs,g,y,hs,O,ma,os,ia,ws,b,ua,V,ba,fa,B,ja,da,ks,U,xs,W,ga,ys,Y,Es,E,_a,X,$a,va,As,G,Ps,Z,wa,Ts;return S=new ka({}),D=new ka({}),F=new cs({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)`}}),H=new cs({props:{code:`dataset = dataset.map(lambda examples: tokenizer(examples["text"]), batched=True)
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> examples: tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>]), batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;the rock is destined to be the 21st century\\&#x27;s new &quot; conan &quot; and that he\\&#x27;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .&#x27;</span>, 
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>, 
 <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2600</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">16036</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">2022</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">7398</span>, <span class="hljs-number">2301</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">1055</span>, <span class="hljs-number">2047</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">16608</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">1998</span>, <span class="hljs-number">2008</span>, <span class="hljs-number">2002</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">1055</span>, <span class="hljs-number">2183</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">2191</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">17624</span>, <span class="hljs-number">2130</span>, <span class="hljs-number">3618</span>, <span class="hljs-number">2084</span>, <span class="hljs-number">7779</span>, <span class="hljs-number">29058</span>, <span class="hljs-number">8625</span>, <span class="hljs-number">13327</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">3744</span>, <span class="hljs-number">1011</span>, <span class="hljs-number">18856</span>, <span class="hljs-number">19513</span>, <span class="hljs-number">3158</span>, <span class="hljs-number">5477</span>, <span class="hljs-number">4168</span>, <span class="hljs-number">2030</span>, <span class="hljs-number">7112</span>, <span class="hljs-number">16562</span>, <span class="hljs-number">2140</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),O=new ka({}),U=new cs({props:{code:"label2id = {'entailment': 0, 'neutral': 1, 'contradiction': 2}",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>label2id = {<span class="hljs-string">&#x27;entailment&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;neutral&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;contradiction&#x27;</span>: <span class="hljs-number">2</span>}'}}),Y=new cs({props:{code:'label2id = {"contradiction": 0, "neutral": 1, "entailment": 2}',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>label2id = {<span class="hljs-string">&quot;contradiction&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;neutral&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;entailment&quot;</span>: <span class="hljs-number">2</span>}'}}),G=new cs({props:{code:`from datasets import load_dataset

mnli = load_dataset("glue", "mnli", split="train")
mnli_aligned = mnli.align_labels_with_mapping(label2id, "label")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>mnli = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>mnli_aligned = mnli.align_labels_with_mapping(label2id, <span class="hljs-string">&quot;label&quot;</span>)`}}),{c(){f=l("meta"),ms=m(),j=l("h1"),_=l("a"),as=l("span"),P(S.$$.fragment),Fs=m(),ns=l("span"),Hs=p("Process text data"),is=m(),J=l("p"),Os=p("This guide shows specific methods for processing text datasets. Learn how to:"),us=m(),$=l("ul"),I=l("li"),Bs=p("Tokenize a dataset with "),R=l("a"),Us=p("map()"),Ys=p("."),Gs=m(),es=l("li"),Js=p("Align dataset labels with label ids for NLI datasets."),bs=m(),v=l("p"),Rs=p("For a guide on processing any type of dataset, take a look at the "),M=l("a"),Ks=p("general process guide"),Qs=p("."),fs=m(),d=l("h2"),w=l("a"),ls=l("span"),P(D.$$.fragment),Vs=m(),ts=l("span"),Ws=p("Map"),js=m(),k=l("p"),Xs=p("The "),K=l("a"),Zs=p("map()"),sa=p(" function supports processing batches of examples at once which speeds up tokenization."),ds=m(),x=l("p"),aa=p("Load a tokenizer from \u{1F917} "),C=l("a"),na=p("Transformers"),ea=p(":"),gs=m(),P(F.$$.fragment),_s=m(),u=l("p"),la=p("Set the "),ps=l("code"),ta=p("batched"),pa=p(" parameter to "),rs=l("code"),ra=p("True"),ha=p(" in the "),Q=l("a"),oa=p("map()"),ca=p(" function to apply the tokenizer to batches of examples:"),$s=m(),P(H.$$.fragment),vs=m(),g=l("h2"),y=l("a"),hs=l("span"),P(O.$$.fragment),ma=m(),os=l("span"),ia=p("Align"),ws=m(),b=l("p"),ua=p("The "),V=l("a"),ba=p("align_labels_with_mapping()"),fa=p(" function aligns a dataset label id with the label name. Not all \u{1F917} Transformers models follow the prescribed label mapping of the original dataset, especially for NLI datasets. For example, the "),B=l("a"),ja=p("MNLI"),da=p(" dataset uses the following label mapping:"),ks=m(),P(U.$$.fragment),xs=m(),W=l("p"),ga=p("To align the dataset label mapping with the mapping used by a model, create a dictionary of the label name and id to align on:"),ys=m(),P(Y.$$.fragment),Es=m(),E=l("p"),_a=p("Pass the dictionary of the label mappings to the "),X=l("a"),$a=p("align_labels_with_mapping()"),va=p(" function, and the column to align on:"),As=m(),P(G.$$.fragment),Ps=m(),Z=l("p"),wa=p("You can also use this function to assign a custom mapping of labels to ids."),this.h()},l(s){const e=Wa('[data-svelte="svelte-1phssyn"]',document.head);f=t(e,"META",{name:!0,content:!0}),e.forEach(a),ms=i(s),j=t(s,"H1",{class:!0});var qs=r(j);_=t(qs,"A",{id:!0,class:!0,href:!0});var ya=r(_);as=t(ya,"SPAN",{});var Ea=r(as);T(S.$$.fragment,Ea),Ea.forEach(a),ya.forEach(a),Fs=i(qs),ns=t(qs,"SPAN",{});var Aa=r(ns);Hs=h(Aa,"Process text data"),Aa.forEach(a),qs.forEach(a),is=i(s),J=t(s,"P",{});var Pa=r(J);Os=h(Pa,"This guide shows specific methods for processing text datasets. Learn how to:"),Pa.forEach(a),us=i(s),$=t(s,"UL",{});var zs=r($);I=t(zs,"LI",{});var Ls=r(I);Bs=h(Ls,"Tokenize a dataset with "),R=t(Ls,"A",{href:!0});var Ta=r(R);Us=h(Ta,"map()"),Ta.forEach(a),Ys=h(Ls,"."),Ls.forEach(a),Gs=i(zs),es=t(zs,"LI",{});var qa=r(es);Js=h(qa,"Align dataset labels with label ids for NLI datasets."),qa.forEach(a),zs.forEach(a),bs=i(s),v=t(s,"P",{});var Ns=r(v);Rs=h(Ns,"For a guide on processing any type of dataset, take a look at the "),M=t(Ns,"A",{class:!0,href:!0});var za=r(M);Ks=h(za,"general process guide"),za.forEach(a),Qs=h(Ns,"."),Ns.forEach(a),fs=i(s),d=t(s,"H2",{class:!0});var Ss=r(d);w=t(Ss,"A",{id:!0,class:!0,href:!0});var La=r(w);ls=t(La,"SPAN",{});var Na=r(ls);T(D.$$.fragment,Na),Na.forEach(a),La.forEach(a),Vs=i(Ss),ts=t(Ss,"SPAN",{});var Sa=r(ts);Ws=h(Sa,"Map"),Sa.forEach(a),Ss.forEach(a),js=i(s),k=t(s,"P",{});var Is=r(k);Xs=h(Is,"The "),K=t(Is,"A",{href:!0});var Ia=r(K);Zs=h(Ia,"map()"),Ia.forEach(a),sa=h(Is," function supports processing batches of examples at once which speeds up tokenization."),Is.forEach(a),ds=i(s),x=t(s,"P",{});var Ms=r(x);aa=h(Ms,"Load a tokenizer from \u{1F917} "),C=t(Ms,"A",{href:!0,rel:!0});var Ma=r(C);na=h(Ma,"Transformers"),Ma.forEach(a),ea=h(Ms,":"),Ms.forEach(a),gs=i(s),T(F.$$.fragment,s),_s=i(s),u=t(s,"P",{});var A=r(u);la=h(A,"Set the "),ps=t(A,"CODE",{});var Da=r(ps);ta=h(Da,"batched"),Da.forEach(a),pa=h(A," parameter to "),rs=t(A,"CODE",{});var Ca=r(rs);ra=h(Ca,"True"),Ca.forEach(a),ha=h(A," in the "),Q=t(A,"A",{href:!0});var Fa=r(Q);oa=h(Fa,"map()"),Fa.forEach(a),ca=h(A," function to apply the tokenizer to batches of examples:"),A.forEach(a),$s=i(s),T(H.$$.fragment,s),vs=i(s),g=t(s,"H2",{class:!0});var Ds=r(g);y=t(Ds,"A",{id:!0,class:!0,href:!0});var Ha=r(y);hs=t(Ha,"SPAN",{});var Oa=r(hs);T(O.$$.fragment,Oa),Oa.forEach(a),Ha.forEach(a),ma=i(Ds),os=t(Ds,"SPAN",{});var Ba=r(os);ia=h(Ba,"Align"),Ba.forEach(a),Ds.forEach(a),ws=i(s),b=t(s,"P",{});var ss=r(b);ua=h(ss,"The "),V=t(ss,"A",{href:!0});var Ua=r(V);ba=h(Ua,"align_labels_with_mapping()"),Ua.forEach(a),fa=h(ss," function aligns a dataset label id with the label name. Not all \u{1F917} Transformers models follow the prescribed label mapping of the original dataset, especially for NLI datasets. For example, the "),B=t(ss,"A",{href:!0,rel:!0});var Ya=r(B);ja=h(Ya,"MNLI"),Ya.forEach(a),da=h(ss," dataset uses the following label mapping:"),ss.forEach(a),ks=i(s),T(U.$$.fragment,s),xs=i(s),W=t(s,"P",{});var Ga=r(W);ga=h(Ga,"To align the dataset label mapping with the mapping used by a model, create a dictionary of the label name and id to align on:"),Ga.forEach(a),ys=i(s),T(Y.$$.fragment,s),Es=i(s),E=t(s,"P",{});var Cs=r(E);_a=h(Cs,"Pass the dictionary of the label mappings to the "),X=t(Cs,"A",{href:!0});var Ja=r(X);$a=h(Ja,"align_labels_with_mapping()"),Ja.forEach(a),va=h(Cs," function, and the column to align on:"),Cs.forEach(a),As=i(s),T(G.$$.fragment,s),Ps=i(s),Z=t(s,"P",{});var Ra=r(Z);wa=h(Ra,"You can also use this function to assign a custom mapping of labels to ids."),Ra.forEach(a),this.h()},h(){c(f,"name","hf:doc:metadata"),c(f,"content",JSON.stringify(an)),c(_,"id","process-text-data"),c(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_,"href","#process-text-data"),c(j,"class","relative group"),c(R,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Dataset.map"),c(M,"class","bg-pink-200 dark:bg-pink-500 px-1 rounded font-bold underline decoration-pink-900 text-pink-900 dark:bg-pink-500"),c(M,"href","./process"),c(w,"id","map"),c(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w,"href","#map"),c(d,"class","relative group"),c(K,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Dataset.map"),c(C,"href","https://huggingface.co/transformers/"),c(C,"rel","nofollow"),c(Q,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Dataset.map"),c(y,"id","align"),c(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y,"href","#align"),c(g,"class","relative group"),c(V,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping"),c(B,"href","https://huggingface.co/datasets/glue"),c(B,"rel","nofollow"),c(X,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping")},m(s,e){n(document.head,f),o(s,ms,e),o(s,j,e),n(j,_),n(_,as),q(S,as,null),n(j,Fs),n(j,ns),n(ns,Hs),o(s,is,e),o(s,J,e),n(J,Os),o(s,us,e),o(s,$,e),n($,I),n(I,Bs),n(I,R),n(R,Us),n(I,Ys),n($,Gs),n($,es),n(es,Js),o(s,bs,e),o(s,v,e),n(v,Rs),n(v,M),n(M,Ks),n(v,Qs),o(s,fs,e),o(s,d,e),n(d,w),n(w,ls),q(D,ls,null),n(d,Vs),n(d,ts),n(ts,Ws),o(s,js,e),o(s,k,e),n(k,Xs),n(k,K),n(K,Zs),n(k,sa),o(s,ds,e),o(s,x,e),n(x,aa),n(x,C),n(C,na),n(x,ea),o(s,gs,e),q(F,s,e),o(s,_s,e),o(s,u,e),n(u,la),n(u,ps),n(ps,ta),n(u,pa),n(u,rs),n(rs,ra),n(u,ha),n(u,Q),n(Q,oa),n(u,ca),o(s,$s,e),q(H,s,e),o(s,vs,e),o(s,g,e),n(g,y),n(y,hs),q(O,hs,null),n(g,ma),n(g,os),n(os,ia),o(s,ws,e),o(s,b,e),n(b,ua),n(b,V),n(V,ba),n(b,fa),n(b,B),n(B,ja),n(b,da),o(s,ks,e),q(U,s,e),o(s,xs,e),o(s,W,e),n(W,ga),o(s,ys,e),q(Y,s,e),o(s,Es,e),o(s,E,e),n(E,_a),n(E,X),n(X,$a),n(E,va),o(s,As,e),q(G,s,e),o(s,Ps,e),o(s,Z,e),n(Z,wa),Ts=!0},p:Xa,i(s){Ts||(z(S.$$.fragment,s),z(D.$$.fragment,s),z(F.$$.fragment,s),z(H.$$.fragment,s),z(O.$$.fragment,s),z(U.$$.fragment,s),z(Y.$$.fragment,s),z(G.$$.fragment,s),Ts=!0)},o(s){L(S.$$.fragment,s),L(D.$$.fragment,s),L(F.$$.fragment,s),L(H.$$.fragment,s),L(O.$$.fragment,s),L(U.$$.fragment,s),L(Y.$$.fragment,s),L(G.$$.fragment,s),Ts=!1},d(s){a(f),s&&a(ms),s&&a(j),N(S),s&&a(is),s&&a(J),s&&a(us),s&&a($),s&&a(bs),s&&a(v),s&&a(fs),s&&a(d),N(D),s&&a(js),s&&a(k),s&&a(ds),s&&a(x),s&&a(gs),N(F,s),s&&a(_s),s&&a(u),s&&a($s),N(H,s),s&&a(vs),s&&a(g),N(O),s&&a(ws),s&&a(b),s&&a(ks),N(U,s),s&&a(xs),s&&a(W),s&&a(ys),N(Y,s),s&&a(Es),s&&a(E),s&&a(As),N(G,s),s&&a(Ps),s&&a(Z)}}}const an={local:"process-text-data",sections:[{local:"map",title:"Map"},{local:"align",title:"Align"}],title:"Process text data"};function nn(xa){return Za(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pn extends Ka{constructor(f){super();Qa(this,f,nn,sn,Va,{})}}export{pn as default,an as metadata};
