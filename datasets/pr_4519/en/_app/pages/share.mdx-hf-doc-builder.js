import{S as Br,i as Vr,s as Wr,e as o,k as u,w as c,t as n,M as Kr,c as s,d as t,m as d,a as r,x as m,h as f,b as h,G as a,g as i,y,q as v,o as g,B as w,v as Qr}from"../chunks/vendor-hf-doc-builder.js";import{T as Xr}from"../chunks/Tip-hf-doc-builder.js";import{I as je}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as W}from"../chunks/CodeBlock-hf-doc-builder.js";function el(qt){let p,D;return{c(){p=o("p"),D=n("The distinction between a Hub dataset and a dataset from GitHub only comes from the legacy sharing workflow. It does not involve any ranking, decisioning, or opinion regarding the contents of the dataset itself.")},l(_){p=s(_,"P",{});var b=r(p);D=f(b,"The distinction between a Hub dataset and a dataset from GitHub only comes from the legacy sharing workflow. It does not involve any ranking, decisioning, or opinion regarding the contents of the dataset itself."),b.forEach(t)},m(_,b){i(_,p,b),a(p,D)},d(_){_&&t(p)}}}function tl(qt){let p,D,_,b,Be,K,Za,Ve,Ra,Ct,Pe,Ya,Nt,Le,Ja,Ot,$,We,Ba,Va,Ke,Wa,Ka,Qe,Qa,Xa,Xe,eo,to,et,ao,Gt,Ae,oo,Mt,Ie,zt,P,T,tt,Q,so,at,ro,Ut,Se,lo,Zt,Fe,io,Rt,x,no,ot,fo,uo,Yt,De,ho,Jt,Te,po,Bt,q,st,co,mo,rt,yo,Vt,C,vo,xe,go,wo,Wt,L,N,lt,X,_o,it,$o,Kt,k,bo,ee,Eo,ko,te,Ho,jo,Qt,qe,nt,Po,Xt,ae,ea,oe,ft,Lo,ta,se,aa,O,Ao,ut,Io,So,oa,re,sa,A,G,dt,le,Fo,ht,Do,ra,ie,ne,To,fe,xo,qo,la,ue,ia,M,Co,pt,No,Oo,na,I,z,ct,de,Go,mt,Mo,fa,he,yt,zo,ua,E,vt,U,gt,Uo,Zo,Ce,Ro,Yo,Jo,wt,pe,Bo,Ne,Vo,Wo,Ko,_t,Z,$t,Qo,Xo,Oe,es,ts,as,bt,Ge,Et,os,ss,da,S,R,kt,ce,rs,Ht,ls,ha,Me,is,pa,me,ye,ns,jt,fs,us,ca,ve,ma,ge,Pt,ds,ya,we,va,_e,Lt,hs,ga,$e,wa,ze,ps,_a,be,$a,F,Y,At,Ee,cs,It,ms,ba,Ue,ys,Ea,J,ka,Ze,vs,Ha,Re,gs,ja,H,St,ws,_s,Ft,$s,bs,Dt,Es,Pa,B,ks,ke,Hs,js,La;return K=new je({}),Q=new je({}),X=new je({}),ae=new W({props:{code:"huggingface-cli login",highlighted:'huggingface-<span class="hljs-keyword">cli</span> login'}}),se=new W({props:{code:"huggingface-cli repo create your_dataset_name --type dataset",highlighted:'huggingface-cli repo <span class="hljs-keyword">create</span> your_dataset_name --<span class="hljs-built_in">type</span> <span class="hljs-keyword">dataset</span>'}}),re=new W({props:{code:"huggingface-cli repo create your_dataset_name --type dataset --organization your-org-name",highlighted:'huggingface-cli repo <span class="hljs-keyword">create</span> your_dataset_name --<span class="hljs-built_in">type</span> <span class="hljs-keyword">dataset</span> --organization your-org-name'}}),le=new je({}),ue=new W({props:{code:"",highlighted:`<span class="hljs-comment"># Make sure you have git-lfs installed</span>
<span class="hljs-comment"># (https://git-lfs.github.com/)</span>
git lfs install

git clone https:<span class="hljs-regexp">//</span>huggingface.co<span class="hljs-regexp">/datasets/</span>namespace/your_dataset_name`}}),de=new je({}),ce=new je({}),ve=new W({props:{code:`cp /somewhere/data/*.json .
git lfs track *.json
git add .gitattributes
git add *.json
git commit -m "add json files"`,highlighted:`cp <span class="hljs-string">/somewhere/data/</span>*<span class="hljs-string">.json</span> .
git lfs track *<span class="hljs-string">.json</span>
git add <span class="hljs-string">.gitattributes</span>
git add *<span class="hljs-string">.json</span>
git commit -m <span class="hljs-string">&quot;add json files&quot;</span>`}}),we=new W({props:{code:`cp /somewhere/data/dataset_infos.json .
cp /somewhere/data/load_script.py .
git add --all`,highlighted:`<span class="hljs-title">cp</span> /somewhere/<span class="hljs-class"><span class="hljs-keyword">data</span>/dataset_infos.json .</span>
<span class="hljs-title">cp</span> /somewhere/<span class="hljs-class"><span class="hljs-keyword">data</span>/load_script.py .</span>
<span class="hljs-title">git</span> add <span class="hljs-comment">--all</span>`}}),$e=new W({props:{code:`git status
git commit -m "First version of the your_dataset_name dataset."
git push`,highlighted:`git <span class="hljs-built_in">status</span>
git commit -m <span class="hljs-string">&quot;First version of the your_dataset_name dataset.&quot;</span>
git <span class="hljs-built_in">push</span>`}}),be=new W({props:{code:'dataset = load_dataset("namespace/your_dataset_name")',highlighted:'<span class="hljs-attribute">dataset</span> <span class="hljs-operator">=</span> load_dataset(<span class="hljs-string">&quot;namespace/your_dataset_name&quot;</span>)'}}),Ee=new je({}),J=new Xr({props:{$$slots:{default:[el]},$$scope:{ctx:qt}}}),{c(){p=o("meta"),D=u(),_=o("h1"),b=o("a"),Be=o("span"),c(K.$$.fragment),Za=u(),Ve=o("span"),Ra=n("Share"),Ct=u(),Pe=o("p"),Ya=n("At Hugging Face, we are on a mission to democratize good Machine Learning and we believe in the value of open source. That\u2019s why we designed \u{1F917} Datasets so that anyone can share a dataset with the greater ML community. There are currently thousands of datasets in over 100 languages in the Hugging Face Hub, and the Hugging Face team always welcomes new contributions!"),Nt=u(),Le=o("p"),Ja=n("Dataset repositories offer features such as:"),Ot=u(),$=o("ul"),We=o("li"),Ba=n("Free dataset hosting"),Va=u(),Ke=o("li"),Wa=n("Dataset versioning"),Ka=u(),Qe=o("li"),Qa=n("Commit history and diffs"),Xa=u(),Xe=o("li"),eo=n("Metadata for discoverability"),to=u(),et=o("li"),ao=n("Dataset cards for documentation, licensing, limitations, etc."),Gt=u(),Ae=o("p"),oo=n("This guide will show you how to share a dataset that can be easily accessed by anyone."),Mt=u(),Ie=o("a"),zt=u(),P=o("h2"),T=o("a"),tt=o("span"),c(Q.$$.fragment),so=u(),at=o("span"),ro=n("Add a dataset"),Ut=u(),Se=o("p"),lo=n(`You can share your dataset with the community with a dataset repository on the Hugging Face Hub.
It can also be a private dataset if you want to control who has access to it.`),Zt=u(),Fe=o("p"),io=n("In a dataset repository, you can either host all your data files and/or use a dataset script."),Rt=u(),x=o("p"),no=n(`The dataset script is optional if your dataset is in one of the following formats: CSV, JSON, JSON lines, text or Parquet.
The script also supports many kinds of compressed file types such as: GZ, BZ2, LZ4, LZMA or ZSTD.
For example, your dataset can be made of `),ot=o("code"),fo=n(".json.gz"),uo=n(" files."),Yt=u(),De=o("p"),ho=n("On the other hand, if your dataset is not in a supported format or if you want more control over how your dataset is loaded, you can write your own dataset script."),Jt=u(),Te=o("p"),po=n("When loading a dataset from the Hub:"),Bt=u(),q=o("ul"),st=o("li"),co=n("If there\u2019s no dataset script, all the files in the supported formats are loaded."),mo=u(),rt=o("li"),yo=n("If there\u2019s a dataset script, it is downloaded and executed to download and prepare the dataset."),Vt=u(),C=o("p"),vo=n("For more information on how to load a dataset from the Hub, take a look at the "),xe=o("a"),go=n("load a dataset from the Hub"),wo=n(" tutorial."),Wt=u(),L=o("h3"),N=o("a"),lt=o("span"),c(X.$$.fragment),_o=u(),it=o("span"),$o=n("Create the repository"),Kt=u(),k=o("p"),bo=n("Sharing a community dataset will require you to create an account on "),ee=o("a"),Eo=n("hf.co"),ko=n(` if you don\u2019t have one yet.
You can directly create a `),te=o("a"),Ho=n("new dataset repository"),jo=n(" from your account on the Hugging Face Hub, but this guide will show you how to upload a dataset from the terminal."),Qt=u(),qe=o("ol"),nt=o("li"),Po=n("Make sure you are in the virtual environment where you installed Datasets, and run the following command:"),Xt=u(),c(ae.$$.fragment),ea=u(),oe=o("ol"),ft=o("li"),Lo=n("Login using your Hugging Face Hub credentials, and create a new dataset repository:"),ta=u(),c(se.$$.fragment),aa=u(),O=o("p"),Ao=n("Add the "),ut=o("code"),Io=n("-organization"),So=n(" flag to create a repository under a specific organization:"),oa=u(),c(re.$$.fragment),sa=u(),A=o("h3"),G=o("a"),dt=o("span"),c(le.$$.fragment),Fo=u(),ht=o("span"),Do=n("Clone the repository"),ra=u(),ie=o("ol"),ne=o("li"),To=n("Install "),fe=o("a"),xo=n("Git LFS"),qo=n(" and clone your repository:"),la=u(),c(ue.$$.fragment),ia=u(),M=o("p"),Co=n("Here the "),pt=o("code"),No=n("namespace"),Oo=n(" is either your username or your organization name."),na=u(),I=o("h3"),z=o("a"),ct=o("span"),c(de.$$.fragment),Go=u(),mt=o("span"),Mo=n("Prepare your files"),fa=u(),he=o("ol"),yt=o("li"),zo=n("Now is a good time to check your directory to ensure the only files you\u2019re uploading are:"),ua=u(),E=o("ul"),vt=o("li"),U=o("p"),gt=o("code"),Uo=n("README.md"),Zo=n(" is a Dataset card that describes the datasets contents, creation, and usage. To write a Dataset card, see the "),Ce=o("a"),Ro=n("dataset card"),Yo=n(" page."),Jo=u(),wt=o("li"),pe=o("p"),Bo=n("The raw data files of the dataset (optional, if they are hosted elsewhere you can specify the URLs in the dataset script). If you don\u2019t need a dataset script, you can take a look at "),Ne=o("a"),Vo=n("how to structure your dataset repository for your data files"),Wo=n("."),Ko=u(),_t=o("li"),Z=o("p"),$t=o("code"),Qo=n("your_dataset_name.py"),Xo=n(" is your dataset loading script (optional if your data files are already in the supported formats csv/jsonl/json/parquet/txt). To create a dataset script, see the "),Oe=o("a"),es=n("dataset script"),ts=n(" page."),as=u(),bt=o("li"),Ge=o("p"),Et=o("code"),os=n("dataset_infos.json"),ss=n(" contains metadata about the dataset (required only if you have a dataset script, or if you want to specify custom feature types)."),da=u(),S=o("h3"),R=o("a"),kt=o("span"),c(ce.$$.fragment),rs=u(),Ht=o("span"),ls=n("Upload your files"),ha=u(),Me=o("p"),is=n("You can directly upload your files from your repository on the Hugging Face Hub, but this guide will show you how to upload the files from the terminal."),pa=u(),me=o("ol"),ye=o("li"),ns=n("It is important to add the large data files first with "),jt=o("code"),fs=n("git lfs track"),us=n(" or else you will encounter an error later when you push your files:"),ca=u(),c(ve.$$.fragment),ma=u(),ge=o("ol"),Pt=o("li"),ds=n("Add the dataset loading script and metadata file:"),ya=u(),c(we.$$.fragment),va=u(),_e=o("ol"),Lt=o("li"),hs=n("Verify the files have been correctly staged. Then you can commit and push your files:"),ga=u(),c($e.$$.fragment),wa=u(),ze=o("p"),ps=n("Congratulations, your dataset has now been uploaded to the Hugging Face Hub where anyone can load it in a single line of code! \u{1F973}"),_a=u(),c(be.$$.fragment),$a=u(),F=o("h2"),Y=o("a"),At=o("span"),c(Ee.$$.fragment),cs=u(),It=o("span"),ms=n("Datasets on GitHub (legacy)"),ba=u(),Ue=o("p"),ys=n(`Datasets used to be hosted on our GitHub repository, but all datasets have now been migrated to the Hugging Face Hub.
The legacy GitHub datasets were added originally on our GitHub repository and therefore don\u2019t have a namespace: \u201Csquad\u201D, \u201Cglue\u201D, etc. unlike the other datasets that are named \u201Cusername/dataset_name\u201D or \u201Corg/dataset_name\u201D.
Those datasets are still maintained, and if you\u2019d like to edit them, please open a Pull Request on the huggingface/datasets repository.
Sharing your dataset to the Hub is the recommended way of adding a dataset.`),Ea=u(),c(J.$$.fragment),ka=u(),Ze=o("p"),vs=n("The code of these datasets are reviewed by the Hugging Face team, and they require test data in order to be regularly tested."),Ha=u(),Re=o("p"),gs=n("In some cases it makes more sense to open a PR on GitHub:"),ja=u(),H=o("ul"),St=o("li"),ws=n("when you need the dataset to be reviewed"),_s=u(),Ft=o("li"),$s=n("when you need long-term maintenance from the Hugging Face team"),bs=u(),Dt=o("li"),Es=n("when there\u2019s no clear org name / namespace that you can put the dataset under"),Pa=u(),B=o("p"),ks=n("For more info, please take a look at the documentation on "),ke=o("a"),Hs=n("How to add a new dataset in the huggingface/datasets repository"),js=n("."),this.h()},l(e){const l=Kr('[data-svelte="svelte-1phssyn"]',document.head);p=s(l,"META",{name:!0,content:!0}),l.forEach(t),D=d(e),_=s(e,"H1",{class:!0});var He=r(_);b=s(He,"A",{id:!0,class:!0,href:!0});var Ls=r(b);Be=s(Ls,"SPAN",{});var As=r(Be);m(K.$$.fragment,As),As.forEach(t),Ls.forEach(t),Za=d(He),Ve=s(He,"SPAN",{});var Is=r(Ve);Ra=f(Is,"Share"),Is.forEach(t),He.forEach(t),Ct=d(e),Pe=s(e,"P",{});var Ss=r(Pe);Ya=f(Ss,"At Hugging Face, we are on a mission to democratize good Machine Learning and we believe in the value of open source. That\u2019s why we designed \u{1F917} Datasets so that anyone can share a dataset with the greater ML community. There are currently thousands of datasets in over 100 languages in the Hugging Face Hub, and the Hugging Face team always welcomes new contributions!"),Ss.forEach(t),Nt=d(e),Le=s(e,"P",{});var Fs=r(Le);Ja=f(Fs,"Dataset repositories offer features such as:"),Fs.forEach(t),Ot=d(e),$=s(e,"UL",{});var j=r($);We=s(j,"LI",{});var Ds=r(We);Ba=f(Ds,"Free dataset hosting"),Ds.forEach(t),Va=d(j),Ke=s(j,"LI",{});var Ts=r(Ke);Wa=f(Ts,"Dataset versioning"),Ts.forEach(t),Ka=d(j),Qe=s(j,"LI",{});var xs=r(Qe);Qa=f(xs,"Commit history and diffs"),xs.forEach(t),Xa=d(j),Xe=s(j,"LI",{});var qs=r(Xe);eo=f(qs,"Metadata for discoverability"),qs.forEach(t),to=d(j),et=s(j,"LI",{});var Cs=r(et);ao=f(Cs,"Dataset cards for documentation, licensing, limitations, etc."),Cs.forEach(t),j.forEach(t),Gt=d(e),Ae=s(e,"P",{});var Ns=r(Ae);oo=f(Ns,"This guide will show you how to share a dataset that can be easily accessed by anyone."),Ns.forEach(t),Mt=d(e),Ie=s(e,"A",{id:!0}),r(Ie).forEach(t),zt=d(e),P=s(e,"H2",{class:!0});var Aa=r(P);T=s(Aa,"A",{id:!0,class:!0,href:!0});var Os=r(T);tt=s(Os,"SPAN",{});var Gs=r(tt);m(Q.$$.fragment,Gs),Gs.forEach(t),Os.forEach(t),so=d(Aa),at=s(Aa,"SPAN",{});var Ms=r(at);ro=f(Ms,"Add a dataset"),Ms.forEach(t),Aa.forEach(t),Ut=d(e),Se=s(e,"P",{});var zs=r(Se);lo=f(zs,`You can share your dataset with the community with a dataset repository on the Hugging Face Hub.
It can also be a private dataset if you want to control who has access to it.`),zs.forEach(t),Zt=d(e),Fe=s(e,"P",{});var Us=r(Fe);io=f(Us,"In a dataset repository, you can either host all your data files and/or use a dataset script."),Us.forEach(t),Rt=d(e),x=s(e,"P",{});var Ia=r(x);no=f(Ia,`The dataset script is optional if your dataset is in one of the following formats: CSV, JSON, JSON lines, text or Parquet.
The script also supports many kinds of compressed file types such as: GZ, BZ2, LZ4, LZMA or ZSTD.
For example, your dataset can be made of `),ot=s(Ia,"CODE",{});var Zs=r(ot);fo=f(Zs,".json.gz"),Zs.forEach(t),uo=f(Ia," files."),Ia.forEach(t),Yt=d(e),De=s(e,"P",{});var Rs=r(De);ho=f(Rs,"On the other hand, if your dataset is not in a supported format or if you want more control over how your dataset is loaded, you can write your own dataset script."),Rs.forEach(t),Jt=d(e),Te=s(e,"P",{});var Ys=r(Te);po=f(Ys,"When loading a dataset from the Hub:"),Ys.forEach(t),Bt=d(e),q=s(e,"UL",{});var Sa=r(q);st=s(Sa,"LI",{});var Js=r(st);co=f(Js,"If there\u2019s no dataset script, all the files in the supported formats are loaded."),Js.forEach(t),mo=d(Sa),rt=s(Sa,"LI",{});var Bs=r(rt);yo=f(Bs,"If there\u2019s a dataset script, it is downloaded and executed to download and prepare the dataset."),Bs.forEach(t),Sa.forEach(t),Vt=d(e),C=s(e,"P",{});var Fa=r(C);vo=f(Fa,"For more information on how to load a dataset from the Hub, take a look at the "),xe=s(Fa,"A",{href:!0});var Vs=r(xe);go=f(Vs,"load a dataset from the Hub"),Vs.forEach(t),wo=f(Fa," tutorial."),Fa.forEach(t),Wt=d(e),L=s(e,"H3",{class:!0});var Da=r(L);N=s(Da,"A",{id:!0,class:!0,href:!0});var Ws=r(N);lt=s(Ws,"SPAN",{});var Ks=r(lt);m(X.$$.fragment,Ks),Ks.forEach(t),Ws.forEach(t),_o=d(Da),it=s(Da,"SPAN",{});var Qs=r(it);$o=f(Qs,"Create the repository"),Qs.forEach(t),Da.forEach(t),Kt=d(e),k=s(e,"P",{});var Ye=r(k);bo=f(Ye,"Sharing a community dataset will require you to create an account on "),ee=s(Ye,"A",{href:!0,rel:!0});var Xs=r(ee);Eo=f(Xs,"hf.co"),Xs.forEach(t),ko=f(Ye,` if you don\u2019t have one yet.
You can directly create a `),te=s(Ye,"A",{href:!0,rel:!0});var er=r(te);Ho=f(er,"new dataset repository"),er.forEach(t),jo=f(Ye," from your account on the Hugging Face Hub, but this guide will show you how to upload a dataset from the terminal."),Ye.forEach(t),Qt=d(e),qe=s(e,"OL",{});var tr=r(qe);nt=s(tr,"LI",{});var ar=r(nt);Po=f(ar,"Make sure you are in the virtual environment where you installed Datasets, and run the following command:"),ar.forEach(t),tr.forEach(t),Xt=d(e),m(ae.$$.fragment,e),ea=d(e),oe=s(e,"OL",{start:!0});var or=r(oe);ft=s(or,"LI",{});var sr=r(ft);Lo=f(sr,"Login using your Hugging Face Hub credentials, and create a new dataset repository:"),sr.forEach(t),or.forEach(t),ta=d(e),m(se.$$.fragment,e),aa=d(e),O=s(e,"P",{});var Ta=r(O);Ao=f(Ta,"Add the "),ut=s(Ta,"CODE",{});var rr=r(ut);Io=f(rr,"-organization"),rr.forEach(t),So=f(Ta," flag to create a repository under a specific organization:"),Ta.forEach(t),oa=d(e),m(re.$$.fragment,e),sa=d(e),A=s(e,"H3",{class:!0});var xa=r(A);G=s(xa,"A",{id:!0,class:!0,href:!0});var lr=r(G);dt=s(lr,"SPAN",{});var ir=r(dt);m(le.$$.fragment,ir),ir.forEach(t),lr.forEach(t),Fo=d(xa),ht=s(xa,"SPAN",{});var nr=r(ht);Do=f(nr,"Clone the repository"),nr.forEach(t),xa.forEach(t),ra=d(e),ie=s(e,"OL",{start:!0});var fr=r(ie);ne=s(fr,"LI",{});var qa=r(ne);To=f(qa,"Install "),fe=s(qa,"A",{href:!0,rel:!0});var ur=r(fe);xo=f(ur,"Git LFS"),ur.forEach(t),qo=f(qa," and clone your repository:"),qa.forEach(t),fr.forEach(t),la=d(e),m(ue.$$.fragment,e),ia=d(e),M=s(e,"P",{});var Ca=r(M);Co=f(Ca,"Here the "),pt=s(Ca,"CODE",{});var dr=r(pt);No=f(dr,"namespace"),dr.forEach(t),Oo=f(Ca," is either your username or your organization name."),Ca.forEach(t),na=d(e),I=s(e,"H3",{class:!0});var Na=r(I);z=s(Na,"A",{id:!0,class:!0,href:!0});var hr=r(z);ct=s(hr,"SPAN",{});var pr=r(ct);m(de.$$.fragment,pr),pr.forEach(t),hr.forEach(t),Go=d(Na),mt=s(Na,"SPAN",{});var cr=r(mt);Mo=f(cr,"Prepare your files"),cr.forEach(t),Na.forEach(t),fa=d(e),he=s(e,"OL",{start:!0});var mr=r(he);yt=s(mr,"LI",{});var yr=r(yt);zo=f(yr,"Now is a good time to check your directory to ensure the only files you\u2019re uploading are:"),yr.forEach(t),mr.forEach(t),ua=d(e),E=s(e,"UL",{});var V=r(E);vt=s(V,"LI",{});var vr=r(vt);U=s(vr,"P",{});var Tt=r(U);gt=s(Tt,"CODE",{});var gr=r(gt);Uo=f(gr,"README.md"),gr.forEach(t),Zo=f(Tt," is a Dataset card that describes the datasets contents, creation, and usage. To write a Dataset card, see the "),Ce=s(Tt,"A",{href:!0});var wr=r(Ce);Ro=f(wr,"dataset card"),wr.forEach(t),Yo=f(Tt," page."),Tt.forEach(t),vr.forEach(t),Jo=d(V),wt=s(V,"LI",{});var _r=r(wt);pe=s(_r,"P",{});var Oa=r(pe);Bo=f(Oa,"The raw data files of the dataset (optional, if they are hosted elsewhere you can specify the URLs in the dataset script). If you don\u2019t need a dataset script, you can take a look at "),Ne=s(Oa,"A",{href:!0});var $r=r(Ne);Vo=f($r,"how to structure your dataset repository for your data files"),$r.forEach(t),Wo=f(Oa,"."),Oa.forEach(t),_r.forEach(t),Ko=d(V),_t=s(V,"LI",{});var br=r(_t);Z=s(br,"P",{});var xt=r(Z);$t=s(xt,"CODE",{});var Er=r($t);Qo=f(Er,"your_dataset_name.py"),Er.forEach(t),Xo=f(xt," is your dataset loading script (optional if your data files are already in the supported formats csv/jsonl/json/parquet/txt). To create a dataset script, see the "),Oe=s(xt,"A",{href:!0});var kr=r(Oe);es=f(kr,"dataset script"),kr.forEach(t),ts=f(xt," page."),xt.forEach(t),br.forEach(t),as=d(V),bt=s(V,"LI",{});var Hr=r(bt);Ge=s(Hr,"P",{});var Ps=r(Ge);Et=s(Ps,"CODE",{});var jr=r(Et);os=f(jr,"dataset_infos.json"),jr.forEach(t),ss=f(Ps," contains metadata about the dataset (required only if you have a dataset script, or if you want to specify custom feature types)."),Ps.forEach(t),Hr.forEach(t),V.forEach(t),da=d(e),S=s(e,"H3",{class:!0});var Ga=r(S);R=s(Ga,"A",{id:!0,class:!0,href:!0});var Pr=r(R);kt=s(Pr,"SPAN",{});var Lr=r(kt);m(ce.$$.fragment,Lr),Lr.forEach(t),Pr.forEach(t),rs=d(Ga),Ht=s(Ga,"SPAN",{});var Ar=r(Ht);ls=f(Ar,"Upload your files"),Ar.forEach(t),Ga.forEach(t),ha=d(e),Me=s(e,"P",{});var Ir=r(Me);is=f(Ir,"You can directly upload your files from your repository on the Hugging Face Hub, but this guide will show you how to upload the files from the terminal."),Ir.forEach(t),pa=d(e),me=s(e,"OL",{start:!0});var Sr=r(me);ye=s(Sr,"LI",{});var Ma=r(ye);ns=f(Ma,"It is important to add the large data files first with "),jt=s(Ma,"CODE",{});var Fr=r(jt);fs=f(Fr,"git lfs track"),Fr.forEach(t),us=f(Ma," or else you will encounter an error later when you push your files:"),Ma.forEach(t),Sr.forEach(t),ca=d(e),m(ve.$$.fragment,e),ma=d(e),ge=s(e,"OL",{start:!0});var Dr=r(ge);Pt=s(Dr,"LI",{});var Tr=r(Pt);ds=f(Tr,"Add the dataset loading script and metadata file:"),Tr.forEach(t),Dr.forEach(t),ya=d(e),m(we.$$.fragment,e),va=d(e),_e=s(e,"OL",{start:!0});var xr=r(_e);Lt=s(xr,"LI",{});var qr=r(Lt);hs=f(qr,"Verify the files have been correctly staged. Then you can commit and push your files:"),qr.forEach(t),xr.forEach(t),ga=d(e),m($e.$$.fragment,e),wa=d(e),ze=s(e,"P",{});var Cr=r(ze);ps=f(Cr,"Congratulations, your dataset has now been uploaded to the Hugging Face Hub where anyone can load it in a single line of code! \u{1F973}"),Cr.forEach(t),_a=d(e),m(be.$$.fragment,e),$a=d(e),F=s(e,"H2",{class:!0});var za=r(F);Y=s(za,"A",{id:!0,class:!0,href:!0});var Nr=r(Y);At=s(Nr,"SPAN",{});var Or=r(At);m(Ee.$$.fragment,Or),Or.forEach(t),Nr.forEach(t),cs=d(za),It=s(za,"SPAN",{});var Gr=r(It);ms=f(Gr,"Datasets on GitHub (legacy)"),Gr.forEach(t),za.forEach(t),ba=d(e),Ue=s(e,"P",{});var Mr=r(Ue);ys=f(Mr,`Datasets used to be hosted on our GitHub repository, but all datasets have now been migrated to the Hugging Face Hub.
The legacy GitHub datasets were added originally on our GitHub repository and therefore don\u2019t have a namespace: \u201Csquad\u201D, \u201Cglue\u201D, etc. unlike the other datasets that are named \u201Cusername/dataset_name\u201D or \u201Corg/dataset_name\u201D.
Those datasets are still maintained, and if you\u2019d like to edit them, please open a Pull Request on the huggingface/datasets repository.
Sharing your dataset to the Hub is the recommended way of adding a dataset.`),Mr.forEach(t),Ea=d(e),m(J.$$.fragment,e),ka=d(e),Ze=s(e,"P",{});var zr=r(Ze);vs=f(zr,"The code of these datasets are reviewed by the Hugging Face team, and they require test data in order to be regularly tested."),zr.forEach(t),Ha=d(e),Re=s(e,"P",{});var Ur=r(Re);gs=f(Ur,"In some cases it makes more sense to open a PR on GitHub:"),Ur.forEach(t),ja=d(e),H=s(e,"UL",{});var Je=r(H);St=s(Je,"LI",{});var Zr=r(St);ws=f(Zr,"when you need the dataset to be reviewed"),Zr.forEach(t),_s=d(Je),Ft=s(Je,"LI",{});var Rr=r(Ft);$s=f(Rr,"when you need long-term maintenance from the Hugging Face team"),Rr.forEach(t),bs=d(Je),Dt=s(Je,"LI",{});var Yr=r(Dt);Es=f(Yr,"when there\u2019s no clear org name / namespace that you can put the dataset under"),Yr.forEach(t),Je.forEach(t),Pa=d(e),B=s(e,"P",{});var Ua=r(B);ks=f(Ua,"For more info, please take a look at the documentation on "),ke=s(Ua,"A",{href:!0,rel:!0});var Jr=r(ke);Hs=f(Jr,"How to add a new dataset in the huggingface/datasets repository"),Jr.forEach(t),js=f(Ua,"."),Ua.forEach(t),this.h()},h(){h(p,"name","hf:doc:metadata"),h(p,"content",JSON.stringify(al)),h(b,"id","share"),h(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(b,"href","#share"),h(_,"class","relative group"),h(Ie,"id","upload_dataset_repo"),h(T,"id","add-a-dataset"),h(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(T,"href","#add-a-dataset"),h(P,"class","relative group"),h(xe,"href","./load_hub"),h(N,"id","create-the-repository"),h(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(N,"href","#create-the-repository"),h(L,"class","relative group"),h(ee,"href","https://huggingface.co/join"),h(ee,"rel","nofollow"),h(te,"href","https://huggingface.co/login?next=%2Fnew-dataset"),h(te,"rel","nofollow"),h(oe,"start","2"),h(G,"id","clone-the-repository"),h(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(G,"href","#clone-the-repository"),h(A,"class","relative group"),h(fe,"href","https://git-lfs.github.com/"),h(fe,"rel","nofollow"),h(ie,"start","3"),h(z,"id","prepare-your-files"),h(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(z,"href","#prepare-your-files"),h(I,"class","relative group"),h(he,"start","4"),h(Ce,"href","dataset_card"),h(Ne,"href","repository_structure"),h(Oe,"href","dataset_script"),h(R,"id","upload-your-files"),h(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(R,"href","#upload-your-files"),h(S,"class","relative group"),h(me,"start","5"),h(ge,"start","6"),h(_e,"start","7"),h(Y,"id","datasets-on-github-legacy"),h(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Y,"href","#datasets-on-github-legacy"),h(F,"class","relative group"),h(ke,"href","https://github.com/huggingface/datasets/blob/master/ADD_NEW_DATASET.md"),h(ke,"rel","nofollow")},m(e,l){a(document.head,p),i(e,D,l),i(e,_,l),a(_,b),a(b,Be),y(K,Be,null),a(_,Za),a(_,Ve),a(Ve,Ra),i(e,Ct,l),i(e,Pe,l),a(Pe,Ya),i(e,Nt,l),i(e,Le,l),a(Le,Ja),i(e,Ot,l),i(e,$,l),a($,We),a(We,Ba),a($,Va),a($,Ke),a(Ke,Wa),a($,Ka),a($,Qe),a(Qe,Qa),a($,Xa),a($,Xe),a(Xe,eo),a($,to),a($,et),a(et,ao),i(e,Gt,l),i(e,Ae,l),a(Ae,oo),i(e,Mt,l),i(e,Ie,l),i(e,zt,l),i(e,P,l),a(P,T),a(T,tt),y(Q,tt,null),a(P,so),a(P,at),a(at,ro),i(e,Ut,l),i(e,Se,l),a(Se,lo),i(e,Zt,l),i(e,Fe,l),a(Fe,io),i(e,Rt,l),i(e,x,l),a(x,no),a(x,ot),a(ot,fo),a(x,uo),i(e,Yt,l),i(e,De,l),a(De,ho),i(e,Jt,l),i(e,Te,l),a(Te,po),i(e,Bt,l),i(e,q,l),a(q,st),a(st,co),a(q,mo),a(q,rt),a(rt,yo),i(e,Vt,l),i(e,C,l),a(C,vo),a(C,xe),a(xe,go),a(C,wo),i(e,Wt,l),i(e,L,l),a(L,N),a(N,lt),y(X,lt,null),a(L,_o),a(L,it),a(it,$o),i(e,Kt,l),i(e,k,l),a(k,bo),a(k,ee),a(ee,Eo),a(k,ko),a(k,te),a(te,Ho),a(k,jo),i(e,Qt,l),i(e,qe,l),a(qe,nt),a(nt,Po),i(e,Xt,l),y(ae,e,l),i(e,ea,l),i(e,oe,l),a(oe,ft),a(ft,Lo),i(e,ta,l),y(se,e,l),i(e,aa,l),i(e,O,l),a(O,Ao),a(O,ut),a(ut,Io),a(O,So),i(e,oa,l),y(re,e,l),i(e,sa,l),i(e,A,l),a(A,G),a(G,dt),y(le,dt,null),a(A,Fo),a(A,ht),a(ht,Do),i(e,ra,l),i(e,ie,l),a(ie,ne),a(ne,To),a(ne,fe),a(fe,xo),a(ne,qo),i(e,la,l),y(ue,e,l),i(e,ia,l),i(e,M,l),a(M,Co),a(M,pt),a(pt,No),a(M,Oo),i(e,na,l),i(e,I,l),a(I,z),a(z,ct),y(de,ct,null),a(I,Go),a(I,mt),a(mt,Mo),i(e,fa,l),i(e,he,l),a(he,yt),a(yt,zo),i(e,ua,l),i(e,E,l),a(E,vt),a(vt,U),a(U,gt),a(gt,Uo),a(U,Zo),a(U,Ce),a(Ce,Ro),a(U,Yo),a(E,Jo),a(E,wt),a(wt,pe),a(pe,Bo),a(pe,Ne),a(Ne,Vo),a(pe,Wo),a(E,Ko),a(E,_t),a(_t,Z),a(Z,$t),a($t,Qo),a(Z,Xo),a(Z,Oe),a(Oe,es),a(Z,ts),a(E,as),a(E,bt),a(bt,Ge),a(Ge,Et),a(Et,os),a(Ge,ss),i(e,da,l),i(e,S,l),a(S,R),a(R,kt),y(ce,kt,null),a(S,rs),a(S,Ht),a(Ht,ls),i(e,ha,l),i(e,Me,l),a(Me,is),i(e,pa,l),i(e,me,l),a(me,ye),a(ye,ns),a(ye,jt),a(jt,fs),a(ye,us),i(e,ca,l),y(ve,e,l),i(e,ma,l),i(e,ge,l),a(ge,Pt),a(Pt,ds),i(e,ya,l),y(we,e,l),i(e,va,l),i(e,_e,l),a(_e,Lt),a(Lt,hs),i(e,ga,l),y($e,e,l),i(e,wa,l),i(e,ze,l),a(ze,ps),i(e,_a,l),y(be,e,l),i(e,$a,l),i(e,F,l),a(F,Y),a(Y,At),y(Ee,At,null),a(F,cs),a(F,It),a(It,ms),i(e,ba,l),i(e,Ue,l),a(Ue,ys),i(e,Ea,l),y(J,e,l),i(e,ka,l),i(e,Ze,l),a(Ze,vs),i(e,Ha,l),i(e,Re,l),a(Re,gs),i(e,ja,l),i(e,H,l),a(H,St),a(St,ws),a(H,_s),a(H,Ft),a(Ft,$s),a(H,bs),a(H,Dt),a(Dt,Es),i(e,Pa,l),i(e,B,l),a(B,ks),a(B,ke),a(ke,Hs),a(B,js),La=!0},p(e,[l]){const He={};l&2&&(He.$$scope={dirty:l,ctx:e}),J.$set(He)},i(e){La||(v(K.$$.fragment,e),v(Q.$$.fragment,e),v(X.$$.fragment,e),v(ae.$$.fragment,e),v(se.$$.fragment,e),v(re.$$.fragment,e),v(le.$$.fragment,e),v(ue.$$.fragment,e),v(de.$$.fragment,e),v(ce.$$.fragment,e),v(ve.$$.fragment,e),v(we.$$.fragment,e),v($e.$$.fragment,e),v(be.$$.fragment,e),v(Ee.$$.fragment,e),v(J.$$.fragment,e),La=!0)},o(e){g(K.$$.fragment,e),g(Q.$$.fragment,e),g(X.$$.fragment,e),g(ae.$$.fragment,e),g(se.$$.fragment,e),g(re.$$.fragment,e),g(le.$$.fragment,e),g(ue.$$.fragment,e),g(de.$$.fragment,e),g(ce.$$.fragment,e),g(ve.$$.fragment,e),g(we.$$.fragment,e),g($e.$$.fragment,e),g(be.$$.fragment,e),g(Ee.$$.fragment,e),g(J.$$.fragment,e),La=!1},d(e){t(p),e&&t(D),e&&t(_),w(K),e&&t(Ct),e&&t(Pe),e&&t(Nt),e&&t(Le),e&&t(Ot),e&&t($),e&&t(Gt),e&&t(Ae),e&&t(Mt),e&&t(Ie),e&&t(zt),e&&t(P),w(Q),e&&t(Ut),e&&t(Se),e&&t(Zt),e&&t(Fe),e&&t(Rt),e&&t(x),e&&t(Yt),e&&t(De),e&&t(Jt),e&&t(Te),e&&t(Bt),e&&t(q),e&&t(Vt),e&&t(C),e&&t(Wt),e&&t(L),w(X),e&&t(Kt),e&&t(k),e&&t(Qt),e&&t(qe),e&&t(Xt),w(ae,e),e&&t(ea),e&&t(oe),e&&t(ta),w(se,e),e&&t(aa),e&&t(O),e&&t(oa),w(re,e),e&&t(sa),e&&t(A),w(le),e&&t(ra),e&&t(ie),e&&t(la),w(ue,e),e&&t(ia),e&&t(M),e&&t(na),e&&t(I),w(de),e&&t(fa),e&&t(he),e&&t(ua),e&&t(E),e&&t(da),e&&t(S),w(ce),e&&t(ha),e&&t(Me),e&&t(pa),e&&t(me),e&&t(ca),w(ve,e),e&&t(ma),e&&t(ge),e&&t(ya),w(we,e),e&&t(va),e&&t(_e),e&&t(ga),w($e,e),e&&t(wa),e&&t(ze),e&&t(_a),w(be,e),e&&t($a),e&&t(F),w(Ee),e&&t(ba),e&&t(Ue),e&&t(Ea),w(J,e),e&&t(ka),e&&t(Ze),e&&t(Ha),e&&t(Re),e&&t(ja),e&&t(H),e&&t(Pa),e&&t(B)}}}const al={local:"share",sections:[{local:"add-a-dataset",sections:[{local:"create-the-repository",title:"Create the repository"},{local:"clone-the-repository",title:"Clone the repository"},{local:"prepare-your-files",title:"Prepare your files"},{local:"upload-your-files",title:"Upload your files"}],title:"Add a dataset"},{local:"datasets-on-github-legacy",title:"Datasets on GitHub (legacy)"}],title:"Share"};function ol(qt){return Qr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class nl extends Br{constructor(p){super();Vr(this,p,ol,tl,Wr,{})}}export{nl as default,al as metadata};
