import{S as qt,i as kt,s as Ct,e as n,k as u,w as K,t as s,M as Ot,c as l,d as e,m as h,a as d,x as Q,h as o,b as m,G as t,g as c,y as V,q as X,o as Y,B as Z,v as It}from"../chunks/vendor-hf-doc-builder.js";import{T as Pt}from"../chunks/Tip-hf-doc-builder.js";import{I as At}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as lt}from"../chunks/CodeBlock-hf-doc-builder.js";function St(pa){let r,k,p,v,E,_,P,b;return{c(){r=n("p"),k=s("Index into an audio dataset using the row index first and then the "),p=n("code"),v=s("audio"),E=s(" column - "),_=n("code"),P=s('dataset[0]["audio"]'),b=s(" - to avoid decoding and resampling all the audio files in the dataset. Otherwise, this can be a slow and time-consuming process if you have a large dataset.")},l(A){r=l(A,"P",{});var g=d(r);k=o(g,"Index into an audio dataset using the row index first and then the "),p=l(g,"CODE",{});var j=d(p);v=o(j,"audio"),j.forEach(e),E=o(g," column - "),_=l(g,"CODE",{});var T=d(_);P=o(T,'dataset[0]["audio"]'),T.forEach(e),b=o(g," - to avoid decoding and resampling all the audio files in the dataset. Otherwise, this can be a slow and time-consuming process if you have a large dataset."),g.forEach(e)},m(A,g){c(A,r,g),t(r,k),t(r,p),t(p,v),t(r,E),t(r,_),t(_,P),t(r,b)},d(A){A&&e(r)}}}function Dt(pa){let r,k,p,v,E,_,P,b,A,g,j,T,aa,Ea,ba,ua,w,F,ta,Aa,qa,ka,J,ea,Ca,Oa,Ia,M,sa,Pa,Sa,ha,x,Da,oa,Ua,La,B,Na,Ta,fa,S,ma,C,_a,q,O,na,D,Fa,la,Ja,ga,f,Ma,da,Ba,Ha,H,Wa,Ga,ia,Ra,za,W,Ka,Qa,va,U,$a,$,Va,ra,Xa,Ya,ca,Za,at,G,tt,et,ja,L,wa;return _=new At({}),S=new lt({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
dataset[0]["audio"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, <span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.00024414</span>, -<span class="hljs-number">0.00024414</span>, ..., -<span class="hljs-number">0.00024414</span>,
         <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        ], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">8000</span>}`}}),C=new Pt({props:{warning:!0,$$slots:{default:[St]},$$scope:{ctx:pa}}}),D=new At({}),U=new lt({props:{code:'audio_dataset = Dataset.from_dict({"audio": ["path/to/audio_1", "path/to/audio_2", ..., "path/to/audio_n"]}).cast_column("audio", Audio())',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>audio_dataset = Dataset.from_dict({<span class="hljs-string">&quot;audio&quot;</span>: [<span class="hljs-string">&quot;path/to/audio_1&quot;</span>, <span class="hljs-string">&quot;path/to/audio_2&quot;</span>, ..., <span class="hljs-string">&quot;path/to/audio_n&quot;</span>]}).cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio())'}}),L=new lt({props:{code:`dataset = load_dataset("PolyAI/minds14", "en-US", split="train").cast_column("audio", Audio(decode=False))
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, <span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>).cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(decode=<span class="hljs-literal">False</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>: {<span class="hljs-string">&#x27;bytes&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>},
 <span class="hljs-string">&#x27;english_transcription&#x27;</span>: <span class="hljs-string">&#x27;I would like to set up a joint account with my partner&#x27;</span>,
 <span class="hljs-string">&#x27;intent_class&#x27;</span>: <span class="hljs-number">11</span>,
 <span class="hljs-string">&#x27;lang_id&#x27;</span>: <span class="hljs-number">4</span>,
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;transcription&#x27;</span>: <span class="hljs-string">&#x27;I would like to set up a joint account with my partner&#x27;</span>}`}}),{c(){r=n("meta"),k=u(),p=n("h1"),v=n("a"),E=n("span"),K(_.$$.fragment),P=u(),b=n("span"),A=s("Load audio data"),g=u(),j=n("p"),T=s("Audio datasets are loaded from the "),aa=n("code"),Ea=s("audio"),ba=s(" column, which contains three important fields:"),ua=u(),w=n("ul"),F=n("li"),ta=n("code"),Aa=s("array"),qa=s(": the decoded audio data represented as a 1-dimensional array."),ka=u(),J=n("li"),ea=n("code"),Ca=s("path"),Oa=s(": the path to the downloaded audio file."),Ia=u(),M=n("li"),sa=n("code"),Pa=s("sampling_rate"),Sa=s(": the sampling rate of the audio data."),ha=u(),x=n("p"),Da=s("When you load an audio dataset and call the "),oa=n("code"),Ua=s("audio"),La=s(" column, the "),B=n("a"),Na=s("Audio"),Ta=s(" feature automatically decodes and resamples the audio file:"),fa=u(),K(S.$$.fragment),ma=u(),K(C.$$.fragment),_a=u(),q=n("h2"),O=n("a"),na=n("span"),K(D.$$.fragment),Fa=u(),la=n("span"),Ja=s("Local files"),ga=u(),f=n("p"),Ma=s("The "),da=n("code"),Ba=s("path"),Ha=s(" is useful for loading your own dataset. Use the "),H=n("a"),Wa=s("cast_column()"),Ga=s(" function to take a column of audio file paths, and decode it into "),ia=n("code"),Ra=s("array"),za=s("\u2019s with the "),W=n("a"),Ka=s("Audio"),Qa=s(" feature:"),va=u(),K(U.$$.fragment),$a=u(),$=n("p"),Va=s("If you only want to load the underlying path to the audio dataset without decoding the audio file into an "),ra=n("code"),Xa=s("array"),Ya=s(", set "),ca=n("code"),Za=s("decode=False"),at=s(" in the "),G=n("a"),tt=s("Audio"),et=s(" feature:"),ja=u(),K(L.$$.fragment),this.h()},l(a){const i=Ot('[data-svelte="svelte-1phssyn"]',document.head);r=l(i,"META",{name:!0,content:!0}),i.forEach(e),k=h(a),p=l(a,"H1",{class:!0});var N=d(p);v=l(N,"A",{id:!0,class:!0,href:!0});var dt=d(v);E=l(dt,"SPAN",{});var it=d(E);Q(_.$$.fragment,it),it.forEach(e),dt.forEach(e),P=h(N),b=l(N,"SPAN",{});var rt=d(b);A=o(rt,"Load audio data"),rt.forEach(e),N.forEach(e),g=h(a),j=l(a,"P",{});var xa=d(j);T=o(xa,"Audio datasets are loaded from the "),aa=l(xa,"CODE",{});var ct=d(aa);Ea=o(ct,"audio"),ct.forEach(e),ba=o(xa," column, which contains three important fields:"),xa.forEach(e),ua=h(a),w=l(a,"UL",{});var R=d(w);F=l(R,"LI",{});var st=d(F);ta=l(st,"CODE",{});var pt=d(ta);Aa=o(pt,"array"),pt.forEach(e),qa=o(st,": the decoded audio data represented as a 1-dimensional array."),st.forEach(e),ka=h(R),J=l(R,"LI",{});var ot=d(J);ea=l(ot,"CODE",{});var ut=d(ea);Ca=o(ut,"path"),ut.forEach(e),Oa=o(ot,": the path to the downloaded audio file."),ot.forEach(e),Ia=h(R),M=l(R,"LI",{});var nt=d(M);sa=l(nt,"CODE",{});var ht=d(sa);Pa=o(ht,"sampling_rate"),ht.forEach(e),Sa=o(nt,": the sampling rate of the audio data."),nt.forEach(e),R.forEach(e),ha=h(a),x=l(a,"P",{});var z=d(x);Da=o(z,"When you load an audio dataset and call the "),oa=l(z,"CODE",{});var ft=d(oa);Ua=o(ft,"audio"),ft.forEach(e),La=o(z," column, the "),B=l(z,"A",{href:!0});var mt=d(B);Na=o(mt,"Audio"),mt.forEach(e),Ta=o(z," feature automatically decodes and resamples the audio file:"),z.forEach(e),fa=h(a),Q(S.$$.fragment,a),ma=h(a),Q(C.$$.fragment,a),_a=h(a),q=l(a,"H2",{class:!0});var ya=d(q);O=l(ya,"A",{id:!0,class:!0,href:!0});var _t=d(O);na=l(_t,"SPAN",{});var gt=d(na);Q(D.$$.fragment,gt),gt.forEach(e),_t.forEach(e),Fa=h(ya),la=l(ya,"SPAN",{});var vt=d(la);Ja=o(vt,"Local files"),vt.forEach(e),ya.forEach(e),ga=h(a),f=l(a,"P",{});var y=d(f);Ma=o(y,"The "),da=l(y,"CODE",{});var $t=d(da);Ba=o($t,"path"),$t.forEach(e),Ha=o(y," is useful for loading your own dataset. Use the "),H=l(y,"A",{href:!0});var jt=d(H);Wa=o(jt,"cast_column()"),jt.forEach(e),Ga=o(y," function to take a column of audio file paths, and decode it into "),ia=l(y,"CODE",{});var wt=d(ia);Ra=o(wt,"array"),wt.forEach(e),za=o(y,"\u2019s with the "),W=l(y,"A",{href:!0});var xt=d(W);Ka=o(xt,"Audio"),xt.forEach(e),Qa=o(y," feature:"),y.forEach(e),va=h(a),Q(U.$$.fragment,a),$a=h(a),$=l(a,"P",{});var I=d($);Va=o(I,"If you only want to load the underlying path to the audio dataset without decoding the audio file into an "),ra=l(I,"CODE",{});var yt=d(ra);Xa=o(yt,"array"),yt.forEach(e),Ya=o(I,", set "),ca=l(I,"CODE",{});var Et=d(ca);Za=o(Et,"decode=False"),Et.forEach(e),at=o(I," in the "),G=l(I,"A",{href:!0});var bt=d(G);tt=o(bt,"Audio"),bt.forEach(e),et=o(I," feature:"),I.forEach(e),ja=h(a),Q(L.$$.fragment,a),this.h()},h(){m(r,"name","hf:doc:metadata"),m(r,"content",JSON.stringify(Ut)),m(v,"id","load-audio-data"),m(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(v,"href","#load-audio-data"),m(p,"class","relative group"),m(B,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Audio"),m(O,"id","local-files"),m(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(O,"href","#local-files"),m(q,"class","relative group"),m(H,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Dataset.cast_column"),m(W,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Audio"),m(G,"href","/docs/datasets/pr_4519/en/package_reference/main_classes#datasets.Audio")},m(a,i){t(document.head,r),c(a,k,i),c(a,p,i),t(p,v),t(v,E),V(_,E,null),t(p,P),t(p,b),t(b,A),c(a,g,i),c(a,j,i),t(j,T),t(j,aa),t(aa,Ea),t(j,ba),c(a,ua,i),c(a,w,i),t(w,F),t(F,ta),t(ta,Aa),t(F,qa),t(w,ka),t(w,J),t(J,ea),t(ea,Ca),t(J,Oa),t(w,Ia),t(w,M),t(M,sa),t(sa,Pa),t(M,Sa),c(a,ha,i),c(a,x,i),t(x,Da),t(x,oa),t(oa,Ua),t(x,La),t(x,B),t(B,Na),t(x,Ta),c(a,fa,i),V(S,a,i),c(a,ma,i),V(C,a,i),c(a,_a,i),c(a,q,i),t(q,O),t(O,na),V(D,na,null),t(q,Fa),t(q,la),t(la,Ja),c(a,ga,i),c(a,f,i),t(f,Ma),t(f,da),t(da,Ba),t(f,Ha),t(f,H),t(H,Wa),t(f,Ga),t(f,ia),t(ia,Ra),t(f,za),t(f,W),t(W,Ka),t(f,Qa),c(a,va,i),V(U,a,i),c(a,$a,i),c(a,$,i),t($,Va),t($,ra),t(ra,Xa),t($,Ya),t($,ca),t(ca,Za),t($,at),t($,G),t(G,tt),t($,et),c(a,ja,i),V(L,a,i),wa=!0},p(a,[i]){const N={};i&2&&(N.$$scope={dirty:i,ctx:a}),C.$set(N)},i(a){wa||(X(_.$$.fragment,a),X(S.$$.fragment,a),X(C.$$.fragment,a),X(D.$$.fragment,a),X(U.$$.fragment,a),X(L.$$.fragment,a),wa=!0)},o(a){Y(_.$$.fragment,a),Y(S.$$.fragment,a),Y(C.$$.fragment,a),Y(D.$$.fragment,a),Y(U.$$.fragment,a),Y(L.$$.fragment,a),wa=!1},d(a){e(r),a&&e(k),a&&e(p),Z(_),a&&e(g),a&&e(j),a&&e(ua),a&&e(w),a&&e(ha),a&&e(x),a&&e(fa),Z(S,a),a&&e(ma),Z(C,a),a&&e(_a),a&&e(q),Z(D),a&&e(ga),a&&e(f),a&&e(va),Z(U,a),a&&e($a),a&&e($),a&&e(ja),Z(L,a)}}}const Ut={local:"load-audio-data",sections:[{local:"local-files",title:"Local files"}],title:"Load audio data"};function Lt(pa){return It(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Mt extends qt{constructor(r){super();kt(this,r,Lt,Dt,Ct,{})}}export{Mt as default,Ut as metadata};
