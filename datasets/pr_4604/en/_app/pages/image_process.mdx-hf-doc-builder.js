import{S as Up,i as Mp,s as Kp,e as o,k as m,w as h,t as s,M as Qp,c as r,d as t,m as f,a as p,x as d,h as l,b as c,N as Yp,G as a,g as i,y as u,q as g,o as _,B as v,v as Vp}from"../chunks/vendor-hf-doc-builder.js";import{T as Wp}from"../chunks/Tip-hf-doc-builder.js";import{I as U}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as $}from"../chunks/CodeBlock-hf-doc-builder.js";function Xp(Ot){let j,M,w,y,T;return{c(){j=o("p"),M=s("Feel free to use other data augmentation libraries like "),w=o("a"),y=s("Albumentations"),T=s(". \u{1F917} Datasets can apply any custom function and transforms to an entire dataset!"),this.h()},l(E){j=r(E,"P",{});var I=p(j);M=l(I,"Feel free to use other data augmentation libraries like "),w=r(I,"A",{href:!0,rel:!0});var K=p(w);y=l(K,"Albumentations"),K.forEach(t),T=l(I,". \u{1F917} Datasets can apply any custom function and transforms to an entire dataset!"),I.forEach(t),this.h()},h(){c(w,"href","https://albumentations.ai/docs/"),c(w,"rel","nofollow")},m(E,I){i(E,j,I),a(j,M),a(j,w),a(w,y),a(j,T)},d(E){E&&t(j)}}}function Zp(Ot){let j,M,w,y,T,E,I,K,wl,Lt,Q,bl,ia,El,yl,Nt,q,Na,ql,kl,qe,xl,Ba,Il,Dl,Pl,ke,Al,ma,Cl,Fl,Tl,xe,Ol,fa,Ll,Nl,Bt,O,V,za,Ie,Bl,Sa,zl,zt,D,Sl,ca,Jl,Rl,ha,Hl,Gl,St,De,Jt,L,W,Ja,Pe,Yl,Ra,Ul,Rt,da,Ml,Ht,X,Ae,Kl,Ha,Ql,Vl,Wl,Ga,Xl,Gt,Z,Zl,Ce,eo,ao,Yt,Fe,Ut,k,to,ua,so,lo,Ya,oo,ro,Ua,no,po,Mt,Te,Kt,ga,_a,hn,Qt,P,io,va,mo,fo,$a,co,ho,Vt,Oe,Wt,A,uo,Ma,go,_o,Ka,vo,$o,Xt,Le,Zt,N,ee,Qa,Ne,jo,Va,wo,es,ae,bo,Wa,Eo,yo,as,Be,ts,C,qo,Xa,ko,xo,Za,Io,Do,ss,ze,ls,te,Po,et,Ao,Co,os,Se,rs,B,at,Fo,To,tt,Oo,Lo,ns,x,No,st,Bo,zo,lt,So,Jo,ja,Ro,Ho,ps,z,se,ot,Je,Go,rt,Yo,is,le,Uo,nt,Mo,Ko,ms,Re,fs,oe,Qo,pt,Vo,Wo,cs,S,re,it,He,Xo,mt,Zo,hs,ne,er,ft,ar,tr,ds,Ge,us,J,ct,sr,lr,ht,or,rr,gs,Ye,_s,R,pe,dt,Ue,nr,ut,pr,vs,ie,ir,gt,mr,fr,$s,Me,js,H,_t,cr,hr,vt,dr,ur,ws,Ke,bs,G,me,$t,Qe,gr,jt,_r,Es,Ve,wa,vr,$r,ys,fe,jr,We,wt,wr,br,qs,Xe,ks,b,Er,ba,yr,qr,bt,kr,xr,Et,Ir,Dr,yt,Pr,Ar,xs,Ze,Is,ce,Cr,Ea,Fr,Tr,Ds,ea,ya,Or,Lr,Ps,he,qa,ka,qt,Nr,Br,zr,xa,Ia,kt,Sr,Jr,As,de,Rr,Da,Hr,Gr,Cs,Y,ue,xt,aa,Yr,It,Ur,Fs,ge,Mr,ta,Kr,Qr,Ts,_e,Os,ve,Vr,sa,Dt,Wr,Xr,Ls,la,Ns,$e,Zr,Pt,en,an,Bs,oa,zs,je,tn,Pa,sn,ln,Ss,ra,Js,we,on,At,rn,nn,Rs,na,Hs,Aa,Ca,dn,Gs;return E=new U({}),Ie=new U({}),De=new $({props:{code:"pip install datasets[vision]",highlighted:"pip install datasets[vision]"}}),Pe=new U({}),Fe=new $({props:{code:`from datasets import load_dataset, Image

dataset = load_dataset("food101", split="train[:100]")
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[:100]&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="hljs-number">0x7FC45AB5C590</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>}`}}),Te=new $({props:{code:`from datasets import load_dataset, Image

dataset = load_dataset("food101", split="train[100:200]")
dataset[0]["image"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[100:200]&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]
&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="hljs-number">0x16289FBE0</span>&gt;`}}),Oe=new $({props:{code:`from datasets import load_dataset, Image

dataset = Dataset.from_dict({"image": ["path/to/image_1", "path/to/image_2", ..., "path/to/image_n"]}).cast_column("image", Image())
dataset[0]["image"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = Dataset.from_dict({<span class="hljs-string">&quot;image&quot;</span>: [<span class="hljs-string">&quot;path/to/image_1&quot;</span>, <span class="hljs-string">&quot;path/to/image_2&quot;</span>, ..., <span class="hljs-string">&quot;path/to/image_n&quot;</span>]}).cast_column(<span class="hljs-string">&quot;image&quot;</span>, Image())
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]
&lt;PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1200x215 at <span class="hljs-number">0x15E6D7160</span>&gt;]`}}),Le=new $({props:{code:`dataset = load_dataset("food101", split="train[:100]").cast_column('image', Image(decode=False))`,highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[:100]&quot;</span>).cast_column(<span class="hljs-string">&#x27;image&#x27;</span>, Image(decode=<span class="hljs-literal">False</span>))'}}),Ne=new U({}),Be=new $({props:{code:"",highlighted:`folder<span class="hljs-regexp">/train/</span>dog/golden_retriever.png
folder<span class="hljs-regexp">/train/</span>dog/german_shepherd.png
folder<span class="hljs-regexp">/train/</span>dog/chihuahua.png

folder<span class="hljs-regexp">/train/</span>cat/maine_coon.png
folder<span class="hljs-regexp">/train/</span>cat/bengal.png
folder<span class="hljs-regexp">/train/</span>cat/birman.png`}}),ze=new $({props:{code:`from datasets import load_dataset
dataset = load_dataset("imagefolder", data_dir="/path/to/folder")
dataset["train"][0]["image"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]
&lt;PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1200x215 at <span class="hljs-number">0x15E6D7160</span>&gt;]`}}),Se=new $({props:{code:'dataset = load_dataset("imagefolder", data_files="https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip", split="train")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_files=<span class="hljs-string">&quot;https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)'}}),Je=new U({}),Re=new $({props:{code:`folder/train/metadata.jsonl
folder/train/0001.png
folder/train/0002.png
folder/train/0003.png`,highlighted:`folder<span class="hljs-regexp">/train/m</span>etadata.jsonl
folder<span class="hljs-regexp">/train/</span><span class="hljs-number">0001</span>.png
folder<span class="hljs-regexp">/train/</span><span class="hljs-number">0002</span>.png
folder<span class="hljs-regexp">/train/</span><span class="hljs-number">0003</span>.png`}}),He=new U({}),Ge=new $({props:{code:`{"file_name": "0001.png", "text": "This is a golden retriever playing with a ball"}
{"file_name": "0002.png", "text": "A german shepherd"}
{"file_name": "0003.png", "text": "One chihuahua"}`,highlighted:`{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0001.png&quot;</span>, <span class="hljs-comment">&quot;text&quot;</span>: <span class="hljs-comment">&quot;This is a golden retriever playing with a ball&quot;</span>}
{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0002.png&quot;</span>, <span class="hljs-comment">&quot;text&quot;</span>: <span class="hljs-comment">&quot;A german shepherd&quot;</span>}
{<span class="hljs-comment">&quot;file_name&quot;</span>: <span class="hljs-comment">&quot;0003.png&quot;</span>, <span class="hljs-comment">&quot;text&quot;</span>: <span class="hljs-comment">&quot;One chihuahua&quot;</span>}`}}),Ye=new $({props:{code:`dataset = load_dataset("imagefolder", data_dir="/path/to/folder", split="train")
dataset[0]["text"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>]
This <span class="hljs-keyword">is</span> a golden retriever playing <span class="hljs-keyword">with</span> a ball`}}),Ue=new U({}),Me=new $({props:{code:`{"file_name": "0001.png", "objects": {"bbox": [[302.0, 109.0, 73.0, 52.0]], "categories": [0]}}
{"file_name": "0002.png", "objects": {"bbox": [[810.0, 100.0, 57.0, 28.0]], "categories": [1]}}
{"file_name": "0003.png", "objects": {"bbox": [[160.0, 31.0, 248.0, 616.0], [741.0, 68.0, 202.0, 401.0]], "categories": [2, 2]}}`,highlighted:`{<span class="hljs-string">&quot;file_name&quot;</span>: <span class="hljs-string">&quot;0001.png&quot;</span>, <span class="hljs-string">&quot;objects&quot;</span>: {<span class="hljs-string">&quot;bbox&quot;</span>: <span class="hljs-string">[[302.0, 109.0, 73.0, 52.0]]</span>, <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">0</span>]}}
{<span class="hljs-string">&quot;file_name&quot;</span>: <span class="hljs-string">&quot;0002.png&quot;</span>, <span class="hljs-string">&quot;objects&quot;</span>: {<span class="hljs-string">&quot;bbox&quot;</span>: <span class="hljs-string">[[810.0, 100.0, 57.0, 28.0]]</span>, <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">1</span>]}}
{<span class="hljs-string">&quot;file_name&quot;</span>: <span class="hljs-string">&quot;0003.png&quot;</span>, <span class="hljs-string">&quot;objects&quot;</span>: {<span class="hljs-string">&quot;bbox&quot;</span>: <span class="hljs-string">[[160.0, 31.0, 248.0, 616.0], [741.0, 68.0, 202.0, 401.0]]</span>, <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]}}`}}),Ke=new $({props:{code:`dataset = load_dataset("imagefolder", data_dir="/path/to/folder", split="train")
dataset[0]["objects"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;/path/to/folder&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;objects&quot;</span>]
{<span class="hljs-string">&quot;bbox&quot;</span>: [[<span class="hljs-number">302.0</span>, <span class="hljs-number">109.0</span>, <span class="hljs-number">73.0</span>, <span class="hljs-number">52.0</span>]], <span class="hljs-string">&quot;categories&quot;</span>: [<span class="hljs-number">0</span>]}`}}),Qe=new U({}),Xe=new $({props:{code:`def transforms(examples):
    examples["pixel_values"] = [image.convert("RGB").resize((100,100)) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [image.convert(<span class="hljs-string">&quot;RGB&quot;</span>).resize((<span class="hljs-number">100</span>,<span class="hljs-number">100</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),Ze=new $({props:{code:`dataset = dataset.map(transforms, remove_columns=["image"], batched=True)
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(transforms, remove_columns=[<span class="hljs-string">&quot;image&quot;</span>], batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>,
 <span class="hljs-string">&#x27;pixel_values&#x27;</span>: &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=100x100 at <span class="hljs-number">0x7F058237BB10</span>&gt;}`}}),aa=new U({}),_e=new Wp({props:{$$slots:{default:[Xp]},$$scope:{ctx:Ot}}}),la=new $({props:{code:`from torchvision.transforms import Compose, ColorJitter, ToTensor

jitter = Compose(
    [
         ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.7),
         ToTensor(),
    ]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = Compose(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>         ColorJitter(brightness=<span class="hljs-number">0.25</span>, contrast=<span class="hljs-number">0.25</span>, saturation=<span class="hljs-number">0.25</span>, hue=<span class="hljs-number">0.7</span>),
<span class="hljs-meta">... </span>         ToTensor(),
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)`}}),oa=new $({props:{code:`def transforms(examples):
    examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),ra=new $({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),na=new $({props:{code:`import numpy as np
import matplotlib.pyplot as plt

img = dataset[0]["pixel_values"]
plt.imshow(img.permute(1, 2, 0))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))`}}),{c(){j=o("meta"),M=m(),w=o("h1"),y=o("a"),T=o("span"),h(E.$$.fragment),I=m(),K=o("span"),wl=s("Process image data"),Lt=m(),Q=o("p"),bl=s("\u{1F917} Datasets support loading and processing images with the "),ia=o("a"),El=s("Image"),yl=s(" feature. This guide will show you how to:"),Nt=m(),q=o("ul"),Na=o("li"),ql=s("Load an image dataset."),kl=m(),qe=o("li"),xl=s("Load a generic image dataset with "),Ba=o("code"),Il=s("ImageFolder"),Dl=s("."),Pl=m(),ke=o("li"),Al=s("Use "),ma=o("a"),Cl=s("Dataset.map()"),Fl=s(" to quickly apply transforms to an entire dataset."),Tl=m(),xe=o("li"),Ol=s("Add data augmentations to your images with "),fa=o("a"),Ll=s("Dataset.set_transform()"),Nl=s("."),Bt=m(),O=o("h2"),V=o("a"),za=o("span"),h(Ie.$$.fragment),Bl=m(),Sa=o("span"),zl=s("Installation"),zt=m(),D=o("p"),Sl=s("The "),ca=o("a"),Jl=s("Image"),Rl=s(" feature should be installed as an extra dependency in \u{1F917} Datasets. Install the "),ha=o("a"),Hl=s("Image"),Gl=s(" feature (and its dependencies) with pip:"),St=m(),h(De.$$.fragment),Jt=m(),L=o("h2"),W=o("a"),Ja=o("span"),h(Pe.$$.fragment),Yl=m(),Ra=o("span"),Ul=s("Image datasets"),Rt=m(),da=o("p"),Ml=s("The images in an image dataset are typically either a:"),Ht=m(),X=o("ul"),Ae=o("li"),Kl=s("PIL "),Ha=o("code"),Ql=s("image"),Vl=s("."),Wl=m(),Ga=o("li"),Xl=s("Path to an image file you can load."),Gt=m(),Z=o("p"),Zl=s("For example, load the "),Ce=o("a"),eo=s("Food-101"),ao=s(" dataset and take a look:"),Yt=m(),h(Fe.$$.fragment),Ut=m(),k=o("p"),to=s("The "),ua=o("a"),so=s("Image"),lo=s(" feature automatically decodes the data from the "),Ya=o("code"),oo=s("image"),ro=s(" column to return an image object. Now try and call the "),Ua=o("code"),no=s("image"),po=s(" column to see what the image is:"),Mt=m(),h(Te.$$.fragment),Kt=m(),ga=o("p"),_a=o("img"),Qt=m(),P=o("p"),io=s("To load an image from its path, use the "),va=o("a"),mo=s("Dataset.cast_column()"),fo=s(" method. The "),$a=o("a"),co=s("Image"),ho=s(" feature will decode the data at the path to return an image object:"),Vt=m(),h(Oe.$$.fragment),Wt=m(),A=o("p"),uo=s("You can also access the path and bytes of an image file by setting "),Ma=o("code"),go=s("decode=False"),_o=s(" when you load a dataset. In this case, you will need to cast the "),Ka=o("code"),vo=s("image"),$o=s(" column:"),Xt=m(),h(Le.$$.fragment),Zt=m(),N=o("h2"),ee=o("a"),Qa=o("span"),h(Ne.$$.fragment),jo=m(),Va=o("span"),wo=s("ImageFolder"),es=m(),ae=o("p"),bo=s("You can also load your image dataset with a "),Wa=o("code"),Eo=s("ImageFolder"),yo=s(" dataset builder without writing a custom dataloader. Your image dataset structure should look like this:"),as=m(),h(Be.$$.fragment),ts=m(),C=o("p"),qo=s("Then load your dataset by specifying "),Xa=o("code"),ko=s("imagefolder"),xo=s(" and the directory of your dataset in "),Za=o("code"),Io=s("data_dir"),Do=s(":"),ss=m(),h(ze.$$.fragment),ls=m(),te=o("p"),Po=s("Load remote datasets from their URLs with the "),et=o("code"),Ao=s("data_files"),Co=s(" parameter:"),os=m(),h(Se.$$.fragment),rs=m(),B=o("p"),at=o("code"),Fo=s("ImageFolder"),To=s(" will create a "),tt=o("code"),Oo=s("label"),Lo=s(" column, and the label name is based on the directory name."),ns=m(),x=o("p"),No=s("You can pass "),st=o("code"),Bo=s("drop_labels=False"),zo=s(" to ignore the "),lt=o("code"),So=s("label"),Jo=s(" column, as defined in "),ja=o("a"),Ro=s("ImageFolderConfig"),Ho=s("."),ps=m(),z=o("h2"),se=o("a"),ot=o("span"),h(Je.$$.fragment),Go=m(),rt=o("span"),Yo=s("ImageFolder with metadata"),is=m(),le=o("p"),Uo=s("If your image dataset comes with metadata, they will be also loaded. First, make sure your dataset has a "),nt=o("code"),Mo=s("metadata.jsonl"),Ko=s(":"),ms=m(),h(Re.$$.fragment),fs=m(),oe=o("p"),Qo=s("You can link the metadata in "),pt=o("code"),Vo=s("metadata.jsonl"),Wo=s(" file to the images using the \u201Cfile_path\u201D field."),cs=m(),S=o("h3"),re=o("a"),it=o("span"),h(He.$$.fragment),Xo=m(),mt=o("span"),Zo=s("Image captioning"),hs=m(),ne=o("p"),er=s("Here is an example of "),ft=o("code"),ar=s("metadata.jsonl"),tr=s(" for image captioning:"),ds=m(),h(Ge.$$.fragment),us=m(),J=o("p"),ct=o("code"),sr=s("ImageFolder"),lr=s(" will create a "),ht=o("code"),or=s("text"),rr=s(" column for the image captions:"),gs=m(),h(Ye.$$.fragment),_s=m(),R=o("h3"),pe=o("a"),dt=o("span"),h(Ue.$$.fragment),nr=m(),ut=o("span"),pr=s("Object detection"),vs=m(),ie=o("p"),ir=s("Here is an example of "),gt=o("code"),mr=s("metadata.jsonl"),fr=s(" for object detection:"),$s=m(),h(Me.$$.fragment),js=m(),H=o("p"),_t=o("code"),cr=s("ImageFolder"),hr=s(" will create a "),vt=o("code"),dr=s("objects"),ur=s(" column with the bounding boxes and the categories:"),ws=m(),h(Ke.$$.fragment),bs=m(),G=o("h2"),me=o("a"),$t=o("span"),h(Qe.$$.fragment),gr=m(),jt=o("span"),_r=s("Map"),Es=m(),Ve=o("p"),wa=o("a"),vr=s("Dataset.map()"),$r=s(" can apply transforms over an entire dataset and it also generates a cache file."),ys=m(),fe=o("p"),jr=s("Create a simple "),We=o("a"),wt=o("code"),wr=s("Resize"),br=s(" function:"),qs=m(),h(Xe.$$.fragment),ks=m(),b=o("p"),Er=s("Now "),ba=o("a"),yr=s("Dataset.map()"),qr=s(" the function over the entire dataset and set "),bt=o("code"),kr=s("batched=True"),xr=s(". The transform returns "),Et=o("code"),Ir=s("pixel_values"),Dr=s(" as a cacheable "),yt=o("code"),Pr=s("PIL.Image"),Ar=s(" object:"),xs=m(),h(Ze.$$.fragment),Is=m(),ce=o("p"),Cr=s("This saves time because you don\u2019t have to execute the same transform twice. It is best to use "),Ea=o("a"),Fr=s("Dataset.map()"),Tr=s(" for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),Ds=m(),ea=o("p"),ya=o("a"),Or=s("Dataset.map()"),Lr=s(" takes up some memory, but you can reduce its memory requirements with the following parameters:"),Ps=m(),he=o("ul"),qa=o("li"),ka=o("a"),qt=o("code"),Nr=s("batch_size"),Br=s(" determines the number of examples that are processed in one call to the transform function."),zr=m(),xa=o("li"),Ia=o("a"),kt=o("code"),Sr=s("writer_batch_size"),Jr=s(" determines the number of processed examples that are kept in memory before they are stored away."),As=m(),de=o("p"),Rr=s("Both parameter values default to 1000, which can be expensive if you are storing images. Lower the value to use less memory when calling "),Da=o("a"),Hr=s("Dataset.map()"),Gr=s("."),Cs=m(),Y=o("h2"),ue=o("a"),xt=o("span"),h(aa.$$.fragment),Yr=m(),It=o("span"),Ur=s("Data augmentation"),Fs=m(),ge=o("p"),Mr=s("Adding data augmentations to a dataset is common to prevent overfitting and achieve better performance. You can use any library or package you want to apply the augmentations. This guide will use the transforms from "),ta=o("a"),Kr=s("torchvision"),Qr=s("."),Ts=m(),h(_e.$$.fragment),Os=m(),ve=o("p"),Vr=s("Add the "),sa=o("a"),Dt=o("code"),Wr=s("ColorJitter"),Xr=s(" transform to change the color properties of the image randomly:"),Ls=m(),h(la.$$.fragment),Ns=m(),$e=o("p"),Zr=s("Create a function to apply the "),Pt=o("code"),en=s("ColorJitter"),an=s(" transform to an image:"),Bs=m(),h(oa.$$.fragment),zs=m(),je=o("p"),tn=s("Then you can use the "),Pa=o("a"),sn=s("Dataset.set_transform()"),ln=s(" function to apply the transform on-the-fly to consume less disk space. Use this function if you only need to access the examples once:"),Ss=m(),h(ra.$$.fragment),Js=m(),we=o("p"),on=s("Now visualize the results of the "),At=o("code"),rn=s("ColorJitter"),nn=s(" transform:"),Rs=m(),h(na.$$.fragment),Hs=m(),Aa=o("p"),Ca=o("img"),this.h()},l(e){const n=Qp('[data-svelte="svelte-1phssyn"]',document.head);j=r(n,"META",{name:!0,content:!0}),n.forEach(t),M=f(e),w=r(e,"H1",{class:!0});var pa=p(w);y=r(pa,"A",{id:!0,class:!0,href:!0});var un=p(y);T=r(un,"SPAN",{});var gn=p(T);d(E.$$.fragment,gn),gn.forEach(t),un.forEach(t),I=f(pa),K=r(pa,"SPAN",{});var _n=p(K);wl=l(_n,"Process image data"),_n.forEach(t),pa.forEach(t),Lt=f(e),Q=r(e,"P",{});var Ys=p(Q);bl=l(Ys,"\u{1F917} Datasets support loading and processing images with the "),ia=r(Ys,"A",{href:!0});var vn=p(ia);El=l(vn,"Image"),vn.forEach(t),yl=l(Ys," feature. This guide will show you how to:"),Ys.forEach(t),Nt=f(e),q=r(e,"UL",{});var be=p(q);Na=r(be,"LI",{});var $n=p(Na);ql=l($n,"Load an image dataset."),$n.forEach(t),kl=f(be),qe=r(be,"LI",{});var Us=p(qe);xl=l(Us,"Load a generic image dataset with "),Ba=r(Us,"CODE",{});var jn=p(Ba);Il=l(jn,"ImageFolder"),jn.forEach(t),Dl=l(Us,"."),Us.forEach(t),Pl=f(be),ke=r(be,"LI",{});var Ms=p(ke);Al=l(Ms,"Use "),ma=r(Ms,"A",{href:!0});var wn=p(ma);Cl=l(wn,"Dataset.map()"),wn.forEach(t),Fl=l(Ms," to quickly apply transforms to an entire dataset."),Ms.forEach(t),Tl=f(be),xe=r(be,"LI",{});var Ks=p(xe);Ol=l(Ks,"Add data augmentations to your images with "),fa=r(Ks,"A",{href:!0});var bn=p(fa);Ll=l(bn,"Dataset.set_transform()"),bn.forEach(t),Nl=l(Ks,"."),Ks.forEach(t),be.forEach(t),Bt=f(e),O=r(e,"H2",{class:!0});var Qs=p(O);V=r(Qs,"A",{id:!0,class:!0,href:!0});var En=p(V);za=r(En,"SPAN",{});var yn=p(za);d(Ie.$$.fragment,yn),yn.forEach(t),En.forEach(t),Bl=f(Qs),Sa=r(Qs,"SPAN",{});var qn=p(Sa);zl=l(qn,"Installation"),qn.forEach(t),Qs.forEach(t),zt=f(e),D=r(e,"P",{});var Fa=p(D);Sl=l(Fa,"The "),ca=r(Fa,"A",{href:!0});var kn=p(ca);Jl=l(kn,"Image"),kn.forEach(t),Rl=l(Fa," feature should be installed as an extra dependency in \u{1F917} Datasets. Install the "),ha=r(Fa,"A",{href:!0});var xn=p(ha);Hl=l(xn,"Image"),xn.forEach(t),Gl=l(Fa," feature (and its dependencies) with pip:"),Fa.forEach(t),St=f(e),d(De.$$.fragment,e),Jt=f(e),L=r(e,"H2",{class:!0});var Vs=p(L);W=r(Vs,"A",{id:!0,class:!0,href:!0});var In=p(W);Ja=r(In,"SPAN",{});var Dn=p(Ja);d(Pe.$$.fragment,Dn),Dn.forEach(t),In.forEach(t),Yl=f(Vs),Ra=r(Vs,"SPAN",{});var Pn=p(Ra);Ul=l(Pn,"Image datasets"),Pn.forEach(t),Vs.forEach(t),Rt=f(e),da=r(e,"P",{});var An=p(da);Ml=l(An,"The images in an image dataset are typically either a:"),An.forEach(t),Ht=f(e),X=r(e,"UL",{});var Ws=p(X);Ae=r(Ws,"LI",{});var Xs=p(Ae);Kl=l(Xs,"PIL "),Ha=r(Xs,"CODE",{});var Cn=p(Ha);Ql=l(Cn,"image"),Cn.forEach(t),Vl=l(Xs,"."),Xs.forEach(t),Wl=f(Ws),Ga=r(Ws,"LI",{});var Fn=p(Ga);Xl=l(Fn,"Path to an image file you can load."),Fn.forEach(t),Ws.forEach(t),Gt=f(e),Z=r(e,"P",{});var Zs=p(Z);Zl=l(Zs,"For example, load the "),Ce=r(Zs,"A",{href:!0,rel:!0});var Tn=p(Ce);eo=l(Tn,"Food-101"),Tn.forEach(t),ao=l(Zs," dataset and take a look:"),Zs.forEach(t),Yt=f(e),d(Fe.$$.fragment,e),Ut=f(e),k=r(e,"P",{});var Ee=p(k);to=l(Ee,"The "),ua=r(Ee,"A",{href:!0});var On=p(ua);so=l(On,"Image"),On.forEach(t),lo=l(Ee," feature automatically decodes the data from the "),Ya=r(Ee,"CODE",{});var Ln=p(Ya);oo=l(Ln,"image"),Ln.forEach(t),ro=l(Ee," column to return an image object. Now try and call the "),Ua=r(Ee,"CODE",{});var Nn=p(Ua);no=l(Nn,"image"),Nn.forEach(t),po=l(Ee," column to see what the image is:"),Ee.forEach(t),Mt=f(e),d(Te.$$.fragment,e),Kt=f(e),ga=r(e,"P",{});var Bn=p(ga);_a=r(Bn,"IMG",{src:!0,alt:!0}),Bn.forEach(t),Qt=f(e),P=r(e,"P",{});var Ta=p(P);io=l(Ta,"To load an image from its path, use the "),va=r(Ta,"A",{href:!0});var zn=p(va);mo=l(zn,"Dataset.cast_column()"),zn.forEach(t),fo=l(Ta," method. The "),$a=r(Ta,"A",{href:!0});var Sn=p($a);co=l(Sn,"Image"),Sn.forEach(t),ho=l(Ta," feature will decode the data at the path to return an image object:"),Ta.forEach(t),Vt=f(e),d(Oe.$$.fragment,e),Wt=f(e),A=r(e,"P",{});var Oa=p(A);uo=l(Oa,"You can also access the path and bytes of an image file by setting "),Ma=r(Oa,"CODE",{});var Jn=p(Ma);go=l(Jn,"decode=False"),Jn.forEach(t),_o=l(Oa," when you load a dataset. In this case, you will need to cast the "),Ka=r(Oa,"CODE",{});var Rn=p(Ka);vo=l(Rn,"image"),Rn.forEach(t),$o=l(Oa," column:"),Oa.forEach(t),Xt=f(e),d(Le.$$.fragment,e),Zt=f(e),N=r(e,"H2",{class:!0});var el=p(N);ee=r(el,"A",{id:!0,class:!0,href:!0});var Hn=p(ee);Qa=r(Hn,"SPAN",{});var Gn=p(Qa);d(Ne.$$.fragment,Gn),Gn.forEach(t),Hn.forEach(t),jo=f(el),Va=r(el,"SPAN",{});var Yn=p(Va);wo=l(Yn,"ImageFolder"),Yn.forEach(t),el.forEach(t),es=f(e),ae=r(e,"P",{});var al=p(ae);bo=l(al,"You can also load your image dataset with a "),Wa=r(al,"CODE",{});var Un=p(Wa);Eo=l(Un,"ImageFolder"),Un.forEach(t),yo=l(al," dataset builder without writing a custom dataloader. Your image dataset structure should look like this:"),al.forEach(t),as=f(e),d(Be.$$.fragment,e),ts=f(e),C=r(e,"P",{});var La=p(C);qo=l(La,"Then load your dataset by specifying "),Xa=r(La,"CODE",{});var Mn=p(Xa);ko=l(Mn,"imagefolder"),Mn.forEach(t),xo=l(La," and the directory of your dataset in "),Za=r(La,"CODE",{});var Kn=p(Za);Io=l(Kn,"data_dir"),Kn.forEach(t),Do=l(La,":"),La.forEach(t),ss=f(e),d(ze.$$.fragment,e),ls=f(e),te=r(e,"P",{});var tl=p(te);Po=l(tl,"Load remote datasets from their URLs with the "),et=r(tl,"CODE",{});var Qn=p(et);Ao=l(Qn,"data_files"),Qn.forEach(t),Co=l(tl," parameter:"),tl.forEach(t),os=f(e),d(Se.$$.fragment,e),rs=f(e),B=r(e,"P",{});var Ct=p(B);at=r(Ct,"CODE",{});var Vn=p(at);Fo=l(Vn,"ImageFolder"),Vn.forEach(t),To=l(Ct," will create a "),tt=r(Ct,"CODE",{});var Wn=p(tt);Oo=l(Wn,"label"),Wn.forEach(t),Lo=l(Ct," column, and the label name is based on the directory name."),Ct.forEach(t),ns=f(e),x=r(e,"P",{});var ye=p(x);No=l(ye,"You can pass "),st=r(ye,"CODE",{});var Xn=p(st);Bo=l(Xn,"drop_labels=False"),Xn.forEach(t),zo=l(ye," to ignore the "),lt=r(ye,"CODE",{});var Zn=p(lt);So=l(Zn,"label"),Zn.forEach(t),Jo=l(ye," column, as defined in "),ja=r(ye,"A",{href:!0});var ep=p(ja);Ro=l(ep,"ImageFolderConfig"),ep.forEach(t),Ho=l(ye,"."),ye.forEach(t),ps=f(e),z=r(e,"H2",{class:!0});var sl=p(z);se=r(sl,"A",{id:!0,class:!0,href:!0});var ap=p(se);ot=r(ap,"SPAN",{});var tp=p(ot);d(Je.$$.fragment,tp),tp.forEach(t),ap.forEach(t),Go=f(sl),rt=r(sl,"SPAN",{});var sp=p(rt);Yo=l(sp,"ImageFolder with metadata"),sp.forEach(t),sl.forEach(t),is=f(e),le=r(e,"P",{});var ll=p(le);Uo=l(ll,"If your image dataset comes with metadata, they will be also loaded. First, make sure your dataset has a "),nt=r(ll,"CODE",{});var lp=p(nt);Mo=l(lp,"metadata.jsonl"),lp.forEach(t),Ko=l(ll,":"),ll.forEach(t),ms=f(e),d(Re.$$.fragment,e),fs=f(e),oe=r(e,"P",{});var ol=p(oe);Qo=l(ol,"You can link the metadata in "),pt=r(ol,"CODE",{});var op=p(pt);Vo=l(op,"metadata.jsonl"),op.forEach(t),Wo=l(ol," file to the images using the \u201Cfile_path\u201D field."),ol.forEach(t),cs=f(e),S=r(e,"H3",{class:!0});var rl=p(S);re=r(rl,"A",{id:!0,class:!0,href:!0});var rp=p(re);it=r(rp,"SPAN",{});var np=p(it);d(He.$$.fragment,np),np.forEach(t),rp.forEach(t),Xo=f(rl),mt=r(rl,"SPAN",{});var pp=p(mt);Zo=l(pp,"Image captioning"),pp.forEach(t),rl.forEach(t),hs=f(e),ne=r(e,"P",{});var nl=p(ne);er=l(nl,"Here is an example of "),ft=r(nl,"CODE",{});var ip=p(ft);ar=l(ip,"metadata.jsonl"),ip.forEach(t),tr=l(nl," for image captioning:"),nl.forEach(t),ds=f(e),d(Ge.$$.fragment,e),us=f(e),J=r(e,"P",{});var Ft=p(J);ct=r(Ft,"CODE",{});var mp=p(ct);sr=l(mp,"ImageFolder"),mp.forEach(t),lr=l(Ft," will create a "),ht=r(Ft,"CODE",{});var fp=p(ht);or=l(fp,"text"),fp.forEach(t),rr=l(Ft," column for the image captions:"),Ft.forEach(t),gs=f(e),d(Ye.$$.fragment,e),_s=f(e),R=r(e,"H3",{class:!0});var pl=p(R);pe=r(pl,"A",{id:!0,class:!0,href:!0});var cp=p(pe);dt=r(cp,"SPAN",{});var hp=p(dt);d(Ue.$$.fragment,hp),hp.forEach(t),cp.forEach(t),nr=f(pl),ut=r(pl,"SPAN",{});var dp=p(ut);pr=l(dp,"Object detection"),dp.forEach(t),pl.forEach(t),vs=f(e),ie=r(e,"P",{});var il=p(ie);ir=l(il,"Here is an example of "),gt=r(il,"CODE",{});var up=p(gt);mr=l(up,"metadata.jsonl"),up.forEach(t),fr=l(il," for object detection:"),il.forEach(t),$s=f(e),d(Me.$$.fragment,e),js=f(e),H=r(e,"P",{});var Tt=p(H);_t=r(Tt,"CODE",{});var gp=p(_t);cr=l(gp,"ImageFolder"),gp.forEach(t),hr=l(Tt," will create a "),vt=r(Tt,"CODE",{});var _p=p(vt);dr=l(_p,"objects"),_p.forEach(t),ur=l(Tt," column with the bounding boxes and the categories:"),Tt.forEach(t),ws=f(e),d(Ke.$$.fragment,e),bs=f(e),G=r(e,"H2",{class:!0});var ml=p(G);me=r(ml,"A",{id:!0,class:!0,href:!0});var vp=p(me);$t=r(vp,"SPAN",{});var $p=p($t);d(Qe.$$.fragment,$p),$p.forEach(t),vp.forEach(t),gr=f(ml),jt=r(ml,"SPAN",{});var jp=p(jt);_r=l(jp,"Map"),jp.forEach(t),ml.forEach(t),Es=f(e),Ve=r(e,"P",{});var pn=p(Ve);wa=r(pn,"A",{href:!0});var wp=p(wa);vr=l(wp,"Dataset.map()"),wp.forEach(t),$r=l(pn," can apply transforms over an entire dataset and it also generates a cache file."),pn.forEach(t),ys=f(e),fe=r(e,"P",{});var fl=p(fe);jr=l(fl,"Create a simple "),We=r(fl,"A",{href:!0,rel:!0});var bp=p(We);wt=r(bp,"CODE",{});var Ep=p(wt);wr=l(Ep,"Resize"),Ep.forEach(t),bp.forEach(t),br=l(fl," function:"),fl.forEach(t),qs=f(e),d(Xe.$$.fragment,e),ks=f(e),b=r(e,"P",{});var F=p(b);Er=l(F,"Now "),ba=r(F,"A",{href:!0});var yp=p(ba);yr=l(yp,"Dataset.map()"),yp.forEach(t),qr=l(F," the function over the entire dataset and set "),bt=r(F,"CODE",{});var qp=p(bt);kr=l(qp,"batched=True"),qp.forEach(t),xr=l(F,". The transform returns "),Et=r(F,"CODE",{});var kp=p(Et);Ir=l(kp,"pixel_values"),kp.forEach(t),Dr=l(F," as a cacheable "),yt=r(F,"CODE",{});var xp=p(yt);Pr=l(xp,"PIL.Image"),xp.forEach(t),Ar=l(F," object:"),F.forEach(t),xs=f(e),d(Ze.$$.fragment,e),Is=f(e),ce=r(e,"P",{});var cl=p(ce);Cr=l(cl,"This saves time because you don\u2019t have to execute the same transform twice. It is best to use "),Ea=r(cl,"A",{href:!0});var Ip=p(Ea);Fr=l(Ip,"Dataset.map()"),Ip.forEach(t),Tr=l(cl," for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),cl.forEach(t),Ds=f(e),ea=r(e,"P",{});var mn=p(ea);ya=r(mn,"A",{href:!0});var Dp=p(ya);Or=l(Dp,"Dataset.map()"),Dp.forEach(t),Lr=l(mn," takes up some memory, but you can reduce its memory requirements with the following parameters:"),mn.forEach(t),Ps=f(e),he=r(e,"UL",{});var hl=p(he);qa=r(hl,"LI",{});var fn=p(qa);ka=r(fn,"A",{href:!0});var Pp=p(ka);qt=r(Pp,"CODE",{});var Ap=p(qt);Nr=l(Ap,"batch_size"),Ap.forEach(t),Pp.forEach(t),Br=l(fn," determines the number of examples that are processed in one call to the transform function."),fn.forEach(t),zr=f(hl),xa=r(hl,"LI",{});var cn=p(xa);Ia=r(cn,"A",{href:!0});var Cp=p(Ia);kt=r(Cp,"CODE",{});var Fp=p(kt);Sr=l(Fp,"writer_batch_size"),Fp.forEach(t),Cp.forEach(t),Jr=l(cn," determines the number of processed examples that are kept in memory before they are stored away."),cn.forEach(t),hl.forEach(t),As=f(e),de=r(e,"P",{});var dl=p(de);Rr=l(dl,"Both parameter values default to 1000, which can be expensive if you are storing images. Lower the value to use less memory when calling "),Da=r(dl,"A",{href:!0});var Tp=p(Da);Hr=l(Tp,"Dataset.map()"),Tp.forEach(t),Gr=l(dl,"."),dl.forEach(t),Cs=f(e),Y=r(e,"H2",{class:!0});var ul=p(Y);ue=r(ul,"A",{id:!0,class:!0,href:!0});var Op=p(ue);xt=r(Op,"SPAN",{});var Lp=p(xt);d(aa.$$.fragment,Lp),Lp.forEach(t),Op.forEach(t),Yr=f(ul),It=r(ul,"SPAN",{});var Np=p(It);Ur=l(Np,"Data augmentation"),Np.forEach(t),ul.forEach(t),Fs=f(e),ge=r(e,"P",{});var gl=p(ge);Mr=l(gl,"Adding data augmentations to a dataset is common to prevent overfitting and achieve better performance. You can use any library or package you want to apply the augmentations. This guide will use the transforms from "),ta=r(gl,"A",{href:!0,rel:!0});var Bp=p(ta);Kr=l(Bp,"torchvision"),Bp.forEach(t),Qr=l(gl,"."),gl.forEach(t),Ts=f(e),d(_e.$$.fragment,e),Os=f(e),ve=r(e,"P",{});var _l=p(ve);Vr=l(_l,"Add the "),sa=r(_l,"A",{href:!0,rel:!0});var zp=p(sa);Dt=r(zp,"CODE",{});var Sp=p(Dt);Wr=l(Sp,"ColorJitter"),Sp.forEach(t),zp.forEach(t),Xr=l(_l," transform to change the color properties of the image randomly:"),_l.forEach(t),Ls=f(e),d(la.$$.fragment,e),Ns=f(e),$e=r(e,"P",{});var vl=p($e);Zr=l(vl,"Create a function to apply the "),Pt=r(vl,"CODE",{});var Jp=p(Pt);en=l(Jp,"ColorJitter"),Jp.forEach(t),an=l(vl," transform to an image:"),vl.forEach(t),Bs=f(e),d(oa.$$.fragment,e),zs=f(e),je=r(e,"P",{});var $l=p(je);tn=l($l,"Then you can use the "),Pa=r($l,"A",{href:!0});var Rp=p(Pa);sn=l(Rp,"Dataset.set_transform()"),Rp.forEach(t),ln=l($l," function to apply the transform on-the-fly to consume less disk space. Use this function if you only need to access the examples once:"),$l.forEach(t),Ss=f(e),d(ra.$$.fragment,e),Js=f(e),we=r(e,"P",{});var jl=p(we);on=l(jl,"Now visualize the results of the "),At=r(jl,"CODE",{});var Hp=p(At);rn=l(Hp,"ColorJitter"),Hp.forEach(t),nn=l(jl," transform:"),jl.forEach(t),Rs=f(e),d(na.$$.fragment,e),Hs=f(e),Aa=r(e,"P",{});var Gp=p(Aa);Ca=r(Gp,"IMG",{src:!0,alt:!0}),Gp.forEach(t),this.h()},h(){c(j,"name","hf:doc:metadata"),c(j,"content",JSON.stringify(ei)),c(y,"id","process-image-data"),c(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y,"href","#process-image-data"),c(w,"class","relative group"),c(ia,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Image"),c(ma,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.map"),c(fa,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.set_transform"),c(V,"id","installation"),c(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V,"href","#installation"),c(O,"class","relative group"),c(ca,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Image"),c(ha,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Image"),c(W,"id","image-datasets"),c(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W,"href","#image-datasets"),c(L,"class","relative group"),c(Ce,"href","https://huggingface.co/datasets/food101"),c(Ce,"rel","nofollow"),c(ua,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Image"),Yp(_a.src,hn="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_beignet.png")||c(_a,"src",hn),c(_a,"alt","image_process_beignet"),c(va,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.cast_column"),c($a,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Image"),c(ee,"id","imagefolder"),c(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ee,"href","#imagefolder"),c(N,"class","relative group"),c(ja,"href","/docs/datasets/pr_4604/en/package_reference/loading_methods#datasets.packaged_modules.imagefolder.ImageFolderConfig"),c(se,"id","imagefolder-with-metadata"),c(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(se,"href","#imagefolder-with-metadata"),c(z,"class","relative group"),c(re,"id","image-captioning"),c(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(re,"href","#image-captioning"),c(S,"class","relative group"),c(pe,"id","object-detection"),c(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pe,"href","#object-detection"),c(R,"class","relative group"),c(me,"id","map"),c(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(me,"href","#map"),c(G,"class","relative group"),c(wa,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.map"),c(We,"href","https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html"),c(We,"rel","nofollow"),c(ba,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.map"),c(Ea,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.map"),c(ya,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.map"),c(ka,"href","./package_reference/main_classes#datasets.DatasetDict.map.batch_size"),c(Ia,"href","./package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size"),c(Da,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.map"),c(ue,"id","data-augmentation"),c(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ue,"href","#data-augmentation"),c(Y,"class","relative group"),c(ta,"href","https://pytorch.org/vision/stable/transforms.html"),c(ta,"rel","nofollow"),c(sa,"href","https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ColorJitter"),c(sa,"rel","nofollow"),c(Pa,"href","/docs/datasets/pr_4604/en/package_reference/main_classes#datasets.Dataset.set_transform"),Yp(Ca.src,dn="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_jitter.png")||c(Ca,"src",dn),c(Ca,"alt","image_process_jitter")},m(e,n){a(document.head,j),i(e,M,n),i(e,w,n),a(w,y),a(y,T),u(E,T,null),a(w,I),a(w,K),a(K,wl),i(e,Lt,n),i(e,Q,n),a(Q,bl),a(Q,ia),a(ia,El),a(Q,yl),i(e,Nt,n),i(e,q,n),a(q,Na),a(Na,ql),a(q,kl),a(q,qe),a(qe,xl),a(qe,Ba),a(Ba,Il),a(qe,Dl),a(q,Pl),a(q,ke),a(ke,Al),a(ke,ma),a(ma,Cl),a(ke,Fl),a(q,Tl),a(q,xe),a(xe,Ol),a(xe,fa),a(fa,Ll),a(xe,Nl),i(e,Bt,n),i(e,O,n),a(O,V),a(V,za),u(Ie,za,null),a(O,Bl),a(O,Sa),a(Sa,zl),i(e,zt,n),i(e,D,n),a(D,Sl),a(D,ca),a(ca,Jl),a(D,Rl),a(D,ha),a(ha,Hl),a(D,Gl),i(e,St,n),u(De,e,n),i(e,Jt,n),i(e,L,n),a(L,W),a(W,Ja),u(Pe,Ja,null),a(L,Yl),a(L,Ra),a(Ra,Ul),i(e,Rt,n),i(e,da,n),a(da,Ml),i(e,Ht,n),i(e,X,n),a(X,Ae),a(Ae,Kl),a(Ae,Ha),a(Ha,Ql),a(Ae,Vl),a(X,Wl),a(X,Ga),a(Ga,Xl),i(e,Gt,n),i(e,Z,n),a(Z,Zl),a(Z,Ce),a(Ce,eo),a(Z,ao),i(e,Yt,n),u(Fe,e,n),i(e,Ut,n),i(e,k,n),a(k,to),a(k,ua),a(ua,so),a(k,lo),a(k,Ya),a(Ya,oo),a(k,ro),a(k,Ua),a(Ua,no),a(k,po),i(e,Mt,n),u(Te,e,n),i(e,Kt,n),i(e,ga,n),a(ga,_a),i(e,Qt,n),i(e,P,n),a(P,io),a(P,va),a(va,mo),a(P,fo),a(P,$a),a($a,co),a(P,ho),i(e,Vt,n),u(Oe,e,n),i(e,Wt,n),i(e,A,n),a(A,uo),a(A,Ma),a(Ma,go),a(A,_o),a(A,Ka),a(Ka,vo),a(A,$o),i(e,Xt,n),u(Le,e,n),i(e,Zt,n),i(e,N,n),a(N,ee),a(ee,Qa),u(Ne,Qa,null),a(N,jo),a(N,Va),a(Va,wo),i(e,es,n),i(e,ae,n),a(ae,bo),a(ae,Wa),a(Wa,Eo),a(ae,yo),i(e,as,n),u(Be,e,n),i(e,ts,n),i(e,C,n),a(C,qo),a(C,Xa),a(Xa,ko),a(C,xo),a(C,Za),a(Za,Io),a(C,Do),i(e,ss,n),u(ze,e,n),i(e,ls,n),i(e,te,n),a(te,Po),a(te,et),a(et,Ao),a(te,Co),i(e,os,n),u(Se,e,n),i(e,rs,n),i(e,B,n),a(B,at),a(at,Fo),a(B,To),a(B,tt),a(tt,Oo),a(B,Lo),i(e,ns,n),i(e,x,n),a(x,No),a(x,st),a(st,Bo),a(x,zo),a(x,lt),a(lt,So),a(x,Jo),a(x,ja),a(ja,Ro),a(x,Ho),i(e,ps,n),i(e,z,n),a(z,se),a(se,ot),u(Je,ot,null),a(z,Go),a(z,rt),a(rt,Yo),i(e,is,n),i(e,le,n),a(le,Uo),a(le,nt),a(nt,Mo),a(le,Ko),i(e,ms,n),u(Re,e,n),i(e,fs,n),i(e,oe,n),a(oe,Qo),a(oe,pt),a(pt,Vo),a(oe,Wo),i(e,cs,n),i(e,S,n),a(S,re),a(re,it),u(He,it,null),a(S,Xo),a(S,mt),a(mt,Zo),i(e,hs,n),i(e,ne,n),a(ne,er),a(ne,ft),a(ft,ar),a(ne,tr),i(e,ds,n),u(Ge,e,n),i(e,us,n),i(e,J,n),a(J,ct),a(ct,sr),a(J,lr),a(J,ht),a(ht,or),a(J,rr),i(e,gs,n),u(Ye,e,n),i(e,_s,n),i(e,R,n),a(R,pe),a(pe,dt),u(Ue,dt,null),a(R,nr),a(R,ut),a(ut,pr),i(e,vs,n),i(e,ie,n),a(ie,ir),a(ie,gt),a(gt,mr),a(ie,fr),i(e,$s,n),u(Me,e,n),i(e,js,n),i(e,H,n),a(H,_t),a(_t,cr),a(H,hr),a(H,vt),a(vt,dr),a(H,ur),i(e,ws,n),u(Ke,e,n),i(e,bs,n),i(e,G,n),a(G,me),a(me,$t),u(Qe,$t,null),a(G,gr),a(G,jt),a(jt,_r),i(e,Es,n),i(e,Ve,n),a(Ve,wa),a(wa,vr),a(Ve,$r),i(e,ys,n),i(e,fe,n),a(fe,jr),a(fe,We),a(We,wt),a(wt,wr),a(fe,br),i(e,qs,n),u(Xe,e,n),i(e,ks,n),i(e,b,n),a(b,Er),a(b,ba),a(ba,yr),a(b,qr),a(b,bt),a(bt,kr),a(b,xr),a(b,Et),a(Et,Ir),a(b,Dr),a(b,yt),a(yt,Pr),a(b,Ar),i(e,xs,n),u(Ze,e,n),i(e,Is,n),i(e,ce,n),a(ce,Cr),a(ce,Ea),a(Ea,Fr),a(ce,Tr),i(e,Ds,n),i(e,ea,n),a(ea,ya),a(ya,Or),a(ea,Lr),i(e,Ps,n),i(e,he,n),a(he,qa),a(qa,ka),a(ka,qt),a(qt,Nr),a(qa,Br),a(he,zr),a(he,xa),a(xa,Ia),a(Ia,kt),a(kt,Sr),a(xa,Jr),i(e,As,n),i(e,de,n),a(de,Rr),a(de,Da),a(Da,Hr),a(de,Gr),i(e,Cs,n),i(e,Y,n),a(Y,ue),a(ue,xt),u(aa,xt,null),a(Y,Yr),a(Y,It),a(It,Ur),i(e,Fs,n),i(e,ge,n),a(ge,Mr),a(ge,ta),a(ta,Kr),a(ge,Qr),i(e,Ts,n),u(_e,e,n),i(e,Os,n),i(e,ve,n),a(ve,Vr),a(ve,sa),a(sa,Dt),a(Dt,Wr),a(ve,Xr),i(e,Ls,n),u(la,e,n),i(e,Ns,n),i(e,$e,n),a($e,Zr),a($e,Pt),a(Pt,en),a($e,an),i(e,Bs,n),u(oa,e,n),i(e,zs,n),i(e,je,n),a(je,tn),a(je,Pa),a(Pa,sn),a(je,ln),i(e,Ss,n),u(ra,e,n),i(e,Js,n),i(e,we,n),a(we,on),a(we,At),a(At,rn),a(we,nn),i(e,Rs,n),u(na,e,n),i(e,Hs,n),i(e,Aa,n),a(Aa,Ca),Gs=!0},p(e,[n]){const pa={};n&2&&(pa.$$scope={dirty:n,ctx:e}),_e.$set(pa)},i(e){Gs||(g(E.$$.fragment,e),g(Ie.$$.fragment,e),g(De.$$.fragment,e),g(Pe.$$.fragment,e),g(Fe.$$.fragment,e),g(Te.$$.fragment,e),g(Oe.$$.fragment,e),g(Le.$$.fragment,e),g(Ne.$$.fragment,e),g(Be.$$.fragment,e),g(ze.$$.fragment,e),g(Se.$$.fragment,e),g(Je.$$.fragment,e),g(Re.$$.fragment,e),g(He.$$.fragment,e),g(Ge.$$.fragment,e),g(Ye.$$.fragment,e),g(Ue.$$.fragment,e),g(Me.$$.fragment,e),g(Ke.$$.fragment,e),g(Qe.$$.fragment,e),g(Xe.$$.fragment,e),g(Ze.$$.fragment,e),g(aa.$$.fragment,e),g(_e.$$.fragment,e),g(la.$$.fragment,e),g(oa.$$.fragment,e),g(ra.$$.fragment,e),g(na.$$.fragment,e),Gs=!0)},o(e){_(E.$$.fragment,e),_(Ie.$$.fragment,e),_(De.$$.fragment,e),_(Pe.$$.fragment,e),_(Fe.$$.fragment,e),_(Te.$$.fragment,e),_(Oe.$$.fragment,e),_(Le.$$.fragment,e),_(Ne.$$.fragment,e),_(Be.$$.fragment,e),_(ze.$$.fragment,e),_(Se.$$.fragment,e),_(Je.$$.fragment,e),_(Re.$$.fragment,e),_(He.$$.fragment,e),_(Ge.$$.fragment,e),_(Ye.$$.fragment,e),_(Ue.$$.fragment,e),_(Me.$$.fragment,e),_(Ke.$$.fragment,e),_(Qe.$$.fragment,e),_(Xe.$$.fragment,e),_(Ze.$$.fragment,e),_(aa.$$.fragment,e),_(_e.$$.fragment,e),_(la.$$.fragment,e),_(oa.$$.fragment,e),_(ra.$$.fragment,e),_(na.$$.fragment,e),Gs=!1},d(e){t(j),e&&t(M),e&&t(w),v(E),e&&t(Lt),e&&t(Q),e&&t(Nt),e&&t(q),e&&t(Bt),e&&t(O),v(Ie),e&&t(zt),e&&t(D),e&&t(St),v(De,e),e&&t(Jt),e&&t(L),v(Pe),e&&t(Rt),e&&t(da),e&&t(Ht),e&&t(X),e&&t(Gt),e&&t(Z),e&&t(Yt),v(Fe,e),e&&t(Ut),e&&t(k),e&&t(Mt),v(Te,e),e&&t(Kt),e&&t(ga),e&&t(Qt),e&&t(P),e&&t(Vt),v(Oe,e),e&&t(Wt),e&&t(A),e&&t(Xt),v(Le,e),e&&t(Zt),e&&t(N),v(Ne),e&&t(es),e&&t(ae),e&&t(as),v(Be,e),e&&t(ts),e&&t(C),e&&t(ss),v(ze,e),e&&t(ls),e&&t(te),e&&t(os),v(Se,e),e&&t(rs),e&&t(B),e&&t(ns),e&&t(x),e&&t(ps),e&&t(z),v(Je),e&&t(is),e&&t(le),e&&t(ms),v(Re,e),e&&t(fs),e&&t(oe),e&&t(cs),e&&t(S),v(He),e&&t(hs),e&&t(ne),e&&t(ds),v(Ge,e),e&&t(us),e&&t(J),e&&t(gs),v(Ye,e),e&&t(_s),e&&t(R),v(Ue),e&&t(vs),e&&t(ie),e&&t($s),v(Me,e),e&&t(js),e&&t(H),e&&t(ws),v(Ke,e),e&&t(bs),e&&t(G),v(Qe),e&&t(Es),e&&t(Ve),e&&t(ys),e&&t(fe),e&&t(qs),v(Xe,e),e&&t(ks),e&&t(b),e&&t(xs),v(Ze,e),e&&t(Is),e&&t(ce),e&&t(Ds),e&&t(ea),e&&t(Ps),e&&t(he),e&&t(As),e&&t(de),e&&t(Cs),e&&t(Y),v(aa),e&&t(Fs),e&&t(ge),e&&t(Ts),v(_e,e),e&&t(Os),e&&t(ve),e&&t(Ls),v(la,e),e&&t(Ns),e&&t($e),e&&t(Bs),v(oa,e),e&&t(zs),e&&t(je),e&&t(Ss),v(ra,e),e&&t(Js),e&&t(we),e&&t(Rs),v(na,e),e&&t(Hs),e&&t(Aa)}}}const ei={local:"process-image-data",sections:[{local:"installation",title:"Installation"},{local:"image-datasets",title:"Image datasets"},{local:"imagefolder",title:"ImageFolder"},{local:"imagefolder-with-metadata",sections:[{local:"image-captioning",title:"Image captioning"},{local:"object-detection",title:"Object detection"}],title:"ImageFolder with metadata"},{local:"map",title:"Map"},{local:"data-augmentation",title:"Data augmentation"}],title:"Process image data"};function ai(Ot){return Vp(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ri extends Up{constructor(j){super();Mp(this,j,ai,Zp,Kp,{})}}export{ri as default,ei as metadata};
