import{S as en,i as tn,s as an,e as n,k as o,w as d,t as l,M as nn,c as r,d as a,m as i,a as s,x as u,h as c,b as m,G as t,g,y as h,L as rn,q as _,o as f,B as b,v as sn}from"../chunks/vendor-hf-doc-builder.js";import{D as y}from"../chunks/Docstring-hf-doc-builder.js";import{I as bt}from"../chunks/IconCopyLink-hf-doc-builder.js";function on(xa){let C,We,E,S,ye,U,vt,ke,$t,Qe,R,V,xe,J,yt,De,kt,Ue,v,j,xt,D,K,Dt,we,wt,Pt,Pe,zt,Ct,w,X,Et,ze,Rt,Lt,Ce,Tt,At,M,Y,qt,Ee,Nt,It,O,Z,St,ee,Vt,he,Mt,Ot,Bt,B,te,Ft,ae,Gt,_e,Ht,Wt,Je,L,F,Re,ne,Qt,Le,Ut,je,T,re,Jt,Te,jt,Ke,A,se,Kt,Ae,Xt,Xe,q,oe,Yt,qe,Zt,Ye,N,ie,ea,Ne,ta,Ze,I,G,Ie,me,aa,Se,na,et,$,le,ra,P,ce,sa,Ve,oa,ia,Me,ma,la,z,pe,ca,Oe,pa,da,Be,ua,ga,H,de,ha,Fe,_a,fa,W,ue,ba,Ge,va,$a,Q,ge,ya,He,ka,tt;return U=new bt({}),J=new bt({}),j=new y({props:{name:"class optimum.runs_base.Run",anchor:"optimum.runs_base.Run",parameters:[{name:"run_config",val:": dict"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/runs_base.py#L46"}}),K=new y({props:{name:"__init__",anchor:"optimum.runs_base.Run.__init__",parameters:[{name:"run_config",val:": dict"}],parametersDescription:[{anchor:"optimum.runs_base.Run.__init__.run_config",description:'<strong>run_config</strong> (dict) &#x2014; Parameters to use for the run. See <a href="/docs/optimum/pr_194/en/benchmark#optimum.utils.runs.RunConfig">RunConfig</a> for the expected keys.',name:"run_config"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/runs_base.py#L47"}}),X=new y({props:{name:"launch",anchor:"optimum.runs_base.Run.launch",parameters:[],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/runs_base.py#L104",returnDescription:`
<p>Finalized run data with metrics stored in the \u201Cevaluation\u201D key.</p>
`,returnType:`
<p><code>dict</code></p>
`}}),Y=new y({props:{name:"load_datasets",anchor:"optimum.runs_base.Run.load_datasets",parameters:[],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/runs_base.py#L138"}}),Z=new y({props:{name:"get_calibration_dataset",anchor:"optimum.runs_base.Run.get_calibration_dataset",parameters:[],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/runs_base.py#L146",returnDescription:`
<p>Calibration dataset.</p>
`,returnType:`
<p><code>datasets.Dataset</code></p>
`}}),te=new y({props:{name:"get_eval_dataset",anchor:"optimum.runs_base.Run.get_eval_dataset",parameters:[],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/runs_base.py#L156",returnDescription:`
<p>Evaluation dataset.</p>
`,returnType:`
<p><code>datasets.Dataset</code></p>
`}}),ne=new bt({}),re=new y({props:{name:"class optimum.utils.runs.RunConfig",anchor:"optimum.utils.runs.RunConfig",parameters:[{name:"model_name_or_path",val:": str"},{name:"task",val:": str"},{name:"task_args",val:": TaskArgs = None"},{name:"quantization_approach",val:": QuantizationApproach"},{name:"dataset",val:": DatasetArgs"},{name:"operators_to_quantize",val:": typing.List[str] = ['Add', 'MatMul']"},{name:"node_exclusion",val:": typing.List[str] = []"},{name:"per_channel",val:": bool = False"},{name:"calibration",val:": Calibration = None"},{name:"framework",val:": Frameworks"},{name:"framework_args",val:": FrameworkArgs"},{name:"aware_training",val:": bool = False"},{name:"metrics",val:": typing.List[str]"},{name:"batch_sizes",val:": typing.List[int] = [4, 8]"},{name:"input_lengths",val:": typing.List[int] = [128]"}],parametersDescription:[{anchor:"optimum.utils.runs.RunConfig.model_name_or_path",description:"<strong>model_name_or_path</strong> (<code>str</code>) &#x2014; Name of the model hosted on the Hub to use for the run.",name:"model_name_or_path"},{anchor:"optimum.utils.runs.RunConfig.task",description:"<strong>task</strong> (<code>str</code>) &#x2014; Task performed by the model.",name:"task"},{anchor:"optimum.utils.runs.RunConfig.task_args",description:"<strong>task_args</strong> (<code>TaskArgs</code>, <em>optional</em>) &#x2014; Task-specific arguments (default: <code>None</code>).",name:"task_args"},{anchor:"optimum.utils.runs.RunConfig.quantization_approach",description:"<strong>quantization_approach</strong> (<code>QuantizationApproach</code>) &#x2014; Whether to use dynamic or static quantization.",name:"quantization_approach"},{anchor:"optimum.utils.runs.RunConfig.dataset",description:"<strong>dataset</strong> (<code>DatasetArgs</code>) &#x2014; Dataset to use. Several keys must be set on top of the dataset name.",name:"dataset"},{anchor:"optimum.utils.runs.RunConfig.operators_to_quantize",description:"<strong>operators_to_quantize</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014; Operators to quantize, doing no modifications to others (default: <code>[&quot;Add&quot;, &quot;MatMul&quot;]</code>).",name:"operators_to_quantize"},{anchor:"optimum.utils.runs.RunConfig.node_exclusion",description:"<strong>node_exclusion</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014; Specific nodes to exclude from being quantized (default: <code>[]</code>).",name:"node_exclusion"},{anchor:"optimum.utils.runs.RunConfig.per_channel",description:"<strong>per_channel</strong> (<code>bool</code>, <em>optional</em>) &#x2014; Whether to quantize per channel (default: <code>False</code>).",name:"per_channel"},{anchor:"optimum.utils.runs.RunConfig.calibration",description:"<strong>calibration</strong> (<code>Calibration</code>, <em>optional</em>) &#x2014; Calibration parameters, in case static quantization is used.",name:"calibration"},{anchor:"optimum.utils.runs.RunConfig.framework",description:"<strong>framework</strong> (<code>Frameworks</code>) &#x2014; Name of the framework used (e.g. &#x201C;onnxruntime&#x201D;).",name:"framework"},{anchor:"optimum.utils.runs.RunConfig.framework_args",description:"<strong>framework_args</strong> (<code>FrameworkArgs</code>) &#x2014; Framework-specific arguments.",name:"framework_args"},{anchor:"optimum.utils.runs.RunConfig.aware_training",description:"<strong>aware_training</strong> (<code>bool</code>, <em>optional</em>) &#x2014; Whether the quantization is to be done with Quantization-Aware Training (not supported).",name:"aware_training"},{anchor:"optimum.utils.runs.RunConfig.metrics",description:"<strong>metrics</strong> (<code>List[str]</code>) &#x2014; List of metrics to evaluate on.",name:"metrics"},{anchor:"optimum.utils.runs.RunConfig.batch_sizes",description:"<strong>batch_sizes</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014; Batch sizes to include in the run to measure time metrics.",name:"batch_sizes"},{anchor:"optimum.utils.runs.RunConfig.input_lengths",description:"<strong>input_lengths</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014; Input lengths to include in the run to measure time metrics.",name:"input_lengths"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/runs.py#L205"}}),se=new y({props:{name:"class optimum.utils.runs.Calibration",anchor:"optimum.utils.runs.Calibration",parameters:[{name:"method",val:": CalibrationMethods"},{name:"num_calibration_samples",val:": int"},{name:"calibration_histogram_percentile",val:": float = None"},{name:"calibration_moving_average",val:": bool = None"},{name:"calibration_moving_average_constant",val:": float = None"}],parametersDescription:[{anchor:"optimum.utils.runs.Calibration.method",description:"<strong>method</strong> (<code>CalibrationMethods</code>) &#x2014; Calibration method used, either &#x201C;minmax&#x201D;, &#x201C;entropy&#x201D; or &#x201C;percentile&#x201D;.",name:"method"},{anchor:"optimum.utils.runs.Calibration.num_calibration_samples",description:"<strong>num_calibration_samples</strong> (<code>int</code>) &#x2014; Number of examples to use for the calibration step resulting from static quantization.",name:"num_calibration_samples"},{anchor:"optimum.utils.runs.Calibration.calibration_histogram_percentile",description:"<strong>calibration_histogram_percentile</strong> (<code>float</code>, <em>optional</em>) &#x2014; The percentile used for the percentile calibration method.",name:"calibration_histogram_percentile"},{anchor:"optimum.utils.runs.Calibration.calibration_moving_average",description:"<strong>calibration_moving_average</strong> (<code>bool</code>, <em>optional</em>) &#x2014; Whether to compute the moving average of the minimum and maximum values for the minmax calibration method.",name:"calibration_moving_average"},{anchor:"optimum.utils.runs.Calibration.calibration_moving_average_constant",description:"<strong>calibration_moving_average_constant</strong> (<code>float</code>, <em>optional</em>) &#x2014; Constant smoothing factor to use when computing the moving average of the minimum and maximum values. Effective only when the selected calibration method is minmax and <code>calibration_moving_average</code> is set to True.",name:"calibration_moving_average_constant"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/runs.py#L59"}}),oe=new y({props:{name:"class optimum.utils.runs.DatasetArgs",anchor:"optimum.utils.runs.DatasetArgs",parameters:[{name:"path",val:": str"},{name:"name",val:": str = None"},{name:"calibration_split",val:": str = None"},{name:"eval_split",val:": str"},{name:"data_keys",val:": typing.Dict[str, typing.Optional[str]]"},{name:"ref_keys",val:": typing.List[str]"}],parametersDescription:[{anchor:"optimum.utils.runs.DatasetArgs.path",description:"<strong>path</strong> (<code>str</code>) &#x2014; Path to the dataset, as in <code>datasets.load_dataset(path)</code>.",name:"path"},{anchor:"optimum.utils.runs.DatasetArgs.name",description:"<strong>name</strong> (<code>str</code>, <em>optional</em>) &#x2014; Name of the dataset, as in <code>datasets.load_dataset(path, name)</code>.",name:"name"},{anchor:"optimum.utils.runs.DatasetArgs.calibration_split",description:"<strong>calibration_split</strong> (<code>str</code>, <em>optional</em>) &#x2014; Dataset split used for calibration (e.g. &#x201C;train&#x201D;).",name:"calibration_split"},{anchor:"optimum.utils.runs.DatasetArgs.eval_split",description:"<strong>eval_split</strong> (<code>str</code>) &#x2014; Dataset split used for evaluation (e.g. &#x201C;test&#x201D;).",name:"eval_split"},{anchor:"optimum.utils.runs.DatasetArgs.data_keys",description:"<strong>data_keys</strong> (<code>Mapping[str, Union[str, NoneType]]</code>) &#x2014; Dataset columns used as input data. At most two, indicated with &#x201C;primary&#x201D; and &#x201C;secondary&#x201D;.",name:"data_keys"},{anchor:"optimum.utils.runs.DatasetArgs.ref_keys",description:"<strong>ref_keys</strong> (<code>List[str]</code>) &#x2014; Dataset column used for references during evaluation.",name:"ref_keys"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/runs.py#L118"}}),ie=new y({props:{name:"class optimum.utils.runs.TaskArgs",anchor:"optimum.utils.runs.TaskArgs",parameters:[{name:"is_regression",val:": bool = None"}],parametersDescription:[{anchor:"optimum.utils.runs.TaskArgs.is_regression",description:"<strong>is_regression</strong> (<code>bool</code>, <em>optional</em>) &#x2014; Text classification specific. Set whether the task is regression (output = one float).",name:"is_regression"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/runs.py#L133"}}),me=new bt({}),le=new y({props:{name:"class optimum.utils.preprocessing.base.DatasetProcessing",anchor:"optimum.utils.preprocessing.base.DatasetProcessing",parameters:[{name:"dataset_path",val:": str"},{name:"dataset_name",val:": str"},{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"eval_split",val:": str"},{name:"static_quantization",val:": bool"},{name:"data_keys",val:": typing.Dict[str, str]"},{name:"ref_keys",val:": typing.List[str]"},{name:"config",val:": PretrainedConfig"},{name:"task_args",val:": typing.Optional[typing.Dict] = None"},{name:"num_calibration_samples",val:": typing.Optional[int] = None"},{name:"calibration_split",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/preprocessing/base.py#L7"}}),ce=new y({props:{name:"__init__",anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__",parameters:[{name:"dataset_path",val:": str"},{name:"dataset_name",val:": str"},{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"eval_split",val:": str"},{name:"static_quantization",val:": bool"},{name:"data_keys",val:": typing.Dict[str, str]"},{name:"ref_keys",val:": typing.List[str]"},{name:"config",val:": PretrainedConfig"},{name:"task_args",val:": typing.Optional[typing.Dict] = None"},{name:"num_calibration_samples",val:": typing.Optional[int] = None"},{name:"calibration_split",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.dataset_path",description:'<strong>dataset_path</strong> (<code>str</code>) &#x2014; Dataset path (<a href="https://huggingface.co/docs/datasets/v2.2.1/en/package_reference/loading_methods#datasets.load_dataset.path" rel="nofollow">https://huggingface.co/docs/datasets/v2.2.1/en/package_reference/loading_methods#datasets.load_dataset.path</a>)',name:"dataset_path"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.dataset_name",description:'<strong>dataset_name</strong> (<code>str</code>) &#x2014; Dataset name (<a href="https://huggingface.co/docs/datasets/v2.2.1/en/package_reference/loading_methods#datasets.load_dataset.name" rel="nofollow">https://huggingface.co/docs/datasets/v2.2.1/en/package_reference/loading_methods#datasets.load_dataset.name</a>)',name:"dataset_name"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.tokenizer",description:"<strong>tokenizer</strong> (<code>PreTrainedTokenizerBase</code>) &#x2014; Tokenizer used for evaluation.",name:"tokenizer"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.eval_split",description:"<strong>eval_split</strong> (<code>str</code>) &#x2014; Dataset split used for evaluation (e.g. &#x201C;test&#x201D;).",name:"eval_split"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.static_quantization",description:"<strong>static_quantization</strong> (<code>bool</code>) &#x2014; Static quantization is used.",name:"static_quantization"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.data_keys",description:"<strong>data_keys</strong> (<code>Dict[str, str]</code>) &#x2014; Map &#x201C;primary&#x201D; and &#x201C;secondary&#x201D; to data column names.",name:"data_keys"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.ref_keys",description:"<strong>ref_keys</strong> (<code>List[str]</code>) &#x2014; References column names.",name:"ref_keys"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.config",description:"<strong>config</strong> (<code>PretrainedConfig</code>) &#x2014; Model configuration, useful for some tasks.",name:"config"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.task_args(Dict,",description:"<strong>task_args(<code>Dict</code>,</strong> <em>optional</em>) &#x2014; Task-specific arguments.",name:"task_args(Dict,"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.num_calibration_samples",description:"<strong>num_calibration_samples</strong> (<code>int</code>, <em>optional</em>) &#x2014; Number of calibration samples for static quantization. Defaults to None.",name:"num_calibration_samples"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.__init__.calibration_split",description:"<strong>calibration_split</strong> (<code>str</code>, <em>optional</em>) &#x2014; Calibration split (e.g. &#x201C;train&#x201D;) for static quantization. Defaults to None.",name:"calibration_split"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/preprocessing/base.py#L8"}}),pe=new y({props:{name:"load_datasets",anchor:"optimum.utils.preprocessing.base.DatasetProcessing.load_datasets",parameters:[],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/preprocessing/base.py#L54",returnDescription:`
<p>Dictionary holding the datasets.</p>
`,returnType:`
<p><code>Dict</code></p>
`}}),de=new y({props:{name:"run_inference",anchor:"optimum.utils.preprocessing.base.DatasetProcessing.run_inference",parameters:[{name:"eval_dataset",val:": Dataset"},{name:"pipeline",val:": Pipeline"}],parametersDescription:[{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.run_inference.eval_dataset",description:"<strong>eval_dataset</strong> (<code>Dataset</code>) &#x2014; Raw dataset to run inference on.",name:"eval_dataset"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.run_inference.pipeline",description:"<strong>pipeline</strong> (<code>Pipeline</code>) &#x2014; Pipeline used for inference. Should be initialized beforehand.",name:"pipeline"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/preprocessing/base.py#L64",returnDescription:`
<ul>
<li><strong>labels</strong> are the references for evaluation.</li>
<li><strong>predictions</strong> are the predictions on the dataset using the pipeline.</li>
</ul>
`,returnType:`
<p><code>tuple(List)</code> comprising labels and predictions</p>
`}}),ue=new y({props:{name:"get_metrics",anchor:"optimum.utils.preprocessing.base.DatasetProcessing.get_metrics",parameters:[{name:"predictions",val:""},{name:"references",val:""},{name:"metric",val:""}],parametersDescription:[{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.get_metrics.predictions",description:"<strong>predictions</strong> (<code>List</code>) &#x2014; Predictions.",name:"predictions"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.get_metrics.references",description:"<strong>references</strong> (<code>List</code>) &#x2014; References.",name:"references"},{anchor:"optimum.utils.preprocessing.base.DatasetProcessing.get_metrics.metric",description:"<strong>metric</strong> (<code>Metric</code>) &#x2014; Pre-loaded metric to run evaluation on.",name:"metric"}],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/preprocessing/base.py#L78",returnDescription:`
<p>Computed metrics.</p>
`,returnType:`
<p><code>Dict</code></p>
`}}),ge=new y({props:{name:"get_pipeline_kwargs",anchor:"optimum.utils.preprocessing.base.DatasetProcessing.get_pipeline_kwargs",parameters:[],source:"https://github.com/huggingface/optimum/blob/vr_194/src/optimum/utils/preprocessing/base.py#L91",returnDescription:`
<p>Task-specific kwargs to initialize the pipeline.</p>
`,returnType:`
<p><code>Dict</code></p>
`}}),{c(){C=n("meta"),We=o(),E=n("h1"),S=n("a"),ye=n("span"),d(U.$$.fragment),vt=o(),ke=n("span"),$t=l("Benchmarking"),Qe=o(),R=n("h2"),V=n("a"),xe=n("span"),d(J.$$.fragment),yt=o(),De=n("span"),kt=l("Run"),Ue=o(),v=n("div"),d(j.$$.fragment),xt=o(),D=n("div"),d(K.$$.fragment),Dt=o(),we=n("p"),wt=l("Initialize the Run class holding methods to perform inference and evaluation given a config."),Pt=o(),Pe=n("p"),zt=l("A run compares a transformers model and an optimized model on latency/throughput, model size, and provided metrics."),Ct=o(),w=n("div"),d(X.$$.fragment),Et=o(),ze=n("p"),Rt=l("Launch inference to compare metrics between the original and optimized model."),Lt=o(),Ce=n("p"),Tt=l("These metrics are latency, throughput, model size, and user provided metrics."),At=o(),M=n("div"),d(Y.$$.fragment),qt=o(),Ee=n("p"),Nt=l("Load evaluation dataset, and if needed, calibration dataset for static quantization."),It=o(),O=n("div"),d(Z.$$.fragment),St=o(),ee=n("p"),Vt=l("Get calibration dataset. The dataset needs to be loaded first with "),he=n("a"),Mt=l("load_datasets()"),Ot=l("."),Bt=o(),B=n("div"),d(te.$$.fragment),Ft=o(),ae=n("p"),Gt=l("Get evaluation dataset.  The dataset needs to be loaded first with "),_e=n("a"),Ht=l("load_datasets()"),Wt=l("."),Je=o(),L=n("h2"),F=n("a"),Re=n("span"),d(ne.$$.fragment),Qt=o(),Le=n("span"),Ut=l("RunConfig"),je=o(),T=n("div"),d(re.$$.fragment),Jt=o(),Te=n("p"),jt=l("Parameters defining a run. A run is an evaluation of a triplet (model, dataset, metric) coupled with optimization parameters, allowing to compare a transformers baseline and a model optimized with Optimum."),Ke=o(),A=n("div"),d(se.$$.fragment),Kt=o(),Ae=n("p"),Xt=l("Parameters for post-training calibration with static quantization."),Xe=o(),q=n("div"),d(oe.$$.fragment),Yt=o(),qe=n("p"),Zt=l("Parameters related to the dataset."),Ye=o(),N=n("div"),d(ie.$$.fragment),ea=o(),Ne=n("p"),ta=l("Task-specific parameters."),Ze=o(),I=n("h2"),G=n("a"),Ie=n("span"),d(me.$$.fragment),aa=o(),Se=n("span"),na=l("Processing utility methods"),et=o(),$=n("div"),d(le.$$.fragment),ra=o(),P=n("div"),d(ce.$$.fragment),sa=o(),Ve=n("p"),oa=l("Initialize the class in charge of loading datasets, running inference and evaluation."),ia=o(),Me=n("p"),ma=l("This class should be task-dependent, backend independent."),la=o(),z=n("div"),d(pe.$$.fragment),ca=o(),Oe=n("p"),pa=l("Load calibration dataset if needed, and evaluation dataset."),da=o(),Be=n("p"),ua=l("The evaluation dataset is meant to be used by a pipeline and is therefore not preprocessed. The calibration dataset is preprocessed."),ga=o(),H=n("div"),d(de.$$.fragment),ha=o(),Fe=n("p"),_a=l("Run inference on the provided dataset using a pipeline, and return all labels, predictions."),fa=o(),W=n("div"),d(ue.$$.fragment),ba=o(),Ge=n("p"),va=l("Compute a metric given pre-formatted predictions and references."),$a=o(),Q=n("div"),d(ge.$$.fragment),ya=o(),He=n("p"),ka=l("Get task-specific kwargs to initialize the pipeline."),this.h()},l(e){const p=nn('[data-svelte="svelte-1phssyn"]',document.head);C=r(p,"META",{name:!0,content:!0}),p.forEach(a),We=i(e),E=r(e,"H1",{class:!0});var at=s(E);S=r(at,"A",{id:!0,class:!0,href:!0});var Da=s(S);ye=r(Da,"SPAN",{});var wa=s(ye);u(U.$$.fragment,wa),wa.forEach(a),Da.forEach(a),vt=i(at),ke=r(at,"SPAN",{});var Pa=s(ke);$t=c(Pa,"Benchmarking"),Pa.forEach(a),at.forEach(a),Qe=i(e),R=r(e,"H2",{class:!0});var nt=s(R);V=r(nt,"A",{id:!0,class:!0,href:!0});var za=s(V);xe=r(za,"SPAN",{});var Ca=s(xe);u(J.$$.fragment,Ca),Ca.forEach(a),za.forEach(a),yt=i(nt),De=r(nt,"SPAN",{});var Ea=s(De);kt=c(Ea,"Run"),Ea.forEach(a),nt.forEach(a),Ue=i(e),v=r(e,"DIV",{class:!0});var k=s(v);u(j.$$.fragment,k),xt=i(k),D=r(k,"DIV",{class:!0});var fe=s(D);u(K.$$.fragment,fe),Dt=i(fe),we=r(fe,"P",{});var Ra=s(we);wt=c(Ra,"Initialize the Run class holding methods to perform inference and evaluation given a config."),Ra.forEach(a),Pt=i(fe),Pe=r(fe,"P",{});var La=s(Pe);zt=c(La,"A run compares a transformers model and an optimized model on latency/throughput, model size, and provided metrics."),La.forEach(a),fe.forEach(a),Ct=i(k),w=r(k,"DIV",{class:!0});var be=s(w);u(X.$$.fragment,be),Et=i(be),ze=r(be,"P",{});var Ta=s(ze);Rt=c(Ta,"Launch inference to compare metrics between the original and optimized model."),Ta.forEach(a),Lt=i(be),Ce=r(be,"P",{});var Aa=s(Ce);Tt=c(Aa,"These metrics are latency, throughput, model size, and user provided metrics."),Aa.forEach(a),be.forEach(a),At=i(k),M=r(k,"DIV",{class:!0});var rt=s(M);u(Y.$$.fragment,rt),qt=i(rt),Ee=r(rt,"P",{});var qa=s(Ee);Nt=c(qa,"Load evaluation dataset, and if needed, calibration dataset for static quantization."),qa.forEach(a),rt.forEach(a),It=i(k),O=r(k,"DIV",{class:!0});var st=s(O);u(Z.$$.fragment,st),St=i(st),ee=r(st,"P",{});var ot=s(ee);Vt=c(ot,"Get calibration dataset. The dataset needs to be loaded first with "),he=r(ot,"A",{href:!0});var Na=s(he);Mt=c(Na,"load_datasets()"),Na.forEach(a),Ot=c(ot,"."),ot.forEach(a),st.forEach(a),Bt=i(k),B=r(k,"DIV",{class:!0});var it=s(B);u(te.$$.fragment,it),Ft=i(it),ae=r(it,"P",{});var mt=s(ae);Gt=c(mt,"Get evaluation dataset.  The dataset needs to be loaded first with "),_e=r(mt,"A",{href:!0});var Ia=s(_e);Ht=c(Ia,"load_datasets()"),Ia.forEach(a),Wt=c(mt,"."),mt.forEach(a),it.forEach(a),k.forEach(a),Je=i(e),L=r(e,"H2",{class:!0});var lt=s(L);F=r(lt,"A",{id:!0,class:!0,href:!0});var Sa=s(F);Re=r(Sa,"SPAN",{});var Va=s(Re);u(ne.$$.fragment,Va),Va.forEach(a),Sa.forEach(a),Qt=i(lt),Le=r(lt,"SPAN",{});var Ma=s(Le);Ut=c(Ma,"RunConfig"),Ma.forEach(a),lt.forEach(a),je=i(e),T=r(e,"DIV",{class:!0});var ct=s(T);u(re.$$.fragment,ct),Jt=i(ct),Te=r(ct,"P",{});var Oa=s(Te);jt=c(Oa,"Parameters defining a run. A run is an evaluation of a triplet (model, dataset, metric) coupled with optimization parameters, allowing to compare a transformers baseline and a model optimized with Optimum."),Oa.forEach(a),ct.forEach(a),Ke=i(e),A=r(e,"DIV",{class:!0});var pt=s(A);u(se.$$.fragment,pt),Kt=i(pt),Ae=r(pt,"P",{});var Ba=s(Ae);Xt=c(Ba,"Parameters for post-training calibration with static quantization."),Ba.forEach(a),pt.forEach(a),Xe=i(e),q=r(e,"DIV",{class:!0});var dt=s(q);u(oe.$$.fragment,dt),Yt=i(dt),qe=r(dt,"P",{});var Fa=s(qe);Zt=c(Fa,"Parameters related to the dataset."),Fa.forEach(a),dt.forEach(a),Ye=i(e),N=r(e,"DIV",{class:!0});var ut=s(N);u(ie.$$.fragment,ut),ea=i(ut),Ne=r(ut,"P",{});var Ga=s(Ne);ta=c(Ga,"Task-specific parameters."),Ga.forEach(a),ut.forEach(a),Ze=i(e),I=r(e,"H2",{class:!0});var gt=s(I);G=r(gt,"A",{id:!0,class:!0,href:!0});var Ha=s(G);Ie=r(Ha,"SPAN",{});var Wa=s(Ie);u(me.$$.fragment,Wa),Wa.forEach(a),Ha.forEach(a),aa=i(gt),Se=r(gt,"SPAN",{});var Qa=s(Se);na=c(Qa,"Processing utility methods"),Qa.forEach(a),gt.forEach(a),et=i(e),$=r(e,"DIV",{class:!0});var x=s($);u(le.$$.fragment,x),ra=i(x),P=r(x,"DIV",{class:!0});var ve=s(P);u(ce.$$.fragment,ve),sa=i(ve),Ve=r(ve,"P",{});var Ua=s(Ve);oa=c(Ua,"Initialize the class in charge of loading datasets, running inference and evaluation."),Ua.forEach(a),ia=i(ve),Me=r(ve,"P",{});var Ja=s(Me);ma=c(Ja,"This class should be task-dependent, backend independent."),Ja.forEach(a),ve.forEach(a),la=i(x),z=r(x,"DIV",{class:!0});var $e=s(z);u(pe.$$.fragment,$e),ca=i($e),Oe=r($e,"P",{});var ja=s(Oe);pa=c(ja,"Load calibration dataset if needed, and evaluation dataset."),ja.forEach(a),da=i($e),Be=r($e,"P",{});var Ka=s(Be);ua=c(Ka,"The evaluation dataset is meant to be used by a pipeline and is therefore not preprocessed. The calibration dataset is preprocessed."),Ka.forEach(a),$e.forEach(a),ga=i(x),H=r(x,"DIV",{class:!0});var ht=s(H);u(de.$$.fragment,ht),ha=i(ht),Fe=r(ht,"P",{});var Xa=s(Fe);_a=c(Xa,"Run inference on the provided dataset using a pipeline, and return all labels, predictions."),Xa.forEach(a),ht.forEach(a),fa=i(x),W=r(x,"DIV",{class:!0});var _t=s(W);u(ue.$$.fragment,_t),ba=i(_t),Ge=r(_t,"P",{});var Ya=s(Ge);va=c(Ya,"Compute a metric given pre-formatted predictions and references."),Ya.forEach(a),_t.forEach(a),$a=i(x),Q=r(x,"DIV",{class:!0});var ft=s(Q);u(ge.$$.fragment,ft),ya=i(ft),He=r(ft,"P",{});var Za=s(He);ka=c(Za,"Get task-specific kwargs to initialize the pipeline."),Za.forEach(a),ft.forEach(a),x.forEach(a),this.h()},h(){m(C,"name","hf:doc:metadata"),m(C,"content",JSON.stringify(mn)),m(S,"id","benchmarking"),m(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S,"href","#benchmarking"),m(E,"class","relative group"),m(V,"id","optimum.runs_base.Run"),m(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(V,"href","#optimum.runs_base.Run"),m(R,"class","relative group"),m(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(he,"href","/docs/optimum/pr_194/en/benchmark#optimum.runs_base.Run.load_datasets"),m(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_e,"href","/docs/optimum/pr_194/en/benchmark#optimum.runs_base.Run.load_datasets"),m(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(v,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F,"id","optimum.utils.runs.RunConfig"),m(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(F,"href","#optimum.utils.runs.RunConfig"),m(L,"class","relative group"),m(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G,"id","optimum.utils.preprocessing.base.DatasetProcessing"),m(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(G,"href","#optimum.utils.preprocessing.base.DatasetProcessing"),m(I,"class","relative group"),m(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,p){t(document.head,C),g(e,We,p),g(e,E,p),t(E,S),t(S,ye),h(U,ye,null),t(E,vt),t(E,ke),t(ke,$t),g(e,Qe,p),g(e,R,p),t(R,V),t(V,xe),h(J,xe,null),t(R,yt),t(R,De),t(De,kt),g(e,Ue,p),g(e,v,p),h(j,v,null),t(v,xt),t(v,D),h(K,D,null),t(D,Dt),t(D,we),t(we,wt),t(D,Pt),t(D,Pe),t(Pe,zt),t(v,Ct),t(v,w),h(X,w,null),t(w,Et),t(w,ze),t(ze,Rt),t(w,Lt),t(w,Ce),t(Ce,Tt),t(v,At),t(v,M),h(Y,M,null),t(M,qt),t(M,Ee),t(Ee,Nt),t(v,It),t(v,O),h(Z,O,null),t(O,St),t(O,ee),t(ee,Vt),t(ee,he),t(he,Mt),t(ee,Ot),t(v,Bt),t(v,B),h(te,B,null),t(B,Ft),t(B,ae),t(ae,Gt),t(ae,_e),t(_e,Ht),t(ae,Wt),g(e,Je,p),g(e,L,p),t(L,F),t(F,Re),h(ne,Re,null),t(L,Qt),t(L,Le),t(Le,Ut),g(e,je,p),g(e,T,p),h(re,T,null),t(T,Jt),t(T,Te),t(Te,jt),g(e,Ke,p),g(e,A,p),h(se,A,null),t(A,Kt),t(A,Ae),t(Ae,Xt),g(e,Xe,p),g(e,q,p),h(oe,q,null),t(q,Yt),t(q,qe),t(qe,Zt),g(e,Ye,p),g(e,N,p),h(ie,N,null),t(N,ea),t(N,Ne),t(Ne,ta),g(e,Ze,p),g(e,I,p),t(I,G),t(G,Ie),h(me,Ie,null),t(I,aa),t(I,Se),t(Se,na),g(e,et,p),g(e,$,p),h(le,$,null),t($,ra),t($,P),h(ce,P,null),t(P,sa),t(P,Ve),t(Ve,oa),t(P,ia),t(P,Me),t(Me,ma),t($,la),t($,z),h(pe,z,null),t(z,ca),t(z,Oe),t(Oe,pa),t(z,da),t(z,Be),t(Be,ua),t($,ga),t($,H),h(de,H,null),t(H,ha),t(H,Fe),t(Fe,_a),t($,fa),t($,W),h(ue,W,null),t(W,ba),t(W,Ge),t(Ge,va),t($,$a),t($,Q),h(ge,Q,null),t(Q,ya),t(Q,He),t(He,ka),tt=!0},p:rn,i(e){tt||(_(U.$$.fragment,e),_(J.$$.fragment,e),_(j.$$.fragment,e),_(K.$$.fragment,e),_(X.$$.fragment,e),_(Y.$$.fragment,e),_(Z.$$.fragment,e),_(te.$$.fragment,e),_(ne.$$.fragment,e),_(re.$$.fragment,e),_(se.$$.fragment,e),_(oe.$$.fragment,e),_(ie.$$.fragment,e),_(me.$$.fragment,e),_(le.$$.fragment,e),_(ce.$$.fragment,e),_(pe.$$.fragment,e),_(de.$$.fragment,e),_(ue.$$.fragment,e),_(ge.$$.fragment,e),tt=!0)},o(e){f(U.$$.fragment,e),f(J.$$.fragment,e),f(j.$$.fragment,e),f(K.$$.fragment,e),f(X.$$.fragment,e),f(Y.$$.fragment,e),f(Z.$$.fragment,e),f(te.$$.fragment,e),f(ne.$$.fragment,e),f(re.$$.fragment,e),f(se.$$.fragment,e),f(oe.$$.fragment,e),f(ie.$$.fragment,e),f(me.$$.fragment,e),f(le.$$.fragment,e),f(ce.$$.fragment,e),f(pe.$$.fragment,e),f(de.$$.fragment,e),f(ue.$$.fragment,e),f(ge.$$.fragment,e),tt=!1},d(e){a(C),e&&a(We),e&&a(E),b(U),e&&a(Qe),e&&a(R),b(J),e&&a(Ue),e&&a(v),b(j),b(K),b(X),b(Y),b(Z),b(te),e&&a(Je),e&&a(L),b(ne),e&&a(je),e&&a(T),b(re),e&&a(Ke),e&&a(A),b(se),e&&a(Xe),e&&a(q),b(oe),e&&a(Ye),e&&a(N),b(ie),e&&a(Ze),e&&a(I),b(me),e&&a(et),e&&a($),b(le),b(ce),b(pe),b(de),b(ue),b(ge)}}}const mn={local:"benchmarking",sections:[{local:"optimum.runs_base.Run",title:"Run"},{local:"optimum.utils.runs.RunConfig",title:"RunConfig"},{local:"optimum.utils.preprocessing.base.DatasetProcessing",title:"Processing utility methods"}],title:"Benchmarking"};function ln(xa){return sn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class un extends en{constructor(C){super();tn(this,C,ln,on,an,{})}}export{un as default,mn as metadata};
