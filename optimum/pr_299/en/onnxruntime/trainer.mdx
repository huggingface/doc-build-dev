---
local: trainer
sections:
- local: optimum.onnxruntime.ORTTrainer
  title: ORTTrainer
- local: optimum.onnxruntime.ORTSeq2SeqTrainer
  title: ORTSeq2SeqTrainer
title: Trainer
---
<script lang="ts">
import {onMount} from "svelte";
import Tip from "$lib/Tip.svelte";
import Youtube from "$lib/Youtube.svelte";
import Docstring from "$lib/Docstring.svelte";
import CodeBlock from "$lib/CodeBlock.svelte";
import CodeBlockFw from "$lib/CodeBlockFw.svelte";
import DocNotebookDropdown from "$lib/DocNotebookDropdown.svelte";
import IconCopyLink from "$lib/IconCopyLink.svelte";
import FrameworkContent from "$lib/FrameworkContent.svelte";
import Markdown from "$lib/Markdown.svelte";
import Question from "$lib/Question.svelte";
import FrameworkSwitchCourse from "$lib/FrameworkSwitchCourse.svelte";
import InferenceApi from "$lib/InferenceApi.svelte";
import TokenizersLanguageContent from "$lib/TokenizersLanguageContent.svelte";
import ExampleCodeBlock from "$lib/ExampleCodeBlock.svelte";
let fw: "pt" | "tf" = "pt";
onMount(() => {
    const urlParams = new URLSearchParams(window.location.search);
    fw = urlParams.get("fw") || "pt";
});
</script>
<svelte:head>
  <meta name="hf:doc:metadata" content={JSON.stringify(metadata)} >
</svelte:head>
<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

<h1 id="trainer">Trainer</h1>

<h2 id="optimum.onnxruntime.ORTTrainer">ORTTrainer</h2>

<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">

<docstring><name>class optimum.onnxruntime.ORTTrainer</name><anchor>optimum.onnxruntime.ORTTrainer</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer.py#L125</source><parameters>[{"name": "model", "val": ": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"}, {"name": "tokenizer", "val": ": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"}, {"name": "feature", "val": ": str = 'default'"}, {"name": "args", "val": ": TrainingArguments = None"}, {"name": "data_collator", "val": ": typing.Optional[DataCollator] = None"}, {"name": "train_dataset", "val": ": typing.Optional[torch.utils.data.dataset.Dataset] = None"}, {"name": "eval_dataset", "val": ": typing.Optional[torch.utils.data.dataset.Dataset] = None"}, {"name": "model_init", "val": ": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"}, {"name": "compute_metrics", "val": ": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"}, {"name": "callbacks", "val": ": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"}, {"name": "optimizers", "val": ": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"}, {"name": "preprocess_logits_for_metrics", "val": ": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"}, {"name": "onnx_model_path", "val": ": typing.Union[str, os.PathLike] = None"}]</parameters></docstring>



<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>compute_loss_ort</name><anchor>optimum.onnxruntime.ORTTrainer.compute_loss_ort</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer.py#L1261</source><parameters>[{"name": "model", "val": ""}, {"name": "inputs", "val": ""}, {"name": "input_names", "val": ""}, {"name": "output_names", "val": ""}, {"name": "return_outputs", "val": " = False"}]</parameters></docstring>

How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.


</div>
<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>evaluate</name><anchor>optimum.onnxruntime.ORTTrainer.evaluate</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer.py#L633</source><parameters>[{"name": "eval_dataset", "val": ": typing.Optional[torch.utils.data.dataset.Dataset] = None"}, {"name": "ignore_keys", "val": ": typing.Optional[typing.List[str]] = None"}, {"name": "metric_key_prefix", "val": ": str = 'eval'"}, {"name": "inference_with_ort", "val": ": bool = False"}]</parameters></docstring>

Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from `Trainer.evaluate()`)


</div>
<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>evaluation_loop_ort</name><anchor>optimum.onnxruntime.ORTTrainer.evaluation_loop_ort</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer.py#L755</source><parameters>[{"name": "dataloader", "val": ": DataLoader"}, {"name": "description", "val": ": str"}, {"name": "prediction_loss_only", "val": ": typing.Optional[bool] = None"}, {"name": "ignore_keys", "val": ": typing.Optional[typing.List[str]] = None"}, {"name": "metric_key_prefix", "val": ": str = 'eval'"}]</parameters></docstring>

Prediction/evaluation loop, shared by `ORTTrainer.evaluate()` and `ORTTrainer.predict()`.
Works both with or without labels.


</div>
<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>predict</name><anchor>optimum.onnxruntime.ORTTrainer.predict</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer.py#L700</source><parameters>[{"name": "test_dataset", "val": ": Dataset"}, {"name": "ignore_keys", "val": ": typing.Optional[typing.List[str]] = None"}, {"name": "metric_key_prefix", "val": ": str = 'test'"}, {"name": "inference_with_ort", "val": ": bool = False"}]</parameters></docstring>

Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `Trainer.predict()`)


</div>
<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>prediction_loop_ort</name><anchor>optimum.onnxruntime.ORTTrainer.prediction_loop_ort</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer.py#L999</source><parameters>[{"name": "dataloader", "val": ": DataLoader"}, {"name": "description", "val": ": str"}, {"name": "prediction_loss_only", "val": ": typing.Optional[bool] = None"}, {"name": "ignore_keys", "val": ": typing.Optional[typing.List[str]] = None"}, {"name": "metric_key_prefix", "val": ": str = 'eval'"}]</parameters></docstring>

Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.
Works both with or without labels.


</div>
<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>train</name><anchor>optimum.onnxruntime.ORTTrainer.train</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer.py#L164</source><parameters>[{"name": "resume_from_checkpoint", "val": ": typing.Union[bool, str, NoneType] = None"}, {"name": "trial", "val": ": typing.Union[ForwardRef('optuna.Trial'), typing.Dict[str, typing.Any]] = None"}, {"name": "ignore_keys_for_eval", "val": ": typing.Optional[typing.List[str]] = None"}, {"name": "**kwargs", "val": ""}]</parameters><paramsdesc>- **resume_from_checkpoint** (`str` or `bool`, *optional*) --
  If a `str`, local path to a saved checkpoint as saved by a previous instance of `Trainer`. If a
  `bool` and equals `True`, load the last checkpoint in *args.output_dir* as saved by a previous instance
  of `Trainer`. If present, training will resume from the model/optimizer/scheduler states loaded here.
- **trial** (`optuna.Trial` or `Dict[str, Any]`, *optional*) --
  The trial run or the hyperparameter dictionary for hyperparameter search.
- **ignore_keys_for_eval** (`List[str]`, *optional*) --
  A list of keys in the output of your model (if it is a dictionary) that should be ignored when
  gathering predictions for evaluation during the training.
  kwargs --
  Additional keyword arguments used to hide deprecated arguments</paramsdesc><paramgroups>0</paramgroups></docstring>

Main onnxruntime training entry point.



</div></div>

<h2 id="optimum.onnxruntime.ORTSeq2SeqTrainer">ORTSeq2SeqTrainer</h2>

<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">

<docstring><name>class optimum.onnxruntime.ORTSeq2SeqTrainer</name><anchor>optimum.onnxruntime.ORTSeq2SeqTrainer</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer_seq2seq.py#L38</source><parameters>[{"name": "model", "val": ": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"}, {"name": "tokenizer", "val": ": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"}, {"name": "feature", "val": ": str = 'default'"}, {"name": "args", "val": ": TrainingArguments = None"}, {"name": "data_collator", "val": ": typing.Optional[DataCollator] = None"}, {"name": "train_dataset", "val": ": typing.Optional[torch.utils.data.dataset.Dataset] = None"}, {"name": "eval_dataset", "val": ": typing.Optional[torch.utils.data.dataset.Dataset] = None"}, {"name": "model_init", "val": ": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"}, {"name": "compute_metrics", "val": ": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"}, {"name": "callbacks", "val": ": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"}, {"name": "optimizers", "val": ": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"}, {"name": "preprocess_logits_for_metrics", "val": ": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"}, {"name": "onnx_model_path", "val": ": typing.Union[str, os.PathLike] = None"}]</parameters></docstring>



<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>evaluate</name><anchor>optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer_seq2seq.py#L39</source><parameters>[{"name": "eval_dataset", "val": ": typing.Optional[torch.utils.data.dataset.Dataset] = None"}, {"name": "ignore_keys", "val": ": typing.Optional[typing.List[str]] = None"}, {"name": "metric_key_prefix", "val": ": str = 'eval'"}, {"name": "max_length", "val": ": typing.Optional[int] = None"}, {"name": "num_beams", "val": ": typing.Optional[int] = None"}, {"name": "inference_with_ort", "val": ": bool = False"}]</parameters><paramsdesc>- **eval_dataset** (`Dataset`, *optional*) --
  Pass a dataset if you wish to override `self.eval_dataset`. If it is an `datasets.Dataset`,
  columns not accepted by the `model.forward()` method are automatically removed. It must implement the
  `__len__` method.
- **ignore_keys** (`List[str]`, *optional*) --
  A list of keys in the output of your model (if it is a dictionary) that should be ignored when
  gathering predictions.
- **metric_key_prefix** (`str`, *optional*, defaults to `"eval"`) --
  An optional prefix to be used as the metrics key prefix. For example the metrics "bleu" will be named
  "eval_bleu" if the prefix is `"eval"` (default)
- **max_length** (`int`, *optional*) --
  The maximum target length to use when predicting with the generate method.
- **num_beams** (`int`, *optional*) --
  Number of beams for beam search that will be used when predicting with the generate method. 1 means no
  beam search.
- **inference_with_ort** (`bool`, *optional*) --
  Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.</paramsdesc><paramgroups>0</paramgroups><retdesc>A dictionary containing the evaluation loss(only within PyTorch) and the potential metrics computed from the predictions. The
dictionary also contains the epoch number which comes from the training state.</retdesc></docstring>

Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `compute_metrics` argument).
You can also subclass and override this method to inject custom behavior.





</div>
<div class="docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8">
<docstring><name>predict</name><anchor>optimum.onnxruntime.ORTSeq2SeqTrainer.predict</anchor><source>https://github.com/huggingface/optimum/blob/vr_299/src/optimum/onnxruntime/trainer_seq2seq.py#L88</source><parameters>[{"name": "test_dataset", "val": ": Dataset"}, {"name": "ignore_keys", "val": ": typing.Optional[typing.List[str]] = None"}, {"name": "metric_key_prefix", "val": ": str = 'eval'"}, {"name": "max_length", "val": ": typing.Optional[int] = None"}, {"name": "num_beams", "val": ": typing.Optional[int] = None"}, {"name": "inference_with_ort", "val": ": bool = False"}]</parameters><paramsdesc>- **test_dataset** (`Dataset`) --
  Dataset to run the predictions on. If it is an `datasets.Dataset`, columns not accepted by the
  `model.forward()` method are automatically removed. Has to implement the method `__len__`
- **ignore_keys** (`List[str]`, *optional*) --
  A list of keys in the output of your model (if it is a dictionary) that should be ignored when
  gathering predictions.
- **metric_key_prefix** (`str`, *optional*, defaults to `"eval"`) --
  An optional prefix to be used as the metrics key prefix. For example the metrics "bleu" will be named
  "eval_bleu" if the prefix is `"eval"` (default)
- **max_length** (`int`, *optional*) --
  The maximum target length to use when predicting with the generate method.
- **num_beams** (`int`, *optional*) --
  Number of beams for beam search that will be used when predicting with the generate method. 1 means no
  beam search.
- **inference_with_ort** (`bool`, *optional*) --
  Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.</paramsdesc><paramgroups>0</paramgroups></docstring>

Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `evaluate()`.


<Tip>

If your predictions or labels have different sequence lengths (for instance because you're doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.

</Tip>

Returns: *NamedTuple* A namedtuple with the following keys:
- predictions (`np.ndarray`): The predictions on `test_dataset`.
- label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).
- metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset
  contained labels).


</div></div>
