import{S as _r,i as vr,s as br,e as r,k as l,w as g,t as i,M as yr,c as a,d as t,m,a as o,x as f,h as s,b as d,G as e,g as k,y as _,q as v,o as b,B as y,v as Tr}from"../../chunks/vendor-hf-doc-builder.js";import{T as $r}from"../../chunks/Tip-hf-doc-builder.js";import{D as w}from"../../chunks/Docstring-hf-doc-builder.js";import{I as Fn}from"../../chunks/IconCopyLink-hf-doc-builder.js";function xr(Ge){let u,I;return{c(){u=r("p"),I=i(`If your predictions or labels have different sequence lengths (for instance because you\u2019re doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`)},l(T){u=a(T,"P",{});var x=o(u);I=s(x,`If your predictions or labels have different sequence lengths (for instance because you\u2019re doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`),x.forEach(t)},m(T,x){k(T,u,x),e(u,I)},d(T){T&&t(u)}}}function wr(Ge){let u,I,T,x,we,G,vt,Oe,bt,Je,R,z,ke,J,yt,Ee,Tt,Ke,c,K,$t,A,Q,xt,Re,wt,Ot,M,Z,kt,ee,Et,Ne,Rt,Nt,qt,V,te,Dt,ne,St,qe,Pt,Lt,Ct,U,re,It,N,zt,De,At,Mt,Se,Vt,Ut,Ft,F,ae,Wt,Pe,Ht,Xt,W,oe,Bt,ie,jt,Le,Yt,Gt,Jt,H,se,Kt,q,Qt,Ce,Zt,en,Ie,tn,nn,rn,X,le,an,ze,on,Qe,D,B,Ae,me,sn,Me,ln,Ze,O,de,mn,j,ce,dn,pe,cn,Ve,pn,un,hn,$,ue,gn,he,fn,Ue,_n,vn,bn,Y,yn,ge,Tn,Fe,$n,xn,wn,S,P,On,We,kn,En,He,Rn,Nn,qn,L,Dn,Xe,Sn,Pn,Be,Ln,Cn,In,C,zn,je,An,Mn,Ye,Vn,Un,et;return G=new Fn({}),J=new Fn({}),K=new w({props:{name:"class optimum.onnxruntime.ORTTrainer",anchor:"optimum.onnxruntime.ORTTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"preprocess_logits_for_metrics",val:": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L123"}}),Q=new w({props:{name:"compute_loss_ort",anchor:"optimum.onnxruntime.ORTTrainer.compute_loss_ort",parameters:[{name:"model",val:""},{name:"inputs",val:""},{name:"input_names",val:""},{name:"output_names",val:""},{name:"return_outputs",val:" = False"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L1259"}}),Z=new w({props:{name:"create_optimizer",anchor:"optimum.onnxruntime.ORTTrainer.create_optimizer",parameters:[],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L1428"}}),te=new w({props:{name:"evaluate",anchor:"optimum.onnxruntime.ORTTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L631"}}),re=new w({props:{name:"evaluation_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.evaluation_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L753"}}),ae=new w({props:{name:"get_ort_optimizer_cls_and_kwargs",anchor:"optimum.onnxruntime.ORTTrainer.get_ort_optimizer_cls_and_kwargs",parameters:[{name:"args",val:": TrainingArguments"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTTrainer.get_ort_optimizer_cls_and_kwargs.args",description:`<strong>args</strong> (<code>optimum.onnxruntime.training_args.ORTTrainingArguments</code>) &#x2014;
The training arguments for the training session.`,name:"args"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L1480"}}),oe=new w({props:{name:"predict",anchor:"optimum.onnxruntime.ORTTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'test'"},{name:"inference_with_ort",val:": bool = False"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L698"}}),se=new w({props:{name:"prediction_loop_ort",anchor:"optimum.onnxruntime.ORTTrainer.prediction_loop_ort",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L997"}}),le=new w({props:{name:"train",anchor:"optimum.onnxruntime.ORTTrainer.train",parameters:[{name:"resume_from_checkpoint",val:": typing.Union[bool, str, NoneType] = None"},{name:"trial",val:": typing.Union[ForwardRef('optuna.Trial'), typing.Dict[str, typing.Any]] = None"},{name:"ignore_keys_for_eval",val:": typing.Optional[typing.List[str]] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTTrainer.train.resume_from_checkpoint",description:`<strong>resume_from_checkpoint</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
If a <code>str</code>, local path to a saved checkpoint as saved by a previous instance of <code>Trainer</code>. If a
<code>bool</code> and equals <code>True</code>, load the last checkpoint in <em>args.output_dir</em> as saved by a previous instance
of <code>Trainer</code>. If present, training will resume from the model/optimizer/scheduler states loaded here.`,name:"resume_from_checkpoint"},{anchor:"optimum.onnxruntime.ORTTrainer.train.trial",description:`<strong>trial</strong> (<code>optuna.Trial</code> or <code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The trial run or the hyperparameter dictionary for hyperparameter search.`,name:"trial"},{anchor:"optimum.onnxruntime.ORTTrainer.train.ignore_keys_for_eval",description:`<strong>ignore_keys_for_eval</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions for evaluation during the training.
kwargs &#x2014;
Additional keyword arguments used to hide deprecated arguments`,name:"ignore_keys_for_eval"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer.py#L162"}}),me=new Fn({}),de=new w({props:{name:"class optimum.onnxruntime.ORTSeq2SeqTrainer",anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"feature",val:": str = 'default'"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"preprocess_logits_for_metrics",val:": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"},{name:"onnx_model_path",val:": typing.Union[str, os.PathLike] = None"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer_seq2seq.py#L38"}}),ce=new w({props:{name:"evaluate",anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"num_beams",val:": typing.Optional[int] = None"},{name:"inference_with_ort",val:": bool = False"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.eval_dataset",description:`<strong>eval_dataset</strong> (<code>Dataset</code>, <em>optional</em>) &#x2014;
Pass a dataset if you wish to override <code>self.eval_dataset</code>. If it is an <code>datasets.Dataset</code>,
columns not accepted by the <code>model.forward()</code> method are automatically removed. It must implement the
<code>__len__</code> method.`,name:"eval_dataset"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.`,name:"num_beams"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.evaluate.inference_with_ort",description:`<strong>inference_with_ort</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.`,name:"inference_with_ort"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer_seq2seq.py#L39",returnDescription:`
<p>A dictionary containing the evaluation loss(only within PyTorch) and the potential metrics computed from the predictions. The
dictionary also contains the epoch number which comes from the training state.</p>
`}}),ue=new w({props:{name:"predict",anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"num_beams",val:": typing.Optional[int] = None"},{name:"inference_with_ort",val:": bool = False"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.test_dataset",description:`<strong>test_dataset</strong> (<code>Dataset</code>) &#x2014;
Dataset to run the predictions on. If it is an <code>datasets.Dataset</code>, columns not accepted by the
<code>model.forward()</code> method are automatically removed. Has to implement the method <code>__len__</code>`,name:"test_dataset"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.`,name:"num_beams"},{anchor:"optimum.onnxruntime.ORTSeq2SeqTrainer.predict.inference_with_ort",description:`<strong>inference_with_ort</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether enable inference within ONNX Runtime backend. The inference will be done within PyTorch by default.`,name:"inference_with_ort"}],source:"https://github.com/huggingface/optimum/blob/vr_311/src/optimum/onnxruntime/trainer_seq2seq.py#L88"}}),Y=new $r({props:{$$slots:{default:[xr]},$$scope:{ctx:Ge}}}),{c(){u=r("meta"),I=l(),T=r("h1"),x=r("a"),we=r("span"),g(G.$$.fragment),vt=l(),Oe=r("span"),bt=i("Trainer"),Je=l(),R=r("h2"),z=r("a"),ke=r("span"),g(J.$$.fragment),yt=l(),Ee=r("span"),Tt=i("ORTTrainer"),Ke=l(),c=r("div"),g(K.$$.fragment),$t=l(),A=r("div"),g(Q.$$.fragment),xt=l(),Re=r("p"),wt=i(`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),Ot=l(),M=r("div"),g(Z.$$.fragment),kt=l(),ee=r("p"),Et=i(`Setup the optimizer.
We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
ORTTrainer\u2019s init through `),Ne=r("code"),Rt=i("optimizers"),Nt=i(", or subclass and override this method in a subclass."),qt=l(),V=r("div"),g(te.$$.fragment),Dt=l(),ne=r("p"),St=i("Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),qe=r("code"),Pt=i("Trainer.evaluate()"),Lt=i(")"),Ct=l(),U=r("div"),g(re.$$.fragment),It=l(),N=r("p"),zt=i("Prediction/evaluation loop, shared by "),De=r("code"),At=i("ORTTrainer.evaluate()"),Mt=i(" and "),Se=r("code"),Vt=i("ORTTrainer.predict()"),Ut=i(`.
Works both with or without labels.`),Ft=l(),F=r("div"),g(ae.$$.fragment),Wt=l(),Pe=r("p"),Ht=i("Returns the optimizer class and optimizer parameters based on the ORT training arguments."),Xt=l(),W=r("div"),g(oe.$$.fragment),Bt=l(),ie=r("p"),jt=i(`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),Le=r("code"),Yt=i("Trainer.predict()"),Gt=i(")"),Jt=l(),H=r("div"),g(se.$$.fragment),Kt=l(),q=r("p"),Qt=i("Prediction/evaluation loop, shared by "),Ce=r("code"),Zt=i("Trainer.evaluate()"),en=i(" and "),Ie=r("code"),tn=i("Trainer.predict()"),nn=i(`.
Works both with or without labels.`),rn=l(),X=r("div"),g(le.$$.fragment),an=l(),ze=r("p"),on=i("Main onnxruntime training entry point."),Qe=l(),D=r("h2"),B=r("a"),Ae=r("span"),g(me.$$.fragment),sn=l(),Me=r("span"),ln=i("ORTSeq2SeqTrainer"),Ze=l(),O=r("div"),g(de.$$.fragment),mn=l(),j=r("div"),g(ce.$$.fragment),dn=l(),pe=r("p"),cn=i(`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Ve=r("code"),pn=i("compute_metrics"),un=i(` argument).
You can also subclass and override this method to inject custom behavior.`),hn=l(),$=r("div"),g(ue.$$.fragment),gn=l(),he=r("p"),fn=i(`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Ue=r("code"),_n=i("evaluate()"),vn=i("."),bn=l(),g(Y.$$.fragment),yn=l(),ge=r("p"),Tn=i("Returns: "),Fe=r("em"),$n=i("NamedTuple"),xn=i(" A namedtuple with the following keys:"),wn=l(),S=r("ul"),P=r("li"),On=i("predictions ("),We=r("code"),kn=i("np.ndarray"),En=i("): The predictions on "),He=r("code"),Rn=i("test_dataset"),Nn=i("."),qn=l(),L=r("li"),Dn=i("label_ids ("),Xe=r("code"),Sn=i("np.ndarray"),Pn=i(", "),Be=r("em"),Ln=i("optional"),Cn=i("): The labels (if the dataset contained some)."),In=l(),C=r("li"),zn=i("metrics ("),je=r("code"),An=i("Dict[str, float]"),Mn=i(", "),Ye=r("em"),Vn=i("optional"),Un=i(`): The potential dictionary of metrics (if the dataset
contained labels).`),this.h()},l(n){const h=yr('[data-svelte="svelte-1phssyn"]',document.head);u=a(h,"META",{name:!0,content:!0}),h.forEach(t),I=m(n),T=a(n,"H1",{class:!0});var fe=o(T);x=a(fe,"A",{id:!0,class:!0,href:!0});var Wn=o(x);we=a(Wn,"SPAN",{});var Hn=o(we);f(G.$$.fragment,Hn),Hn.forEach(t),Wn.forEach(t),vt=m(fe),Oe=a(fe,"SPAN",{});var Xn=o(Oe);bt=s(Xn,"Trainer"),Xn.forEach(t),fe.forEach(t),Je=m(n),R=a(n,"H2",{class:!0});var tt=o(R);z=a(tt,"A",{id:!0,class:!0,href:!0});var Bn=o(z);ke=a(Bn,"SPAN",{});var jn=o(ke);f(J.$$.fragment,jn),jn.forEach(t),Bn.forEach(t),yt=m(tt),Ee=a(tt,"SPAN",{});var Yn=o(Ee);Tt=s(Yn,"ORTTrainer"),Yn.forEach(t),tt.forEach(t),Ke=m(n),c=a(n,"DIV",{class:!0});var p=o(c);f(K.$$.fragment,p),$t=m(p),A=a(p,"DIV",{class:!0});var nt=o(A);f(Q.$$.fragment,nt),xt=m(nt),Re=a(nt,"P",{});var Gn=o(Re);wt=s(Gn,`How the loss is computed by Trainer. By default, all models return the loss in the first element.
Subclass and override for custom behavior.`),Gn.forEach(t),nt.forEach(t),Ot=m(p),M=a(p,"DIV",{class:!0});var rt=o(M);f(Z.$$.fragment,rt),kt=m(rt),ee=a(rt,"P",{});var at=o(ee);Et=s(at,`Setup the optimizer.
We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
ORTTrainer\u2019s init through `),Ne=a(at,"CODE",{});var Jn=o(Ne);Rt=s(Jn,"optimizers"),Jn.forEach(t),Nt=s(at,", or subclass and override this method in a subclass."),at.forEach(t),rt.forEach(t),qt=m(p),V=a(p,"DIV",{class:!0});var ot=o(V);f(te.$$.fragment,ot),Dt=m(ot),ne=a(ot,"P",{});var it=o(ne);St=s(it,"Run evaluation within ONNX Runtime or PyTorch backend and returns metrics.(Overriden from "),qe=a(it,"CODE",{});var Kn=o(qe);Pt=s(Kn,"Trainer.evaluate()"),Kn.forEach(t),Lt=s(it,")"),it.forEach(t),ot.forEach(t),Ct=m(p),U=a(p,"DIV",{class:!0});var st=o(U);f(re.$$.fragment,st),It=m(st),N=a(st,"P",{});var _e=o(N);zt=s(_e,"Prediction/evaluation loop, shared by "),De=a(_e,"CODE",{});var Qn=o(De);At=s(Qn,"ORTTrainer.evaluate()"),Qn.forEach(t),Mt=s(_e," and "),Se=a(_e,"CODE",{});var Zn=o(Se);Vt=s(Zn,"ORTTrainer.predict()"),Zn.forEach(t),Ut=s(_e,`.
Works both with or without labels.`),_e.forEach(t),st.forEach(t),Ft=m(p),F=a(p,"DIV",{class:!0});var lt=o(F);f(ae.$$.fragment,lt),Wt=m(lt),Pe=a(lt,"P",{});var er=o(Pe);Ht=s(er,"Returns the optimizer class and optimizer parameters based on the ORT training arguments."),er.forEach(t),lt.forEach(t),Xt=m(p),W=a(p,"DIV",{class:!0});var mt=o(W);f(oe.$$.fragment,mt),Bt=m(mt),ie=a(mt,"P",{});var dt=o(ie);jt=s(dt,`Run prediction within ONNX Runtime or PyTorch backend and returns predictions and potential metrics.
(Overriden from `),Le=a(dt,"CODE",{});var tr=o(Le);Yt=s(tr,"Trainer.predict()"),tr.forEach(t),Gt=s(dt,")"),dt.forEach(t),mt.forEach(t),Jt=m(p),H=a(p,"DIV",{class:!0});var ct=o(H);f(se.$$.fragment,ct),Kt=m(ct),q=a(ct,"P",{});var ve=o(q);Qt=s(ve,"Prediction/evaluation loop, shared by "),Ce=a(ve,"CODE",{});var nr=o(Ce);Zt=s(nr,"Trainer.evaluate()"),nr.forEach(t),en=s(ve," and "),Ie=a(ve,"CODE",{});var rr=o(Ie);tn=s(rr,"Trainer.predict()"),rr.forEach(t),nn=s(ve,`.
Works both with or without labels.`),ve.forEach(t),ct.forEach(t),rn=m(p),X=a(p,"DIV",{class:!0});var pt=o(X);f(le.$$.fragment,pt),an=m(pt),ze=a(pt,"P",{});var ar=o(ze);on=s(ar,"Main onnxruntime training entry point."),ar.forEach(t),pt.forEach(t),p.forEach(t),Qe=m(n),D=a(n,"H2",{class:!0});var ut=o(D);B=a(ut,"A",{id:!0,class:!0,href:!0});var or=o(B);Ae=a(or,"SPAN",{});var ir=o(Ae);f(me.$$.fragment,ir),ir.forEach(t),or.forEach(t),sn=m(ut),Me=a(ut,"SPAN",{});var sr=o(Me);ln=s(sr,"ORTSeq2SeqTrainer"),sr.forEach(t),ut.forEach(t),Ze=m(n),O=a(n,"DIV",{class:!0});var be=o(O);f(de.$$.fragment,be),mn=m(be),j=a(be,"DIV",{class:!0});var ht=o(j);f(ce.$$.fragment,ht),dn=m(ht),pe=a(ht,"P",{});var gt=o(pe);cn=s(gt,`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Ve=a(gt,"CODE",{});var lr=o(Ve);pn=s(lr,"compute_metrics"),lr.forEach(t),un=s(gt,` argument).
You can also subclass and override this method to inject custom behavior.`),gt.forEach(t),ht.forEach(t),hn=m(be),$=a(be,"DIV",{class:!0});var E=o($);f(ue.$$.fragment,E),gn=m(E),he=a(E,"P",{});var ft=o(he);fn=s(ft,`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Ue=a(ft,"CODE",{});var mr=o(Ue);_n=s(mr,"evaluate()"),mr.forEach(t),vn=s(ft,"."),ft.forEach(t),bn=m(E),f(Y.$$.fragment,E),yn=m(E),ge=a(E,"P",{});var _t=o(ge);Tn=s(_t,"Returns: "),Fe=a(_t,"EM",{});var dr=o(Fe);$n=s(dr,"NamedTuple"),dr.forEach(t),xn=s(_t," A namedtuple with the following keys:"),_t.forEach(t),wn=m(E),S=a(E,"UL",{});var ye=o(S);P=a(ye,"LI",{});var Te=o(P);On=s(Te,"predictions ("),We=a(Te,"CODE",{});var cr=o(We);kn=s(cr,"np.ndarray"),cr.forEach(t),En=s(Te,"): The predictions on "),He=a(Te,"CODE",{});var pr=o(He);Rn=s(pr,"test_dataset"),pr.forEach(t),Nn=s(Te,"."),Te.forEach(t),qn=m(ye),L=a(ye,"LI",{});var $e=o(L);Dn=s($e,"label_ids ("),Xe=a($e,"CODE",{});var ur=o(Xe);Sn=s(ur,"np.ndarray"),ur.forEach(t),Pn=s($e,", "),Be=a($e,"EM",{});var hr=o(Be);Ln=s(hr,"optional"),hr.forEach(t),Cn=s($e,"): The labels (if the dataset contained some)."),$e.forEach(t),In=m(ye),C=a(ye,"LI",{});var xe=o(C);zn=s(xe,"metrics ("),je=a(xe,"CODE",{});var gr=o(je);An=s(gr,"Dict[str, float]"),gr.forEach(t),Mn=s(xe,", "),Ye=a(xe,"EM",{});var fr=o(Ye);Vn=s(fr,"optional"),fr.forEach(t),Un=s(xe,`): The potential dictionary of metrics (if the dataset
contained labels).`),xe.forEach(t),ye.forEach(t),E.forEach(t),be.forEach(t),this.h()},h(){d(u,"name","hf:doc:metadata"),d(u,"content",JSON.stringify(Or)),d(x,"id","trainer"),d(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(x,"href","#trainer"),d(T,"class","relative group"),d(z,"id","optimum.onnxruntime.ORTTrainer"),d(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z,"href","#optimum.onnxruntime.ORTTrainer"),d(R,"class","relative group"),d(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(c,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(B,"id","optimum.onnxruntime.ORTSeq2SeqTrainer"),d(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(B,"href","#optimum.onnxruntime.ORTSeq2SeqTrainer"),d(D,"class","relative group"),d(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(n,h){e(document.head,u),k(n,I,h),k(n,T,h),e(T,x),e(x,we),_(G,we,null),e(T,vt),e(T,Oe),e(Oe,bt),k(n,Je,h),k(n,R,h),e(R,z),e(z,ke),_(J,ke,null),e(R,yt),e(R,Ee),e(Ee,Tt),k(n,Ke,h),k(n,c,h),_(K,c,null),e(c,$t),e(c,A),_(Q,A,null),e(A,xt),e(A,Re),e(Re,wt),e(c,Ot),e(c,M),_(Z,M,null),e(M,kt),e(M,ee),e(ee,Et),e(ee,Ne),e(Ne,Rt),e(ee,Nt),e(c,qt),e(c,V),_(te,V,null),e(V,Dt),e(V,ne),e(ne,St),e(ne,qe),e(qe,Pt),e(ne,Lt),e(c,Ct),e(c,U),_(re,U,null),e(U,It),e(U,N),e(N,zt),e(N,De),e(De,At),e(N,Mt),e(N,Se),e(Se,Vt),e(N,Ut),e(c,Ft),e(c,F),_(ae,F,null),e(F,Wt),e(F,Pe),e(Pe,Ht),e(c,Xt),e(c,W),_(oe,W,null),e(W,Bt),e(W,ie),e(ie,jt),e(ie,Le),e(Le,Yt),e(ie,Gt),e(c,Jt),e(c,H),_(se,H,null),e(H,Kt),e(H,q),e(q,Qt),e(q,Ce),e(Ce,Zt),e(q,en),e(q,Ie),e(Ie,tn),e(q,nn),e(c,rn),e(c,X),_(le,X,null),e(X,an),e(X,ze),e(ze,on),k(n,Qe,h),k(n,D,h),e(D,B),e(B,Ae),_(me,Ae,null),e(D,sn),e(D,Me),e(Me,ln),k(n,Ze,h),k(n,O,h),_(de,O,null),e(O,mn),e(O,j),_(ce,j,null),e(j,dn),e(j,pe),e(pe,cn),e(pe,Ve),e(Ve,pn),e(pe,un),e(O,hn),e(O,$),_(ue,$,null),e($,gn),e($,he),e(he,fn),e(he,Ue),e(Ue,_n),e(he,vn),e($,bn),_(Y,$,null),e($,yn),e($,ge),e(ge,Tn),e(ge,Fe),e(Fe,$n),e(ge,xn),e($,wn),e($,S),e(S,P),e(P,On),e(P,We),e(We,kn),e(P,En),e(P,He),e(He,Rn),e(P,Nn),e(S,qn),e(S,L),e(L,Dn),e(L,Xe),e(Xe,Sn),e(L,Pn),e(L,Be),e(Be,Ln),e(L,Cn),e(S,In),e(S,C),e(C,zn),e(C,je),e(je,An),e(C,Mn),e(C,Ye),e(Ye,Vn),e(C,Un),et=!0},p(n,[h]){const fe={};h&2&&(fe.$$scope={dirty:h,ctx:n}),Y.$set(fe)},i(n){et||(v(G.$$.fragment,n),v(J.$$.fragment,n),v(K.$$.fragment,n),v(Q.$$.fragment,n),v(Z.$$.fragment,n),v(te.$$.fragment,n),v(re.$$.fragment,n),v(ae.$$.fragment,n),v(oe.$$.fragment,n),v(se.$$.fragment,n),v(le.$$.fragment,n),v(me.$$.fragment,n),v(de.$$.fragment,n),v(ce.$$.fragment,n),v(ue.$$.fragment,n),v(Y.$$.fragment,n),et=!0)},o(n){b(G.$$.fragment,n),b(J.$$.fragment,n),b(K.$$.fragment,n),b(Q.$$.fragment,n),b(Z.$$.fragment,n),b(te.$$.fragment,n),b(re.$$.fragment,n),b(ae.$$.fragment,n),b(oe.$$.fragment,n),b(se.$$.fragment,n),b(le.$$.fragment,n),b(me.$$.fragment,n),b(de.$$.fragment,n),b(ce.$$.fragment,n),b(ue.$$.fragment,n),b(Y.$$.fragment,n),et=!1},d(n){t(u),n&&t(I),n&&t(T),y(G),n&&t(Je),n&&t(R),y(J),n&&t(Ke),n&&t(c),y(K),y(Q),y(Z),y(te),y(re),y(ae),y(oe),y(se),y(le),n&&t(Qe),n&&t(D),y(me),n&&t(Ze),n&&t(O),y(de),y(ce),y(ue),y(Y)}}}const Or={local:"trainer",sections:[{local:"optimum.onnxruntime.ORTTrainer",title:"ORTTrainer"},{local:"optimum.onnxruntime.ORTSeq2SeqTrainer",title:"ORTSeq2SeqTrainer"}],title:"Trainer"};function kr(Ge){return Tr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Dr extends _r{constructor(u){super();vr(this,u,kr,wr,br,{})}}export{Dr as default,Or as metadata};
