import{S as ud,i as hd,s as fd,e as s,k as i,w as x,t as r,M as md,c as l,d as a,m as d,a as o,x as A,h as n,b as p,G as e,g as u,y as C,q as P,o as O,B as H,v as vd}from"../chunks/vendor-hf-doc-builder.js";import{T as gd}from"../chunks/Tip-hf-doc-builder.js";import{I as Ie}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as ma}from"../chunks/CodeBlock-hf-doc-builder.js";function _d(Za){let m,me,E,S,te,B,g,X,Ne,ve,_,Le,ae,se,ze,le,oe,Se,re,z,Be;return{c(){m=s("p"),me=r("The sole results from the "),E=s("code"),S=r("Evaluator"),te=r(" should probably not be trusted to compare model performances. Outside of the architecture, many parameters may influence performances:"),B=i(),g=s("ul"),X=s("li"),Ne=r("Hyperparameters used during training"),ve=i(),_=s("li"),Le=r("Training data (some models may have been trained on more data than others)"),ae=i(),se=s("li"),ze=r("Model size"),le=i(),oe=s("li"),Se=r("Training time"),re=i(),z=s("p"),Be=r("Moreover, the time performances should only be considered as a first proxy, as they include all the processing that goes on in the pipeline. This may include tokenizing, post-processing, that may be different depending on the model, and may not reflect the exact model time performances. Especially, depending on the usage of slow or fast tokenizers, the results may be signifiicantly impacted.")},l(f){m=l(f,"P",{});var h=o(m);me=n(h,"The sole results from the "),E=l(h,"CODE",{});var Y=o(E);S=n(Y,"Evaluator"),Y.forEach(a),te=n(h," should probably not be trusted to compare model performances. Outside of the architecture, many parameters may influence performances:"),h.forEach(a),B=d(f),g=l(f,"UL",{});var I=o(g);X=l(I,"LI",{});var lt=o(X);Ne=n(lt,"Hyperparameters used during training"),lt.forEach(a),ve=d(I),_=l(I,"LI",{});var ot=o(_);Le=n(ot,"Training data (some models may have been trained on more data than others)"),ot.forEach(a),ae=d(I),se=l(I,"LI",{});var ne=o(se);ze=n(ne,"Model size"),ne.forEach(a),le=d(I),oe=l(I,"LI",{});var rt=o(oe);Se=n(rt,"Training time"),rt.forEach(a),I.forEach(a),re=d(f),z=l(f,"P",{});var nt=o(z);Be=n(nt,"Moreover, the time performances should only be considered as a first proxy, as they include all the processing that goes on in the pipeline. This may include tokenizing, post-processing, that may be different depending on the model, and may not reflect the exact model time performances. Especially, depending on the usage of slow or fast tokenizers, the results may be signifiicantly impacted."),nt.forEach(a)},m(f,h){u(f,m,h),e(m,me),e(m,E),e(E,S),e(m,te),u(f,B,h),u(f,g,h),e(g,X),e(X,Ne),e(g,ve),e(g,_),e(_,Le),e(g,ae),e(g,se),e(se,ze),e(g,le),e(g,oe),e(oe,Se),u(f,re,h),u(f,z,h),e(z,Be)},d(f){f&&a(m),f&&a(B),f&&a(g),f&&a(re),f&&a(z)}}}function bd(Za){let m,me,E,S,te,B,g,X,Ne,ve,_,Le,ae,se,ze,le,oe,Se,re,z,Be,f,h,Y,I,lt,ot,ne,rt,nt,Ks,ge,va,Js,Vs,it,Qs,Ws,Xs,Z,ga,Ys,Zs,_a,el,tl,dt,al,sl,ll,_e,ba,ol,rl,pt,nl,il,es,ct,dl,ts,ie,be,Ea,Ue,pl,ka,cl,as,ut,ul,ss,Re,ls,ht,hl,os,Me,rs,ft,fl,ns,de,Ee,wa,Fe,ml,ya,vl,is,ke,gl,ja,_l,bl,ds,Ge,ps,pe,we,qa,Ke,El,$a,kl,cs,ye,wl,Ta,yl,jl,us,mt,ql,hs,Je,fs,ce,je,Da,Ve,$l,xa,Tl,ms,qe,Dl,Aa,xl,Al,vs,Qe,gs,vt,Cl,_s,$e,Ca,k,gt,Pl,Ol,_t,Hl,Il,bt,Nl,Ll,Et,zl,Sl,kt,Bl,Ul,wt,Rl,Ml,v,w,yt,Fl,Gl,jt,Kl,Jl,qt,Vl,Ql,$t,Wl,Xl,Tt,Yl,Zl,Dt,eo,to,y,xt,ao,so,At,lo,oo,Ct,ro,no,Pt,io,po,Ot,co,uo,Ht,ho,fo,j,It,mo,vo,Nt,go,_o,Lt,bo,Eo,zt,ko,wo,St,yo,jo,Bt,qo,$o,q,Ut,To,Do,Rt,xo,Ao,Mt,Co,Po,Ft,Oo,Ho,Gt,Io,No,Kt,Lo,zo,$,Jt,So,Bo,Vt,Uo,Ro,Qt,Mo,Fo,Wt,Go,Ko,Xt,Jo,Vo,Yt,Qo,Wo,T,Zt,Xo,Yo,ea,Zo,er,ta,tr,ar,aa,sr,lr,sa,or,rr,la,nr,ir,D,oa,dr,pr,ra,cr,ur,na,hr,fr,ia,mr,vr,da,gr,_r,pa,br,bs,Te,Es,ue,De,Pa,We,Er,Oa,kr,ks,ca,wr,ws,b,yr,Ha,jr,qr,Ia,$r,Tr,Na,Dr,xr,La,Ar,Cr,za,Pr,Or,ys,N,Hr,Sa,Ir,Nr,Ba,Lr,zr,Ua,Sr,Br,Xe,Ur,Rr,js,xe,Mr,Ra,Fr,Gr,qs,U,Kr,Ma,Jr,Vr,Fa,Qr,Wr,Ga,Xr,Yr,$s,he,Ae,Ka,Ye,Zr,Ja,en,Ts,Ce,tn,Ze,an,sn,Ds,fe,Pe,Va,et,ln,Qa,on,xs,ua,rn,As,ha,nn,Cs,tt,Ps;return B=new Ie({}),Ue=new Ie({}),Re=new ma({props:{code:`from datasets import load_dataset
from evaluate import evaluator

task_evaluator = evaluator("question-answering")

data = load_dataset("squad", split="validation[:100]")
eval_results = task_evaluator.compute(
    model_or_pipeline="distilbert-base-uncased-distilled-squad",
    data=data,
    metric="squad"
)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator

task_evaluator = evaluator(<span class="hljs-string">&quot;question-answering&quot;</span>)

data = load_dataset(<span class="hljs-string">&quot;squad&quot;</span>, split=<span class="hljs-string">&quot;validation[:100]&quot;</span>)
eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;distilbert-base-uncased-distilled-squad&quot;</span>,
    data=data,
    metric=<span class="hljs-string">&quot;squad&quot;</span>
)`}}),Me=new ma({props:{code:`{
    'exact_match': 84.0,
    'f1': 88.53333333333335,
    'latency_in_seconds': 0.009725173320002795,
    'samples_per_second': 102.82593092127149,
    'total_time_in_seconds': 0.9725173320002796
}`,highlighted:`{
    <span class="hljs-string">&#x27;exact_match&#x27;</span>: <span class="hljs-number">84.0</span>,
    <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">88.53333333333335</span>,
    <span class="hljs-string">&#x27;latency_in_seconds&#x27;</span>: <span class="hljs-number">0.009725173320002795</span>,
    <span class="hljs-string">&#x27;samples_per_second&#x27;</span>: <span class="hljs-number">102.82593092127149</span>,
    <span class="hljs-string">&#x27;total_time_in_seconds&#x27;</span>: <span class="hljs-number">0.9725173320002796</span>
}`}}),Fe=new Ie({}),Ge=new ma({props:{code:`
from datasets import load_dataset
from evaluate import evaluator
from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer

model = AutoModelForTokenClassification.from_pretrained("/path/to/model/folder/")
tokenizer = AutoTokenizer.from_pretrained("/path/to/model/folder/")

pipe = pipeline(task="token-classification", model=model, tokenizer=tokenizer)

data = load_dataset("imdb", split="test").shuffle(seed=42).select(range(1000))

task_evaluator = evaluator("text-classification")
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric="seqeval",
    label_mapping=pipe.model.config.label2id
)`,highlighted:`
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline, AutoModelForTokenClassification, AutoTokenizer

model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;/path/to/model/folder/&quot;</span>)
tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;/path/to/model/folder/&quot;</span>)

pipe = pipeline(task=<span class="hljs-string">&quot;token-classification&quot;</span>, model=model, tokenizer=tokenizer)

data = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>, split=<span class="hljs-string">&quot;test&quot;</span>).shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))

task_evaluator = evaluator(<span class="hljs-string">&quot;text-classification&quot;</span>)
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric=<span class="hljs-string">&quot;seqeval&quot;</span>,
    label_mapping=pipe.model.config.label2id
)`}}),Ke=new Ie({}),Je=new ma({props:{code:`# TODO EXTEND
from datasets import load_dataset
from evaluate import evaluator

task_evaluator = evaluator("text-classification")

data = load_dataset("imdb", split="test").shuffle(seed=42).select(range(1000))
eval_results = task_evaluator.compute(
    model_or_pipeline="lvwerra/distilbert-imdb",
    data=data,
    metric="accuracy",
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)`,highlighted:`<span class="hljs-comment"># TODO EXTEND</span>
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator

task_evaluator = evaluator(<span class="hljs-string">&quot;text-classification&quot;</span>)

data = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>, split=<span class="hljs-string">&quot;test&quot;</span>).shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>,
    data=data,
    metric=<span class="hljs-string">&quot;accuracy&quot;</span>,
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)`}}),Ve=new Ie({}),Qe=new ma({props:{code:`import pandas as pd
import torch
import traceback
from tabulate import tabulate

from datasets import load_dataset
from evaluate import evaluator
from tqdm import tqdm
from transformers import pipeline

models = [
    "xlm-roberta-large-finetuned-conll03-english",
    "dbmdz/bert-large-cased-finetuned-conll03-english",
    "elastic/distilbert-base-uncased-finetuned-conll03-english",
    "dbmdz/electra-large-discriminator-finetuned-conll03-english",
    "gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner",
    "philschmid/distilroberta-base-ner-conll2003",
    "Jorgeutd/albert-base-v2-finetuned-ner",
]
models.sort()

device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")

data = load_dataset("conll2003", split="validation")

num_samples = 1000
if num_samples != "all":
    data = data.shuffle(seed=42).select(range(num_samples))

task_evaluator = evaluator("token-classification")

full_results = []
evaluated_models = []
for model in tqdm(models):
    try:
        print(model)
        pipe = pipeline(task="token-classification", model=model, device=device)

        eval_results = task_evaluator.compute(
            model_or_pipeline=pipe, data=data, metric="seqeval", join_by=" "
        )

        full_results.append(eval_results)
        evaluated_models.append(model)
    except Exception as e:
        print(model, e)
        print(traceback.format_exc())

df = pd.DataFrame(full_results, index=evaluated_models)
df_filtered = df[["overall_f1", "overall_accuracy", "total_time_in_seconds", "samples_per_second", "latency_in_seconds"]]

print(df_filtered)
print("----")
print(tabulate(df_filtered, tablefmt="pipe", headers="keys", floatfmt=".3f"))`,highlighted:`<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> traceback
<span class="hljs-keyword">from</span> tabulate <span class="hljs-keyword">import</span> tabulate

<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator
<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

models = [
    <span class="hljs-string">&quot;xlm-roberta-large-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;elastic/distilbert-base-uncased-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;dbmdz/electra-large-discriminator-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner&quot;</span>,
    <span class="hljs-string">&quot;philschmid/distilroberta-base-ner-conll2003&quot;</span>,
    <span class="hljs-string">&quot;Jorgeutd/albert-base-v2-finetuned-ner&quot;</span>,
]
models.sort()

device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)

data = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>)

num_samples = <span class="hljs-number">1000</span>
<span class="hljs-keyword">if</span> num_samples != <span class="hljs-string">&quot;all&quot;</span>:
    data = data.shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(num_samples))

task_evaluator = evaluator(<span class="hljs-string">&quot;token-classification&quot;</span>)

full_results = []
evaluated_models = []
<span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> tqdm(models):
    <span class="hljs-keyword">try</span>:
        <span class="hljs-built_in">print</span>(model)
        pipe = pipeline(task=<span class="hljs-string">&quot;token-classification&quot;</span>, model=model, device=device)

        eval_results = task_evaluator.compute(
            model_or_pipeline=pipe, data=data, metric=<span class="hljs-string">&quot;seqeval&quot;</span>, join_by=<span class="hljs-string">&quot; &quot;</span>
        )

        full_results.append(eval_results)
        evaluated_models.append(model)
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        <span class="hljs-built_in">print</span>(model, e)
        <span class="hljs-built_in">print</span>(traceback.format_exc())

df = pd.DataFrame(full_results, index=evaluated_models)
df_filtered = df[[<span class="hljs-string">&quot;overall_f1&quot;</span>, <span class="hljs-string">&quot;overall_accuracy&quot;</span>, <span class="hljs-string">&quot;total_time_in_seconds&quot;</span>, <span class="hljs-string">&quot;samples_per_second&quot;</span>, <span class="hljs-string">&quot;latency_in_seconds&quot;</span>]]

<span class="hljs-built_in">print</span>(df_filtered)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;----&quot;</span>)
<span class="hljs-built_in">print</span>(tabulate(df_filtered, tablefmt=<span class="hljs-string">&quot;pipe&quot;</span>, headers=<span class="hljs-string">&quot;keys&quot;</span>, floatfmt=<span class="hljs-string">&quot;.3f&quot;</span>))`}}),Te=new gd({props:{warning:!0,$$slots:{default:[_d]},$$scope:{ctx:Za}}}),We=new Ie({}),Ye=new Ie({}),et=new Ie({}),tt=new ma({props:{code:`from datasets import load_dataset
from evaluate import evaluator
from transformers import pipeline

data = load_dataset("imagenet-1k", split="validation", use_auth_token=True)
data = data.shuffle(seed=42).select(range(500))

pipe = pipeline(
    task="image-classification",
    model="facebook/deit-small-distilled-patch16-224"
)

task_evaluator = evaluator("image-classification")
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric="accuracy",
    label_mapping=pipe.model.config.label2id
)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

data = load_dataset(<span class="hljs-string">&quot;imagenet-1k&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>, use_auth_token=<span class="hljs-literal">True</span>)
data = data.shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">500</span>))

pipe = pipeline(
    task=<span class="hljs-string">&quot;image-classification&quot;</span>,
    model=<span class="hljs-string">&quot;facebook/deit-small-distilled-patch16-224&quot;</span>
)

task_evaluator = evaluator(<span class="hljs-string">&quot;image-classification&quot;</span>)
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric=<span class="hljs-string">&quot;accuracy&quot;</span>,
    label_mapping=pipe.model.config.label2id
)`}}),{c(){m=s("meta"),me=i(),E=s("h1"),S=s("a"),te=s("span"),x(B.$$.fragment),g=i(),X=s("span"),Ne=r("Using the evaluator with transformers models"),ve=i(),_=s("p"),Le=r("The "),ae=s("code"),se=r("Evaluator"),ze=r(" abstraction allows to evaluate models wrapped in a pipeline, responsible for handling all preprocessing and post-processing. Out-of-the-box, "),le=s("code"),oe=r("Evaluator"),Se=r(" supports transformers pipelines for the supported tasks, but custom pipelines can be passed, as showcased in [LINK]."),re=i(),z=s("p"),Be=r("Currently supported tasks are:"),f=i(),h=s("ul"),Y=s("li"),I=s("code"),lt=r('"image-classification"'),ot=r(": will use the "),ne=s("a"),rt=r("ImageClassificationEvaluator"),nt=r("."),Ks=i(),ge=s("li"),va=s("code"),Js=r('"question-answering"'),Vs=r(": will use the "),it=s("a"),Qs=r("QuestionAnsweringEvaluator"),Ws=r("."),Xs=i(),Z=s("li"),ga=s("code"),Ys=r('"text-classification"'),Zs=r(" (alias "),_a=s("code"),el=r('"sentiment-analysis"'),tl=r(" available): will use the "),dt=s("a"),al=r("TextClassificationEvaluator"),sl=r("."),ll=i(),_e=s("li"),ba=s("code"),ol=r('"token-classification"'),rl=r(": will use the "),pt=s("a"),nl=r("TokenClassificationEvaluator"),il=r("."),es=i(),ct=s("p"),dl=r("Each task has its own set of requirements for the dataset format and pipeline output, make sure to check them out for your custom use case!"),ts=i(),ie=s("h2"),be=s("a"),Ea=s("span"),x(Ue.$$.fragment),pl=i(),ka=s("span"),cl=r("Using a model from the Hub"),as=i(),ut=s("p"),ul=r("Models from the Hugging Face Hub can be loaded out-of-the-box just given the namespace of the model on the Hub."),ss=i(),x(Re.$$.fragment),ls=i(),ht=s("p"),hl=r("Results are as follow:"),os=i(),x(Me.$$.fragment),rs=i(),ft=s("p"),fl=r("Note that evaluation results include both the requested metric, and information about the time it took to obtain predictions through the pipeline. These additional time metrics give an useful first information on model speed as inference."),ns=i(),de=s("h2"),Ee=s("a"),wa=s("span"),x(Fe.$$.fragment),ml=i(),ya=s("span"),vl=r("Using a local model"),is=i(),ke=s("p"),gl=r("Local models respecting the format from "),ja=s("code"),_l=r("save_pretrained()"),bl=r(" (LINK) can be used as well! In this case, the model needs to be loaded into a pipeline first:"),ds=i(),x(Ge.$$.fragment),ps=i(),pe=s("h2"),we=s("a"),qa=s("span"),x(Ke.$$.fragment),El=i(),$a=s("span"),kl=r("Combining several metrics"),cs=i(),ye=s("p"),wl=r("The evaluator can perform evaluation on several metrics at once using "),Ta=s("code"),yl=r("combine"),jl=r("."),us=i(),mt=s("p"),ql=r("TODO use e.g. text-classification here?"),hs=i(),x(Je.$$.fragment),fs=i(),ce=s("h2"),je=s("a"),Da=s("span"),x(Ve.$$.fragment),$l=i(),xa=s("span"),Tl=r("Benchmarking several models"),ms=i(),qe=s("p"),Dl=r("Here is an example where several models can be compared thanks to the "),Aa=s("code"),xl=r("Evaluator"),Al=r(" in only a few lines of code, abstracting away the preprocessing, inference, postprocessing, metric computation:"),vs=i(),x(Qe.$$.fragment),gs=i(),vt=s("p"),Cl=r("Results:"),_s=i(),$e=s("table"),Ca=s("thead"),k=s("tr"),gt=s("th"),Pl=r("model"),Ol=i(),_t=s("th"),Hl=r("overall_f1"),Il=i(),bt=s("th"),Nl=r("overall_accuracy"),Ll=i(),Et=s("th"),zl=r("total_time_in_seconds"),Sl=i(),kt=s("th"),Bl=r("samples_per_second"),Ul=i(),wt=s("th"),Rl=r("latency_in_seconds"),Ml=i(),v=s("tbody"),w=s("tr"),yt=s("td"),Fl=r("Jorgeutd/albert-base-v2-finetuned-ner"),Gl=i(),jt=s("td"),Kl=r("0.941"),Jl=i(),qt=s("td"),Vl=r("0.989"),Ql=i(),$t=s("td"),Wl=r("4.515"),Xl=i(),Tt=s("td"),Yl=r("221.468"),Zl=i(),Dt=s("td"),eo=r("0.005"),to=i(),y=s("tr"),xt=s("td"),ao=r("dbmdz/bert-large-cased-finetuned-conll03-english"),so=i(),At=s("td"),lo=r("0.962"),oo=i(),Ct=s("td"),ro=r("0.881"),no=i(),Pt=s("td"),io=r("11.648"),po=i(),Ot=s("td"),co=r("85.850"),uo=i(),Ht=s("td"),ho=r("0.012"),fo=i(),j=s("tr"),It=s("td"),mo=r("dbmdz/electra-large-discriminator-finetuned-conll03-english"),vo=i(),Nt=s("td"),go=r("0.965"),_o=i(),Lt=s("td"),bo=r("0.881"),Eo=i(),zt=s("td"),ko=r("11.456"),wo=i(),St=s("td"),yo=r("87.292"),jo=i(),Bt=s("td"),qo=r("0.011"),$o=i(),q=s("tr"),Ut=s("td"),To=r("elastic/distilbert-base-uncased-finetuned-conll03-english"),Do=i(),Rt=s("td"),xo=r("0.940"),Ao=i(),Mt=s("td"),Co=r("0.989"),Po=i(),Ft=s("td"),Oo=r("2.318"),Ho=i(),Gt=s("td"),Io=r("431.378"),No=i(),Kt=s("td"),Lo=r("0.002"),zo=i(),$=s("tr"),Jt=s("td"),So=r("gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner"),Bo=i(),Vt=s("td"),Uo=r("0.947"),Ro=i(),Qt=s("td"),Mo=r("0.991"),Fo=i(),Wt=s("td"),Go=r("2.376"),Ko=i(),Xt=s("td"),Jo=r("420.873"),Vo=i(),Yt=s("td"),Qo=r("0.002"),Wo=i(),T=s("tr"),Zt=s("td"),Xo=r("philschmid/distilroberta-base-ner-conll2003"),Yo=i(),ea=s("td"),Zo=r("0.961"),er=i(),ta=s("td"),tr=r("0.994"),ar=i(),aa=s("td"),sr=r("2.436"),lr=i(),sa=s("td"),or=r("410.579"),rr=i(),la=s("td"),nr=r("0.002"),ir=i(),D=s("tr"),oa=s("td"),dr=r("xlm-roberta-large-finetuned-conll03-english"),pr=i(),ra=s("td"),cr=r("0.969"),ur=i(),na=s("td"),hr=r("0.882"),fr=i(),ia=s("td"),mr=r("11.996"),vr=i(),da=s("td"),gr=r("83.359"),_r=i(),pa=s("td"),br=r("0.012"),bs=i(),x(Te.$$.fragment),Es=i(),ue=s("h2"),De=s("a"),Pa=s("span"),x(We.$$.fragment),Er=i(),Oa=s("span"),kr=r("Evaluator task-specific arguments"),ks=i(),ca=s("p"),wr=r("Depending on the task, some task-specific arguments must be set. It is therefore best to check LINK for each task."),ws=i(),b=s("p"),yr=r("As an example, pipelines for classification tasks may ouput a label as a string, as in sentiment analysis between "),Ha=s("code"),jr=r("negative"),qr=r(", "),Ia=s("code"),$r=r("neutral"),Tr=r(" and "),Na=s("code"),Dr=r("positive"),xr=r(" sentences. To map these predictions to an id, we need an argument "),La=s("code"),Ar=r("label_mapping"),Cr=r(" mapping strings to numbers. In the case of transformers models, you will typically want to pass "),za=s("code"),Pr=r("pipe.model.config.label2id"),Or=r("."),ys=i(),N=s("p"),Hr=r("However, beware that some models on the Hub have a label mapping that do not match with the dataset mapping! This may be that there is even no "),Sa=s("code"),Ir=r("label2id"),Nr=r(", or that the labels are uninformative ("),Ba=s("code"),Lr=r("LABEL_0"),zr=r(", "),Ua=s("code"),Sr=r("LABEL_1"),Br=r(", etc.), as for "),Xe=s("a"),Ur=r("this model"),Rr=r("."),js=i(),xe=s("p"),Mr=r("In such case, it is best to inspect the dataset features in "),Ra=s("code"),Fr=r("data.features"),Gr=r(", and, if possible, to use (Dataset.align_labels_with_mapping)[https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping] to align the dataset labels with the model\u2019s outputs."),qs=i(),U=s("p"),Kr=r("An other example is for "),Ma=s("code"),Jr=r("token-classification"),Vr=r(", as in named entity recoginition (NER) or part of speech tagging (POS), where the common dataset structure assumes a list of words to be tagged as an input. Pipelines assume a single string as an input, and the list of word needs to be joined into a single string, using the "),Fa=s("code"),Qr=r("join_by"),Wr=r(" parameter, defaulting to "),Ga=s("code"),Xr=r('" "'),Yr=r(" for space-separated languages."),$s=i(),he=s("h2"),Ae=s("a"),Ka=s("span"),x(Ye.$$.fragment),Zr=i(),Ja=s("span"),en=r("Confidence intervals"),Ts=i(),Ce=s("p"),tn=r("TODO "),Ze=s("a"),an=r("https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html"),sn=r("."),Ds=i(),fe=s("h2"),Pe=s("a"),Va=s("span"),x(et.$$.fragment),ln=i(),Qa=s("span"),on=r("Handling large datasets"),xs=i(),ua=s("p"),rn=r("The evaluator can be used on large datasets! Below, an example shows how to use it on ImageNet-1k for image classification. Beware that this example will require to download ~150 GB."),As=i(),ha=s("p"),nn=r("Without specifying a device, the default will be the first GPU if available, else CPU."),Cs=i(),x(tt.$$.fragment),this.h()},l(t){const c=md('[data-svelte="svelte-1phssyn"]',document.head);m=l(c,"META",{name:!0,content:!0}),c.forEach(a),me=d(t),E=l(t,"H1",{class:!0});var at=o(E);S=l(at,"A",{id:!0,class:!0,href:!0});var dn=o(S);te=l(dn,"SPAN",{});var pn=o(te);A(B.$$.fragment,pn),pn.forEach(a),dn.forEach(a),g=d(at),X=l(at,"SPAN",{});var cn=o(X);Ne=n(cn,"Using the evaluator with transformers models"),cn.forEach(a),at.forEach(a),ve=d(t),_=l(t,"P",{});var fa=o(_);Le=n(fa,"The "),ae=l(fa,"CODE",{});var un=o(ae);se=n(un,"Evaluator"),un.forEach(a),ze=n(fa," abstraction allows to evaluate models wrapped in a pipeline, responsible for handling all preprocessing and post-processing. Out-of-the-box, "),le=l(fa,"CODE",{});var hn=o(le);oe=n(hn,"Evaluator"),hn.forEach(a),Se=n(fa," supports transformers pipelines for the supported tasks, but custom pipelines can be passed, as showcased in [LINK]."),fa.forEach(a),re=d(t),z=l(t,"P",{});var fn=o(z);Be=n(fn,"Currently supported tasks are:"),fn.forEach(a),f=d(t),h=l(t,"UL",{});var Oe=o(h);Y=l(Oe,"LI",{});var Wa=o(Y);I=l(Wa,"CODE",{});var mn=o(I);lt=n(mn,'"image-classification"'),mn.forEach(a),ot=n(Wa,": will use the "),ne=l(Wa,"A",{href:!0});var vn=o(ne);rt=n(vn,"ImageClassificationEvaluator"),vn.forEach(a),nt=n(Wa,"."),Wa.forEach(a),Ks=d(Oe),ge=l(Oe,"LI",{});var Xa=o(ge);va=l(Xa,"CODE",{});var gn=o(va);Js=n(gn,'"question-answering"'),gn.forEach(a),Vs=n(Xa,": will use the "),it=l(Xa,"A",{href:!0});var _n=o(it);Qs=n(_n,"QuestionAnsweringEvaluator"),_n.forEach(a),Ws=n(Xa,"."),Xa.forEach(a),Xs=d(Oe),Z=l(Oe,"LI",{});var st=o(Z);ga=l(st,"CODE",{});var bn=o(ga);Ys=n(bn,'"text-classification"'),bn.forEach(a),Zs=n(st," (alias "),_a=l(st,"CODE",{});var En=o(_a);el=n(En,'"sentiment-analysis"'),En.forEach(a),tl=n(st," available): will use the "),dt=l(st,"A",{href:!0});var kn=o(dt);al=n(kn,"TextClassificationEvaluator"),kn.forEach(a),sl=n(st,"."),st.forEach(a),ll=d(Oe),_e=l(Oe,"LI",{});var Ya=o(_e);ba=l(Ya,"CODE",{});var wn=o(ba);ol=n(wn,'"token-classification"'),wn.forEach(a),rl=n(Ya,": will use the "),pt=l(Ya,"A",{href:!0});var yn=o(pt);nl=n(yn,"TokenClassificationEvaluator"),yn.forEach(a),il=n(Ya,"."),Ya.forEach(a),Oe.forEach(a),es=d(t),ct=l(t,"P",{});var jn=o(ct);dl=n(jn,"Each task has its own set of requirements for the dataset format and pipeline output, make sure to check them out for your custom use case!"),jn.forEach(a),ts=d(t),ie=l(t,"H2",{class:!0});var Os=o(ie);be=l(Os,"A",{id:!0,class:!0,href:!0});var qn=o(be);Ea=l(qn,"SPAN",{});var $n=o(Ea);A(Ue.$$.fragment,$n),$n.forEach(a),qn.forEach(a),pl=d(Os),ka=l(Os,"SPAN",{});var Tn=o(ka);cl=n(Tn,"Using a model from the Hub"),Tn.forEach(a),Os.forEach(a),as=d(t),ut=l(t,"P",{});var Dn=o(ut);ul=n(Dn,"Models from the Hugging Face Hub can be loaded out-of-the-box just given the namespace of the model on the Hub."),Dn.forEach(a),ss=d(t),A(Re.$$.fragment,t),ls=d(t),ht=l(t,"P",{});var xn=o(ht);hl=n(xn,"Results are as follow:"),xn.forEach(a),os=d(t),A(Me.$$.fragment,t),rs=d(t),ft=l(t,"P",{});var An=o(ft);fl=n(An,"Note that evaluation results include both the requested metric, and information about the time it took to obtain predictions through the pipeline. These additional time metrics give an useful first information on model speed as inference."),An.forEach(a),ns=d(t),de=l(t,"H2",{class:!0});var Hs=o(de);Ee=l(Hs,"A",{id:!0,class:!0,href:!0});var Cn=o(Ee);wa=l(Cn,"SPAN",{});var Pn=o(wa);A(Fe.$$.fragment,Pn),Pn.forEach(a),Cn.forEach(a),ml=d(Hs),ya=l(Hs,"SPAN",{});var On=o(ya);vl=n(On,"Using a local model"),On.forEach(a),Hs.forEach(a),is=d(t),ke=l(t,"P",{});var Is=o(ke);gl=n(Is,"Local models respecting the format from "),ja=l(Is,"CODE",{});var Hn=o(ja);_l=n(Hn,"save_pretrained()"),Hn.forEach(a),bl=n(Is," (LINK) can be used as well! In this case, the model needs to be loaded into a pipeline first:"),Is.forEach(a),ds=d(t),A(Ge.$$.fragment,t),ps=d(t),pe=l(t,"H2",{class:!0});var Ns=o(pe);we=l(Ns,"A",{id:!0,class:!0,href:!0});var In=o(we);qa=l(In,"SPAN",{});var Nn=o(qa);A(Ke.$$.fragment,Nn),Nn.forEach(a),In.forEach(a),El=d(Ns),$a=l(Ns,"SPAN",{});var Ln=o($a);kl=n(Ln,"Combining several metrics"),Ln.forEach(a),Ns.forEach(a),cs=d(t),ye=l(t,"P",{});var Ls=o(ye);wl=n(Ls,"The evaluator can perform evaluation on several metrics at once using "),Ta=l(Ls,"CODE",{});var zn=o(Ta);yl=n(zn,"combine"),zn.forEach(a),jl=n(Ls,"."),Ls.forEach(a),us=d(t),mt=l(t,"P",{});var Sn=o(mt);ql=n(Sn,"TODO use e.g. text-classification here?"),Sn.forEach(a),hs=d(t),A(Je.$$.fragment,t),fs=d(t),ce=l(t,"H2",{class:!0});var zs=o(ce);je=l(zs,"A",{id:!0,class:!0,href:!0});var Bn=o(je);Da=l(Bn,"SPAN",{});var Un=o(Da);A(Ve.$$.fragment,Un),Un.forEach(a),Bn.forEach(a),$l=d(zs),xa=l(zs,"SPAN",{});var Rn=o(xa);Tl=n(Rn,"Benchmarking several models"),Rn.forEach(a),zs.forEach(a),ms=d(t),qe=l(t,"P",{});var Ss=o(qe);Dl=n(Ss,"Here is an example where several models can be compared thanks to the "),Aa=l(Ss,"CODE",{});var Mn=o(Aa);xl=n(Mn,"Evaluator"),Mn.forEach(a),Al=n(Ss," in only a few lines of code, abstracting away the preprocessing, inference, postprocessing, metric computation:"),Ss.forEach(a),vs=d(t),A(Qe.$$.fragment,t),gs=d(t),vt=l(t,"P",{});var Fn=o(vt);Cl=n(Fn,"Results:"),Fn.forEach(a),_s=d(t),$e=l(t,"TABLE",{});var Bs=o($e);Ca=l(Bs,"THEAD",{});var Gn=o(Ca);k=l(Gn,"TR",{});var R=o(k);gt=l(R,"TH",{align:!0});var Kn=o(gt);Pl=n(Kn,"model"),Kn.forEach(a),Ol=d(R),_t=l(R,"TH",{align:!0});var Jn=o(_t);Hl=n(Jn,"overall_f1"),Jn.forEach(a),Il=d(R),bt=l(R,"TH",{align:!0});var Vn=o(bt);Nl=n(Vn,"overall_accuracy"),Vn.forEach(a),Ll=d(R),Et=l(R,"TH",{align:!0});var Qn=o(Et);zl=n(Qn,"total_time_in_seconds"),Qn.forEach(a),Sl=d(R),kt=l(R,"TH",{align:!0});var Wn=o(kt);Bl=n(Wn,"samples_per_second"),Wn.forEach(a),Ul=d(R),wt=l(R,"TH",{align:!0});var Xn=o(wt);Rl=n(Xn,"latency_in_seconds"),Xn.forEach(a),R.forEach(a),Gn.forEach(a),Ml=d(Bs),v=l(Bs,"TBODY",{});var L=o(v);w=l(L,"TR",{});var M=o(w);yt=l(M,"TD",{align:!0});var Yn=o(yt);Fl=n(Yn,"Jorgeutd/albert-base-v2-finetuned-ner"),Yn.forEach(a),Gl=d(M),jt=l(M,"TD",{align:!0});var Zn=o(jt);Kl=n(Zn,"0.941"),Zn.forEach(a),Jl=d(M),qt=l(M,"TD",{align:!0});var ei=o(qt);Vl=n(ei,"0.989"),ei.forEach(a),Ql=d(M),$t=l(M,"TD",{align:!0});var ti=o($t);Wl=n(ti,"4.515"),ti.forEach(a),Xl=d(M),Tt=l(M,"TD",{align:!0});var ai=o(Tt);Yl=n(ai,"221.468"),ai.forEach(a),Zl=d(M),Dt=l(M,"TD",{align:!0});var si=o(Dt);eo=n(si,"0.005"),si.forEach(a),M.forEach(a),to=d(L),y=l(L,"TR",{});var F=o(y);xt=l(F,"TD",{align:!0});var li=o(xt);ao=n(li,"dbmdz/bert-large-cased-finetuned-conll03-english"),li.forEach(a),so=d(F),At=l(F,"TD",{align:!0});var oi=o(At);lo=n(oi,"0.962"),oi.forEach(a),oo=d(F),Ct=l(F,"TD",{align:!0});var ri=o(Ct);ro=n(ri,"0.881"),ri.forEach(a),no=d(F),Pt=l(F,"TD",{align:!0});var ni=o(Pt);io=n(ni,"11.648"),ni.forEach(a),po=d(F),Ot=l(F,"TD",{align:!0});var ii=o(Ot);co=n(ii,"85.850"),ii.forEach(a),uo=d(F),Ht=l(F,"TD",{align:!0});var di=o(Ht);ho=n(di,"0.012"),di.forEach(a),F.forEach(a),fo=d(L),j=l(L,"TR",{});var G=o(j);It=l(G,"TD",{align:!0});var pi=o(It);mo=n(pi,"dbmdz/electra-large-discriminator-finetuned-conll03-english"),pi.forEach(a),vo=d(G),Nt=l(G,"TD",{align:!0});var ci=o(Nt);go=n(ci,"0.965"),ci.forEach(a),_o=d(G),Lt=l(G,"TD",{align:!0});var ui=o(Lt);bo=n(ui,"0.881"),ui.forEach(a),Eo=d(G),zt=l(G,"TD",{align:!0});var hi=o(zt);ko=n(hi,"11.456"),hi.forEach(a),wo=d(G),St=l(G,"TD",{align:!0});var fi=o(St);yo=n(fi,"87.292"),fi.forEach(a),jo=d(G),Bt=l(G,"TD",{align:!0});var mi=o(Bt);qo=n(mi,"0.011"),mi.forEach(a),G.forEach(a),$o=d(L),q=l(L,"TR",{});var K=o(q);Ut=l(K,"TD",{align:!0});var vi=o(Ut);To=n(vi,"elastic/distilbert-base-uncased-finetuned-conll03-english"),vi.forEach(a),Do=d(K),Rt=l(K,"TD",{align:!0});var gi=o(Rt);xo=n(gi,"0.940"),gi.forEach(a),Ao=d(K),Mt=l(K,"TD",{align:!0});var _i=o(Mt);Co=n(_i,"0.989"),_i.forEach(a),Po=d(K),Ft=l(K,"TD",{align:!0});var bi=o(Ft);Oo=n(bi,"2.318"),bi.forEach(a),Ho=d(K),Gt=l(K,"TD",{align:!0});var Ei=o(Gt);Io=n(Ei,"431.378"),Ei.forEach(a),No=d(K),Kt=l(K,"TD",{align:!0});var ki=o(Kt);Lo=n(ki,"0.002"),ki.forEach(a),K.forEach(a),zo=d(L),$=l(L,"TR",{});var J=o($);Jt=l(J,"TD",{align:!0});var wi=o(Jt);So=n(wi,"gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner"),wi.forEach(a),Bo=d(J),Vt=l(J,"TD",{align:!0});var yi=o(Vt);Uo=n(yi,"0.947"),yi.forEach(a),Ro=d(J),Qt=l(J,"TD",{align:!0});var ji=o(Qt);Mo=n(ji,"0.991"),ji.forEach(a),Fo=d(J),Wt=l(J,"TD",{align:!0});var qi=o(Wt);Go=n(qi,"2.376"),qi.forEach(a),Ko=d(J),Xt=l(J,"TD",{align:!0});var $i=o(Xt);Jo=n($i,"420.873"),$i.forEach(a),Vo=d(J),Yt=l(J,"TD",{align:!0});var Ti=o(Yt);Qo=n(Ti,"0.002"),Ti.forEach(a),J.forEach(a),Wo=d(L),T=l(L,"TR",{});var V=o(T);Zt=l(V,"TD",{align:!0});var Di=o(Zt);Xo=n(Di,"philschmid/distilroberta-base-ner-conll2003"),Di.forEach(a),Yo=d(V),ea=l(V,"TD",{align:!0});var xi=o(ea);Zo=n(xi,"0.961"),xi.forEach(a),er=d(V),ta=l(V,"TD",{align:!0});var Ai=o(ta);tr=n(Ai,"0.994"),Ai.forEach(a),ar=d(V),aa=l(V,"TD",{align:!0});var Ci=o(aa);sr=n(Ci,"2.436"),Ci.forEach(a),lr=d(V),sa=l(V,"TD",{align:!0});var Pi=o(sa);or=n(Pi,"410.579"),Pi.forEach(a),rr=d(V),la=l(V,"TD",{align:!0});var Oi=o(la);nr=n(Oi,"0.002"),Oi.forEach(a),V.forEach(a),ir=d(L),D=l(L,"TR",{});var Q=o(D);oa=l(Q,"TD",{align:!0});var Hi=o(oa);dr=n(Hi,"xlm-roberta-large-finetuned-conll03-english"),Hi.forEach(a),pr=d(Q),ra=l(Q,"TD",{align:!0});var Ii=o(ra);cr=n(Ii,"0.969"),Ii.forEach(a),ur=d(Q),na=l(Q,"TD",{align:!0});var Ni=o(na);hr=n(Ni,"0.882"),Ni.forEach(a),fr=d(Q),ia=l(Q,"TD",{align:!0});var Li=o(ia);mr=n(Li,"11.996"),Li.forEach(a),vr=d(Q),da=l(Q,"TD",{align:!0});var zi=o(da);gr=n(zi,"83.359"),zi.forEach(a),_r=d(Q),pa=l(Q,"TD",{align:!0});var Si=o(pa);br=n(Si,"0.012"),Si.forEach(a),Q.forEach(a),L.forEach(a),Bs.forEach(a),bs=d(t),A(Te.$$.fragment,t),Es=d(t),ue=l(t,"H2",{class:!0});var Us=o(ue);De=l(Us,"A",{id:!0,class:!0,href:!0});var Bi=o(De);Pa=l(Bi,"SPAN",{});var Ui=o(Pa);A(We.$$.fragment,Ui),Ui.forEach(a),Bi.forEach(a),Er=d(Us),Oa=l(Us,"SPAN",{});var Ri=o(Oa);kr=n(Ri,"Evaluator task-specific arguments"),Ri.forEach(a),Us.forEach(a),ks=d(t),ca=l(t,"P",{});var Mi=o(ca);wr=n(Mi,"Depending on the task, some task-specific arguments must be set. It is therefore best to check LINK for each task."),Mi.forEach(a),ws=d(t),b=l(t,"P",{});var W=o(b);yr=n(W,"As an example, pipelines for classification tasks may ouput a label as a string, as in sentiment analysis between "),Ha=l(W,"CODE",{});var Fi=o(Ha);jr=n(Fi,"negative"),Fi.forEach(a),qr=n(W,", "),Ia=l(W,"CODE",{});var Gi=o(Ia);$r=n(Gi,"neutral"),Gi.forEach(a),Tr=n(W," and "),Na=l(W,"CODE",{});var Ki=o(Na);Dr=n(Ki,"positive"),Ki.forEach(a),xr=n(W," sentences. To map these predictions to an id, we need an argument "),La=l(W,"CODE",{});var Ji=o(La);Ar=n(Ji,"label_mapping"),Ji.forEach(a),Cr=n(W," mapping strings to numbers. In the case of transformers models, you will typically want to pass "),za=l(W,"CODE",{});var Vi=o(za);Pr=n(Vi,"pipe.model.config.label2id"),Vi.forEach(a),Or=n(W,"."),W.forEach(a),ys=d(t),N=l(t,"P",{});var ee=o(N);Hr=n(ee,"However, beware that some models on the Hub have a label mapping that do not match with the dataset mapping! This may be that there is even no "),Sa=l(ee,"CODE",{});var Qi=o(Sa);Ir=n(Qi,"label2id"),Qi.forEach(a),Nr=n(ee,", or that the labels are uninformative ("),Ba=l(ee,"CODE",{});var Wi=o(Ba);Lr=n(Wi,"LABEL_0"),Wi.forEach(a),zr=n(ee,", "),Ua=l(ee,"CODE",{});var Xi=o(Ua);Sr=n(Xi,"LABEL_1"),Xi.forEach(a),Br=n(ee,", etc.), as for "),Xe=l(ee,"A",{href:!0,rel:!0});var Yi=o(Xe);Ur=n(Yi,"this model"),Yi.forEach(a),Rr=n(ee,"."),ee.forEach(a),js=d(t),xe=l(t,"P",{});var Rs=o(xe);Mr=n(Rs,"In such case, it is best to inspect the dataset features in "),Ra=l(Rs,"CODE",{});var Zi=o(Ra);Fr=n(Zi,"data.features"),Zi.forEach(a),Gr=n(Rs,", and, if possible, to use (Dataset.align_labels_with_mapping)[https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.Dataset.align_labels_with_mapping] to align the dataset labels with the model\u2019s outputs."),Rs.forEach(a),qs=d(t),U=l(t,"P",{});var He=o(U);Kr=n(He,"An other example is for "),Ma=l(He,"CODE",{});var ed=o(Ma);Jr=n(ed,"token-classification"),ed.forEach(a),Vr=n(He,", as in named entity recoginition (NER) or part of speech tagging (POS), where the common dataset structure assumes a list of words to be tagged as an input. Pipelines assume a single string as an input, and the list of word needs to be joined into a single string, using the "),Fa=l(He,"CODE",{});var td=o(Fa);Qr=n(td,"join_by"),td.forEach(a),Wr=n(He," parameter, defaulting to "),Ga=l(He,"CODE",{});var ad=o(Ga);Xr=n(ad,'" "'),ad.forEach(a),Yr=n(He," for space-separated languages."),He.forEach(a),$s=d(t),he=l(t,"H2",{class:!0});var Ms=o(he);Ae=l(Ms,"A",{id:!0,class:!0,href:!0});var sd=o(Ae);Ka=l(sd,"SPAN",{});var ld=o(Ka);A(Ye.$$.fragment,ld),ld.forEach(a),sd.forEach(a),Zr=d(Ms),Ja=l(Ms,"SPAN",{});var od=o(Ja);en=n(od,"Confidence intervals"),od.forEach(a),Ms.forEach(a),Ts=d(t),Ce=l(t,"P",{});var Fs=o(Ce);tn=n(Fs,"TODO "),Ze=l(Fs,"A",{href:!0,rel:!0});var rd=o(Ze);an=n(rd,"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html"),rd.forEach(a),sn=n(Fs,"."),Fs.forEach(a),Ds=d(t),fe=l(t,"H2",{class:!0});var Gs=o(fe);Pe=l(Gs,"A",{id:!0,class:!0,href:!0});var nd=o(Pe);Va=l(nd,"SPAN",{});var id=o(Va);A(et.$$.fragment,id),id.forEach(a),nd.forEach(a),ln=d(Gs),Qa=l(Gs,"SPAN",{});var dd=o(Qa);on=n(dd,"Handling large datasets"),dd.forEach(a),Gs.forEach(a),xs=d(t),ua=l(t,"P",{});var pd=o(ua);rn=n(pd,"The evaluator can be used on large datasets! Below, an example shows how to use it on ImageNet-1k for image classification. Beware that this example will require to download ~150 GB."),pd.forEach(a),As=d(t),ha=l(t,"P",{});var cd=o(ha);nn=n(cd,"Without specifying a device, the default will be the first GPU if available, else CPU."),cd.forEach(a),Cs=d(t),A(tt.$$.fragment,t),this.h()},h(){p(m,"name","hf:doc:metadata"),p(m,"content",JSON.stringify(Ed)),p(S,"id","using-the-evaluator-with-transformers-models"),p(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(S,"href","#using-the-evaluator-with-transformers-models"),p(E,"class","relative group"),p(ne,"href","/docs/evaluate/pr_198/en/package_reference/evaluator_classes#evaluate.ImageClassificationEvaluator"),p(it,"href","/docs/evaluate/pr_198/en/package_reference/evaluator_classes#evaluate.QuestionAnsweringEvaluator"),p(dt,"href","/docs/evaluate/pr_198/en/package_reference/evaluator_classes#evaluate.TextClassificationEvaluator"),p(pt,"href","/docs/evaluate/pr_198/en/package_reference/evaluator_classes#evaluate.TokenClassificationEvaluator"),p(be,"id","using-a-model-from-the-hub"),p(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(be,"href","#using-a-model-from-the-hub"),p(ie,"class","relative group"),p(Ee,"id","using-a-local-model"),p(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ee,"href","#using-a-local-model"),p(de,"class","relative group"),p(we,"id","combining-several-metrics"),p(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(we,"href","#combining-several-metrics"),p(pe,"class","relative group"),p(je,"id","benchmarking-several-models"),p(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(je,"href","#benchmarking-several-models"),p(ce,"class","relative group"),p(gt,"align","left"),p(_t,"align","right"),p(bt,"align","right"),p(Et,"align","right"),p(kt,"align","right"),p(wt,"align","right"),p(yt,"align","left"),p(jt,"align","right"),p(qt,"align","right"),p($t,"align","right"),p(Tt,"align","right"),p(Dt,"align","right"),p(xt,"align","left"),p(At,"align","right"),p(Ct,"align","right"),p(Pt,"align","right"),p(Ot,"align","right"),p(Ht,"align","right"),p(It,"align","left"),p(Nt,"align","right"),p(Lt,"align","right"),p(zt,"align","right"),p(St,"align","right"),p(Bt,"align","right"),p(Ut,"align","left"),p(Rt,"align","right"),p(Mt,"align","right"),p(Ft,"align","right"),p(Gt,"align","right"),p(Kt,"align","right"),p(Jt,"align","left"),p(Vt,"align","right"),p(Qt,"align","right"),p(Wt,"align","right"),p(Xt,"align","right"),p(Yt,"align","right"),p(Zt,"align","left"),p(ea,"align","right"),p(ta,"align","right"),p(aa,"align","right"),p(sa,"align","right"),p(la,"align","right"),p(oa,"align","left"),p(ra,"align","right"),p(na,"align","right"),p(ia,"align","right"),p(da,"align","right"),p(pa,"align","right"),p(De,"id","evaluator-taskspecific-arguments"),p(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(De,"href","#evaluator-taskspecific-arguments"),p(ue,"class","relative group"),p(Xe,"href","https://huggingface.co/ArBert/albert-base-v2-finetuned-ner/blob/main/config.json"),p(Xe,"rel","nofollow"),p(Ae,"id","confidence-intervals"),p(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ae,"href","#confidence-intervals"),p(he,"class","relative group"),p(Ze,"href","https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html"),p(Ze,"rel","nofollow"),p(Pe,"id","handling-large-datasets"),p(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Pe,"href","#handling-large-datasets"),p(fe,"class","relative group")},m(t,c){e(document.head,m),u(t,me,c),u(t,E,c),e(E,S),e(S,te),C(B,te,null),e(E,g),e(E,X),e(X,Ne),u(t,ve,c),u(t,_,c),e(_,Le),e(_,ae),e(ae,se),e(_,ze),e(_,le),e(le,oe),e(_,Se),u(t,re,c),u(t,z,c),e(z,Be),u(t,f,c),u(t,h,c),e(h,Y),e(Y,I),e(I,lt),e(Y,ot),e(Y,ne),e(ne,rt),e(Y,nt),e(h,Ks),e(h,ge),e(ge,va),e(va,Js),e(ge,Vs),e(ge,it),e(it,Qs),e(ge,Ws),e(h,Xs),e(h,Z),e(Z,ga),e(ga,Ys),e(Z,Zs),e(Z,_a),e(_a,el),e(Z,tl),e(Z,dt),e(dt,al),e(Z,sl),e(h,ll),e(h,_e),e(_e,ba),e(ba,ol),e(_e,rl),e(_e,pt),e(pt,nl),e(_e,il),u(t,es,c),u(t,ct,c),e(ct,dl),u(t,ts,c),u(t,ie,c),e(ie,be),e(be,Ea),C(Ue,Ea,null),e(ie,pl),e(ie,ka),e(ka,cl),u(t,as,c),u(t,ut,c),e(ut,ul),u(t,ss,c),C(Re,t,c),u(t,ls,c),u(t,ht,c),e(ht,hl),u(t,os,c),C(Me,t,c),u(t,rs,c),u(t,ft,c),e(ft,fl),u(t,ns,c),u(t,de,c),e(de,Ee),e(Ee,wa),C(Fe,wa,null),e(de,ml),e(de,ya),e(ya,vl),u(t,is,c),u(t,ke,c),e(ke,gl),e(ke,ja),e(ja,_l),e(ke,bl),u(t,ds,c),C(Ge,t,c),u(t,ps,c),u(t,pe,c),e(pe,we),e(we,qa),C(Ke,qa,null),e(pe,El),e(pe,$a),e($a,kl),u(t,cs,c),u(t,ye,c),e(ye,wl),e(ye,Ta),e(Ta,yl),e(ye,jl),u(t,us,c),u(t,mt,c),e(mt,ql),u(t,hs,c),C(Je,t,c),u(t,fs,c),u(t,ce,c),e(ce,je),e(je,Da),C(Ve,Da,null),e(ce,$l),e(ce,xa),e(xa,Tl),u(t,ms,c),u(t,qe,c),e(qe,Dl),e(qe,Aa),e(Aa,xl),e(qe,Al),u(t,vs,c),C(Qe,t,c),u(t,gs,c),u(t,vt,c),e(vt,Cl),u(t,_s,c),u(t,$e,c),e($e,Ca),e(Ca,k),e(k,gt),e(gt,Pl),e(k,Ol),e(k,_t),e(_t,Hl),e(k,Il),e(k,bt),e(bt,Nl),e(k,Ll),e(k,Et),e(Et,zl),e(k,Sl),e(k,kt),e(kt,Bl),e(k,Ul),e(k,wt),e(wt,Rl),e($e,Ml),e($e,v),e(v,w),e(w,yt),e(yt,Fl),e(w,Gl),e(w,jt),e(jt,Kl),e(w,Jl),e(w,qt),e(qt,Vl),e(w,Ql),e(w,$t),e($t,Wl),e(w,Xl),e(w,Tt),e(Tt,Yl),e(w,Zl),e(w,Dt),e(Dt,eo),e(v,to),e(v,y),e(y,xt),e(xt,ao),e(y,so),e(y,At),e(At,lo),e(y,oo),e(y,Ct),e(Ct,ro),e(y,no),e(y,Pt),e(Pt,io),e(y,po),e(y,Ot),e(Ot,co),e(y,uo),e(y,Ht),e(Ht,ho),e(v,fo),e(v,j),e(j,It),e(It,mo),e(j,vo),e(j,Nt),e(Nt,go),e(j,_o),e(j,Lt),e(Lt,bo),e(j,Eo),e(j,zt),e(zt,ko),e(j,wo),e(j,St),e(St,yo),e(j,jo),e(j,Bt),e(Bt,qo),e(v,$o),e(v,q),e(q,Ut),e(Ut,To),e(q,Do),e(q,Rt),e(Rt,xo),e(q,Ao),e(q,Mt),e(Mt,Co),e(q,Po),e(q,Ft),e(Ft,Oo),e(q,Ho),e(q,Gt),e(Gt,Io),e(q,No),e(q,Kt),e(Kt,Lo),e(v,zo),e(v,$),e($,Jt),e(Jt,So),e($,Bo),e($,Vt),e(Vt,Uo),e($,Ro),e($,Qt),e(Qt,Mo),e($,Fo),e($,Wt),e(Wt,Go),e($,Ko),e($,Xt),e(Xt,Jo),e($,Vo),e($,Yt),e(Yt,Qo),e(v,Wo),e(v,T),e(T,Zt),e(Zt,Xo),e(T,Yo),e(T,ea),e(ea,Zo),e(T,er),e(T,ta),e(ta,tr),e(T,ar),e(T,aa),e(aa,sr),e(T,lr),e(T,sa),e(sa,or),e(T,rr),e(T,la),e(la,nr),e(v,ir),e(v,D),e(D,oa),e(oa,dr),e(D,pr),e(D,ra),e(ra,cr),e(D,ur),e(D,na),e(na,hr),e(D,fr),e(D,ia),e(ia,mr),e(D,vr),e(D,da),e(da,gr),e(D,_r),e(D,pa),e(pa,br),u(t,bs,c),C(Te,t,c),u(t,Es,c),u(t,ue,c),e(ue,De),e(De,Pa),C(We,Pa,null),e(ue,Er),e(ue,Oa),e(Oa,kr),u(t,ks,c),u(t,ca,c),e(ca,wr),u(t,ws,c),u(t,b,c),e(b,yr),e(b,Ha),e(Ha,jr),e(b,qr),e(b,Ia),e(Ia,$r),e(b,Tr),e(b,Na),e(Na,Dr),e(b,xr),e(b,La),e(La,Ar),e(b,Cr),e(b,za),e(za,Pr),e(b,Or),u(t,ys,c),u(t,N,c),e(N,Hr),e(N,Sa),e(Sa,Ir),e(N,Nr),e(N,Ba),e(Ba,Lr),e(N,zr),e(N,Ua),e(Ua,Sr),e(N,Br),e(N,Xe),e(Xe,Ur),e(N,Rr),u(t,js,c),u(t,xe,c),e(xe,Mr),e(xe,Ra),e(Ra,Fr),e(xe,Gr),u(t,qs,c),u(t,U,c),e(U,Kr),e(U,Ma),e(Ma,Jr),e(U,Vr),e(U,Fa),e(Fa,Qr),e(U,Wr),e(U,Ga),e(Ga,Xr),e(U,Yr),u(t,$s,c),u(t,he,c),e(he,Ae),e(Ae,Ka),C(Ye,Ka,null),e(he,Zr),e(he,Ja),e(Ja,en),u(t,Ts,c),u(t,Ce,c),e(Ce,tn),e(Ce,Ze),e(Ze,an),e(Ce,sn),u(t,Ds,c),u(t,fe,c),e(fe,Pe),e(Pe,Va),C(et,Va,null),e(fe,ln),e(fe,Qa),e(Qa,on),u(t,xs,c),u(t,ua,c),e(ua,rn),u(t,As,c),u(t,ha,c),e(ha,nn),u(t,Cs,c),C(tt,t,c),Ps=!0},p(t,[c]){const at={};c&2&&(at.$$scope={dirty:c,ctx:t}),Te.$set(at)},i(t){Ps||(P(B.$$.fragment,t),P(Ue.$$.fragment,t),P(Re.$$.fragment,t),P(Me.$$.fragment,t),P(Fe.$$.fragment,t),P(Ge.$$.fragment,t),P(Ke.$$.fragment,t),P(Je.$$.fragment,t),P(Ve.$$.fragment,t),P(Qe.$$.fragment,t),P(Te.$$.fragment,t),P(We.$$.fragment,t),P(Ye.$$.fragment,t),P(et.$$.fragment,t),P(tt.$$.fragment,t),Ps=!0)},o(t){O(B.$$.fragment,t),O(Ue.$$.fragment,t),O(Re.$$.fragment,t),O(Me.$$.fragment,t),O(Fe.$$.fragment,t),O(Ge.$$.fragment,t),O(Ke.$$.fragment,t),O(Je.$$.fragment,t),O(Ve.$$.fragment,t),O(Qe.$$.fragment,t),O(Te.$$.fragment,t),O(We.$$.fragment,t),O(Ye.$$.fragment,t),O(et.$$.fragment,t),O(tt.$$.fragment,t),Ps=!1},d(t){a(m),t&&a(me),t&&a(E),H(B),t&&a(ve),t&&a(_),t&&a(re),t&&a(z),t&&a(f),t&&a(h),t&&a(es),t&&a(ct),t&&a(ts),t&&a(ie),H(Ue),t&&a(as),t&&a(ut),t&&a(ss),H(Re,t),t&&a(ls),t&&a(ht),t&&a(os),H(Me,t),t&&a(rs),t&&a(ft),t&&a(ns),t&&a(de),H(Fe),t&&a(is),t&&a(ke),t&&a(ds),H(Ge,t),t&&a(ps),t&&a(pe),H(Ke),t&&a(cs),t&&a(ye),t&&a(us),t&&a(mt),t&&a(hs),H(Je,t),t&&a(fs),t&&a(ce),H(Ve),t&&a(ms),t&&a(qe),t&&a(vs),H(Qe,t),t&&a(gs),t&&a(vt),t&&a(_s),t&&a($e),t&&a(bs),H(Te,t),t&&a(Es),t&&a(ue),H(We),t&&a(ks),t&&a(ca),t&&a(ws),t&&a(b),t&&a(ys),t&&a(N),t&&a(js),t&&a(xe),t&&a(qs),t&&a(U),t&&a($s),t&&a(he),H(Ye),t&&a(Ts),t&&a(Ce),t&&a(Ds),t&&a(fe),H(et),t&&a(xs),t&&a(ua),t&&a(As),t&&a(ha),t&&a(Cs),H(tt,t)}}}const Ed={local:"using-the-evaluator-with-transformers-models",sections:[{local:"using-a-model-from-the-hub",title:"Using a model from the Hub"},{local:"using-a-local-model",title:"Using a local model"},{local:"combining-several-metrics",title:"Combining several metrics"},{local:"benchmarking-several-models",title:"Benchmarking several models"},{local:"evaluator-taskspecific-arguments",title:"Evaluator task-specific arguments"},{local:"confidence-intervals",title:"Confidence intervals"},{local:"handling-large-datasets",title:"Handling large datasets"}],title:"Using the evaluator with transformers models"};function kd(Za){return vd(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $d extends ud{constructor(m){super();hd(this,m,kd,bd,fd,{})}}export{$d as default,Ed as metadata};
