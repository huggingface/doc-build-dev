import{S as sa,i as aa,s as la,e as n,k as c,w,t as a,M as oa,c as i,d as s,m as h,a as p,x as v,h as l,b as f,G as t,g as r,y as _,L as na,q as y,o as $,B as b,v as ia}from"../chunks/vendor-hf-doc-builder.js";import{I as bs}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as T}from"../chunks/CodeBlock-hf-doc-builder.js";function pa(ks){let P,Oe,S,O,pe,M,ht,W,ft,re,dt,ut,Ie,d,mt,ce,wt,vt,he,_t,yt,fe,$t,bt,B,kt,jt,z,Et,xt,Le,C,I,de,H,gt,ue,qt,Ae,L,Pt,U,St,Ct,Ne,V,Fe,A,Dt,me,Tt,Ot,Me,Y,We,u,It,we,Lt,At,ve,Nt,Ft,_e,Mt,Wt,ye,Bt,zt,Be,G,ze,k,Ht,$e,Ut,Vt,be,Yt,Gt,He,J,Ue,j,Jt,ke,Rt,Kt,je,Qt,Xt,Ve,D,N,Ee,R,Zt,xe,es,Ye,E,ts,ge,ss,as,qe,ls,os,Ge,K,Je,x,ns,Pe,is,ps,Se,rs,cs,Re,Q,Ke,g,hs,Ce,fs,ds,De,us,ms,Qe,X,Xe,te,ws,Ze,Z,et,F,vs,Te,_s,ys,tt,ee,st,se,$s,at;return M=new bs({}),H=new bs({}),V=new T({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

ds = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>)`}}),Y=new T({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline
<span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> MultinomialNB
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfTransformer
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer

text_clf = Pipeline([
        (<span class="hljs-string">&#x27;vect&#x27;</span>, CountVectorizer()),
        (<span class="hljs-string">&#x27;tfidf&#x27;</span>, TfidfTransformer()),
        (<span class="hljs-string">&#x27;clf&#x27;</span>, MultinomialNB()),
])

text_clf.fit(ds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;text&quot;</span>], ds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;label&quot;</span>])`}}),G=new T({props:{code:`
`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">ScikitEvalPipeline</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, pipeline</span>):
        self.pipeline = pipeline
        self.task = <span class="hljs-string">&quot;text-classification&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, input_texts, **kwargs</span>):
        <span class="hljs-keyword">return</span> [{<span class="hljs-string">&quot;label&quot;</span>: p} <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.pipeline.predict(input_texts)]

pipe = ScikitEvalPipeline(text_clf)`}}),J=new T({props:{code:`

{'accuracy': 0.82956}`,highlighted:`<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator

<span class="hljs-built_in">eval</span> = evaluator(<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-built_in">eval</span>.compute(pipe, ds[<span class="hljs-string">&quot;test&quot;</span>], <span class="hljs-string">&quot;accuracy&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.82956</span>}`}}),R=new bs({}),K=new T({props:{code:`pip install spacytextblob
python -m textblob.download_corpora
python -m spacy download en_core_web_sm`,highlighted:`pip install spacytextblob
python -m textblob.download_corpora
python -m spacy download en_core_web_sm`}}),Q=new T({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> spacy

nlp = spacy.load(<span class="hljs-string">&#x27;en_core_web_sm&#x27;</span>)
nlp.add_pipe(<span class="hljs-string">&#x27;spacytextblob&#x27;</span>)`}}),X=new T({props:{code:"",highlighted:`texts = [<span class="hljs-string">&quot;This movie is horrible&quot;</span>, <span class="hljs-string">&quot;This movie is awesome&quot;</span>]
results = nlp.pipe(texts)

<span class="hljs-keyword">for</span> txt, res <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(texts, results):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{text}</span> | Polarity: <span class="hljs-subst">{res._.blob.polarity}</span>&quot;</span>)`}}),Z=new T({props:{code:`
`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">SpacyEvalPipeline</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, nlp</span>):
        self.nlp = nlp
        self.task = <span class="hljs-string">&quot;text-classification&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, input_texts, **kwargs</span>):
        results =[]
        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.nlp.pipe(input_texts):
            <span class="hljs-keyword">if</span> p._.blob.polarity&gt;=<span class="hljs-number">0</span>:
                results.append({<span class="hljs-string">&quot;label&quot;</span>: <span class="hljs-number">1</span>})
            <span class="hljs-keyword">else</span>:
                results.append({<span class="hljs-string">&quot;label&quot;</span>: <span class="hljs-number">0</span>})
        <span class="hljs-keyword">return</span> results

pipe = SpacyEvalPipeline(nlp)`}}),ee=new T({props:{code:"{'accuracy': 0.6914}",highlighted:`<span class="hljs-built_in">eval</span>.compute(pipe, ds[<span class="hljs-string">&quot;test&quot;</span>], <span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.6914</span>}`}}),{c(){P=n("meta"),Oe=c(),S=n("h1"),O=n("a"),pe=n("span"),w(M.$$.fragment),ht=c(),W=n("span"),ft=a("Using the "),re=n("code"),dt=a("evaluator"),ut=a(" with custom models"),Ie=c(),d=n("p"),mt=a("The evaluator is designed to work with "),ce=n("code"),wt=a("transformer"),vt=a(" pipelines out-of-the-box. However, in many cases you might have a model or pipeline that\u2019s not part of the "),he=n("code"),_t=a("transformer"),yt=a(" ecosystem. You can still use "),fe=n("code"),$t=a("evaluator"),bt=a(" to easily compute metrics them. In this guide we show how to do this for a Scikit-Learn "),B=n("a"),kt=a("pipeline"),jt=a(" and a Spacy "),z=n("a"),Et=a("pipeline"),xt=a(". Let\u2019s start with the Scikit-Learn case."),Le=c(),C=n("h2"),I=n("a"),de=n("span"),w(H.$$.fragment),gt=c(),ue=n("span"),qt=a("Scikit-Learn"),Ae=c(),L=n("p"),Pt=a("First we need to train a model. We\u2019ll train a simple text classifier on the "),U=n("a"),St=a("IMDb dataset"),Ct=a(", so let\u2019s start by downloading the dataset:"),Ne=c(),w(V.$$.fragment),Fe=c(),A=n("p"),Dt=a("Then we can build a simple TF-IDF preprocessor and Naive Bayes classifier wrapped in a "),me=n("code"),Tt=a("Pipeline"),Ot=a(":"),Me=c(),w(Y.$$.fragment),We=c(),u=n("p"),It=a("Following the convention in the "),we=n("code"),Lt=a("TextClassificationPipeline"),At=a(" of "),ve=n("code"),Nt=a("transformers"),Ft=a(" our pipeline should be callable and return a list of dictionaries. In addition we use the "),_e=n("code"),Mt=a("task"),Wt=a(" attribute to check if the pipeline is compatible with the "),ye=n("code"),Bt=a("evaluator"),zt=a(". We can write a small wrapper class for that purpose:"),Be=c(),w(G.$$.fragment),ze=c(),k=n("p"),Ht=a("We can now pass this "),$e=n("code"),Ut=a("pipeline"),Vt=a(" to the "),be=n("code"),Yt=a("evaluator"),Gt=a(":"),He=c(),w(J.$$.fragment),Ue=c(),j=n("p"),Jt=a("Implementing that simple wrapper is all that\u2019s needed to use any model from any framework with the "),ke=n("code"),Rt=a("evaluator"),Kt=a(". In the "),je=n("code"),Qt=a("__call__"),Xt=a(" you can implement all logic necessary for efficient forward passes through your model."),Ve=c(),D=n("h2"),N=n("a"),Ee=n("span"),w(R.$$.fragment),Zt=c(),xe=n("span"),es=a("Spacy"),Ye=c(),E=n("p"),ts=a("We\u2019ll use the "),ge=n("code"),ss=a("polarity"),as=a(" feature of the "),qe=n("code"),ls=a("spacytextblob"),os=a(" project to get a simple sentiment analyzer. First you\u2019ll need to install the project and download the resources:"),Ge=c(),w(K.$$.fragment),Je=c(),x=n("p"),ns=a("Then we can simply load the "),Pe=n("code"),is=a("nlp"),ps=a(" pipeline and add the "),Se=n("code"),rs=a("spacytextblob"),cs=a(" pipeline:"),Re=c(),w(Q.$$.fragment),Ke=c(),g=n("p"),hs=a("This snippet shows how we can use the "),Ce=n("code"),fs=a("polarity"),ds=a(" feature added with "),De=n("code"),us=a("spacytextblob"),ms=a(" to get the sentiment of a text:"),Qe=c(),w(X.$$.fragment),Xe=c(),te=n("p"),ws=a("Now we can wrap it in a simple wrapper class like in the Scikit-Learn example before. It just has to return a list of dictionaries with the predicted lables. If the polarity is larger than 0 we\u2019ll predict positive sentiment and negative otherwise:"),Ze=c(),w(Z.$$.fragment),et=c(),F=n("p"),vs=a("That class is compatible with the "),Te=n("code"),_s=a("evaluator"),ys=a(" and we can use the same instance from the previous examlpe along with the IMDb test set:"),tt=c(),w(ee.$$.fragment),st=c(),se=n("p"),$s=a("This will take a little longer than the Scikit-Learn example but after roughly 10-15min you will have the evaluation results!"),this.h()},l(e){const o=oa('[data-svelte="svelte-1phssyn"]',document.head);P=i(o,"META",{name:!0,content:!0}),o.forEach(s),Oe=h(e),S=i(e,"H1",{class:!0});var lt=p(S);O=i(lt,"A",{id:!0,class:!0,href:!0});var js=p(O);pe=i(js,"SPAN",{});var Es=p(pe);v(M.$$.fragment,Es),Es.forEach(s),js.forEach(s),ht=h(lt),W=i(lt,"SPAN",{});var ot=p(W);ft=l(ot,"Using the "),re=i(ot,"CODE",{});var xs=p(re);dt=l(xs,"evaluator"),xs.forEach(s),ut=l(ot," with custom models"),ot.forEach(s),lt.forEach(s),Ie=h(e),d=i(e,"P",{});var m=p(d);mt=l(m,"The evaluator is designed to work with "),ce=i(m,"CODE",{});var gs=p(ce);wt=l(gs,"transformer"),gs.forEach(s),vt=l(m," pipelines out-of-the-box. However, in many cases you might have a model or pipeline that\u2019s not part of the "),he=i(m,"CODE",{});var qs=p(he);_t=l(qs,"transformer"),qs.forEach(s),yt=l(m," ecosystem. You can still use "),fe=i(m,"CODE",{});var Ps=p(fe);$t=l(Ps,"evaluator"),Ps.forEach(s),bt=l(m," to easily compute metrics them. In this guide we show how to do this for a Scikit-Learn "),B=i(m,"A",{href:!0,rel:!0});var Ss=p(B);kt=l(Ss,"pipeline"),Ss.forEach(s),jt=l(m," and a Spacy "),z=i(m,"A",{href:!0,rel:!0});var Cs=p(z);Et=l(Cs,"pipeline"),Cs.forEach(s),xt=l(m,". Let\u2019s start with the Scikit-Learn case."),m.forEach(s),Le=h(e),C=i(e,"H2",{class:!0});var nt=p(C);I=i(nt,"A",{id:!0,class:!0,href:!0});var Ds=p(I);de=i(Ds,"SPAN",{});var Ts=p(de);v(H.$$.fragment,Ts),Ts.forEach(s),Ds.forEach(s),gt=h(nt),ue=i(nt,"SPAN",{});var Os=p(ue);qt=l(Os,"Scikit-Learn"),Os.forEach(s),nt.forEach(s),Ae=h(e),L=i(e,"P",{});var it=p(L);Pt=l(it,"First we need to train a model. We\u2019ll train a simple text classifier on the "),U=i(it,"A",{href:!0,rel:!0});var Is=p(U);St=l(Is,"IMDb dataset"),Is.forEach(s),Ct=l(it,", so let\u2019s start by downloading the dataset:"),it.forEach(s),Ne=h(e),v(V.$$.fragment,e),Fe=h(e),A=i(e,"P",{});var pt=p(A);Dt=l(pt,"Then we can build a simple TF-IDF preprocessor and Naive Bayes classifier wrapped in a "),me=i(pt,"CODE",{});var Ls=p(me);Tt=l(Ls,"Pipeline"),Ls.forEach(s),Ot=l(pt,":"),pt.forEach(s),Me=h(e),v(Y.$$.fragment,e),We=h(e),u=i(e,"P",{});var q=p(u);It=l(q,"Following the convention in the "),we=i(q,"CODE",{});var As=p(we);Lt=l(As,"TextClassificationPipeline"),As.forEach(s),At=l(q," of "),ve=i(q,"CODE",{});var Ns=p(ve);Nt=l(Ns,"transformers"),Ns.forEach(s),Ft=l(q," our pipeline should be callable and return a list of dictionaries. In addition we use the "),_e=i(q,"CODE",{});var Fs=p(_e);Mt=l(Fs,"task"),Fs.forEach(s),Wt=l(q," attribute to check if the pipeline is compatible with the "),ye=i(q,"CODE",{});var Ms=p(ye);Bt=l(Ms,"evaluator"),Ms.forEach(s),zt=l(q,". We can write a small wrapper class for that purpose:"),q.forEach(s),Be=h(e),v(G.$$.fragment,e),ze=h(e),k=i(e,"P",{});var ae=p(k);Ht=l(ae,"We can now pass this "),$e=i(ae,"CODE",{});var Ws=p($e);Ut=l(Ws,"pipeline"),Ws.forEach(s),Vt=l(ae," to the "),be=i(ae,"CODE",{});var Bs=p(be);Yt=l(Bs,"evaluator"),Bs.forEach(s),Gt=l(ae,":"),ae.forEach(s),He=h(e),v(J.$$.fragment,e),Ue=h(e),j=i(e,"P",{});var le=p(j);Jt=l(le,"Implementing that simple wrapper is all that\u2019s needed to use any model from any framework with the "),ke=i(le,"CODE",{});var zs=p(ke);Rt=l(zs,"evaluator"),zs.forEach(s),Kt=l(le,". In the "),je=i(le,"CODE",{});var Hs=p(je);Qt=l(Hs,"__call__"),Hs.forEach(s),Xt=l(le," you can implement all logic necessary for efficient forward passes through your model."),le.forEach(s),Ve=h(e),D=i(e,"H2",{class:!0});var rt=p(D);N=i(rt,"A",{id:!0,class:!0,href:!0});var Us=p(N);Ee=i(Us,"SPAN",{});var Vs=p(Ee);v(R.$$.fragment,Vs),Vs.forEach(s),Us.forEach(s),Zt=h(rt),xe=i(rt,"SPAN",{});var Ys=p(xe);es=l(Ys,"Spacy"),Ys.forEach(s),rt.forEach(s),Ye=h(e),E=i(e,"P",{});var oe=p(E);ts=l(oe,"We\u2019ll use the "),ge=i(oe,"CODE",{});var Gs=p(ge);ss=l(Gs,"polarity"),Gs.forEach(s),as=l(oe," feature of the "),qe=i(oe,"CODE",{});var Js=p(qe);ls=l(Js,"spacytextblob"),Js.forEach(s),os=l(oe," project to get a simple sentiment analyzer. First you\u2019ll need to install the project and download the resources:"),oe.forEach(s),Ge=h(e),v(K.$$.fragment,e),Je=h(e),x=i(e,"P",{});var ne=p(x);ns=l(ne,"Then we can simply load the "),Pe=i(ne,"CODE",{});var Rs=p(Pe);is=l(Rs,"nlp"),Rs.forEach(s),ps=l(ne," pipeline and add the "),Se=i(ne,"CODE",{});var Ks=p(Se);rs=l(Ks,"spacytextblob"),Ks.forEach(s),cs=l(ne," pipeline:"),ne.forEach(s),Re=h(e),v(Q.$$.fragment,e),Ke=h(e),g=i(e,"P",{});var ie=p(g);hs=l(ie,"This snippet shows how we can use the "),Ce=i(ie,"CODE",{});var Qs=p(Ce);fs=l(Qs,"polarity"),Qs.forEach(s),ds=l(ie," feature added with "),De=i(ie,"CODE",{});var Xs=p(De);us=l(Xs,"spacytextblob"),Xs.forEach(s),ms=l(ie," to get the sentiment of a text:"),ie.forEach(s),Qe=h(e),v(X.$$.fragment,e),Xe=h(e),te=i(e,"P",{});var Zs=p(te);ws=l(Zs,"Now we can wrap it in a simple wrapper class like in the Scikit-Learn example before. It just has to return a list of dictionaries with the predicted lables. If the polarity is larger than 0 we\u2019ll predict positive sentiment and negative otherwise:"),Zs.forEach(s),Ze=h(e),v(Z.$$.fragment,e),et=h(e),F=i(e,"P",{});var ct=p(F);vs=l(ct,"That class is compatible with the "),Te=i(ct,"CODE",{});var ea=p(Te);_s=l(ea,"evaluator"),ea.forEach(s),ys=l(ct," and we can use the same instance from the previous examlpe along with the IMDb test set:"),ct.forEach(s),tt=h(e),v(ee.$$.fragment,e),st=h(e),se=i(e,"P",{});var ta=p(se);$s=l(ta,"This will take a little longer than the Scikit-Learn example but after roughly 10-15min you will have the evaluation results!"),ta.forEach(s),this.h()},h(){f(P,"name","hf:doc:metadata"),f(P,"content",JSON.stringify(ra)),f(O,"id","using-the-evaluator-with-custom-models"),f(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(O,"href","#using-the-evaluator-with-custom-models"),f(S,"class","relative group"),f(B,"href","https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline"),f(B,"rel","nofollow"),f(z,"href","https://spacy.io"),f(z,"rel","nofollow"),f(I,"id","scikitlearn"),f(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(I,"href","#scikitlearn"),f(C,"class","relative group"),f(U,"href","https://huggingface.co/datasets/imdb"),f(U,"rel","nofollow"),f(N,"id","spacy"),f(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(N,"href","#spacy"),f(D,"class","relative group")},m(e,o){t(document.head,P),r(e,Oe,o),r(e,S,o),t(S,O),t(O,pe),_(M,pe,null),t(S,ht),t(S,W),t(W,ft),t(W,re),t(re,dt),t(W,ut),r(e,Ie,o),r(e,d,o),t(d,mt),t(d,ce),t(ce,wt),t(d,vt),t(d,he),t(he,_t),t(d,yt),t(d,fe),t(fe,$t),t(d,bt),t(d,B),t(B,kt),t(d,jt),t(d,z),t(z,Et),t(d,xt),r(e,Le,o),r(e,C,o),t(C,I),t(I,de),_(H,de,null),t(C,gt),t(C,ue),t(ue,qt),r(e,Ae,o),r(e,L,o),t(L,Pt),t(L,U),t(U,St),t(L,Ct),r(e,Ne,o),_(V,e,o),r(e,Fe,o),r(e,A,o),t(A,Dt),t(A,me),t(me,Tt),t(A,Ot),r(e,Me,o),_(Y,e,o),r(e,We,o),r(e,u,o),t(u,It),t(u,we),t(we,Lt),t(u,At),t(u,ve),t(ve,Nt),t(u,Ft),t(u,_e),t(_e,Mt),t(u,Wt),t(u,ye),t(ye,Bt),t(u,zt),r(e,Be,o),_(G,e,o),r(e,ze,o),r(e,k,o),t(k,Ht),t(k,$e),t($e,Ut),t(k,Vt),t(k,be),t(be,Yt),t(k,Gt),r(e,He,o),_(J,e,o),r(e,Ue,o),r(e,j,o),t(j,Jt),t(j,ke),t(ke,Rt),t(j,Kt),t(j,je),t(je,Qt),t(j,Xt),r(e,Ve,o),r(e,D,o),t(D,N),t(N,Ee),_(R,Ee,null),t(D,Zt),t(D,xe),t(xe,es),r(e,Ye,o),r(e,E,o),t(E,ts),t(E,ge),t(ge,ss),t(E,as),t(E,qe),t(qe,ls),t(E,os),r(e,Ge,o),_(K,e,o),r(e,Je,o),r(e,x,o),t(x,ns),t(x,Pe),t(Pe,is),t(x,ps),t(x,Se),t(Se,rs),t(x,cs),r(e,Re,o),_(Q,e,o),r(e,Ke,o),r(e,g,o),t(g,hs),t(g,Ce),t(Ce,fs),t(g,ds),t(g,De),t(De,us),t(g,ms),r(e,Qe,o),_(X,e,o),r(e,Xe,o),r(e,te,o),t(te,ws),r(e,Ze,o),_(Z,e,o),r(e,et,o),r(e,F,o),t(F,vs),t(F,Te),t(Te,_s),t(F,ys),r(e,tt,o),_(ee,e,o),r(e,st,o),r(e,se,o),t(se,$s),at=!0},p:na,i(e){at||(y(M.$$.fragment,e),y(H.$$.fragment,e),y(V.$$.fragment,e),y(Y.$$.fragment,e),y(G.$$.fragment,e),y(J.$$.fragment,e),y(R.$$.fragment,e),y(K.$$.fragment,e),y(Q.$$.fragment,e),y(X.$$.fragment,e),y(Z.$$.fragment,e),y(ee.$$.fragment,e),at=!0)},o(e){$(M.$$.fragment,e),$(H.$$.fragment,e),$(V.$$.fragment,e),$(Y.$$.fragment,e),$(G.$$.fragment,e),$(J.$$.fragment,e),$(R.$$.fragment,e),$(K.$$.fragment,e),$(Q.$$.fragment,e),$(X.$$.fragment,e),$(Z.$$.fragment,e),$(ee.$$.fragment,e),at=!1},d(e){s(P),e&&s(Oe),e&&s(S),b(M),e&&s(Ie),e&&s(d),e&&s(Le),e&&s(C),b(H),e&&s(Ae),e&&s(L),e&&s(Ne),b(V,e),e&&s(Fe),e&&s(A),e&&s(Me),b(Y,e),e&&s(We),e&&s(u),e&&s(Be),b(G,e),e&&s(ze),e&&s(k),e&&s(He),b(J,e),e&&s(Ue),e&&s(j),e&&s(Ve),e&&s(D),b(R),e&&s(Ye),e&&s(E),e&&s(Ge),b(K,e),e&&s(Je),e&&s(x),e&&s(Re),b(Q,e),e&&s(Ke),e&&s(g),e&&s(Qe),b(X,e),e&&s(Xe),e&&s(te),e&&s(Ze),b(Z,e),e&&s(et),e&&s(F),e&&s(tt),b(ee,e),e&&s(st),e&&s(se)}}}const ra={local:"using-the-evaluator-with-custom-models",sections:[{local:"scikitlearn",title:"Scikit-Learn"},{local:"spacy",title:"Spacy"}],title:"Using the `evaluator` with custom models"};function ca(ks){return ia(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ua extends sa{constructor(P){super();aa(this,P,ca,pa,la,{})}}export{ua as default,ra as metadata};
