import{S as $h,i as qh,s as jh,e as l,k as r,w as f,t as n,M as Th,c as s,d as a,m as c,a as o,x as m,h as i,b as h,G as e,g as d,y as v,q as _,o as g,B as b,v as xh}from"../chunks/vendor-hf-doc-builder.js";import{T as Dh}from"../chunks/Tip-hf-doc-builder.js";import{I as ie}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as $e}from"../chunks/CodeBlock-hf-doc-builder.js";function Ih(ss){let E,qe,j,G,re,M,k,te,Je,je,w,Ye,ce,pe,Ke,de,he,Xe,B,le,ue;return{c(){E=l("p"),qe=n("The sole results from the "),j=l("code"),G=n("Evaluator"),re=n(" should probably not be trusted to compare model performances. Outside of the architecture, many parameters may influence performances:"),M=r(),k=l("ul"),te=l("li"),Je=n("Hyperparameters used during training"),je=r(),w=l("li"),Ye=n("Training data (some models may have been trained on more data than others)"),ce=r(),pe=l("li"),Ke=n("Model size"),de=r(),he=l("li"),Xe=n("Training time"),B=r(),le=l("p"),ue=n("Moreover, the time performances should only be considered as a first proxy, as they include all the processing that goes on in the pipeline. This may include tokenizing, post-processing, that may be different depending on the model, and may not reflect the exact model time performances. Especially, depending on the usage of slow or fast tokenizers, the results may be signifiicantly impacted.")},l(u){E=s(u,"P",{});var S=o(E);qe=i(S,"The sole results from the "),j=s(S,"CODE",{});var Et=o(j);G=i(Et,"Evaluator"),Et.forEach(a),re=i(S," should probably not be trusted to compare model performances. Outside of the architecture, many parameters may influence performances:"),S.forEach(a),M=c(u),k=s(u,"UL",{});var R=o(k);te=s(R,"LI",{});var fe=o(te);Je=i(fe,"Hyperparameters used during training"),fe.forEach(a),je=c(R),w=s(R,"LI",{});var wt=o(w);Ye=i(wt,"Training data (some models may have been trained on more data than others)"),wt.forEach(a),ce=c(R),pe=s(R,"LI",{});var Ze=o(pe);Ke=i(Ze,"Model size"),Ze.forEach(a),de=c(R),he=s(R,"LI",{});var T=o(he);Xe=i(T,"Training time"),T.forEach(a),R.forEach(a),B=c(u),le=s(u,"P",{});var ae=o(le);ue=i(ae,"Moreover, the time performances should only be considered as a first proxy, as they include all the processing that goes on in the pipeline. This may include tokenizing, post-processing, that may be different depending on the model, and may not reflect the exact model time performances. Especially, depending on the usage of slow or fast tokenizers, the results may be signifiicantly impacted."),ae.forEach(a)},m(u,S){d(u,E,S),e(E,qe),e(E,j),e(j,G),e(E,re),d(u,M,S),d(u,k,S),e(k,te),e(te,Je),e(k,je),e(k,w),e(w,Ye),e(k,ce),e(k,pe),e(pe,Ke),e(k,de),e(k,he),e(he,Xe),d(u,B,S),d(u,le,S),e(le,ue)},d(u){u&&a(E),u&&a(M),u&&a(k),u&&a(B),u&&a(le)}}}function Ph(ss){let E,qe,j,G,re,M,k,te,Je,je,w,Ye,ce,pe,Ke,de,he,Xe,B,le,ue,u,S,Et,R,fe,wt,Ze,T,ae,Xa,vo,_o,yt,go,bo,Eo,Te,Za,wo,yo,kt,ko,$o,qo,xe,el,jo,To,$t,xo,Do,Io,De,tl,Po,Co,qt,Ao,Oo,os,jt,No,ns,me,Ie,al,et,So,ll,Lo,is,Tt,Ho,rs,se,xt,sl,Bo,Ro,Wo,Dt,ol,zo,Go,Mo,$,nl,Uo,Vo,il,Fo,Qo,rl,Jo,Yo,cl,Ko,Xo,pl,Zo,en,dl,tn,an,cs,Pe,ln,hl,sn,on,ps,ve,Ce,ul,tt,nn,fl,rn,ds,U,cn,ml,pn,dn,vl,hn,un,_l,fn,mn,hs,It,vn,us,at,fs,Pt,_n,ms,lt,vs,Ct,gn,_s,st,gs,At,bn,bs,_e,Ae,gl,ot,En,bl,wn,Es,Oe,yn,El,kn,$n,ws,nt,ys,Ot,qn,ks,it,$s,Nt,jn,qs,ge,Ne,wl,rt,Tn,yl,xn,js,St,Dn,Ts,V,Lt,kl,In,Pn,Cn,Ht,$l,An,On,Nn,q,ql,Sn,Ln,jl,Hn,Bn,Tl,Rn,Wn,xl,zn,Gn,Dl,Mn,Un,Il,Vn,Fn,Qn,Bt,Pl,Jn,Yn,xs,Rt,Kn,Ds,be,Se,Cl,ct,Xn,Al,Zn,Is,Le,ei,Ol,ti,ai,Ps,pt,Cs,Wt,li,As,He,Nl,x,zt,si,oi,Gt,ni,ii,Mt,ri,ci,Ut,pi,di,Vt,hi,ui,Ft,fi,mi,y,D,Qt,vi,_i,Jt,gi,bi,Yt,Ei,wi,Kt,yi,ki,Xt,$i,qi,Zt,ji,Ti,I,ea,xi,Di,ta,Ii,Pi,aa,Ci,Ai,la,Oi,Ni,sa,Si,Li,oa,Hi,Bi,P,na,Ri,Wi,ia,zi,Gi,ra,Mi,Ui,ca,Vi,Fi,pa,Qi,Ji,da,Yi,Ki,C,ha,Xi,Zi,ua,er,tr,fa,ar,lr,ma,sr,or,va,nr,ir,_a,rr,cr,A,ga,pr,dr,ba,hr,ur,Ea,fr,mr,wa,vr,_r,ya,gr,br,ka,Er,wr,O,$a,yr,kr,qa,$r,qr,ja,jr,Tr,Ta,xr,Dr,xa,Ir,Pr,Da,Cr,Ar,N,Ia,Or,Nr,Pa,Sr,Lr,Ca,Hr,Br,Aa,Rr,Wr,Oa,zr,Gr,Na,Mr,Os,Be,Ns,Ee,Re,Sl,dt,Ur,Ll,Vr,Ss,Sa,Fr,Ls,L,La,Hl,Qr,Jr,Yr,Ha,Bl,Kr,Xr,Zr,Ba,Rl,ec,tc,ac,Ra,Wl,lc,sc,oc,Wa,zl,nc,ic,Hs,za,rc,Bs,we,We,Gl,ht,cc,Ml,pc,Rs,ut,Ws,Ga,dc,zs,ft,Gs,ye,ze,Ul,mt,hc,Vl,uc,Ms,Ma,fc,Us,oe,Ua,Fl,mc,vc,_c,Va,Ql,gc,bc,Ec,vt,Jl,wc,yc,Yl,kc,Vs,Fa,$c,Fs,ke,Ge,Kl,_t,qc,Xl,jc,Qs,Qa,Tc,Js,Ja,xc,Ys,gt,Ks,Me,Dc,Zl,Ic,Pc,Xs;return M=new ie({}),et=new ie({}),tt=new ie({}),at=new $e({props:{code:`from datasets import load_dataset
from evaluate import evaluator
from transformers import AutoModelForSequenceClassification, pipeline

data = load_dataset("imdb", split="test").shuffle(seed=42).select(range(1000))
task_evaluator = evaluator("text-classification")

eval_results = task_evaluator.compute(
    model_or_pipeline="lvwerra/distilbert-imdb",
    data=data,
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)

model = AutoModelForSequenceClassification.from_pretrained("lvwerra/distilbert-imdb")

eval_results = task_evaluator.compute(
    model_or_pipeline=model,
    data=data,
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)

pipe = pipeline("text-classification", model="lvwerra/distilbert-imdb")

eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)
print(eval_results)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification, pipeline

data = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>, split=<span class="hljs-string">&quot;test&quot;</span>).shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
task_evaluator = evaluator(<span class="hljs-string">&quot;text-classification&quot;</span>)

eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>,
    data=data,
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)

model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>)

eval_results = task_evaluator.compute(
    model_or_pipeline=model,
    data=data,
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)

pipe = pipeline(<span class="hljs-string">&quot;text-classification&quot;</span>, model=<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>)

eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)
<span class="hljs-built_in">print</span>(eval_results)`}}),lt=new $e({props:{code:"",highlighted:""}}),st=new $e({props:{code:`{
    'accuracy': 0.918,
    'latency_in_seconds': 0.01274,
    'samples_per_second': 78.887,
    'total_time_in_seconds': 12.676
}`,highlighted:`{
    <span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.918</span>,
    <span class="hljs-string">&#x27;latency_in_seconds&#x27;</span>: <span class="hljs-number">0.01274</span>,
    <span class="hljs-string">&#x27;samples_per_second&#x27;</span>: <span class="hljs-number">78.887</span>,
    <span class="hljs-string">&#x27;total_time_in_seconds&#x27;</span>: <span class="hljs-number">12.676</span>
}`}}),ot=new ie({}),nt=new $e({props:{code:`import evaluate

eval_results = task_evaluator.compute(
    model_or_pipeline="lvwerra/distilbert-imdb",
    data=data,
    metric=evaluate.combine(["accuracy", "recall", "precision", "f1"]),
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)
print(eval_results)
`,highlighted:`<span class="hljs-keyword">import</span> evaluate

eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>,
    data=data,
    metric=evaluate.combine([<span class="hljs-string">&quot;accuracy&quot;</span>, <span class="hljs-string">&quot;recall&quot;</span>, <span class="hljs-string">&quot;precision&quot;</span>, <span class="hljs-string">&quot;f1&quot;</span>]),
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)
<span class="hljs-built_in">print</span>(eval_results)
`}}),it=new $e({props:{code:`{
    'accuracy': 0.918,
    'f1': 0.916,
    'precision': 0.9147,
    'recall': 0.9187,
    'latency_in_seconds': 0.01274,
    'samples_per_second': 78.887,
    'total_time_in_seconds': 12.676
}`,highlighted:`{
    <span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.918</span>,
    <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.916</span>,
    <span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.9147</span>,
    <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.9187</span>,
    <span class="hljs-string">&#x27;latency_in_seconds&#x27;</span>: <span class="hljs-number">0.01274</span>,
    <span class="hljs-string">&#x27;samples_per_second&#x27;</span>: <span class="hljs-number">78.887</span>,
    <span class="hljs-string">&#x27;total_time_in_seconds&#x27;</span>: <span class="hljs-number">12.676</span>
}`}}),rt=new ie({}),ct=new ie({}),pt=new $e({props:{code:`import pandas as pd
from datasets import load_dataset
from evaluate import evaluator
from transformers import pipeline

models = [
    "xlm-roberta-large-finetuned-conll03-english",
    "dbmdz/bert-large-cased-finetuned-conll03-english",
    "elastic/distilbert-base-uncased-finetuned-conll03-english",
    "dbmdz/electra-large-discriminator-finetuned-conll03-english",
    "gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner",
    "philschmid/distilroberta-base-ner-conll2003",
    "Jorgeutd/albert-base-v2-finetuned-ner",
]

data = load_dataset("conll2003", split="validation").shuffle().select(1000)
task_evaluator = evaluator("token-classification")

results = []
for model in models:
    results.append(
        task_evaluator.compute(
            model_or_pipeline=model, data=data, metric="seqeval", join_by=" "
            )
        )

df = pd.DataFrame(results, index=models)
df[["overall_f1", "overall_accuracy", "total_time_in_seconds", "samples_per_second", "latency_in_seconds"]]`,highlighted:`<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

models = [
    <span class="hljs-string">&quot;xlm-roberta-large-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;elastic/distilbert-base-uncased-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;dbmdz/electra-large-discriminator-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner&quot;</span>,
    <span class="hljs-string">&quot;philschmid/distilroberta-base-ner-conll2003&quot;</span>,
    <span class="hljs-string">&quot;Jorgeutd/albert-base-v2-finetuned-ner&quot;</span>,
]

data = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>).shuffle().select(<span class="hljs-number">1000</span>)
task_evaluator = evaluator(<span class="hljs-string">&quot;token-classification&quot;</span>)

results = []
<span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> models:
    results.append(
        task_evaluator.compute(
            model_or_pipeline=model, data=data, metric=<span class="hljs-string">&quot;seqeval&quot;</span>, join_by=<span class="hljs-string">&quot; &quot;</span>
            )
        )

df = pd.DataFrame(results, index=models)
df[[<span class="hljs-string">&quot;overall_f1&quot;</span>, <span class="hljs-string">&quot;overall_accuracy&quot;</span>, <span class="hljs-string">&quot;total_time_in_seconds&quot;</span>, <span class="hljs-string">&quot;samples_per_second&quot;</span>, <span class="hljs-string">&quot;latency_in_seconds&quot;</span>]]`}}),Be=new Dh({props:{warning:!0,$$slots:{default:[Ih]},$$scope:{ctx:ss}}}),dt=new ie({}),ht=new ie({}),ut=new $e({props:{code:`from datasets import load_dataset
from evaluate import evaluator

task_evaluator = evaluator("question-answering")

data = load_dataset("squad", split="validation[:1000]")
eval_results = task_evaluator.compute(
    model_or_pipeline="distilbert-base-uncased-distilled-squad",
    data=data,
    metric="squad",
    strategy="bootstrap",
    n_resamples=30
)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator

task_evaluator = evaluator(<span class="hljs-string">&quot;question-answering&quot;</span>)

data = load_dataset(<span class="hljs-string">&quot;squad&quot;</span>, split=<span class="hljs-string">&quot;validation[:1000]&quot;</span>)
eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;distilbert-base-uncased-distilled-squad&quot;</span>,
    data=data,
    metric=<span class="hljs-string">&quot;squad&quot;</span>,
    strategy=<span class="hljs-string">&quot;bootstrap&quot;</span>,
    n_resamples=<span class="hljs-number">30</span>
)`}}),ft=new $e({props:{code:`{
    'exact_match': 
    {
        'confidence_interval': (79.67, 84.54),
        'score': 82.30,
        'standard_error': 1.28
    },
    'f1': 
    {
        'confidence_interval': (85.30, 88.88),
        'score': 87.23,
        'standard_error': 0.97
    },
    'latency_in_seconds': 0.0085,
    'samples_per_second': 117.31,
    'total_time_in_seconds': 8.52
 }`,highlighted:`{
    <span class="hljs-string">&#x27;exact_match&#x27;</span>: 
    {
        <span class="hljs-string">&#x27;confidence_interval&#x27;</span>: (<span class="hljs-number">79.67</span>, <span class="hljs-number">84.54</span>),
        <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">82.30</span>,
        <span class="hljs-string">&#x27;standard_error&#x27;</span>: <span class="hljs-number">1.28</span>
    },
    <span class="hljs-string">&#x27;f1&#x27;</span>: 
    {
        <span class="hljs-string">&#x27;confidence_interval&#x27;</span>: (<span class="hljs-number">85.30</span>, <span class="hljs-number">88.88</span>),
        <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">87.23</span>,
        <span class="hljs-string">&#x27;standard_error&#x27;</span>: <span class="hljs-number">0.97</span>
    },
    <span class="hljs-string">&#x27;latency_in_seconds&#x27;</span>: <span class="hljs-number">0.0085</span>,
    <span class="hljs-string">&#x27;samples_per_second&#x27;</span>: <span class="hljs-number">117.31</span>,
    <span class="hljs-string">&#x27;total_time_in_seconds&#x27;</span>: <span class="hljs-number">8.52</span>
 }`}}),mt=new ie({}),_t=new ie({}),gt=new $e({props:{code:`data = load_dataset("imagenet-1k", split="validation", use_auth_token=True)

pipe = pipeline(
    task="image-classification",
    model="facebook/deit-small-distilled-patch16-224"
)

task_evaluator = evaluator("image-classification")
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric="accuracy",
    label_mapping=pipe.model.config.label2id
)`,highlighted:`data = load_dataset(<span class="hljs-string">&quot;imagenet-1k&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>, use_auth_token=<span class="hljs-literal">True</span>)

pipe = pipeline(
    task=<span class="hljs-string">&quot;image-classification&quot;</span>,
    model=<span class="hljs-string">&quot;facebook/deit-small-distilled-patch16-224&quot;</span>
)

task_evaluator = evaluator(<span class="hljs-string">&quot;image-classification&quot;</span>)
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric=<span class="hljs-string">&quot;accuracy&quot;</span>,
    label_mapping=pipe.model.config.label2id
)`}}),{c(){E=l("meta"),qe=r(),j=l("h1"),G=l("a"),re=l("span"),f(M.$$.fragment),k=r(),te=l("span"),Je=n("Using the evaluator"),je=r(),w=l("p"),Ye=n("The "),ce=l("code"),pe=n("Evaluator"),Ke=n(" classes allow to evaluate a  triplet of model, dataset, and metric. The models wrapped in a pipeline, responsible for handling all preprocessing and post-processing and out-of-the-box, "),de=l("code"),he=n("Evaluator"),Xe=n("s support transformers pipelines for the supported tasks, but custom pipelines can be passed, as showcased in the section "),B=l("a"),le=n("Using the "),ue=l("code"),u=n("evaluator"),S=n(" with custom models"),Et=n("."),R=r(),fe=l("p"),wt=n("Currently supported tasks are:"),Ze=r(),T=l("ul"),ae=l("li"),Xa=l("code"),vo=n('"text-classification"'),_o=n(": will use the "),yt=l("a"),go=n("TextClassificationEvaluator"),bo=n("."),Eo=r(),Te=l("li"),Za=l("code"),wo=n('"token-classification"'),yo=n(": will use the "),kt=l("a"),ko=n("TokenClassificationEvaluator"),$o=n("."),qo=r(),xe=l("li"),el=l("code"),jo=n('"question-answering"'),To=n(": will use the "),$t=l("a"),xo=n("QuestionAnsweringEvaluator"),Do=n("."),Io=r(),De=l("li"),tl=l("code"),Po=n('"image-classification"'),Co=n(": will use the "),qt=l("a"),Ao=n("ImageClassificationEvaluator"),Oo=n("."),os=r(),jt=l("p"),No=n("Each task has its own set of requirements for the dataset format and pipeline output, make sure to check them out for your custom use case. Let\u2019s have a look at each one of them and see how you can use the evaluator to evalute a single or multiple of models, datasets, and metrics at the same time."),ns=r(),me=l("h2"),Ie=l("a"),al=l("span"),f(et.$$.fragment),So=r(),ll=l("span"),Lo=n("Text classification"),is=r(),Tt=l("p"),Ho=n("The text classification evaluator can be used to evaluate text models on classification datasets such as IMDb. Beside the model, data, and metric inputs it takes the following optional inputs:"),rs=r(),se=l("ul"),xt=l("li"),sl=l("code"),Bo=n('input_column="text"'),Ro=n(": with this argument the column with the data for the pipeline can be specified."),Wo=r(),Dt=l("li"),ol=l("code"),zo=n('label_column="label"'),Go=n(": with this argument the column with the labels for the evaluation can be specified."),Mo=r(),$=l("li"),nl=l("code"),Uo=n("label_mapping=None"),Vo=n(": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),il=l("code"),Fo=n("label_column"),Qo=n(" can be integers ("),rl=l("code"),Jo=n("0"),Yo=n("/"),cl=l("code"),Ko=n("1"),Xo=n(") whereas the pipeline can produce label names such as "),pl=l("code"),Zo=n('"positive"'),en=n("/"),dl=l("code"),tn=n('"negative"'),an=n(". With that dictionary the pipeline outputs are mapped to the labels."),cs=r(),Pe=l("p"),ln=n("By default the "),hl=l("code"),sn=n('"accuracy"'),on=n(" metric is computed."),ps=r(),ve=l("h3"),Ce=l("a"),ul=l("span"),f(tt.$$.fragment),nn=r(),fl=l("span"),rn=n("Evaluate models on the Hub"),ds=r(),U=l("p"),cn=n("There are several ways to pass a model to the evaluator: you can pass the name of a model on the Hub, you can load a "),ml=l("code"),pn=n("transformers"),dn=n(" model and pass it to the evaluator or you can pass an initialized "),vl=l("code"),hn=n("transformers.Pipeline"),un=n(". Alternatively you can pass any callable function that behaves like a "),_l=l("code"),fn=n("pipeline"),mn=n(" call for the task in any framework."),hs=r(),It=l("p"),vn=n("So any of the following works:"),us=r(),f(at.$$.fragment),fs=r(),Pt=l("p"),_n=n("The results will always look as follows:"),ms=r(),f(lt.$$.fragment),vs=r(),Ct=l("p"),gn=n("The results will look as follows:"),_s=r(),f(st.$$.fragment),gs=r(),At=l("p"),bn=n("Note that evaluation results include both the requested metric, and information about the time it took to obtain predictions through the pipeline. These additional time metrics give an useful first information on model speed for inference."),bs=r(),_e=l("h3"),Ae=l("a"),gl=l("span"),f(ot.$$.fragment),En=r(),bl=l("span"),wn=n("Evaluate multiple metrics"),Es=r(),Oe=l("p"),yn=n("With the "),El=l("code"),kn=n("combine"),$n=n(" function one can bundle several metrics into an object that behaves like a single metric. We can use this to evaluate several metrics at once in an evaluator:"),ws=r(),f(nt.$$.fragment),ys=r(),Ot=l("p"),qn=n("The results will look as follows:"),ks=r(),f(it.$$.fragment),$s=r(),Nt=l("p"),jn=n("Next let\u2019s have a look at token classification."),qs=r(),ge=l("h2"),Ne=l("a"),wl=l("span"),f(rt.$$.fragment),Tn=r(),yl=l("span"),xn=n("Token Classification"),js=r(),St=l("p"),Dn=n("With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),Ts=r(),V=l("ul"),Lt=l("li"),kl=l("code"),In=n('input_column="text"'),Pn=n(": with this argument the column with the data for the pipeline can be specified."),Cn=r(),Ht=l("li"),$l=l("code"),An=n('label_column="label"'),On=n(": with this argument the column with the labels for the evaluation can be specified."),Nn=r(),q=l("li"),ql=l("code"),Sn=n("label_mapping=None"),Ln=n(": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),jl=l("code"),Hn=n("label_column"),Bn=n(" can be integers ("),Tl=l("code"),Rn=n("0"),Wn=n("/"),xl=l("code"),zn=n("1"),Gn=n(") whereas the pipeline can produce label names such as "),Dl=l("code"),Mn=n('"positive"'),Un=n("/"),Il=l("code"),Vn=n('"negative"'),Fn=n(". With that dictionary the pipeline outputs are mapped to the labels."),Qn=r(),Bt=l("li"),Pl=l("code"),Jn=n('join_by=" "'),Yn=n(": While most datasets are already tokenized the pipeline expects a string. Thus the tokens need to be joined before passing to the pipeline. By default they are joined with a whitespace."),xs=r(),Rt=l("p"),Kn=n("Let\u2019s have a look how we can use the evaluator to benchmark several models."),Ds=r(),be=l("h3"),Se=l("a"),Cl=l("span"),f(ct.$$.fragment),Xn=r(),Al=l("span"),Zn=n("Benchmarking several models"),Is=r(),Le=l("p"),ei=n("Here is an example where several models can be compared thanks to the "),Ol=l("code"),ti=n("Evaluator"),ai=n(" in only a few lines of code, abstracting away the preprocessing, inference, postprocessing, metric computation:"),Ps=r(),f(pt.$$.fragment),Cs=r(),Wt=l("p"),li=n("Results:"),As=r(),He=l("table"),Nl=l("thead"),x=l("tr"),zt=l("th"),si=n("model"),oi=r(),Gt=l("th"),ni=n("overall_f1"),ii=r(),Mt=l("th"),ri=n("overall_accuracy"),ci=r(),Ut=l("th"),pi=n("total_time_in_seconds"),di=r(),Vt=l("th"),hi=n("samples_per_second"),ui=r(),Ft=l("th"),fi=n("latency_in_seconds"),mi=r(),y=l("tbody"),D=l("tr"),Qt=l("td"),vi=n("Jorgeutd/albert-base-v2-finetuned-ner"),_i=r(),Jt=l("td"),gi=n("0.941"),bi=r(),Yt=l("td"),Ei=n("0.989"),wi=r(),Kt=l("td"),yi=n("4.515"),ki=r(),Xt=l("td"),$i=n("221.468"),qi=r(),Zt=l("td"),ji=n("0.005"),Ti=r(),I=l("tr"),ea=l("td"),xi=n("dbmdz/bert-large-cased-finetuned-conll03-english"),Di=r(),ta=l("td"),Ii=n("0.962"),Pi=r(),aa=l("td"),Ci=n("0.881"),Ai=r(),la=l("td"),Oi=n("11.648"),Ni=r(),sa=l("td"),Si=n("85.850"),Li=r(),oa=l("td"),Hi=n("0.012"),Bi=r(),P=l("tr"),na=l("td"),Ri=n("dbmdz/electra-large-discriminator-finetuned-conll03-english"),Wi=r(),ia=l("td"),zi=n("0.965"),Gi=r(),ra=l("td"),Mi=n("0.881"),Ui=r(),ca=l("td"),Vi=n("11.456"),Fi=r(),pa=l("td"),Qi=n("87.292"),Ji=r(),da=l("td"),Yi=n("0.011"),Ki=r(),C=l("tr"),ha=l("td"),Xi=n("elastic/distilbert-base-uncased-finetuned-conll03-english"),Zi=r(),ua=l("td"),er=n("0.940"),tr=r(),fa=l("td"),ar=n("0.989"),lr=r(),ma=l("td"),sr=n("2.318"),or=r(),va=l("td"),nr=n("431.378"),ir=r(),_a=l("td"),rr=n("0.002"),cr=r(),A=l("tr"),ga=l("td"),pr=n("gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner"),dr=r(),ba=l("td"),hr=n("0.947"),ur=r(),Ea=l("td"),fr=n("0.991"),mr=r(),wa=l("td"),vr=n("2.376"),_r=r(),ya=l("td"),gr=n("420.873"),br=r(),ka=l("td"),Er=n("0.002"),wr=r(),O=l("tr"),$a=l("td"),yr=n("philschmid/distilroberta-base-ner-conll2003"),kr=r(),qa=l("td"),$r=n("0.961"),qr=r(),ja=l("td"),jr=n("0.994"),Tr=r(),Ta=l("td"),xr=n("2.436"),Dr=r(),xa=l("td"),Ir=n("410.579"),Pr=r(),Da=l("td"),Cr=n("0.002"),Ar=r(),N=l("tr"),Ia=l("td"),Or=n("xlm-roberta-large-finetuned-conll03-english"),Nr=r(),Pa=l("td"),Sr=n("0.969"),Lr=r(),Ca=l("td"),Hr=n("0.882"),Br=r(),Aa=l("td"),Rr=n("11.996"),Wr=r(),Oa=l("td"),zr=n("83.359"),Gr=r(),Na=l("td"),Mr=n("0.012"),Os=r(),f(Be.$$.fragment),Ns=r(),Ee=l("h2"),Re=l("a"),Sl=l("span"),f(dt.$$.fragment),Ur=r(),Ll=l("span"),Vr=n("Question Answering"),Ss=r(),Sa=l("p"),Fr=n("With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),Ls=r(),L=l("ul"),La=l("li"),Hl=l("code"),Qr=n('question_column="question"'),Jr=n(": the name of the column containing the question in the dataset"),Yr=r(),Ha=l("li"),Bl=l("code"),Kr=n('context_column="context"'),Xr=n(": the name of the column containing the context"),Zr=r(),Ba=l("li"),Rl=l("code"),ec=n('id_column="id"'),tc=n(": the name of the column cointaing the identification field of the question and answer pair"),ac=r(),Ra=l("li"),Wl=l("code"),lc=n('label_column="answers"'),sc=n(": the name of the column containing the answers"),oc=r(),Wa=l("li"),zl=l("code"),nc=n("squad_v2_format=None"),ic=n(": whether the dataset follows the format of squad_v2 dataset where a question may have no answer in the context. If this parameter is not provided, the format will be automatically inferred."),Hs=r(),za=l("p"),rc=n("Let\u2019s have a look how we can evaluate QA models and compute confidence intervals at the same time."),Bs=r(),we=l("h3"),We=l("a"),Gl=l("span"),f(ht.$$.fragment),cc=r(),Ml=l("span"),pc=n("Confidence intervals"),Rs=n('\n\nEvery evaluator comes with the options to compute confidence intervals using [bootstrapping](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html). Simply pass `strategy="bootstrap"` and set the number of resanmples with `n_resamples`.\n\n	'),f(ut.$$.fragment),Ws=r(),Ga=l("p"),dc=n("Results include confidence intervals as well as error estimates as follows:"),zs=r(),f(ft.$$.fragment),Gs=r(),ye=l("h2"),ze=l("a"),Ul=l("span"),f(mt.$$.fragment),hc=r(),Vl=l("span"),uc=n("Image classification"),Ms=r(),Ma=l("p"),fc=n("With the image classification evaluator we can evaluate any image classifier. It uses the same keyword arguments at the text classifier:"),Us=r(),oe=l("ul"),Ua=l("li"),Fl=l("code"),mc=n('input_column="image"'),vc=n(": the name of the column containing the images as PIL ImageFile"),_c=r(),Va=l("li"),Ql=l("code"),gc=n('label_column="label"'),bc=n(": the name of the column containing the labels"),Ec=r(),vt=l("li"),Jl=l("code"),wc=n("label_mapping=None"),yc=n(": We want to map class labels defined by the model in the pipeline to values consistent with those defined in the "),Yl=l("code"),kc=n("label_column"),Vs=r(),Fa=l("p"),$c=n("Let\u2019s have a look at how can evaluate image classification models on large datasets."),Fs=r(),ke=l("h3"),Ge=l("a"),Kl=l("span"),f(_t.$$.fragment),qc=r(),Xl=l("span"),jc=n("Handling large datasets"),Qs=r(),Qa=l("p"),Tc=n("The evaluator can be used on large datasets! Below, an example shows how to use it on ImageNet-1k for image classification. Beware that this example will require to download ~150 GB."),Js=r(),Ja=l("p"),xc=n("Without specifying a device, the default will be the first GPU if available, else CPU."),Ys=r(),f(gt.$$.fragment),Ks=r(),Me=l("p"),Dc=n("Since we are using "),Zl=l("code"),Ic=n("datasets"),Pc=n(" to store data we make use of a technique called memory mappings. This means that the dataset is never fully loaded into memory which saves a lot of RAM. Running the above code only uses roughly 1.5 GB of RAM while the validation split is more than 30 GB big."),this.h()},l(t){const p=Th('[data-svelte="svelte-1phssyn"]',document.head);E=s(p,"META",{name:!0,content:!0}),p.forEach(a),qe=c(t),j=s(t,"H1",{class:!0});var bt=o(j);G=s(bt,"A",{id:!0,class:!0,href:!0});var Mc=o(G);re=s(Mc,"SPAN",{});var Uc=o(re);m(M.$$.fragment,Uc),Uc.forEach(a),Mc.forEach(a),k=c(bt),te=s(bt,"SPAN",{});var Vc=o(te);Je=i(Vc,"Using the evaluator"),Vc.forEach(a),bt.forEach(a),je=c(t),w=s(t,"P",{});var Ue=o(w);Ye=i(Ue,"The "),ce=s(Ue,"CODE",{});var Fc=o(ce);pe=i(Fc,"Evaluator"),Fc.forEach(a),Ke=i(Ue," classes allow to evaluate a  triplet of model, dataset, and metric. The models wrapped in a pipeline, responsible for handling all preprocessing and post-processing and out-of-the-box, "),de=s(Ue,"CODE",{});var Qc=o(de);he=i(Qc,"Evaluator"),Qc.forEach(a),Xe=i(Ue,"s support transformers pipelines for the supported tasks, but custom pipelines can be passed, as showcased in the section "),B=s(Ue,"A",{href:!0});var Zs=o(B);le=i(Zs,"Using the "),ue=s(Zs,"CODE",{});var Jc=o(ue);u=i(Jc,"evaluator"),Jc.forEach(a),S=i(Zs," with custom models"),Zs.forEach(a),Et=i(Ue,"."),Ue.forEach(a),R=c(t),fe=s(t,"P",{});var Yc=o(fe);wt=i(Yc,"Currently supported tasks are:"),Yc.forEach(a),Ze=c(t),T=s(t,"UL",{});var Ve=o(T);ae=s(Ve,"LI",{});var es=o(ae);Xa=s(es,"CODE",{});var Kc=o(Xa);vo=i(Kc,'"text-classification"'),Kc.forEach(a),_o=i(es,": will use the "),yt=s(es,"A",{href:!0});var Xc=o(yt);go=i(Xc,"TextClassificationEvaluator"),Xc.forEach(a),bo=i(es,"."),es.forEach(a),Eo=c(Ve),Te=s(Ve,"LI",{});var ts=o(Te);Za=s(ts,"CODE",{});var Zc=o(Za);wo=i(Zc,'"token-classification"'),Zc.forEach(a),yo=i(ts,": will use the "),kt=s(ts,"A",{href:!0});var ep=o(kt);ko=i(ep,"TokenClassificationEvaluator"),ep.forEach(a),$o=i(ts,"."),ts.forEach(a),qo=c(Ve),xe=s(Ve,"LI",{});var as=o(xe);el=s(as,"CODE",{});var tp=o(el);jo=i(tp,'"question-answering"'),tp.forEach(a),To=i(as,": will use the "),$t=s(as,"A",{href:!0});var ap=o($t);xo=i(ap,"QuestionAnsweringEvaluator"),ap.forEach(a),Do=i(as,"."),as.forEach(a),Io=c(Ve),De=s(Ve,"LI",{});var ls=o(De);tl=s(ls,"CODE",{});var lp=o(tl);Po=i(lp,'"image-classification"'),lp.forEach(a),Co=i(ls,": will use the "),qt=s(ls,"A",{href:!0});var sp=o(qt);Ao=i(sp,"ImageClassificationEvaluator"),sp.forEach(a),Oo=i(ls,"."),ls.forEach(a),Ve.forEach(a),os=c(t),jt=s(t,"P",{});var op=o(jt);No=i(op,"Each task has its own set of requirements for the dataset format and pipeline output, make sure to check them out for your custom use case. Let\u2019s have a look at each one of them and see how you can use the evaluator to evalute a single or multiple of models, datasets, and metrics at the same time."),op.forEach(a),ns=c(t),me=s(t,"H2",{class:!0});var eo=o(me);Ie=s(eo,"A",{id:!0,class:!0,href:!0});var np=o(Ie);al=s(np,"SPAN",{});var ip=o(al);m(et.$$.fragment,ip),ip.forEach(a),np.forEach(a),So=c(eo),ll=s(eo,"SPAN",{});var rp=o(ll);Lo=i(rp,"Text classification"),rp.forEach(a),eo.forEach(a),is=c(t),Tt=s(t,"P",{});var cp=o(Tt);Ho=i(cp,"The text classification evaluator can be used to evaluate text models on classification datasets such as IMDb. Beside the model, data, and metric inputs it takes the following optional inputs:"),cp.forEach(a),rs=c(t),se=s(t,"UL",{});var Ya=o(se);xt=s(Ya,"LI",{});var Cc=o(xt);sl=s(Cc,"CODE",{});var pp=o(sl);Bo=i(pp,'input_column="text"'),pp.forEach(a),Ro=i(Cc,": with this argument the column with the data for the pipeline can be specified."),Cc.forEach(a),Wo=c(Ya),Dt=s(Ya,"LI",{});var Ac=o(Dt);ol=s(Ac,"CODE",{});var dp=o(ol);zo=i(dp,'label_column="label"'),dp.forEach(a),Go=i(Ac,": with this argument the column with the labels for the evaluation can be specified."),Ac.forEach(a),Mo=c(Ya),$=s(Ya,"LI",{});var W=o($);nl=s(W,"CODE",{});var hp=o(nl);Uo=i(hp,"label_mapping=None"),hp.forEach(a),Vo=i(W,": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),il=s(W,"CODE",{});var up=o(il);Fo=i(up,"label_column"),up.forEach(a),Qo=i(W," can be integers ("),rl=s(W,"CODE",{});var fp=o(rl);Jo=i(fp,"0"),fp.forEach(a),Yo=i(W,"/"),cl=s(W,"CODE",{});var mp=o(cl);Ko=i(mp,"1"),mp.forEach(a),Xo=i(W,") whereas the pipeline can produce label names such as "),pl=s(W,"CODE",{});var vp=o(pl);Zo=i(vp,'"positive"'),vp.forEach(a),en=i(W,"/"),dl=s(W,"CODE",{});var _p=o(dl);tn=i(_p,'"negative"'),_p.forEach(a),an=i(W,". With that dictionary the pipeline outputs are mapped to the labels."),W.forEach(a),Ya.forEach(a),cs=c(t),Pe=s(t,"P",{});var to=o(Pe);ln=i(to,"By default the "),hl=s(to,"CODE",{});var gp=o(hl);sn=i(gp,'"accuracy"'),gp.forEach(a),on=i(to," metric is computed."),to.forEach(a),ps=c(t),ve=s(t,"H3",{class:!0});var ao=o(ve);Ce=s(ao,"A",{id:!0,class:!0,href:!0});var bp=o(Ce);ul=s(bp,"SPAN",{});var Ep=o(ul);m(tt.$$.fragment,Ep),Ep.forEach(a),bp.forEach(a),nn=c(ao),fl=s(ao,"SPAN",{});var wp=o(fl);rn=i(wp,"Evaluate models on the Hub"),wp.forEach(a),ao.forEach(a),ds=c(t),U=s(t,"P",{});var Fe=o(U);cn=i(Fe,"There are several ways to pass a model to the evaluator: you can pass the name of a model on the Hub, you can load a "),ml=s(Fe,"CODE",{});var yp=o(ml);pn=i(yp,"transformers"),yp.forEach(a),dn=i(Fe," model and pass it to the evaluator or you can pass an initialized "),vl=s(Fe,"CODE",{});var kp=o(vl);hn=i(kp,"transformers.Pipeline"),kp.forEach(a),un=i(Fe,". Alternatively you can pass any callable function that behaves like a "),_l=s(Fe,"CODE",{});var $p=o(_l);fn=i($p,"pipeline"),$p.forEach(a),mn=i(Fe," call for the task in any framework."),Fe.forEach(a),hs=c(t),It=s(t,"P",{});var qp=o(It);vn=i(qp,"So any of the following works:"),qp.forEach(a),us=c(t),m(at.$$.fragment,t),fs=c(t),Pt=s(t,"P",{});var jp=o(Pt);_n=i(jp,"The results will always look as follows:"),jp.forEach(a),ms=c(t),m(lt.$$.fragment,t),vs=c(t),Ct=s(t,"P",{});var Tp=o(Ct);gn=i(Tp,"The results will look as follows:"),Tp.forEach(a),_s=c(t),m(st.$$.fragment,t),gs=c(t),At=s(t,"P",{});var xp=o(At);bn=i(xp,"Note that evaluation results include both the requested metric, and information about the time it took to obtain predictions through the pipeline. These additional time metrics give an useful first information on model speed for inference."),xp.forEach(a),bs=c(t),_e=s(t,"H3",{class:!0});var lo=o(_e);Ae=s(lo,"A",{id:!0,class:!0,href:!0});var Dp=o(Ae);gl=s(Dp,"SPAN",{});var Ip=o(gl);m(ot.$$.fragment,Ip),Ip.forEach(a),Dp.forEach(a),En=c(lo),bl=s(lo,"SPAN",{});var Pp=o(bl);wn=i(Pp,"Evaluate multiple metrics"),Pp.forEach(a),lo.forEach(a),Es=c(t),Oe=s(t,"P",{});var so=o(Oe);yn=i(so,"With the "),El=s(so,"CODE",{});var Cp=o(El);kn=i(Cp,"combine"),Cp.forEach(a),$n=i(so," function one can bundle several metrics into an object that behaves like a single metric. We can use this to evaluate several metrics at once in an evaluator:"),so.forEach(a),ws=c(t),m(nt.$$.fragment,t),ys=c(t),Ot=s(t,"P",{});var Ap=o(Ot);qn=i(Ap,"The results will look as follows:"),Ap.forEach(a),ks=c(t),m(it.$$.fragment,t),$s=c(t),Nt=s(t,"P",{});var Op=o(Nt);jn=i(Op,"Next let\u2019s have a look at token classification."),Op.forEach(a),qs=c(t),ge=s(t,"H2",{class:!0});var oo=o(ge);Ne=s(oo,"A",{id:!0,class:!0,href:!0});var Np=o(Ne);wl=s(Np,"SPAN",{});var Sp=o(wl);m(rt.$$.fragment,Sp),Sp.forEach(a),Np.forEach(a),Tn=c(oo),yl=s(oo,"SPAN",{});var Lp=o(yl);xn=i(Lp,"Token Classification"),Lp.forEach(a),oo.forEach(a),js=c(t),St=s(t,"P",{});var Hp=o(St);Dn=i(Hp,"With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),Hp.forEach(a),Ts=c(t),V=s(t,"UL",{});var Qe=o(V);Lt=s(Qe,"LI",{});var Oc=o(Lt);kl=s(Oc,"CODE",{});var Bp=o(kl);In=i(Bp,'input_column="text"'),Bp.forEach(a),Pn=i(Oc,": with this argument the column with the data for the pipeline can be specified."),Oc.forEach(a),Cn=c(Qe),Ht=s(Qe,"LI",{});var Nc=o(Ht);$l=s(Nc,"CODE",{});var Rp=o($l);An=i(Rp,'label_column="label"'),Rp.forEach(a),On=i(Nc,": with this argument the column with the labels for the evaluation can be specified."),Nc.forEach(a),Nn=c(Qe),q=s(Qe,"LI",{});var z=o(q);ql=s(z,"CODE",{});var Wp=o(ql);Sn=i(Wp,"label_mapping=None"),Wp.forEach(a),Ln=i(z,": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),jl=s(z,"CODE",{});var zp=o(jl);Hn=i(zp,"label_column"),zp.forEach(a),Bn=i(z," can be integers ("),Tl=s(z,"CODE",{});var Gp=o(Tl);Rn=i(Gp,"0"),Gp.forEach(a),Wn=i(z,"/"),xl=s(z,"CODE",{});var Mp=o(xl);zn=i(Mp,"1"),Mp.forEach(a),Gn=i(z,") whereas the pipeline can produce label names such as "),Dl=s(z,"CODE",{});var Up=o(Dl);Mn=i(Up,'"positive"'),Up.forEach(a),Un=i(z,"/"),Il=s(z,"CODE",{});var Vp=o(Il);Vn=i(Vp,'"negative"'),Vp.forEach(a),Fn=i(z,". With that dictionary the pipeline outputs are mapped to the labels."),z.forEach(a),Qn=c(Qe),Bt=s(Qe,"LI",{});var Sc=o(Bt);Pl=s(Sc,"CODE",{});var Fp=o(Pl);Jn=i(Fp,'join_by=" "'),Fp.forEach(a),Yn=i(Sc,": While most datasets are already tokenized the pipeline expects a string. Thus the tokens need to be joined before passing to the pipeline. By default they are joined with a whitespace."),Sc.forEach(a),Qe.forEach(a),xs=c(t),Rt=s(t,"P",{});var Qp=o(Rt);Kn=i(Qp,"Let\u2019s have a look how we can use the evaluator to benchmark several models."),Qp.forEach(a),Ds=c(t),be=s(t,"H3",{class:!0});var no=o(be);Se=s(no,"A",{id:!0,class:!0,href:!0});var Jp=o(Se);Cl=s(Jp,"SPAN",{});var Yp=o(Cl);m(ct.$$.fragment,Yp),Yp.forEach(a),Jp.forEach(a),Xn=c(no),Al=s(no,"SPAN",{});var Kp=o(Al);Zn=i(Kp,"Benchmarking several models"),Kp.forEach(a),no.forEach(a),Is=c(t),Le=s(t,"P",{});var io=o(Le);ei=i(io,"Here is an example where several models can be compared thanks to the "),Ol=s(io,"CODE",{});var Xp=o(Ol);ti=i(Xp,"Evaluator"),Xp.forEach(a),ai=i(io," in only a few lines of code, abstracting away the preprocessing, inference, postprocessing, metric computation:"),io.forEach(a),Ps=c(t),m(pt.$$.fragment,t),Cs=c(t),Wt=s(t,"P",{});var Zp=o(Wt);li=i(Zp,"Results:"),Zp.forEach(a),As=c(t),He=s(t,"TABLE",{});var ro=o(He);Nl=s(ro,"THEAD",{});var ed=o(Nl);x=s(ed,"TR",{});var F=o(x);zt=s(F,"TH",{align:!0});var td=o(zt);si=i(td,"model"),td.forEach(a),oi=c(F),Gt=s(F,"TH",{align:!0});var ad=o(Gt);ni=i(ad,"overall_f1"),ad.forEach(a),ii=c(F),Mt=s(F,"TH",{align:!0});var ld=o(Mt);ri=i(ld,"overall_accuracy"),ld.forEach(a),ci=c(F),Ut=s(F,"TH",{align:!0});var sd=o(Ut);pi=i(sd,"total_time_in_seconds"),sd.forEach(a),di=c(F),Vt=s(F,"TH",{align:!0});var od=o(Vt);hi=i(od,"samples_per_second"),od.forEach(a),ui=c(F),Ft=s(F,"TH",{align:!0});var nd=o(Ft);fi=i(nd,"latency_in_seconds"),nd.forEach(a),F.forEach(a),ed.forEach(a),mi=c(ro),y=s(ro,"TBODY",{});var H=o(y);D=s(H,"TR",{});var Q=o(D);Qt=s(Q,"TD",{align:!0});var id=o(Qt);vi=i(id,"Jorgeutd/albert-base-v2-finetuned-ner"),id.forEach(a),_i=c(Q),Jt=s(Q,"TD",{align:!0});var rd=o(Jt);gi=i(rd,"0.941"),rd.forEach(a),bi=c(Q),Yt=s(Q,"TD",{align:!0});var cd=o(Yt);Ei=i(cd,"0.989"),cd.forEach(a),wi=c(Q),Kt=s(Q,"TD",{align:!0});var pd=o(Kt);yi=i(pd,"4.515"),pd.forEach(a),ki=c(Q),Xt=s(Q,"TD",{align:!0});var dd=o(Xt);$i=i(dd,"221.468"),dd.forEach(a),qi=c(Q),Zt=s(Q,"TD",{align:!0});var hd=o(Zt);ji=i(hd,"0.005"),hd.forEach(a),Q.forEach(a),Ti=c(H),I=s(H,"TR",{});var J=o(I);ea=s(J,"TD",{align:!0});var ud=o(ea);xi=i(ud,"dbmdz/bert-large-cased-finetuned-conll03-english"),ud.forEach(a),Di=c(J),ta=s(J,"TD",{align:!0});var fd=o(ta);Ii=i(fd,"0.962"),fd.forEach(a),Pi=c(J),aa=s(J,"TD",{align:!0});var md=o(aa);Ci=i(md,"0.881"),md.forEach(a),Ai=c(J),la=s(J,"TD",{align:!0});var vd=o(la);Oi=i(vd,"11.648"),vd.forEach(a),Ni=c(J),sa=s(J,"TD",{align:!0});var _d=o(sa);Si=i(_d,"85.850"),_d.forEach(a),Li=c(J),oa=s(J,"TD",{align:!0});var gd=o(oa);Hi=i(gd,"0.012"),gd.forEach(a),J.forEach(a),Bi=c(H),P=s(H,"TR",{});var Y=o(P);na=s(Y,"TD",{align:!0});var bd=o(na);Ri=i(bd,"dbmdz/electra-large-discriminator-finetuned-conll03-english"),bd.forEach(a),Wi=c(Y),ia=s(Y,"TD",{align:!0});var Ed=o(ia);zi=i(Ed,"0.965"),Ed.forEach(a),Gi=c(Y),ra=s(Y,"TD",{align:!0});var wd=o(ra);Mi=i(wd,"0.881"),wd.forEach(a),Ui=c(Y),ca=s(Y,"TD",{align:!0});var yd=o(ca);Vi=i(yd,"11.456"),yd.forEach(a),Fi=c(Y),pa=s(Y,"TD",{align:!0});var kd=o(pa);Qi=i(kd,"87.292"),kd.forEach(a),Ji=c(Y),da=s(Y,"TD",{align:!0});var $d=o(da);Yi=i($d,"0.011"),$d.forEach(a),Y.forEach(a),Ki=c(H),C=s(H,"TR",{});var K=o(C);ha=s(K,"TD",{align:!0});var qd=o(ha);Xi=i(qd,"elastic/distilbert-base-uncased-finetuned-conll03-english"),qd.forEach(a),Zi=c(K),ua=s(K,"TD",{align:!0});var jd=o(ua);er=i(jd,"0.940"),jd.forEach(a),tr=c(K),fa=s(K,"TD",{align:!0});var Td=o(fa);ar=i(Td,"0.989"),Td.forEach(a),lr=c(K),ma=s(K,"TD",{align:!0});var xd=o(ma);sr=i(xd,"2.318"),xd.forEach(a),or=c(K),va=s(K,"TD",{align:!0});var Dd=o(va);nr=i(Dd,"431.378"),Dd.forEach(a),ir=c(K),_a=s(K,"TD",{align:!0});var Id=o(_a);rr=i(Id,"0.002"),Id.forEach(a),K.forEach(a),cr=c(H),A=s(H,"TR",{});var X=o(A);ga=s(X,"TD",{align:!0});var Pd=o(ga);pr=i(Pd,"gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner"),Pd.forEach(a),dr=c(X),ba=s(X,"TD",{align:!0});var Cd=o(ba);hr=i(Cd,"0.947"),Cd.forEach(a),ur=c(X),Ea=s(X,"TD",{align:!0});var Ad=o(Ea);fr=i(Ad,"0.991"),Ad.forEach(a),mr=c(X),wa=s(X,"TD",{align:!0});var Od=o(wa);vr=i(Od,"2.376"),Od.forEach(a),_r=c(X),ya=s(X,"TD",{align:!0});var Nd=o(ya);gr=i(Nd,"420.873"),Nd.forEach(a),br=c(X),ka=s(X,"TD",{align:!0});var Sd=o(ka);Er=i(Sd,"0.002"),Sd.forEach(a),X.forEach(a),wr=c(H),O=s(H,"TR",{});var Z=o(O);$a=s(Z,"TD",{align:!0});var Ld=o($a);yr=i(Ld,"philschmid/distilroberta-base-ner-conll2003"),Ld.forEach(a),kr=c(Z),qa=s(Z,"TD",{align:!0});var Hd=o(qa);$r=i(Hd,"0.961"),Hd.forEach(a),qr=c(Z),ja=s(Z,"TD",{align:!0});var Bd=o(ja);jr=i(Bd,"0.994"),Bd.forEach(a),Tr=c(Z),Ta=s(Z,"TD",{align:!0});var Rd=o(Ta);xr=i(Rd,"2.436"),Rd.forEach(a),Dr=c(Z),xa=s(Z,"TD",{align:!0});var Wd=o(xa);Ir=i(Wd,"410.579"),Wd.forEach(a),Pr=c(Z),Da=s(Z,"TD",{align:!0});var zd=o(Da);Cr=i(zd,"0.002"),zd.forEach(a),Z.forEach(a),Ar=c(H),N=s(H,"TR",{});var ee=o(N);Ia=s(ee,"TD",{align:!0});var Gd=o(Ia);Or=i(Gd,"xlm-roberta-large-finetuned-conll03-english"),Gd.forEach(a),Nr=c(ee),Pa=s(ee,"TD",{align:!0});var Md=o(Pa);Sr=i(Md,"0.969"),Md.forEach(a),Lr=c(ee),Ca=s(ee,"TD",{align:!0});var Ud=o(Ca);Hr=i(Ud,"0.882"),Ud.forEach(a),Br=c(ee),Aa=s(ee,"TD",{align:!0});var Vd=o(Aa);Rr=i(Vd,"11.996"),Vd.forEach(a),Wr=c(ee),Oa=s(ee,"TD",{align:!0});var Fd=o(Oa);zr=i(Fd,"83.359"),Fd.forEach(a),Gr=c(ee),Na=s(ee,"TD",{align:!0});var Qd=o(Na);Mr=i(Qd,"0.012"),Qd.forEach(a),ee.forEach(a),H.forEach(a),ro.forEach(a),Os=c(t),m(Be.$$.fragment,t),Ns=c(t),Ee=s(t,"H2",{class:!0});var co=o(Ee);Re=s(co,"A",{id:!0,class:!0,href:!0});var Jd=o(Re);Sl=s(Jd,"SPAN",{});var Yd=o(Sl);m(dt.$$.fragment,Yd),Yd.forEach(a),Jd.forEach(a),Ur=c(co),Ll=s(co,"SPAN",{});var Kd=o(Ll);Vr=i(Kd,"Question Answering"),Kd.forEach(a),co.forEach(a),Ss=c(t),Sa=s(t,"P",{});var Xd=o(Sa);Fr=i(Xd,"With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),Xd.forEach(a),Ls=c(t),L=s(t,"UL",{});var ne=o(L);La=s(ne,"LI",{});var Lc=o(La);Hl=s(Lc,"CODE",{});var Zd=o(Hl);Qr=i(Zd,'question_column="question"'),Zd.forEach(a),Jr=i(Lc,": the name of the column containing the question in the dataset"),Lc.forEach(a),Yr=c(ne),Ha=s(ne,"LI",{});var Hc=o(Ha);Bl=s(Hc,"CODE",{});var eh=o(Bl);Kr=i(eh,'context_column="context"'),eh.forEach(a),Xr=i(Hc,": the name of the column containing the context"),Hc.forEach(a),Zr=c(ne),Ba=s(ne,"LI",{});var Bc=o(Ba);Rl=s(Bc,"CODE",{});var th=o(Rl);ec=i(th,'id_column="id"'),th.forEach(a),tc=i(Bc,": the name of the column cointaing the identification field of the question and answer pair"),Bc.forEach(a),ac=c(ne),Ra=s(ne,"LI",{});var Rc=o(Ra);Wl=s(Rc,"CODE",{});var ah=o(Wl);lc=i(ah,'label_column="answers"'),ah.forEach(a),sc=i(Rc,": the name of the column containing the answers"),Rc.forEach(a),oc=c(ne),Wa=s(ne,"LI",{});var Wc=o(Wa);zl=s(Wc,"CODE",{});var lh=o(zl);nc=i(lh,"squad_v2_format=None"),lh.forEach(a),ic=i(Wc,": whether the dataset follows the format of squad_v2 dataset where a question may have no answer in the context. If this parameter is not provided, the format will be automatically inferred."),Wc.forEach(a),ne.forEach(a),Hs=c(t),za=s(t,"P",{});var sh=o(za);rc=i(sh,"Let\u2019s have a look how we can evaluate QA models and compute confidence intervals at the same time."),sh.forEach(a),Bs=c(t),we=s(t,"H3",{class:!0});var po=o(we);We=s(po,"A",{id:!0,class:!0,href:!0});var oh=o(We);Gl=s(oh,"SPAN",{});var nh=o(Gl);m(ht.$$.fragment,nh),nh.forEach(a),oh.forEach(a),cc=c(po),Ml=s(po,"SPAN",{});var ih=o(Ml);pc=i(ih,"Confidence intervals"),ih.forEach(a),po.forEach(a),Rs=i(t,'\n\nEvery evaluator comes with the options to compute confidence intervals using [bootstrapping](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html). Simply pass `strategy="bootstrap"` and set the number of resanmples with `n_resamples`.\n\n	'),m(ut.$$.fragment,t),Ws=c(t),Ga=s(t,"P",{});var rh=o(Ga);dc=i(rh,"Results include confidence intervals as well as error estimates as follows:"),rh.forEach(a),zs=c(t),m(ft.$$.fragment,t),Gs=c(t),ye=s(t,"H2",{class:!0});var ho=o(ye);ze=s(ho,"A",{id:!0,class:!0,href:!0});var ch=o(ze);Ul=s(ch,"SPAN",{});var ph=o(Ul);m(mt.$$.fragment,ph),ph.forEach(a),ch.forEach(a),hc=c(ho),Vl=s(ho,"SPAN",{});var dh=o(Vl);uc=i(dh,"Image classification"),dh.forEach(a),ho.forEach(a),Ms=c(t),Ma=s(t,"P",{});var hh=o(Ma);fc=i(hh,"With the image classification evaluator we can evaluate any image classifier. It uses the same keyword arguments at the text classifier:"),hh.forEach(a),Us=c(t),oe=s(t,"UL",{});var Ka=o(oe);Ua=s(Ka,"LI",{});var zc=o(Ua);Fl=s(zc,"CODE",{});var uh=o(Fl);mc=i(uh,'input_column="image"'),uh.forEach(a),vc=i(zc,": the name of the column containing the images as PIL ImageFile"),zc.forEach(a),_c=c(Ka),Va=s(Ka,"LI",{});var Gc=o(Va);Ql=s(Gc,"CODE",{});var fh=o(Ql);gc=i(fh,'label_column="label"'),fh.forEach(a),bc=i(Gc,": the name of the column containing the labels"),Gc.forEach(a),Ec=c(Ka),vt=s(Ka,"LI",{});var uo=o(vt);Jl=s(uo,"CODE",{});var mh=o(Jl);wc=i(mh,"label_mapping=None"),mh.forEach(a),yc=i(uo,": We want to map class labels defined by the model in the pipeline to values consistent with those defined in the "),Yl=s(uo,"CODE",{});var vh=o(Yl);kc=i(vh,"label_column"),vh.forEach(a),uo.forEach(a),Ka.forEach(a),Vs=c(t),Fa=s(t,"P",{});var _h=o(Fa);$c=i(_h,"Let\u2019s have a look at how can evaluate image classification models on large datasets."),_h.forEach(a),Fs=c(t),ke=s(t,"H3",{class:!0});var fo=o(ke);Ge=s(fo,"A",{id:!0,class:!0,href:!0});var gh=o(Ge);Kl=s(gh,"SPAN",{});var bh=o(Kl);m(_t.$$.fragment,bh),bh.forEach(a),gh.forEach(a),qc=c(fo),Xl=s(fo,"SPAN",{});var Eh=o(Xl);jc=i(Eh,"Handling large datasets"),Eh.forEach(a),fo.forEach(a),Qs=c(t),Qa=s(t,"P",{});var wh=o(Qa);Tc=i(wh,"The evaluator can be used on large datasets! Below, an example shows how to use it on ImageNet-1k for image classification. Beware that this example will require to download ~150 GB."),wh.forEach(a),Js=c(t),Ja=s(t,"P",{});var yh=o(Ja);xc=i(yh,"Without specifying a device, the default will be the first GPU if available, else CPU."),yh.forEach(a),Ys=c(t),m(gt.$$.fragment,t),Ks=c(t),Me=s(t,"P",{});var mo=o(Me);Dc=i(mo,"Since we are using "),Zl=s(mo,"CODE",{});var kh=o(Zl);Ic=i(kh,"datasets"),kh.forEach(a),Pc=i(mo," to store data we make use of a technique called memory mappings. This means that the dataset is never fully loaded into memory which saves a lot of RAM. Running the above code only uses roughly 1.5 GB of RAM while the validation split is more than 30 GB big."),mo.forEach(a),this.h()},h(){h(E,"name","hf:doc:metadata"),h(E,"content",JSON.stringify(Ch)),h(G,"id","using-the-evaluator"),h(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(G,"href","#using-the-evaluator"),h(j,"class","relative group"),h(B,"href","custom_evaluator"),h(yt,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.TextClassificationEvaluator"),h(kt,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.TokenClassificationEvaluator"),h($t,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.QuestionAnsweringEvaluator"),h(qt,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.ImageClassificationEvaluator"),h(Ie,"id","text-classification"),h(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ie,"href","#text-classification"),h(me,"class","relative group"),h(Ce,"id","evaluate-models-on-the-hub"),h(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ce,"href","#evaluate-models-on-the-hub"),h(ve,"class","relative group"),h(Ae,"id","evaluate-multiple-metrics"),h(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ae,"href","#evaluate-multiple-metrics"),h(_e,"class","relative group"),h(Ne,"id","token-classification"),h(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ne,"href","#token-classification"),h(ge,"class","relative group"),h(Se,"id","benchmarking-several-models"),h(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Se,"href","#benchmarking-several-models"),h(be,"class","relative group"),h(zt,"align","left"),h(Gt,"align","right"),h(Mt,"align","right"),h(Ut,"align","right"),h(Vt,"align","right"),h(Ft,"align","right"),h(Qt,"align","left"),h(Jt,"align","right"),h(Yt,"align","right"),h(Kt,"align","right"),h(Xt,"align","right"),h(Zt,"align","right"),h(ea,"align","left"),h(ta,"align","right"),h(aa,"align","right"),h(la,"align","right"),h(sa,"align","right"),h(oa,"align","right"),h(na,"align","left"),h(ia,"align","right"),h(ra,"align","right"),h(ca,"align","right"),h(pa,"align","right"),h(da,"align","right"),h(ha,"align","left"),h(ua,"align","right"),h(fa,"align","right"),h(ma,"align","right"),h(va,"align","right"),h(_a,"align","right"),h(ga,"align","left"),h(ba,"align","right"),h(Ea,"align","right"),h(wa,"align","right"),h(ya,"align","right"),h(ka,"align","right"),h($a,"align","left"),h(qa,"align","right"),h(ja,"align","right"),h(Ta,"align","right"),h(xa,"align","right"),h(Da,"align","right"),h(Ia,"align","left"),h(Pa,"align","right"),h(Ca,"align","right"),h(Aa,"align","right"),h(Oa,"align","right"),h(Na,"align","right"),h(Re,"id","question-answering"),h(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Re,"href","#question-answering"),h(Ee,"class","relative group"),h(We,"id","confidence-intervals"),h(We,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(We,"href","#confidence-intervals"),h(we,"class","relative group"),h(ze,"id","image-classification"),h(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ze,"href","#image-classification"),h(ye,"class","relative group"),h(Ge,"id","handling-large-datasets"),h(Ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ge,"href","#handling-large-datasets"),h(ke,"class","relative group")},m(t,p){e(document.head,E),d(t,qe,p),d(t,j,p),e(j,G),e(G,re),v(M,re,null),e(j,k),e(j,te),e(te,Je),d(t,je,p),d(t,w,p),e(w,Ye),e(w,ce),e(ce,pe),e(w,Ke),e(w,de),e(de,he),e(w,Xe),e(w,B),e(B,le),e(B,ue),e(ue,u),e(B,S),e(w,Et),d(t,R,p),d(t,fe,p),e(fe,wt),d(t,Ze,p),d(t,T,p),e(T,ae),e(ae,Xa),e(Xa,vo),e(ae,_o),e(ae,yt),e(yt,go),e(ae,bo),e(T,Eo),e(T,Te),e(Te,Za),e(Za,wo),e(Te,yo),e(Te,kt),e(kt,ko),e(Te,$o),e(T,qo),e(T,xe),e(xe,el),e(el,jo),e(xe,To),e(xe,$t),e($t,xo),e(xe,Do),e(T,Io),e(T,De),e(De,tl),e(tl,Po),e(De,Co),e(De,qt),e(qt,Ao),e(De,Oo),d(t,os,p),d(t,jt,p),e(jt,No),d(t,ns,p),d(t,me,p),e(me,Ie),e(Ie,al),v(et,al,null),e(me,So),e(me,ll),e(ll,Lo),d(t,is,p),d(t,Tt,p),e(Tt,Ho),d(t,rs,p),d(t,se,p),e(se,xt),e(xt,sl),e(sl,Bo),e(xt,Ro),e(se,Wo),e(se,Dt),e(Dt,ol),e(ol,zo),e(Dt,Go),e(se,Mo),e(se,$),e($,nl),e(nl,Uo),e($,Vo),e($,il),e(il,Fo),e($,Qo),e($,rl),e(rl,Jo),e($,Yo),e($,cl),e(cl,Ko),e($,Xo),e($,pl),e(pl,Zo),e($,en),e($,dl),e(dl,tn),e($,an),d(t,cs,p),d(t,Pe,p),e(Pe,ln),e(Pe,hl),e(hl,sn),e(Pe,on),d(t,ps,p),d(t,ve,p),e(ve,Ce),e(Ce,ul),v(tt,ul,null),e(ve,nn),e(ve,fl),e(fl,rn),d(t,ds,p),d(t,U,p),e(U,cn),e(U,ml),e(ml,pn),e(U,dn),e(U,vl),e(vl,hn),e(U,un),e(U,_l),e(_l,fn),e(U,mn),d(t,hs,p),d(t,It,p),e(It,vn),d(t,us,p),v(at,t,p),d(t,fs,p),d(t,Pt,p),e(Pt,_n),d(t,ms,p),v(lt,t,p),d(t,vs,p),d(t,Ct,p),e(Ct,gn),d(t,_s,p),v(st,t,p),d(t,gs,p),d(t,At,p),e(At,bn),d(t,bs,p),d(t,_e,p),e(_e,Ae),e(Ae,gl),v(ot,gl,null),e(_e,En),e(_e,bl),e(bl,wn),d(t,Es,p),d(t,Oe,p),e(Oe,yn),e(Oe,El),e(El,kn),e(Oe,$n),d(t,ws,p),v(nt,t,p),d(t,ys,p),d(t,Ot,p),e(Ot,qn),d(t,ks,p),v(it,t,p),d(t,$s,p),d(t,Nt,p),e(Nt,jn),d(t,qs,p),d(t,ge,p),e(ge,Ne),e(Ne,wl),v(rt,wl,null),e(ge,Tn),e(ge,yl),e(yl,xn),d(t,js,p),d(t,St,p),e(St,Dn),d(t,Ts,p),d(t,V,p),e(V,Lt),e(Lt,kl),e(kl,In),e(Lt,Pn),e(V,Cn),e(V,Ht),e(Ht,$l),e($l,An),e(Ht,On),e(V,Nn),e(V,q),e(q,ql),e(ql,Sn),e(q,Ln),e(q,jl),e(jl,Hn),e(q,Bn),e(q,Tl),e(Tl,Rn),e(q,Wn),e(q,xl),e(xl,zn),e(q,Gn),e(q,Dl),e(Dl,Mn),e(q,Un),e(q,Il),e(Il,Vn),e(q,Fn),e(V,Qn),e(V,Bt),e(Bt,Pl),e(Pl,Jn),e(Bt,Yn),d(t,xs,p),d(t,Rt,p),e(Rt,Kn),d(t,Ds,p),d(t,be,p),e(be,Se),e(Se,Cl),v(ct,Cl,null),e(be,Xn),e(be,Al),e(Al,Zn),d(t,Is,p),d(t,Le,p),e(Le,ei),e(Le,Ol),e(Ol,ti),e(Le,ai),d(t,Ps,p),v(pt,t,p),d(t,Cs,p),d(t,Wt,p),e(Wt,li),d(t,As,p),d(t,He,p),e(He,Nl),e(Nl,x),e(x,zt),e(zt,si),e(x,oi),e(x,Gt),e(Gt,ni),e(x,ii),e(x,Mt),e(Mt,ri),e(x,ci),e(x,Ut),e(Ut,pi),e(x,di),e(x,Vt),e(Vt,hi),e(x,ui),e(x,Ft),e(Ft,fi),e(He,mi),e(He,y),e(y,D),e(D,Qt),e(Qt,vi),e(D,_i),e(D,Jt),e(Jt,gi),e(D,bi),e(D,Yt),e(Yt,Ei),e(D,wi),e(D,Kt),e(Kt,yi),e(D,ki),e(D,Xt),e(Xt,$i),e(D,qi),e(D,Zt),e(Zt,ji),e(y,Ti),e(y,I),e(I,ea),e(ea,xi),e(I,Di),e(I,ta),e(ta,Ii),e(I,Pi),e(I,aa),e(aa,Ci),e(I,Ai),e(I,la),e(la,Oi),e(I,Ni),e(I,sa),e(sa,Si),e(I,Li),e(I,oa),e(oa,Hi),e(y,Bi),e(y,P),e(P,na),e(na,Ri),e(P,Wi),e(P,ia),e(ia,zi),e(P,Gi),e(P,ra),e(ra,Mi),e(P,Ui),e(P,ca),e(ca,Vi),e(P,Fi),e(P,pa),e(pa,Qi),e(P,Ji),e(P,da),e(da,Yi),e(y,Ki),e(y,C),e(C,ha),e(ha,Xi),e(C,Zi),e(C,ua),e(ua,er),e(C,tr),e(C,fa),e(fa,ar),e(C,lr),e(C,ma),e(ma,sr),e(C,or),e(C,va),e(va,nr),e(C,ir),e(C,_a),e(_a,rr),e(y,cr),e(y,A),e(A,ga),e(ga,pr),e(A,dr),e(A,ba),e(ba,hr),e(A,ur),e(A,Ea),e(Ea,fr),e(A,mr),e(A,wa),e(wa,vr),e(A,_r),e(A,ya),e(ya,gr),e(A,br),e(A,ka),e(ka,Er),e(y,wr),e(y,O),e(O,$a),e($a,yr),e(O,kr),e(O,qa),e(qa,$r),e(O,qr),e(O,ja),e(ja,jr),e(O,Tr),e(O,Ta),e(Ta,xr),e(O,Dr),e(O,xa),e(xa,Ir),e(O,Pr),e(O,Da),e(Da,Cr),e(y,Ar),e(y,N),e(N,Ia),e(Ia,Or),e(N,Nr),e(N,Pa),e(Pa,Sr),e(N,Lr),e(N,Ca),e(Ca,Hr),e(N,Br),e(N,Aa),e(Aa,Rr),e(N,Wr),e(N,Oa),e(Oa,zr),e(N,Gr),e(N,Na),e(Na,Mr),d(t,Os,p),v(Be,t,p),d(t,Ns,p),d(t,Ee,p),e(Ee,Re),e(Re,Sl),v(dt,Sl,null),e(Ee,Ur),e(Ee,Ll),e(Ll,Vr),d(t,Ss,p),d(t,Sa,p),e(Sa,Fr),d(t,Ls,p),d(t,L,p),e(L,La),e(La,Hl),e(Hl,Qr),e(La,Jr),e(L,Yr),e(L,Ha),e(Ha,Bl),e(Bl,Kr),e(Ha,Xr),e(L,Zr),e(L,Ba),e(Ba,Rl),e(Rl,ec),e(Ba,tc),e(L,ac),e(L,Ra),e(Ra,Wl),e(Wl,lc),e(Ra,sc),e(L,oc),e(L,Wa),e(Wa,zl),e(zl,nc),e(Wa,ic),d(t,Hs,p),d(t,za,p),e(za,rc),d(t,Bs,p),d(t,we,p),e(we,We),e(We,Gl),v(ht,Gl,null),e(we,cc),e(we,Ml),e(Ml,pc),d(t,Rs,p),v(ut,t,p),d(t,Ws,p),d(t,Ga,p),e(Ga,dc),d(t,zs,p),v(ft,t,p),d(t,Gs,p),d(t,ye,p),e(ye,ze),e(ze,Ul),v(mt,Ul,null),e(ye,hc),e(ye,Vl),e(Vl,uc),d(t,Ms,p),d(t,Ma,p),e(Ma,fc),d(t,Us,p),d(t,oe,p),e(oe,Ua),e(Ua,Fl),e(Fl,mc),e(Ua,vc),e(oe,_c),e(oe,Va),e(Va,Ql),e(Ql,gc),e(Va,bc),e(oe,Ec),e(oe,vt),e(vt,Jl),e(Jl,wc),e(vt,yc),e(vt,Yl),e(Yl,kc),d(t,Vs,p),d(t,Fa,p),e(Fa,$c),d(t,Fs,p),d(t,ke,p),e(ke,Ge),e(Ge,Kl),v(_t,Kl,null),e(ke,qc),e(ke,Xl),e(Xl,jc),d(t,Qs,p),d(t,Qa,p),e(Qa,Tc),d(t,Js,p),d(t,Ja,p),e(Ja,xc),d(t,Ys,p),v(gt,t,p),d(t,Ks,p),d(t,Me,p),e(Me,Dc),e(Me,Zl),e(Zl,Ic),e(Me,Pc),Xs=!0},p(t,[p]){const bt={};p&2&&(bt.$$scope={dirty:p,ctx:t}),Be.$set(bt)},i(t){Xs||(_(M.$$.fragment,t),_(et.$$.fragment,t),_(tt.$$.fragment,t),_(at.$$.fragment,t),_(lt.$$.fragment,t),_(st.$$.fragment,t),_(ot.$$.fragment,t),_(nt.$$.fragment,t),_(it.$$.fragment,t),_(rt.$$.fragment,t),_(ct.$$.fragment,t),_(pt.$$.fragment,t),_(Be.$$.fragment,t),_(dt.$$.fragment,t),_(ht.$$.fragment,t),_(ut.$$.fragment,t),_(ft.$$.fragment,t),_(mt.$$.fragment,t),_(_t.$$.fragment,t),_(gt.$$.fragment,t),Xs=!0)},o(t){g(M.$$.fragment,t),g(et.$$.fragment,t),g(tt.$$.fragment,t),g(at.$$.fragment,t),g(lt.$$.fragment,t),g(st.$$.fragment,t),g(ot.$$.fragment,t),g(nt.$$.fragment,t),g(it.$$.fragment,t),g(rt.$$.fragment,t),g(ct.$$.fragment,t),g(pt.$$.fragment,t),g(Be.$$.fragment,t),g(dt.$$.fragment,t),g(ht.$$.fragment,t),g(ut.$$.fragment,t),g(ft.$$.fragment,t),g(mt.$$.fragment,t),g(_t.$$.fragment,t),g(gt.$$.fragment,t),Xs=!1},d(t){a(E),t&&a(qe),t&&a(j),b(M),t&&a(je),t&&a(w),t&&a(R),t&&a(fe),t&&a(Ze),t&&a(T),t&&a(os),t&&a(jt),t&&a(ns),t&&a(me),b(et),t&&a(is),t&&a(Tt),t&&a(rs),t&&a(se),t&&a(cs),t&&a(Pe),t&&a(ps),t&&a(ve),b(tt),t&&a(ds),t&&a(U),t&&a(hs),t&&a(It),t&&a(us),b(at,t),t&&a(fs),t&&a(Pt),t&&a(ms),b(lt,t),t&&a(vs),t&&a(Ct),t&&a(_s),b(st,t),t&&a(gs),t&&a(At),t&&a(bs),t&&a(_e),b(ot),t&&a(Es),t&&a(Oe),t&&a(ws),b(nt,t),t&&a(ys),t&&a(Ot),t&&a(ks),b(it,t),t&&a($s),t&&a(Nt),t&&a(qs),t&&a(ge),b(rt),t&&a(js),t&&a(St),t&&a(Ts),t&&a(V),t&&a(xs),t&&a(Rt),t&&a(Ds),t&&a(be),b(ct),t&&a(Is),t&&a(Le),t&&a(Ps),b(pt,t),t&&a(Cs),t&&a(Wt),t&&a(As),t&&a(He),t&&a(Os),b(Be,t),t&&a(Ns),t&&a(Ee),b(dt),t&&a(Ss),t&&a(Sa),t&&a(Ls),t&&a(L),t&&a(Hs),t&&a(za),t&&a(Bs),t&&a(we),b(ht),t&&a(Rs),b(ut,t),t&&a(Ws),t&&a(Ga),t&&a(zs),b(ft,t),t&&a(Gs),t&&a(ye),b(mt),t&&a(Ms),t&&a(Ma),t&&a(Us),t&&a(oe),t&&a(Vs),t&&a(Fa),t&&a(Fs),t&&a(ke),b(_t),t&&a(Qs),t&&a(Qa),t&&a(Js),t&&a(Ja),t&&a(Ys),b(gt,t),t&&a(Ks),t&&a(Me)}}}const Ch={local:"using-the-evaluator",sections:[{local:"text-classification",sections:[{local:"evaluate-models-on-the-hub",title:"Evaluate models on the Hub"},{local:"evaluate-multiple-metrics",title:"Evaluate multiple metrics"}],title:"Text classification"},{local:"token-classification",sections:[{local:"benchmarking-several-models",title:"Benchmarking several models"}],title:"Token Classification"},{local:"question-answering",sections:[{local:"confidence-intervals",title:"Confidence intervals"}],title:"Question Answering"},{local:"image-classification",sections:[{local:"handling-large-datasets",title:"Handling large datasets"}],title:"Image classification"}],title:"Using the evaluator"};function Ah(ss){return xh(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Hh extends $h{constructor(E){super();qh(this,E,Ah,Ph,jh,{})}}export{Hh as default,Ch as metadata};
