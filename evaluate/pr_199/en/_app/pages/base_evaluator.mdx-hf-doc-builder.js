import{S as Lh,i as Hh,s as Bh,e as l,k as r,w as u,t as n,M as Rh,c as s,d as a,m as c,a as o,x as f,h as i,b as d,G as e,g as h,y as m,q as v,o as _,B as g,v as Wh}from"../chunks/vendor-hf-doc-builder.js";import{T as zh}from"../chunks/Tip-hf-doc-builder.js";import{I as Z}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ne}from"../chunks/CodeBlock-hf-doc-builder.js";function Gh(Fl){let E,ce;return{c(){E=l("p"),ce=n("The time performances should be taken with a grain of salt: they include all the processing that goes on in the pipeline. This may include tokenizing, post-processing, that may be different depending on the model. Furthermore, it depends a lot on the hardware you are running the evaluation on and you may be able to improve the performance by optimizing things like the batch size.")},l(y){E=s(y,"P",{});var O=o(E);ce=i(O,"The time performances should be taken with a grain of salt: they include all the processing that goes on in the pipeline. This may include tokenizing, post-processing, that may be different depending on the model. Furthermore, it depends a lot on the hardware you are running the evaluation on and you may be able to improve the performance by optimizing things like the batch size."),O.forEach(a)},m(y,O){h(y,E,O),e(E,ce)},d(y){y&&a(E)}}}function Vh(Fl){let E,ce,y,O,Na,Se,no,lt,io,Sa,ro,Ql,L,co,La,po,ho,Ha,uo,fo,pe,mo,Ba,vo,_o,go,Jl,st,bo,Yl,H,de,Ra,Eo,wo,ot,ko,yo,$o,he,Wa,jo,qo,nt,To,xo,Do,ue,za,Po,Co,it,Io,Ao,Oo,fe,Ga,No,So,rt,Lo,Ho,Kl,ct,Bo,Xl,ee,me,Va,Le,Ro,Ua,Wo,Zl,pt,zo,es,Y,dt,Ma,Go,Vo,Uo,ht,Fa,Mo,Fo,Qo,w,Qa,Jo,Yo,Ja,Ko,Xo,Ya,Zo,en,Ka,tn,an,Xa,ln,sn,Za,on,nn,ts,ve,rn,el,cn,pn,as,te,_e,tl,He,dn,al,hn,ls,B,un,ll,fn,mn,sl,vn,_n,ol,gn,bn,ss,ut,En,os,Be,ns,ft,wn,is,Re,rs,mt,kn,cs,ae,ge,nl,We,yn,il,$n,ps,be,jn,vt,qn,Tn,ds,ze,hs,_t,xn,us,Ge,fs,gt,Dn,ms,le,Ee,rl,Ve,Pn,cl,Cn,vs,bt,In,_s,R,Et,pl,An,On,Nn,wt,dl,Sn,Ln,Hn,k,hl,Bn,Rn,ul,Wn,zn,fl,Gn,Vn,ml,Un,Mn,vl,Fn,Qn,_l,Jn,Yn,Kn,kt,gl,Xn,Zn,gs,yt,ei,bs,se,we,bl,Ue,ti,El,ai,Es,ke,li,wl,si,oi,ws,Me,ks,$t,ni,ys,ye,kl,$,jt,ii,ri,qt,ci,pi,Tt,di,hi,xt,ui,fi,Dt,mi,vi,Pt,_i,gi,b,j,Ct,bi,Ei,It,wi,ki,At,yi,$i,Ot,ji,qi,Nt,Ti,xi,St,Di,Pi,q,Lt,Ci,Ii,Ht,Ai,Oi,Bt,Ni,Si,Rt,Li,Hi,Wt,Bi,Ri,zt,Wi,zi,T,Gt,Gi,Vi,Vt,Ui,Mi,Ut,Fi,Qi,Mt,Ji,Yi,Ft,Ki,Xi,Qt,Zi,er,x,Jt,tr,ar,Yt,lr,sr,Kt,or,nr,Xt,ir,rr,Zt,cr,pr,ea,dr,hr,D,ta,ur,fr,aa,mr,vr,la,_r,gr,sa,br,Er,oa,wr,kr,na,yr,$r,P,ia,jr,qr,ra,Tr,xr,ca,Dr,Pr,pa,Cr,Ir,da,Ar,Or,ha,Nr,Sr,C,ua,Lr,Hr,fa,Br,Rr,ma,Wr,zr,va,Gr,Vr,_a,Ur,Mr,ga,Fr,$s,$e,js,oe,je,yl,Fe,Qr,$l,Jr,qs,ba,Yr,Ts,I,Ea,jl,Kr,Xr,Zr,wa,ql,ec,tc,ac,ka,Tl,lc,sc,oc,ya,xl,nc,ic,rc,$a,Dl,cc,pc,xs,ja,dc,Ds,ne,qe,Pl,Qe,hc,Cl,uc,Ps,W,fc,Je,mc,vc,Il,_c,gc,Al,bc,Ec,Cs,Ye,Is,qa,wc,As,Ke,Os,ie,Te,Ol,Xe,kc,Nl,yc,Ns,Ta,$c,Ss,K,xa,Sl,jc,qc,Tc,Da,Ll,xc,Dc,Pc,Ze,Hl,Cc,Ic,Bl,Ac,Ls,Pa,Oc,Hs,re,xe,Rl,et,Nc,Wl,Sc,Bs,Ca,Lc,Rs,Ia,Hc,Ws,tt,zs,De,Bc,zl,Rc,Wc,Gs;return Se=new Z({}),Le=new Z({}),He=new Z({}),Be=new Ne({props:{code:`from datasets import load_dataset
from evaluate import evaluator
from transformers import AutoModelForSequenceClassification, pipeline

data = load_dataset("imdb", split="test").shuffle(seed=42).select(range(1000))
task_evaluator = evaluator("text-classification")

# 1. Pass a model name or path
eval_results = task_evaluator.compute(
    model_or_pipeline="lvwerra/distilbert-imdb",
    data=data,
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)

# 2. Pass an instantiated model
model = AutoModelForSequenceClassification.from_pretrained("lvwerra/distilbert-imdb")

eval_results = task_evaluator.compute(
    model_or_pipeline=model,
    data=data,
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)

# 3. Pass an instantiated pipeline 
pipe = pipeline("text-classification", model="lvwerra/distilbert-imdb")

eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)
print(eval_results)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification, pipeline

data = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>, split=<span class="hljs-string">&quot;test&quot;</span>).shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
task_evaluator = evaluator(<span class="hljs-string">&quot;text-classification&quot;</span>)

<span class="hljs-comment"># 1. Pass a model name or path</span>
eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>,
    data=data,
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)

<span class="hljs-comment"># 2. Pass an instantiated model</span>
model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>)

eval_results = task_evaluator.compute(
    model_or_pipeline=model,
    data=data,
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)

<span class="hljs-comment"># 3. Pass an instantiated pipeline </span>
pipe = pipeline(<span class="hljs-string">&quot;text-classification&quot;</span>, model=<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>)

eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)
<span class="hljs-built_in">print</span>(eval_results)`}}),Re=new Ne({props:{code:`{
    'accuracy': 0.918,
    'latency_in_seconds': 0.013,
    'samples_per_second': 78.887,
    'total_time_in_seconds': 12.676
}`,highlighted:`{
    <span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.918</span>,
    <span class="hljs-string">&#x27;latency_in_seconds&#x27;</span>: <span class="hljs-number">0.013</span>,
    <span class="hljs-string">&#x27;samples_per_second&#x27;</span>: <span class="hljs-number">78.887</span>,
    <span class="hljs-string">&#x27;total_time_in_seconds&#x27;</span>: <span class="hljs-number">12.676</span>
}`}}),We=new Z({}),ze=new Ne({props:{code:`import evaluate

eval_results = task_evaluator.compute(
    model_or_pipeline="lvwerra/distilbert-imdb",
    data=data,
    metric=evaluate.combine(["accuracy", "recall", "precision", "f1"]),
    label_mapping={"NEGATIVE": 0, "POSITIVE": 1}
)
print(eval_results)
`,highlighted:`<span class="hljs-keyword">import</span> evaluate

eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;lvwerra/distilbert-imdb&quot;</span>,
    data=data,
    metric=evaluate.combine([<span class="hljs-string">&quot;accuracy&quot;</span>, <span class="hljs-string">&quot;recall&quot;</span>, <span class="hljs-string">&quot;precision&quot;</span>, <span class="hljs-string">&quot;f1&quot;</span>]),
    label_mapping={<span class="hljs-string">&quot;NEGATIVE&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;POSITIVE&quot;</span>: <span class="hljs-number">1</span>}
)
<span class="hljs-built_in">print</span>(eval_results)
`}}),Ge=new Ne({props:{code:`{
    'accuracy': 0.918,
    'f1': 0.916,
    'precision': 0.9147,
    'recall': 0.9187,
    'latency_in_seconds': 0.013,
    'samples_per_second': 78.887,
    'total_time_in_seconds': 12.676
}`,highlighted:`{
    <span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.918</span>,
    <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.916</span>,
    <span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.9147</span>,
    <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.9187</span>,
    <span class="hljs-string">&#x27;latency_in_seconds&#x27;</span>: <span class="hljs-number">0.013</span>,
    <span class="hljs-string">&#x27;samples_per_second&#x27;</span>: <span class="hljs-number">78.887</span>,
    <span class="hljs-string">&#x27;total_time_in_seconds&#x27;</span>: <span class="hljs-number">12.676</span>
}`}}),Ve=new Z({}),Ue=new Z({}),Me=new Ne({props:{code:`import pandas as pd
from datasets import load_dataset
from evaluate import evaluator
from transformers import pipeline

models = [
    "xlm-roberta-large-finetuned-conll03-english",
    "dbmdz/bert-large-cased-finetuned-conll03-english",
    "elastic/distilbert-base-uncased-finetuned-conll03-english",
    "dbmdz/electra-large-discriminator-finetuned-conll03-english",
    "gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner",
    "philschmid/distilroberta-base-ner-conll2003",
    "Jorgeutd/albert-base-v2-finetuned-ner",
]

data = load_dataset("conll2003", split="validation").shuffle().select(1000)
task_evaluator = evaluator("token-classification")

results = []
for model in models:
    results.append(
        task_evaluator.compute(
            model_or_pipeline=model, data=data, metric="seqeval", join_by=" "
            )
        )

df = pd.DataFrame(results, index=models)
df[["overall_f1", "overall_accuracy", "total_time_in_seconds", "samples_per_second", "latency_in_seconds"]]`,highlighted:`<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

models = [
    <span class="hljs-string">&quot;xlm-roberta-large-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;elastic/distilbert-base-uncased-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;dbmdz/electra-large-discriminator-finetuned-conll03-english&quot;</span>,
    <span class="hljs-string">&quot;gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner&quot;</span>,
    <span class="hljs-string">&quot;philschmid/distilroberta-base-ner-conll2003&quot;</span>,
    <span class="hljs-string">&quot;Jorgeutd/albert-base-v2-finetuned-ner&quot;</span>,
]

data = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>).shuffle().select(<span class="hljs-number">1000</span>)
task_evaluator = evaluator(<span class="hljs-string">&quot;token-classification&quot;</span>)

results = []
<span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> models:
    results.append(
        task_evaluator.compute(
            model_or_pipeline=model, data=data, metric=<span class="hljs-string">&quot;seqeval&quot;</span>, join_by=<span class="hljs-string">&quot; &quot;</span>
            )
        )

df = pd.DataFrame(results, index=models)
df[[<span class="hljs-string">&quot;overall_f1&quot;</span>, <span class="hljs-string">&quot;overall_accuracy&quot;</span>, <span class="hljs-string">&quot;total_time_in_seconds&quot;</span>, <span class="hljs-string">&quot;samples_per_second&quot;</span>, <span class="hljs-string">&quot;latency_in_seconds&quot;</span>]]`}}),$e=new zh({props:{warning:!0,$$slots:{default:[Gh]},$$scope:{ctx:Fl}}}),Fe=new Z({}),Qe=new Z({}),Ye=new Ne({props:{code:`from datasets import load_dataset
from evaluate import evaluator

task_evaluator = evaluator("question-answering")

data = load_dataset("squad", split="validation[:1000]")
eval_results = task_evaluator.compute(
    model_or_pipeline="distilbert-base-uncased-distilled-squad",
    data=data,
    metric="squad",
    strategy="bootstrap",
    n_resamples=30
)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator

task_evaluator = evaluator(<span class="hljs-string">&quot;question-answering&quot;</span>)

data = load_dataset(<span class="hljs-string">&quot;squad&quot;</span>, split=<span class="hljs-string">&quot;validation[:1000]&quot;</span>)
eval_results = task_evaluator.compute(
    model_or_pipeline=<span class="hljs-string">&quot;distilbert-base-uncased-distilled-squad&quot;</span>,
    data=data,
    metric=<span class="hljs-string">&quot;squad&quot;</span>,
    strategy=<span class="hljs-string">&quot;bootstrap&quot;</span>,
    n_resamples=<span class="hljs-number">30</span>
)`}}),Ke=new Ne({props:{code:`{
    'exact_match': 
    {
        'confidence_interval': (79.67, 84.54),
        'score': 82.30,
        'standard_error': 1.28
    },
    'f1': 
    {
        'confidence_interval': (85.30, 88.88),
        'score': 87.23,
        'standard_error': 0.97
    },
    'latency_in_seconds': 0.0085,
    'samples_per_second': 117.31,
    'total_time_in_seconds': 8.52
 }`,highlighted:`{
    <span class="hljs-string">&#x27;exact_match&#x27;</span>: 
    {
        <span class="hljs-string">&#x27;confidence_interval&#x27;</span>: (<span class="hljs-number">79.67</span>, <span class="hljs-number">84.54</span>),
        <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">82.30</span>,
        <span class="hljs-string">&#x27;standard_error&#x27;</span>: <span class="hljs-number">1.28</span>
    },
    <span class="hljs-string">&#x27;f1&#x27;</span>: 
    {
        <span class="hljs-string">&#x27;confidence_interval&#x27;</span>: (<span class="hljs-number">85.30</span>, <span class="hljs-number">88.88</span>),
        <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">87.23</span>,
        <span class="hljs-string">&#x27;standard_error&#x27;</span>: <span class="hljs-number">0.97</span>
    },
    <span class="hljs-string">&#x27;latency_in_seconds&#x27;</span>: <span class="hljs-number">0.0085</span>,
    <span class="hljs-string">&#x27;samples_per_second&#x27;</span>: <span class="hljs-number">117.31</span>,
    <span class="hljs-string">&#x27;total_time_in_seconds&#x27;</span>: <span class="hljs-number">8.52</span>
 }`}}),Xe=new Z({}),et=new Z({}),tt=new Ne({props:{code:`data = load_dataset("imagenet-1k", split="validation", use_auth_token=True)

pipe = pipeline(
    task="image-classification",
    model="facebook/deit-small-distilled-patch16-224"
)

task_evaluator = evaluator("image-classification")
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric="accuracy",
    label_mapping=pipe.model.config.label2id
)`,highlighted:`data = load_dataset(<span class="hljs-string">&quot;imagenet-1k&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>, use_auth_token=<span class="hljs-literal">True</span>)

pipe = pipeline(
    task=<span class="hljs-string">&quot;image-classification&quot;</span>,
    model=<span class="hljs-string">&quot;facebook/deit-small-distilled-patch16-224&quot;</span>
)

task_evaluator = evaluator(<span class="hljs-string">&quot;image-classification&quot;</span>)
eval_results = task_evaluator.compute(
    model_or_pipeline=pipe,
    data=data,
    metric=<span class="hljs-string">&quot;accuracy&quot;</span>,
    label_mapping=pipe.model.config.label2id
)`}}),{c(){E=l("meta"),ce=r(),y=l("h1"),O=l("a"),Na=l("span"),u(Se.$$.fragment),no=r(),lt=l("span"),io=n("Using the "),Sa=l("code"),ro=n("evaluator"),Ql=r(),L=l("p"),co=n("The "),La=l("code"),po=n("Evaluator"),ho=n(" classes allow to evaluate a  triplet of model, dataset, and metric. The models wrapped in a pipeline, responsible for handling all preprocessing and post-processing and out-of-the-box, "),Ha=l("code"),uo=n("Evaluator"),fo=n("s support transformers pipelines for the supported tasks, but custom pipelines can be passed, as showcased in the section "),pe=l("a"),mo=n("Using the "),Ba=l("code"),vo=n("evaluator"),_o=n(" with custom models"),go=n("."),Jl=r(),st=l("p"),bo=n("Currently supported tasks are:"),Yl=r(),H=l("ul"),de=l("li"),Ra=l("code"),Eo=n('"text-classification"'),wo=n(": will use the "),ot=l("a"),ko=n("TextClassificationEvaluator"),yo=n("."),$o=r(),he=l("li"),Wa=l("code"),jo=n('"token-classification"'),qo=n(": will use the "),nt=l("a"),To=n("TokenClassificationEvaluator"),xo=n("."),Do=r(),ue=l("li"),za=l("code"),Po=n('"question-answering"'),Co=n(": will use the "),it=l("a"),Io=n("QuestionAnsweringEvaluator"),Ao=n("."),Oo=r(),fe=l("li"),Ga=l("code"),No=n('"image-classification"'),So=n(": will use the "),rt=l("a"),Lo=n("ImageClassificationEvaluator"),Ho=n("."),Kl=r(),ct=l("p"),Bo=n("Each task has its own set of requirements for the dataset format and pipeline output, make sure to check them out for your custom use case. Let\u2019s have a look at each one of them and see how you can use the evaluator to evalute a single or multiple of models, datasets, and metrics at the same time."),Xl=r(),ee=l("h2"),me=l("a"),Va=l("span"),u(Le.$$.fragment),Ro=r(),Ua=l("span"),Wo=n("Text classification"),Zl=r(),pt=l("p"),zo=n("The text classification evaluator can be used to evaluate text models on classification datasets such as IMDb. Beside the model, data, and metric inputs it takes the following optional inputs:"),es=r(),Y=l("ul"),dt=l("li"),Ma=l("code"),Go=n('input_column="text"'),Vo=n(": with this argument the column with the data for the pipeline can be specified."),Uo=r(),ht=l("li"),Fa=l("code"),Mo=n('label_column="label"'),Fo=n(": with this argument the column with the labels for the evaluation can be specified."),Qo=r(),w=l("li"),Qa=l("code"),Jo=n("label_mapping=None"),Yo=n(": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),Ja=l("code"),Ko=n("label_column"),Xo=n(" can be integers ("),Ya=l("code"),Zo=n("0"),en=n("/"),Ka=l("code"),tn=n("1"),an=n(") whereas the pipeline can produce label names such as "),Xa=l("code"),ln=n('"positive"'),sn=n("/"),Za=l("code"),on=n('"negative"'),nn=n(". With that dictionary the pipeline outputs are mapped to the labels."),ts=r(),ve=l("p"),rn=n("By default the "),el=l("code"),cn=n('"accuracy"'),pn=n(" metric is computed."),as=r(),te=l("h3"),_e=l("a"),tl=l("span"),u(He.$$.fragment),dn=r(),al=l("span"),hn=n("Evaluate models on the Hub"),ls=r(),B=l("p"),un=n("There are several ways to pass a model to the evaluator: you can pass the name of a model on the Hub, you can load a "),ll=l("code"),fn=n("transformers"),mn=n(" model and pass it to the evaluator or you can pass an initialized "),sl=l("code"),vn=n("transformers.Pipeline"),_n=n(". Alternatively you can pass any callable function that behaves like a "),ol=l("code"),gn=n("pipeline"),bn=n(" call for the task in any framework."),ss=r(),ut=l("p"),En=n("So any of the following works:"),os=r(),u(Be.$$.fragment),ns=r(),ft=l("p"),wn=n("The results will look as follows:"),is=r(),u(Re.$$.fragment),rs=r(),mt=l("p"),kn=n("Note that evaluation results include both the requested metric, and information about the time it took to obtain predictions through the pipeline. These additional time metrics give an useful first information on model speed for inference."),cs=r(),ae=l("h3"),ge=l("a"),nl=l("span"),u(We.$$.fragment),yn=r(),il=l("span"),$n=n("Evaluate multiple metrics"),ps=r(),be=l("p"),jn=n("With the "),vt=l("a"),qn=n("combine()"),Tn=n(" function one can bundle several metrics into an object that behaves like a single metric. We can use this to evaluate several metrics at once in an evaluator:"),ds=r(),u(ze.$$.fragment),hs=r(),_t=l("p"),xn=n("The results will look as follows:"),us=r(),u(Ge.$$.fragment),fs=r(),gt=l("p"),Dn=n("Next let\u2019s have a look at token classification."),ms=r(),le=l("h2"),Ee=l("a"),rl=l("span"),u(Ve.$$.fragment),Pn=r(),cl=l("span"),Cn=n("Token Classification"),vs=r(),bt=l("p"),In=n("With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),_s=r(),R=l("ul"),Et=l("li"),pl=l("code"),An=n('input_column="text"'),On=n(": with this argument the column with the data for the pipeline can be specified."),Nn=r(),wt=l("li"),dl=l("code"),Sn=n('label_column="label"'),Ln=n(": with this argument the column with the labels for the evaluation can be specified."),Hn=r(),k=l("li"),hl=l("code"),Bn=n("label_mapping=None"),Rn=n(": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),ul=l("code"),Wn=n("label_column"),zn=n(" can be integers ("),fl=l("code"),Gn=n("0"),Vn=n("/"),ml=l("code"),Un=n("1"),Mn=n(") whereas the pipeline can produce label names such as "),vl=l("code"),Fn=n('"positive"'),Qn=n("/"),_l=l("code"),Jn=n('"negative"'),Yn=n(". With that dictionary the pipeline outputs are mapped to the labels."),Kn=r(),kt=l("li"),gl=l("code"),Xn=n('join_by=" "'),Zn=n(": While most datasets are already tokenized the pipeline expects a string. Thus the tokens need to be joined before passing to the pipeline. By default they are joined with a whitespace."),gs=r(),yt=l("p"),ei=n("Let\u2019s have a look how we can use the evaluator to benchmark several models."),bs=r(),se=l("h3"),we=l("a"),bl=l("span"),u(Ue.$$.fragment),ti=r(),El=l("span"),ai=n("Benchmarking several models"),Es=r(),ke=l("p"),li=n("Here is an example where several models can be compared thanks to the "),wl=l("code"),si=n("Evaluator"),oi=n(" in only a few lines of code, abstracting away the preprocessing, inference, postprocessing, metric computation:"),ws=r(),u(Me.$$.fragment),ks=r(),$t=l("p"),ni=n("Results:"),ys=r(),ye=l("table"),kl=l("thead"),$=l("tr"),jt=l("th"),ii=n("model"),ri=r(),qt=l("th"),ci=n("overall_f1"),pi=r(),Tt=l("th"),di=n("overall_accuracy"),hi=r(),xt=l("th"),ui=n("total_time_in_seconds"),fi=r(),Dt=l("th"),mi=n("samples_per_second"),vi=r(),Pt=l("th"),_i=n("latency_in_seconds"),gi=r(),b=l("tbody"),j=l("tr"),Ct=l("td"),bi=n("Jorgeutd/albert-base-v2-finetuned-ner"),Ei=r(),It=l("td"),wi=n("0.941"),ki=r(),At=l("td"),yi=n("0.989"),$i=r(),Ot=l("td"),ji=n("4.515"),qi=r(),Nt=l("td"),Ti=n("221.468"),xi=r(),St=l("td"),Di=n("0.005"),Pi=r(),q=l("tr"),Lt=l("td"),Ci=n("dbmdz/bert-large-cased-finetuned-conll03-english"),Ii=r(),Ht=l("td"),Ai=n("0.962"),Oi=r(),Bt=l("td"),Ni=n("0.881"),Si=r(),Rt=l("td"),Li=n("11.648"),Hi=r(),Wt=l("td"),Bi=n("85.850"),Ri=r(),zt=l("td"),Wi=n("0.012"),zi=r(),T=l("tr"),Gt=l("td"),Gi=n("dbmdz/electra-large-discriminator-finetuned-conll03-english"),Vi=r(),Vt=l("td"),Ui=n("0.965"),Mi=r(),Ut=l("td"),Fi=n("0.881"),Qi=r(),Mt=l("td"),Ji=n("11.456"),Yi=r(),Ft=l("td"),Ki=n("87.292"),Xi=r(),Qt=l("td"),Zi=n("0.011"),er=r(),x=l("tr"),Jt=l("td"),tr=n("elastic/distilbert-base-uncased-finetuned-conll03-english"),ar=r(),Yt=l("td"),lr=n("0.940"),sr=r(),Kt=l("td"),or=n("0.989"),nr=r(),Xt=l("td"),ir=n("2.318"),rr=r(),Zt=l("td"),cr=n("431.378"),pr=r(),ea=l("td"),dr=n("0.002"),hr=r(),D=l("tr"),ta=l("td"),ur=n("gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner"),fr=r(),aa=l("td"),mr=n("0.947"),vr=r(),la=l("td"),_r=n("0.991"),gr=r(),sa=l("td"),br=n("2.376"),Er=r(),oa=l("td"),wr=n("420.873"),kr=r(),na=l("td"),yr=n("0.002"),$r=r(),P=l("tr"),ia=l("td"),jr=n("philschmid/distilroberta-base-ner-conll2003"),qr=r(),ra=l("td"),Tr=n("0.961"),xr=r(),ca=l("td"),Dr=n("0.994"),Pr=r(),pa=l("td"),Cr=n("2.436"),Ir=r(),da=l("td"),Ar=n("410.579"),Or=r(),ha=l("td"),Nr=n("0.002"),Sr=r(),C=l("tr"),ua=l("td"),Lr=n("xlm-roberta-large-finetuned-conll03-english"),Hr=r(),fa=l("td"),Br=n("0.969"),Rr=r(),ma=l("td"),Wr=n("0.882"),zr=r(),va=l("td"),Gr=n("11.996"),Vr=r(),_a=l("td"),Ur=n("83.359"),Mr=r(),ga=l("td"),Fr=n("0.012"),$s=r(),u($e.$$.fragment),js=r(),oe=l("h2"),je=l("a"),yl=l("span"),u(Fe.$$.fragment),Qr=r(),$l=l("span"),Jr=n("Question Answering"),qs=r(),ba=l("p"),Yr=n("With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),Ts=r(),I=l("ul"),Ea=l("li"),jl=l("code"),Kr=n('question_column="question"'),Xr=n(": the name of the column containing the question in the dataset"),Zr=r(),wa=l("li"),ql=l("code"),ec=n('context_column="context"'),tc=n(": the name of the column containing the context"),ac=r(),ka=l("li"),Tl=l("code"),lc=n('id_column="id"'),sc=n(": the name of the column cointaing the identification field of the question and answer pair"),oc=r(),ya=l("li"),xl=l("code"),nc=n('label_column="answers"'),ic=n(": the name of the column containing the answers"),rc=r(),$a=l("li"),Dl=l("code"),cc=n("squad_v2_format=None"),pc=n(": whether the dataset follows the format of squad_v2 dataset where a question may have no answer in the context. If this parameter is not provided, the format will be automatically inferred."),xs=r(),ja=l("p"),dc=n("Let\u2019s have a look how we can evaluate QA models and compute confidence intervals at the same time."),Ds=r(),ne=l("h3"),qe=l("a"),Pl=l("span"),u(Qe.$$.fragment),hc=r(),Cl=l("span"),uc=n("Confidence intervals"),Ps=r(),W=l("p"),fc=n("Every evaluator comes with the options to compute confidence intervals using "),Je=l("a"),mc=n("bootstrapping"),vc=n(". Simply pass "),Il=l("code"),_c=n('strategy="bootstrap"'),gc=n(" and set the number of resanmples with "),Al=l("code"),bc=n("n_resamples"),Ec=n("."),Cs=r(),u(Ye.$$.fragment),Is=r(),qa=l("p"),wc=n("Results include confidence intervals as well as error estimates as follows:"),As=r(),u(Ke.$$.fragment),Os=r(),ie=l("h2"),Te=l("a"),Ol=l("span"),u(Xe.$$.fragment),kc=r(),Nl=l("span"),yc=n("Image classification"),Ns=r(),Ta=l("p"),$c=n("With the image classification evaluator we can evaluate any image classifier. It uses the same keyword arguments at the text classifier:"),Ss=r(),K=l("ul"),xa=l("li"),Sl=l("code"),jc=n('input_column="image"'),qc=n(": the name of the column containing the images as PIL ImageFile"),Tc=r(),Da=l("li"),Ll=l("code"),xc=n('label_column="label"'),Dc=n(": the name of the column containing the labels"),Pc=r(),Ze=l("li"),Hl=l("code"),Cc=n("label_mapping=None"),Ic=n(": We want to map class labels defined by the model in the pipeline to values consistent with those defined in the "),Bl=l("code"),Ac=n("label_column"),Ls=r(),Pa=l("p"),Oc=n("Let\u2019s have a look at how can evaluate image classification models on large datasets."),Hs=r(),re=l("h3"),xe=l("a"),Rl=l("span"),u(et.$$.fragment),Nc=r(),Wl=l("span"),Sc=n("Handling large datasets"),Bs=r(),Ca=l("p"),Lc=n("The evaluator can be used on large datasets! Below, an example shows how to use it on ImageNet-1k for image classification. Beware that this example will require to download ~150 GB."),Rs=r(),Ia=l("p"),Hc=n("Without specifying a device, the default will be the first GPU if available, else CPU."),Ws=r(),u(tt.$$.fragment),zs=r(),De=l("p"),Bc=n("Since we are using "),zl=l("code"),Rc=n("datasets"),Wc=n(" to store data we make use of a technique called memory mappings. This means that the dataset is never fully loaded into memory which saves a lot of RAM. Running the above code only uses roughly 1.5 GB of RAM while the validation split is more than 30 GB big."),this.h()},l(t){const p=Rh('[data-svelte="svelte-1phssyn"]',document.head);E=s(p,"META",{name:!0,content:!0}),p.forEach(a),ce=c(t),y=s(t,"H1",{class:!0});var at=o(y);O=s(at,"A",{id:!0,class:!0,href:!0});var tp=o(O);Na=s(tp,"SPAN",{});var ap=o(Na);f(Se.$$.fragment,ap),ap.forEach(a),tp.forEach(a),no=c(at),lt=s(at,"SPAN",{});var zc=o(lt);io=i(zc,"Using the "),Sa=s(zc,"CODE",{});var lp=o(Sa);ro=i(lp,"evaluator"),lp.forEach(a),zc.forEach(a),at.forEach(a),Ql=c(t),L=s(t,"P",{});var Pe=o(L);co=i(Pe,"The "),La=s(Pe,"CODE",{});var sp=o(La);po=i(sp,"Evaluator"),sp.forEach(a),ho=i(Pe," classes allow to evaluate a  triplet of model, dataset, and metric. The models wrapped in a pipeline, responsible for handling all preprocessing and post-processing and out-of-the-box, "),Ha=s(Pe,"CODE",{});var op=o(Ha);uo=i(op,"Evaluator"),op.forEach(a),fo=i(Pe,"s support transformers pipelines for the supported tasks, but custom pipelines can be passed, as showcased in the section "),pe=s(Pe,"A",{href:!0});var Vs=o(pe);mo=i(Vs,"Using the "),Ba=s(Vs,"CODE",{});var np=o(Ba);vo=i(np,"evaluator"),np.forEach(a),_o=i(Vs," with custom models"),Vs.forEach(a),go=i(Pe,"."),Pe.forEach(a),Jl=c(t),st=s(t,"P",{});var ip=o(st);bo=i(ip,"Currently supported tasks are:"),ip.forEach(a),Yl=c(t),H=s(t,"UL",{});var Ce=o(H);de=s(Ce,"LI",{});var Gl=o(de);Ra=s(Gl,"CODE",{});var rp=o(Ra);Eo=i(rp,'"text-classification"'),rp.forEach(a),wo=i(Gl,": will use the "),ot=s(Gl,"A",{href:!0});var cp=o(ot);ko=i(cp,"TextClassificationEvaluator"),cp.forEach(a),yo=i(Gl,"."),Gl.forEach(a),$o=c(Ce),he=s(Ce,"LI",{});var Vl=o(he);Wa=s(Vl,"CODE",{});var pp=o(Wa);jo=i(pp,'"token-classification"'),pp.forEach(a),qo=i(Vl,": will use the "),nt=s(Vl,"A",{href:!0});var dp=o(nt);To=i(dp,"TokenClassificationEvaluator"),dp.forEach(a),xo=i(Vl,"."),Vl.forEach(a),Do=c(Ce),ue=s(Ce,"LI",{});var Ul=o(ue);za=s(Ul,"CODE",{});var hp=o(za);Po=i(hp,'"question-answering"'),hp.forEach(a),Co=i(Ul,": will use the "),it=s(Ul,"A",{href:!0});var up=o(it);Io=i(up,"QuestionAnsweringEvaluator"),up.forEach(a),Ao=i(Ul,"."),Ul.forEach(a),Oo=c(Ce),fe=s(Ce,"LI",{});var Ml=o(fe);Ga=s(Ml,"CODE",{});var fp=o(Ga);No=i(fp,'"image-classification"'),fp.forEach(a),So=i(Ml,": will use the "),rt=s(Ml,"A",{href:!0});var mp=o(rt);Lo=i(mp,"ImageClassificationEvaluator"),mp.forEach(a),Ho=i(Ml,"."),Ml.forEach(a),Ce.forEach(a),Kl=c(t),ct=s(t,"P",{});var vp=o(ct);Bo=i(vp,"Each task has its own set of requirements for the dataset format and pipeline output, make sure to check them out for your custom use case. Let\u2019s have a look at each one of them and see how you can use the evaluator to evalute a single or multiple of models, datasets, and metrics at the same time."),vp.forEach(a),Xl=c(t),ee=s(t,"H2",{class:!0});var Us=o(ee);me=s(Us,"A",{id:!0,class:!0,href:!0});var _p=o(me);Va=s(_p,"SPAN",{});var gp=o(Va);f(Le.$$.fragment,gp),gp.forEach(a),_p.forEach(a),Ro=c(Us),Ua=s(Us,"SPAN",{});var bp=o(Ua);Wo=i(bp,"Text classification"),bp.forEach(a),Us.forEach(a),Zl=c(t),pt=s(t,"P",{});var Ep=o(pt);zo=i(Ep,"The text classification evaluator can be used to evaluate text models on classification datasets such as IMDb. Beside the model, data, and metric inputs it takes the following optional inputs:"),Ep.forEach(a),es=c(t),Y=s(t,"UL",{});var Aa=o(Y);dt=s(Aa,"LI",{});var Gc=o(dt);Ma=s(Gc,"CODE",{});var wp=o(Ma);Go=i(wp,'input_column="text"'),wp.forEach(a),Vo=i(Gc,": with this argument the column with the data for the pipeline can be specified."),Gc.forEach(a),Uo=c(Aa),ht=s(Aa,"LI",{});var Vc=o(ht);Fa=s(Vc,"CODE",{});var kp=o(Fa);Mo=i(kp,'label_column="label"'),kp.forEach(a),Fo=i(Vc,": with this argument the column with the labels for the evaluation can be specified."),Vc.forEach(a),Qo=c(Aa),w=s(Aa,"LI",{});var N=o(w);Qa=s(N,"CODE",{});var yp=o(Qa);Jo=i(yp,"label_mapping=None"),yp.forEach(a),Yo=i(N,": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),Ja=s(N,"CODE",{});var $p=o(Ja);Ko=i($p,"label_column"),$p.forEach(a),Xo=i(N," can be integers ("),Ya=s(N,"CODE",{});var jp=o(Ya);Zo=i(jp,"0"),jp.forEach(a),en=i(N,"/"),Ka=s(N,"CODE",{});var qp=o(Ka);tn=i(qp,"1"),qp.forEach(a),an=i(N,") whereas the pipeline can produce label names such as "),Xa=s(N,"CODE",{});var Tp=o(Xa);ln=i(Tp,'"positive"'),Tp.forEach(a),sn=i(N,"/"),Za=s(N,"CODE",{});var xp=o(Za);on=i(xp,'"negative"'),xp.forEach(a),nn=i(N,". With that dictionary the pipeline outputs are mapped to the labels."),N.forEach(a),Aa.forEach(a),ts=c(t),ve=s(t,"P",{});var Ms=o(ve);rn=i(Ms,"By default the "),el=s(Ms,"CODE",{});var Dp=o(el);cn=i(Dp,'"accuracy"'),Dp.forEach(a),pn=i(Ms," metric is computed."),Ms.forEach(a),as=c(t),te=s(t,"H3",{class:!0});var Fs=o(te);_e=s(Fs,"A",{id:!0,class:!0,href:!0});var Pp=o(_e);tl=s(Pp,"SPAN",{});var Cp=o(tl);f(He.$$.fragment,Cp),Cp.forEach(a),Pp.forEach(a),dn=c(Fs),al=s(Fs,"SPAN",{});var Ip=o(al);hn=i(Ip,"Evaluate models on the Hub"),Ip.forEach(a),Fs.forEach(a),ls=c(t),B=s(t,"P",{});var Ie=o(B);un=i(Ie,"There are several ways to pass a model to the evaluator: you can pass the name of a model on the Hub, you can load a "),ll=s(Ie,"CODE",{});var Ap=o(ll);fn=i(Ap,"transformers"),Ap.forEach(a),mn=i(Ie," model and pass it to the evaluator or you can pass an initialized "),sl=s(Ie,"CODE",{});var Op=o(sl);vn=i(Op,"transformers.Pipeline"),Op.forEach(a),_n=i(Ie,". Alternatively you can pass any callable function that behaves like a "),ol=s(Ie,"CODE",{});var Np=o(ol);gn=i(Np,"pipeline"),Np.forEach(a),bn=i(Ie," call for the task in any framework."),Ie.forEach(a),ss=c(t),ut=s(t,"P",{});var Sp=o(ut);En=i(Sp,"So any of the following works:"),Sp.forEach(a),os=c(t),f(Be.$$.fragment,t),ns=c(t),ft=s(t,"P",{});var Lp=o(ft);wn=i(Lp,"The results will look as follows:"),Lp.forEach(a),is=c(t),f(Re.$$.fragment,t),rs=c(t),mt=s(t,"P",{});var Hp=o(mt);kn=i(Hp,"Note that evaluation results include both the requested metric, and information about the time it took to obtain predictions through the pipeline. These additional time metrics give an useful first information on model speed for inference."),Hp.forEach(a),cs=c(t),ae=s(t,"H3",{class:!0});var Qs=o(ae);ge=s(Qs,"A",{id:!0,class:!0,href:!0});var Bp=o(ge);nl=s(Bp,"SPAN",{});var Rp=o(nl);f(We.$$.fragment,Rp),Rp.forEach(a),Bp.forEach(a),yn=c(Qs),il=s(Qs,"SPAN",{});var Wp=o(il);$n=i(Wp,"Evaluate multiple metrics"),Wp.forEach(a),Qs.forEach(a),ps=c(t),be=s(t,"P",{});var Js=o(be);jn=i(Js,"With the "),vt=s(Js,"A",{href:!0});var zp=o(vt);qn=i(zp,"combine()"),zp.forEach(a),Tn=i(Js," function one can bundle several metrics into an object that behaves like a single metric. We can use this to evaluate several metrics at once in an evaluator:"),Js.forEach(a),ds=c(t),f(ze.$$.fragment,t),hs=c(t),_t=s(t,"P",{});var Gp=o(_t);xn=i(Gp,"The results will look as follows:"),Gp.forEach(a),us=c(t),f(Ge.$$.fragment,t),fs=c(t),gt=s(t,"P",{});var Vp=o(gt);Dn=i(Vp,"Next let\u2019s have a look at token classification."),Vp.forEach(a),ms=c(t),le=s(t,"H2",{class:!0});var Ys=o(le);Ee=s(Ys,"A",{id:!0,class:!0,href:!0});var Up=o(Ee);rl=s(Up,"SPAN",{});var Mp=o(rl);f(Ve.$$.fragment,Mp),Mp.forEach(a),Up.forEach(a),Pn=c(Ys),cl=s(Ys,"SPAN",{});var Fp=o(cl);Cn=i(Fp,"Token Classification"),Fp.forEach(a),Ys.forEach(a),vs=c(t),bt=s(t,"P",{});var Qp=o(bt);In=i(Qp,"With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),Qp.forEach(a),_s=c(t),R=s(t,"UL",{});var Ae=o(R);Et=s(Ae,"LI",{});var Uc=o(Et);pl=s(Uc,"CODE",{});var Jp=o(pl);An=i(Jp,'input_column="text"'),Jp.forEach(a),On=i(Uc,": with this argument the column with the data for the pipeline can be specified."),Uc.forEach(a),Nn=c(Ae),wt=s(Ae,"LI",{});var Mc=o(wt);dl=s(Mc,"CODE",{});var Yp=o(dl);Sn=i(Yp,'label_column="label"'),Yp.forEach(a),Ln=i(Mc,": with this argument the column with the labels for the evaluation can be specified."),Mc.forEach(a),Hn=c(Ae),k=s(Ae,"LI",{});var S=o(k);hl=s(S,"CODE",{});var Kp=o(hl);Bn=i(Kp,"label_mapping=None"),Kp.forEach(a),Rn=i(S,": the label mapping aligns the labels in the pipeline output with the labels need for evaluation. E.g. the labels in "),ul=s(S,"CODE",{});var Xp=o(ul);Wn=i(Xp,"label_column"),Xp.forEach(a),zn=i(S," can be integers ("),fl=s(S,"CODE",{});var Zp=o(fl);Gn=i(Zp,"0"),Zp.forEach(a),Vn=i(S,"/"),ml=s(S,"CODE",{});var ed=o(ml);Un=i(ed,"1"),ed.forEach(a),Mn=i(S,") whereas the pipeline can produce label names such as "),vl=s(S,"CODE",{});var td=o(vl);Fn=i(td,'"positive"'),td.forEach(a),Qn=i(S,"/"),_l=s(S,"CODE",{});var ad=o(_l);Jn=i(ad,'"negative"'),ad.forEach(a),Yn=i(S,". With that dictionary the pipeline outputs are mapped to the labels."),S.forEach(a),Kn=c(Ae),kt=s(Ae,"LI",{});var Fc=o(kt);gl=s(Fc,"CODE",{});var ld=o(gl);Xn=i(ld,'join_by=" "'),ld.forEach(a),Zn=i(Fc,": While most datasets are already tokenized the pipeline expects a string. Thus the tokens need to be joined before passing to the pipeline. By default they are joined with a whitespace."),Fc.forEach(a),Ae.forEach(a),gs=c(t),yt=s(t,"P",{});var sd=o(yt);ei=i(sd,"Let\u2019s have a look how we can use the evaluator to benchmark several models."),sd.forEach(a),bs=c(t),se=s(t,"H3",{class:!0});var Ks=o(se);we=s(Ks,"A",{id:!0,class:!0,href:!0});var od=o(we);bl=s(od,"SPAN",{});var nd=o(bl);f(Ue.$$.fragment,nd),nd.forEach(a),od.forEach(a),ti=c(Ks),El=s(Ks,"SPAN",{});var id=o(El);ai=i(id,"Benchmarking several models"),id.forEach(a),Ks.forEach(a),Es=c(t),ke=s(t,"P",{});var Xs=o(ke);li=i(Xs,"Here is an example where several models can be compared thanks to the "),wl=s(Xs,"CODE",{});var rd=o(wl);si=i(rd,"Evaluator"),rd.forEach(a),oi=i(Xs," in only a few lines of code, abstracting away the preprocessing, inference, postprocessing, metric computation:"),Xs.forEach(a),ws=c(t),f(Me.$$.fragment,t),ks=c(t),$t=s(t,"P",{});var cd=o($t);ni=i(cd,"Results:"),cd.forEach(a),ys=c(t),ye=s(t,"TABLE",{});var Zs=o(ye);kl=s(Zs,"THEAD",{});var pd=o(kl);$=s(pd,"TR",{});var z=o($);jt=s(z,"TH",{align:!0});var dd=o(jt);ii=i(dd,"model"),dd.forEach(a),ri=c(z),qt=s(z,"TH",{align:!0});var hd=o(qt);ci=i(hd,"overall_f1"),hd.forEach(a),pi=c(z),Tt=s(z,"TH",{align:!0});var ud=o(Tt);di=i(ud,"overall_accuracy"),ud.forEach(a),hi=c(z),xt=s(z,"TH",{align:!0});var fd=o(xt);ui=i(fd,"total_time_in_seconds"),fd.forEach(a),fi=c(z),Dt=s(z,"TH",{align:!0});var md=o(Dt);mi=i(md,"samples_per_second"),md.forEach(a),vi=c(z),Pt=s(z,"TH",{align:!0});var vd=o(Pt);_i=i(vd,"latency_in_seconds"),vd.forEach(a),z.forEach(a),pd.forEach(a),gi=c(Zs),b=s(Zs,"TBODY",{});var A=o(b);j=s(A,"TR",{});var G=o(j);Ct=s(G,"TD",{align:!0});var _d=o(Ct);bi=i(_d,"Jorgeutd/albert-base-v2-finetuned-ner"),_d.forEach(a),Ei=c(G),It=s(G,"TD",{align:!0});var gd=o(It);wi=i(gd,"0.941"),gd.forEach(a),ki=c(G),At=s(G,"TD",{align:!0});var bd=o(At);yi=i(bd,"0.989"),bd.forEach(a),$i=c(G),Ot=s(G,"TD",{align:!0});var Ed=o(Ot);ji=i(Ed,"4.515"),Ed.forEach(a),qi=c(G),Nt=s(G,"TD",{align:!0});var wd=o(Nt);Ti=i(wd,"221.468"),wd.forEach(a),xi=c(G),St=s(G,"TD",{align:!0});var kd=o(St);Di=i(kd,"0.005"),kd.forEach(a),G.forEach(a),Pi=c(A),q=s(A,"TR",{});var V=o(q);Lt=s(V,"TD",{align:!0});var yd=o(Lt);Ci=i(yd,"dbmdz/bert-large-cased-finetuned-conll03-english"),yd.forEach(a),Ii=c(V),Ht=s(V,"TD",{align:!0});var $d=o(Ht);Ai=i($d,"0.962"),$d.forEach(a),Oi=c(V),Bt=s(V,"TD",{align:!0});var jd=o(Bt);Ni=i(jd,"0.881"),jd.forEach(a),Si=c(V),Rt=s(V,"TD",{align:!0});var qd=o(Rt);Li=i(qd,"11.648"),qd.forEach(a),Hi=c(V),Wt=s(V,"TD",{align:!0});var Td=o(Wt);Bi=i(Td,"85.850"),Td.forEach(a),Ri=c(V),zt=s(V,"TD",{align:!0});var xd=o(zt);Wi=i(xd,"0.012"),xd.forEach(a),V.forEach(a),zi=c(A),T=s(A,"TR",{});var U=o(T);Gt=s(U,"TD",{align:!0});var Dd=o(Gt);Gi=i(Dd,"dbmdz/electra-large-discriminator-finetuned-conll03-english"),Dd.forEach(a),Vi=c(U),Vt=s(U,"TD",{align:!0});var Pd=o(Vt);Ui=i(Pd,"0.965"),Pd.forEach(a),Mi=c(U),Ut=s(U,"TD",{align:!0});var Cd=o(Ut);Fi=i(Cd,"0.881"),Cd.forEach(a),Qi=c(U),Mt=s(U,"TD",{align:!0});var Id=o(Mt);Ji=i(Id,"11.456"),Id.forEach(a),Yi=c(U),Ft=s(U,"TD",{align:!0});var Ad=o(Ft);Ki=i(Ad,"87.292"),Ad.forEach(a),Xi=c(U),Qt=s(U,"TD",{align:!0});var Od=o(Qt);Zi=i(Od,"0.011"),Od.forEach(a),U.forEach(a),er=c(A),x=s(A,"TR",{});var M=o(x);Jt=s(M,"TD",{align:!0});var Nd=o(Jt);tr=i(Nd,"elastic/distilbert-base-uncased-finetuned-conll03-english"),Nd.forEach(a),ar=c(M),Yt=s(M,"TD",{align:!0});var Sd=o(Yt);lr=i(Sd,"0.940"),Sd.forEach(a),sr=c(M),Kt=s(M,"TD",{align:!0});var Ld=o(Kt);or=i(Ld,"0.989"),Ld.forEach(a),nr=c(M),Xt=s(M,"TD",{align:!0});var Hd=o(Xt);ir=i(Hd,"2.318"),Hd.forEach(a),rr=c(M),Zt=s(M,"TD",{align:!0});var Bd=o(Zt);cr=i(Bd,"431.378"),Bd.forEach(a),pr=c(M),ea=s(M,"TD",{align:!0});var Rd=o(ea);dr=i(Rd,"0.002"),Rd.forEach(a),M.forEach(a),hr=c(A),D=s(A,"TR",{});var F=o(D);ta=s(F,"TD",{align:!0});var Wd=o(ta);ur=i(Wd,"gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner"),Wd.forEach(a),fr=c(F),aa=s(F,"TD",{align:!0});var zd=o(aa);mr=i(zd,"0.947"),zd.forEach(a),vr=c(F),la=s(F,"TD",{align:!0});var Gd=o(la);_r=i(Gd,"0.991"),Gd.forEach(a),gr=c(F),sa=s(F,"TD",{align:!0});var Vd=o(sa);br=i(Vd,"2.376"),Vd.forEach(a),Er=c(F),oa=s(F,"TD",{align:!0});var Ud=o(oa);wr=i(Ud,"420.873"),Ud.forEach(a),kr=c(F),na=s(F,"TD",{align:!0});var Md=o(na);yr=i(Md,"0.002"),Md.forEach(a),F.forEach(a),$r=c(A),P=s(A,"TR",{});var Q=o(P);ia=s(Q,"TD",{align:!0});var Fd=o(ia);jr=i(Fd,"philschmid/distilroberta-base-ner-conll2003"),Fd.forEach(a),qr=c(Q),ra=s(Q,"TD",{align:!0});var Qd=o(ra);Tr=i(Qd,"0.961"),Qd.forEach(a),xr=c(Q),ca=s(Q,"TD",{align:!0});var Jd=o(ca);Dr=i(Jd,"0.994"),Jd.forEach(a),Pr=c(Q),pa=s(Q,"TD",{align:!0});var Yd=o(pa);Cr=i(Yd,"2.436"),Yd.forEach(a),Ir=c(Q),da=s(Q,"TD",{align:!0});var Kd=o(da);Ar=i(Kd,"410.579"),Kd.forEach(a),Or=c(Q),ha=s(Q,"TD",{align:!0});var Xd=o(ha);Nr=i(Xd,"0.002"),Xd.forEach(a),Q.forEach(a),Sr=c(A),C=s(A,"TR",{});var J=o(C);ua=s(J,"TD",{align:!0});var Zd=o(ua);Lr=i(Zd,"xlm-roberta-large-finetuned-conll03-english"),Zd.forEach(a),Hr=c(J),fa=s(J,"TD",{align:!0});var eh=o(fa);Br=i(eh,"0.969"),eh.forEach(a),Rr=c(J),ma=s(J,"TD",{align:!0});var th=o(ma);Wr=i(th,"0.882"),th.forEach(a),zr=c(J),va=s(J,"TD",{align:!0});var ah=o(va);Gr=i(ah,"11.996"),ah.forEach(a),Vr=c(J),_a=s(J,"TD",{align:!0});var lh=o(_a);Ur=i(lh,"83.359"),lh.forEach(a),Mr=c(J),ga=s(J,"TD",{align:!0});var sh=o(ga);Fr=i(sh,"0.012"),sh.forEach(a),J.forEach(a),A.forEach(a),Zs.forEach(a),$s=c(t),f($e.$$.fragment,t),js=c(t),oe=s(t,"H2",{class:!0});var eo=o(oe);je=s(eo,"A",{id:!0,class:!0,href:!0});var oh=o(je);yl=s(oh,"SPAN",{});var nh=o(yl);f(Fe.$$.fragment,nh),nh.forEach(a),oh.forEach(a),Qr=c(eo),$l=s(eo,"SPAN",{});var ih=o($l);Jr=i(ih,"Question Answering"),ih.forEach(a),eo.forEach(a),qs=c(t),ba=s(t,"P",{});var rh=o(ba);Yr=i(rh,"With the token classification evaluator one can evaluate models for tasks such as NER or POS tagging. It has the following specific arguments:"),rh.forEach(a),Ts=c(t),I=s(t,"UL",{});var X=o(I);Ea=s(X,"LI",{});var Qc=o(Ea);jl=s(Qc,"CODE",{});var ch=o(jl);Kr=i(ch,'question_column="question"'),ch.forEach(a),Xr=i(Qc,": the name of the column containing the question in the dataset"),Qc.forEach(a),Zr=c(X),wa=s(X,"LI",{});var Jc=o(wa);ql=s(Jc,"CODE",{});var ph=o(ql);ec=i(ph,'context_column="context"'),ph.forEach(a),tc=i(Jc,": the name of the column containing the context"),Jc.forEach(a),ac=c(X),ka=s(X,"LI",{});var Yc=o(ka);Tl=s(Yc,"CODE",{});var dh=o(Tl);lc=i(dh,'id_column="id"'),dh.forEach(a),sc=i(Yc,": the name of the column cointaing the identification field of the question and answer pair"),Yc.forEach(a),oc=c(X),ya=s(X,"LI",{});var Kc=o(ya);xl=s(Kc,"CODE",{});var hh=o(xl);nc=i(hh,'label_column="answers"'),hh.forEach(a),ic=i(Kc,": the name of the column containing the answers"),Kc.forEach(a),rc=c(X),$a=s(X,"LI",{});var Xc=o($a);Dl=s(Xc,"CODE",{});var uh=o(Dl);cc=i(uh,"squad_v2_format=None"),uh.forEach(a),pc=i(Xc,": whether the dataset follows the format of squad_v2 dataset where a question may have no answer in the context. If this parameter is not provided, the format will be automatically inferred."),Xc.forEach(a),X.forEach(a),xs=c(t),ja=s(t,"P",{});var fh=o(ja);dc=i(fh,"Let\u2019s have a look how we can evaluate QA models and compute confidence intervals at the same time."),fh.forEach(a),Ds=c(t),ne=s(t,"H3",{class:!0});var to=o(ne);qe=s(to,"A",{id:!0,class:!0,href:!0});var mh=o(qe);Pl=s(mh,"SPAN",{});var vh=o(Pl);f(Qe.$$.fragment,vh),vh.forEach(a),mh.forEach(a),hc=c(to),Cl=s(to,"SPAN",{});var _h=o(Cl);uc=i(_h,"Confidence intervals"),_h.forEach(a),to.forEach(a),Ps=c(t),W=s(t,"P",{});var Oe=o(W);fc=i(Oe,"Every evaluator comes with the options to compute confidence intervals using "),Je=s(Oe,"A",{href:!0,rel:!0});var gh=o(Je);mc=i(gh,"bootstrapping"),gh.forEach(a),vc=i(Oe,". Simply pass "),Il=s(Oe,"CODE",{});var bh=o(Il);_c=i(bh,'strategy="bootstrap"'),bh.forEach(a),gc=i(Oe," and set the number of resanmples with "),Al=s(Oe,"CODE",{});var Eh=o(Al);bc=i(Eh,"n_resamples"),Eh.forEach(a),Ec=i(Oe,"."),Oe.forEach(a),Cs=c(t),f(Ye.$$.fragment,t),Is=c(t),qa=s(t,"P",{});var wh=o(qa);wc=i(wh,"Results include confidence intervals as well as error estimates as follows:"),wh.forEach(a),As=c(t),f(Ke.$$.fragment,t),Os=c(t),ie=s(t,"H2",{class:!0});var ao=o(ie);Te=s(ao,"A",{id:!0,class:!0,href:!0});var kh=o(Te);Ol=s(kh,"SPAN",{});var yh=o(Ol);f(Xe.$$.fragment,yh),yh.forEach(a),kh.forEach(a),kc=c(ao),Nl=s(ao,"SPAN",{});var $h=o(Nl);yc=i($h,"Image classification"),$h.forEach(a),ao.forEach(a),Ns=c(t),Ta=s(t,"P",{});var jh=o(Ta);$c=i(jh,"With the image classification evaluator we can evaluate any image classifier. It uses the same keyword arguments at the text classifier:"),jh.forEach(a),Ss=c(t),K=s(t,"UL",{});var Oa=o(K);xa=s(Oa,"LI",{});var Zc=o(xa);Sl=s(Zc,"CODE",{});var qh=o(Sl);jc=i(qh,'input_column="image"'),qh.forEach(a),qc=i(Zc,": the name of the column containing the images as PIL ImageFile"),Zc.forEach(a),Tc=c(Oa),Da=s(Oa,"LI",{});var ep=o(Da);Ll=s(ep,"CODE",{});var Th=o(Ll);xc=i(Th,'label_column="label"'),Th.forEach(a),Dc=i(ep,": the name of the column containing the labels"),ep.forEach(a),Pc=c(Oa),Ze=s(Oa,"LI",{});var lo=o(Ze);Hl=s(lo,"CODE",{});var xh=o(Hl);Cc=i(xh,"label_mapping=None"),xh.forEach(a),Ic=i(lo,": We want to map class labels defined by the model in the pipeline to values consistent with those defined in the "),Bl=s(lo,"CODE",{});var Dh=o(Bl);Ac=i(Dh,"label_column"),Dh.forEach(a),lo.forEach(a),Oa.forEach(a),Ls=c(t),Pa=s(t,"P",{});var Ph=o(Pa);Oc=i(Ph,"Let\u2019s have a look at how can evaluate image classification models on large datasets."),Ph.forEach(a),Hs=c(t),re=s(t,"H3",{class:!0});var so=o(re);xe=s(so,"A",{id:!0,class:!0,href:!0});var Ch=o(xe);Rl=s(Ch,"SPAN",{});var Ih=o(Rl);f(et.$$.fragment,Ih),Ih.forEach(a),Ch.forEach(a),Nc=c(so),Wl=s(so,"SPAN",{});var Ah=o(Wl);Sc=i(Ah,"Handling large datasets"),Ah.forEach(a),so.forEach(a),Bs=c(t),Ca=s(t,"P",{});var Oh=o(Ca);Lc=i(Oh,"The evaluator can be used on large datasets! Below, an example shows how to use it on ImageNet-1k for image classification. Beware that this example will require to download ~150 GB."),Oh.forEach(a),Rs=c(t),Ia=s(t,"P",{});var Nh=o(Ia);Hc=i(Nh,"Without specifying a device, the default will be the first GPU if available, else CPU."),Nh.forEach(a),Ws=c(t),f(tt.$$.fragment,t),zs=c(t),De=s(t,"P",{});var oo=o(De);Bc=i(oo,"Since we are using "),zl=s(oo,"CODE",{});var Sh=o(zl);Rc=i(Sh,"datasets"),Sh.forEach(a),Wc=i(oo," to store data we make use of a technique called memory mappings. This means that the dataset is never fully loaded into memory which saves a lot of RAM. Running the above code only uses roughly 1.5 GB of RAM while the validation split is more than 30 GB big."),oo.forEach(a),this.h()},h(){d(E,"name","hf:doc:metadata"),d(E,"content",JSON.stringify(Uh)),d(O,"id","using-the-evaluator"),d(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(O,"href","#using-the-evaluator"),d(y,"class","relative group"),d(pe,"href","custom_evaluator"),d(ot,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.TextClassificationEvaluator"),d(nt,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.TokenClassificationEvaluator"),d(it,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.QuestionAnsweringEvaluator"),d(rt,"href","/docs/evaluate/pr_199/en/package_reference/evaluator_classes#evaluate.ImageClassificationEvaluator"),d(me,"id","text-classification"),d(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(me,"href","#text-classification"),d(ee,"class","relative group"),d(_e,"id","evaluate-models-on-the-hub"),d(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_e,"href","#evaluate-models-on-the-hub"),d(te,"class","relative group"),d(ge,"id","evaluate-multiple-metrics"),d(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ge,"href","#evaluate-multiple-metrics"),d(ae,"class","relative group"),d(vt,"href","/docs/evaluate/pr_199/en/package_reference/main_classes#evaluate.combine"),d(Ee,"id","token-classification"),d(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ee,"href","#token-classification"),d(le,"class","relative group"),d(we,"id","benchmarking-several-models"),d(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(we,"href","#benchmarking-several-models"),d(se,"class","relative group"),d(jt,"align","left"),d(qt,"align","right"),d(Tt,"align","right"),d(xt,"align","right"),d(Dt,"align","right"),d(Pt,"align","right"),d(Ct,"align","left"),d(It,"align","right"),d(At,"align","right"),d(Ot,"align","right"),d(Nt,"align","right"),d(St,"align","right"),d(Lt,"align","left"),d(Ht,"align","right"),d(Bt,"align","right"),d(Rt,"align","right"),d(Wt,"align","right"),d(zt,"align","right"),d(Gt,"align","left"),d(Vt,"align","right"),d(Ut,"align","right"),d(Mt,"align","right"),d(Ft,"align","right"),d(Qt,"align","right"),d(Jt,"align","left"),d(Yt,"align","right"),d(Kt,"align","right"),d(Xt,"align","right"),d(Zt,"align","right"),d(ea,"align","right"),d(ta,"align","left"),d(aa,"align","right"),d(la,"align","right"),d(sa,"align","right"),d(oa,"align","right"),d(na,"align","right"),d(ia,"align","left"),d(ra,"align","right"),d(ca,"align","right"),d(pa,"align","right"),d(da,"align","right"),d(ha,"align","right"),d(ua,"align","left"),d(fa,"align","right"),d(ma,"align","right"),d(va,"align","right"),d(_a,"align","right"),d(ga,"align","right"),d(je,"id","question-answering"),d(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(je,"href","#question-answering"),d(oe,"class","relative group"),d(qe,"id","confidence-intervals"),d(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qe,"href","#confidence-intervals"),d(ne,"class","relative group"),d(Je,"href","https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html"),d(Je,"rel","nofollow"),d(Te,"id","image-classification"),d(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Te,"href","#image-classification"),d(ie,"class","relative group"),d(xe,"id","handling-large-datasets"),d(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xe,"href","#handling-large-datasets"),d(re,"class","relative group")},m(t,p){e(document.head,E),h(t,ce,p),h(t,y,p),e(y,O),e(O,Na),m(Se,Na,null),e(y,no),e(y,lt),e(lt,io),e(lt,Sa),e(Sa,ro),h(t,Ql,p),h(t,L,p),e(L,co),e(L,La),e(La,po),e(L,ho),e(L,Ha),e(Ha,uo),e(L,fo),e(L,pe),e(pe,mo),e(pe,Ba),e(Ba,vo),e(pe,_o),e(L,go),h(t,Jl,p),h(t,st,p),e(st,bo),h(t,Yl,p),h(t,H,p),e(H,de),e(de,Ra),e(Ra,Eo),e(de,wo),e(de,ot),e(ot,ko),e(de,yo),e(H,$o),e(H,he),e(he,Wa),e(Wa,jo),e(he,qo),e(he,nt),e(nt,To),e(he,xo),e(H,Do),e(H,ue),e(ue,za),e(za,Po),e(ue,Co),e(ue,it),e(it,Io),e(ue,Ao),e(H,Oo),e(H,fe),e(fe,Ga),e(Ga,No),e(fe,So),e(fe,rt),e(rt,Lo),e(fe,Ho),h(t,Kl,p),h(t,ct,p),e(ct,Bo),h(t,Xl,p),h(t,ee,p),e(ee,me),e(me,Va),m(Le,Va,null),e(ee,Ro),e(ee,Ua),e(Ua,Wo),h(t,Zl,p),h(t,pt,p),e(pt,zo),h(t,es,p),h(t,Y,p),e(Y,dt),e(dt,Ma),e(Ma,Go),e(dt,Vo),e(Y,Uo),e(Y,ht),e(ht,Fa),e(Fa,Mo),e(ht,Fo),e(Y,Qo),e(Y,w),e(w,Qa),e(Qa,Jo),e(w,Yo),e(w,Ja),e(Ja,Ko),e(w,Xo),e(w,Ya),e(Ya,Zo),e(w,en),e(w,Ka),e(Ka,tn),e(w,an),e(w,Xa),e(Xa,ln),e(w,sn),e(w,Za),e(Za,on),e(w,nn),h(t,ts,p),h(t,ve,p),e(ve,rn),e(ve,el),e(el,cn),e(ve,pn),h(t,as,p),h(t,te,p),e(te,_e),e(_e,tl),m(He,tl,null),e(te,dn),e(te,al),e(al,hn),h(t,ls,p),h(t,B,p),e(B,un),e(B,ll),e(ll,fn),e(B,mn),e(B,sl),e(sl,vn),e(B,_n),e(B,ol),e(ol,gn),e(B,bn),h(t,ss,p),h(t,ut,p),e(ut,En),h(t,os,p),m(Be,t,p),h(t,ns,p),h(t,ft,p),e(ft,wn),h(t,is,p),m(Re,t,p),h(t,rs,p),h(t,mt,p),e(mt,kn),h(t,cs,p),h(t,ae,p),e(ae,ge),e(ge,nl),m(We,nl,null),e(ae,yn),e(ae,il),e(il,$n),h(t,ps,p),h(t,be,p),e(be,jn),e(be,vt),e(vt,qn),e(be,Tn),h(t,ds,p),m(ze,t,p),h(t,hs,p),h(t,_t,p),e(_t,xn),h(t,us,p),m(Ge,t,p),h(t,fs,p),h(t,gt,p),e(gt,Dn),h(t,ms,p),h(t,le,p),e(le,Ee),e(Ee,rl),m(Ve,rl,null),e(le,Pn),e(le,cl),e(cl,Cn),h(t,vs,p),h(t,bt,p),e(bt,In),h(t,_s,p),h(t,R,p),e(R,Et),e(Et,pl),e(pl,An),e(Et,On),e(R,Nn),e(R,wt),e(wt,dl),e(dl,Sn),e(wt,Ln),e(R,Hn),e(R,k),e(k,hl),e(hl,Bn),e(k,Rn),e(k,ul),e(ul,Wn),e(k,zn),e(k,fl),e(fl,Gn),e(k,Vn),e(k,ml),e(ml,Un),e(k,Mn),e(k,vl),e(vl,Fn),e(k,Qn),e(k,_l),e(_l,Jn),e(k,Yn),e(R,Kn),e(R,kt),e(kt,gl),e(gl,Xn),e(kt,Zn),h(t,gs,p),h(t,yt,p),e(yt,ei),h(t,bs,p),h(t,se,p),e(se,we),e(we,bl),m(Ue,bl,null),e(se,ti),e(se,El),e(El,ai),h(t,Es,p),h(t,ke,p),e(ke,li),e(ke,wl),e(wl,si),e(ke,oi),h(t,ws,p),m(Me,t,p),h(t,ks,p),h(t,$t,p),e($t,ni),h(t,ys,p),h(t,ye,p),e(ye,kl),e(kl,$),e($,jt),e(jt,ii),e($,ri),e($,qt),e(qt,ci),e($,pi),e($,Tt),e(Tt,di),e($,hi),e($,xt),e(xt,ui),e($,fi),e($,Dt),e(Dt,mi),e($,vi),e($,Pt),e(Pt,_i),e(ye,gi),e(ye,b),e(b,j),e(j,Ct),e(Ct,bi),e(j,Ei),e(j,It),e(It,wi),e(j,ki),e(j,At),e(At,yi),e(j,$i),e(j,Ot),e(Ot,ji),e(j,qi),e(j,Nt),e(Nt,Ti),e(j,xi),e(j,St),e(St,Di),e(b,Pi),e(b,q),e(q,Lt),e(Lt,Ci),e(q,Ii),e(q,Ht),e(Ht,Ai),e(q,Oi),e(q,Bt),e(Bt,Ni),e(q,Si),e(q,Rt),e(Rt,Li),e(q,Hi),e(q,Wt),e(Wt,Bi),e(q,Ri),e(q,zt),e(zt,Wi),e(b,zi),e(b,T),e(T,Gt),e(Gt,Gi),e(T,Vi),e(T,Vt),e(Vt,Ui),e(T,Mi),e(T,Ut),e(Ut,Fi),e(T,Qi),e(T,Mt),e(Mt,Ji),e(T,Yi),e(T,Ft),e(Ft,Ki),e(T,Xi),e(T,Qt),e(Qt,Zi),e(b,er),e(b,x),e(x,Jt),e(Jt,tr),e(x,ar),e(x,Yt),e(Yt,lr),e(x,sr),e(x,Kt),e(Kt,or),e(x,nr),e(x,Xt),e(Xt,ir),e(x,rr),e(x,Zt),e(Zt,cr),e(x,pr),e(x,ea),e(ea,dr),e(b,hr),e(b,D),e(D,ta),e(ta,ur),e(D,fr),e(D,aa),e(aa,mr),e(D,vr),e(D,la),e(la,_r),e(D,gr),e(D,sa),e(sa,br),e(D,Er),e(D,oa),e(oa,wr),e(D,kr),e(D,na),e(na,yr),e(b,$r),e(b,P),e(P,ia),e(ia,jr),e(P,qr),e(P,ra),e(ra,Tr),e(P,xr),e(P,ca),e(ca,Dr),e(P,Pr),e(P,pa),e(pa,Cr),e(P,Ir),e(P,da),e(da,Ar),e(P,Or),e(P,ha),e(ha,Nr),e(b,Sr),e(b,C),e(C,ua),e(ua,Lr),e(C,Hr),e(C,fa),e(fa,Br),e(C,Rr),e(C,ma),e(ma,Wr),e(C,zr),e(C,va),e(va,Gr),e(C,Vr),e(C,_a),e(_a,Ur),e(C,Mr),e(C,ga),e(ga,Fr),h(t,$s,p),m($e,t,p),h(t,js,p),h(t,oe,p),e(oe,je),e(je,yl),m(Fe,yl,null),e(oe,Qr),e(oe,$l),e($l,Jr),h(t,qs,p),h(t,ba,p),e(ba,Yr),h(t,Ts,p),h(t,I,p),e(I,Ea),e(Ea,jl),e(jl,Kr),e(Ea,Xr),e(I,Zr),e(I,wa),e(wa,ql),e(ql,ec),e(wa,tc),e(I,ac),e(I,ka),e(ka,Tl),e(Tl,lc),e(ka,sc),e(I,oc),e(I,ya),e(ya,xl),e(xl,nc),e(ya,ic),e(I,rc),e(I,$a),e($a,Dl),e(Dl,cc),e($a,pc),h(t,xs,p),h(t,ja,p),e(ja,dc),h(t,Ds,p),h(t,ne,p),e(ne,qe),e(qe,Pl),m(Qe,Pl,null),e(ne,hc),e(ne,Cl),e(Cl,uc),h(t,Ps,p),h(t,W,p),e(W,fc),e(W,Je),e(Je,mc),e(W,vc),e(W,Il),e(Il,_c),e(W,gc),e(W,Al),e(Al,bc),e(W,Ec),h(t,Cs,p),m(Ye,t,p),h(t,Is,p),h(t,qa,p),e(qa,wc),h(t,As,p),m(Ke,t,p),h(t,Os,p),h(t,ie,p),e(ie,Te),e(Te,Ol),m(Xe,Ol,null),e(ie,kc),e(ie,Nl),e(Nl,yc),h(t,Ns,p),h(t,Ta,p),e(Ta,$c),h(t,Ss,p),h(t,K,p),e(K,xa),e(xa,Sl),e(Sl,jc),e(xa,qc),e(K,Tc),e(K,Da),e(Da,Ll),e(Ll,xc),e(Da,Dc),e(K,Pc),e(K,Ze),e(Ze,Hl),e(Hl,Cc),e(Ze,Ic),e(Ze,Bl),e(Bl,Ac),h(t,Ls,p),h(t,Pa,p),e(Pa,Oc),h(t,Hs,p),h(t,re,p),e(re,xe),e(xe,Rl),m(et,Rl,null),e(re,Nc),e(re,Wl),e(Wl,Sc),h(t,Bs,p),h(t,Ca,p),e(Ca,Lc),h(t,Rs,p),h(t,Ia,p),e(Ia,Hc),h(t,Ws,p),m(tt,t,p),h(t,zs,p),h(t,De,p),e(De,Bc),e(De,zl),e(zl,Rc),e(De,Wc),Gs=!0},p(t,[p]){const at={};p&2&&(at.$$scope={dirty:p,ctx:t}),$e.$set(at)},i(t){Gs||(v(Se.$$.fragment,t),v(Le.$$.fragment,t),v(He.$$.fragment,t),v(Be.$$.fragment,t),v(Re.$$.fragment,t),v(We.$$.fragment,t),v(ze.$$.fragment,t),v(Ge.$$.fragment,t),v(Ve.$$.fragment,t),v(Ue.$$.fragment,t),v(Me.$$.fragment,t),v($e.$$.fragment,t),v(Fe.$$.fragment,t),v(Qe.$$.fragment,t),v(Ye.$$.fragment,t),v(Ke.$$.fragment,t),v(Xe.$$.fragment,t),v(et.$$.fragment,t),v(tt.$$.fragment,t),Gs=!0)},o(t){_(Se.$$.fragment,t),_(Le.$$.fragment,t),_(He.$$.fragment,t),_(Be.$$.fragment,t),_(Re.$$.fragment,t),_(We.$$.fragment,t),_(ze.$$.fragment,t),_(Ge.$$.fragment,t),_(Ve.$$.fragment,t),_(Ue.$$.fragment,t),_(Me.$$.fragment,t),_($e.$$.fragment,t),_(Fe.$$.fragment,t),_(Qe.$$.fragment,t),_(Ye.$$.fragment,t),_(Ke.$$.fragment,t),_(Xe.$$.fragment,t),_(et.$$.fragment,t),_(tt.$$.fragment,t),Gs=!1},d(t){a(E),t&&a(ce),t&&a(y),g(Se),t&&a(Ql),t&&a(L),t&&a(Jl),t&&a(st),t&&a(Yl),t&&a(H),t&&a(Kl),t&&a(ct),t&&a(Xl),t&&a(ee),g(Le),t&&a(Zl),t&&a(pt),t&&a(es),t&&a(Y),t&&a(ts),t&&a(ve),t&&a(as),t&&a(te),g(He),t&&a(ls),t&&a(B),t&&a(ss),t&&a(ut),t&&a(os),g(Be,t),t&&a(ns),t&&a(ft),t&&a(is),g(Re,t),t&&a(rs),t&&a(mt),t&&a(cs),t&&a(ae),g(We),t&&a(ps),t&&a(be),t&&a(ds),g(ze,t),t&&a(hs),t&&a(_t),t&&a(us),g(Ge,t),t&&a(fs),t&&a(gt),t&&a(ms),t&&a(le),g(Ve),t&&a(vs),t&&a(bt),t&&a(_s),t&&a(R),t&&a(gs),t&&a(yt),t&&a(bs),t&&a(se),g(Ue),t&&a(Es),t&&a(ke),t&&a(ws),g(Me,t),t&&a(ks),t&&a($t),t&&a(ys),t&&a(ye),t&&a($s),g($e,t),t&&a(js),t&&a(oe),g(Fe),t&&a(qs),t&&a(ba),t&&a(Ts),t&&a(I),t&&a(xs),t&&a(ja),t&&a(Ds),t&&a(ne),g(Qe),t&&a(Ps),t&&a(W),t&&a(Cs),g(Ye,t),t&&a(Is),t&&a(qa),t&&a(As),g(Ke,t),t&&a(Os),t&&a(ie),g(Xe),t&&a(Ns),t&&a(Ta),t&&a(Ss),t&&a(K),t&&a(Ls),t&&a(Pa),t&&a(Hs),t&&a(re),g(et),t&&a(Bs),t&&a(Ca),t&&a(Rs),t&&a(Ia),t&&a(Ws),g(tt,t),t&&a(zs),t&&a(De)}}}const Uh={local:"using-the-evaluator",sections:[{local:"text-classification",sections:[{local:"evaluate-models-on-the-hub",title:"Evaluate models on the Hub"},{local:"evaluate-multiple-metrics",title:"Evaluate multiple metrics"}],title:"Text classification"},{local:"token-classification",sections:[{local:"benchmarking-several-models",title:"Benchmarking several models"}],title:"Token Classification"},{local:"question-answering",sections:[{local:"confidence-intervals",title:"Confidence intervals"}],title:"Question Answering"},{local:"image-classification",sections:[{local:"handling-large-datasets",title:"Handling large datasets"}],title:"Image classification"}],title:"Using the `evaluator`"};function Mh(Fl){return Wh(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Kh extends Lh{constructor(E){super();Hh(this,E,Mh,Vh,Bh,{})}}export{Kh as default,Uh as metadata};
