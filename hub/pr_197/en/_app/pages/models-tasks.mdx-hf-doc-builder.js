import{S as Ql,i as Xl,s as Zl,e as a,k as c,w as S,t as l,N as es,c as r,d as o,m as d,a as i,x as C,h as s,b as n,P as Kl,G as t,g as h,y as H,L as ts,q as O,o as U,B as R,v as os}from"../chunks/vendor-hf-doc-builder.js";import{I as q}from"../chunks/IconCopyLink-hf-doc-builder.js";function as(gi){let b,Zt,_,D,lt,se,sa,st,na,eo,E,Y,nt,ne,fa,ft,ha,to,De,ca,oo,k,Ye,yi,da,We,wi,ao,W,ua,ht,pa,ma,ro,A,j,ct,fe,va,dt,ga,io,je,ya,lo,m,ut,wa,ba,pt,_a,Ea,mt,ka,so,Ge,Aa,no,G,Ia,he,Pa,$a,fo,Me,Ta,ho,v,ce,La,vt,xa,Na,Sa,Fe,Ca,Be,Ha,Oa,gt,Ua,co,Ve,Ra,uo,M,qa,yt,Da,Ya,po,I,F,wt,de,Wa,bt,ja,mo,P,B,_t,ue,Ga,Et,Ma,vo,u,Fa,kt,Ba,Va,At,Ja,za,It,Ka,Qa,go,V,Pt,pe,Xa,Za,$t,me,er,yo,Je,tr,wo,$,J,Tt,ve,or,Lt,ar,bo,z,rr,ge,ir,lr,_o,ze,xt,sr,Eo,K,Q,nr,ye,fr,hr,T,Nt,we,cr,dr,St,be,ur,pr,Ct,_e,mr,vr,X,gr,Ee,Ht,yr,wr,Ot,Ut,ke,br,ko,L,Z,Rt,Ae,_r,qt,Er,Ao,Ke,Dt,kr,Io,ee,Ar,Ie,Ir,Pr,Po,p,$r,Pe,Tr,Lr,Yt,xr,Nr,Wt,Sr,Cr,$o,x,te,jt,$e,Hr,Gt,Or,To,Qe,Ur,Lo,Xe,Ze,Rr,Mt,qr,xo,oe,Dr,Te,Yr,Wr,No,g,Le,jr,Ft,Gr,Mr,Fr,xe,Br,Bt,Vr,Jr,zr,Ne,Kr,Vt,Qr,Xr,So,Se,Jt,Zr,Co,y,ei,Ce,ti,oi,He,ai,ri,Ho,N,ae,zt,Oe,ii,Kt,li,Oo,re,si,Ue,ni,fi,Uo,w,hi,Re,ci,di,qe,ui,pi,Ro;return se=new q({}),ne=new q({}),fe=new q({}),de=new q({}),ue=new q({}),ve=new q({}),Ae=new q({}),$e=new q({}),Oe=new q({}),{c(){b=a("meta"),Zt=c(),_=a("h1"),D=a("a"),lt=a("span"),S(se.$$.fragment),sa=c(),st=a("span"),na=l("Tasks"),eo=c(),E=a("h2"),Y=a("a"),nt=a("span"),S(ne.$$.fragment),fa=c(),ft=a("span"),ha=l("What's a task?"),to=c(),De=a("p"),ca=l("Tasks, or pipeline types, describe the \u201Cshape\u201D of each model\u2019s API (inputs and outputs) and are used to determine which Inference API and widget we want to display for any given model."),oo=c(),k=a("div"),Ye=a("img"),da=c(),We=a("img"),ao=c(),W=a("p"),ua=l("This classification is relatively coarse-grained (you can always add more fine-grained task names in your model tags), so "),ht=a("strong"),pa=l("you should rarely have to create a new task"),ma=l(". If you want to add support for a new task, this document explains the required steps."),ro=c(),A=a("h2"),j=a("a"),ct=a("span"),S(fe.$$.fragment),va=c(),dt=a("span"),ga=l("Overview"),io=c(),je=a("p"),ya=l("Having a new task integrated into the Hub means that:"),lo=c(),m=a("ul"),ut=a("li"),wa=l("Users can search for all models of a given task."),ba=c(),pt=a("li"),_a=l("The Inference API supports the task."),Ea=c(),mt=a("li"),ka=l("Users can try out models directly with the widget. \u{1F3C6}"),so=c(),Ge=a("p"),Aa=l("Note that you don\u2019t need to implement all the steps by yourself. Adding a new task is a community effort, and multiple people can contribute. \u{1F9D1}\u200D\u{1F91D}\u200D\u{1F9D1}"),no=c(),G=a("p"),Ia=l("To begin the process, open a new issue in the "),he=a("a"),Pa=l("huggingface_hub"),$a=l(" repository. Please use the \u201CAdding a new task\u201D template. \u26A0\uFE0FBefore doing any coding, it\u2019s suggested to go over this document. \u26A0\uFE0F"),fo=c(),Me=a("p"),Ta=l("The first step is to upload a model for your proposed task. Once you have a model in the Hub for the new task, the next step is to enable it in the Inference API. There are three types of support that you can choose from:"),ho=c(),v=a("ul"),ce=a("li"),La=l("\u{1F917} using a "),vt=a("code"),xa=l("transformers"),Na=l(" model"),Sa=c(),Fe=a("li"),Ca=l("\u{1F433} using a model from an "),Be=a("a"),Ha=l("officially supported library"),Oa=c(),gt=a("li"),Ua=l("\u{1F5A8}\uFE0F using a model with custom inference code. This experimental option has downsides, so we recommend using one of the other approaches."),co=c(),Ve=a("p"),Ra=l("Finally, you can add a couple of UI elements, such as the task icon and the widget, that complete the integration in the Hub. \u{1F4F7}"),uo=c(),M=a("p"),qa=l("Some steps are orthogonal; you don\u2019t need to do them in order. "),yt=a("strong"),Da=l("You don\u2019t need the Inference API to add the icon."),Ya=l(" This means that, even if there isn\u2019t full integration yet, users can still search for models of a given task."),po=c(),I=a("h2"),F=a("a"),wt=a("span"),S(de.$$.fragment),Wa=c(),bt=a("span"),ja=l("Adding new tasks to the Hub"),mo=c(),P=a("h3"),B=a("a"),_t=a("span"),S(ue.$$.fragment),Ga=c(),Et=a("span"),Ma=l("Using Hugging Face transformers library"),vo=c(),u=a("p"),Fa=l("If your model is a "),kt=a("code"),Ba=l("transformers"),Va=l("-based model, there is a 1:1 mapping between the Inference API task and a "),At=a("code"),Ja=l("pipeline"),za=l(" class. Here are some example PRs from the "),It=a("code"),Ka=l("transformers"),Qa=l(" library:"),go=c(),V=a("ul"),Pt=a("li"),pe=a("a"),Xa=l("Adding ImageClassificationPipeline"),Za=c(),$t=a("li"),me=a("a"),er=l("Adding AudioClassificationPipeline"),yo=c(),Je=a("p"),tr=l("Once the pipeline is submitted and deployed, you should be able to use the Inference API for your model."),wo=c(),$=a("h3"),J=a("a"),Tt=a("span"),S(ve.$$.fragment),or=c(),Lt=a("span"),ar=l("Using Community Inference API with a supported library"),bo=c(),z=a("p"),rr=l("The Hub also supports over 10 open-source libraries in the "),ge=a("a"),ir=l("Community Inference API"),lr=l("."),_o=c(),ze=a("p"),xt=a("strong"),sr=l("Adding a new task is relatively straightforward and requires 2 PRs:"),Eo=c(),K=a("ul"),Q=a("li"),nr=l("PR 1: Add the new task to the API "),ye=a("a"),fr=l("validation"),hr=l(". This code ensures that the inference input is valid for a given task. Some PR examples:"),T=a("ul"),Nt=a("li"),we=a("a"),cr=l("Add text-to-image"),dr=c(),St=a("li"),be=a("a"),ur=l("Add audio-classification"),pr=c(),Ct=a("li"),_e=a("a"),mr=l("Add tabular-classification"),vr=c(),X=a("li"),gr=l("PR 2: Add the new task to a library docker image. You should also add a template to "),Ee=a("a"),Ht=a("code"),yr=l("docker_images/common/app/pipelines"),wr=l(" to facilitate integrating the task in other libraries. Here is an example PR:"),Ot=a("ul"),Ut=a("li"),ke=a("a"),br=l("Add text-classification to spaCy"),ko=c(),L=a("h3"),Z=a("a"),Rt=a("span"),S(Ae.$$.fragment),_r=c(),qt=a("span"),Er=l("Adding Community Inference API for a quick prototype"),Ao=c(),Ke=a("p"),Dt=a("strong"),kr=l("My model is not supported by any library. Am I doomed? \u{1F631}"),Io=c(),ee=a("p"),Ar=l("No, you\u2019re not! The "),Ie=a("a"),Ir=l("generic Inference API"),Pr=l(" is an experimental Docker image for quickly prototyping new tasks and introducing new libraries,  which should allow you to have a new task in production with very little development from your side."),Po=c(),p=a("p"),$r=l("How does it work from the user\u2019s point of view? Users create a copy of a "),Pe=a("a"),Tr=l("template"),Lr=l(" repo for their given task. Users then need to define their "),Yt=a("code"),xr=l("requirements.txt"),Nr=l(" and fill "),Wt=a("code"),Sr=l("pipeline.py"),Cr=l(". Note that this is intended for quick experimentation and prototyping instead of fast production use-cases."),$o=c(),x=a("h3"),te=a("a"),jt=a("span"),S($e.$$.fragment),Hr=c(),Gt=a("span"),Or=l("UI elements"),To=c(),Qe=a("p"),Ur=l("The Hub allows users to filter models by a given task. To do this, you need to add the task to several places. You\u2019ll also get to pick an icon for the task!"),Lo=c(),Xe=a("ol"),Ze=a("li"),Rr=l("Add the task type to "),Mt=a("code"),qr=l("Types.ts"),xo=c(),oe=a("p"),Dr=l("In "),Te=a("a"),Yr=l("interfaces/Types.ts"),Wr=l(", you need to do a couple of things"),No=c(),g=a("ul"),Le=a("li"),jr=l("Add the type to "),Ft=a("code"),Gr=l("PipelineType"),Mr=l(". Note that pipeline types are sorted into different categories (NLP, Audio, Computer Vision, and others)."),Fr=c(),xe=a("li"),Br=l("Specify the task color in "),Bt=a("code"),Vr=l("PIPELINE_COLOR"),Jr=l("."),zr=c(),Ne=a("li"),Kr=l("Specify the display order in "),Vt=a("code"),Qr=l("PIPELINE_TAGS_DISPLAY_ORDER"),Xr=l("."),So=c(),Se=a("ol"),Jt=a("li"),Zr=l("Choose an icon"),Co=c(),y=a("p"),ei=l("You can add an icon in the "),Ce=a("a"),ti=l("lib/Icons"),oi=l(" directory. We usually choose carbon icons from "),He=a("a"),ai=l("https://icones.js.org/collection/carbon"),ri=l("."),Ho=c(),N=a("h3"),ae=a("a"),zt=a("span"),S(Oe.$$.fragment),ii=c(),Kt=a("span"),li=l("Widget"),Oo=c(),re=a("p"),si=l("Once the task is in production, what could be more exciting than implementing some way for users to play directly with the models in their browser? \u{1F929} You can find all the widgets "),Ue=a("a"),ni=l("here"),fi=l("."),Uo=c(),w=a("p"),hi=l("If you would be interested in contributing with a widget, you can look at the "),Re=a("a"),ci=l("implementation"),di=l(" of all the widgets. You can also find WIP documentation on implementing a widget in "),qe=a("a"),ui=l("https://github.com/huggingface/hub-docs/tree/main/js"),pi=l("."),this.h()},l(e){const f=es('[data-svelte="svelte-1phssyn"]',document.head);b=r(f,"META",{name:!0,content:!0}),f.forEach(o),Zt=d(e),_=r(e,"H1",{class:!0});var qo=i(_);D=r(qo,"A",{id:!0,class:!0,href:!0});var bi=i(D);lt=r(bi,"SPAN",{});var _i=i(lt);C(se.$$.fragment,_i),_i.forEach(o),bi.forEach(o),sa=d(qo),st=r(qo,"SPAN",{});var Ei=i(st);na=s(Ei,"Tasks"),Ei.forEach(o),qo.forEach(o),eo=d(e),E=r(e,"H2",{class:!0});var Do=i(E);Y=r(Do,"A",{id:!0,class:!0,href:!0});var ki=i(Y);nt=r(ki,"SPAN",{});var Ai=i(nt);C(ne.$$.fragment,Ai),Ai.forEach(o),ki.forEach(o),fa=d(Do),ft=r(Do,"SPAN",{});var Ii=i(ft);ha=s(Ii,"What's a task?"),Ii.forEach(o),Do.forEach(o),to=d(e),De=r(e,"P",{});var Pi=i(De);ca=s(Pi,"Tasks, or pipeline types, describe the \u201Cshape\u201D of each model\u2019s API (inputs and outputs) and are used to determine which Inference API and widget we want to display for any given model."),Pi.forEach(o),oo=d(e),k=r(e,"DIV",{class:!0});var Yo=i(k);Ye=r(Yo,"IMG",{class:!0,src:!0}),da=d(Yo),We=r(Yo,"IMG",{class:!0,src:!0}),Yo.forEach(o),ao=d(e),W=r(e,"P",{});var Wo=i(W);ua=s(Wo,"This classification is relatively coarse-grained (you can always add more fine-grained task names in your model tags), so "),ht=r(Wo,"STRONG",{});var $i=i(ht);pa=s($i,"you should rarely have to create a new task"),$i.forEach(o),ma=s(Wo,". If you want to add support for a new task, this document explains the required steps."),Wo.forEach(o),ro=d(e),A=r(e,"H2",{class:!0});var jo=i(A);j=r(jo,"A",{id:!0,class:!0,href:!0});var Ti=i(j);ct=r(Ti,"SPAN",{});var Li=i(ct);C(fe.$$.fragment,Li),Li.forEach(o),Ti.forEach(o),va=d(jo),dt=r(jo,"SPAN",{});var xi=i(dt);ga=s(xi,"Overview"),xi.forEach(o),jo.forEach(o),io=d(e),je=r(e,"P",{});var Ni=i(je);ya=s(Ni,"Having a new task integrated into the Hub means that:"),Ni.forEach(o),lo=d(e),m=r(e,"UL",{});var et=i(m);ut=r(et,"LI",{});var Si=i(ut);wa=s(Si,"Users can search for all models of a given task."),Si.forEach(o),ba=d(et),pt=r(et,"LI",{});var Ci=i(pt);_a=s(Ci,"The Inference API supports the task."),Ci.forEach(o),Ea=d(et),mt=r(et,"LI",{});var Hi=i(mt);ka=s(Hi,"Users can try out models directly with the widget. \u{1F3C6}"),Hi.forEach(o),et.forEach(o),so=d(e),Ge=r(e,"P",{});var Oi=i(Ge);Aa=s(Oi,"Note that you don\u2019t need to implement all the steps by yourself. Adding a new task is a community effort, and multiple people can contribute. \u{1F9D1}\u200D\u{1F91D}\u200D\u{1F9D1}"),Oi.forEach(o),no=d(e),G=r(e,"P",{});var Go=i(G);Ia=s(Go,"To begin the process, open a new issue in the "),he=r(Go,"A",{href:!0,rel:!0});var Ui=i(he);Pa=s(Ui,"huggingface_hub"),Ui.forEach(o),$a=s(Go," repository. Please use the \u201CAdding a new task\u201D template. \u26A0\uFE0FBefore doing any coding, it\u2019s suggested to go over this document. \u26A0\uFE0F"),Go.forEach(o),fo=d(e),Me=r(e,"P",{});var Ri=i(Me);Ta=s(Ri,"The first step is to upload a model for your proposed task. Once you have a model in the Hub for the new task, the next step is to enable it in the Inference API. There are three types of support that you can choose from:"),Ri.forEach(o),ho=d(e),v=r(e,"UL",{});var tt=i(v);ce=r(tt,"LI",{});var Mo=i(ce);La=s(Mo,"\u{1F917} using a "),vt=r(Mo,"CODE",{});var qi=i(vt);xa=s(qi,"transformers"),qi.forEach(o),Na=s(Mo," model"),Mo.forEach(o),Sa=d(tt),Fe=r(tt,"LI",{});var mi=i(Fe);Ca=s(mi,"\u{1F433} using a model from an "),Be=r(mi,"A",{href:!0});var Di=i(Be);Ha=s(Di,"officially supported library"),Di.forEach(o),mi.forEach(o),Oa=d(tt),gt=r(tt,"LI",{});var Yi=i(gt);Ua=s(Yi,"\u{1F5A8}\uFE0F using a model with custom inference code. This experimental option has downsides, so we recommend using one of the other approaches."),Yi.forEach(o),tt.forEach(o),co=d(e),Ve=r(e,"P",{});var Wi=i(Ve);Ra=s(Wi,"Finally, you can add a couple of UI elements, such as the task icon and the widget, that complete the integration in the Hub. \u{1F4F7}"),Wi.forEach(o),uo=d(e),M=r(e,"P",{});var Fo=i(M);qa=s(Fo,"Some steps are orthogonal; you don\u2019t need to do them in order. "),yt=r(Fo,"STRONG",{});var ji=i(yt);Da=s(ji,"You don\u2019t need the Inference API to add the icon."),ji.forEach(o),Ya=s(Fo," This means that, even if there isn\u2019t full integration yet, users can still search for models of a given task."),Fo.forEach(o),po=d(e),I=r(e,"H2",{class:!0});var Bo=i(I);F=r(Bo,"A",{id:!0,class:!0,href:!0});var Gi=i(F);wt=r(Gi,"SPAN",{});var Mi=i(wt);C(de.$$.fragment,Mi),Mi.forEach(o),Gi.forEach(o),Wa=d(Bo),bt=r(Bo,"SPAN",{});var Fi=i(bt);ja=s(Fi,"Adding new tasks to the Hub"),Fi.forEach(o),Bo.forEach(o),mo=d(e),P=r(e,"H3",{class:!0});var Vo=i(P);B=r(Vo,"A",{id:!0,class:!0,href:!0});var Bi=i(B);_t=r(Bi,"SPAN",{});var Vi=i(_t);C(ue.$$.fragment,Vi),Vi.forEach(o),Bi.forEach(o),Ga=d(Vo),Et=r(Vo,"SPAN",{});var Ji=i(Et);Ma=s(Ji,"Using Hugging Face transformers library"),Ji.forEach(o),Vo.forEach(o),vo=d(e),u=r(e,"P",{});var ie=i(u);Fa=s(ie,"If your model is a "),kt=r(ie,"CODE",{});var zi=i(kt);Ba=s(zi,"transformers"),zi.forEach(o),Va=s(ie,"-based model, there is a 1:1 mapping between the Inference API task and a "),At=r(ie,"CODE",{});var Ki=i(At);Ja=s(Ki,"pipeline"),Ki.forEach(o),za=s(ie," class. Here are some example PRs from the "),It=r(ie,"CODE",{});var Qi=i(It);Ka=s(Qi,"transformers"),Qi.forEach(o),Qa=s(ie," library:"),ie.forEach(o),go=d(e),V=r(e,"UL",{});var Jo=i(V);Pt=r(Jo,"LI",{});var Xi=i(Pt);pe=r(Xi,"A",{href:!0,rel:!0});var Zi=i(pe);Xa=s(Zi,"Adding ImageClassificationPipeline"),Zi.forEach(o),Xi.forEach(o),Za=d(Jo),$t=r(Jo,"LI",{});var el=i($t);me=r(el,"A",{href:!0,rel:!0});var tl=i(me);er=s(tl,"Adding AudioClassificationPipeline"),tl.forEach(o),el.forEach(o),Jo.forEach(o),yo=d(e),Je=r(e,"P",{});var ol=i(Je);tr=s(ol,"Once the pipeline is submitted and deployed, you should be able to use the Inference API for your model."),ol.forEach(o),wo=d(e),$=r(e,"H3",{class:!0});var zo=i($);J=r(zo,"A",{id:!0,class:!0,href:!0});var al=i(J);Tt=r(al,"SPAN",{});var rl=i(Tt);C(ve.$$.fragment,rl),rl.forEach(o),al.forEach(o),or=d(zo),Lt=r(zo,"SPAN",{});var il=i(Lt);ar=s(il,"Using Community Inference API with a supported library"),il.forEach(o),zo.forEach(o),bo=d(e),z=r(e,"P",{});var Ko=i(z);rr=s(Ko,"The Hub also supports over 10 open-source libraries in the "),ge=r(Ko,"A",{href:!0,rel:!0});var ll=i(ge);ir=s(ll,"Community Inference API"),ll.forEach(o),lr=s(Ko,"."),Ko.forEach(o),_o=d(e),ze=r(e,"P",{});var sl=i(ze);xt=r(sl,"STRONG",{});var nl=i(xt);sr=s(nl,"Adding a new task is relatively straightforward and requires 2 PRs:"),nl.forEach(o),sl.forEach(o),Eo=d(e),K=r(e,"UL",{});var Qo=i(K);Q=r(Qo,"LI",{});var Qt=i(Q);nr=s(Qt,"PR 1: Add the new task to the API "),ye=r(Qt,"A",{href:!0,rel:!0});var fl=i(ye);fr=s(fl,"validation"),fl.forEach(o),hr=s(Qt,". This code ensures that the inference input is valid for a given task. Some PR examples:"),T=r(Qt,"UL",{});var ot=i(T);Nt=r(ot,"LI",{});var hl=i(Nt);we=r(hl,"A",{href:!0,rel:!0});var cl=i(we);cr=s(cl,"Add text-to-image"),cl.forEach(o),hl.forEach(o),dr=d(ot),St=r(ot,"LI",{});var dl=i(St);be=r(dl,"A",{href:!0,rel:!0});var ul=i(be);ur=s(ul,"Add audio-classification"),ul.forEach(o),dl.forEach(o),pr=d(ot),Ct=r(ot,"LI",{});var pl=i(Ct);_e=r(pl,"A",{href:!0,rel:!0});var ml=i(_e);mr=s(ml,"Add tabular-classification"),ml.forEach(o),pl.forEach(o),ot.forEach(o),Qt.forEach(o),vr=d(Qo),X=r(Qo,"LI",{});var Xt=i(X);gr=s(Xt,"PR 2: Add the new task to a library docker image. You should also add a template to "),Ee=r(Xt,"A",{href:!0,rel:!0});var vl=i(Ee);Ht=r(vl,"CODE",{});var gl=i(Ht);yr=s(gl,"docker_images/common/app/pipelines"),gl.forEach(o),vl.forEach(o),wr=s(Xt," to facilitate integrating the task in other libraries. Here is an example PR:"),Ot=r(Xt,"UL",{});var yl=i(Ot);Ut=r(yl,"LI",{});var wl=i(Ut);ke=r(wl,"A",{href:!0,rel:!0});var bl=i(ke);br=s(bl,"Add text-classification to spaCy"),bl.forEach(o),wl.forEach(o),yl.forEach(o),Xt.forEach(o),Qo.forEach(o),ko=d(e),L=r(e,"H3",{class:!0});var Xo=i(L);Z=r(Xo,"A",{id:!0,class:!0,href:!0});var _l=i(Z);Rt=r(_l,"SPAN",{});var El=i(Rt);C(Ae.$$.fragment,El),El.forEach(o),_l.forEach(o),_r=d(Xo),qt=r(Xo,"SPAN",{});var kl=i(qt);Er=s(kl,"Adding Community Inference API for a quick prototype"),kl.forEach(o),Xo.forEach(o),Ao=d(e),Ke=r(e,"P",{});var Al=i(Ke);Dt=r(Al,"STRONG",{});var Il=i(Dt);kr=s(Il,"My model is not supported by any library. Am I doomed? \u{1F631}"),Il.forEach(o),Al.forEach(o),Io=d(e),ee=r(e,"P",{});var Zo=i(ee);Ar=s(Zo,"No, you\u2019re not! The "),Ie=r(Zo,"A",{href:!0,rel:!0});var Pl=i(Ie);Ir=s(Pl,"generic Inference API"),Pl.forEach(o),Pr=s(Zo," is an experimental Docker image for quickly prototyping new tasks and introducing new libraries,  which should allow you to have a new task in production with very little development from your side."),Zo.forEach(o),Po=d(e),p=r(e,"P",{});var le=i(p);$r=s(le,"How does it work from the user\u2019s point of view? Users create a copy of a "),Pe=r(le,"A",{href:!0,rel:!0});var $l=i(Pe);Tr=s($l,"template"),$l.forEach(o),Lr=s(le," repo for their given task. Users then need to define their "),Yt=r(le,"CODE",{});var Tl=i(Yt);xr=s(Tl,"requirements.txt"),Tl.forEach(o),Nr=s(le," and fill "),Wt=r(le,"CODE",{});var Ll=i(Wt);Sr=s(Ll,"pipeline.py"),Ll.forEach(o),Cr=s(le,". Note that this is intended for quick experimentation and prototyping instead of fast production use-cases."),le.forEach(o),$o=d(e),x=r(e,"H3",{class:!0});var ea=i(x);te=r(ea,"A",{id:!0,class:!0,href:!0});var xl=i(te);jt=r(xl,"SPAN",{});var Nl=i(jt);C($e.$$.fragment,Nl),Nl.forEach(o),xl.forEach(o),Hr=d(ea),Gt=r(ea,"SPAN",{});var Sl=i(Gt);Or=s(Sl,"UI elements"),Sl.forEach(o),ea.forEach(o),To=d(e),Qe=r(e,"P",{});var Cl=i(Qe);Ur=s(Cl,"The Hub allows users to filter models by a given task. To do this, you need to add the task to several places. You\u2019ll also get to pick an icon for the task!"),Cl.forEach(o),Lo=d(e),Xe=r(e,"OL",{});var Hl=i(Xe);Ze=r(Hl,"LI",{});var vi=i(Ze);Rr=s(vi,"Add the task type to "),Mt=r(vi,"CODE",{});var Ol=i(Mt);qr=s(Ol,"Types.ts"),Ol.forEach(o),vi.forEach(o),Hl.forEach(o),xo=d(e),oe=r(e,"P",{});var ta=i(oe);Dr=s(ta,"In "),Te=r(ta,"A",{href:!0,rel:!0});var Ul=i(Te);Yr=s(Ul,"interfaces/Types.ts"),Ul.forEach(o),Wr=s(ta,", you need to do a couple of things"),ta.forEach(o),No=d(e),g=r(e,"UL",{});var at=i(g);Le=r(at,"LI",{});var oa=i(Le);jr=s(oa,"Add the type to "),Ft=r(oa,"CODE",{});var Rl=i(Ft);Gr=s(Rl,"PipelineType"),Rl.forEach(o),Mr=s(oa,". Note that pipeline types are sorted into different categories (NLP, Audio, Computer Vision, and others)."),oa.forEach(o),Fr=d(at),xe=r(at,"LI",{});var aa=i(xe);Br=s(aa,"Specify the task color in "),Bt=r(aa,"CODE",{});var ql=i(Bt);Vr=s(ql,"PIPELINE_COLOR"),ql.forEach(o),Jr=s(aa,"."),aa.forEach(o),zr=d(at),Ne=r(at,"LI",{});var ra=i(Ne);Kr=s(ra,"Specify the display order in "),Vt=r(ra,"CODE",{});var Dl=i(Vt);Qr=s(Dl,"PIPELINE_TAGS_DISPLAY_ORDER"),Dl.forEach(o),Xr=s(ra,"."),ra.forEach(o),at.forEach(o),So=d(e),Se=r(e,"OL",{start:!0});var Yl=i(Se);Jt=r(Yl,"LI",{});var Wl=i(Jt);Zr=s(Wl,"Choose an icon"),Wl.forEach(o),Yl.forEach(o),Co=d(e),y=r(e,"P",{});var rt=i(y);ei=s(rt,"You can add an icon in the "),Ce=r(rt,"A",{href:!0,rel:!0});var jl=i(Ce);ti=s(jl,"lib/Icons"),jl.forEach(o),oi=s(rt," directory. We usually choose carbon icons from "),He=r(rt,"A",{href:!0,rel:!0});var Gl=i(He);ai=s(Gl,"https://icones.js.org/collection/carbon"),Gl.forEach(o),ri=s(rt,"."),rt.forEach(o),Ho=d(e),N=r(e,"H3",{class:!0});var ia=i(N);ae=r(ia,"A",{id:!0,class:!0,href:!0});var Ml=i(ae);zt=r(Ml,"SPAN",{});var Fl=i(zt);C(Oe.$$.fragment,Fl),Fl.forEach(o),Ml.forEach(o),ii=d(ia),Kt=r(ia,"SPAN",{});var Bl=i(Kt);li=s(Bl,"Widget"),Bl.forEach(o),ia.forEach(o),Oo=d(e),re=r(e,"P",{});var la=i(re);si=s(la,"Once the task is in production, what could be more exciting than implementing some way for users to play directly with the models in their browser? \u{1F929} You can find all the widgets "),Ue=r(la,"A",{href:!0,rel:!0});var Vl=i(Ue);ni=s(Vl,"here"),Vl.forEach(o),fi=s(la,"."),la.forEach(o),Uo=d(e),w=r(e,"P",{});var it=i(w);hi=s(it,"If you would be interested in contributing with a widget, you can look at the "),Re=r(it,"A",{href:!0,rel:!0});var Jl=i(Re);ci=s(Jl,"implementation"),Jl.forEach(o),di=s(it," of all the widgets. You can also find WIP documentation on implementing a widget in "),qe=r(it,"A",{href:!0,rel:!0});var zl=i(qe);ui=s(zl,"https://github.com/huggingface/hub-docs/tree/main/js"),zl.forEach(o),pi=s(it,"."),it.forEach(o),this.h()},h(){n(b,"name","hf:doc:metadata"),n(b,"content",JSON.stringify(rs)),n(D,"id","tasks"),n(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(D,"href","#tasks"),n(_,"class","relative group"),n(Y,"id","whats-a-task"),n(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(Y,"href","#whats-a-task"),n(E,"class","relative group"),n(Ye,"class","block dark:hidden"),Kl(Ye.src,yi="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/tasks.png")||n(Ye,"src",yi),n(We,"class","hidden dark:block"),Kl(We.src,wi="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/tasks-dark.png")||n(We,"src",wi),n(k,"class","flex justify-center"),n(j,"id","overview"),n(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(j,"href","#overview"),n(A,"class","relative group"),n(he,"href","https://github.com/huggingface/huggingface_hub/issues"),n(he,"rel","nofollow"),n(Be,"href","./models-libraries"),n(F,"id","adding-new-tasks-to-the-hub"),n(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(F,"href","#adding-new-tasks-to-the-hub"),n(I,"class","relative group"),n(B,"id","using-hugging-face-transformers-library"),n(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(B,"href","#using-hugging-face-transformers-library"),n(P,"class","relative group"),n(pe,"href","https://github.com/huggingface/transformers/pull/11598"),n(pe,"rel","nofollow"),n(me,"href","https://github.com/huggingface/transformers/pull/13342"),n(me,"rel","nofollow"),n(J,"id","using-community-inference-api-with-a-supported-library"),n(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(J,"href","#using-community-inference-api-with-a-supported-library"),n($,"class","relative group"),n(ge,"href","https://github.com/huggingface/api-inference-community"),n(ge,"rel","nofollow"),n(ye,"href","https://github.com/huggingface/api-inference-community/blob/main/api_inference_community/validation.py"),n(ye,"rel","nofollow"),n(we,"href","https://github.com/huggingface/huggingface_hub/commit/5f040a117cf2a44d704621012eb41c01b103cfca#diff-db8bbac95c077540d79900384cfd524d451e629275cbb5de7a31fc1cd5d6c189"),n(we,"rel","nofollow"),n(be,"href","https://github.com/huggingface/huggingface_hub/commit/141e30588a2031d4d5798eaa2c1250d1d1b75905#diff-db8bbac95c077540d79900384cfd524d451e629275cbb5de7a31fc1cd5d6c189"),n(be,"rel","nofollow"),n(_e,"href","https://github.com/huggingface/huggingface_hub/commit/dbea604a45df163d3f0b4b1d897e4b0fb951c650#diff-db8bbac95c077540d79900384cfd524d451e629275cbb5de7a31fc1cd5d6c189"),n(_e,"rel","nofollow"),n(Ee,"href","https://github.com/huggingface/api-inference-community/tree/main/docker_images/common/app/pipelines"),n(Ee,"rel","nofollow"),n(ke,"href","https://github.com/huggingface/huggingface_hub/commit/6926fd9bec23cb963ce3f58ec53496083997f0fa#diff-3f1083a92ca0047b50f9ad2d04f0fe8dfaeee0e26ab71eb8835e365359a1d0dc"),n(ke,"rel","nofollow"),n(Z,"id","adding-community-inference-api-for-a-quick-prototype"),n(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(Z,"href","#adding-community-inference-api-for-a-quick-prototype"),n(L,"class","relative group"),n(Ie,"href","https://github.com/huggingface/api-inference-community/tree/main/docker_images/generic"),n(Ie,"rel","nofollow"),n(Pe,"href","https://huggingface.co/templates"),n(Pe,"rel","nofollow"),n(te,"id","ui-elements"),n(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(te,"href","#ui-elements"),n(x,"class","relative group"),n(Te,"href","https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts"),n(Te,"rel","nofollow"),n(Se,"start","2"),n(Ce,"href","https://github.com/huggingface/hub-docs/tree/main/js/src/lib/Icons"),n(Ce,"rel","nofollow"),n(He,"href","https://icones.js.org/collection/carbon"),n(He,"rel","nofollow"),n(ae,"id","widget"),n(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(ae,"href","#widget"),n(N,"class","relative group"),n(Ue,"href","https://huggingface-widgets.netlify.app/"),n(Ue,"rel","nofollow"),n(Re,"href","https://github.com/huggingface/hub-docs/tree/main/js/src/lib/components/InferenceWidget/widgets"),n(Re,"rel","nofollow"),n(qe,"href","https://github.com/huggingface/hub-docs/tree/main/js"),n(qe,"rel","nofollow")},m(e,f){t(document.head,b),h(e,Zt,f),h(e,_,f),t(_,D),t(D,lt),H(se,lt,null),t(_,sa),t(_,st),t(st,na),h(e,eo,f),h(e,E,f),t(E,Y),t(Y,nt),H(ne,nt,null),t(E,fa),t(E,ft),t(ft,ha),h(e,to,f),h(e,De,f),t(De,ca),h(e,oo,f),h(e,k,f),t(k,Ye),t(k,da),t(k,We),h(e,ao,f),h(e,W,f),t(W,ua),t(W,ht),t(ht,pa),t(W,ma),h(e,ro,f),h(e,A,f),t(A,j),t(j,ct),H(fe,ct,null),t(A,va),t(A,dt),t(dt,ga),h(e,io,f),h(e,je,f),t(je,ya),h(e,lo,f),h(e,m,f),t(m,ut),t(ut,wa),t(m,ba),t(m,pt),t(pt,_a),t(m,Ea),t(m,mt),t(mt,ka),h(e,so,f),h(e,Ge,f),t(Ge,Aa),h(e,no,f),h(e,G,f),t(G,Ia),t(G,he),t(he,Pa),t(G,$a),h(e,fo,f),h(e,Me,f),t(Me,Ta),h(e,ho,f),h(e,v,f),t(v,ce),t(ce,La),t(ce,vt),t(vt,xa),t(ce,Na),t(v,Sa),t(v,Fe),t(Fe,Ca),t(Fe,Be),t(Be,Ha),t(v,Oa),t(v,gt),t(gt,Ua),h(e,co,f),h(e,Ve,f),t(Ve,Ra),h(e,uo,f),h(e,M,f),t(M,qa),t(M,yt),t(yt,Da),t(M,Ya),h(e,po,f),h(e,I,f),t(I,F),t(F,wt),H(de,wt,null),t(I,Wa),t(I,bt),t(bt,ja),h(e,mo,f),h(e,P,f),t(P,B),t(B,_t),H(ue,_t,null),t(P,Ga),t(P,Et),t(Et,Ma),h(e,vo,f),h(e,u,f),t(u,Fa),t(u,kt),t(kt,Ba),t(u,Va),t(u,At),t(At,Ja),t(u,za),t(u,It),t(It,Ka),t(u,Qa),h(e,go,f),h(e,V,f),t(V,Pt),t(Pt,pe),t(pe,Xa),t(V,Za),t(V,$t),t($t,me),t(me,er),h(e,yo,f),h(e,Je,f),t(Je,tr),h(e,wo,f),h(e,$,f),t($,J),t(J,Tt),H(ve,Tt,null),t($,or),t($,Lt),t(Lt,ar),h(e,bo,f),h(e,z,f),t(z,rr),t(z,ge),t(ge,ir),t(z,lr),h(e,_o,f),h(e,ze,f),t(ze,xt),t(xt,sr),h(e,Eo,f),h(e,K,f),t(K,Q),t(Q,nr),t(Q,ye),t(ye,fr),t(Q,hr),t(Q,T),t(T,Nt),t(Nt,we),t(we,cr),t(T,dr),t(T,St),t(St,be),t(be,ur),t(T,pr),t(T,Ct),t(Ct,_e),t(_e,mr),t(K,vr),t(K,X),t(X,gr),t(X,Ee),t(Ee,Ht),t(Ht,yr),t(X,wr),t(X,Ot),t(Ot,Ut),t(Ut,ke),t(ke,br),h(e,ko,f),h(e,L,f),t(L,Z),t(Z,Rt),H(Ae,Rt,null),t(L,_r),t(L,qt),t(qt,Er),h(e,Ao,f),h(e,Ke,f),t(Ke,Dt),t(Dt,kr),h(e,Io,f),h(e,ee,f),t(ee,Ar),t(ee,Ie),t(Ie,Ir),t(ee,Pr),h(e,Po,f),h(e,p,f),t(p,$r),t(p,Pe),t(Pe,Tr),t(p,Lr),t(p,Yt),t(Yt,xr),t(p,Nr),t(p,Wt),t(Wt,Sr),t(p,Cr),h(e,$o,f),h(e,x,f),t(x,te),t(te,jt),H($e,jt,null),t(x,Hr),t(x,Gt),t(Gt,Or),h(e,To,f),h(e,Qe,f),t(Qe,Ur),h(e,Lo,f),h(e,Xe,f),t(Xe,Ze),t(Ze,Rr),t(Ze,Mt),t(Mt,qr),h(e,xo,f),h(e,oe,f),t(oe,Dr),t(oe,Te),t(Te,Yr),t(oe,Wr),h(e,No,f),h(e,g,f),t(g,Le),t(Le,jr),t(Le,Ft),t(Ft,Gr),t(Le,Mr),t(g,Fr),t(g,xe),t(xe,Br),t(xe,Bt),t(Bt,Vr),t(xe,Jr),t(g,zr),t(g,Ne),t(Ne,Kr),t(Ne,Vt),t(Vt,Qr),t(Ne,Xr),h(e,So,f),h(e,Se,f),t(Se,Jt),t(Jt,Zr),h(e,Co,f),h(e,y,f),t(y,ei),t(y,Ce),t(Ce,ti),t(y,oi),t(y,He),t(He,ai),t(y,ri),h(e,Ho,f),h(e,N,f),t(N,ae),t(ae,zt),H(Oe,zt,null),t(N,ii),t(N,Kt),t(Kt,li),h(e,Oo,f),h(e,re,f),t(re,si),t(re,Ue),t(Ue,ni),t(re,fi),h(e,Uo,f),h(e,w,f),t(w,hi),t(w,Re),t(Re,ci),t(w,di),t(w,qe),t(qe,ui),t(w,pi),Ro=!0},p:ts,i(e){Ro||(O(se.$$.fragment,e),O(ne.$$.fragment,e),O(fe.$$.fragment,e),O(de.$$.fragment,e),O(ue.$$.fragment,e),O(ve.$$.fragment,e),O(Ae.$$.fragment,e),O($e.$$.fragment,e),O(Oe.$$.fragment,e),Ro=!0)},o(e){U(se.$$.fragment,e),U(ne.$$.fragment,e),U(fe.$$.fragment,e),U(de.$$.fragment,e),U(ue.$$.fragment,e),U(ve.$$.fragment,e),U(Ae.$$.fragment,e),U($e.$$.fragment,e),U(Oe.$$.fragment,e),Ro=!1},d(e){o(b),e&&o(Zt),e&&o(_),R(se),e&&o(eo),e&&o(E),R(ne),e&&o(to),e&&o(De),e&&o(oo),e&&o(k),e&&o(ao),e&&o(W),e&&o(ro),e&&o(A),R(fe),e&&o(io),e&&o(je),e&&o(lo),e&&o(m),e&&o(so),e&&o(Ge),e&&o(no),e&&o(G),e&&o(fo),e&&o(Me),e&&o(ho),e&&o(v),e&&o(co),e&&o(Ve),e&&o(uo),e&&o(M),e&&o(po),e&&o(I),R(de),e&&o(mo),e&&o(P),R(ue),e&&o(vo),e&&o(u),e&&o(go),e&&o(V),e&&o(yo),e&&o(Je),e&&o(wo),e&&o($),R(ve),e&&o(bo),e&&o(z),e&&o(_o),e&&o(ze),e&&o(Eo),e&&o(K),e&&o(ko),e&&o(L),R(Ae),e&&o(Ao),e&&o(Ke),e&&o(Io),e&&o(ee),e&&o(Po),e&&o(p),e&&o($o),e&&o(x),R($e),e&&o(To),e&&o(Qe),e&&o(Lo),e&&o(Xe),e&&o(xo),e&&o(oe),e&&o(No),e&&o(g),e&&o(So),e&&o(Se),e&&o(Co),e&&o(y),e&&o(Ho),e&&o(N),R(Oe),e&&o(Oo),e&&o(re),e&&o(Uo),e&&o(w)}}}const rs={local:"tasks",sections:[{local:"whats-a-task",title:"What's a task?"},{local:"overview",title:"Overview"},{local:"adding-new-tasks-to-the-hub",sections:[{local:"using-hugging-face-transformers-library",title:"Using Hugging Face transformers library"},{local:"using-community-inference-api-with-a-supported-library",title:"Using Community Inference API with a supported library"},{local:"adding-community-inference-api-for-a-quick-prototype",title:"Adding Community Inference API for a quick prototype"},{local:"ui-elements",title:"UI elements"},{local:"widget",title:"Widget"}],title:"Adding new tasks to the Hub"}],title:"Tasks"};function is(gi){return os(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ns extends Ql{constructor(b){super();Xl(this,b,is,as,Zl,{})}}export{ns as default,rs as metadata};
