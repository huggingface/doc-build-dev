import{S as Ti,i as _i,s as Ei,e as r,k as n,w as si,t as l,N as pi,c as a,d as e,m as s,a as o,x as hi,h as d,b as h,G as t,g as Q,y as ii,L as gi,q as fi,o as ci,B as ui,v as mi}from"../chunks/vendor-hf-doc-builder.js";import{I as vi}from"../chunks/IconCopyLink-hf-doc-builder.js";function Di(Sn){let Z,Wr,tt,rt,jt,st,ea,Kt,ra,qr,at,aa,Yt,oa,la,Gr,ot,da,ht,na,sa,Jr,lt,Qt,u,Zt,ha,ia,te,fa,ca,ee,ua,va,Rt,Ta,_a,re,Ea,pa,ae,ga,ma,f,v,oe,it,Da,ba,le,ya,wa,de,Aa,Pa,kt,Sa,La,ne,Ra,ka,se,Ha,Ca,T,he,ft,Na,Ia,ie,$a,xa,fe,Fa,Ma,Ht,Oa,za,ce,Ba,Wa,ue,qa,Ga,_,ve,ct,Ja,Va,Te,Ua,Xa,_e,ja,Ka,Ct,Ya,Qa,Ee,Za,to,pe,eo,ro,E,ge,ut,ao,oo,me,lo,no,De,so,ho,Nt,io,fo,be,co,uo,ye,vo,To,p,we,vt,_o,Eo,Ae,po,go,Pe,mo,Do,It,bo,yo,Se,wo,Ao,Le,Po,So,g,Re,Tt,Lo,Ro,ke,ko,Ho,He,Co,No,$t,Io,$o,Ce,xo,Fo,Ne,Mo,Oo,m,Ie,_t,zo,Bo,$e,Wo,qo,xe,Go,Jo,xt,Vo,Uo,Fe,Xo,jo,Me,Ko,Yo,D,Oe,Et,Qo,Zo,ze,tl,el,Be,rl,al,Ft,ol,ll,We,dl,nl,qe,sl,hl,b,Ge,pt,il,fl,Je,cl,ul,Ve,vl,Tl,Mt,_l,El,Ue,pl,gl,Xe,ml,Dl,y,je,gt,bl,yl,Ke,wl,Al,Ye,Pl,Sl,Ot,Ll,Rl,Qe,kl,Hl,Ze,Cl,Nl,w,tr,mt,Il,$l,er,xl,Fl,rr,Ml,Ol,zt,zl,Bl,ar,Wl,ql,or,Gl,Jl,A,lr,Dt,Vl,Ul,dr,Xl,jl,nr,Kl,Yl,Bt,Ql,Zl,sr,td,ed,hr,rd,ad,P,ir,bt,od,ld,fr,dd,nd,cr,sd,hd,Wt,id,fd,ur,cd,ud,vr,vd,Td,S,Tr,yt,_d,Ed,_r,pd,gd,Er,md,Dd,qt,bd,yd,pr,wd,Ad,gr,Pd,Sd,L,mr,wt,Ld,Rd,Dr,kd,Hd,br,Cd,Nd,Gt,Id,$d,yr,xd,Fd,wr,Md,Od,R,Ar,At,zd,Bd,Pr,Wd,qd,Sr,Gd,Jd,Jt,Vd,Ud,Lr,Xd,jd,Rr,Kd,Yd,k,kr,Pt,Qd,Zd,Hr,tn,en,Cr,rn,an,Vt,on,ln,Nr,dn,nn,Ir,sn,hn,H,$r,St,fn,cn,xr,un,vn,Fr,Tn,_n,Ut,En,pn,Mr,gn,mn,Or,Dn,Vr,et,dt,zr,Lt,bn,Br,yn,Ur,nt,wn,Xt,An,Pn,Xr;return st=new vi({}),Lt=new vi({}),{c(){Z=r("meta"),Wr=n(),tt=r("h1"),rt=r("a"),jt=r("span"),si(st.$$.fragment),ea=n(),Kt=r("span"),ra=l("Libraries"),qr=n(),at=r("p"),aa=l("The Hub has support for dozens of libraries in the Open Source ecosystem. Thanks to the "),Yt=r("code"),oa=l("huggingface_hub"),la=l(" Python library, it\u2019s easy to enable sharing your models in the Hub. The Hub supports many libraries, and we\u2019re working on expanding this support! We\u2019re happy to welcome to the Hub a set of Open Source libraries that are pushing Machine Learning forward."),Gr=n(),ot=r("p"),da=l("The table below summarizes the supported libraries and their level of integration. Find all our supported libraries "),ht=r("a"),na=l("here"),sa=l("!"),Jr=n(),lt=r("table"),Qt=r("thead"),u=r("tr"),Zt=r("th"),ha=l("Library"),ia=n(),te=r("th"),fa=l("Description"),ca=n(),ee=r("th"),ua=l("Inference API"),va=n(),Rt=r("th"),Ta=l("Widgets"),_a=n(),re=r("th"),Ea=l("Download from Hub"),pa=n(),ae=r("th"),ga=l("Push to Hub"),ma=n(),f=r("tbody"),v=r("tr"),oe=r("td"),it=r("a"),Da=l("\u{1F917} Transformers"),ba=n(),le=r("td"),ya=l("State-of-the-art Natural Language Processing for Pytorch, TensorFlow, and JAX"),wa=n(),de=r("td"),Aa=l("\u2705"),Pa=n(),kt=r("td"),Sa=l("\u2705"),La=n(),ne=r("td"),Ra=l("\u2705"),ka=n(),se=r("td"),Ha=l("\u2705"),Ca=n(),T=r("tr"),he=r("td"),ft=r("a"),Na=l("\u{1F917} Diffusers"),Ia=n(),ie=r("td"),$a=l("A modular toolbox for inference and training of diffusion models"),xa=n(),fe=r("td"),Fa=l("\u274C"),Ma=n(),Ht=r("td"),Oa=l("\u274C"),za=n(),ce=r("td"),Ba=l("\u2705"),Wa=n(),ue=r("td"),qa=l("\u2705"),Ga=n(),_=r("tr"),ve=r("td"),ct=r("a"),Ja=l("Adapter Transformers"),Va=n(),Te=r("td"),Ua=l("Extends \u{1F917}Transformers with Adapters."),Xa=n(),_e=r("td"),ja=l("\u274C"),Ka=n(),Ct=r("td"),Ya=l("\u274C"),Qa=n(),Ee=r("td"),Za=l("\u2705"),to=n(),pe=r("td"),eo=l("\u2705"),ro=n(),E=r("tr"),ge=r("td"),ut=r("a"),ao=l("AllenNLP"),oo=n(),me=r("td"),lo=l("An open-source NLP research library, built on PyTorch."),no=n(),De=r("td"),so=l("\u2705"),ho=n(),Nt=r("td"),io=l("\u2705"),fo=n(),be=r("td"),co=l("\u2705"),uo=n(),ye=r("td"),vo=l("\u274C"),To=n(),p=r("tr"),we=r("td"),vt=r("a"),_o=l("Asteroid"),Eo=n(),Ae=r("td"),po=l("Pytorch-based audio source separation toolkit"),go=n(),Pe=r("td"),mo=l("\u2705"),Do=n(),It=r("td"),bo=l("\u2705"),yo=n(),Se=r("td"),wo=l("\u2705"),Ao=n(),Le=r("td"),Po=l("\u274C"),So=n(),g=r("tr"),Re=r("td"),Tt=r("a"),Lo=l("docTR"),Ro=n(),ke=r("td"),ko=l("Models and datasets for OCR-related tasks in PyTorch & TensorFlow"),Ho=n(),He=r("td"),Co=l("\u2705"),No=n(),$t=r("td"),Io=l("\u2705"),$o=n(),Ce=r("td"),xo=l("\u2705"),Fo=n(),Ne=r("td"),Mo=l("\u274C"),Oo=n(),m=r("tr"),Ie=r("td"),_t=r("a"),zo=l("ESPnet"),Bo=n(),$e=r("td"),Wo=l("End-to-end speech processing toolkit (e.g. TTS)"),qo=n(),xe=r("td"),Go=l("\u2705"),Jo=n(),xt=r("td"),Vo=l("\u2705"),Uo=n(),Fe=r("td"),Xo=l("\u2705"),jo=n(),Me=r("td"),Ko=l("\u274C"),Yo=n(),D=r("tr"),Oe=r("td"),Et=r("a"),Qo=l("fastai"),Zo=n(),ze=r("td"),tl=l("Library to train fast and accurate models with state-of-the-art outputs."),el=n(),Be=r("td"),rl=l("\u2705"),al=n(),Ft=r("td"),ol=l("\u2705"),ll=n(),We=r("td"),dl=l("\u2705"),nl=n(),qe=r("td"),sl=l("\u2705"),hl=n(),b=r("tr"),Ge=r("td"),pt=r("a"),il=l("Flair"),fl=n(),Je=r("td"),cl=l("Very simple framework for state-of-the-art NLP."),ul=n(),Ve=r("td"),vl=l("\u2705"),Tl=n(),Mt=r("td"),_l=l("\u2705"),El=n(),Ue=r("td"),pl=l("\u2705"),gl=n(),Xe=r("td"),ml=l("\u274C"),Dl=n(),y=r("tr"),je=r("td"),gt=r("a"),bl=l("NeMo"),yl=n(),Ke=r("td"),wl=l("Conversational AI toolkit built for researchers"),Al=n(),Ye=r("td"),Pl=l("\u2705"),Sl=n(),Ot=r("td"),Ll=l("\u2705"),Rl=n(),Qe=r("td"),kl=l("\u2705"),Hl=n(),Ze=r("td"),Cl=l("\u274C"),Nl=n(),w=r("tr"),tr=r("td"),mt=r("a"),Il=l("Pyannote"),$l=n(),er=r("td"),xl=l("Neural building blocks for speaker diarization."),Fl=n(),rr=r("td"),Ml=l("\u274C"),Ol=n(),zt=r("td"),zl=l("\u274C"),Bl=n(),ar=r("td"),Wl=l("\u2705"),ql=n(),or=r("td"),Gl=l("\u274C"),Jl=n(),A=r("tr"),lr=r("td"),Dt=r("a"),Vl=l("PyCTCDecode"),Ul=n(),dr=r("td"),Xl=l("Language model supported CTC decoding for speech recognition"),jl=n(),nr=r("td"),Kl=l("\u274C"),Yl=n(),Bt=r("td"),Ql=l("\u274C"),Zl=n(),sr=r("td"),td=l("\u2705"),ed=n(),hr=r("td"),rd=l("\u274C"),ad=n(),P=r("tr"),ir=r("td"),bt=r("a"),od=l("Sentence Transformers"),ld=n(),fr=r("td"),dd=l("Compute dense vector representations for sentences, paragraphs, and images."),nd=n(),cr=r("td"),sd=l("\u2705"),hd=n(),Wt=r("td"),id=l("\u2705"),fd=n(),ur=r("td"),cd=l("\u2705"),ud=n(),vr=r("td"),vd=l("\u2705"),Td=n(),S=r("tr"),Tr=r("td"),yt=r("a"),_d=l("spaCy"),Ed=n(),_r=r("td"),pd=l("Advanced Natural Language Processing in Python and Cython."),gd=n(),Er=r("td"),md=l("\u2705"),Dd=n(),qt=r("td"),bd=l("\u2705"),yd=n(),pr=r("td"),wd=l("\u2705"),Ad=n(),gr=r("td"),Pd=l("\u2705"),Sd=n(),L=r("tr"),mr=r("td"),wt=r("a"),Ld=l("Speechbrain"),Rd=n(),Dr=r("td"),kd=l("A PyTorch Powered Speech Toolkit."),Hd=n(),br=r("td"),Cd=l("\u2705"),Nd=n(),Gt=r("td"),Id=l("\u2705"),$d=n(),yr=r("td"),xd=l("\u2705"),Fd=n(),wr=r("td"),Md=l("\u274C"),Od=n(),R=r("tr"),Ar=r("td"),At=r("a"),zd=l("Stable-Baselines3"),Bd=n(),Pr=r("td"),Wd=l("Set of reliable implementations of deep reinforcement learning algorithms in PyTorch"),qd=n(),Sr=r("td"),Gd=l("\u274C"),Jd=n(),Jt=r("td"),Vd=l("\u2705"),Ud=n(),Lr=r("td"),Xd=l("\u2705"),jd=n(),Rr=r("td"),Kd=l("\u2705"),Yd=n(),k=r("tr"),kr=r("td"),Pt=r("a"),Qd=l("TensorFlowTTS"),Zd=n(),Hr=r("td"),tn=l("Real-time state-of-the-art speech synthesis architectures."),en=n(),Cr=r("td"),rn=l("\u274C"),an=n(),Vt=r("td"),on=l("\u274C"),ln=n(),Nr=r("td"),dn=l("\u2705"),nn=n(),Ir=r("td"),sn=l("\u274C"),hn=n(),H=r("tr"),$r=r("td"),St=r("a"),fn=l("Timm"),cn=n(),xr=r("td"),un=l("Collection of image models, scripts, pretrained weights, etc."),vn=n(),Fr=r("td"),Tn=l("\u274C"),_n=n(),Ut=r("td"),En=l("\u274C"),pn=n(),Mr=r("td"),gn=l("\u2705"),mn=n(),Or=r("td"),Dn=l("\u274C"),Vr=n(),et=r("h3"),dt=r("a"),zr=r("span"),si(Lt.$$.fragment),bn=n(),Br=r("span"),yn=l("How can I add a new library to the Inference API?"),Ur=n(),nt=r("p"),wn=l("If you\u2019re interested in adding your library, please reach out to us! Read about it in "),Xt=r("a"),An=l("Adding a Library Guide"),Pn=l("."),this.h()},l(i){const C=pi('[data-svelte="svelte-1phssyn"]',document.head);Z=a(C,"META",{name:!0,content:!0}),C.forEach(e),Wr=s(i),tt=a(i,"H1",{class:!0});var jr=o(tt);rt=a(jr,"A",{id:!0,class:!0,href:!0});var Ln=o(rt);jt=a(Ln,"SPAN",{});var Rn=o(jt);hi(st.$$.fragment,Rn),Rn.forEach(e),Ln.forEach(e),ea=s(jr),Kt=a(jr,"SPAN",{});var kn=o(Kt);ra=d(kn,"Libraries"),kn.forEach(e),jr.forEach(e),qr=s(i),at=a(i,"P",{});var Kr=o(at);aa=d(Kr,"The Hub has support for dozens of libraries in the Open Source ecosystem. Thanks to the "),Yt=a(Kr,"CODE",{});var Hn=o(Yt);oa=d(Hn,"huggingface_hub"),Hn.forEach(e),la=d(Kr," Python library, it\u2019s easy to enable sharing your models in the Hub. The Hub supports many libraries, and we\u2019re working on expanding this support! We\u2019re happy to welcome to the Hub a set of Open Source libraries that are pushing Machine Learning forward."),Kr.forEach(e),Gr=s(i),ot=a(i,"P",{});var Yr=o(ot);da=d(Yr,"The table below summarizes the supported libraries and their level of integration. Find all our supported libraries "),ht=a(Yr,"A",{href:!0,rel:!0});var Cn=o(ht);na=d(Cn,"here"),Cn.forEach(e),sa=d(Yr,"!"),Yr.forEach(e),Jr=s(i),lt=a(i,"TABLE",{});var Qr=o(lt);Qt=a(Qr,"THEAD",{});var Nn=o(Qt);u=a(Nn,"TR",{});var N=o(u);Zt=a(N,"TH",{});var In=o(Zt);ha=d(In,"Library"),In.forEach(e),ia=s(N),te=a(N,"TH",{});var $n=o(te);fa=d($n,"Description"),$n.forEach(e),ca=s(N),ee=a(N,"TH",{});var xn=o(ee);ua=d(xn,"Inference API"),xn.forEach(e),va=s(N),Rt=a(N,"TH",{align:!0});var Fn=o(Rt);Ta=d(Fn,"Widgets"),Fn.forEach(e),_a=s(N),re=a(N,"TH",{});var Mn=o(re);Ea=d(Mn,"Download from Hub"),Mn.forEach(e),pa=s(N),ae=a(N,"TH",{});var On=o(ae);ga=d(On,"Push to Hub"),On.forEach(e),N.forEach(e),Nn.forEach(e),ma=s(Qr),f=a(Qr,"TBODY",{});var c=o(f);v=a(c,"TR",{});var I=o(v);oe=a(I,"TD",{});var zn=o(oe);it=a(zn,"A",{href:!0,rel:!0});var Bn=o(it);Da=d(Bn,"\u{1F917} Transformers"),Bn.forEach(e),zn.forEach(e),ba=s(I),le=a(I,"TD",{});var Wn=o(le);ya=d(Wn,"State-of-the-art Natural Language Processing for Pytorch, TensorFlow, and JAX"),Wn.forEach(e),wa=s(I),de=a(I,"TD",{});var qn=o(de);Aa=d(qn,"\u2705"),qn.forEach(e),Pa=s(I),kt=a(I,"TD",{align:!0});var Gn=o(kt);Sa=d(Gn,"\u2705"),Gn.forEach(e),La=s(I),ne=a(I,"TD",{});var Jn=o(ne);Ra=d(Jn,"\u2705"),Jn.forEach(e),ka=s(I),se=a(I,"TD",{});var Vn=o(se);Ha=d(Vn,"\u2705"),Vn.forEach(e),I.forEach(e),Ca=s(c),T=a(c,"TR",{});var $=o(T);he=a($,"TD",{});var Un=o(he);ft=a(Un,"A",{href:!0,rel:!0});var Xn=o(ft);Na=d(Xn,"\u{1F917} Diffusers"),Xn.forEach(e),Un.forEach(e),Ia=s($),ie=a($,"TD",{});var jn=o(ie);$a=d(jn,"A modular toolbox for inference and training of diffusion models"),jn.forEach(e),xa=s($),fe=a($,"TD",{});var Kn=o(fe);Fa=d(Kn,"\u274C"),Kn.forEach(e),Ma=s($),Ht=a($,"TD",{align:!0});var Yn=o(Ht);Oa=d(Yn,"\u274C"),Yn.forEach(e),za=s($),ce=a($,"TD",{});var Qn=o(ce);Ba=d(Qn,"\u2705"),Qn.forEach(e),Wa=s($),ue=a($,"TD",{});var Zn=o(ue);qa=d(Zn,"\u2705"),Zn.forEach(e),$.forEach(e),Ga=s(c),_=a(c,"TR",{});var x=o(_);ve=a(x,"TD",{});var ts=o(ve);ct=a(ts,"A",{href:!0,rel:!0});var es=o(ct);Ja=d(es,"Adapter Transformers"),es.forEach(e),ts.forEach(e),Va=s(x),Te=a(x,"TD",{});var rs=o(Te);Ua=d(rs,"Extends \u{1F917}Transformers with Adapters."),rs.forEach(e),Xa=s(x),_e=a(x,"TD",{});var as=o(_e);ja=d(as,"\u274C"),as.forEach(e),Ka=s(x),Ct=a(x,"TD",{align:!0});var os=o(Ct);Ya=d(os,"\u274C"),os.forEach(e),Qa=s(x),Ee=a(x,"TD",{});var ls=o(Ee);Za=d(ls,"\u2705"),ls.forEach(e),to=s(x),pe=a(x,"TD",{});var ds=o(pe);eo=d(ds,"\u2705"),ds.forEach(e),x.forEach(e),ro=s(c),E=a(c,"TR",{});var F=o(E);ge=a(F,"TD",{});var ns=o(ge);ut=a(ns,"A",{href:!0,rel:!0});var ss=o(ut);ao=d(ss,"AllenNLP"),ss.forEach(e),ns.forEach(e),oo=s(F),me=a(F,"TD",{});var hs=o(me);lo=d(hs,"An open-source NLP research library, built on PyTorch."),hs.forEach(e),no=s(F),De=a(F,"TD",{});var is=o(De);so=d(is,"\u2705"),is.forEach(e),ho=s(F),Nt=a(F,"TD",{align:!0});var fs=o(Nt);io=d(fs,"\u2705"),fs.forEach(e),fo=s(F),be=a(F,"TD",{});var cs=o(be);co=d(cs,"\u2705"),cs.forEach(e),uo=s(F),ye=a(F,"TD",{});var us=o(ye);vo=d(us,"\u274C"),us.forEach(e),F.forEach(e),To=s(c),p=a(c,"TR",{});var M=o(p);we=a(M,"TD",{});var vs=o(we);vt=a(vs,"A",{href:!0,rel:!0});var Ts=o(vt);_o=d(Ts,"Asteroid"),Ts.forEach(e),vs.forEach(e),Eo=s(M),Ae=a(M,"TD",{});var _s=o(Ae);po=d(_s,"Pytorch-based audio source separation toolkit"),_s.forEach(e),go=s(M),Pe=a(M,"TD",{});var Es=o(Pe);mo=d(Es,"\u2705"),Es.forEach(e),Do=s(M),It=a(M,"TD",{align:!0});var ps=o(It);bo=d(ps,"\u2705"),ps.forEach(e),yo=s(M),Se=a(M,"TD",{});var gs=o(Se);wo=d(gs,"\u2705"),gs.forEach(e),Ao=s(M),Le=a(M,"TD",{});var ms=o(Le);Po=d(ms,"\u274C"),ms.forEach(e),M.forEach(e),So=s(c),g=a(c,"TR",{});var O=o(g);Re=a(O,"TD",{});var Ds=o(Re);Tt=a(Ds,"A",{href:!0,rel:!0});var bs=o(Tt);Lo=d(bs,"docTR"),bs.forEach(e),Ds.forEach(e),Ro=s(O),ke=a(O,"TD",{});var ys=o(ke);ko=d(ys,"Models and datasets for OCR-related tasks in PyTorch & TensorFlow"),ys.forEach(e),Ho=s(O),He=a(O,"TD",{});var ws=o(He);Co=d(ws,"\u2705"),ws.forEach(e),No=s(O),$t=a(O,"TD",{align:!0});var As=o($t);Io=d(As,"\u2705"),As.forEach(e),$o=s(O),Ce=a(O,"TD",{});var Ps=o(Ce);xo=d(Ps,"\u2705"),Ps.forEach(e),Fo=s(O),Ne=a(O,"TD",{});var Ss=o(Ne);Mo=d(Ss,"\u274C"),Ss.forEach(e),O.forEach(e),Oo=s(c),m=a(c,"TR",{});var z=o(m);Ie=a(z,"TD",{});var Ls=o(Ie);_t=a(Ls,"A",{href:!0,rel:!0});var Rs=o(_t);zo=d(Rs,"ESPnet"),Rs.forEach(e),Ls.forEach(e),Bo=s(z),$e=a(z,"TD",{});var ks=o($e);Wo=d(ks,"End-to-end speech processing toolkit (e.g. TTS)"),ks.forEach(e),qo=s(z),xe=a(z,"TD",{});var Hs=o(xe);Go=d(Hs,"\u2705"),Hs.forEach(e),Jo=s(z),xt=a(z,"TD",{align:!0});var Cs=o(xt);Vo=d(Cs,"\u2705"),Cs.forEach(e),Uo=s(z),Fe=a(z,"TD",{});var Ns=o(Fe);Xo=d(Ns,"\u2705"),Ns.forEach(e),jo=s(z),Me=a(z,"TD",{});var Is=o(Me);Ko=d(Is,"\u274C"),Is.forEach(e),z.forEach(e),Yo=s(c),D=a(c,"TR",{});var B=o(D);Oe=a(B,"TD",{});var $s=o(Oe);Et=a($s,"A",{href:!0,rel:!0});var xs=o(Et);Qo=d(xs,"fastai"),xs.forEach(e),$s.forEach(e),Zo=s(B),ze=a(B,"TD",{});var Fs=o(ze);tl=d(Fs,"Library to train fast and accurate models with state-of-the-art outputs."),Fs.forEach(e),el=s(B),Be=a(B,"TD",{});var Ms=o(Be);rl=d(Ms,"\u2705"),Ms.forEach(e),al=s(B),Ft=a(B,"TD",{align:!0});var Os=o(Ft);ol=d(Os,"\u2705"),Os.forEach(e),ll=s(B),We=a(B,"TD",{});var zs=o(We);dl=d(zs,"\u2705"),zs.forEach(e),nl=s(B),qe=a(B,"TD",{});var Bs=o(qe);sl=d(Bs,"\u2705"),Bs.forEach(e),B.forEach(e),hl=s(c),b=a(c,"TR",{});var W=o(b);Ge=a(W,"TD",{});var Ws=o(Ge);pt=a(Ws,"A",{href:!0,rel:!0});var qs=o(pt);il=d(qs,"Flair"),qs.forEach(e),Ws.forEach(e),fl=s(W),Je=a(W,"TD",{});var Gs=o(Je);cl=d(Gs,"Very simple framework for state-of-the-art NLP."),Gs.forEach(e),ul=s(W),Ve=a(W,"TD",{});var Js=o(Ve);vl=d(Js,"\u2705"),Js.forEach(e),Tl=s(W),Mt=a(W,"TD",{align:!0});var Vs=o(Mt);_l=d(Vs,"\u2705"),Vs.forEach(e),El=s(W),Ue=a(W,"TD",{});var Us=o(Ue);pl=d(Us,"\u2705"),Us.forEach(e),gl=s(W),Xe=a(W,"TD",{});var Xs=o(Xe);ml=d(Xs,"\u274C"),Xs.forEach(e),W.forEach(e),Dl=s(c),y=a(c,"TR",{});var q=o(y);je=a(q,"TD",{});var js=o(je);gt=a(js,"A",{href:!0,rel:!0});var Ks=o(gt);bl=d(Ks,"NeMo"),Ks.forEach(e),js.forEach(e),yl=s(q),Ke=a(q,"TD",{});var Ys=o(Ke);wl=d(Ys,"Conversational AI toolkit built for researchers"),Ys.forEach(e),Al=s(q),Ye=a(q,"TD",{});var Qs=o(Ye);Pl=d(Qs,"\u2705"),Qs.forEach(e),Sl=s(q),Ot=a(q,"TD",{align:!0});var Zs=o(Ot);Ll=d(Zs,"\u2705"),Zs.forEach(e),Rl=s(q),Qe=a(q,"TD",{});var th=o(Qe);kl=d(th,"\u2705"),th.forEach(e),Hl=s(q),Ze=a(q,"TD",{});var eh=o(Ze);Cl=d(eh,"\u274C"),eh.forEach(e),q.forEach(e),Nl=s(c),w=a(c,"TR",{});var G=o(w);tr=a(G,"TD",{});var rh=o(tr);mt=a(rh,"A",{href:!0,rel:!0});var ah=o(mt);Il=d(ah,"Pyannote"),ah.forEach(e),rh.forEach(e),$l=s(G),er=a(G,"TD",{});var oh=o(er);xl=d(oh,"Neural building blocks for speaker diarization."),oh.forEach(e),Fl=s(G),rr=a(G,"TD",{});var lh=o(rr);Ml=d(lh,"\u274C"),lh.forEach(e),Ol=s(G),zt=a(G,"TD",{align:!0});var dh=o(zt);zl=d(dh,"\u274C"),dh.forEach(e),Bl=s(G),ar=a(G,"TD",{});var nh=o(ar);Wl=d(nh,"\u2705"),nh.forEach(e),ql=s(G),or=a(G,"TD",{});var sh=o(or);Gl=d(sh,"\u274C"),sh.forEach(e),G.forEach(e),Jl=s(c),A=a(c,"TR",{});var J=o(A);lr=a(J,"TD",{});var hh=o(lr);Dt=a(hh,"A",{href:!0,rel:!0});var ih=o(Dt);Vl=d(ih,"PyCTCDecode"),ih.forEach(e),hh.forEach(e),Ul=s(J),dr=a(J,"TD",{});var fh=o(dr);Xl=d(fh,"Language model supported CTC decoding for speech recognition"),fh.forEach(e),jl=s(J),nr=a(J,"TD",{});var ch=o(nr);Kl=d(ch,"\u274C"),ch.forEach(e),Yl=s(J),Bt=a(J,"TD",{align:!0});var uh=o(Bt);Ql=d(uh,"\u274C"),uh.forEach(e),Zl=s(J),sr=a(J,"TD",{});var vh=o(sr);td=d(vh,"\u2705"),vh.forEach(e),ed=s(J),hr=a(J,"TD",{});var Th=o(hr);rd=d(Th,"\u274C"),Th.forEach(e),J.forEach(e),ad=s(c),P=a(c,"TR",{});var V=o(P);ir=a(V,"TD",{});var _h=o(ir);bt=a(_h,"A",{href:!0,rel:!0});var Eh=o(bt);od=d(Eh,"Sentence Transformers"),Eh.forEach(e),_h.forEach(e),ld=s(V),fr=a(V,"TD",{});var ph=o(fr);dd=d(ph,"Compute dense vector representations for sentences, paragraphs, and images."),ph.forEach(e),nd=s(V),cr=a(V,"TD",{});var gh=o(cr);sd=d(gh,"\u2705"),gh.forEach(e),hd=s(V),Wt=a(V,"TD",{align:!0});var mh=o(Wt);id=d(mh,"\u2705"),mh.forEach(e),fd=s(V),ur=a(V,"TD",{});var Dh=o(ur);cd=d(Dh,"\u2705"),Dh.forEach(e),ud=s(V),vr=a(V,"TD",{});var bh=o(vr);vd=d(bh,"\u2705"),bh.forEach(e),V.forEach(e),Td=s(c),S=a(c,"TR",{});var U=o(S);Tr=a(U,"TD",{});var yh=o(Tr);yt=a(yh,"A",{href:!0,rel:!0});var wh=o(yt);_d=d(wh,"spaCy"),wh.forEach(e),yh.forEach(e),Ed=s(U),_r=a(U,"TD",{});var Ah=o(_r);pd=d(Ah,"Advanced Natural Language Processing in Python and Cython."),Ah.forEach(e),gd=s(U),Er=a(U,"TD",{});var Ph=o(Er);md=d(Ph,"\u2705"),Ph.forEach(e),Dd=s(U),qt=a(U,"TD",{align:!0});var Sh=o(qt);bd=d(Sh,"\u2705"),Sh.forEach(e),yd=s(U),pr=a(U,"TD",{});var Lh=o(pr);wd=d(Lh,"\u2705"),Lh.forEach(e),Ad=s(U),gr=a(U,"TD",{});var Rh=o(gr);Pd=d(Rh,"\u2705"),Rh.forEach(e),U.forEach(e),Sd=s(c),L=a(c,"TR",{});var X=o(L);mr=a(X,"TD",{});var kh=o(mr);wt=a(kh,"A",{href:!0,rel:!0});var Hh=o(wt);Ld=d(Hh,"Speechbrain"),Hh.forEach(e),kh.forEach(e),Rd=s(X),Dr=a(X,"TD",{});var Ch=o(Dr);kd=d(Ch,"A PyTorch Powered Speech Toolkit."),Ch.forEach(e),Hd=s(X),br=a(X,"TD",{});var Nh=o(br);Cd=d(Nh,"\u2705"),Nh.forEach(e),Nd=s(X),Gt=a(X,"TD",{align:!0});var Ih=o(Gt);Id=d(Ih,"\u2705"),Ih.forEach(e),$d=s(X),yr=a(X,"TD",{});var $h=o(yr);xd=d($h,"\u2705"),$h.forEach(e),Fd=s(X),wr=a(X,"TD",{});var xh=o(wr);Md=d(xh,"\u274C"),xh.forEach(e),X.forEach(e),Od=s(c),R=a(c,"TR",{});var j=o(R);Ar=a(j,"TD",{});var Fh=o(Ar);At=a(Fh,"A",{href:!0,rel:!0});var Mh=o(At);zd=d(Mh,"Stable-Baselines3"),Mh.forEach(e),Fh.forEach(e),Bd=s(j),Pr=a(j,"TD",{});var Oh=o(Pr);Wd=d(Oh,"Set of reliable implementations of deep reinforcement learning algorithms in PyTorch"),Oh.forEach(e),qd=s(j),Sr=a(j,"TD",{});var zh=o(Sr);Gd=d(zh,"\u274C"),zh.forEach(e),Jd=s(j),Jt=a(j,"TD",{align:!0});var Bh=o(Jt);Vd=d(Bh,"\u2705"),Bh.forEach(e),Ud=s(j),Lr=a(j,"TD",{});var Wh=o(Lr);Xd=d(Wh,"\u2705"),Wh.forEach(e),jd=s(j),Rr=a(j,"TD",{});var qh=o(Rr);Kd=d(qh,"\u2705"),qh.forEach(e),j.forEach(e),Yd=s(c),k=a(c,"TR",{});var K=o(k);kr=a(K,"TD",{});var Gh=o(kr);Pt=a(Gh,"A",{href:!0,rel:!0});var Jh=o(Pt);Qd=d(Jh,"TensorFlowTTS"),Jh.forEach(e),Gh.forEach(e),Zd=s(K),Hr=a(K,"TD",{});var Vh=o(Hr);tn=d(Vh,"Real-time state-of-the-art speech synthesis architectures."),Vh.forEach(e),en=s(K),Cr=a(K,"TD",{});var Uh=o(Cr);rn=d(Uh,"\u274C"),Uh.forEach(e),an=s(K),Vt=a(K,"TD",{align:!0});var Xh=o(Vt);on=d(Xh,"\u274C"),Xh.forEach(e),ln=s(K),Nr=a(K,"TD",{});var jh=o(Nr);dn=d(jh,"\u2705"),jh.forEach(e),nn=s(K),Ir=a(K,"TD",{});var Kh=o(Ir);sn=d(Kh,"\u274C"),Kh.forEach(e),K.forEach(e),hn=s(c),H=a(c,"TR",{});var Y=o(H);$r=a(Y,"TD",{});var Yh=o($r);St=a(Yh,"A",{href:!0,rel:!0});var Qh=o(St);fn=d(Qh,"Timm"),Qh.forEach(e),Yh.forEach(e),cn=s(Y),xr=a(Y,"TD",{});var Zh=o(xr);un=d(Zh,"Collection of image models, scripts, pretrained weights, etc."),Zh.forEach(e),vn=s(Y),Fr=a(Y,"TD",{});var ti=o(Fr);Tn=d(ti,"\u274C"),ti.forEach(e),_n=s(Y),Ut=a(Y,"TD",{align:!0});var ei=o(Ut);En=d(ei,"\u274C"),ei.forEach(e),pn=s(Y),Mr=a(Y,"TD",{});var ri=o(Mr);gn=d(ri,"\u2705"),ri.forEach(e),mn=s(Y),Or=a(Y,"TD",{});var ai=o(Or);Dn=d(ai,"\u274C"),ai.forEach(e),Y.forEach(e),c.forEach(e),Qr.forEach(e),Vr=s(i),et=a(i,"H3",{class:!0});var Zr=o(et);dt=a(Zr,"A",{id:!0,class:!0,href:!0});var oi=o(dt);zr=a(oi,"SPAN",{});var li=o(zr);hi(Lt.$$.fragment,li),li.forEach(e),oi.forEach(e),bn=s(Zr),Br=a(Zr,"SPAN",{});var di=o(Br);yn=d(di,"How can I add a new library to the Inference API?"),di.forEach(e),Zr.forEach(e),Ur=s(i),nt=a(i,"P",{});var ta=o(nt);wn=d(ta,"If you\u2019re interested in adding your library, please reach out to us! Read about it in "),Xt=a(ta,"A",{href:!0});var ni=o(Xt);An=d(ni,"Adding a Library Guide"),ni.forEach(e),Pn=d(ta,"."),ta.forEach(e),this.h()},h(){h(Z,"name","hf:doc:metadata"),h(Z,"content",JSON.stringify(bi)),h(rt,"id","libraries"),h(rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(rt,"href","#libraries"),h(tt,"class","relative group"),h(ht,"href","https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Libraries.ts"),h(ht,"rel","nofollow"),h(Rt,"align","right"),h(it,"href","https://github.com/huggingface/transformers"),h(it,"rel","nofollow"),h(kt,"align","right"),h(ft,"href","https://github.com/huggingface/diffusers"),h(ft,"rel","nofollow"),h(Ht,"align","right"),h(ct,"href","https://github.com/Adapter-Hub/adapter-transformers"),h(ct,"rel","nofollow"),h(Ct,"align","right"),h(ut,"href","https://github.com/allenai/allennlp"),h(ut,"rel","nofollow"),h(Nt,"align","right"),h(vt,"href","https://github.com/asteroid-team/asteroid"),h(vt,"rel","nofollow"),h(It,"align","right"),h(Tt,"href","https://github.com/mindee/doctr"),h(Tt,"rel","nofollow"),h($t,"align","right"),h(_t,"href","https://github.com/espnet/espnet"),h(_t,"rel","nofollow"),h(xt,"align","right"),h(Et,"href","https://github.com/fastai/fastai"),h(Et,"rel","nofollow"),h(Ft,"align","right"),h(pt,"href","https://github.com/flairNLP/flair"),h(pt,"rel","nofollow"),h(Mt,"align","right"),h(gt,"href","https://github.com/NVIDIA/NeMo"),h(gt,"rel","nofollow"),h(Ot,"align","right"),h(mt,"href","https://github.com/pyannote/pyannote-audio"),h(mt,"rel","nofollow"),h(zt,"align","right"),h(Dt,"href","https://github.com/kensho-technologies/pyctcdecode"),h(Dt,"rel","nofollow"),h(Bt,"align","right"),h(bt,"href","https://github.com/UKPLab/sentence-transformers"),h(bt,"rel","nofollow"),h(Wt,"align","right"),h(yt,"href","https://github.com/explosion/spaCy"),h(yt,"rel","nofollow"),h(qt,"align","right"),h(wt,"href","https://speechbrain.github.io/"),h(wt,"rel","nofollow"),h(Gt,"align","right"),h(At,"href","https://github.com/DLR-RM/stable-baselines3"),h(At,"rel","nofollow"),h(Jt,"align","right"),h(Pt,"href","https://github.com/TensorSpeech/TensorFlowTTS"),h(Pt,"rel","nofollow"),h(Vt,"align","right"),h(St,"href","https://github.com/rwightman/pytorch-image-models"),h(St,"rel","nofollow"),h(Ut,"align","right"),h(dt,"id","how-can-i-add-a-new-library-to-the-inference-api"),h(dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(dt,"href","#how-can-i-add-a-new-library-to-the-inference-api"),h(et,"class","relative group"),h(Xt,"href","./models-adding-libraries")},m(i,C){t(document.head,Z),Q(i,Wr,C),Q(i,tt,C),t(tt,rt),t(rt,jt),ii(st,jt,null),t(tt,ea),t(tt,Kt),t(Kt,ra),Q(i,qr,C),Q(i,at,C),t(at,aa),t(at,Yt),t(Yt,oa),t(at,la),Q(i,Gr,C),Q(i,ot,C),t(ot,da),t(ot,ht),t(ht,na),t(ot,sa),Q(i,Jr,C),Q(i,lt,C),t(lt,Qt),t(Qt,u),t(u,Zt),t(Zt,ha),t(u,ia),t(u,te),t(te,fa),t(u,ca),t(u,ee),t(ee,ua),t(u,va),t(u,Rt),t(Rt,Ta),t(u,_a),t(u,re),t(re,Ea),t(u,pa),t(u,ae),t(ae,ga),t(lt,ma),t(lt,f),t(f,v),t(v,oe),t(oe,it),t(it,Da),t(v,ba),t(v,le),t(le,ya),t(v,wa),t(v,de),t(de,Aa),t(v,Pa),t(v,kt),t(kt,Sa),t(v,La),t(v,ne),t(ne,Ra),t(v,ka),t(v,se),t(se,Ha),t(f,Ca),t(f,T),t(T,he),t(he,ft),t(ft,Na),t(T,Ia),t(T,ie),t(ie,$a),t(T,xa),t(T,fe),t(fe,Fa),t(T,Ma),t(T,Ht),t(Ht,Oa),t(T,za),t(T,ce),t(ce,Ba),t(T,Wa),t(T,ue),t(ue,qa),t(f,Ga),t(f,_),t(_,ve),t(ve,ct),t(ct,Ja),t(_,Va),t(_,Te),t(Te,Ua),t(_,Xa),t(_,_e),t(_e,ja),t(_,Ka),t(_,Ct),t(Ct,Ya),t(_,Qa),t(_,Ee),t(Ee,Za),t(_,to),t(_,pe),t(pe,eo),t(f,ro),t(f,E),t(E,ge),t(ge,ut),t(ut,ao),t(E,oo),t(E,me),t(me,lo),t(E,no),t(E,De),t(De,so),t(E,ho),t(E,Nt),t(Nt,io),t(E,fo),t(E,be),t(be,co),t(E,uo),t(E,ye),t(ye,vo),t(f,To),t(f,p),t(p,we),t(we,vt),t(vt,_o),t(p,Eo),t(p,Ae),t(Ae,po),t(p,go),t(p,Pe),t(Pe,mo),t(p,Do),t(p,It),t(It,bo),t(p,yo),t(p,Se),t(Se,wo),t(p,Ao),t(p,Le),t(Le,Po),t(f,So),t(f,g),t(g,Re),t(Re,Tt),t(Tt,Lo),t(g,Ro),t(g,ke),t(ke,ko),t(g,Ho),t(g,He),t(He,Co),t(g,No),t(g,$t),t($t,Io),t(g,$o),t(g,Ce),t(Ce,xo),t(g,Fo),t(g,Ne),t(Ne,Mo),t(f,Oo),t(f,m),t(m,Ie),t(Ie,_t),t(_t,zo),t(m,Bo),t(m,$e),t($e,Wo),t(m,qo),t(m,xe),t(xe,Go),t(m,Jo),t(m,xt),t(xt,Vo),t(m,Uo),t(m,Fe),t(Fe,Xo),t(m,jo),t(m,Me),t(Me,Ko),t(f,Yo),t(f,D),t(D,Oe),t(Oe,Et),t(Et,Qo),t(D,Zo),t(D,ze),t(ze,tl),t(D,el),t(D,Be),t(Be,rl),t(D,al),t(D,Ft),t(Ft,ol),t(D,ll),t(D,We),t(We,dl),t(D,nl),t(D,qe),t(qe,sl),t(f,hl),t(f,b),t(b,Ge),t(Ge,pt),t(pt,il),t(b,fl),t(b,Je),t(Je,cl),t(b,ul),t(b,Ve),t(Ve,vl),t(b,Tl),t(b,Mt),t(Mt,_l),t(b,El),t(b,Ue),t(Ue,pl),t(b,gl),t(b,Xe),t(Xe,ml),t(f,Dl),t(f,y),t(y,je),t(je,gt),t(gt,bl),t(y,yl),t(y,Ke),t(Ke,wl),t(y,Al),t(y,Ye),t(Ye,Pl),t(y,Sl),t(y,Ot),t(Ot,Ll),t(y,Rl),t(y,Qe),t(Qe,kl),t(y,Hl),t(y,Ze),t(Ze,Cl),t(f,Nl),t(f,w),t(w,tr),t(tr,mt),t(mt,Il),t(w,$l),t(w,er),t(er,xl),t(w,Fl),t(w,rr),t(rr,Ml),t(w,Ol),t(w,zt),t(zt,zl),t(w,Bl),t(w,ar),t(ar,Wl),t(w,ql),t(w,or),t(or,Gl),t(f,Jl),t(f,A),t(A,lr),t(lr,Dt),t(Dt,Vl),t(A,Ul),t(A,dr),t(dr,Xl),t(A,jl),t(A,nr),t(nr,Kl),t(A,Yl),t(A,Bt),t(Bt,Ql),t(A,Zl),t(A,sr),t(sr,td),t(A,ed),t(A,hr),t(hr,rd),t(f,ad),t(f,P),t(P,ir),t(ir,bt),t(bt,od),t(P,ld),t(P,fr),t(fr,dd),t(P,nd),t(P,cr),t(cr,sd),t(P,hd),t(P,Wt),t(Wt,id),t(P,fd),t(P,ur),t(ur,cd),t(P,ud),t(P,vr),t(vr,vd),t(f,Td),t(f,S),t(S,Tr),t(Tr,yt),t(yt,_d),t(S,Ed),t(S,_r),t(_r,pd),t(S,gd),t(S,Er),t(Er,md),t(S,Dd),t(S,qt),t(qt,bd),t(S,yd),t(S,pr),t(pr,wd),t(S,Ad),t(S,gr),t(gr,Pd),t(f,Sd),t(f,L),t(L,mr),t(mr,wt),t(wt,Ld),t(L,Rd),t(L,Dr),t(Dr,kd),t(L,Hd),t(L,br),t(br,Cd),t(L,Nd),t(L,Gt),t(Gt,Id),t(L,$d),t(L,yr),t(yr,xd),t(L,Fd),t(L,wr),t(wr,Md),t(f,Od),t(f,R),t(R,Ar),t(Ar,At),t(At,zd),t(R,Bd),t(R,Pr),t(Pr,Wd),t(R,qd),t(R,Sr),t(Sr,Gd),t(R,Jd),t(R,Jt),t(Jt,Vd),t(R,Ud),t(R,Lr),t(Lr,Xd),t(R,jd),t(R,Rr),t(Rr,Kd),t(f,Yd),t(f,k),t(k,kr),t(kr,Pt),t(Pt,Qd),t(k,Zd),t(k,Hr),t(Hr,tn),t(k,en),t(k,Cr),t(Cr,rn),t(k,an),t(k,Vt),t(Vt,on),t(k,ln),t(k,Nr),t(Nr,dn),t(k,nn),t(k,Ir),t(Ir,sn),t(f,hn),t(f,H),t(H,$r),t($r,St),t(St,fn),t(H,cn),t(H,xr),t(xr,un),t(H,vn),t(H,Fr),t(Fr,Tn),t(H,_n),t(H,Ut),t(Ut,En),t(H,pn),t(H,Mr),t(Mr,gn),t(H,mn),t(H,Or),t(Or,Dn),Q(i,Vr,C),Q(i,et,C),t(et,dt),t(dt,zr),ii(Lt,zr,null),t(et,bn),t(et,Br),t(Br,yn),Q(i,Ur,C),Q(i,nt,C),t(nt,wn),t(nt,Xt),t(Xt,An),t(nt,Pn),Xr=!0},p:gi,i(i){Xr||(fi(st.$$.fragment,i),fi(Lt.$$.fragment,i),Xr=!0)},o(i){ci(st.$$.fragment,i),ci(Lt.$$.fragment,i),Xr=!1},d(i){e(Z),i&&e(Wr),i&&e(tt),ui(st),i&&e(qr),i&&e(at),i&&e(Gr),i&&e(ot),i&&e(Jr),i&&e(lt),i&&e(Vr),i&&e(et),ui(Lt),i&&e(Ur),i&&e(nt)}}}const bi={local:"libraries",sections:[{local:"how-can-i-add-a-new-library-to-the-inference-api",title:"How can I add a new library to the Inference API?"}],title:"Libraries"};function yi(Sn){return mi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Pi extends Ti{constructor(Z){super();_i(this,Z,yi,Di,Ei,{})}}export{Pi as default,bi as metadata};
