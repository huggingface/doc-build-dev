import{S as Aa,i as Sa,s as Ia,e as s,k as f,w as ge,t as o,N as Pa,c as i,d as a,m as p,a as r,x as ve,h as l,b as n,P as ze,G as t,g as h,y as _e,L as Ca,q as be,o as Ee,B as we,v as Ha}from"../chunks/vendor-hf-doc-builder.js";import{I as Ke}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ba}from"../chunks/CodeBlock-hf-doc-builder.js";function Da(Yt){let v,ye,_,$,K,H,Qe,Q,We,ke,B,W,Xe,Ze,$e,b,x,X,D,et,Z,tt,xe,g,at,ee,st,it,L,rt,ot,Ae,T,lt,Se,m,te,nt,ct,ae,ht,ft,se,pt,dt,ie,ut,Ie,E,A,re,O,mt,oe,gt,Pe,d,le,vt,_t,ne,bt,Et,ce,wt,yt,he,kt,$t,fe,xt,At,pe,St,It,Ce,F,Pt,He,M,Be,S,Ct,de,Ht,Bt,De,w,V,Jt,Dt,Y,Rt,Le,y,J,zt,Lt,R,Kt,Oe,k,I,ue,N,Ot,me,Mt,Me,P,U,Nt,q,Ut,qt,jt,j,Gt,G,Tt,Ft,Ne;return H=new Ke({}),D=new Ke({}),O=new Ke({}),M=new Ba({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> torchaudio
<span class="hljs-keyword">from</span> speechbrain.pretrained <span class="hljs-keyword">import</span> EncoderClassifier

classifier = EncoderClassifier.from_hparams(
    source=<span class="hljs-string">&quot;speechbrain/urbansound8k_ecapa&quot;</span>
)
out_prob, score, index, text_lab = classifier.classify_file(<span class="hljs-string">&#x27;speechbrain/urbansound8k_ecapa/dog_bark.wav&#x27;</span>)`}}),N=new Ke({}),{c(){v=s("meta"),ye=f(),_=s("h1"),$=s("a"),K=s("span"),ge(H.$$.fragment),Qe=f(),Q=s("span"),We=o("Using SpeechBrain at Hugging Face"),ke=f(),B=s("p"),W=s("code"),Xe=o("speechbrain"),Ze=o(" is an open-source and all-in-one conversational toolkit for audio/speech. The goal is to create a single, flexible, and user-friendly toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for speech recognition, speaker recognition, speech enhancement, speech separation, language identification, multi-microphone signal processing, and many others."),$e=f(),b=s("h2"),x=s("a"),X=s("span"),ge(D.$$.fragment),et=f(),Z=s("span"),tt=o("Exploring SpeechBrain in the Hub"),xe=f(),g=s("p"),at=o("You can find "),ee=s("code"),st=o("speechbrain"),it=o(" models by filtering at the left of the "),L=s("a"),rt=o("models page"),ot=o("."),Ae=f(),T=s("p"),lt=o("All models on the Hub come up with the following features:"),Se=f(),m=s("ol"),te=s("li"),nt=o("An automatically generated model card with a brief description."),ct=f(),ae=s("li"),ht=o("Metadata tags that help for discoverability with information such as the language, license, paper, and more."),ft=f(),se=s("li"),pt=o("An interactive widget you can use to play out with the model directly in the browser."),dt=f(),ie=s("li"),ut=o("An Inference API that allows to make inference requests."),Ie=f(),E=s("h2"),A=s("a"),re=s("span"),ge(O.$$.fragment),mt=f(),oe=s("span"),gt=o("Using existing models"),Pe=f(),d=s("p"),le=s("code"),vt=o("speechbrain"),_t=o(" offers different interfaces to manage pretrained models for different tasks, such as "),ne=s("code"),bt=o("EncoderClassifier"),Et=o(", "),ce=s("code"),wt=o("EncoderClassifier"),yt=o(", "),he=s("code"),kt=o("SepformerSeperation"),$t=o(", and "),fe=s("code"),xt=o("SpectralMaskEnhancement"),At=o(". These classes have a "),pe=s("code"),St=o("from_hparams"),It=o(" method you can use to load a model from the Hub"),Ce=f(),F=s("p"),Pt=o("Here is an example to run inference for sound recognition in urban sounds."),He=f(),ge(M.$$.fragment),Be=f(),S=s("p"),Ct=o("If you want to see how to load a specific model, you can click "),de=s("code"),Ht=o("Use in speechbrain"),Bt=o(" and you will be given a working snippet that you can load it!"),De=f(),w=s("div"),V=s("img"),Dt=f(),Y=s("img"),Le=f(),y=s("div"),J=s("img"),Lt=f(),R=s("img"),Oe=f(),k=s("h2"),I=s("a"),ue=s("span"),ge(N.$$.fragment),Ot=f(),me=s("span"),Mt=o("Additional resources"),Me=f(),P=s("ul"),U=s("li"),Nt=o("SpeechBrain "),q=s("a"),Ut=o("website"),qt=o("."),jt=f(),j=s("li"),Gt=o("SpeechBrain "),G=s("a"),Tt=o("docs"),Ft=o("."),this.h()},l(e){const c=Pa('[data-svelte="svelte-1phssyn"]',document.head);v=i(c,"META",{name:!0,content:!0}),c.forEach(a),ye=p(e),_=i(e,"H1",{class:!0});var Ue=r(_);$=i(Ue,"A",{id:!0,class:!0,href:!0});var Qt=r($);K=i(Qt,"SPAN",{});var Wt=r(K);ve(H.$$.fragment,Wt),Wt.forEach(a),Qt.forEach(a),Qe=p(Ue),Q=i(Ue,"SPAN",{});var Xt=r(Q);We=l(Xt,"Using SpeechBrain at Hugging Face"),Xt.forEach(a),Ue.forEach(a),ke=p(e),B=i(e,"P",{});var Vt=r(B);W=i(Vt,"CODE",{});var Zt=r(W);Xe=l(Zt,"speechbrain"),Zt.forEach(a),Ze=l(Vt," is an open-source and all-in-one conversational toolkit for audio/speech. The goal is to create a single, flexible, and user-friendly toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for speech recognition, speaker recognition, speech enhancement, speech separation, language identification, multi-microphone signal processing, and many others."),Vt.forEach(a),$e=p(e),b=i(e,"H2",{class:!0});var qe=r(b);x=i(qe,"A",{id:!0,class:!0,href:!0});var ea=r(x);X=i(ea,"SPAN",{});var ta=r(X);ve(D.$$.fragment,ta),ta.forEach(a),ea.forEach(a),et=p(qe),Z=i(qe,"SPAN",{});var aa=r(Z);tt=l(aa,"Exploring SpeechBrain in the Hub"),aa.forEach(a),qe.forEach(a),xe=p(e),g=i(e,"P",{});var z=r(g);at=l(z,"You can find "),ee=i(z,"CODE",{});var sa=r(ee);st=l(sa,"speechbrain"),sa.forEach(a),it=l(z," models by filtering at the left of the "),L=i(z,"A",{href:!0,rel:!0});var ia=r(L);rt=l(ia,"models page"),ia.forEach(a),ot=l(z,"."),z.forEach(a),Ae=p(e),T=i(e,"P",{});var ra=r(T);lt=l(ra,"All models on the Hub come up with the following features:"),ra.forEach(a),Se=p(e),m=i(e,"OL",{});var C=r(m);te=i(C,"LI",{});var oa=r(te);nt=l(oa,"An automatically generated model card with a brief description."),oa.forEach(a),ct=p(C),ae=i(C,"LI",{});var la=r(ae);ht=l(la,"Metadata tags that help for discoverability with information such as the language, license, paper, and more."),la.forEach(a),ft=p(C),se=i(C,"LI",{});var na=r(se);pt=l(na,"An interactive widget you can use to play out with the model directly in the browser."),na.forEach(a),dt=p(C),ie=i(C,"LI",{});var ca=r(ie);ut=l(ca,"An Inference API that allows to make inference requests."),ca.forEach(a),C.forEach(a),Ie=p(e),E=i(e,"H2",{class:!0});var je=r(E);A=i(je,"A",{id:!0,class:!0,href:!0});var ha=r(A);re=i(ha,"SPAN",{});var fa=r(re);ve(O.$$.fragment,fa),fa.forEach(a),ha.forEach(a),mt=p(je),oe=i(je,"SPAN",{});var pa=r(oe);gt=l(pa,"Using existing models"),pa.forEach(a),je.forEach(a),Pe=p(e),d=i(e,"P",{});var u=r(d);le=i(u,"CODE",{});var da=r(le);vt=l(da,"speechbrain"),da.forEach(a),_t=l(u," offers different interfaces to manage pretrained models for different tasks, such as "),ne=i(u,"CODE",{});var ua=r(ne);bt=l(ua,"EncoderClassifier"),ua.forEach(a),Et=l(u,", "),ce=i(u,"CODE",{});var ma=r(ce);wt=l(ma,"EncoderClassifier"),ma.forEach(a),yt=l(u,", "),he=i(u,"CODE",{});var ga=r(he);kt=l(ga,"SepformerSeperation"),ga.forEach(a),$t=l(u,", and "),fe=i(u,"CODE",{});var va=r(fe);xt=l(va,"SpectralMaskEnhancement"),va.forEach(a),At=l(u,". These classes have a "),pe=i(u,"CODE",{});var _a=r(pe);St=l(_a,"from_hparams"),_a.forEach(a),It=l(u," method you can use to load a model from the Hub"),u.forEach(a),Ce=p(e),F=i(e,"P",{});var ba=r(F);Pt=l(ba,"Here is an example to run inference for sound recognition in urban sounds."),ba.forEach(a),He=p(e),ve(M.$$.fragment,e),Be=p(e),S=i(e,"P",{});var Ge=r(S);Ct=l(Ge,"If you want to see how to load a specific model, you can click "),de=i(Ge,"CODE",{});var Ea=r(de);Ht=l(Ea,"Use in speechbrain"),Ea.forEach(a),Bt=l(Ge," and you will be given a working snippet that you can load it!"),Ge.forEach(a),De=p(e),w=i(e,"DIV",{class:!0});var Te=r(w);V=i(Te,"IMG",{class:!0,src:!0}),Dt=p(Te),Y=i(Te,"IMG",{class:!0,src:!0}),Te.forEach(a),Le=p(e),y=i(e,"DIV",{class:!0});var Fe=r(y);J=i(Fe,"IMG",{class:!0,src:!0}),Lt=p(Fe),R=i(Fe,"IMG",{class:!0,src:!0}),Fe.forEach(a),Oe=p(e),k=i(e,"H2",{class:!0});var Ve=r(k);I=i(Ve,"A",{id:!0,class:!0,href:!0});var wa=r(I);ue=i(wa,"SPAN",{});var ya=r(ue);ve(N.$$.fragment,ya),ya.forEach(a),wa.forEach(a),Ot=p(Ve),me=i(Ve,"SPAN",{});var ka=r(me);Mt=l(ka,"Additional resources"),ka.forEach(a),Ve.forEach(a),Me=p(e),P=i(e,"UL",{});var Ye=r(P);U=i(Ye,"LI",{});var Je=r(U);Nt=l(Je,"SpeechBrain "),q=i(Je,"A",{href:!0,rel:!0});var $a=r(q);Ut=l($a,"website"),$a.forEach(a),qt=l(Je,"."),Je.forEach(a),jt=p(Ye),j=i(Ye,"LI",{});var Re=r(j);Gt=l(Re,"SpeechBrain "),G=i(Re,"A",{href:!0,rel:!0});var xa=r(G);Tt=l(xa,"docs"),xa.forEach(a),Ft=l(Re,"."),Re.forEach(a),Ye.forEach(a),this.h()},h(){n(v,"name","hf:doc:metadata"),n(v,"content",JSON.stringify(La)),n($,"id","using-speechbrain-at-hugging-face"),n($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n($,"href","#using-speechbrain-at-hugging-face"),n(_,"class","relative group"),n(x,"id","exploring-speechbrain-in-the-hub"),n(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(x,"href","#exploring-speechbrain-in-the-hub"),n(b,"class","relative group"),n(L,"href","https://huggingface.co/models?library=speechbrain"),n(L,"rel","nofollow"),n(A,"id","using-existing-models"),n(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(A,"href","#using-existing-models"),n(E,"class","relative group"),n(V,"class","block dark:hidden"),ze(V.src,Jt="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet1.png")||n(V,"src",Jt),n(Y,"class","hidden dark:block"),ze(Y.src,Rt="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet1-dark.png")||n(Y,"src",Rt),n(w,"class","flex justify-center"),n(J,"class","block dark:hidden"),ze(J.src,zt="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet2.png")||n(J,"src",zt),n(R,"class","hidden dark:block"),ze(R.src,Kt="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet2-dark.png")||n(R,"src",Kt),n(y,"class","flex justify-center"),n(I,"id","additional-resources"),n(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(I,"href","#additional-resources"),n(k,"class","relative group"),n(q,"href","https://speechbrain.github.io/"),n(q,"rel","nofollow"),n(G,"href","https://speechbrain.readthedocs.io/en/latest/index.html"),n(G,"rel","nofollow")},m(e,c){t(document.head,v),h(e,ye,c),h(e,_,c),t(_,$),t($,K),_e(H,K,null),t(_,Qe),t(_,Q),t(Q,We),h(e,ke,c),h(e,B,c),t(B,W),t(W,Xe),t(B,Ze),h(e,$e,c),h(e,b,c),t(b,x),t(x,X),_e(D,X,null),t(b,et),t(b,Z),t(Z,tt),h(e,xe,c),h(e,g,c),t(g,at),t(g,ee),t(ee,st),t(g,it),t(g,L),t(L,rt),t(g,ot),h(e,Ae,c),h(e,T,c),t(T,lt),h(e,Se,c),h(e,m,c),t(m,te),t(te,nt),t(m,ct),t(m,ae),t(ae,ht),t(m,ft),t(m,se),t(se,pt),t(m,dt),t(m,ie),t(ie,ut),h(e,Ie,c),h(e,E,c),t(E,A),t(A,re),_e(O,re,null),t(E,mt),t(E,oe),t(oe,gt),h(e,Pe,c),h(e,d,c),t(d,le),t(le,vt),t(d,_t),t(d,ne),t(ne,bt),t(d,Et),t(d,ce),t(ce,wt),t(d,yt),t(d,he),t(he,kt),t(d,$t),t(d,fe),t(fe,xt),t(d,At),t(d,pe),t(pe,St),t(d,It),h(e,Ce,c),h(e,F,c),t(F,Pt),h(e,He,c),_e(M,e,c),h(e,Be,c),h(e,S,c),t(S,Ct),t(S,de),t(de,Ht),t(S,Bt),h(e,De,c),h(e,w,c),t(w,V),t(w,Dt),t(w,Y),h(e,Le,c),h(e,y,c),t(y,J),t(y,Lt),t(y,R),h(e,Oe,c),h(e,k,c),t(k,I),t(I,ue),_e(N,ue,null),t(k,Ot),t(k,me),t(me,Mt),h(e,Me,c),h(e,P,c),t(P,U),t(U,Nt),t(U,q),t(q,Ut),t(U,qt),t(P,jt),t(P,j),t(j,Gt),t(j,G),t(G,Tt),t(j,Ft),Ne=!0},p:Ca,i(e){Ne||(be(H.$$.fragment,e),be(D.$$.fragment,e),be(O.$$.fragment,e),be(M.$$.fragment,e),be(N.$$.fragment,e),Ne=!0)},o(e){Ee(H.$$.fragment,e),Ee(D.$$.fragment,e),Ee(O.$$.fragment,e),Ee(M.$$.fragment,e),Ee(N.$$.fragment,e),Ne=!1},d(e){a(v),e&&a(ye),e&&a(_),we(H),e&&a(ke),e&&a(B),e&&a($e),e&&a(b),we(D),e&&a(xe),e&&a(g),e&&a(Ae),e&&a(T),e&&a(Se),e&&a(m),e&&a(Ie),e&&a(E),we(O),e&&a(Pe),e&&a(d),e&&a(Ce),e&&a(F),e&&a(He),we(M,e),e&&a(Be),e&&a(S),e&&a(De),e&&a(w),e&&a(Le),e&&a(y),e&&a(Oe),e&&a(k),we(N),e&&a(Me),e&&a(P)}}}const La={local:"using-speechbrain-at-hugging-face",sections:[{local:"exploring-speechbrain-in-the-hub",title:"Exploring SpeechBrain in the Hub"},{local:"using-existing-models",title:"Using existing models"},{local:"additional-resources",title:"Additional resources"}],title:"Using SpeechBrain at Hugging Face"};function Oa(Yt){return Ha(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class qa extends Aa{constructor(v){super();Sa(this,v,Oa,Da,Ia,{})}}export{qa as default,La as metadata};
