<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;using-speechbrain-at-hugging-face&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;exploring-speechbrain-in-the-hub&quot;,&quot;title&quot;:&quot;Exploring SpeechBrain in the Hub&quot;},{&quot;local&quot;:&quot;using-existing-models&quot;,&quot;title&quot;:&quot;Using existing models&quot;},{&quot;local&quot;:&quot;additional-resources&quot;,&quot;title&quot;:&quot;Additional resources&quot;}],&quot;title&quot;:&quot;Using SpeechBrain at Hugging Face&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/pages/speechbrain.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/chunks/IconCopyLink-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub-docs/pr_189/en/_app/chunks/CodeBlock-hf-doc-builder.js"> 





<h1 class="relative group"><a id="using-speechbrain-at-hugging-face" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#using-speechbrain-at-hugging-face"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Using SpeechBrain at Hugging Face
	</span></h1>

<p><code>speechbrain</code> is an open-source and all-in-one conversational toolkit for audio/speech. The goal is to create a single, flexible, and user-friendly toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for speech recognition, speaker recognition, speech enhancement, speech separation, language identification, multi-microphone signal processing, and many others.</p>
<h2 class="relative group"><a id="exploring-speechbrain-in-the-hub" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#exploring-speechbrain-in-the-hub"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Exploring SpeechBrain in the Hub
	</span></h2>

<p>You can find <code>speechbrain</code> models by filtering at the left of the <a href="https://huggingface.co/models?library=speechbrain" rel="nofollow">models page</a>.</p>
<p>All models on the Hub come up with the following features:</p>
<ol><li>An automatically generated model card with a brief description.</li>
<li>Metadata tags that help for discoverability with information such as the language, license, paper, and more.</li>
<li>An interactive widget you can use to play out with the model directly in the browser.</li>
<li>An Inference API that allows to make inference requests.</li></ol>
<h2 class="relative group"><a id="using-existing-models" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#using-existing-models"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Using existing models
	</span></h2>

<p><code>speechbrain</code> offers different interfaces to manage pretrained models for different tasks, such as <code>EncoderClassifier</code>, <code>EncoderClassifier</code>, <code>SepformerSeperation</code>, and <code>SpectralMaskEnhancement</code>. These classes have a <code>from_hparams</code> method you can use to load a model from the Hub</p>
<p>Here is an example to run inference for sound recognition in urban sounds.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> torchaudio
<span class="hljs-keyword">from</span> speechbrain.pretrained <span class="hljs-keyword">import</span> EncoderClassifier

classifier = EncoderClassifier.from_hparams(
    source=<span class="hljs-string">&quot;speechbrain/urbansound8k_ecapa&quot;</span>
)
out_prob, score, index, text_lab = classifier.classify_file(<span class="hljs-string">&#x27;speechbrain/urbansound8k_ecapa/dog_bark.wav&#x27;</span>)<!-- HTML_TAG_END --></pre></div>
<p>If you want to see how to load a specific model, you can click <code>Use in speechbrain</code> and you will be given a working snippet that you can load it!</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet1.png">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet1-dark.png"></div>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet2.png">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-speechbrain_snippet2-dark.png"></div>
<h2 class="relative group"><a id="additional-resources" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#additional-resources"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Additional resources
	</span></h2>

<ul><li>SpeechBrain <a href="https://speechbrain.github.io/" rel="nofollow">website</a>.</li>
<li>SpeechBrain <a href="https://speechbrain.readthedocs.io/en/latest/index.html" rel="nofollow">docs</a>.</li></ul>


		<script type="module" data-hydrate="zii27w">
		import { start } from "/docs/hub-docs/pr_189/en/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="zii27w"]').parentNode,
			paths: {"base":"/docs/hub-docs/pr_189/en","assets":"/docs/hub-docs/pr_189/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/hub-docs/pr_189/en/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/hub-docs/pr_189/en/_app/pages/speechbrain.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
