import{S as Ga,i as Fa,s as Ra,e as s,k as c,w as H,t as r,N as Ya,c as l,d as o,m as u,a as i,x as z,h as a,b as n,P as Qt,G as e,g as h,y as N,L as Ba,q as O,o as U,B as G,v as Ja}from"../chunks/vendor-hf-doc-builder.js";import{I as st}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Br}from"../chunks/CodeBlock-hf-doc-builder.js";function Wa(Jr){let E,lt,b,j,Ne,F,Zt,R,eo,Oe,to,oo,it,g,ro,Ue,ao,so,Ge,lo,io,nt,$,S,Fe,Y,no,Re,fo,ft,v,ho,Ye,co,uo,B,mo,po,ht,Pe,go,ct,d,J,vo,W,_o,wo,yo,V,Eo,X,bo,$o,ko,K,Ao,Q,xo,Po,Io,Z,jo,ee,So,Lo,To,te,qo,oe,Co,Do,Mo,re,Ho,ae,zo,No,Oo,se,Uo,le,Go,Fo,Ro,ie,Yo,ne,Bo,Jo,Wo,fe,Vo,he,Xo,Ko,Qo,ce,Zo,ue,er,tr,ut,Ie,or,dt,k,je,Wr,rr,Se,Vr,mt,A,L,Be,de,ar,Je,sr,pt,p,lr,We,ir,nr,Ve,fr,hr,Xe,cr,ur,gt,me,vt,Le,dr,_t,pe,wt,T,mr,Ke,pr,gr,yt,x,Te,Xr,vr,qe,Kr,Et,P,q,Qe,ge,_r,Ze,wr,bt,_,yr,et,Er,br,ve,$r,kr,$t,w,Ar,tt,xr,Pr,ot,Ir,jr,kt,_e,At,C,Sr,we,Lr,Tr,xt,I,D,rt,ye,qr,at,Cr,Pt,y,Ee,Dr,be,Mr,Hr,zr,$e,Nr,ke,Or,Ur,Gr,Ae,Fr,xe,Rr,Yr,It;return F=new st({}),Y=new st({}),de=new st({}),me=new Br({props:{code:"",highlighted:`<span class="hljs-comment"># With pipeline, just specify the task and the model id from the Hub.</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
pipe = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;distilgpt2&quot;</span>)

<span class="hljs-comment"># If you want more control, you will need to define the tokenizer and model.</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM
tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),pe=new Br({props:{code:`model = AutoModel.from_pretrained(
    "julien-c/EsperBERTo-small", revision="v2.0.1"  # tag name, or branch name, or commit hash
)`,highlighted:`model = AutoModel.from_pretrained(
    <span class="hljs-string">&quot;julien-c/EsperBERTo-small&quot;</span>, revision=<span class="hljs-string">&quot;v2.0.1&quot;</span>  <span class="hljs-comment"># tag name, or branch name, or commit hash</span>
)`}}),ge=new st({}),_e=new Br({props:{code:`
`,highlighted:`<span class="hljs-comment"># Pushing model to your own account</span>
model.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)

<span class="hljs-comment"># Pushing your tokenizer</span>
tokenizer.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)

<span class="hljs-comment"># Pushing all things after training</span>
trainer.push_to_hub()`}}),ye=new st({}),{c(){E=s("meta"),lt=c(),b=s("h1"),j=s("a"),Ne=s("span"),H(F.$$.fragment),Zt=c(),R=s("span"),eo=r("Using \u{1F917} "),Oe=s("code"),to=r("transformers"),oo=r(" at Hugging Face"),it=c(),g=s("p"),ro=r("\u{1F917} "),Ue=s("code"),ao=r("transformers"),so=r(" is a library with state-of-the-art Machine Learning for Pytorch, TensorFlow and JAX. It provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio. We are a bit biased, but we really like \u{1F917} "),Ge=s("code"),lo=r("transformers"),io=r("!"),nt=c(),$=s("h2"),S=s("a"),Fe=s("span"),H(Y.$$.fragment),no=c(),Re=s("span"),fo=r("Exploring \u{1F917} transformers in the Hub"),ft=c(),v=s("p"),ho=r("There are over 25,000 "),Ye=s("code"),co=r("transformers"),uo=r(" models in the Hub which you can find by filtering at the left of "),B=s("a"),mo=r("the models page"),po=r("."),ht=c(),Pe=s("p"),go=r("You can find models for many different tasks:"),ct=c(),d=s("ul"),J=s("li"),vo=r("Extracting the answer from a context ("),W=s("a"),_o=r("question-answering"),wo=r(")."),yo=c(),V=s("li"),Eo=r("Creating summaries from a large text ("),X=s("a"),bo=r("summarization"),$o=r(")."),ko=c(),K=s("li"),Ao=r("Classify text (e.g. as spam or not spam, "),Q=s("a"),xo=r("text-classification"),Po=r(")."),Io=c(),Z=s("li"),jo=r("Generate a new text with models such as GPT ("),ee=s("a"),So=r("text-generation"),Lo=r(")."),To=c(),te=s("li"),qo=r("Identify parts of speech (verb, subject, etc.) or entities (country, organization, etc.) in a sentence ("),oe=s("a"),Co=r("token-classification"),Do=r(")."),Mo=c(),re=s("li"),Ho=r("Transcribe audio files to text ("),ae=s("a"),zo=r("automatic-speech-recognition"),No=r(")."),Oo=c(),se=s("li"),Uo=r("Classify the speaker or language in an audio file ("),le=s("a"),Go=r("audio-classification"),Fo=r(")."),Ro=c(),ie=s("li"),Yo=r("Detect objects in an image ("),ne=s("a"),Bo=r("object-detection"),Jo=r(")."),Wo=c(),fe=s("li"),Vo=r("Segment an image ("),he=s("a"),Xo=r("image-segmentation"),Ko=r(")."),Qo=c(),ce=s("li"),Zo=r("Do Reinforcement Learning ("),ue=s("a"),er=r("reinforcement-learning"),tr=r(")!"),ut=c(),Ie=s("p"),or=r("You can try out the models directly in the browser if you want to test them out without downloading them thanks to the in-browser widgets!"),dt=c(),k=s("div"),je=s("img"),rr=c(),Se=s("img"),mt=c(),A=s("h2"),L=s("a"),Be=s("span"),H(de.$$.fragment),ar=c(),Je=s("span"),sr=r("Using existing models"),pt=c(),p=s("p"),lr=r("All "),We=s("code"),ir=r("transformer"),nr=r(" models are a line away from being used! Depending on how you want to use them, you can use the high-level API using the "),Ve=s("code"),fr=r("pipeline"),hr=r(" function or you can use "),Xe=s("code"),cr=r("AutoModel"),ur=r(" for more control."),gt=c(),H(me.$$.fragment),vt=c(),Le=s("p"),dr=r("You can also load a model from a specific version (based on commit hash, tag name, or branch) as follows:"),_t=c(),H(pe.$$.fragment),wt=c(),T=s("p"),mr=r("If you want to see how to load a specific model, you can click "),Ke=s("code"),pr=r("Use in Transformers"),gr=r(" and you will be given a working snippet that you can load it! If you need further information about the model architecture, you can also click the \u201CRead model documentation\u201D at the bottom of the snippet."),yt=c(),x=s("div"),Te=s("img"),vr=c(),qe=s("img"),Et=c(),P=s("h2"),q=s("a"),Qe=s("span"),H(ge.$$.fragment),_r=c(),Ze=s("span"),wr=r("Sharing your models"),bt=c(),_=s("p"),yr=r("To read all about sharing models with "),et=s("code"),Er=r("transformers"),br=r(", please head out to the "),ve=s("a"),$r=r("Share a model"),kr=r(" guide in the official documentation."),$t=c(),w=s("p"),Ar=r("Many classes in "),tt=s("code"),xr=r("transformers"),Pr=r(", such as the models and tokenizers, have a "),ot=s("code"),Ir=r("push_to_hub"),jr=r(" method that allows to easily upload the files to a repository."),kt=c(),H(_e.$$.fragment),At=c(),C=s("p"),Sr=r("There is much more you can do, so we suggest to review the "),we=s("a"),Lr=r("Share a model"),Tr=r(" guide."),xt=c(),I=s("h2"),D=s("a"),rt=s("span"),H(ye.$$.fragment),qr=c(),at=s("span"),Cr=r("Additional resources"),Pt=c(),y=s("ul"),Ee=s("li"),Dr=r("Transformers "),be=s("a"),Mr=r("library"),Hr=r("."),zr=c(),$e=s("li"),Nr=r("Transformers "),ke=s("a"),Or=r("docs"),Ur=r("."),Gr=c(),Ae=s("li"),Fr=r("Share a model "),xe=s("a"),Rr=r("guide"),Yr=r("."),this.h()},l(t){const f=Ya('[data-svelte="svelte-1phssyn"]',document.head);E=l(f,"META",{name:!0,content:!0}),f.forEach(o),lt=u(t),b=l(t,"H1",{class:!0});var jt=i(b);j=l(jt,"A",{id:!0,class:!0,href:!0});var Qr=i(j);Ne=l(Qr,"SPAN",{});var Zr=i(Ne);z(F.$$.fragment,Zr),Zr.forEach(o),Qr.forEach(o),Zt=u(jt),R=l(jt,"SPAN",{});var St=i(R);eo=a(St,"Using \u{1F917} "),Oe=l(St,"CODE",{});var ea=i(Oe);to=a(ea,"transformers"),ea.forEach(o),oo=a(St," at Hugging Face"),St.forEach(o),jt.forEach(o),it=u(t),g=l(t,"P",{});var Ce=i(g);ro=a(Ce,"\u{1F917} "),Ue=l(Ce,"CODE",{});var ta=i(Ue);ao=a(ta,"transformers"),ta.forEach(o),so=a(Ce," is a library with state-of-the-art Machine Learning for Pytorch, TensorFlow and JAX. It provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio. We are a bit biased, but we really like \u{1F917} "),Ge=l(Ce,"CODE",{});var oa=i(Ge);lo=a(oa,"transformers"),oa.forEach(o),io=a(Ce,"!"),Ce.forEach(o),nt=u(t),$=l(t,"H2",{class:!0});var Lt=i($);S=l(Lt,"A",{id:!0,class:!0,href:!0});var ra=i(S);Fe=l(ra,"SPAN",{});var aa=i(Fe);z(Y.$$.fragment,aa),aa.forEach(o),ra.forEach(o),no=u(Lt),Re=l(Lt,"SPAN",{});var sa=i(Re);fo=a(sa,"Exploring \u{1F917} transformers in the Hub"),sa.forEach(o),Lt.forEach(o),ft=u(t),v=l(t,"P",{});var De=i(v);ho=a(De,"There are over 25,000 "),Ye=l(De,"CODE",{});var la=i(Ye);co=a(la,"transformers"),la.forEach(o),uo=a(De," models in the Hub which you can find by filtering at the left of "),B=l(De,"A",{href:!0,rel:!0});var ia=i(B);mo=a(ia,"the models page"),ia.forEach(o),po=a(De,"."),De.forEach(o),ht=u(t),Pe=l(t,"P",{});var na=i(Pe);go=a(na,"You can find models for many different tasks:"),na.forEach(o),ct=u(t),d=l(t,"UL",{});var m=i(d);J=l(m,"LI",{});var Tt=i(J);vo=a(Tt,"Extracting the answer from a context ("),W=l(Tt,"A",{href:!0,rel:!0});var fa=i(W);_o=a(fa,"question-answering"),fa.forEach(o),wo=a(Tt,")."),Tt.forEach(o),yo=u(m),V=l(m,"LI",{});var qt=i(V);Eo=a(qt,"Creating summaries from a large text ("),X=l(qt,"A",{href:!0,rel:!0});var ha=i(X);bo=a(ha,"summarization"),ha.forEach(o),$o=a(qt,")."),qt.forEach(o),ko=u(m),K=l(m,"LI",{});var Ct=i(K);Ao=a(Ct,"Classify text (e.g. as spam or not spam, "),Q=l(Ct,"A",{href:!0,rel:!0});var ca=i(Q);xo=a(ca,"text-classification"),ca.forEach(o),Po=a(Ct,")."),Ct.forEach(o),Io=u(m),Z=l(m,"LI",{});var Dt=i(Z);jo=a(Dt,"Generate a new text with models such as GPT ("),ee=l(Dt,"A",{href:!0,rel:!0});var ua=i(ee);So=a(ua,"text-generation"),ua.forEach(o),Lo=a(Dt,")."),Dt.forEach(o),To=u(m),te=l(m,"LI",{});var Mt=i(te);qo=a(Mt,"Identify parts of speech (verb, subject, etc.) or entities (country, organization, etc.) in a sentence ("),oe=l(Mt,"A",{href:!0,rel:!0});var da=i(oe);Co=a(da,"token-classification"),da.forEach(o),Do=a(Mt,")."),Mt.forEach(o),Mo=u(m),re=l(m,"LI",{});var Ht=i(re);Ho=a(Ht,"Transcribe audio files to text ("),ae=l(Ht,"A",{href:!0,rel:!0});var ma=i(ae);zo=a(ma,"automatic-speech-recognition"),ma.forEach(o),No=a(Ht,")."),Ht.forEach(o),Oo=u(m),se=l(m,"LI",{});var zt=i(se);Uo=a(zt,"Classify the speaker or language in an audio file ("),le=l(zt,"A",{href:!0,rel:!0});var pa=i(le);Go=a(pa,"audio-classification"),pa.forEach(o),Fo=a(zt,")."),zt.forEach(o),Ro=u(m),ie=l(m,"LI",{});var Nt=i(ie);Yo=a(Nt,"Detect objects in an image ("),ne=l(Nt,"A",{href:!0,rel:!0});var ga=i(ne);Bo=a(ga,"object-detection"),ga.forEach(o),Jo=a(Nt,")."),Nt.forEach(o),Wo=u(m),fe=l(m,"LI",{});var Ot=i(fe);Vo=a(Ot,"Segment an image ("),he=l(Ot,"A",{href:!0,rel:!0});var va=i(he);Xo=a(va,"image-segmentation"),va.forEach(o),Ko=a(Ot,")."),Ot.forEach(o),Qo=u(m),ce=l(m,"LI",{});var Ut=i(ce);Zo=a(Ut,"Do Reinforcement Learning ("),ue=l(Ut,"A",{href:!0,rel:!0});var _a=i(ue);er=a(_a,"reinforcement-learning"),_a.forEach(o),tr=a(Ut,")!"),Ut.forEach(o),m.forEach(o),ut=u(t),Ie=l(t,"P",{});var wa=i(Ie);or=a(wa,"You can try out the models directly in the browser if you want to test them out without downloading them thanks to the in-browser widgets!"),wa.forEach(o),dt=u(t),k=l(t,"DIV",{class:!0});var Gt=i(k);je=l(Gt,"IMG",{class:!0,src:!0}),rr=u(Gt),Se=l(Gt,"IMG",{class:!0,src:!0}),Gt.forEach(o),mt=u(t),A=l(t,"H2",{class:!0});var Ft=i(A);L=l(Ft,"A",{id:!0,class:!0,href:!0});var ya=i(L);Be=l(ya,"SPAN",{});var Ea=i(Be);z(de.$$.fragment,Ea),Ea.forEach(o),ya.forEach(o),ar=u(Ft),Je=l(Ft,"SPAN",{});var ba=i(Je);sr=a(ba,"Using existing models"),ba.forEach(o),Ft.forEach(o),pt=u(t),p=l(t,"P",{});var M=i(p);lr=a(M,"All "),We=l(M,"CODE",{});var $a=i(We);ir=a($a,"transformer"),$a.forEach(o),nr=a(M," models are a line away from being used! Depending on how you want to use them, you can use the high-level API using the "),Ve=l(M,"CODE",{});var ka=i(Ve);fr=a(ka,"pipeline"),ka.forEach(o),hr=a(M," function or you can use "),Xe=l(M,"CODE",{});var Aa=i(Xe);cr=a(Aa,"AutoModel"),Aa.forEach(o),ur=a(M," for more control."),M.forEach(o),gt=u(t),z(me.$$.fragment,t),vt=u(t),Le=l(t,"P",{});var xa=i(Le);dr=a(xa,"You can also load a model from a specific version (based on commit hash, tag name, or branch) as follows:"),xa.forEach(o),_t=u(t),z(pe.$$.fragment,t),wt=u(t),T=l(t,"P",{});var Rt=i(T);mr=a(Rt,"If you want to see how to load a specific model, you can click "),Ke=l(Rt,"CODE",{});var Pa=i(Ke);pr=a(Pa,"Use in Transformers"),Pa.forEach(o),gr=a(Rt," and you will be given a working snippet that you can load it! If you need further information about the model architecture, you can also click the \u201CRead model documentation\u201D at the bottom of the snippet."),Rt.forEach(o),yt=u(t),x=l(t,"DIV",{class:!0});var Yt=i(x);Te=l(Yt,"IMG",{class:!0,src:!0}),vr=u(Yt),qe=l(Yt,"IMG",{class:!0,src:!0}),Yt.forEach(o),Et=u(t),P=l(t,"H2",{class:!0});var Bt=i(P);q=l(Bt,"A",{id:!0,class:!0,href:!0});var Ia=i(q);Qe=l(Ia,"SPAN",{});var ja=i(Qe);z(ge.$$.fragment,ja),ja.forEach(o),Ia.forEach(o),_r=u(Bt),Ze=l(Bt,"SPAN",{});var Sa=i(Ze);wr=a(Sa,"Sharing your models"),Sa.forEach(o),Bt.forEach(o),bt=u(t),_=l(t,"P",{});var Me=i(_);yr=a(Me,"To read all about sharing models with "),et=l(Me,"CODE",{});var La=i(et);Er=a(La,"transformers"),La.forEach(o),br=a(Me,", please head out to the "),ve=l(Me,"A",{href:!0,rel:!0});var Ta=i(ve);$r=a(Ta,"Share a model"),Ta.forEach(o),kr=a(Me," guide in the official documentation."),Me.forEach(o),$t=u(t),w=l(t,"P",{});var He=i(w);Ar=a(He,"Many classes in "),tt=l(He,"CODE",{});var qa=i(tt);xr=a(qa,"transformers"),qa.forEach(o),Pr=a(He,", such as the models and tokenizers, have a "),ot=l(He,"CODE",{});var Ca=i(ot);Ir=a(Ca,"push_to_hub"),Ca.forEach(o),jr=a(He," method that allows to easily upload the files to a repository."),He.forEach(o),kt=u(t),z(_e.$$.fragment,t),At=u(t),C=l(t,"P",{});var Jt=i(C);Sr=a(Jt,"There is much more you can do, so we suggest to review the "),we=l(Jt,"A",{href:!0,rel:!0});var Da=i(we);Lr=a(Da,"Share a model"),Da.forEach(o),Tr=a(Jt," guide."),Jt.forEach(o),xt=u(t),I=l(t,"H2",{class:!0});var Wt=i(I);D=l(Wt,"A",{id:!0,class:!0,href:!0});var Ma=i(D);rt=l(Ma,"SPAN",{});var Ha=i(rt);z(ye.$$.fragment,Ha),Ha.forEach(o),Ma.forEach(o),qr=u(Wt),at=l(Wt,"SPAN",{});var za=i(at);Cr=a(za,"Additional resources"),za.forEach(o),Wt.forEach(o),Pt=u(t),y=l(t,"UL",{});var ze=i(y);Ee=l(ze,"LI",{});var Vt=i(Ee);Dr=a(Vt,"Transformers "),be=l(Vt,"A",{href:!0,rel:!0});var Na=i(be);Mr=a(Na,"library"),Na.forEach(o),Hr=a(Vt,"."),Vt.forEach(o),zr=u(ze),$e=l(ze,"LI",{});var Xt=i($e);Nr=a(Xt,"Transformers "),ke=l(Xt,"A",{href:!0,rel:!0});var Oa=i(ke);Or=a(Oa,"docs"),Oa.forEach(o),Ur=a(Xt,"."),Xt.forEach(o),Gr=u(ze),Ae=l(ze,"LI",{});var Kt=i(Ae);Fr=a(Kt,"Share a model "),xe=l(Kt,"A",{href:!0,rel:!0});var Ua=i(xe);Rr=a(Ua,"guide"),Ua.forEach(o),Yr=a(Kt,"."),Kt.forEach(o),ze.forEach(o),this.h()},h(){n(E,"name","hf:doc:metadata"),n(E,"content",JSON.stringify(Va)),n(j,"id","using-transformers-at-hugging-face"),n(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(j,"href","#using-transformers-at-hugging-face"),n(b,"class","relative group"),n(S,"id","exploring-transformers-in-the-hub"),n(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(S,"href","#exploring-transformers-in-the-hub"),n($,"class","relative group"),n(B,"href","https://huggingface.co/models?library=transformers&sort=downloads"),n(B,"rel","nofollow"),n(W,"href","https://huggingface.co/models?library=transformers&pipeline_tag=question-answering&sort=downloads"),n(W,"rel","nofollow"),n(X,"href","https://huggingface.co/models?library=transformers&pipeline_tag=summarization&sort=downloads"),n(X,"rel","nofollow"),n(Q,"href","https://huggingface.co/models?library=transformers&pipeline_tag=text-classification&sort=downloads"),n(Q,"rel","nofollow"),n(ee,"href","https://huggingface.co/models?library=transformers&pipeline_tag=text-generation&sort=downloads"),n(ee,"rel","nofollow"),n(oe,"href","https://huggingface.co/models?library=transformers&pipeline_tag=token-classification&sort=downloads"),n(oe,"rel","nofollow"),n(ae,"href","https://huggingface.co/models?library=transformers&pipeline_tag=automatic-speech-recognition&sort=downloads"),n(ae,"rel","nofollow"),n(le,"href","https://huggingface.co/models?library=transformers&pipeline_tag=audio-classification&sort=downloads"),n(le,"rel","nofollow"),n(ne,"href","https://huggingface.co/models?library=transformers&pipeline_tag=object-detection&sort=downloads"),n(ne,"rel","nofollow"),n(he,"href","https://huggingface.co/models?library=transformers&pipeline_tag=image-segmentation&sort=downloads"),n(he,"rel","nofollow"),n(ue,"href","https://huggingface.co/models?library=transformers&pipeline_tag=reinforcement-learning&sort=downloads"),n(ue,"rel","nofollow"),n(je,"class","block dark:hidden"),Qt(je.src,Wr="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_widget.png")||n(je,"src",Wr),n(Se,"class","hidden dark:block"),Qt(Se.src,Vr="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_widget-dark.png")||n(Se,"src",Vr),n(k,"class","flex justify-center"),n(L,"id","using-existing-models"),n(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(L,"href","#using-existing-models"),n(A,"class","relative group"),n(Te,"class","block dark:hidden"),Qt(Te.src,Xr="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_snippet.png")||n(Te,"src",Xr),n(qe,"class","hidden dark:block"),Qt(qe.src,Kr="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_snippet-dark.png")||n(qe,"src",Kr),n(x,"class","flex justify-center"),n(q,"id","sharing-your-models"),n(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(q,"href","#sharing-your-models"),n(P,"class","relative group"),n(ve,"href","https://huggingface.co/docs/transformers/model_sharing"),n(ve,"rel","nofollow"),n(we,"href","https://huggingface.co/docs/transformers/model_sharing"),n(we,"rel","nofollow"),n(D,"id","additional-resources"),n(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(D,"href","#additional-resources"),n(I,"class","relative group"),n(be,"href","https://github.com/huggingface/transformers"),n(be,"rel","nofollow"),n(ke,"href","https://huggingface.co/docs/transformers/index"),n(ke,"rel","nofollow"),n(xe,"href","https://huggingface.co/docs/transformers/model_sharing"),n(xe,"rel","nofollow")},m(t,f){e(document.head,E),h(t,lt,f),h(t,b,f),e(b,j),e(j,Ne),N(F,Ne,null),e(b,Zt),e(b,R),e(R,eo),e(R,Oe),e(Oe,to),e(R,oo),h(t,it,f),h(t,g,f),e(g,ro),e(g,Ue),e(Ue,ao),e(g,so),e(g,Ge),e(Ge,lo),e(g,io),h(t,nt,f),h(t,$,f),e($,S),e(S,Fe),N(Y,Fe,null),e($,no),e($,Re),e(Re,fo),h(t,ft,f),h(t,v,f),e(v,ho),e(v,Ye),e(Ye,co),e(v,uo),e(v,B),e(B,mo),e(v,po),h(t,ht,f),h(t,Pe,f),e(Pe,go),h(t,ct,f),h(t,d,f),e(d,J),e(J,vo),e(J,W),e(W,_o),e(J,wo),e(d,yo),e(d,V),e(V,Eo),e(V,X),e(X,bo),e(V,$o),e(d,ko),e(d,K),e(K,Ao),e(K,Q),e(Q,xo),e(K,Po),e(d,Io),e(d,Z),e(Z,jo),e(Z,ee),e(ee,So),e(Z,Lo),e(d,To),e(d,te),e(te,qo),e(te,oe),e(oe,Co),e(te,Do),e(d,Mo),e(d,re),e(re,Ho),e(re,ae),e(ae,zo),e(re,No),e(d,Oo),e(d,se),e(se,Uo),e(se,le),e(le,Go),e(se,Fo),e(d,Ro),e(d,ie),e(ie,Yo),e(ie,ne),e(ne,Bo),e(ie,Jo),e(d,Wo),e(d,fe),e(fe,Vo),e(fe,he),e(he,Xo),e(fe,Ko),e(d,Qo),e(d,ce),e(ce,Zo),e(ce,ue),e(ue,er),e(ce,tr),h(t,ut,f),h(t,Ie,f),e(Ie,or),h(t,dt,f),h(t,k,f),e(k,je),e(k,rr),e(k,Se),h(t,mt,f),h(t,A,f),e(A,L),e(L,Be),N(de,Be,null),e(A,ar),e(A,Je),e(Je,sr),h(t,pt,f),h(t,p,f),e(p,lr),e(p,We),e(We,ir),e(p,nr),e(p,Ve),e(Ve,fr),e(p,hr),e(p,Xe),e(Xe,cr),e(p,ur),h(t,gt,f),N(me,t,f),h(t,vt,f),h(t,Le,f),e(Le,dr),h(t,_t,f),N(pe,t,f),h(t,wt,f),h(t,T,f),e(T,mr),e(T,Ke),e(Ke,pr),e(T,gr),h(t,yt,f),h(t,x,f),e(x,Te),e(x,vr),e(x,qe),h(t,Et,f),h(t,P,f),e(P,q),e(q,Qe),N(ge,Qe,null),e(P,_r),e(P,Ze),e(Ze,wr),h(t,bt,f),h(t,_,f),e(_,yr),e(_,et),e(et,Er),e(_,br),e(_,ve),e(ve,$r),e(_,kr),h(t,$t,f),h(t,w,f),e(w,Ar),e(w,tt),e(tt,xr),e(w,Pr),e(w,ot),e(ot,Ir),e(w,jr),h(t,kt,f),N(_e,t,f),h(t,At,f),h(t,C,f),e(C,Sr),e(C,we),e(we,Lr),e(C,Tr),h(t,xt,f),h(t,I,f),e(I,D),e(D,rt),N(ye,rt,null),e(I,qr),e(I,at),e(at,Cr),h(t,Pt,f),h(t,y,f),e(y,Ee),e(Ee,Dr),e(Ee,be),e(be,Mr),e(Ee,Hr),e(y,zr),e(y,$e),e($e,Nr),e($e,ke),e(ke,Or),e($e,Ur),e(y,Gr),e(y,Ae),e(Ae,Fr),e(Ae,xe),e(xe,Rr),e(Ae,Yr),It=!0},p:Ba,i(t){It||(O(F.$$.fragment,t),O(Y.$$.fragment,t),O(de.$$.fragment,t),O(me.$$.fragment,t),O(pe.$$.fragment,t),O(ge.$$.fragment,t),O(_e.$$.fragment,t),O(ye.$$.fragment,t),It=!0)},o(t){U(F.$$.fragment,t),U(Y.$$.fragment,t),U(de.$$.fragment,t),U(me.$$.fragment,t),U(pe.$$.fragment,t),U(ge.$$.fragment,t),U(_e.$$.fragment,t),U(ye.$$.fragment,t),It=!1},d(t){o(E),t&&o(lt),t&&o(b),G(F),t&&o(it),t&&o(g),t&&o(nt),t&&o($),G(Y),t&&o(ft),t&&o(v),t&&o(ht),t&&o(Pe),t&&o(ct),t&&o(d),t&&o(ut),t&&o(Ie),t&&o(dt),t&&o(k),t&&o(mt),t&&o(A),G(de),t&&o(pt),t&&o(p),t&&o(gt),G(me,t),t&&o(vt),t&&o(Le),t&&o(_t),G(pe,t),t&&o(wt),t&&o(T),t&&o(yt),t&&o(x),t&&o(Et),t&&o(P),G(ge),t&&o(bt),t&&o(_),t&&o($t),t&&o(w),t&&o(kt),G(_e,t),t&&o(At),t&&o(C),t&&o(xt),t&&o(I),G(ye),t&&o(Pt),t&&o(y)}}}const Va={local:"using-transformers-at-hugging-face",sections:[{local:"exploring-transformers-in-the-hub",title:"Exploring \u{1F917} transformers in the Hub"},{local:"using-existing-models",title:"Using existing models"},{local:"sharing-your-models",title:"Sharing your models"},{local:"additional-resources",title:"Additional resources"}],title:"Using \u{1F917} `transformers` at Hugging Face"};function Xa(Jr){return Ja(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class es extends Ga{constructor(E){super();Fa(this,E,Xa,Wa,Ra,{})}}export{es as default,Va as metadata};
