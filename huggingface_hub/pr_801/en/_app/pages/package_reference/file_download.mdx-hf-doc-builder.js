import{S as bs,i as vs,s as ws,e as a,k as c,w as U,t as l,M as ys,c as n,d as t,m as h,a as s,x as F,h as r,b as m,G as e,g as d,y as M,q as H,o as B,B as V,v as Es,L as $s}from"../../chunks/vendor-hf-doc-builder.js";import{T as jt}from"../../chunks/Tip-hf-doc-builder.js";import{D as At}from"../../chunks/Docstring-hf-doc-builder.js";import{C as Go}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as zo}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as xs}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Ts(se){let g,j,w,f,_,p,v,A,P,$,y,C,S,T,u,E,L,W,R,x,D,N,K,z;return{c(){g=a("p"),j=l("Raises the following errors:"),w=c(),f=a("ul"),_=a("li"),p=a("a"),v=a("code"),A=l("EnvironmentError"),P=l(`
if `),$=a("code"),y=l("use_auth_token=True"),C=l(" and the token cannot be found."),S=c(),T=a("li"),u=a("a"),E=a("code"),L=l("OSError"),W=l(`
if ETag cannot be determined.`),R=c(),x=a("li"),D=a("a"),N=a("code"),K=l("ValueError"),z=l(`
if some parameter value is invalid`),this.h()},l(b){g=n(b,"P",{});var k=s(g);j=r(k,"Raises the following errors:"),k.forEach(t),w=h(b),f=n(b,"UL",{});var O=s(f);_=n(O,"LI",{});var I=s(_);p=n(I,"A",{href:!0,rel:!0});var le=s(p);v=n(le,"CODE",{});var Z=s(v);A=r(Z,"EnvironmentError"),Z.forEach(t),le.forEach(t),P=r(I,`
if `),$=n(I,"CODE",{});var re=s($);y=r(re,"use_auth_token=True"),re.forEach(t),C=r(I," and the token cannot be found."),I.forEach(t),S=h(O),T=n(O,"LI",{});var J=s(T);u=n(J,"A",{href:!0,rel:!0});var ee=s(u);E=n(ee,"CODE",{});var ie=s(E);L=r(ie,"OSError"),ie.forEach(t),ee.forEach(t),W=r(J,`
if ETag cannot be determined.`),J.forEach(t),R=h(O),x=n(O,"LI",{});var Q=s(x);D=n(Q,"A",{href:!0,rel:!0});var oe=s(D);N=n(oe,"CODE",{});var de=s(N);K=r(de,"ValueError"),de.forEach(t),oe.forEach(t),z=r(Q,`
if some parameter value is invalid`),Q.forEach(t),O.forEach(t),this.h()},h(){m(p,"href","https://docs.python.org/3/library/exceptions.html#EnvironmentError"),m(p,"rel","nofollow"),m(u,"href","https://docs.python.org/3/library/exceptions.html#OSError"),m(u,"rel","nofollow"),m(D,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),m(D,"rel","nofollow")},m(b,k){d(b,g,k),e(g,j),d(b,w,k),d(b,f,k),e(f,_),e(_,p),e(p,v),e(v,A),e(_,P),e(_,$),e($,y),e(_,C),e(f,S),e(f,T),e(T,u),e(u,E),e(E,L),e(T,W),e(f,R),e(f,x),e(x,D),e(D,N),e(N,K),e(x,z)},d(b){b&&t(g),b&&t(w),b&&t(f)}}}function ks(se){let g,j,w,f,_,p,v,A,P,$,y,C,S,T,u,E,L,W,R,x,D,N,K,z;return{c(){g=a("p"),j=l("Raises the following errors:"),w=c(),f=a("ul"),_=a("li"),p=a("a"),v=a("code"),A=l("EnvironmentError"),P=l(`
if `),$=a("code"),y=l("use_auth_token=True"),C=l(" and the token cannot be found."),S=c(),T=a("li"),u=a("a"),E=a("code"),L=l("OSError"),W=l(` if
ETag cannot be determined.`),R=c(),x=a("li"),D=a("a"),N=a("code"),K=l("ValueError"),z=l(`
if some parameter value is invalid`),this.h()},l(b){g=n(b,"P",{});var k=s(g);j=r(k,"Raises the following errors:"),k.forEach(t),w=h(b),f=n(b,"UL",{});var O=s(f);_=n(O,"LI",{});var I=s(_);p=n(I,"A",{href:!0,rel:!0});var le=s(p);v=n(le,"CODE",{});var Z=s(v);A=r(Z,"EnvironmentError"),Z.forEach(t),le.forEach(t),P=r(I,`
if `),$=n(I,"CODE",{});var re=s($);y=r(re,"use_auth_token=True"),re.forEach(t),C=r(I," and the token cannot be found."),I.forEach(t),S=h(O),T=n(O,"LI",{});var J=s(T);u=n(J,"A",{href:!0,rel:!0});var ee=s(u);E=n(ee,"CODE",{});var ie=s(E);L=r(ie,"OSError"),ie.forEach(t),ee.forEach(t),W=r(J,` if
ETag cannot be determined.`),J.forEach(t),R=h(O),x=n(O,"LI",{});var Q=s(x);D=n(Q,"A",{href:!0,rel:!0});var oe=s(D);N=n(oe,"CODE",{});var de=s(N);K=r(de,"ValueError"),de.forEach(t),oe.forEach(t),z=r(Q,`
if some parameter value is invalid`),Q.forEach(t),O.forEach(t),this.h()},h(){m(p,"href","https://docs.python.org/3/library/exceptions.html#EnvironmentError"),m(p,"rel","nofollow"),m(u,"href","https://docs.python.org/3/library/exceptions.html#OSError"),m(u,"rel","nofollow"),m(D,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),m(D,"rel","nofollow")},m(b,k){d(b,g,k),e(g,j),d(b,w,k),d(b,f,k),e(f,_),e(_,p),e(p,v),e(v,A),e(_,P),e(_,$),e($,y),e(_,C),e(f,S),e(f,T),e(T,u),e(u,E),e(E,L),e(T,W),e(f,R),e(f,x),e(x,D),e(D,N),e(N,K),e(x,z)},d(b){b&&t(g),b&&t(w),b&&t(f)}}}function Ds(se){let g,j,w,f,_,p,v,A,P,$,y,C,S,T,u,E,L,W,R,x,D,N,K,z;return{c(){g=a("p"),j=l("Raises the following errors:"),w=c(),f=a("ul"),_=a("li"),p=a("a"),v=a("code"),A=l("EnvironmentError"),P=l(`
if `),$=a("code"),y=l("use_auth_token=True"),C=l(" and the token cannot be found."),S=c(),T=a("li"),u=a("a"),E=a("code"),L=l("OSError"),W=l(`
if ETag cannot be determined.`),R=c(),x=a("li"),D=a("a"),N=a("code"),K=l("ValueError"),z=l(`
if some parameter value is invalid`),this.h()},l(b){g=n(b,"P",{});var k=s(g);j=r(k,"Raises the following errors:"),k.forEach(t),w=h(b),f=n(b,"UL",{});var O=s(f);_=n(O,"LI",{});var I=s(_);p=n(I,"A",{href:!0,rel:!0});var le=s(p);v=n(le,"CODE",{});var Z=s(v);A=r(Z,"EnvironmentError"),Z.forEach(t),le.forEach(t),P=r(I,`
if `),$=n(I,"CODE",{});var re=s($);y=r(re,"use_auth_token=True"),re.forEach(t),C=r(I," and the token cannot be found."),I.forEach(t),S=h(O),T=n(O,"LI",{});var J=s(T);u=n(J,"A",{href:!0,rel:!0});var ee=s(u);E=n(ee,"CODE",{});var ie=s(E);L=r(ie,"OSError"),ie.forEach(t),ee.forEach(t),W=r(J,`
if ETag cannot be determined.`),J.forEach(t),R=h(O),x=n(O,"LI",{});var Q=s(x);D=n(Q,"A",{href:!0,rel:!0});var oe=s(D);N=n(oe,"CODE",{});var de=s(N);K=r(de,"ValueError"),de.forEach(t),oe.forEach(t),z=r(Q,`
if some parameter value is invalid`),Q.forEach(t),O.forEach(t),this.h()},h(){m(p,"href","https://docs.python.org/3/library/exceptions.html#EnvironmentError"),m(p,"rel","nofollow"),m(u,"href","https://docs.python.org/3/library/exceptions.html#OSError"),m(u,"rel","nofollow"),m(D,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),m(D,"rel","nofollow")},m(b,k){d(b,g,k),e(g,j),d(b,w,k),d(b,f,k),e(f,_),e(_,p),e(p,v),e(v,A),e(_,P),e(_,$),e($,y),e(_,C),e(f,S),e(f,T),e(T,u),e(u,E),e(E,L),e(T,W),e(f,R),e(f,x),e(x,D),e(D,N),e(N,K),e(x,z)},d(b){b&&t(g),b&&t(w),b&&t(f)}}}function Os(se){let g,j,w,f,_;return f=new Go({props:{code:`from huggingface_hub import hf_hub_url

hf_hub_url(
    repo_id="julien-c/EsperBERTo-small", filename="pytorch_model.bin"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> hf_hub_url

<span class="hljs-meta">&gt;&gt;&gt; </span>hf_hub_url(
<span class="hljs-meta">... </span>    repo_id=<span class="hljs-string">&quot;julien-c/EsperBERTo-small&quot;</span>, filename=<span class="hljs-string">&quot;pytorch_model.bin&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-string">&#x27;https://huggingface.co/julien-c/EsperBERTo-small/resolve/main/pytorch_model.bin&#x27;</span>`}}),{c(){g=a("p"),j=l("Example:"),w=c(),U(f.$$.fragment)},l(p){g=n(p,"P",{});var v=s(g);j=r(v,"Example:"),v.forEach(t),w=h(p),F(f.$$.fragment,p)},m(p,v){d(p,g,v),e(g,j),d(p,w,v),M(f,p,v),_=!0},p:$s,i(p){_||(H(f.$$.fragment,p),_=!0)},o(p){B(f.$$.fragment,p),_=!1},d(p){p&&t(g),p&&t(w),V(f,p)}}}function Cs(se){let g,j,w,f,_,p,v,A,P,$,y,C,S,T;return{c(){g=a("p"),j=l("Notes:"),w=c(),f=a("p"),_=l(`Cloudfront is replicated over the globe so downloads are way faster for
the end user (and it also lowers our bandwidth costs).`),p=c(),v=a("p"),A=l(`Cloudfront aggressively caches files by default (default TTL is 24
hours), however this is not an issue here because we implement a
git-based versioning system on huggingface.co, which means that we store
the files on S3/Cloudfront in a content-addressable way (i.e., the file
name is its hash). Using content-addressable filenames means cache can\u2019t
ever be stale.`),P=c(),$=a("p"),y=l(`In terms of client-side caching from this library, we base our caching
on the objects\u2019 entity tag (`),C=a("code"),S=l("ETag"),T=l(`), which is an identifier of a
specific version of a resource [1]_. An object\u2019s ETag is: its git-sha1
if stored in git, or its sha256 if stored in git-lfs.`)},l(u){g=n(u,"P",{});var E=s(g);j=r(E,"Notes:"),E.forEach(t),w=h(u),f=n(u,"P",{});var L=s(f);_=r(L,`Cloudfront is replicated over the globe so downloads are way faster for
the end user (and it also lowers our bandwidth costs).`),L.forEach(t),p=h(u),v=n(u,"P",{});var W=s(v);A=r(W,`Cloudfront aggressively caches files by default (default TTL is 24
hours), however this is not an issue here because we implement a
git-based versioning system on huggingface.co, which means that we store
the files on S3/Cloudfront in a content-addressable way (i.e., the file
name is its hash). Using content-addressable filenames means cache can\u2019t
ever be stale.`),W.forEach(t),P=h(u),$=n(u,"P",{});var R=s($);y=r(R,`In terms of client-side caching from this library, we base our caching
on the objects\u2019 entity tag (`),C=n(R,"CODE",{});var x=s(C);S=r(x,"ETag"),x.forEach(t),T=r(R,`), which is an identifier of a
specific version of a resource [1]_. An object\u2019s ETag is: its git-sha1
if stored in git, or its sha256 if stored in git-lfs.`),R.forEach(t)},m(u,E){d(u,g,E),e(g,j),d(u,w,E),d(u,f,E),e(f,_),d(u,p,E),d(u,v,E),e(v,A),d(u,P,E),d(u,$,E),e($,y),e($,C),e(C,S),e($,T)},d(u){u&&t(g),u&&t(w),u&&t(f),u&&t(p),u&&t(v),u&&t(P),u&&t($)}}}function js(se){let g,j,w,f,_,p,v,A,P,$,y,C,S,T,u,E,L,W,R,x,D,N,K,z,b,k,O,I,le,Z,re,J,ee,ie,Q,oe,de,Nt,we,Ko,X,Re,It,no,Pt,Lt,so,Rt,St,lo,qt,Ut,ye,Jo,ne,Se,Ft,ro,Mt,Ht,io,Bt,Vt,Ee,Qo,q,qe,Wt,co,zt,Gt,ho,Kt,Jt,$e,Qt,xe,Xt,fo,Yt,Zt,po,Je,ea,Ue,oa,Xo,ge,Te,uo,Fe,ta,mo,aa,Yo,Qe,na,Zo,Xe,sa,et,Me,ot,Ye,la,tt,He,at,Ze,ra,nt,eo,ia,st,Be,lt,oo,da,rt,_e,ke,go,Ve,ca,_o,ha,it,te,fa,bo,pa,ua,vo,ma,ga,wo,_a,ba,yo,va,wa,dt,ce,ya,Eo,Ea,$a,$o,xa,Ta,xo,ka,Da,ct,he,Oa,To,Ca,ja,ko,Aa,Na,Do,Ia,Pa,ht,be,De,Oo,We,La,Co,Ra,ft,Oe,Sa,jo,qa,Ua,pt,ve,Ce,Ao,ze,Fa,No,Ma,ut,je,Ha,Io,Ba,Va,mt,G,Wa,Po,za,Ga,Lo,Ka,Ja,Ro,Qa,Xa,So,Ya,Za,qo,en,on,gt,pe,tn,Uo,an,nn,Fo,sn,ln,_t,Ge,bt,Ae,rn,Mo,dn,cn,vt,Ne,hn,Ho,fn,pn,wt;return p=new zo({}),C=new At({props:{name:"huggingface_hub.hf_hub_download",anchor:"huggingface_hub.hf_hub_download",parameters:[{name:"repo_id",val:": str"},{name:"filename",val:": str"},{name:"subfolder",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"},{name:"library_name",val:": typing.Optional[str] = None"},{name:"library_version",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"user_agent",val:": typing.Union[typing.Dict, str, NoneType] = None"},{name:"force_download",val:": typing.Optional[bool] = False"},{name:"force_filename",val:": typing.Optional[str] = None"},{name:"proxies",val:": typing.Optional[typing.Dict] = None"},{name:"etag_timeout",val:": typing.Optional[float] = 10"},{name:"resume_download",val:": typing.Optional[bool] = False"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"local_files_only",val:": typing.Optional[bool] = False"},{name:"legacy_cache_layout",val:": typing.Optional[bool] = False"}],parametersDescription:[{anchor:"huggingface_hub.hf_hub_download.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A user or an organization name and a repo name separated by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.hf_hub_download.filename",description:`<strong>filename</strong> (<code>str</code>) &#x2014;
The name of the file in the repo.`,name:"filename"},{anchor:"huggingface_hub.hf_hub_download.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional value corresponding to a folder inside the model repo.`,name:"subfolder"},{anchor:"huggingface_hub.hf_hub_download.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.hf_hub_download.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"},{anchor:"huggingface_hub.hf_hub_download.library_name",description:`<strong>library_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the library to which the object corresponds.`,name:"library_name"},{anchor:"huggingface_hub.hf_hub_download.library_version",description:`<strong>library_version</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The version of the library.`,name:"library_version"},{anchor:"huggingface_hub.hf_hub_download.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <code>Path</code>, <em>optional</em>) &#x2014;
Path to the folder where cached files are stored.`,name:"cache_dir"},{anchor:"huggingface_hub.hf_hub_download.user_agent",description:`<strong>user_agent</strong> (<code>dict</code>, <code>str</code>, <em>optional</em>) &#x2014;
The user-agent info in the form of a dictionary or a string.`,name:"user_agent"},{anchor:"huggingface_hub.hf_hub_download.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the file should be downloaded even if it already exists in
the local cache.`,name:"force_download"},{anchor:"huggingface_hub.hf_hub_download.proxies",description:`<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Dictionary mapping protocol to the URL of the proxy passed to
<code>requests.request</code>.`,name:"proxies"},{anchor:"huggingface_hub.hf_hub_download.etag_timeout",description:`<strong>etag_timeout</strong> (<code>float</code>, <em>optional</em>, defaults to <code>10</code>) &#x2014;
When fetching ETag, how many seconds to wait for the server to send
data before giving up which is passed to <code>requests.request</code>.`,name:"etag_timeout"},{anchor:"huggingface_hub.hf_hub_download.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, resume a previously interrupted download.`,name:"resume_download"},{anchor:"huggingface_hub.hf_hub_download.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code>, <code>bool</code>, <em>optional</em>) &#x2014;
A token to be used for the download.<ul>
<li>If <code>True</code>, the token is read from the HuggingFace config
folder.</li>
<li>If a string, it&#x2019;s used as the authentication token.</li>
</ul>`,name:"use_auth_token"},{anchor:"huggingface_hub.hf_hub_download.local_files_only",description:`<strong>local_files_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, avoid downloading the file and return the path to the
local cached file if it exists.`,name:"local_files_only"},{anchor:"huggingface_hub.hf_hub_download.legacy_cache_layout",description:`<strong>legacy_cache_layout</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, uses the legacy file cache layout i.e. just call <code>hf_hub_url</code>
then <code>cached_download</code>. This is deprecated as the new cache layout is
more powerful.`,name:"legacy_cache_layout"}],source:"https://github.com/huggingface/huggingface_hub/blob/vr_801/src/huggingface_hub/file_download.py#L784",returnDescription:`
<p>Local path (string) of file or if networking is off, last version of
file cached on disk.</p>
`}}),we=new jt({props:{$$slots:{default:[Ts]},$$scope:{ctx:se}}}),Re=new At({props:{name:"huggingface_hub.snapshot_download",anchor:"huggingface_hub.snapshot_download",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"library_name",val:": typing.Optional[str] = None"},{name:"library_version",val:": typing.Optional[str] = None"},{name:"user_agent",val:": typing.Union[typing.Dict, str, NoneType] = None"},{name:"proxies",val:": typing.Optional[typing.Dict] = None"},{name:"etag_timeout",val:": typing.Optional[float] = 10"},{name:"resume_download",val:": typing.Optional[bool] = False"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"local_files_only",val:": typing.Optional[bool] = False"},{name:"allow_regex",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_regex",val:": typing.Union[typing.List[str], str, NoneType] = None"}],parametersDescription:[{anchor:"huggingface_hub.snapshot_download.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A user or an organization name and a repo name separated by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.snapshot_download.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"},{anchor:"huggingface_hub.snapshot_download.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.snapshot_download.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <code>Path</code>, <em>optional</em>) &#x2014;
Path to the folder where cached files are stored.`,name:"cache_dir"},{anchor:"huggingface_hub.snapshot_download.library_name",description:`<strong>library_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the library to which the object corresponds.`,name:"library_name"},{anchor:"huggingface_hub.snapshot_download.library_version",description:`<strong>library_version</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The version of the library.`,name:"library_version"},{anchor:"huggingface_hub.snapshot_download.user_agent",description:`<strong>user_agent</strong> (<code>str</code>, <code>dict</code>, <em>optional</em>) &#x2014;
The user-agent info in the form of a dictionary or a string.`,name:"user_agent"},{anchor:"huggingface_hub.snapshot_download.proxies",description:`<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Dictionary mapping protocol to the URL of the proxy passed to
<code>requests.request</code>.`,name:"proxies"},{anchor:"huggingface_hub.snapshot_download.etag_timeout",description:`<strong>etag_timeout</strong> (<code>float</code>, <em>optional</em>, defaults to <code>10</code>) &#x2014;
When fetching ETag, how many seconds to wait for the server to send
data before giving up which is passed to <code>requests.request</code>.`,name:"etag_timeout"},{anchor:"huggingface_hub.snapshot_download.resume_download",description:"<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False) -- If </code>True`, resume a previously interrupted download.",name:"resume_download"},{anchor:"huggingface_hub.snapshot_download.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code>, <code>bool</code>, <em>optional</em>) &#x2014;
A token to be used for the download.<ul>
<li>If <code>True</code>, the token is read from the HuggingFace config
folder.</li>
<li>If a string, it&#x2019;s used as the authentication token.</li>
</ul>`,name:"use_auth_token"},{anchor:"huggingface_hub.snapshot_download.local_files_only",description:`<strong>local_files_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, avoid downloading the file and return the path to the
local cached file if it exists.`,name:"local_files_only"},{anchor:"huggingface_hub.snapshot_download.allow_regex",description:`<strong>allow_regex</strong> (<code>list of str</code>, <code>str</code>, <em>optional</em>) &#x2014;
If provided, only files matching this regex are downloaded.`,name:"allow_regex"},{anchor:"huggingface_hub.snapshot_download.ignore_regex",description:`<strong>ignore_regex</strong> (<code>list of str</code>, <code>str</code>, <em>optional</em>) &#x2014;
If provided, files matching this regex are not downloaded.`,name:"ignore_regex"}],source:"https://github.com/huggingface/huggingface_hub/blob/vr_801/src/huggingface_hub/_snapshot_download.py#L42",returnDescription:`
<p>Local folder path (string) of repo snapshot</p>
`}}),ye=new jt({props:{$$slots:{default:[ks]},$$scope:{ctx:se}}}),Se=new At({props:{name:"huggingface_hub.cached_download",anchor:"huggingface_hub.cached_download",parameters:[{name:"url",val:": str"},{name:"library_name",val:": typing.Optional[str] = None"},{name:"library_version",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"user_agent",val:": typing.Union[typing.Dict, str, NoneType] = None"},{name:"force_download",val:": typing.Optional[bool] = False"},{name:"force_filename",val:": typing.Optional[str] = None"},{name:"proxies",val:": typing.Optional[typing.Dict] = None"},{name:"etag_timeout",val:": typing.Optional[float] = 10"},{name:"resume_download",val:": typing.Optional[bool] = False"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"local_files_only",val:": typing.Optional[bool] = False"},{name:"legacy_cache_layout",val:": typing.Optional[bool] = False"}],parametersDescription:[{anchor:"huggingface_hub.cached_download.url",description:`<strong>url</strong> (<code>str</code>) &#x2014;
The path to the file to be downloaded.`,name:"url"},{anchor:"huggingface_hub.cached_download.library_name",description:`<strong>library_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the library to which the object corresponds.`,name:"library_name"},{anchor:"huggingface_hub.cached_download.library_version",description:`<strong>library_version</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The version of the library.`,name:"library_version"},{anchor:"huggingface_hub.cached_download.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <code>Path</code>, <em>optional</em>) &#x2014;
Path to the folder where cached files are stored.`,name:"cache_dir"},{anchor:"huggingface_hub.cached_download.user_agent",description:`<strong>user_agent</strong> (<code>dict</code>, <code>str</code>, <em>optional</em>) &#x2014;
The user-agent info in the form of a dictionary or a string.`,name:"user_agent"},{anchor:"huggingface_hub.cached_download.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the file should be downloaded even if it already exists in
the local cache.`,name:"force_download"},{anchor:"huggingface_hub.cached_download.force_filename",description:`<strong>force_filename</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Use this name instead of a generated file name.`,name:"force_filename"},{anchor:"huggingface_hub.cached_download.proxies",description:`<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Dictionary mapping protocol to the URL of the proxy passed to
<code>requests.request</code>.`,name:"proxies"},{anchor:"huggingface_hub.cached_download.etag_timeout",description:`<strong>etag_timeout</strong> (<code>float</code>, <em>optional</em> defaults to <code>10</code>) &#x2014;
When fetching ETag, how many seconds to wait for the server to send
data before giving up which is passed to <code>requests.request</code>.`,name:"etag_timeout"},{anchor:"huggingface_hub.cached_download.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, resume a previously interrupted download.`,name:"resume_download"},{anchor:"huggingface_hub.cached_download.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code>, <code>str</code>, <em>optional</em>) &#x2014;
A token to be used for the download.<ul>
<li>If <code>True</code>, the token is read from the HuggingFace config
folder.</li>
<li>If a string, it&#x2019;s used as the authentication token.</li>
</ul>`,name:"use_auth_token"},{anchor:"huggingface_hub.cached_download.local_files_only",description:`<strong>local_files_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, avoid downloading the file and return the path to the
local cached file if it exists.`,name:"local_files_only"},{anchor:"huggingface_hub.cached_download.legacy_cache_layout",description:`<strong>legacy_cache_layout</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set this parameter to <code>True</code> to mention that you&#x2019;d like to continue
the old cache layout. Putting this to <code>True</code> manually will not raise
any warning when using <code>cached_download</code>. We recommend using
<code>hf_hub_download</code> to take advantage of the new cache.`,name:"legacy_cache_layout"}],source:"https://github.com/huggingface/huggingface_hub/blob/vr_801/src/huggingface_hub/file_download.py#L455",returnDescription:`
<p>Local path (string) of file or if networking is off, last version of
file cached on disk.</p>
`}}),Ee=new jt({props:{$$slots:{default:[Ds]},$$scope:{ctx:se}}}),qe=new At({props:{name:"huggingface_hub.hf_hub_url",anchor:"huggingface_hub.hf_hub_url",parameters:[{name:"repo_id",val:": str"},{name:"filename",val:": str"},{name:"subfolder",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.hf_hub_url.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) name and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.hf_hub_url.filename",description:`<strong>filename</strong> (<code>str</code>) &#x2014;
The name of the file in the repo.`,name:"filename"},{anchor:"huggingface_hub.hf_hub_url.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional value corresponding to a folder inside the repo.`,name:"subfolder"},{anchor:"huggingface_hub.hf_hub_url.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.hf_hub_url.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"}],source:"https://github.com/huggingface/huggingface_hub/blob/vr_801/src/huggingface_hub/file_download.py#L153"}}),$e=new xs({props:{anchor:"huggingface_hub.hf_hub_url.example",$$slots:{default:[Os]},$$scope:{ctx:se}}}),xe=new jt({props:{$$slots:{default:[Cs]},$$scope:{ctx:se}}}),Fe=new zo({}),Me=new Go({props:{code:`<CACHE_DIR>
\u251C\u2500 <MODELS>
\u251C\u2500 <DATASETS>
\u251C\u2500 <SPACES>`,highlighted:`<span class="hljs-tag">&lt;<span class="hljs-name">CACHE_DIR</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">MODELS</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">DATASETS</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">SPACES</span>&gt;</span>`}}),He=new Go({props:{code:`<CACHE_DIR>
\u251C\u2500 models--julien-c--EsperBERTo-small
\u251C\u2500 models--lysandrejik--arxiv-nlp
\u251C\u2500 models--bert-base-cased
\u251C\u2500 datasets--glue
\u251C\u2500 datasets--huggingface--DataMeasurementsFiles
\u251C\u2500 spaces--dalle-mini--dalle-mini`,highlighted:`&lt;<span class="hljs-comment">CACHE_DIR</span>&gt;
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">julien</span><span class="hljs-literal">-</span><span class="hljs-comment">c</span>--<span class="hljs-comment">EsperBERTo</span><span class="hljs-literal">-</span><span class="hljs-comment">small</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">lysandrejik</span>--<span class="hljs-comment">arxiv</span><span class="hljs-literal">-</span><span class="hljs-comment">nlp</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">bert</span><span class="hljs-literal">-</span><span class="hljs-comment">base</span><span class="hljs-literal">-</span><span class="hljs-comment">cased</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">datasets</span>--<span class="hljs-comment">glue</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">datasets</span>--<span class="hljs-comment">huggingface</span>--<span class="hljs-comment">DataMeasurementsFiles</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">spaces</span>--<span class="hljs-comment">dalle</span><span class="hljs-literal">-</span><span class="hljs-comment">mini</span>--<span class="hljs-comment">dalle</span><span class="hljs-literal">-</span><span class="hljs-comment">mini</span>`}}),Be=new Go({props:{code:`<CACHE_DIR>
\u251C\u2500 datasets--glue
\u2502  \u251C\u2500 refs
\u2502  \u251C\u2500 blobs
\u2502  \u251C\u2500 snapshots
...`,highlighted:`&lt;CACHE_DIR&gt;
\u251C\u2500 datasets<span class="hljs-params">--glue</span>
\u2502  \u251C\u2500 refs
\u2502  \u251C\u2500 blobs
\u2502  \u251C\u2500 snapshots
<span class="hljs-string">...</span>`}}),Ve=new zo({}),We=new zo({}),ze=new zo({}),Ge=new Go({props:{code:"<CACHE_DIR>/<REPO_NAME>/snapshots/aaaaaa/README.md",highlighted:'&lt;CACHE_DIR&gt;<span class="hljs-regexp">/&lt;REPO_NAME&gt;/</span>snapshots<span class="hljs-regexp">/aaaaaa/</span>README.md'}}),{c(){g=a("meta"),j=c(),w=a("h1"),f=a("a"),_=a("span"),U(p.$$.fragment),v=c(),A=a("span"),P=l("Downloading files"),$=c(),y=a("div"),U(C.$$.fragment),S=c(),T=a("p"),u=l("Download a given file if it\u2019s not already present in the local cache."),E=c(),L=a("p"),W=l("The new cache file layout looks like this:"),R=c(),x=a("ul"),D=a("li"),N=l("The cache directory contains one subfolder per repo_id (namespaced by repo type)"),K=c(),z=a("li"),b=l("inside each repo folder:"),k=a("ul"),O=a("li"),I=l("refs is a list of the latest known revision => commit_hash pairs"),le=c(),Z=a("li"),re=l(`blobs contains the actual file blobs (identified by their git-sha or sha256, depending on
whether they\u2019re LFS files or not)`),J=c(),ee=a("li"),ie=l(`snapshots contains one subfolder per commit, each \u201Ccommit\u201D contains the subset of the files
that have been resolved at that particular commit. Each filename is a symlink to the blob
at that particular commit.`),Q=c(),oe=a("p"),de=l(`[  96]  .
\u2514\u2500\u2500 [ 160]  models\u2014julien-c\u2014EsperBERTo-small
\u251C\u2500\u2500 [ 160]  blobs
\u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
\u251C\u2500\u2500 [  96]  refs
\u2502   \u2514\u2500\u2500 [  40]  main
\u2514\u2500\u2500 [ 128]  snapshots
\u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
\u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
\u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
\u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`),Nt=c(),U(we.$$.fragment),Ko=c(),X=a("div"),U(Re.$$.fragment),It=c(),no=a("p"),Pt=l("Download all files of a repo."),Lt=c(),so=a("p"),Rt=l(`Downloads a whole snapshot of a repo\u2019s files at the specified revision. This
is useful when you want all files from a repo, because you don\u2019t know which
ones you will need a priori. All files are nested inside a folder in order
to keep their actual filename relative to that folder.`),St=c(),lo=a("p"),qt=l(`An alternative would be to just clone a repo but this would require that the
user always has git and git-lfs installed, and properly configured.`),Ut=c(),U(ye.$$.fragment),Jo=c(),ne=a("div"),U(Se.$$.fragment),Ft=c(),ro=a("p"),Mt=l(`Download from a given URL and cache it if it\u2019s not already present in the
local cache.`),Ht=c(),io=a("p"),Bt=l(`Given a URL, this function looks for the corresponding file in the local
cache. If it\u2019s not there, download it. Then return the path to the cached
file.`),Vt=c(),U(Ee.$$.fragment),Qo=c(),q=a("div"),U(qe.$$.fragment),Wt=c(),co=a("p"),zt=l("Construct the URL of a file from the given information."),Gt=c(),ho=a("p"),Kt=l(`The resolved address can either be a huggingface.co-hosted url, or a link to
Cloudfront (a Content Delivery Network, or CDN) for large files which are
more than a few MBs.`),Jt=c(),U($e.$$.fragment),Qt=c(),U(xe.$$.fragment),Xt=c(),fo=a("p"),Yt=l("References:"),Zt=c(),po=a("ul"),Je=a("li"),ea=l("[1] "),Ue=a("a"),oa=l("https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),Xo=c(),ge=a("h2"),Te=a("a"),uo=a("span"),U(Fe.$$.fragment),ta=c(),mo=a("span"),aa=l("Caching"),Yo=c(),Qe=a("p"),na=l(`The methods displayed above are designed to work with a caching system that prevents re-downloading files.
The caching system was updated in v0.8.0 to allow directory structure and file sharing across
libraries that depend on the hub.`),Zo=c(),Xe=a("p"),sa=l("The caching system is designed as follows:"),et=c(),U(Me.$$.fragment),ot=c(),Ye=a("p"),la=l(`Models, datasets and spaces share a common root. Each of these repositories contains the namespace
(organization, username) if it exists, alongside the repository name:`),tt=c(),U(He.$$.fragment),at=c(),Ze=a("p"),ra=l(`It is within these folders that all files will now be downloaded from the hub. Caching ensures that
a file isn\u2019t downloaded twice if it already exists and wasn\u2019t updated; but if it was updated,
and you\u2019re asking for the latest file, then it will download the latest file (while keeping
the previous file intact in case you need it again).`),nt=c(),eo=a("p"),ia=l("In order to achieve this, all folders contain the same skeleton:"),st=c(),U(Be.$$.fragment),lt=c(),oo=a("p"),da=l("Each folder is designed to contain the following:"),rt=c(),_e=a("h3"),ke=a("a"),go=a("span"),U(Ve.$$.fragment),ca=c(),_o=a("span"),ha=l("Refs"),it=c(),te=a("p"),fa=l("The "),bo=a("code"),pa=l("refs"),ua=l(` folder contains files which indicates the latest revision of the given reference. For example,
if we have previously fetched a file from the `),vo=a("code"),ma=l("main"),ga=l(" branch of a repository, the "),wo=a("code"),_a=l("refs"),ba=l(`
folder will contain a file named `),yo=a("code"),va=l("main"),wa=l(", which will itself contain the commit identifier of the current head."),dt=c(),ce=a("p"),ya=l("If the latest commit of "),Eo=a("code"),Ea=l("main"),$a=l(" had "),$o=a("code"),xa=l("aaaaaa"),Ta=l(" as identifier, then it would contain "),xo=a("code"),ka=l("aaaaaa"),Da=l("."),ct=c(),he=a("p"),Oa=l("If that same branch gets updated with a new commit, that has "),To=a("code"),Ca=l("bbbbbb"),ja=l(` as an identifier, then
redownloading a file from that reference will update the `),ko=a("code"),Aa=l("refs/main"),Na=l(" file to contain "),Do=a("code"),Ia=l("bbbbbb"),Pa=l("."),ht=c(),be=a("h3"),De=a("a"),Oo=a("span"),U(We.$$.fragment),La=c(),Co=a("span"),Ra=l("Blobs"),ft=c(),Oe=a("p"),Sa=l("The "),jo=a("code"),qa=l("blobs"),Ua=l(" folder contains the actual files that we have downloaded. The name of each file is their hash."),pt=c(),ve=a("h3"),Ce=a("a"),Ao=a("span"),U(ze.$$.fragment),Fa=c(),No=a("span"),Ma=l("Snapshots"),ut=c(),je=a("p"),Ha=l("The "),Io=a("code"),Ba=l("snapshots"),Va=l(` folder contains symlinks to the blobs mentioned above. It is itself made up of several folders:
one per known revision!`),mt=c(),G=a("p"),Wa=l("In the explanation above, we had initially fetched a file from the "),Po=a("code"),za=l("aaaaaa"),Ga=l(` revision, before fetching a file from
the `),Lo=a("code"),Ka=l("bbbbbb"),Ja=l(" revision. In this situation, we would now have two folders in the "),Ro=a("code"),Qa=l("snapshots"),Xa=l(" folder: "),So=a("code"),Ya=l("aaaaaa"),Za=l(`
and `),qo=a("code"),en=l("bbbbbb"),on=l("."),gt=c(),pe=a("p"),tn=l(`In each of these folders, live symlinks that have the names of the files that we have downloaded. For example,
if we had downloaded the `),Uo=a("code"),an=l("READMD.md"),nn=l(" file at revision "),Fo=a("code"),sn=l("aaaaaa"),ln=l(", we would have the following path:"),_t=c(),U(Ge.$$.fragment),bt=c(),Ae=a("p"),rn=l("That "),Mo=a("code"),dn=l("README.md"),cn=l(" file is actually a symlink linking to the blob that has the hash of the file."),vt=c(),Ne=a("p"),hn=l(`Creating the skeleton this way means opens up the mechanism to file sharing: if the same file was fetched in
revision `),Ho=a("code"),fn=l("bbbbbb"),pn=l(", it would have the same hash and the file would not need to be redownloaded."),this.h()},l(o){const i=ys('[data-svelte="svelte-1phssyn"]',document.head);g=n(i,"META",{name:!0,content:!0}),i.forEach(t),j=h(o),w=n(o,"H1",{class:!0});var Ke=s(w);f=n(Ke,"A",{id:!0,class:!0,href:!0});var Bo=s(f);_=n(Bo,"SPAN",{});var Vo=s(_);F(p.$$.fragment,Vo),Vo.forEach(t),Bo.forEach(t),v=h(Ke),A=n(Ke,"SPAN",{});var Wo=s(A);P=r(Wo,"Downloading files"),Wo.forEach(t),Ke.forEach(t),$=h(o),y=n(o,"DIV",{class:!0});var Y=s(y);F(C.$$.fragment,Y),S=h(Y),T=n(Y,"P",{});var gn=s(T);u=r(gn,"Download a given file if it\u2019s not already present in the local cache."),gn.forEach(t),E=h(Y),L=n(Y,"P",{});var _n=s(L);W=r(_n,"The new cache file layout looks like this:"),_n.forEach(t),R=h(Y),x=n(Y,"UL",{});var yt=s(x);D=n(yt,"LI",{});var bn=s(D);N=r(bn,"The cache directory contains one subfolder per repo_id (namespaced by repo type)"),bn.forEach(t),K=h(yt),z=n(yt,"LI",{});var un=s(z);b=r(un,"inside each repo folder:"),k=n(un,"UL",{});var to=s(k);O=n(to,"LI",{});var vn=s(O);I=r(vn,"refs is a list of the latest known revision => commit_hash pairs"),vn.forEach(t),le=h(to),Z=n(to,"LI",{});var wn=s(Z);re=r(wn,`blobs contains the actual file blobs (identified by their git-sha or sha256, depending on
whether they\u2019re LFS files or not)`),wn.forEach(t),J=h(to),ee=n(to,"LI",{});var yn=s(ee);ie=r(yn,`snapshots contains one subfolder per commit, each \u201Ccommit\u201D contains the subset of the files
that have been resolved at that particular commit. Each filename is a symlink to the blob
at that particular commit.`),yn.forEach(t),to.forEach(t),un.forEach(t),yt.forEach(t),Q=h(Y),oe=n(Y,"P",{});var En=s(oe);de=r(En,`[  96]  .
\u2514\u2500\u2500 [ 160]  models\u2014julien-c\u2014EsperBERTo-small
\u251C\u2500\u2500 [ 160]  blobs
\u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
\u251C\u2500\u2500 [  96]  refs
\u2502   \u2514\u2500\u2500 [  40]  main
\u2514\u2500\u2500 [ 128]  snapshots
\u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
\u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
\u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
\u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`),En.forEach(t),Nt=h(Y),F(we.$$.fragment,Y),Y.forEach(t),Ko=h(o),X=n(o,"DIV",{class:!0});var ue=s(X);F(Re.$$.fragment,ue),It=h(ue),no=n(ue,"P",{});var $n=s(no);Pt=r($n,"Download all files of a repo."),$n.forEach(t),Lt=h(ue),so=n(ue,"P",{});var xn=s(so);Rt=r(xn,`Downloads a whole snapshot of a repo\u2019s files at the specified revision. This
is useful when you want all files from a repo, because you don\u2019t know which
ones you will need a priori. All files are nested inside a folder in order
to keep their actual filename relative to that folder.`),xn.forEach(t),St=h(ue),lo=n(ue,"P",{});var Tn=s(lo);qt=r(Tn,`An alternative would be to just clone a repo but this would require that the
user always has git and git-lfs installed, and properly configured.`),Tn.forEach(t),Ut=h(ue),F(ye.$$.fragment,ue),ue.forEach(t),Jo=h(o),ne=n(o,"DIV",{class:!0});var Ie=s(ne);F(Se.$$.fragment,Ie),Ft=h(Ie),ro=n(Ie,"P",{});var kn=s(ro);Mt=r(kn,`Download from a given URL and cache it if it\u2019s not already present in the
local cache.`),kn.forEach(t),Ht=h(Ie),io=n(Ie,"P",{});var Dn=s(io);Bt=r(Dn,`Given a URL, this function looks for the corresponding file in the local
cache. If it\u2019s not there, download it. Then return the path to the cached
file.`),Dn.forEach(t),Vt=h(Ie),F(Ee.$$.fragment,Ie),Ie.forEach(t),Qo=h(o),q=n(o,"DIV",{class:!0});var ae=s(q);F(qe.$$.fragment,ae),Wt=h(ae),co=n(ae,"P",{});var On=s(co);zt=r(On,"Construct the URL of a file from the given information."),On.forEach(t),Gt=h(ae),ho=n(ae,"P",{});var Cn=s(ho);Kt=r(Cn,`The resolved address can either be a huggingface.co-hosted url, or a link to
Cloudfront (a Content Delivery Network, or CDN) for large files which are
more than a few MBs.`),Cn.forEach(t),Jt=h(ae),F($e.$$.fragment,ae),Qt=h(ae),F(xe.$$.fragment,ae),Xt=h(ae),fo=n(ae,"P",{});var jn=s(fo);Yt=r(jn,"References:"),jn.forEach(t),Zt=h(ae),po=n(ae,"UL",{});var An=s(po);Je=n(An,"LI",{});var mn=s(Je);ea=r(mn,"[1] "),Ue=n(mn,"A",{href:!0,rel:!0});var Nn=s(Ue);oa=r(Nn,"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),Nn.forEach(t),mn.forEach(t),An.forEach(t),ae.forEach(t),Xo=h(o),ge=n(o,"H2",{class:!0});var Et=s(ge);Te=n(Et,"A",{id:!0,class:!0,href:!0});var In=s(Te);uo=n(In,"SPAN",{});var Pn=s(uo);F(Fe.$$.fragment,Pn),Pn.forEach(t),In.forEach(t),ta=h(Et),mo=n(Et,"SPAN",{});var Ln=s(mo);aa=r(Ln,"Caching"),Ln.forEach(t),Et.forEach(t),Yo=h(o),Qe=n(o,"P",{});var Rn=s(Qe);na=r(Rn,`The methods displayed above are designed to work with a caching system that prevents re-downloading files.
The caching system was updated in v0.8.0 to allow directory structure and file sharing across
libraries that depend on the hub.`),Rn.forEach(t),Zo=h(o),Xe=n(o,"P",{});var Sn=s(Xe);sa=r(Sn,"The caching system is designed as follows:"),Sn.forEach(t),et=h(o),F(Me.$$.fragment,o),ot=h(o),Ye=n(o,"P",{});var qn=s(Ye);la=r(qn,`Models, datasets and spaces share a common root. Each of these repositories contains the namespace
(organization, username) if it exists, alongside the repository name:`),qn.forEach(t),tt=h(o),F(He.$$.fragment,o),at=h(o),Ze=n(o,"P",{});var Un=s(Ze);ra=r(Un,`It is within these folders that all files will now be downloaded from the hub. Caching ensures that
a file isn\u2019t downloaded twice if it already exists and wasn\u2019t updated; but if it was updated,
and you\u2019re asking for the latest file, then it will download the latest file (while keeping
the previous file intact in case you need it again).`),Un.forEach(t),nt=h(o),eo=n(o,"P",{});var Fn=s(eo);ia=r(Fn,"In order to achieve this, all folders contain the same skeleton:"),Fn.forEach(t),st=h(o),F(Be.$$.fragment,o),lt=h(o),oo=n(o,"P",{});var Mn=s(oo);da=r(Mn,"Each folder is designed to contain the following:"),Mn.forEach(t),rt=h(o),_e=n(o,"H3",{class:!0});var $t=s(_e);ke=n($t,"A",{id:!0,class:!0,href:!0});var Hn=s(ke);go=n(Hn,"SPAN",{});var Bn=s(go);F(Ve.$$.fragment,Bn),Bn.forEach(t),Hn.forEach(t),ca=h($t),_o=n($t,"SPAN",{});var Vn=s(_o);ha=r(Vn,"Refs"),Vn.forEach(t),$t.forEach(t),it=h(o),te=n(o,"P",{});var me=s(te);fa=r(me,"The "),bo=n(me,"CODE",{});var Wn=s(bo);pa=r(Wn,"refs"),Wn.forEach(t),ua=r(me,` folder contains files which indicates the latest revision of the given reference. For example,
if we have previously fetched a file from the `),vo=n(me,"CODE",{});var zn=s(vo);ma=r(zn,"main"),zn.forEach(t),ga=r(me," branch of a repository, the "),wo=n(me,"CODE",{});var Gn=s(wo);_a=r(Gn,"refs"),Gn.forEach(t),ba=r(me,`
folder will contain a file named `),yo=n(me,"CODE",{});var Kn=s(yo);va=r(Kn,"main"),Kn.forEach(t),wa=r(me,", which will itself contain the commit identifier of the current head."),me.forEach(t),dt=h(o),ce=n(o,"P",{});var Pe=s(ce);ya=r(Pe,"If the latest commit of "),Eo=n(Pe,"CODE",{});var Jn=s(Eo);Ea=r(Jn,"main"),Jn.forEach(t),$a=r(Pe," had "),$o=n(Pe,"CODE",{});var Qn=s($o);xa=r(Qn,"aaaaaa"),Qn.forEach(t),Ta=r(Pe," as identifier, then it would contain "),xo=n(Pe,"CODE",{});var Xn=s(xo);ka=r(Xn,"aaaaaa"),Xn.forEach(t),Da=r(Pe,"."),Pe.forEach(t),ct=h(o),he=n(o,"P",{});var Le=s(he);Oa=r(Le,"If that same branch gets updated with a new commit, that has "),To=n(Le,"CODE",{});var Yn=s(To);Ca=r(Yn,"bbbbbb"),Yn.forEach(t),ja=r(Le,` as an identifier, then
redownloading a file from that reference will update the `),ko=n(Le,"CODE",{});var Zn=s(ko);Aa=r(Zn,"refs/main"),Zn.forEach(t),Na=r(Le," file to contain "),Do=n(Le,"CODE",{});var es=s(Do);Ia=r(es,"bbbbbb"),es.forEach(t),Pa=r(Le,"."),Le.forEach(t),ht=h(o),be=n(o,"H3",{class:!0});var xt=s(be);De=n(xt,"A",{id:!0,class:!0,href:!0});var os=s(De);Oo=n(os,"SPAN",{});var ts=s(Oo);F(We.$$.fragment,ts),ts.forEach(t),os.forEach(t),La=h(xt),Co=n(xt,"SPAN",{});var as=s(Co);Ra=r(as,"Blobs"),as.forEach(t),xt.forEach(t),ft=h(o),Oe=n(o,"P",{});var Tt=s(Oe);Sa=r(Tt,"The "),jo=n(Tt,"CODE",{});var ns=s(jo);qa=r(ns,"blobs"),ns.forEach(t),Ua=r(Tt," folder contains the actual files that we have downloaded. The name of each file is their hash."),Tt.forEach(t),pt=h(o),ve=n(o,"H3",{class:!0});var kt=s(ve);Ce=n(kt,"A",{id:!0,class:!0,href:!0});var ss=s(Ce);Ao=n(ss,"SPAN",{});var ls=s(Ao);F(ze.$$.fragment,ls),ls.forEach(t),ss.forEach(t),Fa=h(kt),No=n(kt,"SPAN",{});var rs=s(No);Ma=r(rs,"Snapshots"),rs.forEach(t),kt.forEach(t),ut=h(o),je=n(o,"P",{});var Dt=s(je);Ha=r(Dt,"The "),Io=n(Dt,"CODE",{});var is=s(Io);Ba=r(is,"snapshots"),is.forEach(t),Va=r(Dt,` folder contains symlinks to the blobs mentioned above. It is itself made up of several folders:
one per known revision!`),Dt.forEach(t),mt=h(o),G=n(o,"P",{});var fe=s(G);Wa=r(fe,"In the explanation above, we had initially fetched a file from the "),Po=n(fe,"CODE",{});var ds=s(Po);za=r(ds,"aaaaaa"),ds.forEach(t),Ga=r(fe,` revision, before fetching a file from
the `),Lo=n(fe,"CODE",{});var cs=s(Lo);Ka=r(cs,"bbbbbb"),cs.forEach(t),Ja=r(fe," revision. In this situation, we would now have two folders in the "),Ro=n(fe,"CODE",{});var hs=s(Ro);Qa=r(hs,"snapshots"),hs.forEach(t),Xa=r(fe," folder: "),So=n(fe,"CODE",{});var fs=s(So);Ya=r(fs,"aaaaaa"),fs.forEach(t),Za=r(fe,`
and `),qo=n(fe,"CODE",{});var ps=s(qo);en=r(ps,"bbbbbb"),ps.forEach(t),on=r(fe,"."),fe.forEach(t),gt=h(o),pe=n(o,"P",{});var ao=s(pe);tn=r(ao,`In each of these folders, live symlinks that have the names of the files that we have downloaded. For example,
if we had downloaded the `),Uo=n(ao,"CODE",{});var us=s(Uo);an=r(us,"READMD.md"),us.forEach(t),nn=r(ao," file at revision "),Fo=n(ao,"CODE",{});var ms=s(Fo);sn=r(ms,"aaaaaa"),ms.forEach(t),ln=r(ao,", we would have the following path:"),ao.forEach(t),_t=h(o),F(Ge.$$.fragment,o),bt=h(o),Ae=n(o,"P",{});var Ot=s(Ae);rn=r(Ot,"That "),Mo=n(Ot,"CODE",{});var gs=s(Mo);dn=r(gs,"README.md"),gs.forEach(t),cn=r(Ot," file is actually a symlink linking to the blob that has the hash of the file."),Ot.forEach(t),vt=h(o),Ne=n(o,"P",{});var Ct=s(Ne);hn=r(Ct,`Creating the skeleton this way means opens up the mechanism to file sharing: if the same file was fetched in
revision `),Ho=n(Ct,"CODE",{});var _s=s(Ho);fn=r(_s,"bbbbbb"),_s.forEach(t),pn=r(Ct,", it would have the same hash and the file would not need to be redownloaded."),Ct.forEach(t),this.h()},h(){m(g,"name","hf:doc:metadata"),m(g,"content",JSON.stringify(As)),m(f,"id","huggingface_hub.hf_hub_download"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#huggingface_hub.hf_hub_download"),m(w,"class","relative group"),m(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ue,"href","https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),m(Ue,"rel","nofollow"),m(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Te,"id","caching"),m(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Te,"href","#caching"),m(ge,"class","relative group"),m(ke,"id","refs"),m(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ke,"href","#refs"),m(_e,"class","relative group"),m(De,"id","blobs"),m(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(De,"href","#blobs"),m(be,"class","relative group"),m(Ce,"id","snapshots"),m(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ce,"href","#snapshots"),m(ve,"class","relative group")},m(o,i){e(document.head,g),d(o,j,i),d(o,w,i),e(w,f),e(f,_),M(p,_,null),e(w,v),e(w,A),e(A,P),d(o,$,i),d(o,y,i),M(C,y,null),e(y,S),e(y,T),e(T,u),e(y,E),e(y,L),e(L,W),e(y,R),e(y,x),e(x,D),e(D,N),e(x,K),e(x,z),e(z,b),e(z,k),e(k,O),e(O,I),e(k,le),e(k,Z),e(Z,re),e(k,J),e(k,ee),e(ee,ie),e(y,Q),e(y,oe),e(oe,de),e(y,Nt),M(we,y,null),d(o,Ko,i),d(o,X,i),M(Re,X,null),e(X,It),e(X,no),e(no,Pt),e(X,Lt),e(X,so),e(so,Rt),e(X,St),e(X,lo),e(lo,qt),e(X,Ut),M(ye,X,null),d(o,Jo,i),d(o,ne,i),M(Se,ne,null),e(ne,Ft),e(ne,ro),e(ro,Mt),e(ne,Ht),e(ne,io),e(io,Bt),e(ne,Vt),M(Ee,ne,null),d(o,Qo,i),d(o,q,i),M(qe,q,null),e(q,Wt),e(q,co),e(co,zt),e(q,Gt),e(q,ho),e(ho,Kt),e(q,Jt),M($e,q,null),e(q,Qt),M(xe,q,null),e(q,Xt),e(q,fo),e(fo,Yt),e(q,Zt),e(q,po),e(po,Je),e(Je,ea),e(Je,Ue),e(Ue,oa),d(o,Xo,i),d(o,ge,i),e(ge,Te),e(Te,uo),M(Fe,uo,null),e(ge,ta),e(ge,mo),e(mo,aa),d(o,Yo,i),d(o,Qe,i),e(Qe,na),d(o,Zo,i),d(o,Xe,i),e(Xe,sa),d(o,et,i),M(Me,o,i),d(o,ot,i),d(o,Ye,i),e(Ye,la),d(o,tt,i),M(He,o,i),d(o,at,i),d(o,Ze,i),e(Ze,ra),d(o,nt,i),d(o,eo,i),e(eo,ia),d(o,st,i),M(Be,o,i),d(o,lt,i),d(o,oo,i),e(oo,da),d(o,rt,i),d(o,_e,i),e(_e,ke),e(ke,go),M(Ve,go,null),e(_e,ca),e(_e,_o),e(_o,ha),d(o,it,i),d(o,te,i),e(te,fa),e(te,bo),e(bo,pa),e(te,ua),e(te,vo),e(vo,ma),e(te,ga),e(te,wo),e(wo,_a),e(te,ba),e(te,yo),e(yo,va),e(te,wa),d(o,dt,i),d(o,ce,i),e(ce,ya),e(ce,Eo),e(Eo,Ea),e(ce,$a),e(ce,$o),e($o,xa),e(ce,Ta),e(ce,xo),e(xo,ka),e(ce,Da),d(o,ct,i),d(o,he,i),e(he,Oa),e(he,To),e(To,Ca),e(he,ja),e(he,ko),e(ko,Aa),e(he,Na),e(he,Do),e(Do,Ia),e(he,Pa),d(o,ht,i),d(o,be,i),e(be,De),e(De,Oo),M(We,Oo,null),e(be,La),e(be,Co),e(Co,Ra),d(o,ft,i),d(o,Oe,i),e(Oe,Sa),e(Oe,jo),e(jo,qa),e(Oe,Ua),d(o,pt,i),d(o,ve,i),e(ve,Ce),e(Ce,Ao),M(ze,Ao,null),e(ve,Fa),e(ve,No),e(No,Ma),d(o,ut,i),d(o,je,i),e(je,Ha),e(je,Io),e(Io,Ba),e(je,Va),d(o,mt,i),d(o,G,i),e(G,Wa),e(G,Po),e(Po,za),e(G,Ga),e(G,Lo),e(Lo,Ka),e(G,Ja),e(G,Ro),e(Ro,Qa),e(G,Xa),e(G,So),e(So,Ya),e(G,Za),e(G,qo),e(qo,en),e(G,on),d(o,gt,i),d(o,pe,i),e(pe,tn),e(pe,Uo),e(Uo,an),e(pe,nn),e(pe,Fo),e(Fo,sn),e(pe,ln),d(o,_t,i),M(Ge,o,i),d(o,bt,i),d(o,Ae,i),e(Ae,rn),e(Ae,Mo),e(Mo,dn),e(Ae,cn),d(o,vt,i),d(o,Ne,i),e(Ne,hn),e(Ne,Ho),e(Ho,fn),e(Ne,pn),wt=!0},p(o,[i]){const Ke={};i&2&&(Ke.$$scope={dirty:i,ctx:o}),we.$set(Ke);const Bo={};i&2&&(Bo.$$scope={dirty:i,ctx:o}),ye.$set(Bo);const Vo={};i&2&&(Vo.$$scope={dirty:i,ctx:o}),Ee.$set(Vo);const Wo={};i&2&&(Wo.$$scope={dirty:i,ctx:o}),$e.$set(Wo);const Y={};i&2&&(Y.$$scope={dirty:i,ctx:o}),xe.$set(Y)},i(o){wt||(H(p.$$.fragment,o),H(C.$$.fragment,o),H(we.$$.fragment,o),H(Re.$$.fragment,o),H(ye.$$.fragment,o),H(Se.$$.fragment,o),H(Ee.$$.fragment,o),H(qe.$$.fragment,o),H($e.$$.fragment,o),H(xe.$$.fragment,o),H(Fe.$$.fragment,o),H(Me.$$.fragment,o),H(He.$$.fragment,o),H(Be.$$.fragment,o),H(Ve.$$.fragment,o),H(We.$$.fragment,o),H(ze.$$.fragment,o),H(Ge.$$.fragment,o),wt=!0)},o(o){B(p.$$.fragment,o),B(C.$$.fragment,o),B(we.$$.fragment,o),B(Re.$$.fragment,o),B(ye.$$.fragment,o),B(Se.$$.fragment,o),B(Ee.$$.fragment,o),B(qe.$$.fragment,o),B($e.$$.fragment,o),B(xe.$$.fragment,o),B(Fe.$$.fragment,o),B(Me.$$.fragment,o),B(He.$$.fragment,o),B(Be.$$.fragment,o),B(Ve.$$.fragment,o),B(We.$$.fragment,o),B(ze.$$.fragment,o),B(Ge.$$.fragment,o),wt=!1},d(o){t(g),o&&t(j),o&&t(w),V(p),o&&t($),o&&t(y),V(C),V(we),o&&t(Ko),o&&t(X),V(Re),V(ye),o&&t(Jo),o&&t(ne),V(Se),V(Ee),o&&t(Qo),o&&t(q),V(qe),V($e),V(xe),o&&t(Xo),o&&t(ge),V(Fe),o&&t(Yo),o&&t(Qe),o&&t(Zo),o&&t(Xe),o&&t(et),V(Me,o),o&&t(ot),o&&t(Ye),o&&t(tt),V(He,o),o&&t(at),o&&t(Ze),o&&t(nt),o&&t(eo),o&&t(st),V(Be,o),o&&t(lt),o&&t(oo),o&&t(rt),o&&t(_e),V(Ve),o&&t(it),o&&t(te),o&&t(dt),o&&t(ce),o&&t(ct),o&&t(he),o&&t(ht),o&&t(be),V(We),o&&t(ft),o&&t(Oe),o&&t(pt),o&&t(ve),V(ze),o&&t(ut),o&&t(je),o&&t(mt),o&&t(G),o&&t(gt),o&&t(pe),o&&t(_t),V(Ge,o),o&&t(bt),o&&t(Ae),o&&t(vt),o&&t(Ne)}}}const As={local:"huggingface_hub.hf_hub_download",sections:[{local:"caching",sections:[{local:"refs",title:"Refs"},{local:"blobs",title:"Blobs"},{local:"snapshots",title:"Snapshots"}],title:"Caching"}],title:"Downloading files"};function Ns(se){return Es(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Us extends bs{constructor(g){super();vs(this,g,Ns,js,ws,{})}}export{Us as default,As as metadata};
