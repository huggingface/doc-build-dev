import{S as Zs,i as er,s as lr,e as a,k as d,w as c,t as n,M as tr,c as o,d as t,m as u,a as i,x as f,h as s,b as p,G as l,g as m,y as g,L as ar,q as h,o as _,B as v,v as or}from"../chunks/vendor-hf-doc-builder.js";import{I as se}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as x}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as ir}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";function nr(xn){let q,ct,I,S,dl,re,ja,ul,qa,ft,me,gt,y,Ia,pl,Ca,Pa,de,Ta,Da,ht,C,B,cl,ue,Aa,fl,Oa,_t,qe,Xa,vt,P,R,gl,pe,Sa,hl,Ba,bt,Ie,Ra,kt,b,Ce,_l,Na,Fa,Ha,Pe,vl,Qa,Wa,Ga,Te,bl,Ua,Ja,Ka,De,kl,Va,Ya,Za,Ae,El,eo,lo,to,Oe,zl,ao,oo,io,Xe,$l,no,so,Et,z,ro,Ml,mo,uo,wl,po,co,xl,fo,go,zt,N,ho,yl,_o,vo,$t,ce,Mt,F,bo,Ll,ko,Eo,wt,fe,xt,Se,zo,yt,ge,Lt,$,$o,jl,Mo,wo,ql,xo,yo,Il,Lo,jo,jt,he,qt,H,qo,Cl,Io,Co,It,_e,Ct,L,Po,ve,To,Do,Pl,Ao,Oo,Pt,T,Q,Tl,be,Xo,Dl,So,Tt,Be,Bo,Dt,W,Re,Al,Ro,No,Fo,Ne,Ol,Ho,Qo,At,Fe,Wo,Ot,D,G,Xl,ke,Go,Sl,Uo,Xt,He,Jo,St,U,Qe,Bl,Ko,Vo,Yo,We,Rl,Zo,ei,Bt,Ge,li,Rt,A,J,Nl,Ee,ti,Fl,ai,Nt,Ue,oi,Ft,K,Je,Hl,ii,ni,si,Ke,Ql,ri,mi,Ht,Ve,di,Qt,O,V,Wl,ze,ui,Gl,pi,Wt,Ye,ci,Gt,Y,Ze,Ul,fi,gi,hi,el,Jl,_i,vi,Ut,Z,bi,Kl,ki,Ei,Jt,$e,Kt,ll,zi,Vt,Me,Yt,M,$i,Vl,Mi,wi,Yl,xi,yi,Zl,Li,ji,Zt,we,ea,X,ee,et,xe,qi,lt,Ii,la,tl,Ci,ta,k,al,tt,Pi,Ti,Di,ol,at,Ai,Oi,Xi,il,ot,Si,Bi,Ri,nl,it,Ni,Fi,Hi,nt,st,Qi,aa,le,Wi,rt,Gi,Ui,oa,ye,ia,sl,Ji,na,Le,sa,w,Ki,mt,Vi,Yi,dt,Zi,en,ut,ln,tn,ra,je,ma,te,an,pt,on,nn,da;return re=new se({}),me=new ir({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/multilingual.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/multilingual.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/multilingual.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/multilingual.ipynb"}]}}),ue=new se({}),pe=new se({}),ce=new x({props:{code:`import torch
from transformers import XLMTokenizer, XLMWithLMHeadModel

tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMTokenizer, XLMWithLMHeadModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMTokenizer.from_pretrained(<span class="hljs-string">&quot;xlm-clm-enfr-1024&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMWithLMHeadModel.from_pretrained(<span class="hljs-string">&quot;xlm-clm-enfr-1024&quot;</span>)`}}),fe=new x({props:{code:"print(tokenizer.lang2id)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer.lang2id)
{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-number">1</span>}`}}),ge=new x({props:{code:'input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # batch size of 1',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([tokenizer.encode(<span class="hljs-string">&quot;Wikipedia was used to&quot;</span>)])  <span class="hljs-comment"># batch size of 1</span>'}}),he=new x({props:{code:`language_id = tokenizer.lang2id["en"]  # 0
langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])

# We reshape it to be of size (batch_size, sequence_length)
langs = langs.view(1, -1)  # is now of shape [1, sequence_length] (we have a batch size of 1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>language_id = tokenizer.lang2id[<span class="hljs-string">&quot;en&quot;</span>]  <span class="hljs-comment"># 0</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = torch.tensor([language_id] * input_ids.shape[<span class="hljs-number">1</span>])  <span class="hljs-comment"># torch.tensor([0, 0, 0, ..., 0])</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># We reshape it to be of size (batch_size, sequence_length)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = langs.view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># is now of shape [1, sequence_length] (we have a batch size of 1)</span>`}}),_e=new x({props:{code:"outputs = model(input_ids, langs=langs)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids, langs=langs)'}}),be=new se({}),ke=new se({}),Ee=new se({}),ze=new se({}),$e=new x({props:{code:`from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
chinese_text = "\u4E0D\u8981\u63D2\u624B\u5DEB\u5E2B\u7684\u4E8B\u52D9, \u56E0\u70BA\u4ED6\u5011\u662F\u5FAE\u5999\u7684, \u5F88\u5FEB\u5C31\u6703\u767C\u6012."

tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M", src_lang="zh")
model = M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> M2M100ForConditionalGeneration, M2M100Tokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>chinese_text = <span class="hljs-string">&quot;\u4E0D\u8981\u63D2\u624B\u5DEB\u5E2B\u7684\u4E8B\u52D9, \u56E0\u70BA\u4ED6\u5011\u662F\u5FAE\u5999\u7684, \u5F88\u5FEB\u5C31\u6703\u767C\u6012.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = M2M100Tokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>, src_lang=<span class="hljs-string">&quot;zh&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = M2M100ForConditionalGeneration.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>)`}}),Me=new x({props:{code:'encoded_zh = tokenizer(chinese_text, return_tensors="pt")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_zh = tokenizer(chinese_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)'}}),we=new x({props:{code:`generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id("en"))
tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(<span class="hljs-string">&quot;en&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&#x27;Do not interfere with the matters of the witches, because they are delicate and will soon be angry.&#x27;</span>`}}),xe=new se({}),ye=new x({props:{code:`from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
fi_text = "\xC4l\xE4 sekaannu velhojen asioihin, sill\xE4 ne ovat hienovaraisia ja nopeasti vihaisia."

tokenizer = AutoTokenizer.from_pretrained("facebook/mbart-large-50-many-to-many-mmt", src_lang="fi_FI")
model = AutoModelForSeq2SeqLM.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>fi_text = <span class="hljs-string">&quot;\xC4l\xE4 sekaannu velhojen asioihin, sill\xE4 ne ovat hienovaraisia ja nopeasti vihaisia.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>, src_lang=<span class="hljs-string">&quot;fi_FI&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>)`}}),Le=new x({props:{code:'encoded_en = tokenizer(en_text, return_tensors="pt")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_en = tokenizer(en_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)'}}),je=new x({props:{code:`generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id("en_XX"))
tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id(<span class="hljs-string">&quot;en_XX&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&quot;Don&#x27;t interfere with the wizard&#x27;s affairs, because they are subtle, will soon get angry.&quot;</span>`}}),{c(){q=a("meta"),ct=d(),I=a("h1"),S=a("a"),dl=a("span"),c(re.$$.fragment),ja=d(),ul=a("span"),qa=n("Modelli multilingue per l'inferenza"),ft=d(),c(me.$$.fragment),gt=d(),y=a("p"),Ia=n("Ci sono diversi modelli multilingue in \u{1F917} Transformers, e il loro utilizzo per l\u2019inferenza differisce da quello dei modelli monolingua. Non "),pl=a("em"),Ca=n("tutti"),Pa=n(" gli utilizzi dei modelli multilingue sono per\xF2 diversi. Alcuni modelli, come "),de=a("a"),Ta=n("bert-base-multilingual-uncased"),Da=n(", possono essere usati come un modello monolingua. Questa guida ti mostrer\xE0 come utilizzare modelli multilingue che utilizzano un modo diverso per fare l\u2019inferenza."),ht=d(),C=a("h2"),B=a("a"),cl=a("span"),c(ue.$$.fragment),Aa=d(),fl=a("span"),Oa=n("XLM"),_t=d(),qe=a("p"),Xa=n("XLM ha dieci diversi checkpoint, di cui solo uno \xE8 monolingua. I nove checkpoint rimanenti possono essere suddivisi in due categorie: i checkpoint che utilizzano i language embeddings e quelli che non li utilizzano."),vt=d(),P=a("h3"),R=a("a"),gl=a("span"),c(pe.$$.fragment),Sa=d(),hl=a("span"),Ba=n("XLM con language embeddings"),bt=d(),Ie=a("p"),Ra=n("I seguenti modelli XLM utilizzano gli embeddings linguistici per specificare la lingua utilizzata per l\u2019inferenza:"),kt=d(),b=a("ul"),Ce=a("li"),_l=a("code"),Na=n("xlm-mlm-ende-1024"),Fa=n(" (Masked language modeling, Inglese-Tedesco)"),Ha=d(),Pe=a("li"),vl=a("code"),Qa=n("xlm-mlm-enfr-1024"),Wa=n(" (Masked language modeling, Inglese-Francese)"),Ga=d(),Te=a("li"),bl=a("code"),Ua=n("xlm-mlm-enro-1024"),Ja=n(" (Masked language modeling, Inglese-Rumeno)"),Ka=d(),De=a("li"),kl=a("code"),Va=n("xlm-mlm-xnli15-1024"),Ya=n(" (Masked language modeling, lingue XNLI)"),Za=d(),Ae=a("li"),El=a("code"),eo=n("xlm-mlm-tlm-xnli15-1024"),lo=n(" (Masked language modeling + traduzione, lingue XNLI)"),to=d(),Oe=a("li"),zl=a("code"),ao=n("xlm-clm-enfr-1024"),oo=n(" (Causal language modeling, Inglese-Francese)"),io=d(),Xe=a("li"),$l=a("code"),no=n("xlm-clm-ende-1024"),so=n(" (Causal language modeling, Inglese-Tedesco)"),Et=d(),z=a("p"),ro=n("Gli embeddings linguistici sono rappresentati come un tensore delle stesse dimensioni dell\u2019 "),Ml=a("code"),mo=n("input_ids"),uo=n(" passato al modello. I valori in questi tensori dipendono dal linguaggio usato e sono identificati dagli attributi "),wl=a("code"),po=n("lang2id"),co=n(" e "),xl=a("code"),fo=n("id2lang"),go=n(" del tokenizer."),zt=d(),N=a("p"),ho=n("In questo esempio, carica il checkpoint "),yl=a("code"),_o=n("xlm-clm-enfr-1024"),vo=n(" (Causal language modeling, Inglese-Francese):"),$t=d(),c(ce.$$.fragment),Mt=d(),F=a("p"),bo=n("L\u2019attributo "),Ll=a("code"),ko=n("lang2id"),Eo=n(" del tokenizer mostra il linguaggio del modello e il suo ids:"),wt=d(),c(fe.$$.fragment),xt=d(),Se=a("p"),zo=n("Poi, crea un esempio di input:"),yt=d(),c(ge.$$.fragment),Lt=d(),$=a("p"),$o=n("Imposta l\u2019id del linguaggio a "),jl=a("code"),Mo=n('"en"'),wo=n(" e usalo per definire il language embedding. Il language embedding \xE8 un tensore riempito con "),ql=a("code"),xo=n("0"),yo=n(" perch\xE9 questo \xE8 il language id per l\u2019inglese. Questo tensore dovrebbe avere la stessa dimensione di "),Il=a("code"),Lo=n("input_ids"),jo=n("."),jt=d(),c(he.$$.fragment),qt=d(),H=a("p"),qo=n("Adesso puoi inserire "),Cl=a("code"),Io=n("input_ids"),Co=n(" e language embedding nel modello:"),It=d(),c(_e.$$.fragment),Ct=d(),L=a("p"),Po=n("Lo script "),ve=a("a"),To=n("run_generation.py"),Do=n(" pu\xF2 generare testo tramite i language embeddings usando i checkpoints "),Pl=a("code"),Ao=n("xlm-clm"),Oo=n("."),Pt=d(),T=a("h3"),Q=a("a"),Tl=a("span"),c(be.$$.fragment),Xo=d(),Dl=a("span"),So=n("XLM senza language embeddings"),Tt=d(),Be=a("p"),Bo=n("I seguenti modelli XLM non richiedono l\u2019utilizzo dei language embeddings per fare inferenza:"),Dt=d(),W=a("ul"),Re=a("li"),Al=a("code"),Ro=n("xlm-mlm-17-1280"),No=n(" (Masked language modeling, 17 lingue)"),Fo=d(),Ne=a("li"),Ol=a("code"),Ho=n("xlm-mlm-100-1280"),Qo=n(" (Masked language modeling, 100 lingue)"),At=d(),Fe=a("p"),Wo=n("Questi modelli sono utilizzati per rappresentazioni generiche di frasi, a differenza dei precedenti checkpoints XML."),Ot=d(),D=a("h2"),G=a("a"),Xl=a("span"),c(ke.$$.fragment),Go=d(),Sl=a("span"),Uo=n("BERT"),Xt=d(),He=a("p"),Jo=n("Il seguente modello BERT pu\xF2 essere usato per compiti multilingue:"),St=d(),U=a("ul"),Qe=a("li"),Bl=a("code"),Ko=n("bert-base-multilingual-uncased"),Vo=n(" (Masked language modeling + Previsione della prossima frase, 102 lingue)"),Yo=d(),We=a("li"),Rl=a("code"),Zo=n("bert-base-multilingual-cased"),ei=n(" (Masked language modeling + Previsione della prossima frase, 104 lingue)"),Bt=d(),Ge=a("p"),li=n("Questi modelli non richiedono language embeddings per fare inferenza. Riescono ad identificare il linguaggio dal contesto e inferire di conseguenza."),Rt=d(),A=a("h2"),J=a("a"),Nl=a("span"),c(Ee.$$.fragment),ti=d(),Fl=a("span"),ai=n("XLM-RoBERTa"),Nt=d(),Ue=a("p"),oi=n("Il seguente modello XLM-RoBERTa pu\xF2 essere usato per compiti multilingue:"),Ft=d(),K=a("ul"),Je=a("li"),Hl=a("code"),ii=n("xlm-roberta-base"),ni=n(" (Masked language modeling, 100 lingue)"),si=d(),Ke=a("li"),Ql=a("code"),ri=n("xlm-roberta-large"),mi=n(" (Masked language modeling, 100 lingue)"),Ht=d(),Ve=a("p"),di=n("XLM-RoBERTa \xE8 stato addestrato su 2.5TB di dati CommonCrawl appena creati e puliti in 100 lingue. Offre notevoli vantaggi rispetto ai modelli multilingue rilasciati in precedenza, come mBERT o XLM, in compiti come la classificazione, l\u2019etichettatura delle sequenze e la risposta alle domande."),Qt=d(),O=a("h2"),V=a("a"),Wl=a("span"),c(ze.$$.fragment),ui=d(),Gl=a("span"),pi=n("M2M100"),Wt=d(),Ye=a("p"),ci=n("Il seguente modello M2M100 pu\xF2 essere usato per compiti multilingue:"),Gt=d(),Y=a("ul"),Ze=a("li"),Ul=a("code"),fi=n("facebook/m2m100_418M"),gi=n(" (Traduzione)"),hi=d(),el=a("li"),Jl=a("code"),_i=n("facebook/m2m100_1.2B"),vi=n(" (Traduzione)"),Ut=d(),Z=a("p"),bi=n("In questo esempio, carica il checkpoint "),Kl=a("code"),ki=n("facebook/m2m100_418M"),Ei=n("  per tradurre dal cinese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),Jt=d(),c($e.$$.fragment),Kt=d(),ll=a("p"),zi=n("Applica il tokenizer al testo:"),Vt=d(),c(Me.$$.fragment),Yt=d(),M=a("p"),$i=n("M2M100 forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),Vl=a("code"),Mi=n("forced_bos_token_id"),wi=n(" a "),Yl=a("code"),xi=n("en"),yi=n(" nel metodo "),Zl=a("code"),Li=n("generate"),ji=n(" per tradurre in inglese:"),Zt=d(),c(we.$$.fragment),ea=d(),X=a("h2"),ee=a("a"),et=a("span"),c(xe.$$.fragment),qi=d(),lt=a("span"),Ii=n("MBart"),la=d(),tl=a("p"),Ci=n("Il seguente modello MBart pu\xF2 essere usato per compiti multilingue:"),ta=d(),k=a("ul"),al=a("li"),tt=a("code"),Pi=n("facebook/mbart-large-50-one-to-many-mmt"),Ti=n(" (Traduzione automatica multilingue uno-a-molti, 50 lingue)"),Di=d(),ol=a("li"),at=a("code"),Ai=n("facebook/mbart-large-50-many-to-many-mmt"),Oi=n(" (Traduzione automatica multilingue molti-a-molti, 50 lingue)"),Xi=d(),il=a("li"),ot=a("code"),Si=n("facebook/mbart-large-50-many-to-one-mmt"),Bi=n(" (Traduzione automatica multilingue molti-a-uno, 50 lingue)"),Ri=d(),nl=a("li"),it=a("code"),Ni=n("facebook/mbart-large-50"),Fi=n(" (Traduzione multilingue, 50 lingue)"),Hi=d(),nt=a("li"),st=a("code"),Qi=n("facebook/mbart-large-cc25"),aa=d(),le=a("p"),Wi=n("In questo esempio, carica il checkpoint "),rt=a("code"),Gi=n("facebook/mbart-large-50-many-to-many-mmt"),Ui=n(" per tradurre dal finlandese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),oa=d(),c(ye.$$.fragment),ia=d(),sl=a("p"),Ji=n("Applica il tokenizer sul testo:"),na=d(),c(Le.$$.fragment),sa=d(),w=a("p"),Ki=n("MBart forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),mt=a("code"),Vi=n("forced_bos_token_id"),Yi=n(" a "),dt=a("code"),Zi=n("en"),en=n(" nel metodo "),ut=a("code"),ln=n("generate"),tn=n(" per tradurre in inglese:"),ra=d(),c(je.$$.fragment),ma=d(),te=a("p"),an=n("Se stai usando il checkpoint "),pt=a("code"),on=n("facebook/mbart-large-50-many-to-one-mmt"),nn=n(", non hai bisogno di forzare l\u2019id della lingua obiettivo come primo token generato altrimenti l\u2019uso \xE8 lo stesso."),this.h()},l(e){const r=tr('[data-svelte="svelte-1phssyn"]',document.head);q=o(r,"META",{name:!0,content:!0}),r.forEach(t),ct=u(e),I=o(e,"H1",{class:!0});var ua=i(I);S=o(ua,"A",{id:!0,class:!0,href:!0});var yn=i(S);dl=o(yn,"SPAN",{});var Ln=i(dl);f(re.$$.fragment,Ln),Ln.forEach(t),yn.forEach(t),ja=u(ua),ul=o(ua,"SPAN",{});var jn=i(ul);qa=s(jn,"Modelli multilingue per l'inferenza"),jn.forEach(t),ua.forEach(t),ft=u(e),f(me.$$.fragment,e),gt=u(e),y=o(e,"P",{});var rl=i(y);Ia=s(rl,"Ci sono diversi modelli multilingue in \u{1F917} Transformers, e il loro utilizzo per l\u2019inferenza differisce da quello dei modelli monolingua. Non "),pl=o(rl,"EM",{});var qn=i(pl);Ca=s(qn,"tutti"),qn.forEach(t),Pa=s(rl," gli utilizzi dei modelli multilingue sono per\xF2 diversi. Alcuni modelli, come "),de=o(rl,"A",{href:!0,rel:!0});var In=i(de);Ta=s(In,"bert-base-multilingual-uncased"),In.forEach(t),Da=s(rl,", possono essere usati come un modello monolingua. Questa guida ti mostrer\xE0 come utilizzare modelli multilingue che utilizzano un modo diverso per fare l\u2019inferenza."),rl.forEach(t),ht=u(e),C=o(e,"H2",{class:!0});var pa=i(C);B=o(pa,"A",{id:!0,class:!0,href:!0});var Cn=i(B);cl=o(Cn,"SPAN",{});var Pn=i(cl);f(ue.$$.fragment,Pn),Pn.forEach(t),Cn.forEach(t),Aa=u(pa),fl=o(pa,"SPAN",{});var Tn=i(fl);Oa=s(Tn,"XLM"),Tn.forEach(t),pa.forEach(t),_t=u(e),qe=o(e,"P",{});var Dn=i(qe);Xa=s(Dn,"XLM ha dieci diversi checkpoint, di cui solo uno \xE8 monolingua. I nove checkpoint rimanenti possono essere suddivisi in due categorie: i checkpoint che utilizzano i language embeddings e quelli che non li utilizzano."),Dn.forEach(t),vt=u(e),P=o(e,"H3",{class:!0});var ca=i(P);R=o(ca,"A",{id:!0,class:!0,href:!0});var An=i(R);gl=o(An,"SPAN",{});var On=i(gl);f(pe.$$.fragment,On),On.forEach(t),An.forEach(t),Sa=u(ca),hl=o(ca,"SPAN",{});var Xn=i(hl);Ba=s(Xn,"XLM con language embeddings"),Xn.forEach(t),ca.forEach(t),bt=u(e),Ie=o(e,"P",{});var Sn=i(Ie);Ra=s(Sn,"I seguenti modelli XLM utilizzano gli embeddings linguistici per specificare la lingua utilizzata per l\u2019inferenza:"),Sn.forEach(t),kt=u(e),b=o(e,"UL",{});var E=i(b);Ce=o(E,"LI",{});var sn=i(Ce);_l=o(sn,"CODE",{});var Bn=i(_l);Na=s(Bn,"xlm-mlm-ende-1024"),Bn.forEach(t),Fa=s(sn," (Masked language modeling, Inglese-Tedesco)"),sn.forEach(t),Ha=u(E),Pe=o(E,"LI",{});var rn=i(Pe);vl=o(rn,"CODE",{});var Rn=i(vl);Qa=s(Rn,"xlm-mlm-enfr-1024"),Rn.forEach(t),Wa=s(rn," (Masked language modeling, Inglese-Francese)"),rn.forEach(t),Ga=u(E),Te=o(E,"LI",{});var mn=i(Te);bl=o(mn,"CODE",{});var Nn=i(bl);Ua=s(Nn,"xlm-mlm-enro-1024"),Nn.forEach(t),Ja=s(mn," (Masked language modeling, Inglese-Rumeno)"),mn.forEach(t),Ka=u(E),De=o(E,"LI",{});var dn=i(De);kl=o(dn,"CODE",{});var Fn=i(kl);Va=s(Fn,"xlm-mlm-xnli15-1024"),Fn.forEach(t),Ya=s(dn," (Masked language modeling, lingue XNLI)"),dn.forEach(t),Za=u(E),Ae=o(E,"LI",{});var un=i(Ae);El=o(un,"CODE",{});var Hn=i(El);eo=s(Hn,"xlm-mlm-tlm-xnli15-1024"),Hn.forEach(t),lo=s(un," (Masked language modeling + traduzione, lingue XNLI)"),un.forEach(t),to=u(E),Oe=o(E,"LI",{});var pn=i(Oe);zl=o(pn,"CODE",{});var Qn=i(zl);ao=s(Qn,"xlm-clm-enfr-1024"),Qn.forEach(t),oo=s(pn," (Causal language modeling, Inglese-Francese)"),pn.forEach(t),io=u(E),Xe=o(E,"LI",{});var cn=i(Xe);$l=o(cn,"CODE",{});var Wn=i($l);no=s(Wn,"xlm-clm-ende-1024"),Wn.forEach(t),so=s(cn," (Causal language modeling, Inglese-Tedesco)"),cn.forEach(t),E.forEach(t),Et=u(e),z=o(e,"P",{});var ae=i(z);ro=s(ae,"Gli embeddings linguistici sono rappresentati come un tensore delle stesse dimensioni dell\u2019 "),Ml=o(ae,"CODE",{});var Gn=i(Ml);mo=s(Gn,"input_ids"),Gn.forEach(t),uo=s(ae," passato al modello. I valori in questi tensori dipendono dal linguaggio usato e sono identificati dagli attributi "),wl=o(ae,"CODE",{});var Un=i(wl);po=s(Un,"lang2id"),Un.forEach(t),co=s(ae," e "),xl=o(ae,"CODE",{});var Jn=i(xl);fo=s(Jn,"id2lang"),Jn.forEach(t),go=s(ae," del tokenizer."),ae.forEach(t),zt=u(e),N=o(e,"P",{});var fa=i(N);ho=s(fa,"In questo esempio, carica il checkpoint "),yl=o(fa,"CODE",{});var Kn=i(yl);_o=s(Kn,"xlm-clm-enfr-1024"),Kn.forEach(t),vo=s(fa," (Causal language modeling, Inglese-Francese):"),fa.forEach(t),$t=u(e),f(ce.$$.fragment,e),Mt=u(e),F=o(e,"P",{});var ga=i(F);bo=s(ga,"L\u2019attributo "),Ll=o(ga,"CODE",{});var Vn=i(Ll);ko=s(Vn,"lang2id"),Vn.forEach(t),Eo=s(ga," del tokenizer mostra il linguaggio del modello e il suo ids:"),ga.forEach(t),wt=u(e),f(fe.$$.fragment,e),xt=u(e),Se=o(e,"P",{});var Yn=i(Se);zo=s(Yn,"Poi, crea un esempio di input:"),Yn.forEach(t),yt=u(e),f(ge.$$.fragment,e),Lt=u(e),$=o(e,"P",{});var oe=i($);$o=s(oe,"Imposta l\u2019id del linguaggio a "),jl=o(oe,"CODE",{});var Zn=i(jl);Mo=s(Zn,'"en"'),Zn.forEach(t),wo=s(oe," e usalo per definire il language embedding. Il language embedding \xE8 un tensore riempito con "),ql=o(oe,"CODE",{});var es=i(ql);xo=s(es,"0"),es.forEach(t),yo=s(oe," perch\xE9 questo \xE8 il language id per l\u2019inglese. Questo tensore dovrebbe avere la stessa dimensione di "),Il=o(oe,"CODE",{});var ls=i(Il);Lo=s(ls,"input_ids"),ls.forEach(t),jo=s(oe,"."),oe.forEach(t),jt=u(e),f(he.$$.fragment,e),qt=u(e),H=o(e,"P",{});var ha=i(H);qo=s(ha,"Adesso puoi inserire "),Cl=o(ha,"CODE",{});var ts=i(Cl);Io=s(ts,"input_ids"),ts.forEach(t),Co=s(ha," e language embedding nel modello:"),ha.forEach(t),It=u(e),f(_e.$$.fragment,e),Ct=u(e),L=o(e,"P",{});var ml=i(L);Po=s(ml,"Lo script "),ve=o(ml,"A",{href:!0,rel:!0});var as=i(ve);To=s(as,"run_generation.py"),as.forEach(t),Do=s(ml," pu\xF2 generare testo tramite i language embeddings usando i checkpoints "),Pl=o(ml,"CODE",{});var os=i(Pl);Ao=s(os,"xlm-clm"),os.forEach(t),Oo=s(ml,"."),ml.forEach(t),Pt=u(e),T=o(e,"H3",{class:!0});var _a=i(T);Q=o(_a,"A",{id:!0,class:!0,href:!0});var is=i(Q);Tl=o(is,"SPAN",{});var ns=i(Tl);f(be.$$.fragment,ns),ns.forEach(t),is.forEach(t),Xo=u(_a),Dl=o(_a,"SPAN",{});var ss=i(Dl);So=s(ss,"XLM senza language embeddings"),ss.forEach(t),_a.forEach(t),Tt=u(e),Be=o(e,"P",{});var rs=i(Be);Bo=s(rs,"I seguenti modelli XLM non richiedono l\u2019utilizzo dei language embeddings per fare inferenza:"),rs.forEach(t),Dt=u(e),W=o(e,"UL",{});var va=i(W);Re=o(va,"LI",{});var fn=i(Re);Al=o(fn,"CODE",{});var ms=i(Al);Ro=s(ms,"xlm-mlm-17-1280"),ms.forEach(t),No=s(fn," (Masked language modeling, 17 lingue)"),fn.forEach(t),Fo=u(va),Ne=o(va,"LI",{});var gn=i(Ne);Ol=o(gn,"CODE",{});var ds=i(Ol);Ho=s(ds,"xlm-mlm-100-1280"),ds.forEach(t),Qo=s(gn," (Masked language modeling, 100 lingue)"),gn.forEach(t),va.forEach(t),At=u(e),Fe=o(e,"P",{});var us=i(Fe);Wo=s(us,"Questi modelli sono utilizzati per rappresentazioni generiche di frasi, a differenza dei precedenti checkpoints XML."),us.forEach(t),Ot=u(e),D=o(e,"H2",{class:!0});var ba=i(D);G=o(ba,"A",{id:!0,class:!0,href:!0});var ps=i(G);Xl=o(ps,"SPAN",{});var cs=i(Xl);f(ke.$$.fragment,cs),cs.forEach(t),ps.forEach(t),Go=u(ba),Sl=o(ba,"SPAN",{});var fs=i(Sl);Uo=s(fs,"BERT"),fs.forEach(t),ba.forEach(t),Xt=u(e),He=o(e,"P",{});var gs=i(He);Jo=s(gs,"Il seguente modello BERT pu\xF2 essere usato per compiti multilingue:"),gs.forEach(t),St=u(e),U=o(e,"UL",{});var ka=i(U);Qe=o(ka,"LI",{});var hn=i(Qe);Bl=o(hn,"CODE",{});var hs=i(Bl);Ko=s(hs,"bert-base-multilingual-uncased"),hs.forEach(t),Vo=s(hn," (Masked language modeling + Previsione della prossima frase, 102 lingue)"),hn.forEach(t),Yo=u(ka),We=o(ka,"LI",{});var _n=i(We);Rl=o(_n,"CODE",{});var _s=i(Rl);Zo=s(_s,"bert-base-multilingual-cased"),_s.forEach(t),ei=s(_n," (Masked language modeling + Previsione della prossima frase, 104 lingue)"),_n.forEach(t),ka.forEach(t),Bt=u(e),Ge=o(e,"P",{});var vs=i(Ge);li=s(vs,"Questi modelli non richiedono language embeddings per fare inferenza. Riescono ad identificare il linguaggio dal contesto e inferire di conseguenza."),vs.forEach(t),Rt=u(e),A=o(e,"H2",{class:!0});var Ea=i(A);J=o(Ea,"A",{id:!0,class:!0,href:!0});var bs=i(J);Nl=o(bs,"SPAN",{});var ks=i(Nl);f(Ee.$$.fragment,ks),ks.forEach(t),bs.forEach(t),ti=u(Ea),Fl=o(Ea,"SPAN",{});var Es=i(Fl);ai=s(Es,"XLM-RoBERTa"),Es.forEach(t),Ea.forEach(t),Nt=u(e),Ue=o(e,"P",{});var zs=i(Ue);oi=s(zs,"Il seguente modello XLM-RoBERTa pu\xF2 essere usato per compiti multilingue:"),zs.forEach(t),Ft=u(e),K=o(e,"UL",{});var za=i(K);Je=o(za,"LI",{});var vn=i(Je);Hl=o(vn,"CODE",{});var $s=i(Hl);ii=s($s,"xlm-roberta-base"),$s.forEach(t),ni=s(vn," (Masked language modeling, 100 lingue)"),vn.forEach(t),si=u(za),Ke=o(za,"LI",{});var bn=i(Ke);Ql=o(bn,"CODE",{});var Ms=i(Ql);ri=s(Ms,"xlm-roberta-large"),Ms.forEach(t),mi=s(bn," (Masked language modeling, 100 lingue)"),bn.forEach(t),za.forEach(t),Ht=u(e),Ve=o(e,"P",{});var ws=i(Ve);di=s(ws,"XLM-RoBERTa \xE8 stato addestrato su 2.5TB di dati CommonCrawl appena creati e puliti in 100 lingue. Offre notevoli vantaggi rispetto ai modelli multilingue rilasciati in precedenza, come mBERT o XLM, in compiti come la classificazione, l\u2019etichettatura delle sequenze e la risposta alle domande."),ws.forEach(t),Qt=u(e),O=o(e,"H2",{class:!0});var $a=i(O);V=o($a,"A",{id:!0,class:!0,href:!0});var xs=i(V);Wl=o(xs,"SPAN",{});var ys=i(Wl);f(ze.$$.fragment,ys),ys.forEach(t),xs.forEach(t),ui=u($a),Gl=o($a,"SPAN",{});var Ls=i(Gl);pi=s(Ls,"M2M100"),Ls.forEach(t),$a.forEach(t),Wt=u(e),Ye=o(e,"P",{});var js=i(Ye);ci=s(js,"Il seguente modello M2M100 pu\xF2 essere usato per compiti multilingue:"),js.forEach(t),Gt=u(e),Y=o(e,"UL",{});var Ma=i(Y);Ze=o(Ma,"LI",{});var kn=i(Ze);Ul=o(kn,"CODE",{});var qs=i(Ul);fi=s(qs,"facebook/m2m100_418M"),qs.forEach(t),gi=s(kn," (Traduzione)"),kn.forEach(t),hi=u(Ma),el=o(Ma,"LI",{});var En=i(el);Jl=o(En,"CODE",{});var Is=i(Jl);_i=s(Is,"facebook/m2m100_1.2B"),Is.forEach(t),vi=s(En," (Traduzione)"),En.forEach(t),Ma.forEach(t),Ut=u(e),Z=o(e,"P",{});var wa=i(Z);bi=s(wa,"In questo esempio, carica il checkpoint "),Kl=o(wa,"CODE",{});var Cs=i(Kl);ki=s(Cs,"facebook/m2m100_418M"),Cs.forEach(t),Ei=s(wa,"  per tradurre dal cinese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),wa.forEach(t),Jt=u(e),f($e.$$.fragment,e),Kt=u(e),ll=o(e,"P",{});var Ps=i(ll);zi=s(Ps,"Applica il tokenizer al testo:"),Ps.forEach(t),Vt=u(e),f(Me.$$.fragment,e),Yt=u(e),M=o(e,"P",{});var ie=i(M);$i=s(ie,"M2M100 forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),Vl=o(ie,"CODE",{});var Ts=i(Vl);Mi=s(Ts,"forced_bos_token_id"),Ts.forEach(t),wi=s(ie," a "),Yl=o(ie,"CODE",{});var Ds=i(Yl);xi=s(Ds,"en"),Ds.forEach(t),yi=s(ie," nel metodo "),Zl=o(ie,"CODE",{});var As=i(Zl);Li=s(As,"generate"),As.forEach(t),ji=s(ie," per tradurre in inglese:"),ie.forEach(t),Zt=u(e),f(we.$$.fragment,e),ea=u(e),X=o(e,"H2",{class:!0});var xa=i(X);ee=o(xa,"A",{id:!0,class:!0,href:!0});var Os=i(ee);et=o(Os,"SPAN",{});var Xs=i(et);f(xe.$$.fragment,Xs),Xs.forEach(t),Os.forEach(t),qi=u(xa),lt=o(xa,"SPAN",{});var Ss=i(lt);Ii=s(Ss,"MBart"),Ss.forEach(t),xa.forEach(t),la=u(e),tl=o(e,"P",{});var Bs=i(tl);Ci=s(Bs,"Il seguente modello MBart pu\xF2 essere usato per compiti multilingue:"),Bs.forEach(t),ta=u(e),k=o(e,"UL",{});var j=i(k);al=o(j,"LI",{});var zn=i(al);tt=o(zn,"CODE",{});var Rs=i(tt);Pi=s(Rs,"facebook/mbart-large-50-one-to-many-mmt"),Rs.forEach(t),Ti=s(zn," (Traduzione automatica multilingue uno-a-molti, 50 lingue)"),zn.forEach(t),Di=u(j),ol=o(j,"LI",{});var $n=i(ol);at=o($n,"CODE",{});var Ns=i(at);Ai=s(Ns,"facebook/mbart-large-50-many-to-many-mmt"),Ns.forEach(t),Oi=s($n," (Traduzione automatica multilingue molti-a-molti, 50 lingue)"),$n.forEach(t),Xi=u(j),il=o(j,"LI",{});var Mn=i(il);ot=o(Mn,"CODE",{});var Fs=i(ot);Si=s(Fs,"facebook/mbart-large-50-many-to-one-mmt"),Fs.forEach(t),Bi=s(Mn," (Traduzione automatica multilingue molti-a-uno, 50 lingue)"),Mn.forEach(t),Ri=u(j),nl=o(j,"LI",{});var wn=i(nl);it=o(wn,"CODE",{});var Hs=i(it);Ni=s(Hs,"facebook/mbart-large-50"),Hs.forEach(t),Fi=s(wn," (Traduzione multilingue, 50 lingue)"),wn.forEach(t),Hi=u(j),nt=o(j,"LI",{});var Qs=i(nt);st=o(Qs,"CODE",{});var Ws=i(st);Qi=s(Ws,"facebook/mbart-large-cc25"),Ws.forEach(t),Qs.forEach(t),j.forEach(t),aa=u(e),le=o(e,"P",{});var ya=i(le);Wi=s(ya,"In questo esempio, carica il checkpoint "),rt=o(ya,"CODE",{});var Gs=i(rt);Gi=s(Gs,"facebook/mbart-large-50-many-to-many-mmt"),Gs.forEach(t),Ui=s(ya," per tradurre dal finlandese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),ya.forEach(t),oa=u(e),f(ye.$$.fragment,e),ia=u(e),sl=o(e,"P",{});var Us=i(sl);Ji=s(Us,"Applica il tokenizer sul testo:"),Us.forEach(t),na=u(e),f(Le.$$.fragment,e),sa=u(e),w=o(e,"P",{});var ne=i(w);Ki=s(ne,"MBart forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),mt=o(ne,"CODE",{});var Js=i(mt);Vi=s(Js,"forced_bos_token_id"),Js.forEach(t),Yi=s(ne," a "),dt=o(ne,"CODE",{});var Ks=i(dt);Zi=s(Ks,"en"),Ks.forEach(t),en=s(ne," nel metodo "),ut=o(ne,"CODE",{});var Vs=i(ut);ln=s(Vs,"generate"),Vs.forEach(t),tn=s(ne," per tradurre in inglese:"),ne.forEach(t),ra=u(e),f(je.$$.fragment,e),ma=u(e),te=o(e,"P",{});var La=i(te);an=s(La,"Se stai usando il checkpoint "),pt=o(La,"CODE",{});var Ys=i(pt);on=s(Ys,"facebook/mbart-large-50-many-to-one-mmt"),Ys.forEach(t),nn=s(La,", non hai bisogno di forzare l\u2019id della lingua obiettivo come primo token generato altrimenti l\u2019uso \xE8 lo stesso."),La.forEach(t),this.h()},h(){p(q,"name","hf:doc:metadata"),p(q,"content",JSON.stringify(sr)),p(S,"id","modelli-multilingue-per-linferenza"),p(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(S,"href","#modelli-multilingue-per-linferenza"),p(I,"class","relative group"),p(de,"href","https://huggingface.co/bert-base-multilingual-uncased"),p(de,"rel","nofollow"),p(B,"id","xlm"),p(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(B,"href","#xlm"),p(C,"class","relative group"),p(R,"id","xlm-con-language-embeddings"),p(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(R,"href","#xlm-con-language-embeddings"),p(P,"class","relative group"),p(ve,"href","https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py"),p(ve,"rel","nofollow"),p(Q,"id","xlm-senza-language-embeddings"),p(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Q,"href","#xlm-senza-language-embeddings"),p(T,"class","relative group"),p(G,"id","bert"),p(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(G,"href","#bert"),p(D,"class","relative group"),p(J,"id","xlmroberta"),p(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(J,"href","#xlmroberta"),p(A,"class","relative group"),p(V,"id","m2m100"),p(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(V,"href","#m2m100"),p(O,"class","relative group"),p(ee,"id","mbart"),p(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ee,"href","#mbart"),p(X,"class","relative group")},m(e,r){l(document.head,q),m(e,ct,r),m(e,I,r),l(I,S),l(S,dl),g(re,dl,null),l(I,ja),l(I,ul),l(ul,qa),m(e,ft,r),g(me,e,r),m(e,gt,r),m(e,y,r),l(y,Ia),l(y,pl),l(pl,Ca),l(y,Pa),l(y,de),l(de,Ta),l(y,Da),m(e,ht,r),m(e,C,r),l(C,B),l(B,cl),g(ue,cl,null),l(C,Aa),l(C,fl),l(fl,Oa),m(e,_t,r),m(e,qe,r),l(qe,Xa),m(e,vt,r),m(e,P,r),l(P,R),l(R,gl),g(pe,gl,null),l(P,Sa),l(P,hl),l(hl,Ba),m(e,bt,r),m(e,Ie,r),l(Ie,Ra),m(e,kt,r),m(e,b,r),l(b,Ce),l(Ce,_l),l(_l,Na),l(Ce,Fa),l(b,Ha),l(b,Pe),l(Pe,vl),l(vl,Qa),l(Pe,Wa),l(b,Ga),l(b,Te),l(Te,bl),l(bl,Ua),l(Te,Ja),l(b,Ka),l(b,De),l(De,kl),l(kl,Va),l(De,Ya),l(b,Za),l(b,Ae),l(Ae,El),l(El,eo),l(Ae,lo),l(b,to),l(b,Oe),l(Oe,zl),l(zl,ao),l(Oe,oo),l(b,io),l(b,Xe),l(Xe,$l),l($l,no),l(Xe,so),m(e,Et,r),m(e,z,r),l(z,ro),l(z,Ml),l(Ml,mo),l(z,uo),l(z,wl),l(wl,po),l(z,co),l(z,xl),l(xl,fo),l(z,go),m(e,zt,r),m(e,N,r),l(N,ho),l(N,yl),l(yl,_o),l(N,vo),m(e,$t,r),g(ce,e,r),m(e,Mt,r),m(e,F,r),l(F,bo),l(F,Ll),l(Ll,ko),l(F,Eo),m(e,wt,r),g(fe,e,r),m(e,xt,r),m(e,Se,r),l(Se,zo),m(e,yt,r),g(ge,e,r),m(e,Lt,r),m(e,$,r),l($,$o),l($,jl),l(jl,Mo),l($,wo),l($,ql),l(ql,xo),l($,yo),l($,Il),l(Il,Lo),l($,jo),m(e,jt,r),g(he,e,r),m(e,qt,r),m(e,H,r),l(H,qo),l(H,Cl),l(Cl,Io),l(H,Co),m(e,It,r),g(_e,e,r),m(e,Ct,r),m(e,L,r),l(L,Po),l(L,ve),l(ve,To),l(L,Do),l(L,Pl),l(Pl,Ao),l(L,Oo),m(e,Pt,r),m(e,T,r),l(T,Q),l(Q,Tl),g(be,Tl,null),l(T,Xo),l(T,Dl),l(Dl,So),m(e,Tt,r),m(e,Be,r),l(Be,Bo),m(e,Dt,r),m(e,W,r),l(W,Re),l(Re,Al),l(Al,Ro),l(Re,No),l(W,Fo),l(W,Ne),l(Ne,Ol),l(Ol,Ho),l(Ne,Qo),m(e,At,r),m(e,Fe,r),l(Fe,Wo),m(e,Ot,r),m(e,D,r),l(D,G),l(G,Xl),g(ke,Xl,null),l(D,Go),l(D,Sl),l(Sl,Uo),m(e,Xt,r),m(e,He,r),l(He,Jo),m(e,St,r),m(e,U,r),l(U,Qe),l(Qe,Bl),l(Bl,Ko),l(Qe,Vo),l(U,Yo),l(U,We),l(We,Rl),l(Rl,Zo),l(We,ei),m(e,Bt,r),m(e,Ge,r),l(Ge,li),m(e,Rt,r),m(e,A,r),l(A,J),l(J,Nl),g(Ee,Nl,null),l(A,ti),l(A,Fl),l(Fl,ai),m(e,Nt,r),m(e,Ue,r),l(Ue,oi),m(e,Ft,r),m(e,K,r),l(K,Je),l(Je,Hl),l(Hl,ii),l(Je,ni),l(K,si),l(K,Ke),l(Ke,Ql),l(Ql,ri),l(Ke,mi),m(e,Ht,r),m(e,Ve,r),l(Ve,di),m(e,Qt,r),m(e,O,r),l(O,V),l(V,Wl),g(ze,Wl,null),l(O,ui),l(O,Gl),l(Gl,pi),m(e,Wt,r),m(e,Ye,r),l(Ye,ci),m(e,Gt,r),m(e,Y,r),l(Y,Ze),l(Ze,Ul),l(Ul,fi),l(Ze,gi),l(Y,hi),l(Y,el),l(el,Jl),l(Jl,_i),l(el,vi),m(e,Ut,r),m(e,Z,r),l(Z,bi),l(Z,Kl),l(Kl,ki),l(Z,Ei),m(e,Jt,r),g($e,e,r),m(e,Kt,r),m(e,ll,r),l(ll,zi),m(e,Vt,r),g(Me,e,r),m(e,Yt,r),m(e,M,r),l(M,$i),l(M,Vl),l(Vl,Mi),l(M,wi),l(M,Yl),l(Yl,xi),l(M,yi),l(M,Zl),l(Zl,Li),l(M,ji),m(e,Zt,r),g(we,e,r),m(e,ea,r),m(e,X,r),l(X,ee),l(ee,et),g(xe,et,null),l(X,qi),l(X,lt),l(lt,Ii),m(e,la,r),m(e,tl,r),l(tl,Ci),m(e,ta,r),m(e,k,r),l(k,al),l(al,tt),l(tt,Pi),l(al,Ti),l(k,Di),l(k,ol),l(ol,at),l(at,Ai),l(ol,Oi),l(k,Xi),l(k,il),l(il,ot),l(ot,Si),l(il,Bi),l(k,Ri),l(k,nl),l(nl,it),l(it,Ni),l(nl,Fi),l(k,Hi),l(k,nt),l(nt,st),l(st,Qi),m(e,aa,r),m(e,le,r),l(le,Wi),l(le,rt),l(rt,Gi),l(le,Ui),m(e,oa,r),g(ye,e,r),m(e,ia,r),m(e,sl,r),l(sl,Ji),m(e,na,r),g(Le,e,r),m(e,sa,r),m(e,w,r),l(w,Ki),l(w,mt),l(mt,Vi),l(w,Yi),l(w,dt),l(dt,Zi),l(w,en),l(w,ut),l(ut,ln),l(w,tn),m(e,ra,r),g(je,e,r),m(e,ma,r),m(e,te,r),l(te,an),l(te,pt),l(pt,on),l(te,nn),da=!0},p:ar,i(e){da||(h(re.$$.fragment,e),h(me.$$.fragment,e),h(ue.$$.fragment,e),h(pe.$$.fragment,e),h(ce.$$.fragment,e),h(fe.$$.fragment,e),h(ge.$$.fragment,e),h(he.$$.fragment,e),h(_e.$$.fragment,e),h(be.$$.fragment,e),h(ke.$$.fragment,e),h(Ee.$$.fragment,e),h(ze.$$.fragment,e),h($e.$$.fragment,e),h(Me.$$.fragment,e),h(we.$$.fragment,e),h(xe.$$.fragment,e),h(ye.$$.fragment,e),h(Le.$$.fragment,e),h(je.$$.fragment,e),da=!0)},o(e){_(re.$$.fragment,e),_(me.$$.fragment,e),_(ue.$$.fragment,e),_(pe.$$.fragment,e),_(ce.$$.fragment,e),_(fe.$$.fragment,e),_(ge.$$.fragment,e),_(he.$$.fragment,e),_(_e.$$.fragment,e),_(be.$$.fragment,e),_(ke.$$.fragment,e),_(Ee.$$.fragment,e),_(ze.$$.fragment,e),_($e.$$.fragment,e),_(Me.$$.fragment,e),_(we.$$.fragment,e),_(xe.$$.fragment,e),_(ye.$$.fragment,e),_(Le.$$.fragment,e),_(je.$$.fragment,e),da=!1},d(e){t(q),e&&t(ct),e&&t(I),v(re),e&&t(ft),v(me,e),e&&t(gt),e&&t(y),e&&t(ht),e&&t(C),v(ue),e&&t(_t),e&&t(qe),e&&t(vt),e&&t(P),v(pe),e&&t(bt),e&&t(Ie),e&&t(kt),e&&t(b),e&&t(Et),e&&t(z),e&&t(zt),e&&t(N),e&&t($t),v(ce,e),e&&t(Mt),e&&t(F),e&&t(wt),v(fe,e),e&&t(xt),e&&t(Se),e&&t(yt),v(ge,e),e&&t(Lt),e&&t($),e&&t(jt),v(he,e),e&&t(qt),e&&t(H),e&&t(It),v(_e,e),e&&t(Ct),e&&t(L),e&&t(Pt),e&&t(T),v(be),e&&t(Tt),e&&t(Be),e&&t(Dt),e&&t(W),e&&t(At),e&&t(Fe),e&&t(Ot),e&&t(D),v(ke),e&&t(Xt),e&&t(He),e&&t(St),e&&t(U),e&&t(Bt),e&&t(Ge),e&&t(Rt),e&&t(A),v(Ee),e&&t(Nt),e&&t(Ue),e&&t(Ft),e&&t(K),e&&t(Ht),e&&t(Ve),e&&t(Qt),e&&t(O),v(ze),e&&t(Wt),e&&t(Ye),e&&t(Gt),e&&t(Y),e&&t(Ut),e&&t(Z),e&&t(Jt),v($e,e),e&&t(Kt),e&&t(ll),e&&t(Vt),v(Me,e),e&&t(Yt),e&&t(M),e&&t(Zt),v(we,e),e&&t(ea),e&&t(X),v(xe),e&&t(la),e&&t(tl),e&&t(ta),e&&t(k),e&&t(aa),e&&t(le),e&&t(oa),v(ye,e),e&&t(ia),e&&t(sl),e&&t(na),v(Le,e),e&&t(sa),e&&t(w),e&&t(ra),v(je,e),e&&t(ma),e&&t(te)}}}const sr={local:"modelli-multilingue-per-linferenza",sections:[{local:"xlm",sections:[{local:"xlm-con-language-embeddings",title:"XLM con language embeddings"},{local:"xlm-senza-language-embeddings",title:"XLM senza language embeddings"}],title:"XLM"},{local:"bert",title:"BERT"},{local:"xlmroberta",title:"XLM-RoBERTa"},{local:"m2m100",title:"M2M100"},{local:"mbart",title:"MBart"}],title:"Modelli multilingue per l'inferenza"};function rr(xn){return or(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class cr extends Zs{constructor(q){super();er(this,q,rr,nr,lr,{})}}export{cr as default,sr as metadata};
