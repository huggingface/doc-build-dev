import{S as KDt,i as ZDt,s as eGt,e as a,k as l,w as F,t as o,M as oGt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as rGt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as wKr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function tGt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,yA,xf,Oe,Qe,Ci,Rn,xA,Pn,Bn,$A,wi,In,kA,Ai,$f,xa;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ti=a("code"),yf=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Mi=a("code"),Ei=o('"new-model"'),yA=o(")."),xf=l(),Oe=a("p"),Qe=o("Likewise, if your "),Ci=a("code"),Rn=o("NewModel"),xA=o(" is a subclass of "),Pn=a("a"),Bn=o("PreTrainedModel"),$A=o(`, make sure its
`),wi=a("code"),In=o("config_class"),kA=o(` attribute is set to the same class you use when registering the model (here
`),Ai=a("code"),$f=o("NewModelConfig"),xa=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var nS=s(p);m=r(nS,"NewModelConfig"),nS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Li=s(d);h=r(Li,"PretrainedConfig"),Li.forEach(t),Eo=r(Ae,`, make sure its
`),Ti=n(Ae,"CODE",{});var sS=s(Ti);yf=r(sS,"model_type"),sS.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Mi=n(Ae,"CODE",{});var lS=s(Mi);Ei=r(lS,'"new-model"'),lS.forEach(t),yA=r(Ae,")."),Ae.forEach(t),xf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),Ci=n(Co,"CODE",{});var $a=s(Ci);Rn=r($a,"NewModel"),$a.forEach(t),xA=r(Co," is a subclass of "),Pn=n(Co,"A",{href:!0});var iS=s(Pn);Bn=r(iS,"PreTrainedModel"),iS.forEach(t),$A=r(Co,`, make sure its
`),wi=n(Co,"CODE",{});var kf=s(wi);In=r(kf,"config_class"),kf.forEach(t),kA=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ai=n(Co,"CODE",{});var dS=s(Ai);$f=r(dS,"NewModelConfig"),dS.forEach(t),xa=r(Co,")."),Co.forEach(t),this.h()},h(){c(Pn,"href","/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,Ti),e(Ti,yf),e(g,at),e(g,Mi),e(Mi,Ei),e(g,yA),b(We,xf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,Ci),e(Ci,Rn),e(Oe,xA),e(Oe,Pn),e(Pn,Bn),e(Oe,$A),e(Oe,wi),e(wi,In),e(Oe,kA),e(Oe,Ai),e(Ai,$f),e(Oe,xa)},d(We){We&&t(g),We&&t(xf),We&&t(Oe)}}}function aGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sGt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function lGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iGt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function dGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Ot(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function COt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Ot(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ROt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function POt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eVt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oVt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rVt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,yA,xf,Oe,Qe,Ci,Rn,xA,Pn,Bn,$A,wi,In,kA,Ai,$f,xa,We,Ae,nS,Li,sS,lS,Co,$a,iS,kf,dS,mQe,YGe,yi,Sf,_te,SA,gQe,ute,hQe,KGe,Nn,pQe,bte,_Qe,uQe,vte,bQe,vQe,ZGe,RA,eOe,cS,FQe,oOe,Rf,rOe,xi,Pf,Fte,PA,TQe,Tte,MQe,tOe,wo,BA,EQe,IA,CQe,fS,wQe,AQe,LQe,NA,yQe,Mte,xQe,$Qe,kQe,Ar,qA,SQe,Ete,RQe,PQe,$i,BQe,Cte,IQe,NQe,wte,qQe,jQe,DQe,A,Bf,Ate,GQe,OQe,mS,VQe,XQe,zQe,If,Lte,QQe,WQe,gS,HQe,UQe,JQe,Nf,yte,YQe,KQe,hS,ZQe,eWe,oWe,qf,xte,rWe,tWe,pS,aWe,nWe,sWe,jf,$te,lWe,iWe,_S,dWe,cWe,fWe,Df,kte,mWe,gWe,uS,hWe,pWe,_We,Gf,Ste,uWe,bWe,bS,vWe,FWe,TWe,Of,Rte,MWe,EWe,vS,CWe,wWe,AWe,Vf,Pte,LWe,yWe,FS,xWe,$We,kWe,Xf,Bte,SWe,RWe,TS,PWe,BWe,IWe,zf,Ite,NWe,qWe,MS,jWe,DWe,GWe,Qf,Nte,OWe,VWe,ES,XWe,zWe,QWe,Wf,qte,WWe,HWe,CS,UWe,JWe,YWe,Hf,jte,KWe,ZWe,wS,eHe,oHe,rHe,Uf,Dte,tHe,aHe,AS,nHe,sHe,lHe,Jf,Gte,iHe,dHe,LS,cHe,fHe,mHe,Yf,Ote,gHe,hHe,yS,pHe,_He,uHe,Kf,Vte,bHe,vHe,xS,FHe,THe,MHe,Zf,Xte,EHe,CHe,$S,wHe,AHe,LHe,em,zte,yHe,xHe,kS,$He,kHe,SHe,om,Qte,RHe,PHe,SS,BHe,IHe,NHe,rm,Wte,qHe,jHe,RS,DHe,GHe,OHe,tm,Hte,VHe,XHe,PS,zHe,QHe,WHe,am,Ute,HHe,UHe,BS,JHe,YHe,KHe,nm,Jte,ZHe,eUe,IS,oUe,rUe,tUe,sm,Yte,aUe,nUe,NS,sUe,lUe,iUe,lm,Kte,dUe,cUe,qS,fUe,mUe,gUe,im,Zte,hUe,pUe,jS,_Ue,uUe,bUe,dm,eae,vUe,FUe,DS,TUe,MUe,EUe,cm,oae,CUe,wUe,GS,AUe,LUe,yUe,fm,rae,xUe,$Ue,OS,kUe,SUe,RUe,mm,tae,PUe,BUe,VS,IUe,NUe,qUe,gm,aae,jUe,DUe,XS,GUe,OUe,VUe,hm,nae,XUe,zUe,zS,QUe,WUe,HUe,pm,sae,UUe,JUe,QS,YUe,KUe,ZUe,_m,lae,eJe,oJe,WS,rJe,tJe,aJe,um,iae,nJe,sJe,HS,lJe,iJe,dJe,bm,dae,cJe,fJe,US,mJe,gJe,hJe,vm,cae,pJe,_Je,JS,uJe,bJe,vJe,Fm,fae,FJe,TJe,YS,MJe,EJe,CJe,Tm,mae,wJe,AJe,KS,LJe,yJe,xJe,Mm,gae,$Je,kJe,ZS,SJe,RJe,PJe,Em,hae,BJe,IJe,eR,NJe,qJe,jJe,Cm,pae,DJe,GJe,oR,OJe,VJe,XJe,wm,_ae,zJe,QJe,rR,WJe,HJe,UJe,Am,uae,JJe,YJe,tR,KJe,ZJe,eYe,Lm,bae,oYe,rYe,aR,tYe,aYe,nYe,ym,vae,sYe,lYe,nR,iYe,dYe,cYe,xm,Fae,fYe,mYe,sR,gYe,hYe,pYe,$m,Tae,_Ye,uYe,lR,bYe,vYe,FYe,km,Mae,TYe,MYe,iR,EYe,CYe,wYe,Sm,Eae,AYe,LYe,dR,yYe,xYe,$Ye,Rm,Cae,kYe,SYe,cR,RYe,PYe,BYe,Pm,wae,IYe,NYe,fR,qYe,jYe,DYe,Bm,Aae,GYe,OYe,mR,VYe,XYe,zYe,Im,Lae,QYe,WYe,gR,HYe,UYe,JYe,Nm,yae,YYe,KYe,hR,ZYe,eKe,oKe,qm,xae,rKe,tKe,pR,aKe,nKe,sKe,jm,$ae,lKe,iKe,_R,dKe,cKe,fKe,Dm,kae,mKe,gKe,uR,hKe,pKe,_Ke,Gm,Sae,uKe,bKe,bR,vKe,FKe,TKe,Om,Rae,MKe,EKe,vR,CKe,wKe,AKe,Vm,Pae,LKe,yKe,FR,xKe,$Ke,kKe,Xm,Bae,SKe,RKe,TR,PKe,BKe,IKe,zm,Iae,NKe,qKe,MR,jKe,DKe,GKe,Qm,Nae,OKe,VKe,ER,XKe,zKe,QKe,Wm,qae,WKe,HKe,CR,UKe,JKe,YKe,Hm,jae,KKe,ZKe,wR,eZe,oZe,rZe,Um,Dae,tZe,aZe,AR,nZe,sZe,lZe,Jm,Gae,iZe,dZe,LR,cZe,fZe,mZe,Ym,Oae,gZe,hZe,yR,pZe,_Ze,uZe,Km,Vae,bZe,vZe,xR,FZe,TZe,MZe,Zm,Xae,EZe,CZe,$R,wZe,AZe,LZe,eg,zae,yZe,xZe,kR,$Ze,kZe,SZe,og,Qae,RZe,PZe,SR,BZe,IZe,NZe,rg,Wae,qZe,jZe,RR,DZe,GZe,OZe,tg,Hae,VZe,XZe,PR,zZe,QZe,WZe,ag,Uae,HZe,UZe,BR,JZe,YZe,KZe,ng,Jae,ZZe,eeo,IR,oeo,reo,teo,sg,Yae,aeo,neo,NR,seo,leo,ieo,lg,Kae,deo,ceo,qR,feo,meo,geo,ig,Zae,heo,peo,jR,_eo,ueo,beo,dg,ene,veo,Feo,DR,Teo,Meo,Eeo,cg,one,Ceo,weo,GR,Aeo,Leo,yeo,fg,rne,xeo,$eo,OR,keo,Seo,Reo,mg,tne,Peo,Beo,VR,Ieo,Neo,qeo,gg,ane,jeo,Deo,XR,Geo,Oeo,Veo,hg,nne,Xeo,zeo,zR,Qeo,Weo,Heo,pg,sne,Ueo,Jeo,QR,Yeo,Keo,Zeo,_g,lne,eoo,ooo,WR,roo,too,aoo,ug,ine,noo,soo,HR,loo,ioo,doo,bg,dne,coo,foo,UR,moo,goo,hoo,vg,cne,poo,_oo,JR,uoo,boo,voo,Fg,fne,Foo,Too,YR,Moo,Eoo,Coo,Tg,mne,woo,Aoo,KR,Loo,yoo,xoo,Mg,gne,$oo,koo,ZR,Soo,Roo,Poo,Eg,hne,Boo,Ioo,eP,Noo,qoo,joo,Cg,pne,Doo,Goo,oP,Ooo,Voo,Xoo,wg,_ne,zoo,Qoo,rP,Woo,Hoo,Uoo,Ag,une,Joo,Yoo,tP,Koo,Zoo,ero,Lg,bne,oro,rro,aP,tro,aro,nro,yg,vne,sro,lro,nP,iro,dro,cro,xg,Fne,fro,mro,sP,gro,hro,pro,$g,Tne,_ro,uro,lP,bro,vro,Fro,kg,Mne,Tro,Mro,iP,Ero,Cro,wro,Sg,Ene,Aro,Lro,dP,yro,xro,$ro,Rg,Cne,kro,Sro,cP,Rro,Pro,Bro,Pg,wne,Iro,Nro,fP,qro,jro,Dro,Bg,Ane,Gro,Oro,mP,Vro,Xro,zro,Ig,Lne,Qro,Wro,gP,Hro,Uro,Jro,Ng,yne,Yro,Kro,hP,Zro,eto,oto,qg,xne,rto,tto,pP,ato,nto,sto,jg,$ne,lto,ito,_P,dto,cto,fto,Dg,kne,mto,gto,uP,hto,pto,_to,Gg,Sne,uto,bto,bP,vto,Fto,Tto,Og,Mto,Vg,jA,Eto,Rne,Cto,aOe,ki,Xg,Pne,DA,wto,Bne,Ato,nOe,Ao,GA,Lto,OA,yto,vP,xto,$to,kto,VA,Sto,Ine,Rto,Pto,Bto,Lr,XA,Ito,Nne,Nto,qto,ka,jto,qne,Dto,Gto,jne,Oto,Vto,Dne,Xto,zto,Qto,k,qn,Gne,Wto,Hto,FP,Uto,Jto,TP,Yto,Kto,Zto,jn,One,eao,oao,MP,rao,tao,EP,aao,nao,sao,Dn,Vne,lao,iao,CP,dao,cao,wP,fao,mao,gao,zg,Xne,hao,pao,AP,_ao,uao,bao,Gn,zne,vao,Fao,LP,Tao,Mao,yP,Eao,Cao,wao,Qg,Qne,Aao,Lao,xP,yao,xao,$ao,Wg,Wne,kao,Sao,$P,Rao,Pao,Bao,Hg,Hne,Iao,Nao,kP,qao,jao,Dao,On,Une,Gao,Oao,SP,Vao,Xao,RP,zao,Qao,Wao,Vn,Jne,Hao,Uao,PP,Jao,Yao,BP,Kao,Zao,eno,Xn,Yne,ono,rno,IP,tno,ano,NP,nno,sno,lno,Ug,Kne,ino,dno,qP,cno,fno,mno,Jg,Zne,gno,hno,jP,pno,_no,uno,Yg,ese,bno,vno,DP,Fno,Tno,Mno,zn,ose,Eno,Cno,GP,wno,Ano,OP,Lno,yno,xno,Kg,rse,$no,kno,VP,Sno,Rno,Pno,Qn,tse,Bno,Ino,XP,Nno,qno,zP,jno,Dno,Gno,Wn,ase,Ono,Vno,QP,Xno,zno,WP,Qno,Wno,Hno,Hn,nse,Uno,Jno,HP,Yno,Kno,UP,Zno,eso,oso,Zg,sse,rso,tso,JP,aso,nso,sso,Un,lse,lso,iso,YP,dso,cso,KP,fso,mso,gso,Jn,ise,hso,pso,ZP,_so,uso,eB,bso,vso,Fso,Yn,dse,Tso,Mso,oB,Eso,Cso,rB,wso,Aso,Lso,Kn,cse,yso,xso,tB,$so,kso,aB,Sso,Rso,Pso,Zn,fse,Bso,Iso,nB,Nso,qso,sB,jso,Dso,Gso,es,mse,Oso,Vso,lB,Xso,zso,iB,Qso,Wso,Hso,eh,gse,Uso,Jso,dB,Yso,Kso,Zso,os,hse,elo,olo,cB,rlo,tlo,fB,alo,nlo,slo,oh,pse,llo,ilo,mB,dlo,clo,flo,rs,_se,mlo,glo,gB,hlo,plo,hB,_lo,ulo,blo,ts,use,vlo,Flo,pB,Tlo,Mlo,_B,Elo,Clo,wlo,as,bse,Alo,Llo,uB,ylo,xlo,bB,$lo,klo,Slo,rh,vse,Rlo,Plo,vB,Blo,Ilo,Nlo,ns,Fse,qlo,jlo,FB,Dlo,Glo,TB,Olo,Vlo,Xlo,ss,Tse,zlo,Qlo,MB,Wlo,Hlo,EB,Ulo,Jlo,Ylo,th,Mse,Klo,Zlo,CB,eio,oio,rio,ls,Ese,tio,aio,wB,nio,sio,AB,lio,iio,dio,ah,Cse,cio,fio,wse,mio,gio,hio,is,Ase,pio,_io,LB,uio,bio,yB,vio,Fio,Tio,ds,Lse,Mio,Eio,xB,Cio,wio,$B,Aio,Lio,yio,cs,yse,xio,$io,kB,kio,Sio,SB,Rio,Pio,Bio,fs,xse,Iio,Nio,RB,qio,jio,PB,Dio,Gio,Oio,ms,$se,Vio,Xio,BB,zio,Qio,IB,Wio,Hio,Uio,gs,kse,Jio,Yio,NB,Kio,Zio,qB,edo,odo,rdo,hs,Sse,tdo,ado,jB,ndo,sdo,DB,ldo,ido,ddo,nh,Rse,cdo,fdo,GB,mdo,gdo,hdo,ps,Pse,pdo,_do,OB,udo,bdo,VB,vdo,Fdo,Tdo,sh,Bse,Mdo,Edo,XB,Cdo,wdo,Ado,lh,Ise,Ldo,ydo,zB,xdo,$do,kdo,_s,Nse,Sdo,Rdo,QB,Pdo,Bdo,WB,Ido,Ndo,qdo,us,qse,jdo,Ddo,HB,Gdo,Odo,UB,Vdo,Xdo,zdo,bs,jse,Qdo,Wdo,JB,Hdo,Udo,YB,Jdo,Ydo,Kdo,ih,Dse,Zdo,eco,KB,oco,rco,tco,vs,Gse,aco,nco,ZB,sco,lco,eI,ico,dco,cco,Fs,Ose,fco,mco,oI,gco,hco,rI,pco,_co,uco,Ts,Vse,bco,vco,tI,Fco,Tco,aI,Mco,Eco,Cco,Ms,Xse,wco,Aco,nI,Lco,yco,sI,xco,$co,kco,Es,zse,Sco,Rco,lI,Pco,Bco,iI,Ico,Nco,qco,Cs,Qse,jco,Dco,dI,Gco,Oco,cI,Vco,Xco,zco,dh,Wse,Qco,Wco,fI,Hco,Uco,Jco,ws,Hse,Yco,Kco,mI,Zco,efo,gI,ofo,rfo,tfo,ch,Use,afo,nfo,hI,sfo,lfo,ifo,fh,Jse,dfo,cfo,pI,ffo,mfo,gfo,mh,Yse,hfo,pfo,_I,_fo,ufo,bfo,gh,Kse,vfo,Ffo,uI,Tfo,Mfo,Efo,As,Zse,Cfo,wfo,bI,Afo,Lfo,vI,yfo,xfo,$fo,hh,ele,kfo,Sfo,FI,Rfo,Pfo,Bfo,Ls,ole,Ifo,Nfo,TI,qfo,jfo,MI,Dfo,Gfo,Ofo,ys,rle,Vfo,Xfo,EI,zfo,Qfo,CI,Wfo,Hfo,Ufo,xs,tle,Jfo,Yfo,wI,Kfo,Zfo,AI,emo,omo,rmo,$s,ale,tmo,amo,LI,nmo,smo,yI,lmo,imo,dmo,ks,nle,cmo,fmo,xI,mmo,gmo,$I,hmo,pmo,_mo,Ss,sle,umo,bmo,kI,vmo,Fmo,SI,Tmo,Mmo,Emo,ph,lle,Cmo,wmo,RI,Amo,Lmo,ymo,_h,ile,xmo,$mo,PI,kmo,Smo,Rmo,Rs,dle,Pmo,Bmo,BI,Imo,Nmo,II,qmo,jmo,Dmo,Ps,cle,Gmo,Omo,NI,Vmo,Xmo,qI,zmo,Qmo,Wmo,Bs,fle,Hmo,Umo,jI,Jmo,Ymo,DI,Kmo,Zmo,ego,uh,mle,ogo,rgo,GI,tgo,ago,ngo,bh,gle,sgo,lgo,OI,igo,dgo,cgo,vh,hle,fgo,mgo,VI,ggo,hgo,pgo,Is,ple,_go,ugo,XI,bgo,vgo,zI,Fgo,Tgo,Mgo,Ns,_le,Ego,Cgo,QI,wgo,Ago,WI,Lgo,ygo,xgo,Fh,ule,$go,kgo,HI,Sgo,Rgo,Pgo,Th,ble,Bgo,Igo,UI,Ngo,qgo,jgo,Mh,vle,Dgo,Ggo,JI,Ogo,Vgo,Xgo,qs,Fle,zgo,Qgo,YI,Wgo,Hgo,KI,Ugo,Jgo,Ygo,Eh,Tle,Kgo,Zgo,ZI,eho,oho,rho,Ch,Mle,tho,aho,eN,nho,sho,lho,js,Ele,iho,dho,oN,cho,fho,rN,mho,gho,hho,Ds,Cle,pho,_ho,tN,uho,bho,aN,vho,Fho,Tho,Gs,wle,Mho,Eho,nN,Cho,who,sN,Aho,Lho,yho,Os,Ale,xho,$ho,lN,kho,Sho,iN,Rho,Pho,Bho,wh,Iho,Ah,zA,Nho,Lle,qho,sOe,Si,Lh,yle,QA,jho,xle,Dho,lOe,Lo,WA,Gho,HA,Oho,dN,Vho,Xho,zho,UA,Qho,$le,Who,Hho,Uho,He,JA,Jho,kle,Yho,Kho,Sa,Zho,Sle,epo,opo,Rle,rpo,tpo,Ple,apo,npo,spo,Y,yh,Ble,lpo,ipo,cN,dpo,cpo,fpo,xh,Ile,mpo,gpo,fN,hpo,ppo,_po,$h,Nle,upo,bpo,mN,vpo,Fpo,Tpo,kh,qle,Mpo,Epo,gN,Cpo,wpo,Apo,Sh,jle,Lpo,ypo,hN,xpo,$po,kpo,Rh,Dle,Spo,Rpo,pN,Ppo,Bpo,Ipo,Ph,Gle,Npo,qpo,_N,jpo,Dpo,Gpo,Bh,Ole,Opo,Vpo,uN,Xpo,zpo,Qpo,Ih,Vle,Wpo,Hpo,bN,Upo,Jpo,Ypo,Nh,Xle,Kpo,Zpo,vN,e_o,o_o,r_o,qh,zle,t_o,a_o,FN,n_o,s_o,l_o,jh,Qle,i_o,d_o,TN,c_o,f_o,m_o,Dh,Wle,g_o,h_o,MN,p_o,__o,u_o,Gh,Hle,b_o,v_o,EN,F_o,T_o,M_o,Oh,Ule,E_o,C_o,CN,w_o,A_o,L_o,Vh,Jle,y_o,x_o,wN,$_o,k_o,S_o,Xh,Yle,R_o,P_o,AN,B_o,I_o,N_o,zh,Kle,q_o,j_o,LN,D_o,G_o,O_o,Qh,Zle,V_o,X_o,yN,z_o,Q_o,W_o,Wh,eie,H_o,U_o,xN,J_o,Y_o,K_o,Hh,oie,Z_o,euo,$N,ouo,ruo,tuo,Uh,rie,auo,nuo,kN,suo,luo,iuo,Jh,tie,duo,cuo,SN,fuo,muo,guo,Yh,aie,huo,puo,RN,_uo,uuo,buo,Kh,nie,vuo,Fuo,PN,Tuo,Muo,Euo,Zh,sie,Cuo,wuo,BN,Auo,Luo,yuo,ep,lie,xuo,$uo,IN,kuo,Suo,Ruo,op,iie,Puo,Buo,NN,Iuo,Nuo,quo,rp,die,juo,Duo,qN,Guo,Ouo,Vuo,tp,cie,Xuo,zuo,jN,Quo,Wuo,Huo,ap,fie,Uuo,Juo,DN,Yuo,Kuo,Zuo,np,mie,e2o,o2o,GN,r2o,t2o,a2o,sp,n2o,lp,s2o,ip,YA,l2o,gie,i2o,iOe,Ri,dp,hie,KA,d2o,pie,c2o,dOe,yo,ZA,f2o,eL,m2o,ON,g2o,h2o,p2o,oL,_2o,_ie,u2o,b2o,v2o,Ue,rL,F2o,uie,T2o,M2o,Pi,E2o,bie,C2o,w2o,vie,A2o,L2o,y2o,he,cp,Fie,x2o,$2o,VN,k2o,S2o,R2o,fp,Tie,P2o,B2o,Mie,I2o,N2o,q2o,mp,Eie,j2o,D2o,XN,G2o,O2o,V2o,gp,Cie,X2o,z2o,zN,Q2o,W2o,H2o,hp,wie,U2o,J2o,QN,Y2o,K2o,Z2o,pp,Aie,e1o,o1o,WN,r1o,t1o,a1o,_p,Lie,n1o,s1o,HN,l1o,i1o,d1o,up,yie,c1o,f1o,UN,m1o,g1o,h1o,bp,xie,p1o,_1o,JN,u1o,b1o,v1o,vp,$ie,F1o,T1o,YN,M1o,E1o,C1o,Fp,kie,w1o,A1o,KN,L1o,y1o,x1o,Tp,Sie,$1o,k1o,ZN,S1o,R1o,P1o,Mp,Rie,B1o,I1o,eq,N1o,q1o,j1o,Ep,Pie,D1o,G1o,oq,O1o,V1o,X1o,Cp,Bie,z1o,Q1o,rq,W1o,H1o,U1o,wp,Iie,J1o,Y1o,tq,K1o,Z1o,ebo,Ap,Nie,obo,rbo,aq,tbo,abo,nbo,Lp,sbo,yp,lbo,xp,tL,ibo,qie,dbo,cOe,Bi,$p,jie,aL,cbo,Die,fbo,fOe,xo,nL,mbo,Ii,gbo,nq,hbo,pbo,sq,_bo,ubo,bbo,sL,vbo,Gie,Fbo,Tbo,Mbo,nt,lL,Ebo,Oie,Cbo,wbo,Ni,Abo,Vie,Lbo,ybo,lq,xbo,$bo,kbo,kp,Sbo,Je,iL,Rbo,Xie,Pbo,Bbo,Ra,Ibo,zie,Nbo,qbo,Qie,jbo,Dbo,Wie,Gbo,Obo,Vbo,y,Sp,Hie,Xbo,zbo,iq,Qbo,Wbo,Hbo,Rp,Uie,Ubo,Jbo,dq,Ybo,Kbo,Zbo,Pp,Jie,evo,ovo,cq,rvo,tvo,avo,Bp,Yie,nvo,svo,fq,lvo,ivo,dvo,Ip,Kie,cvo,fvo,mq,mvo,gvo,hvo,Np,Zie,pvo,_vo,gq,uvo,bvo,vvo,qp,ede,Fvo,Tvo,hq,Mvo,Evo,Cvo,jp,ode,wvo,Avo,pq,Lvo,yvo,xvo,Dp,rde,$vo,kvo,_q,Svo,Rvo,Pvo,Gp,tde,Bvo,Ivo,uq,Nvo,qvo,jvo,Op,ade,Dvo,Gvo,bq,Ovo,Vvo,Xvo,Vp,nde,zvo,Qvo,vq,Wvo,Hvo,Uvo,Xp,sde,Jvo,Yvo,Fq,Kvo,Zvo,eFo,zp,lde,oFo,rFo,Tq,tFo,aFo,nFo,Qp,ide,sFo,lFo,Mq,iFo,dFo,cFo,Wp,dde,fFo,mFo,Eq,gFo,hFo,pFo,Hp,cde,_Fo,uFo,Cq,bFo,vFo,FFo,Up,fde,TFo,MFo,wq,EFo,CFo,wFo,Jp,mde,AFo,LFo,Aq,yFo,xFo,$Fo,Yp,gde,kFo,SFo,Lq,RFo,PFo,BFo,Kp,hde,IFo,NFo,yq,qFo,jFo,DFo,Zp,pde,GFo,OFo,xq,VFo,XFo,zFo,e_,_de,QFo,WFo,$q,HFo,UFo,JFo,o_,ude,YFo,KFo,kq,ZFo,e6o,o6o,r_,bde,r6o,t6o,Sq,a6o,n6o,s6o,t_,vde,l6o,i6o,Rq,d6o,c6o,f6o,a_,Fde,m6o,g6o,Pq,h6o,p6o,_6o,n_,Tde,u6o,b6o,Bq,v6o,F6o,T6o,s_,Mde,M6o,E6o,Iq,C6o,w6o,A6o,l_,Ede,L6o,y6o,Nq,x6o,$6o,k6o,i_,Cde,S6o,R6o,qq,P6o,B6o,I6o,d_,wde,N6o,q6o,jq,j6o,D6o,G6o,c_,Ade,O6o,V6o,Dq,X6o,z6o,Q6o,Vs,Lde,W6o,H6o,Gq,U6o,J6o,Oq,Y6o,K6o,Z6o,f_,yde,eTo,oTo,Vq,rTo,tTo,aTo,m_,xde,nTo,sTo,Xq,lTo,iTo,dTo,g_,$de,cTo,fTo,zq,mTo,gTo,hTo,h_,kde,pTo,_To,Qq,uTo,bTo,vTo,p_,Sde,FTo,TTo,Wq,MTo,ETo,CTo,__,Rde,wTo,ATo,Hq,LTo,yTo,xTo,u_,Pde,$To,kTo,Uq,STo,RTo,PTo,b_,Bde,BTo,ITo,Jq,NTo,qTo,jTo,v_,Ide,DTo,GTo,Nde,OTo,VTo,XTo,F_,qde,zTo,QTo,Yq,WTo,HTo,UTo,T_,jde,JTo,YTo,Kq,KTo,ZTo,e7o,M_,Dde,o7o,r7o,Zq,t7o,a7o,n7o,E_,Gde,s7o,l7o,ej,i7o,d7o,c7o,C_,Ode,f7o,m7o,oj,g7o,h7o,p7o,w_,Vde,_7o,u7o,rj,b7o,v7o,F7o,A_,Xde,T7o,M7o,tj,E7o,C7o,w7o,L_,zde,A7o,L7o,aj,y7o,x7o,$7o,y_,Qde,k7o,S7o,nj,R7o,P7o,B7o,x_,Wde,I7o,N7o,sj,q7o,j7o,D7o,$_,Hde,G7o,O7o,lj,V7o,X7o,z7o,k_,Ude,Q7o,W7o,ij,H7o,U7o,J7o,S_,Jde,Y7o,K7o,dj,Z7o,e8o,o8o,R_,Yde,r8o,t8o,cj,a8o,n8o,s8o,P_,Kde,l8o,i8o,fj,d8o,c8o,f8o,B_,Zde,m8o,g8o,mj,h8o,p8o,_8o,I_,ece,u8o,b8o,gj,v8o,F8o,T8o,N_,oce,M8o,E8o,hj,C8o,w8o,A8o,q_,rce,L8o,y8o,pj,x8o,$8o,k8o,j_,tce,S8o,R8o,_j,P8o,B8o,I8o,D_,ace,N8o,q8o,uj,j8o,D8o,G8o,G_,nce,O8o,V8o,bj,X8o,z8o,Q8o,O_,sce,W8o,H8o,vj,U8o,J8o,Y8o,V_,lce,K8o,Z8o,Fj,eMo,oMo,rMo,X_,ice,tMo,aMo,Tj,nMo,sMo,lMo,z_,dce,iMo,dMo,Mj,cMo,fMo,mMo,Q_,cce,gMo,hMo,Ej,pMo,_Mo,uMo,W_,fce,bMo,vMo,Cj,FMo,TMo,MMo,H_,mce,EMo,CMo,wj,wMo,AMo,LMo,U_,gce,yMo,xMo,Aj,$Mo,kMo,SMo,J_,hce,RMo,PMo,Lj,BMo,IMo,NMo,Y_,pce,qMo,jMo,yj,DMo,GMo,OMo,K_,_ce,VMo,XMo,xj,zMo,QMo,WMo,Z_,uce,HMo,UMo,$j,JMo,YMo,KMo,eu,bce,ZMo,eEo,kj,oEo,rEo,tEo,ou,vce,aEo,nEo,Sj,sEo,lEo,iEo,ru,Fce,dEo,cEo,Rj,fEo,mEo,gEo,tu,Tce,hEo,pEo,Pj,_Eo,uEo,bEo,au,Mce,vEo,FEo,Bj,TEo,MEo,EEo,nu,Ece,CEo,wEo,Ij,AEo,LEo,yEo,su,Cce,xEo,$Eo,Nj,kEo,SEo,REo,lu,wce,PEo,BEo,qj,IEo,NEo,qEo,iu,Ace,jEo,DEo,jj,GEo,OEo,VEo,du,Lce,XEo,zEo,Dj,QEo,WEo,HEo,cu,yce,UEo,JEo,Gj,YEo,KEo,ZEo,fu,xce,e4o,o4o,Oj,r4o,t4o,a4o,mu,$ce,n4o,s4o,Vj,l4o,i4o,d4o,gu,kce,c4o,f4o,Xj,m4o,g4o,h4o,hu,Sce,p4o,_4o,zj,u4o,b4o,v4o,pu,Rce,F4o,T4o,Qj,M4o,E4o,C4o,_u,Pce,w4o,A4o,Wj,L4o,y4o,x4o,uu,Bce,$4o,k4o,Hj,S4o,R4o,P4o,bu,Ice,B4o,I4o,Uj,N4o,q4o,j4o,vu,Nce,D4o,G4o,Jj,O4o,V4o,X4o,Fu,qce,z4o,Q4o,Yj,W4o,H4o,U4o,Tu,jce,J4o,Y4o,Kj,K4o,Z4o,eCo,Mu,Dce,oCo,rCo,Zj,tCo,aCo,nCo,Eu,Gce,sCo,lCo,eD,iCo,dCo,cCo,Cu,Oce,fCo,mCo,oD,gCo,hCo,pCo,wu,Vce,_Co,uCo,rD,bCo,vCo,FCo,Au,Xce,TCo,MCo,tD,ECo,CCo,wCo,Lu,zce,ACo,LCo,aD,yCo,xCo,$Co,yu,Qce,kCo,SCo,nD,RCo,PCo,BCo,xu,Wce,ICo,NCo,sD,qCo,jCo,DCo,$u,Hce,GCo,OCo,lD,VCo,XCo,zCo,ku,QCo,Uce,WCo,HCo,Jce,UCo,JCo,Su,mOe,qi,Ru,Yce,dL,YCo,Kce,KCo,gOe,$o,cL,ZCo,ji,e5o,iD,o5o,r5o,dD,t5o,a5o,n5o,fL,s5o,Zce,l5o,i5o,d5o,st,mL,c5o,efe,f5o,m5o,Di,g5o,ofe,h5o,p5o,cD,_5o,u5o,b5o,Pu,v5o,Ye,gL,F5o,rfe,T5o,M5o,Pa,E5o,tfe,C5o,w5o,afe,A5o,L5o,nfe,y5o,x5o,$5o,G,Bu,sfe,k5o,S5o,fD,R5o,P5o,B5o,Iu,lfe,I5o,N5o,mD,q5o,j5o,D5o,Nu,ife,G5o,O5o,gD,V5o,X5o,z5o,qu,dfe,Q5o,W5o,hD,H5o,U5o,J5o,ju,cfe,Y5o,K5o,pD,Z5o,e3o,o3o,Du,ffe,r3o,t3o,_D,a3o,n3o,s3o,Gu,mfe,l3o,i3o,uD,d3o,c3o,f3o,Ou,gfe,m3o,g3o,bD,h3o,p3o,_3o,Vu,hfe,u3o,b3o,vD,v3o,F3o,T3o,Xu,pfe,M3o,E3o,FD,C3o,w3o,A3o,zu,_fe,L3o,y3o,TD,x3o,$3o,k3o,Qu,ufe,S3o,R3o,MD,P3o,B3o,I3o,Wu,bfe,N3o,q3o,ED,j3o,D3o,G3o,Hu,vfe,O3o,V3o,CD,X3o,z3o,Q3o,Uu,Ffe,W3o,H3o,wD,U3o,J3o,Y3o,Ju,Tfe,K3o,Z3o,AD,e0o,o0o,r0o,Yu,Mfe,t0o,a0o,LD,n0o,s0o,l0o,Ku,Efe,i0o,d0o,yD,c0o,f0o,m0o,Zu,Cfe,g0o,h0o,xD,p0o,_0o,u0o,e2,wfe,b0o,v0o,$D,F0o,T0o,M0o,o2,Afe,E0o,C0o,kD,w0o,A0o,L0o,r2,Lfe,y0o,x0o,SD,$0o,k0o,S0o,t2,yfe,R0o,P0o,RD,B0o,I0o,N0o,a2,xfe,q0o,j0o,PD,D0o,G0o,O0o,n2,$fe,V0o,X0o,BD,z0o,Q0o,W0o,s2,kfe,H0o,U0o,ID,J0o,Y0o,K0o,l2,Sfe,Z0o,ewo,ND,owo,rwo,two,i2,Rfe,awo,nwo,qD,swo,lwo,iwo,d2,Pfe,dwo,cwo,jD,fwo,mwo,gwo,c2,Bfe,hwo,pwo,DD,_wo,uwo,bwo,f2,Ife,vwo,Fwo,GD,Two,Mwo,Ewo,m2,Nfe,Cwo,wwo,OD,Awo,Lwo,ywo,g2,qfe,xwo,$wo,VD,kwo,Swo,Rwo,h2,jfe,Pwo,Bwo,XD,Iwo,Nwo,qwo,p2,Dfe,jwo,Dwo,zD,Gwo,Owo,Vwo,_2,Gfe,Xwo,zwo,QD,Qwo,Wwo,Hwo,u2,Ofe,Uwo,Jwo,WD,Ywo,Kwo,Zwo,b2,Vfe,eAo,oAo,HD,rAo,tAo,aAo,v2,Xfe,nAo,sAo,UD,lAo,iAo,dAo,F2,zfe,cAo,fAo,JD,mAo,gAo,hAo,T2,Qfe,pAo,_Ao,YD,uAo,bAo,vAo,M2,Wfe,FAo,TAo,KD,MAo,EAo,CAo,E2,Hfe,wAo,AAo,ZD,LAo,yAo,xAo,C2,Ufe,$Ao,kAo,eG,SAo,RAo,PAo,w2,BAo,Jfe,IAo,NAo,Yfe,qAo,jAo,A2,hOe,Gi,L2,Kfe,hL,DAo,Zfe,GAo,pOe,ko,pL,OAo,Oi,VAo,oG,XAo,zAo,rG,QAo,WAo,HAo,_L,UAo,eme,JAo,YAo,KAo,lt,uL,ZAo,ome,eLo,oLo,Vi,rLo,rme,tLo,aLo,tG,nLo,sLo,lLo,y2,iLo,Ke,bL,dLo,tme,cLo,fLo,Ba,mLo,ame,gLo,hLo,nme,pLo,_Lo,sme,uLo,bLo,vLo,z,x2,lme,FLo,TLo,aG,MLo,ELo,CLo,$2,ime,wLo,ALo,nG,LLo,yLo,xLo,k2,dme,$Lo,kLo,sG,SLo,RLo,PLo,S2,cme,BLo,ILo,lG,NLo,qLo,jLo,R2,fme,DLo,GLo,iG,OLo,VLo,XLo,P2,mme,zLo,QLo,dG,WLo,HLo,ULo,B2,gme,JLo,YLo,cG,KLo,ZLo,eyo,I2,hme,oyo,ryo,fG,tyo,ayo,nyo,N2,pme,syo,lyo,mG,iyo,dyo,cyo,q2,_me,fyo,myo,gG,gyo,hyo,pyo,j2,ume,_yo,uyo,hG,byo,vyo,Fyo,D2,bme,Tyo,Myo,pG,Eyo,Cyo,wyo,G2,vme,Ayo,Lyo,_G,yyo,xyo,$yo,O2,Fme,kyo,Syo,uG,Ryo,Pyo,Byo,V2,Tme,Iyo,Nyo,bG,qyo,jyo,Dyo,X2,Mme,Gyo,Oyo,vG,Vyo,Xyo,zyo,z2,Eme,Qyo,Wyo,FG,Hyo,Uyo,Jyo,Q2,Cme,Yyo,Kyo,TG,Zyo,e9o,o9o,W2,wme,r9o,t9o,MG,a9o,n9o,s9o,H2,Ame,l9o,i9o,EG,d9o,c9o,f9o,U2,Lme,m9o,g9o,CG,h9o,p9o,_9o,J2,yme,u9o,b9o,wG,v9o,F9o,T9o,Y2,xme,M9o,E9o,AG,C9o,w9o,A9o,K2,$me,L9o,y9o,LG,x9o,$9o,k9o,Z2,kme,S9o,R9o,yG,P9o,B9o,I9o,e1,Sme,N9o,q9o,xG,j9o,D9o,G9o,o1,Rme,O9o,V9o,$G,X9o,z9o,Q9o,r1,Pme,W9o,H9o,kG,U9o,J9o,Y9o,t1,Bme,K9o,Z9o,SG,exo,oxo,rxo,a1,Ime,txo,axo,RG,nxo,sxo,lxo,n1,Nme,ixo,dxo,PG,cxo,fxo,mxo,s1,qme,gxo,hxo,BG,pxo,_xo,uxo,l1,jme,bxo,vxo,IG,Fxo,Txo,Mxo,i1,Dme,Exo,Cxo,NG,wxo,Axo,Lxo,d1,Gme,yxo,xxo,qG,$xo,kxo,Sxo,c1,Ome,Rxo,Pxo,jG,Bxo,Ixo,Nxo,f1,Vme,qxo,jxo,DG,Dxo,Gxo,Oxo,m1,Xme,Vxo,Xxo,GG,zxo,Qxo,Wxo,g1,Hxo,zme,Uxo,Jxo,Qme,Yxo,Kxo,h1,_Oe,Xi,p1,Wme,vL,Zxo,Hme,e$o,uOe,So,FL,o$o,zi,r$o,OG,t$o,a$o,VG,n$o,s$o,l$o,TL,i$o,Ume,d$o,c$o,f$o,it,ML,m$o,Jme,g$o,h$o,Qi,p$o,Yme,_$o,u$o,XG,b$o,v$o,F$o,_1,T$o,Ze,EL,M$o,Kme,E$o,C$o,Ia,w$o,Zme,A$o,L$o,ege,y$o,x$o,oge,$$o,k$o,S$o,Q,u1,rge,R$o,P$o,zG,B$o,I$o,N$o,b1,tge,q$o,j$o,QG,D$o,G$o,O$o,v1,age,V$o,X$o,WG,z$o,Q$o,W$o,F1,nge,H$o,U$o,HG,J$o,Y$o,K$o,T1,sge,Z$o,eko,UG,oko,rko,tko,M1,lge,ako,nko,JG,sko,lko,iko,E1,ige,dko,cko,YG,fko,mko,gko,C1,dge,hko,pko,KG,_ko,uko,bko,w1,cge,vko,Fko,ZG,Tko,Mko,Eko,A1,fge,Cko,wko,eO,Ako,Lko,yko,L1,mge,xko,$ko,oO,kko,Sko,Rko,y1,gge,Pko,Bko,rO,Iko,Nko,qko,x1,hge,jko,Dko,tO,Gko,Oko,Vko,$1,pge,Xko,zko,aO,Qko,Wko,Hko,k1,_ge,Uko,Jko,nO,Yko,Kko,Zko,S1,uge,eSo,oSo,sO,rSo,tSo,aSo,R1,bge,nSo,sSo,lO,lSo,iSo,dSo,P1,vge,cSo,fSo,iO,mSo,gSo,hSo,B1,Fge,pSo,_So,dO,uSo,bSo,vSo,I1,Tge,FSo,TSo,cO,MSo,ESo,CSo,N1,Mge,wSo,ASo,fO,LSo,ySo,xSo,q1,Ege,$So,kSo,mO,SSo,RSo,PSo,j1,Cge,BSo,ISo,gO,NSo,qSo,jSo,D1,wge,DSo,GSo,hO,OSo,VSo,XSo,G1,Age,zSo,QSo,pO,WSo,HSo,USo,O1,Lge,JSo,YSo,_O,KSo,ZSo,eRo,V1,yge,oRo,rRo,uO,tRo,aRo,nRo,X1,xge,sRo,lRo,bO,iRo,dRo,cRo,z1,$ge,fRo,mRo,vO,gRo,hRo,pRo,Q1,kge,_Ro,uRo,FO,bRo,vRo,FRo,W1,Sge,TRo,MRo,TO,ERo,CRo,wRo,H1,Rge,ARo,LRo,MO,yRo,xRo,$Ro,U1,Pge,kRo,SRo,Bge,RRo,PRo,BRo,J1,Ige,IRo,NRo,EO,qRo,jRo,DRo,Y1,Nge,GRo,ORo,CO,VRo,XRo,zRo,K1,qge,QRo,WRo,wO,HRo,URo,JRo,Z1,jge,YRo,KRo,AO,ZRo,ePo,oPo,eb,rPo,Dge,tPo,aPo,Gge,nPo,sPo,ob,bOe,Wi,rb,Oge,CL,lPo,Vge,iPo,vOe,Ro,wL,dPo,Hi,cPo,LO,fPo,mPo,yO,gPo,hPo,pPo,AL,_Po,Xge,uPo,bPo,vPo,dt,LL,FPo,zge,TPo,MPo,Ui,EPo,Qge,CPo,wPo,xO,APo,LPo,yPo,tb,xPo,eo,yL,$Po,Wge,kPo,SPo,Na,RPo,Hge,PPo,BPo,Uge,IPo,NPo,Jge,qPo,jPo,DPo,pe,ab,Yge,GPo,OPo,$O,VPo,XPo,zPo,nb,Kge,QPo,WPo,kO,HPo,UPo,JPo,sb,Zge,YPo,KPo,SO,ZPo,eBo,oBo,lb,ehe,rBo,tBo,RO,aBo,nBo,sBo,ib,ohe,lBo,iBo,PO,dBo,cBo,fBo,db,rhe,mBo,gBo,BO,hBo,pBo,_Bo,cb,the,uBo,bBo,IO,vBo,FBo,TBo,fb,ahe,MBo,EBo,NO,CBo,wBo,ABo,mb,nhe,LBo,yBo,qO,xBo,$Bo,kBo,gb,she,SBo,RBo,jO,PBo,BBo,IBo,hb,lhe,NBo,qBo,DO,jBo,DBo,GBo,pb,ihe,OBo,VBo,GO,XBo,zBo,QBo,_b,dhe,WBo,HBo,OO,UBo,JBo,YBo,ub,che,KBo,ZBo,VO,eIo,oIo,rIo,bb,fhe,tIo,aIo,XO,nIo,sIo,lIo,vb,mhe,iIo,dIo,zO,cIo,fIo,mIo,Fb,ghe,gIo,hIo,QO,pIo,_Io,uIo,Tb,bIo,hhe,vIo,FIo,phe,TIo,MIo,Mb,FOe,Ji,Eb,_he,xL,EIo,uhe,CIo,TOe,Po,$L,wIo,Yi,AIo,WO,LIo,yIo,HO,xIo,$Io,kIo,kL,SIo,bhe,RIo,PIo,BIo,ct,SL,IIo,vhe,NIo,qIo,Ki,jIo,Fhe,DIo,GIo,UO,OIo,VIo,XIo,Cb,zIo,oo,RL,QIo,The,WIo,HIo,qa,UIo,Mhe,JIo,YIo,Ehe,KIo,ZIo,Che,eNo,oNo,rNo,N,wb,whe,tNo,aNo,JO,nNo,sNo,lNo,Ab,Ahe,iNo,dNo,YO,cNo,fNo,mNo,Lb,Lhe,gNo,hNo,KO,pNo,_No,uNo,yb,yhe,bNo,vNo,ZO,FNo,TNo,MNo,xb,xhe,ENo,CNo,eV,wNo,ANo,LNo,$b,$he,yNo,xNo,oV,$No,kNo,SNo,kb,khe,RNo,PNo,rV,BNo,INo,NNo,Sb,She,qNo,jNo,tV,DNo,GNo,ONo,Rb,Rhe,VNo,XNo,aV,zNo,QNo,WNo,Pb,Phe,HNo,UNo,nV,JNo,YNo,KNo,Bb,Bhe,ZNo,eqo,sV,oqo,rqo,tqo,Ib,Ihe,aqo,nqo,lV,sqo,lqo,iqo,Nb,Nhe,dqo,cqo,iV,fqo,mqo,gqo,qb,qhe,hqo,pqo,dV,_qo,uqo,bqo,jb,jhe,vqo,Fqo,cV,Tqo,Mqo,Eqo,Db,Dhe,Cqo,wqo,fV,Aqo,Lqo,yqo,Gb,Ghe,xqo,$qo,mV,kqo,Sqo,Rqo,Ob,Ohe,Pqo,Bqo,gV,Iqo,Nqo,qqo,Vb,Vhe,jqo,Dqo,hV,Gqo,Oqo,Vqo,Xb,Xhe,Xqo,zqo,pV,Qqo,Wqo,Hqo,zb,zhe,Uqo,Jqo,_V,Yqo,Kqo,Zqo,Qb,Qhe,ejo,ojo,uV,rjo,tjo,ajo,Wb,Whe,njo,sjo,bV,ljo,ijo,djo,Hb,Hhe,cjo,fjo,vV,mjo,gjo,hjo,Ub,Uhe,pjo,_jo,FV,ujo,bjo,vjo,Jb,Jhe,Fjo,Tjo,TV,Mjo,Ejo,Cjo,Yb,Yhe,wjo,Ajo,MV,Ljo,yjo,xjo,Kb,Khe,$jo,kjo,EV,Sjo,Rjo,Pjo,Zb,Zhe,Bjo,Ijo,CV,Njo,qjo,jjo,ev,epe,Djo,Gjo,wV,Ojo,Vjo,Xjo,ov,ope,zjo,Qjo,AV,Wjo,Hjo,Ujo,rv,rpe,Jjo,Yjo,LV,Kjo,Zjo,eDo,tv,tpe,oDo,rDo,yV,tDo,aDo,nDo,av,ape,sDo,lDo,xV,iDo,dDo,cDo,nv,npe,fDo,mDo,$V,gDo,hDo,pDo,sv,spe,_Do,uDo,kV,bDo,vDo,FDo,lv,lpe,TDo,MDo,SV,EDo,CDo,wDo,iv,ipe,ADo,LDo,RV,yDo,xDo,$Do,dv,dpe,kDo,SDo,PV,RDo,PDo,BDo,cv,cpe,IDo,NDo,BV,qDo,jDo,DDo,fv,fpe,GDo,ODo,IV,VDo,XDo,zDo,mv,mpe,QDo,WDo,NV,HDo,UDo,JDo,gv,gpe,YDo,KDo,qV,ZDo,eGo,oGo,hv,hpe,rGo,tGo,jV,aGo,nGo,sGo,pv,ppe,lGo,iGo,DV,dGo,cGo,fGo,_v,_pe,mGo,gGo,GV,hGo,pGo,_Go,uv,upe,uGo,bGo,OV,vGo,FGo,TGo,bv,bpe,MGo,EGo,VV,CGo,wGo,AGo,vv,vpe,LGo,yGo,XV,xGo,$Go,kGo,Fv,SGo,Fpe,RGo,PGo,Tpe,BGo,IGo,Tv,MOe,Zi,Mv,Mpe,PL,NGo,Epe,qGo,EOe,Bo,BL,jGo,ed,DGo,zV,GGo,OGo,QV,VGo,XGo,zGo,IL,QGo,Cpe,WGo,HGo,UGo,ft,NL,JGo,wpe,YGo,KGo,od,ZGo,Ape,eOo,oOo,WV,rOo,tOo,aOo,Ev,nOo,ro,qL,sOo,Lpe,lOo,iOo,ja,dOo,ype,cOo,fOo,xpe,mOo,gOo,$pe,hOo,pOo,_Oo,Z,Cv,kpe,uOo,bOo,HV,vOo,FOo,TOo,wv,Spe,MOo,EOo,UV,COo,wOo,AOo,Av,Rpe,LOo,yOo,JV,xOo,$Oo,kOo,Lv,Ppe,SOo,ROo,YV,POo,BOo,IOo,yv,Bpe,NOo,qOo,KV,jOo,DOo,GOo,xv,Ipe,OOo,VOo,ZV,XOo,zOo,QOo,$v,Npe,WOo,HOo,eX,UOo,JOo,YOo,kv,qpe,KOo,ZOo,oX,eVo,oVo,rVo,Sv,jpe,tVo,aVo,rX,nVo,sVo,lVo,Rv,Dpe,iVo,dVo,tX,cVo,fVo,mVo,Pv,Gpe,gVo,hVo,aX,pVo,_Vo,uVo,Bv,Ope,bVo,vVo,nX,FVo,TVo,MVo,Iv,Vpe,EVo,CVo,sX,wVo,AVo,LVo,Nv,Xpe,yVo,xVo,lX,$Vo,kVo,SVo,qv,zpe,RVo,PVo,iX,BVo,IVo,NVo,jv,Qpe,qVo,jVo,dX,DVo,GVo,OVo,Dv,Wpe,VVo,XVo,cX,zVo,QVo,WVo,Gv,Hpe,HVo,UVo,fX,JVo,YVo,KVo,Ov,Upe,ZVo,eXo,mX,oXo,rXo,tXo,Vv,Jpe,aXo,nXo,gX,sXo,lXo,iXo,Xv,Ype,dXo,cXo,hX,fXo,mXo,gXo,zv,Kpe,hXo,pXo,pX,_Xo,uXo,bXo,Qv,Zpe,vXo,FXo,_X,TXo,MXo,EXo,Wv,e_e,CXo,wXo,uX,AXo,LXo,yXo,Hv,o_e,xXo,$Xo,bX,kXo,SXo,RXo,Uv,r_e,PXo,BXo,vX,IXo,NXo,qXo,Jv,t_e,jXo,DXo,FX,GXo,OXo,VXo,Yv,a_e,XXo,zXo,TX,QXo,WXo,HXo,Kv,n_e,UXo,JXo,MX,YXo,KXo,ZXo,Zv,s_e,ezo,ozo,EX,rzo,tzo,azo,eF,nzo,l_e,szo,lzo,i_e,izo,dzo,oF,COe,rd,rF,d_e,jL,czo,c_e,fzo,wOe,Io,DL,mzo,td,gzo,CX,hzo,pzo,wX,_zo,uzo,bzo,GL,vzo,f_e,Fzo,Tzo,Mzo,mt,OL,Ezo,m_e,Czo,wzo,ad,Azo,g_e,Lzo,yzo,AX,xzo,$zo,kzo,tF,Szo,to,VL,Rzo,h_e,Pzo,Bzo,Da,Izo,p_e,Nzo,qzo,__e,jzo,Dzo,u_e,Gzo,Ozo,Vzo,No,aF,b_e,Xzo,zzo,LX,Qzo,Wzo,Hzo,nF,v_e,Uzo,Jzo,yX,Yzo,Kzo,Zzo,sF,F_e,eQo,oQo,xX,rQo,tQo,aQo,lF,T_e,nQo,sQo,$X,lQo,iQo,dQo,iF,M_e,cQo,fQo,kX,mQo,gQo,hQo,dF,E_e,pQo,_Qo,SX,uQo,bQo,vQo,cF,FQo,C_e,TQo,MQo,w_e,EQo,CQo,fF,AOe,nd,mF,A_e,XL,wQo,L_e,AQo,LOe,qo,zL,LQo,sd,yQo,RX,xQo,$Qo,PX,kQo,SQo,RQo,QL,PQo,y_e,BQo,IQo,NQo,gt,WL,qQo,x_e,jQo,DQo,ld,GQo,$_e,OQo,VQo,BX,XQo,zQo,QQo,gF,WQo,ao,HL,HQo,k_e,UQo,JQo,Ga,YQo,S_e,KQo,ZQo,R_e,eWo,oWo,P_e,rWo,tWo,aWo,H,hF,B_e,nWo,sWo,IX,lWo,iWo,dWo,pF,I_e,cWo,fWo,NX,mWo,gWo,hWo,_F,N_e,pWo,_Wo,qX,uWo,bWo,vWo,uF,q_e,FWo,TWo,jX,MWo,EWo,CWo,bF,j_e,wWo,AWo,DX,LWo,yWo,xWo,vF,D_e,$Wo,kWo,GX,SWo,RWo,PWo,FF,G_e,BWo,IWo,OX,NWo,qWo,jWo,TF,O_e,DWo,GWo,VX,OWo,VWo,XWo,MF,V_e,zWo,QWo,XX,WWo,HWo,UWo,EF,X_e,JWo,YWo,zX,KWo,ZWo,eHo,CF,z_e,oHo,rHo,QX,tHo,aHo,nHo,wF,Q_e,sHo,lHo,WX,iHo,dHo,cHo,AF,W_e,fHo,mHo,HX,gHo,hHo,pHo,LF,H_e,_Ho,uHo,UX,bHo,vHo,FHo,yF,U_e,THo,MHo,JX,EHo,CHo,wHo,xF,J_e,AHo,LHo,YX,yHo,xHo,$Ho,$F,Y_e,kHo,SHo,KX,RHo,PHo,BHo,kF,K_e,IHo,NHo,ZX,qHo,jHo,DHo,SF,Z_e,GHo,OHo,ez,VHo,XHo,zHo,RF,eue,QHo,WHo,oz,HHo,UHo,JHo,PF,oue,YHo,KHo,rz,ZHo,eUo,oUo,BF,rue,rUo,tUo,tz,aUo,nUo,sUo,IF,tue,lUo,iUo,az,dUo,cUo,fUo,NF,aue,mUo,gUo,nz,hUo,pUo,_Uo,qF,nue,uUo,bUo,sz,vUo,FUo,TUo,jF,sue,MUo,EUo,lz,CUo,wUo,AUo,DF,lue,LUo,yUo,iz,xUo,$Uo,kUo,GF,iue,SUo,RUo,dz,PUo,BUo,IUo,OF,due,NUo,qUo,cz,jUo,DUo,GUo,VF,cue,OUo,VUo,fz,XUo,zUo,QUo,XF,fue,WUo,HUo,mz,UUo,JUo,YUo,zF,mue,KUo,ZUo,gz,eJo,oJo,rJo,QF,gue,tJo,aJo,hz,nJo,sJo,lJo,WF,hue,iJo,dJo,pz,cJo,fJo,mJo,HF,pue,gJo,hJo,_z,pJo,_Jo,uJo,UF,_ue,bJo,vJo,uz,FJo,TJo,MJo,JF,EJo,uue,CJo,wJo,bue,AJo,LJo,YF,yOe,id,KF,vue,UL,yJo,Fue,xJo,xOe,jo,JL,$Jo,dd,kJo,bz,SJo,RJo,vz,PJo,BJo,IJo,YL,NJo,Tue,qJo,jJo,DJo,ht,KL,GJo,Mue,OJo,VJo,cd,XJo,Eue,zJo,QJo,Fz,WJo,HJo,UJo,ZF,JJo,no,ZL,YJo,Cue,KJo,ZJo,Oa,eYo,wue,oYo,rYo,Aue,tYo,aYo,Lue,nYo,sYo,lYo,V,e6,yue,iYo,dYo,Tz,cYo,fYo,mYo,o6,xue,gYo,hYo,Mz,pYo,_Yo,uYo,r6,$ue,bYo,vYo,Ez,FYo,TYo,MYo,t6,kue,EYo,CYo,Cz,wYo,AYo,LYo,a6,Sue,yYo,xYo,wz,$Yo,kYo,SYo,n6,Rue,RYo,PYo,Az,BYo,IYo,NYo,s6,Pue,qYo,jYo,Lz,DYo,GYo,OYo,l6,Bue,VYo,XYo,yz,zYo,QYo,WYo,i6,Iue,HYo,UYo,xz,JYo,YYo,KYo,d6,Nue,ZYo,eKo,$z,oKo,rKo,tKo,c6,que,aKo,nKo,kz,sKo,lKo,iKo,f6,jue,dKo,cKo,Sz,fKo,mKo,gKo,m6,Due,hKo,pKo,Rz,_Ko,uKo,bKo,g6,Gue,vKo,FKo,Pz,TKo,MKo,EKo,h6,Oue,CKo,wKo,Bz,AKo,LKo,yKo,p6,Vue,xKo,$Ko,Iz,kKo,SKo,RKo,_6,Xue,PKo,BKo,Nz,IKo,NKo,qKo,u6,zue,jKo,DKo,qz,GKo,OKo,VKo,b6,Que,XKo,zKo,jz,QKo,WKo,HKo,v6,Wue,UKo,JKo,Dz,YKo,KKo,ZKo,F6,Hue,eZo,oZo,Gz,rZo,tZo,aZo,T6,Uue,nZo,sZo,Oz,lZo,iZo,dZo,M6,Jue,cZo,fZo,Vz,mZo,gZo,hZo,E6,Yue,pZo,_Zo,Xz,uZo,bZo,vZo,C6,Kue,FZo,TZo,zz,MZo,EZo,CZo,w6,Zue,wZo,AZo,Qz,LZo,yZo,xZo,A6,e2e,$Zo,kZo,Wz,SZo,RZo,PZo,L6,o2e,BZo,IZo,Hz,NZo,qZo,jZo,y6,r2e,DZo,GZo,Uz,OZo,VZo,XZo,x6,t2e,zZo,QZo,Jz,WZo,HZo,UZo,$6,a2e,JZo,YZo,Yz,KZo,ZZo,eer,k6,n2e,oer,rer,Kz,ter,aer,ner,S6,s2e,ser,ler,Zz,ier,der,cer,R6,l2e,fer,mer,eQ,ger,her,per,P6,i2e,_er,uer,oQ,ber,ver,Fer,B6,d2e,Ter,Mer,rQ,Eer,Cer,wer,I6,c2e,Aer,Ler,tQ,yer,xer,$er,N6,f2e,ker,Ser,aQ,Rer,Per,Ber,q6,m2e,Ier,Ner,nQ,qer,jer,Der,j6,g2e,Ger,Oer,sQ,Ver,Xer,zer,D6,h2e,Qer,Wer,lQ,Her,Uer,Jer,G6,Yer,p2e,Ker,Zer,_2e,eor,oor,O6,$Oe,fd,V6,u2e,ey,ror,b2e,tor,kOe,Do,oy,aor,md,nor,iQ,sor,lor,dQ,ior,dor,cor,ry,mor,v2e,gor,hor,por,pt,ty,_or,F2e,uor,bor,gd,vor,T2e,For,Tor,cQ,Mor,Eor,Cor,X6,wor,so,ay,Aor,M2e,Lor,yor,Va,xor,E2e,$or,kor,C2e,Sor,Ror,w2e,Por,Bor,Ior,A2e,z6,L2e,Nor,qor,fQ,jor,Dor,Gor,Q6,Oor,y2e,Vor,Xor,x2e,zor,Qor,W6,SOe,hd,H6,$2e,ny,Wor,k2e,Hor,ROe,Go,sy,Uor,pd,Jor,mQ,Yor,Kor,gQ,Zor,err,orr,ly,rrr,S2e,trr,arr,nrr,_t,iy,srr,R2e,lrr,irr,_d,drr,P2e,crr,frr,hQ,mrr,grr,hrr,U6,prr,lo,dy,_rr,B2e,urr,brr,Xa,vrr,I2e,Frr,Trr,N2e,Mrr,Err,q2e,Crr,wrr,Arr,Fe,J6,j2e,Lrr,yrr,pQ,xrr,$rr,krr,Y6,D2e,Srr,Rrr,_Q,Prr,Brr,Irr,K6,G2e,Nrr,qrr,uQ,jrr,Drr,Grr,Z6,O2e,Orr,Vrr,bQ,Xrr,zrr,Qrr,Xs,V2e,Wrr,Hrr,vQ,Urr,Jrr,FQ,Yrr,Krr,Zrr,eT,X2e,etr,otr,TQ,rtr,ttr,atr,zs,z2e,ntr,str,MQ,ltr,itr,EQ,dtr,ctr,ftr,ut,Q2e,mtr,gtr,CQ,htr,ptr,wQ,_tr,utr,AQ,btr,vtr,Ftr,oT,W2e,Ttr,Mtr,LQ,Etr,Ctr,wtr,rT,H2e,Atr,Ltr,yQ,ytr,xtr,$tr,tT,U2e,ktr,Str,xQ,Rtr,Ptr,Btr,aT,J2e,Itr,Ntr,$Q,qtr,jtr,Dtr,nT,Y2e,Gtr,Otr,kQ,Vtr,Xtr,ztr,sT,K2e,Qtr,Wtr,SQ,Htr,Utr,Jtr,lT,Z2e,Ytr,Ktr,RQ,Ztr,ear,oar,iT,rar,e1e,tar,aar,o1e,nar,sar,dT,POe,ud,cT,r1e,cy,lar,t1e,iar,BOe,Oo,fy,dar,bd,car,PQ,far,mar,BQ,gar,har,par,my,_ar,a1e,uar,bar,Far,bt,gy,Tar,n1e,Mar,Ear,vd,Car,s1e,war,Aar,IQ,Lar,yar,xar,fT,$ar,io,hy,kar,l1e,Sar,Rar,za,Par,i1e,Bar,Iar,d1e,Nar,qar,c1e,jar,Dar,Gar,f1e,mT,m1e,Oar,Var,NQ,Xar,zar,Qar,gT,War,g1e,Har,Uar,h1e,Jar,Yar,hT,IOe,Fd,pT,p1e,py,Kar,_1e,Zar,NOe,Vo,_y,enr,Td,onr,qQ,rnr,tnr,jQ,anr,nnr,snr,uy,lnr,u1e,inr,dnr,cnr,vt,by,fnr,b1e,mnr,gnr,Md,hnr,v1e,pnr,_nr,DQ,unr,bnr,vnr,_T,Fnr,co,vy,Tnr,F1e,Mnr,Enr,Qa,Cnr,T1e,wnr,Anr,M1e,Lnr,ynr,E1e,xnr,$nr,knr,C1e,uT,w1e,Snr,Rnr,GQ,Pnr,Bnr,Inr,bT,Nnr,A1e,qnr,jnr,L1e,Dnr,Gnr,vT,qOe,Ed,FT,y1e,Fy,Onr,x1e,Vnr,jOe,Xo,Ty,Xnr,Cd,znr,OQ,Qnr,Wnr,VQ,Hnr,Unr,Jnr,My,Ynr,$1e,Knr,Znr,esr,Ft,Ey,osr,k1e,rsr,tsr,wd,asr,S1e,nsr,ssr,XQ,lsr,isr,dsr,TT,csr,fo,Cy,fsr,R1e,msr,gsr,Wa,hsr,P1e,psr,_sr,B1e,usr,bsr,I1e,vsr,Fsr,Tsr,Pe,MT,N1e,Msr,Esr,zQ,Csr,wsr,Asr,ET,q1e,Lsr,ysr,QQ,xsr,$sr,ksr,CT,j1e,Ssr,Rsr,WQ,Psr,Bsr,Isr,wT,D1e,Nsr,qsr,HQ,jsr,Dsr,Gsr,AT,G1e,Osr,Vsr,UQ,Xsr,zsr,Qsr,LT,O1e,Wsr,Hsr,JQ,Usr,Jsr,Ysr,yT,V1e,Ksr,Zsr,YQ,elr,olr,rlr,xT,X1e,tlr,alr,KQ,nlr,slr,llr,$T,z1e,ilr,dlr,ZQ,clr,flr,mlr,kT,glr,Q1e,hlr,plr,W1e,_lr,ulr,ST,DOe,Ad,RT,H1e,wy,blr,U1e,vlr,GOe,zo,Ay,Flr,Ld,Tlr,eW,Mlr,Elr,oW,Clr,wlr,Alr,Ly,Llr,J1e,ylr,xlr,$lr,Tt,yy,klr,Y1e,Slr,Rlr,yd,Plr,K1e,Blr,Ilr,rW,Nlr,qlr,jlr,PT,Dlr,mo,xy,Glr,Z1e,Olr,Vlr,Ha,Xlr,ebe,zlr,Qlr,obe,Wlr,Hlr,rbe,Ulr,Jlr,Ylr,et,BT,tbe,Klr,Zlr,tW,eir,oir,rir,IT,abe,tir,air,aW,nir,sir,lir,NT,nbe,iir,dir,nW,cir,fir,mir,qT,sbe,gir,hir,sW,pir,_ir,uir,jT,lbe,bir,vir,lW,Fir,Tir,Mir,DT,Eir,ibe,Cir,wir,dbe,Air,Lir,GT,OOe,xd,OT,cbe,$y,yir,fbe,xir,VOe,Qo,ky,$ir,$d,kir,iW,Sir,Rir,dW,Pir,Bir,Iir,Sy,Nir,mbe,qir,jir,Dir,Mt,Ry,Gir,gbe,Oir,Vir,kd,Xir,hbe,zir,Qir,cW,Wir,Hir,Uir,VT,Jir,go,Py,Yir,pbe,Kir,Zir,Ua,edr,_be,odr,rdr,ube,tdr,adr,bbe,ndr,sdr,ldr,Le,XT,vbe,idr,ddr,fW,cdr,fdr,mdr,zT,Fbe,gdr,hdr,mW,pdr,_dr,udr,QT,Tbe,bdr,vdr,gW,Fdr,Tdr,Mdr,WT,Mbe,Edr,Cdr,hW,wdr,Adr,Ldr,HT,Ebe,ydr,xdr,pW,$dr,kdr,Sdr,UT,Cbe,Rdr,Pdr,_W,Bdr,Idr,Ndr,JT,wbe,qdr,jdr,uW,Ddr,Gdr,Odr,YT,Abe,Vdr,Xdr,bW,zdr,Qdr,Wdr,KT,Lbe,Hdr,Udr,vW,Jdr,Ydr,Kdr,ZT,ybe,Zdr,ecr,FW,ocr,rcr,tcr,e7,acr,xbe,ncr,scr,$be,lcr,icr,o7,XOe,Sd,r7,kbe,By,dcr,Sbe,ccr,zOe,Wo,Iy,fcr,Rd,mcr,TW,gcr,hcr,MW,pcr,_cr,ucr,Ny,bcr,Rbe,vcr,Fcr,Tcr,Et,qy,Mcr,Pbe,Ecr,Ccr,Pd,wcr,Bbe,Acr,Lcr,EW,ycr,xcr,$cr,t7,kcr,ho,jy,Scr,Ibe,Rcr,Pcr,Ja,Bcr,Nbe,Icr,Ncr,qbe,qcr,jcr,jbe,Dcr,Gcr,Ocr,Dy,a7,Dbe,Vcr,Xcr,CW,zcr,Qcr,Wcr,n7,Gbe,Hcr,Ucr,wW,Jcr,Ycr,Kcr,s7,Zcr,Obe,efr,ofr,Vbe,rfr,tfr,l7,QOe,Bd,i7,Xbe,Gy,afr,zbe,nfr,WOe,Ho,Oy,sfr,Id,lfr,AW,ifr,dfr,LW,cfr,ffr,mfr,Vy,gfr,Qbe,hfr,pfr,_fr,Ct,Xy,ufr,Wbe,bfr,vfr,Nd,Ffr,Hbe,Tfr,Mfr,yW,Efr,Cfr,wfr,d7,Afr,po,zy,Lfr,Ube,yfr,xfr,Ya,$fr,Jbe,kfr,Sfr,Ybe,Rfr,Pfr,Kbe,Bfr,Ifr,Nfr,ot,c7,Zbe,qfr,jfr,xW,Dfr,Gfr,Ofr,f7,eve,Vfr,Xfr,$W,zfr,Qfr,Wfr,m7,ove,Hfr,Ufr,kW,Jfr,Yfr,Kfr,g7,rve,Zfr,emr,SW,omr,rmr,tmr,h7,tve,amr,nmr,RW,smr,lmr,imr,p7,dmr,ave,cmr,fmr,nve,mmr,gmr,_7,HOe,qd,u7,sve,Qy,hmr,lve,pmr,UOe,Uo,Wy,_mr,jd,umr,PW,bmr,vmr,BW,Fmr,Tmr,Mmr,Hy,Emr,ive,Cmr,wmr,Amr,wt,Uy,Lmr,dve,ymr,xmr,Dd,$mr,cve,kmr,Smr,IW,Rmr,Pmr,Bmr,b7,Imr,_o,Jy,Nmr,fve,qmr,jmr,Ka,Dmr,mve,Gmr,Omr,gve,Vmr,Xmr,hve,zmr,Qmr,Wmr,Gd,v7,pve,Hmr,Umr,NW,Jmr,Ymr,Kmr,F7,_ve,Zmr,egr,qW,ogr,rgr,tgr,T7,uve,agr,ngr,jW,sgr,lgr,igr,M7,dgr,bve,cgr,fgr,vve,mgr,ggr,E7,JOe,Od,C7,Fve,Yy,hgr,Tve,pgr,YOe,Jo,Ky,_gr,Vd,ugr,DW,bgr,vgr,GW,Fgr,Tgr,Mgr,Zy,Egr,Mve,Cgr,wgr,Agr,At,e9,Lgr,Eve,ygr,xgr,Xd,$gr,Cve,kgr,Sgr,OW,Rgr,Pgr,Bgr,w7,Igr,uo,o9,Ngr,wve,qgr,jgr,Za,Dgr,Ave,Ggr,Ogr,Lve,Vgr,Xgr,yve,zgr,Qgr,Wgr,r9,A7,xve,Hgr,Ugr,VW,Jgr,Ygr,Kgr,L7,$ve,Zgr,ehr,XW,ohr,rhr,thr,y7,ahr,kve,nhr,shr,Sve,lhr,ihr,x7,KOe,zd,$7,Rve,t9,dhr,Pve,chr,ZOe,Yo,a9,fhr,Qd,mhr,zW,ghr,hhr,QW,phr,_hr,uhr,n9,bhr,Bve,vhr,Fhr,Thr,Lt,s9,Mhr,Ive,Ehr,Chr,Wd,whr,Nve,Ahr,Lhr,WW,yhr,xhr,$hr,k7,khr,bo,l9,Shr,qve,Rhr,Phr,en,Bhr,jve,Ihr,Nhr,Dve,qhr,jhr,Gve,Dhr,Ghr,Ohr,Ove,S7,Vve,Vhr,Xhr,HW,zhr,Qhr,Whr,R7,Hhr,Xve,Uhr,Jhr,zve,Yhr,Khr,P7,eVe,Hd,B7,Qve,i9,Zhr,Wve,epr,oVe,Ko,d9,opr,Ud,rpr,UW,tpr,apr,JW,npr,spr,lpr,c9,ipr,Hve,dpr,cpr,fpr,yt,f9,mpr,Uve,gpr,hpr,Jd,ppr,Jve,_pr,upr,YW,bpr,vpr,Fpr,I7,Tpr,vo,m9,Mpr,Yve,Epr,Cpr,on,wpr,Kve,Apr,Lpr,Zve,ypr,xpr,eFe,$pr,kpr,Spr,rn,N7,oFe,Rpr,Ppr,KW,Bpr,Ipr,Npr,q7,rFe,qpr,jpr,ZW,Dpr,Gpr,Opr,j7,tFe,Vpr,Xpr,eH,zpr,Qpr,Wpr,D7,aFe,Hpr,Upr,oH,Jpr,Ypr,Kpr,G7,Zpr,nFe,e_r,o_r,sFe,r_r,t_r,O7,rVe,Yd,V7,lFe,g9,a_r,iFe,n_r,tVe,Zo,h9,s_r,Kd,l_r,rH,i_r,d_r,tH,c_r,f_r,m_r,p9,g_r,dFe,h_r,p_r,__r,xt,_9,u_r,cFe,b_r,v_r,Zd,F_r,fFe,T_r,M_r,aH,E_r,C_r,w_r,X7,A_r,Fo,u9,L_r,mFe,y_r,x_r,tn,$_r,gFe,k_r,S_r,hFe,R_r,P_r,pFe,B_r,I_r,N_r,_Fe,z7,uFe,q_r,j_r,nH,D_r,G_r,O_r,Q7,V_r,bFe,X_r,z_r,vFe,Q_r,W_r,W7,aVe,ec,H7,FFe,b9,H_r,TFe,U_r,nVe,er,v9,J_r,oc,Y_r,sH,K_r,Z_r,lH,eur,our,rur,F9,tur,MFe,aur,nur,sur,$t,T9,lur,EFe,iur,dur,rc,cur,CFe,fur,mur,iH,gur,hur,pur,U7,_ur,yr,M9,uur,wFe,bur,vur,an,Fur,AFe,Tur,Mur,LFe,Eur,Cur,yFe,wur,Aur,Lur,j,J7,xFe,yur,xur,dH,$ur,kur,Sur,Y7,$Fe,Rur,Pur,cH,Bur,Iur,Nur,K7,kFe,qur,jur,fH,Dur,Gur,Our,Z7,SFe,Vur,Xur,mH,zur,Qur,Wur,e8,RFe,Hur,Uur,gH,Jur,Yur,Kur,o8,PFe,Zur,e2r,hH,o2r,r2r,t2r,r8,BFe,a2r,n2r,pH,s2r,l2r,i2r,t8,IFe,d2r,c2r,_H,f2r,m2r,g2r,a8,NFe,h2r,p2r,uH,_2r,u2r,b2r,n8,qFe,v2r,F2r,bH,T2r,M2r,E2r,s8,jFe,C2r,w2r,vH,A2r,L2r,y2r,l8,DFe,x2r,$2r,FH,k2r,S2r,R2r,i8,GFe,P2r,B2r,TH,I2r,N2r,q2r,d8,OFe,j2r,D2r,MH,G2r,O2r,V2r,c8,VFe,X2r,z2r,EH,Q2r,W2r,H2r,f8,XFe,U2r,J2r,CH,Y2r,K2r,Z2r,m8,zFe,e1r,o1r,wH,r1r,t1r,a1r,Qs,QFe,n1r,s1r,AH,l1r,i1r,LH,d1r,c1r,f1r,g8,WFe,m1r,g1r,yH,h1r,p1r,_1r,h8,HFe,u1r,b1r,xH,v1r,F1r,T1r,p8,UFe,M1r,E1r,$H,C1r,w1r,A1r,_8,JFe,L1r,y1r,kH,x1r,$1r,k1r,u8,YFe,S1r,R1r,SH,P1r,B1r,I1r,b8,KFe,N1r,q1r,RH,j1r,D1r,G1r,v8,ZFe,O1r,V1r,PH,X1r,z1r,Q1r,F8,e6e,W1r,H1r,BH,U1r,J1r,Y1r,T8,o6e,K1r,Z1r,IH,ebr,obr,rbr,M8,r6e,tbr,abr,NH,nbr,sbr,lbr,E8,t6e,ibr,dbr,qH,cbr,fbr,mbr,C8,a6e,gbr,hbr,jH,pbr,_br,ubr,w8,n6e,bbr,vbr,DH,Fbr,Tbr,Mbr,A8,s6e,Ebr,Cbr,GH,wbr,Abr,Lbr,L8,l6e,ybr,xbr,OH,$br,kbr,Sbr,y8,i6e,Rbr,Pbr,VH,Bbr,Ibr,Nbr,x8,d6e,qbr,jbr,XH,Dbr,Gbr,Obr,$8,c6e,Vbr,Xbr,zH,zbr,Qbr,Wbr,k8,f6e,Hbr,Ubr,QH,Jbr,Ybr,Kbr,S8,m6e,Zbr,evr,WH,ovr,rvr,tvr,R8,g6e,avr,nvr,HH,svr,lvr,ivr,P8,h6e,dvr,cvr,UH,fvr,mvr,gvr,B8,p6e,hvr,pvr,JH,_vr,uvr,bvr,I8,_6e,vvr,Fvr,YH,Tvr,Mvr,Evr,N8,u6e,Cvr,wvr,KH,Avr,Lvr,yvr,q8,b6e,xvr,$vr,ZH,kvr,Svr,Rvr,j8,v6e,Pvr,Bvr,eU,Ivr,Nvr,qvr,D8,F6e,jvr,Dvr,oU,Gvr,Ovr,Vvr,G8,T6e,Xvr,zvr,rU,Qvr,Wvr,Hvr,O8,sVe,tc,V8,M6e,E9,Uvr,E6e,Jvr,lVe,or,C9,Yvr,ac,Kvr,tU,Zvr,eFr,aU,oFr,rFr,tFr,w9,aFr,C6e,nFr,sFr,lFr,kt,A9,iFr,w6e,dFr,cFr,nc,fFr,A6e,mFr,gFr,nU,hFr,pFr,_Fr,X8,uFr,xr,L9,bFr,L6e,vFr,FFr,nn,TFr,y6e,MFr,EFr,x6e,CFr,wFr,$6e,AFr,LFr,yFr,se,z8,k6e,xFr,$Fr,sU,kFr,SFr,RFr,Q8,S6e,PFr,BFr,lU,IFr,NFr,qFr,W8,R6e,jFr,DFr,iU,GFr,OFr,VFr,H8,P6e,XFr,zFr,dU,QFr,WFr,HFr,U8,B6e,UFr,JFr,cU,YFr,KFr,ZFr,J8,I6e,e6r,o6r,fU,r6r,t6r,a6r,Y8,N6e,n6r,s6r,mU,l6r,i6r,d6r,K8,q6e,c6r,f6r,gU,m6r,g6r,h6r,Z8,j6e,p6r,_6r,hU,u6r,b6r,v6r,eM,D6e,F6r,T6r,pU,M6r,E6r,C6r,oM,G6e,w6r,A6r,_U,L6r,y6r,x6r,rM,O6e,$6r,k6r,uU,S6r,R6r,P6r,tM,V6e,B6r,I6r,bU,N6r,q6r,j6r,aM,X6e,D6r,G6r,vU,O6r,V6r,X6r,nM,z6e,z6r,Q6r,FU,W6r,H6r,U6r,sM,Q6e,J6r,Y6r,TU,K6r,Z6r,eTr,lM,W6e,oTr,rTr,MU,tTr,aTr,nTr,iM,H6e,sTr,lTr,EU,iTr,dTr,cTr,dM,U6e,fTr,mTr,CU,gTr,hTr,pTr,cM,J6e,_Tr,uTr,wU,bTr,vTr,FTr,fM,Y6e,TTr,MTr,AU,ETr,CTr,wTr,mM,K6e,ATr,LTr,LU,yTr,xTr,$Tr,gM,Z6e,kTr,STr,yU,RTr,PTr,BTr,hM,iVe,sc,pM,eTe,y9,ITr,oTe,NTr,dVe,rr,x9,qTr,lc,jTr,xU,DTr,GTr,$U,OTr,VTr,XTr,$9,zTr,rTe,QTr,WTr,HTr,St,k9,UTr,tTe,JTr,YTr,ic,KTr,aTe,ZTr,e7r,kU,o7r,r7r,t7r,_M,a7r,$r,S9,n7r,nTe,s7r,l7r,sn,i7r,sTe,d7r,c7r,lTe,f7r,m7r,iTe,g7r,h7r,p7r,Me,uM,dTe,_7r,u7r,SU,b7r,v7r,F7r,bM,cTe,T7r,M7r,RU,E7r,C7r,w7r,vM,fTe,A7r,L7r,PU,y7r,x7r,$7r,FM,mTe,k7r,S7r,BU,R7r,P7r,B7r,TM,gTe,I7r,N7r,IU,q7r,j7r,D7r,MM,hTe,G7r,O7r,NU,V7r,X7r,z7r,EM,pTe,Q7r,W7r,qU,H7r,U7r,J7r,CM,_Te,Y7r,K7r,jU,Z7r,e8r,o8r,wM,uTe,r8r,t8r,DU,a8r,n8r,s8r,AM,bTe,l8r,i8r,GU,d8r,c8r,f8r,LM,vTe,m8r,g8r,OU,h8r,p8r,_8r,yM,FTe,u8r,b8r,VU,v8r,F8r,T8r,xM,TTe,M8r,E8r,XU,C8r,w8r,A8r,$M,cVe,dc,kM,MTe,R9,L8r,ETe,y8r,fVe,tr,P9,x8r,cc,$8r,zU,k8r,S8r,QU,R8r,P8r,B8r,B9,I8r,CTe,N8r,q8r,j8r,Rt,I9,D8r,wTe,G8r,O8r,fc,V8r,ATe,X8r,z8r,WU,Q8r,W8r,H8r,SM,U8r,kr,N9,J8r,LTe,Y8r,K8r,ln,Z8r,yTe,eMr,oMr,xTe,rMr,tMr,$Te,aMr,nMr,sMr,dn,RM,kTe,lMr,iMr,HU,dMr,cMr,fMr,PM,STe,mMr,gMr,UU,hMr,pMr,_Mr,BM,RTe,uMr,bMr,JU,vMr,FMr,TMr,IM,PTe,MMr,EMr,YU,CMr,wMr,AMr,NM,mVe,mc,qM,BTe,q9,LMr,ITe,yMr,gVe,ar,j9,xMr,gc,$Mr,KU,kMr,SMr,ZU,RMr,PMr,BMr,D9,IMr,NTe,NMr,qMr,jMr,Pt,G9,DMr,qTe,GMr,OMr,hc,VMr,jTe,XMr,zMr,eJ,QMr,WMr,HMr,jM,UMr,Sr,O9,JMr,DTe,YMr,KMr,cn,ZMr,GTe,eEr,oEr,OTe,rEr,tEr,VTe,aEr,nEr,sEr,ie,DM,XTe,lEr,iEr,oJ,dEr,cEr,fEr,GM,zTe,mEr,gEr,rJ,hEr,pEr,_Er,OM,QTe,uEr,bEr,tJ,vEr,FEr,TEr,VM,WTe,MEr,EEr,aJ,CEr,wEr,AEr,XM,HTe,LEr,yEr,nJ,xEr,$Er,kEr,zM,UTe,SEr,REr,sJ,PEr,BEr,IEr,QM,JTe,NEr,qEr,lJ,jEr,DEr,GEr,WM,YTe,OEr,VEr,iJ,XEr,zEr,QEr,HM,KTe,WEr,HEr,dJ,UEr,JEr,YEr,UM,ZTe,KEr,ZEr,cJ,e4r,o4r,r4r,JM,e7e,t4r,a4r,fJ,n4r,s4r,l4r,YM,o7e,i4r,d4r,mJ,c4r,f4r,m4r,KM,r7e,g4r,h4r,gJ,p4r,_4r,u4r,ZM,t7e,b4r,v4r,hJ,F4r,T4r,M4r,eE,a7e,E4r,C4r,pJ,w4r,A4r,L4r,oE,n7e,y4r,x4r,_J,$4r,k4r,S4r,rE,s7e,R4r,P4r,uJ,B4r,I4r,N4r,tE,l7e,q4r,j4r,bJ,D4r,G4r,O4r,aE,i7e,V4r,X4r,vJ,z4r,Q4r,W4r,nE,d7e,H4r,U4r,FJ,J4r,Y4r,K4r,sE,hVe,pc,lE,c7e,V9,Z4r,f7e,eCr,pVe,nr,X9,oCr,_c,rCr,TJ,tCr,aCr,MJ,nCr,sCr,lCr,z9,iCr,m7e,dCr,cCr,fCr,Bt,Q9,mCr,g7e,gCr,hCr,uc,pCr,h7e,_Cr,uCr,EJ,bCr,vCr,FCr,iE,TCr,Rr,W9,MCr,p7e,ECr,CCr,fn,wCr,_7e,ACr,LCr,u7e,yCr,xCr,b7e,$Cr,kCr,SCr,ye,dE,v7e,RCr,PCr,CJ,BCr,ICr,NCr,cE,F7e,qCr,jCr,wJ,DCr,GCr,OCr,fE,T7e,VCr,XCr,AJ,zCr,QCr,WCr,mE,M7e,HCr,UCr,LJ,JCr,YCr,KCr,gE,E7e,ZCr,e5r,yJ,o5r,r5r,t5r,hE,C7e,a5r,n5r,xJ,s5r,l5r,i5r,pE,w7e,d5r,c5r,$J,f5r,m5r,g5r,_E,A7e,h5r,p5r,kJ,_5r,u5r,b5r,uE,L7e,v5r,F5r,SJ,T5r,M5r,E5r,bE,y7e,C5r,w5r,RJ,A5r,L5r,y5r,vE,_Ve,bc,FE,x7e,H9,x5r,$7e,$5r,uVe,sr,U9,k5r,vc,S5r,PJ,R5r,P5r,BJ,B5r,I5r,N5r,J9,q5r,k7e,j5r,D5r,G5r,It,Y9,O5r,S7e,V5r,X5r,Fc,z5r,R7e,Q5r,W5r,IJ,H5r,U5r,J5r,TE,Y5r,Pr,K9,K5r,P7e,Z5r,e3r,mn,o3r,B7e,r3r,t3r,I7e,a3r,n3r,N7e,s3r,l3r,i3r,te,ME,q7e,d3r,c3r,NJ,f3r,m3r,g3r,EE,j7e,h3r,p3r,qJ,_3r,u3r,b3r,CE,D7e,v3r,F3r,jJ,T3r,M3r,E3r,wE,G7e,C3r,w3r,DJ,A3r,L3r,y3r,AE,O7e,x3r,$3r,GJ,k3r,S3r,R3r,LE,V7e,P3r,B3r,OJ,I3r,N3r,q3r,yE,X7e,j3r,D3r,VJ,G3r,O3r,V3r,xE,z7e,X3r,z3r,XJ,Q3r,W3r,H3r,$E,Q7e,U3r,J3r,zJ,Y3r,K3r,Z3r,kE,W7e,e0r,o0r,QJ,r0r,t0r,a0r,SE,H7e,n0r,s0r,WJ,l0r,i0r,d0r,RE,U7e,c0r,f0r,HJ,m0r,g0r,h0r,PE,J7e,p0r,_0r,UJ,u0r,b0r,v0r,BE,Y7e,F0r,T0r,JJ,M0r,E0r,C0r,IE,K7e,w0r,A0r,YJ,L0r,y0r,x0r,NE,Z7e,$0r,k0r,KJ,S0r,R0r,P0r,qE,e8e,B0r,I0r,ZJ,N0r,q0r,j0r,jE,o8e,D0r,G0r,eY,O0r,V0r,X0r,DE,r8e,z0r,Q0r,oY,W0r,H0r,U0r,GE,t8e,J0r,Y0r,rY,K0r,Z0r,ewr,OE,a8e,owr,rwr,tY,twr,awr,nwr,VE,n8e,swr,lwr,aY,iwr,dwr,cwr,XE,s8e,fwr,mwr,nY,gwr,hwr,pwr,zE,l8e,_wr,uwr,sY,bwr,vwr,Fwr,QE,i8e,Twr,Mwr,lY,Ewr,Cwr,wwr,WE,d8e,Awr,Lwr,iY,ywr,xwr,$wr,HE,bVe,Tc,UE,c8e,Z9,kwr,f8e,Swr,vVe,lr,ex,Rwr,Mc,Pwr,dY,Bwr,Iwr,cY,Nwr,qwr,jwr,ox,Dwr,m8e,Gwr,Owr,Vwr,Nt,rx,Xwr,g8e,zwr,Qwr,Ec,Wwr,h8e,Hwr,Uwr,fY,Jwr,Ywr,Kwr,JE,Zwr,Br,tx,eAr,p8e,oAr,rAr,gn,tAr,_8e,aAr,nAr,u8e,sAr,lAr,b8e,iAr,dAr,cAr,_e,YE,v8e,fAr,mAr,mY,gAr,hAr,pAr,KE,F8e,_Ar,uAr,gY,bAr,vAr,FAr,ZE,T8e,TAr,MAr,hY,EAr,CAr,wAr,e4,M8e,AAr,LAr,pY,yAr,xAr,$Ar,o4,E8e,kAr,SAr,_Y,RAr,PAr,BAr,r4,C8e,IAr,NAr,uY,qAr,jAr,DAr,t4,w8e,GAr,OAr,bY,VAr,XAr,zAr,a4,A8e,QAr,WAr,vY,HAr,UAr,JAr,n4,L8e,YAr,KAr,FY,ZAr,eLr,oLr,s4,y8e,rLr,tLr,TY,aLr,nLr,sLr,l4,x8e,lLr,iLr,MY,dLr,cLr,fLr,i4,$8e,mLr,gLr,EY,hLr,pLr,_Lr,d4,k8e,uLr,bLr,CY,vLr,FLr,TLr,c4,S8e,MLr,ELr,wY,CLr,wLr,ALr,f4,R8e,LLr,yLr,AY,xLr,$Lr,kLr,m4,P8e,SLr,RLr,LY,PLr,BLr,ILr,g4,B8e,NLr,qLr,yY,jLr,DLr,GLr,h4,FVe,Cc,p4,I8e,ax,OLr,N8e,VLr,TVe,ir,nx,XLr,wc,zLr,xY,QLr,WLr,$Y,HLr,ULr,JLr,sx,YLr,q8e,KLr,ZLr,eyr,qt,lx,oyr,j8e,ryr,tyr,Ac,ayr,D8e,nyr,syr,kY,lyr,iyr,dyr,_4,cyr,Ir,ix,fyr,G8e,myr,gyr,hn,hyr,O8e,pyr,_yr,V8e,uyr,byr,X8e,vyr,Fyr,Tyr,dx,u4,z8e,Myr,Eyr,SY,Cyr,wyr,Ayr,b4,Q8e,Lyr,yyr,RY,xyr,$yr,kyr,v4,MVe,Lc,F4,W8e,cx,Syr,H8e,Ryr,EVe,dr,fx,Pyr,yc,Byr,PY,Iyr,Nyr,BY,qyr,jyr,Dyr,mx,Gyr,U8e,Oyr,Vyr,Xyr,jt,gx,zyr,J8e,Qyr,Wyr,xc,Hyr,Y8e,Uyr,Jyr,IY,Yyr,Kyr,Zyr,T4,e9r,Nr,hx,o9r,K8e,r9r,t9r,pn,a9r,Z8e,n9r,s9r,eMe,l9r,i9r,oMe,d9r,c9r,f9r,rMe,M4,tMe,m9r,g9r,NY,h9r,p9r,_9r,E4,CVe,$c,C4,aMe,px,u9r,nMe,b9r,wVe,cr,_x,v9r,kc,F9r,qY,T9r,M9r,jY,E9r,C9r,w9r,ux,A9r,sMe,L9r,y9r,x9r,Dt,bx,$9r,lMe,k9r,S9r,Sc,R9r,iMe,P9r,B9r,DY,I9r,N9r,q9r,w4,j9r,qr,vx,D9r,dMe,G9r,O9r,_n,V9r,cMe,X9r,z9r,fMe,Q9r,W9r,mMe,H9r,U9r,J9r,de,A4,gMe,Y9r,K9r,GY,Z9r,exr,oxr,L4,hMe,rxr,txr,OY,axr,nxr,sxr,y4,pMe,lxr,ixr,VY,dxr,cxr,fxr,x4,_Me,mxr,gxr,XY,hxr,pxr,_xr,$4,uMe,uxr,bxr,zY,vxr,Fxr,Txr,k4,bMe,Mxr,Exr,QY,Cxr,wxr,Axr,S4,vMe,Lxr,yxr,WY,xxr,$xr,kxr,R4,FMe,Sxr,Rxr,HY,Pxr,Bxr,Ixr,P4,TMe,Nxr,qxr,UY,jxr,Dxr,Gxr,B4,MMe,Oxr,Vxr,JY,Xxr,zxr,Qxr,I4,EMe,Wxr,Hxr,YY,Uxr,Jxr,Yxr,N4,CMe,Kxr,Zxr,KY,e$r,o$r,r$r,q4,wMe,t$r,a$r,ZY,n$r,s$r,l$r,j4,AMe,i$r,d$r,eK,c$r,f$r,m$r,D4,LMe,g$r,h$r,oK,p$r,_$r,u$r,G4,yMe,b$r,v$r,rK,F$r,T$r,M$r,O4,xMe,E$r,C$r,tK,w$r,A$r,L$r,V4,$Me,y$r,x$r,aK,$$r,k$r,S$r,X4,kMe,R$r,P$r,nK,B$r,I$r,N$r,z4,SMe,q$r,j$r,sK,D$r,G$r,O$r,Q4,AVe,Rc,W4,RMe,Fx,V$r,PMe,X$r,LVe,fr,Tx,z$r,Pc,Q$r,lK,W$r,H$r,iK,U$r,J$r,Y$r,Mx,K$r,BMe,Z$r,ekr,okr,Gt,Ex,rkr,IMe,tkr,akr,Bc,nkr,NMe,skr,lkr,dK,ikr,dkr,ckr,H4,fkr,jr,Cx,mkr,qMe,gkr,hkr,un,pkr,jMe,_kr,ukr,DMe,bkr,vkr,GMe,Fkr,Tkr,Mkr,ce,U4,OMe,Ekr,Ckr,cK,wkr,Akr,Lkr,J4,VMe,ykr,xkr,fK,$kr,kkr,Skr,Y4,XMe,Rkr,Pkr,mK,Bkr,Ikr,Nkr,K4,zMe,qkr,jkr,gK,Dkr,Gkr,Okr,Z4,QMe,Vkr,Xkr,hK,zkr,Qkr,Wkr,eC,WMe,Hkr,Ukr,pK,Jkr,Ykr,Kkr,oC,HMe,Zkr,eSr,_K,oSr,rSr,tSr,rC,UMe,aSr,nSr,uK,sSr,lSr,iSr,tC,JMe,dSr,cSr,bK,fSr,mSr,gSr,aC,YMe,hSr,pSr,vK,_Sr,uSr,bSr,nC,KMe,vSr,FSr,FK,TSr,MSr,ESr,sC,ZMe,CSr,wSr,TK,ASr,LSr,ySr,lC,eEe,xSr,$Sr,MK,kSr,SSr,RSr,iC,oEe,PSr,BSr,EK,ISr,NSr,qSr,dC,rEe,jSr,DSr,CK,GSr,OSr,VSr,cC,tEe,XSr,zSr,wK,QSr,WSr,HSr,fC,aEe,USr,JSr,AK,YSr,KSr,ZSr,mC,nEe,eRr,oRr,LK,rRr,tRr,aRr,gC,sEe,nRr,sRr,yK,lRr,iRr,dRr,hC,lEe,cRr,fRr,xK,mRr,gRr,hRr,pC,yVe,Ic,_C,iEe,wx,pRr,dEe,_Rr,xVe,mr,Ax,uRr,Nc,bRr,$K,vRr,FRr,kK,TRr,MRr,ERr,Lx,CRr,cEe,wRr,ARr,LRr,Ot,yx,yRr,fEe,xRr,$Rr,qc,kRr,mEe,SRr,RRr,SK,PRr,BRr,IRr,uC,NRr,Dr,xx,qRr,gEe,jRr,DRr,bn,GRr,hEe,ORr,VRr,pEe,XRr,zRr,_Ee,QRr,WRr,HRr,uEe,bC,bEe,URr,JRr,RK,YRr,KRr,ZRr,vC,$Ve,jc,FC,vEe,$x,ePr,FEe,oPr,kVe,gr,kx,rPr,Dc,tPr,PK,aPr,nPr,BK,sPr,lPr,iPr,Sx,dPr,TEe,cPr,fPr,mPr,Vt,Rx,gPr,MEe,hPr,pPr,Gc,_Pr,EEe,uPr,bPr,IK,vPr,FPr,TPr,TC,MPr,Gr,Px,EPr,CEe,CPr,wPr,vn,APr,wEe,LPr,yPr,AEe,xPr,$Pr,LEe,kPr,SPr,RPr,yEe,MC,xEe,PPr,BPr,NK,IPr,NPr,qPr,EC,SVe,Oc,CC,$Ee,Bx,jPr,kEe,DPr,RVe,hr,Ix,GPr,Vc,OPr,qK,VPr,XPr,jK,zPr,QPr,WPr,Nx,HPr,SEe,UPr,JPr,YPr,Xt,qx,KPr,REe,ZPr,eBr,Xc,oBr,PEe,rBr,tBr,DK,aBr,nBr,sBr,wC,lBr,Or,jx,iBr,BEe,dBr,cBr,Fn,fBr,IEe,mBr,gBr,NEe,hBr,pBr,qEe,_Br,uBr,bBr,oe,AC,jEe,vBr,FBr,GK,TBr,MBr,EBr,LC,DEe,CBr,wBr,OK,ABr,LBr,yBr,yC,GEe,xBr,$Br,VK,kBr,SBr,RBr,xC,OEe,PBr,BBr,XK,IBr,NBr,qBr,$C,VEe,jBr,DBr,zK,GBr,OBr,VBr,kC,XEe,XBr,zBr,QK,QBr,WBr,HBr,SC,zEe,UBr,JBr,WK,YBr,KBr,ZBr,RC,QEe,eIr,oIr,HK,rIr,tIr,aIr,PC,WEe,nIr,sIr,UK,lIr,iIr,dIr,BC,HEe,cIr,fIr,JK,mIr,gIr,hIr,IC,UEe,pIr,_Ir,YK,uIr,bIr,vIr,NC,JEe,FIr,TIr,KK,MIr,EIr,CIr,qC,YEe,wIr,AIr,ZK,LIr,yIr,xIr,jC,KEe,$Ir,kIr,eZ,SIr,RIr,PIr,DC,ZEe,BIr,IIr,oZ,NIr,qIr,jIr,GC,e4e,DIr,GIr,rZ,OIr,VIr,XIr,OC,o4e,zIr,QIr,tZ,WIr,HIr,UIr,VC,r4e,JIr,YIr,aZ,KIr,ZIr,eNr,XC,t4e,oNr,rNr,nZ,tNr,aNr,nNr,zC,a4e,sNr,lNr,sZ,iNr,dNr,cNr,QC,n4e,fNr,mNr,lZ,gNr,hNr,pNr,WC,s4e,_Nr,uNr,iZ,bNr,vNr,FNr,HC,l4e,TNr,MNr,dZ,ENr,CNr,wNr,UC,i4e,ANr,LNr,cZ,yNr,xNr,$Nr,JC,d4e,kNr,SNr,fZ,RNr,PNr,BNr,YC,c4e,INr,NNr,mZ,qNr,jNr,DNr,KC,f4e,GNr,ONr,gZ,VNr,XNr,zNr,ZC,PVe,zc,e5,m4e,Dx,QNr,g4e,WNr,BVe,pr,Gx,HNr,Qc,UNr,hZ,JNr,YNr,pZ,KNr,ZNr,eqr,Ox,oqr,h4e,rqr,tqr,aqr,zt,Vx,nqr,p4e,sqr,lqr,Wc,iqr,_4e,dqr,cqr,_Z,fqr,mqr,gqr,o5,hqr,Vr,Xx,pqr,u4e,_qr,uqr,Tn,bqr,b4e,vqr,Fqr,v4e,Tqr,Mqr,F4e,Eqr,Cqr,wqr,xe,r5,T4e,Aqr,Lqr,uZ,yqr,xqr,$qr,t5,M4e,kqr,Sqr,bZ,Rqr,Pqr,Bqr,a5,E4e,Iqr,Nqr,vZ,qqr,jqr,Dqr,n5,C4e,Gqr,Oqr,FZ,Vqr,Xqr,zqr,s5,w4e,Qqr,Wqr,TZ,Hqr,Uqr,Jqr,l5,A4e,Yqr,Kqr,MZ,Zqr,ejr,ojr,i5,L4e,rjr,tjr,EZ,ajr,njr,sjr,d5,y4e,ljr,ijr,CZ,djr,cjr,fjr,c5,x4e,mjr,gjr,wZ,hjr,pjr,_jr,f5,$4e,ujr,bjr,AZ,vjr,Fjr,Tjr,m5,IVe,Hc,g5,k4e,zx,Mjr,S4e,Ejr,NVe,_r,Qx,Cjr,Uc,wjr,LZ,Ajr,Ljr,yZ,yjr,xjr,$jr,Wx,kjr,R4e,Sjr,Rjr,Pjr,Qt,Hx,Bjr,P4e,Ijr,Njr,Jc,qjr,B4e,jjr,Djr,xZ,Gjr,Ojr,Vjr,h5,Xjr,Xr,Ux,zjr,I4e,Qjr,Wjr,Mn,Hjr,N4e,Ujr,Jjr,q4e,Yjr,Kjr,j4e,Zjr,eDr,oDr,Ee,p5,D4e,rDr,tDr,$Z,aDr,nDr,sDr,_5,G4e,lDr,iDr,kZ,dDr,cDr,fDr,u5,O4e,mDr,gDr,SZ,hDr,pDr,_Dr,b5,V4e,uDr,bDr,RZ,vDr,FDr,TDr,v5,X4e,MDr,EDr,PZ,CDr,wDr,ADr,F5,z4e,LDr,yDr,BZ,xDr,$Dr,kDr,T5,Q4e,SDr,RDr,IZ,PDr,BDr,IDr,M5,W4e,NDr,qDr,NZ,jDr,DDr,GDr,E5,H4e,ODr,VDr,qZ,XDr,zDr,QDr,C5,U4e,WDr,HDr,jZ,UDr,JDr,YDr,w5,J4e,KDr,ZDr,DZ,eGr,oGr,rGr,A5,Y4e,tGr,aGr,GZ,nGr,sGr,lGr,L5,K4e,iGr,dGr,OZ,cGr,fGr,mGr,y5,qVe,Yc,x5,Z4e,Jx,gGr,eCe,hGr,jVe,ur,Yx,pGr,Kc,_Gr,VZ,uGr,bGr,XZ,vGr,FGr,TGr,Kx,MGr,oCe,EGr,CGr,wGr,Wt,Zx,AGr,rCe,LGr,yGr,Zc,xGr,tCe,$Gr,kGr,zZ,SGr,RGr,PGr,$5,BGr,zr,e$,IGr,aCe,NGr,qGr,En,jGr,nCe,DGr,GGr,sCe,OGr,VGr,lCe,XGr,zGr,QGr,$e,k5,iCe,WGr,HGr,QZ,UGr,JGr,YGr,S5,dCe,KGr,ZGr,WZ,eOr,oOr,rOr,R5,cCe,tOr,aOr,HZ,nOr,sOr,lOr,P5,fCe,iOr,dOr,UZ,cOr,fOr,mOr,B5,mCe,gOr,hOr,JZ,pOr,_Or,uOr,I5,gCe,bOr,vOr,YZ,FOr,TOr,MOr,N5,hCe,EOr,COr,KZ,wOr,AOr,LOr,q5,pCe,yOr,xOr,ZZ,$Or,kOr,SOr,j5,_Ce,ROr,POr,eee,BOr,IOr,NOr,D5,uCe,qOr,jOr,oee,DOr,GOr,OOr,G5,DVe,ef,O5,bCe,o$,VOr,vCe,XOr,GVe,br,r$,zOr,of,QOr,ree,WOr,HOr,tee,UOr,JOr,YOr,t$,KOr,FCe,ZOr,eVr,oVr,Ht,a$,rVr,TCe,tVr,aVr,rf,nVr,MCe,sVr,lVr,aee,iVr,dVr,cVr,V5,fVr,Qr,n$,mVr,ECe,gVr,hVr,Cn,pVr,CCe,_Vr,uVr,wCe,bVr,vVr,ACe,FVr,TVr,MVr,ke,X5,LCe,EVr,CVr,nee,wVr,AVr,LVr,z5,yCe,yVr,xVr,see,$Vr,kVr,SVr,Q5,xCe,RVr,PVr,lee,BVr,IVr,NVr,W5,$Ce,qVr,jVr,iee,DVr,GVr,OVr,H5,kCe,VVr,XVr,dee,zVr,QVr,WVr,U5,SCe,HVr,UVr,cee,JVr,YVr,KVr,J5,RCe,ZVr,eXr,fee,oXr,rXr,tXr,Y5,PCe,aXr,nXr,mee,sXr,lXr,iXr,K5,BCe,dXr,cXr,gee,fXr,mXr,gXr,Z5,ICe,hXr,pXr,hee,_Xr,uXr,bXr,e3,OVe,tf,o3,NCe,s$,vXr,qCe,FXr,VVe,vr,l$,TXr,af,MXr,pee,EXr,CXr,_ee,wXr,AXr,LXr,i$,yXr,jCe,xXr,$Xr,kXr,Ut,d$,SXr,DCe,RXr,PXr,nf,BXr,GCe,IXr,NXr,uee,qXr,jXr,DXr,r3,GXr,Wr,c$,OXr,OCe,VXr,XXr,wn,zXr,VCe,QXr,WXr,XCe,HXr,UXr,zCe,JXr,YXr,KXr,Se,t3,QCe,ZXr,ezr,bee,ozr,rzr,tzr,a3,WCe,azr,nzr,vee,szr,lzr,izr,n3,HCe,dzr,czr,Fee,fzr,mzr,gzr,s3,UCe,hzr,pzr,Tee,_zr,uzr,bzr,l3,JCe,vzr,Fzr,Mee,Tzr,Mzr,Ezr,i3,YCe,Czr,wzr,Eee,Azr,Lzr,yzr,d3,KCe,xzr,$zr,Cee,kzr,Szr,Rzr,c3,ZCe,Pzr,Bzr,wee,Izr,Nzr,qzr,f3,e5e,jzr,Dzr,Aee,Gzr,Ozr,Vzr,m3,o5e,Xzr,zzr,Lee,Qzr,Wzr,Hzr,g3,XVe,sf,h3,r5e,f$,Uzr,t5e,Jzr,zVe,Fr,m$,Yzr,lf,Kzr,yee,Zzr,eQr,xee,oQr,rQr,tQr,g$,aQr,a5e,nQr,sQr,lQr,Jt,h$,iQr,n5e,dQr,cQr,df,fQr,s5e,mQr,gQr,$ee,hQr,pQr,_Qr,p3,uQr,Hr,p$,bQr,l5e,vQr,FQr,An,TQr,i5e,MQr,EQr,d5e,CQr,wQr,c5e,AQr,LQr,yQr,Re,_3,f5e,xQr,$Qr,kee,kQr,SQr,RQr,u3,m5e,PQr,BQr,See,IQr,NQr,qQr,b3,g5e,jQr,DQr,Ree,GQr,OQr,VQr,v3,h5e,XQr,zQr,Pee,QQr,WQr,HQr,F3,p5e,UQr,JQr,Bee,YQr,KQr,ZQr,T3,_5e,eWr,oWr,Iee,rWr,tWr,aWr,M3,u5e,nWr,sWr,Nee,lWr,iWr,dWr,E3,b5e,cWr,fWr,qee,mWr,gWr,hWr,C3,v5e,pWr,_Wr,jee,uWr,bWr,vWr,w3,F5e,FWr,TWr,Dee,MWr,EWr,CWr,A3,QVe,cf,L3,T5e,_$,wWr,M5e,AWr,WVe,Tr,u$,LWr,ff,yWr,Gee,xWr,$Wr,Oee,kWr,SWr,RWr,b$,PWr,E5e,BWr,IWr,NWr,Yt,v$,qWr,C5e,jWr,DWr,mf,GWr,w5e,OWr,VWr,Vee,XWr,zWr,QWr,y3,WWr,Ur,F$,HWr,A5e,UWr,JWr,Ln,YWr,L5e,KWr,ZWr,y5e,eHr,oHr,x5e,rHr,tHr,aHr,Ve,x3,$5e,nHr,sHr,Xee,lHr,iHr,dHr,$3,k5e,cHr,fHr,zee,mHr,gHr,hHr,k3,S5e,pHr,_Hr,Qee,uHr,bHr,vHr,S3,R5e,FHr,THr,Wee,MHr,EHr,CHr,R3,P5e,wHr,AHr,Hee,LHr,yHr,xHr,P3,B5e,$Hr,kHr,Uee,SHr,RHr,PHr,B3,I5e,BHr,IHr,Jee,NHr,qHr,jHr,I3,N5e,DHr,GHr,Yee,OHr,VHr,XHr,N3,HVe,gf,q3,q5e,T$,zHr,j5e,QHr,UVe,Mr,M$,WHr,hf,HHr,Kee,UHr,JHr,Zee,YHr,KHr,ZHr,E$,eUr,D5e,oUr,rUr,tUr,Kt,C$,aUr,G5e,nUr,sUr,pf,lUr,O5e,iUr,dUr,eoe,cUr,fUr,mUr,j3,gUr,Jr,w$,hUr,V5e,pUr,_Ur,yn,uUr,X5e,bUr,vUr,z5e,FUr,TUr,Q5e,MUr,EUr,CUr,Xe,D3,W5e,wUr,AUr,ooe,LUr,yUr,xUr,G3,H5e,$Ur,kUr,roe,SUr,RUr,PUr,O3,U5e,BUr,IUr,toe,NUr,qUr,jUr,V3,J5e,DUr,GUr,aoe,OUr,VUr,XUr,X3,Y5e,zUr,QUr,noe,WUr,HUr,UUr,z3,K5e,JUr,YUr,soe,KUr,ZUr,eJr,Q3,Z5e,oJr,rJr,loe,tJr,aJr,nJr,W3,e3e,sJr,lJr,ioe,iJr,dJr,cJr,H3,JVe,_f,U3,o3e,A$,fJr,r3e,mJr,YVe,Er,L$,gJr,uf,hJr,doe,pJr,_Jr,coe,uJr,bJr,vJr,y$,FJr,t3e,TJr,MJr,EJr,Zt,x$,CJr,a3e,wJr,AJr,bf,LJr,n3e,yJr,xJr,foe,$Jr,kJr,SJr,J3,RJr,Yr,$$,PJr,s3e,BJr,IJr,xn,NJr,l3e,qJr,jJr,i3e,DJr,GJr,d3e,OJr,VJr,XJr,c3e,Y3,f3e,zJr,QJr,moe,WJr,HJr,UJr,K3,KVe,vf,Z3,m3e,k$,JJr,g3e,YJr,ZVe,Cr,S$,KJr,Ff,ZJr,goe,eYr,oYr,hoe,rYr,tYr,aYr,R$,nYr,h3e,sYr,lYr,iYr,ea,P$,dYr,p3e,cYr,fYr,Tf,mYr,_3e,gYr,hYr,poe,pYr,_Yr,uYr,e0,bYr,Kr,B$,vYr,u3e,FYr,TYr,$n,MYr,b3e,EYr,CYr,v3e,wYr,AYr,F3e,LYr,yYr,xYr,I$,o0,T3e,$Yr,kYr,_oe,SYr,RYr,PYr,r0,M3e,BYr,IYr,uoe,NYr,qYr,jYr,t0,eXe,Mf,a0,E3e,N$,DYr,C3e,GYr,oXe,wr,q$,OYr,Ef,VYr,boe,XYr,zYr,voe,QYr,WYr,HYr,j$,UYr,w3e,JYr,YYr,KYr,oa,D$,ZYr,A3e,eKr,oKr,Cf,rKr,L3e,tKr,aKr,Foe,nKr,sKr,lKr,n0,iKr,Zr,G$,dKr,y3e,cKr,fKr,kn,mKr,x3e,gKr,hKr,$3e,pKr,_Kr,k3e,uKr,bKr,vKr,S3e,s0,R3e,FKr,TKr,Toe,MKr,EKr,CKr,l0,rXe;return d=new re({}),xa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),SA=new re({}),RA=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Rf=new wKr({props:{warning:!0,$$slots:{default:[tGt]},$$scope:{ctx:x}}}),PA=new re({}),BA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/configuration_auto.py#L601"}}),qA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/configuration_auto.py#L624"}}),Og=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),jA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/configuration_auto.py#L747"}}),DA=new re({}),GA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/tokenization_auto.py#L401"}}),XA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17826/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/tokenization_auto.py#L415"}}),wh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),zA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/tokenization_auto.py#L614"}}),QA=new re({}),WA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),JA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17826/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/feature_extraction_auto.py#L207"}}),sp=new wKr({props:{$$slots:{default:[sGt]},$$scope:{ctx:x}}}),lp=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[lGt]},$$scope:{ctx:x}}}),YA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/feature_extraction_auto.py#L334"}}),KA=new re({}),ZA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/processing_auto.py#L88"}}),rL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/processing_auto.py#L102"}}),Lp=new wKr({props:{$$slots:{default:[iGt]},$$scope:{ctx:x}}}),yp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[dGt]},$$scope:{ctx:x}}}),tL=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/processing_auto.py#L255"}}),aL=new re({}),nL=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L768"}}),lL=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/jukebox#transformers.JukeboxConfig">JukeboxConfig</a> configuration class: <code>JukeboxModel</code> (Jukebox model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),kp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[cGt]},$$scope:{ctx:x}}}),iL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),Su=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[fGt]},$$scope:{ctx:x}}}),dL=new re({}),cL=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L775"}}),mL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),Pu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[mGt]},$$scope:{ctx:x}}}),gL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),A2=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[gGt]},$$scope:{ctx:x}}}),hL=new re({}),pL=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L790"}}),uL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),y2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[hGt]},$$scope:{ctx:x}}}),bL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),h1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[pGt]},$$scope:{ctx:x}}}),vL=new re({}),FL=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L797"}}),ML=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),_1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[_Gt]},$$scope:{ctx:x}}}),EL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),ob=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[uGt]},$$scope:{ctx:x}}}),CL=new re({}),wL=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L804"}}),LL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),tb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[bGt]},$$scope:{ctx:x}}}),yL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),Mb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[vGt]},$$scope:{ctx:x}}}),xL=new re({}),$L=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L813"}}),SL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),Cb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[FGt]},$$scope:{ctx:x}}}),RL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),Tv=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[TGt]},$$scope:{ctx:x}}}),PL=new re({}),BL=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L858"}}),NL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),Ev=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[MGt]},$$scope:{ctx:x}}}),qL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),oF=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[EGt]},$$scope:{ctx:x}}}),jL=new re({}),DL=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L865"}}),OL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),tF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[CGt]},$$scope:{ctx:x}}}),VL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),fF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[wGt]},$$scope:{ctx:x}}}),XL=new re({}),zL=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L851"}}),WL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),gF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[AGt]},$$scope:{ctx:x}}}),HL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),YF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[LGt]},$$scope:{ctx:x}}}),UL=new re({}),JL=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L822"}}),KL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),ZF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[yGt]},$$scope:{ctx:x}}}),ZL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),O6=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[xGt]},$$scope:{ctx:x}}}),ey=new re({}),oy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L829"}}),ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),X6=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[$Gt]},$$scope:{ctx:x}}}),ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),W6=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[kGt]},$$scope:{ctx:x}}}),ny=new re({}),sy=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L874"}}),iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),U6=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[SGt]},$$scope:{ctx:x}}}),dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),dT=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[RGt]},$$scope:{ctx:x}}}),cy=new re({}),fy=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L913"}}),gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),fT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[PGt]},$$scope:{ctx:x}}}),hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),hT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[BGt]},$$scope:{ctx:x}}}),py=new re({}),_y=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L840"}}),by=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),_T=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[IGt]},$$scope:{ctx:x}}}),vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),vT=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[NGt]},$$scope:{ctx:x}}}),Fy=new re({}),Ty=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L920"}}),Ey=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),TT=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[qGt]},$$scope:{ctx:x}}}),Cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),ST=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[jGt]},$$scope:{ctx:x}}}),wy=new re({}),Ay=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L943"}}),yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),PT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[DGt]},$$scope:{ctx:x}}}),xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),GT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[GGt]},$$scope:{ctx:x}}}),$y=new re({}),ky=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L927"}}),Ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),VT=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[OGt]},$$scope:{ctx:x}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),o7=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[VGt]},$$scope:{ctx:x}}}),By=new re({}),Iy=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L934"}}),qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),t7=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[XGt]},$$scope:{ctx:x}}}),jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),l7=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[zGt]},$$scope:{ctx:x}}}),Gy=new re({}),Oy=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L952"}}),Xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),d7=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[QGt]},$$scope:{ctx:x}}}),zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),_7=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[WGt]},$$scope:{ctx:x}}}),Qy=new re({}),Wy=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L959"}}),Uy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),b7=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[HGt]},$$scope:{ctx:x}}}),Jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),E7=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[UGt]},$$scope:{ctx:x}}}),Yy=new re({}),Ky=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L906"}}),e9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),w7=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[JGt]},$$scope:{ctx:x}}}),o9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),x7=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[YGt]},$$scope:{ctx:x}}}),t9=new re({}),a9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L881"}}),s9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),k7=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[KGt]},$$scope:{ctx:x}}}),l9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[ZGt]},$$scope:{ctx:x}}}),i9=new re({}),d9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L888"}}),f9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[eOt]},$$scope:{ctx:x}}}),m9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),O7=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[oOt]},$$scope:{ctx:x}}}),g9=new re({}),h9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_auto.py#L897"}}),_9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),X7=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[rOt]},$$scope:{ctx:x}}}),u9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),W7=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[tOt]},$$scope:{ctx:x}}}),b9=new re({}),v9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),T9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),U7=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[aOt]},$$scope:{ctx:x}}}),M9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),O8=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[nOt]},$$scope:{ctx:x}}}),E9=new re({}),C9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),A9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),X8=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[sOt]},$$scope:{ctx:x}}}),L9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),hM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[lOt]},$$scope:{ctx:x}}}),y9=new re({}),x9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),k9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),_M=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[iOt]},$$scope:{ctx:x}}}),S9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),$M=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[dOt]},$$scope:{ctx:x}}}),R9=new re({}),P9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),I9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),SM=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[cOt]},$$scope:{ctx:x}}}),N9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),NM=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[fOt]},$$scope:{ctx:x}}}),q9=new re({}),j9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),G9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),jM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[mOt]},$$scope:{ctx:x}}}),O9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),sE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[gOt]},$$scope:{ctx:x}}}),V9=new re({}),X9=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),Q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),iE=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[hOt]},$$scope:{ctx:x}}}),W9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),vE=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[pOt]},$$scope:{ctx:x}}}),H9=new re({}),U9=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),Y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),TE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[_Ot]},$$scope:{ctx:x}}}),K9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),HE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[uOt]},$$scope:{ctx:x}}}),Z9=new re({}),ex=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),rx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),JE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[bOt]},$$scope:{ctx:x}}}),tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),h4=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[vOt]},$$scope:{ctx:x}}}),ax=new re({}),nx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),lx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),_4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[FOt]},$$scope:{ctx:x}}}),ix=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),v4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[TOt]},$$scope:{ctx:x}}}),cx=new re({}),fx=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),gx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),T4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[MOt]},$$scope:{ctx:x}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),E4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[EOt]},$$scope:{ctx:x}}}),px=new re({}),_x=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),bx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),w4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[COt]},$$scope:{ctx:x}}}),vx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),Q4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[wOt]},$$scope:{ctx:x}}}),Fx=new re({}),Tx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),H4=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[AOt]},$$scope:{ctx:x}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),pC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[LOt]},$$scope:{ctx:x}}}),wx=new re({}),Ax=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),yx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),uC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[yOt]},$$scope:{ctx:x}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),vC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[xOt]},$$scope:{ctx:x}}}),$x=new re({}),kx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),TC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[$Ot]},$$scope:{ctx:x}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),EC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[kOt]},$$scope:{ctx:x}}}),Bx=new re({}),Ix=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),qx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),wC=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[SOt]},$$scope:{ctx:x}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),ZC=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[ROt]},$$scope:{ctx:x}}}),Dx=new re({}),Gx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),o5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[POt]},$$scope:{ctx:x}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[BOt]},$$scope:{ctx:x}}}),zx=new re({}),Qx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),Hx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),h5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[IOt]},$$scope:{ctx:x}}}),Ux=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),y5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[NOt]},$$scope:{ctx:x}}}),Jx=new re({}),Yx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),$5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[qOt]},$$scope:{ctx:x}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),G5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[jOt]},$$scope:{ctx:x}}}),o$=new re({}),r$=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),a$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),V5=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[DOt]},$$scope:{ctx:x}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),e3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[GOt]},$$scope:{ctx:x}}}),s$=new re({}),l$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),d$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),r3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[OOt]},$$scope:{ctx:x}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),g3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[VOt]},$$scope:{ctx:x}}}),f$=new re({}),m$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),h$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),p3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[XOt]},$$scope:{ctx:x}}}),p$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),A3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[zOt]},$$scope:{ctx:x}}}),_$=new re({}),u$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),v$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),y3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[QOt]},$$scope:{ctx:x}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),N3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[WOt]},$$scope:{ctx:x}}}),T$=new re({}),M$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),C$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),j3=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[HOt]},$$scope:{ctx:x}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),H3=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[UOt]},$$scope:{ctx:x}}}),A$=new re({}),L$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),x$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),J3=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[JOt]},$$scope:{ctx:x}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),K3=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[YOt]},$$scope:{ctx:x}}}),k$=new re({}),S$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),P$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),e0=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[KOt]},$$scope:{ctx:x}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),t0=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[ZOt]},$$scope:{ctx:x}}}),N$=new re({}),q$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),D$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L389"}}),n0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[eVt]},$$scope:{ctx:x}}}),G$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17826/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17826/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17826/src/transformers/models/auto/auto_factory.py#L417"}}),l0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[oVt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ti=o("Auto Classes"),yf=l(),at=a("p"),Mi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=a("code"),yA=o("from_pretrained()"),xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),Ci=o("Instantiating one of "),Rn=a("a"),xA=o("AutoConfig"),Pn=o(", "),Bn=a("a"),$A=o("AutoModel"),wi=o(`, and
`),In=a("a"),kA=o("AutoTokenizer"),Ai=o(" will directly create a class of the relevant architecture. For instance"),$f=l(),F(xa.$$.fragment),We=l(),Ae=a("p"),nS=o("will create a model that is an instance of "),Li=a("a"),sS=o("BertModel"),lS=o("."),Co=l(),$a=a("p"),iS=o("There is one class of "),kf=a("code"),dS=o("AutoModel"),mQe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),YGe=l(),yi=a("h2"),Sf=a("a"),_te=a("span"),F(SA.$$.fragment),gQe=l(),ute=a("span"),hQe=o("Extending the Auto Classes"),KGe=l(),Nn=a("p"),pQe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),bte=a("code"),_Qe=o("NewModel"),uQe=o(", make sure you have a "),vte=a("code"),bQe=o("NewModelConfig"),vQe=o(` then you can add those to the auto
classes like this:`),ZGe=l(),F(RA.$$.fragment),eOe=l(),cS=a("p"),FQe=o("You will then be able to use the auto classes like you would usually do!"),oOe=l(),F(Rf.$$.fragment),rOe=l(),xi=a("h2"),Pf=a("a"),Fte=a("span"),F(PA.$$.fragment),TQe=l(),Tte=a("span"),MQe=o("AutoConfig"),tOe=l(),wo=a("div"),F(BA.$$.fragment),EQe=l(),IA=a("p"),CQe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),fS=a("a"),wQe=o("from_pretrained()"),AQe=o(" class method."),LQe=l(),NA=a("p"),yQe=o("This class cannot be instantiated directly using "),Mte=a("code"),xQe=o("__init__()"),$Qe=o(" (throws an error)."),kQe=l(),Ar=a("div"),F(qA.$$.fragment),SQe=l(),Ete=a("p"),RQe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),PQe=l(),$i=a("p"),BQe=o("The configuration class to instantiate is selected based on the "),Cte=a("code"),IQe=o("model_type"),NQe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),wte=a("code"),qQe=o("pretrained_model_name_or_path"),jQe=o(":"),DQe=l(),A=a("ul"),Bf=a("li"),Ate=a("strong"),GQe=o("albert"),OQe=o(" \u2014 "),mS=a("a"),VQe=o("AlbertConfig"),XQe=o(" (ALBERT model)"),zQe=l(),If=a("li"),Lte=a("strong"),QQe=o("bart"),WQe=o(" \u2014 "),gS=a("a"),HQe=o("BartConfig"),UQe=o(" (BART model)"),JQe=l(),Nf=a("li"),yte=a("strong"),YQe=o("beit"),KQe=o(" \u2014 "),hS=a("a"),ZQe=o("BeitConfig"),eWe=o(" (BEiT model)"),oWe=l(),qf=a("li"),xte=a("strong"),rWe=o("bert"),tWe=o(" \u2014 "),pS=a("a"),aWe=o("BertConfig"),nWe=o(" (BERT model)"),sWe=l(),jf=a("li"),$te=a("strong"),lWe=o("bert-generation"),iWe=o(" \u2014 "),_S=a("a"),dWe=o("BertGenerationConfig"),cWe=o(" (Bert Generation model)"),fWe=l(),Df=a("li"),kte=a("strong"),mWe=o("big_bird"),gWe=o(" \u2014 "),uS=a("a"),hWe=o("BigBirdConfig"),pWe=o(" (BigBird model)"),_We=l(),Gf=a("li"),Ste=a("strong"),uWe=o("bigbird_pegasus"),bWe=o(" \u2014 "),bS=a("a"),vWe=o("BigBirdPegasusConfig"),FWe=o(" (BigBird-Pegasus model)"),TWe=l(),Of=a("li"),Rte=a("strong"),MWe=o("blenderbot"),EWe=o(" \u2014 "),vS=a("a"),CWe=o("BlenderbotConfig"),wWe=o(" (Blenderbot model)"),AWe=l(),Vf=a("li"),Pte=a("strong"),LWe=o("blenderbot-small"),yWe=o(" \u2014 "),FS=a("a"),xWe=o("BlenderbotSmallConfig"),$We=o(" (BlenderbotSmall model)"),kWe=l(),Xf=a("li"),Bte=a("strong"),SWe=o("bloom"),RWe=o(" \u2014 "),TS=a("a"),PWe=o("BloomConfig"),BWe=o(" (BLOOM model)"),IWe=l(),zf=a("li"),Ite=a("strong"),NWe=o("camembert"),qWe=o(" \u2014 "),MS=a("a"),jWe=o("CamembertConfig"),DWe=o(" (CamemBERT model)"),GWe=l(),Qf=a("li"),Nte=a("strong"),OWe=o("canine"),VWe=o(" \u2014 "),ES=a("a"),XWe=o("CanineConfig"),zWe=o(" (CANINE model)"),QWe=l(),Wf=a("li"),qte=a("strong"),WWe=o("clip"),HWe=o(" \u2014 "),CS=a("a"),UWe=o("CLIPConfig"),JWe=o(" (CLIP model)"),YWe=l(),Hf=a("li"),jte=a("strong"),KWe=o("convbert"),ZWe=o(" \u2014 "),wS=a("a"),eHe=o("ConvBertConfig"),oHe=o(" (ConvBERT model)"),rHe=l(),Uf=a("li"),Dte=a("strong"),tHe=o("convnext"),aHe=o(" \u2014 "),AS=a("a"),nHe=o("ConvNextConfig"),sHe=o(" (ConvNeXT model)"),lHe=l(),Jf=a("li"),Gte=a("strong"),iHe=o("ctrl"),dHe=o(" \u2014 "),LS=a("a"),cHe=o("CTRLConfig"),fHe=o(" (CTRL model)"),mHe=l(),Yf=a("li"),Ote=a("strong"),gHe=o("cvt"),hHe=o(" \u2014 "),yS=a("a"),pHe=o("CvtConfig"),_He=o(" (CvT model)"),uHe=l(),Kf=a("li"),Vte=a("strong"),bHe=o("data2vec-audio"),vHe=o(" \u2014 "),xS=a("a"),FHe=o("Data2VecAudioConfig"),THe=o(" (Data2VecAudio model)"),MHe=l(),Zf=a("li"),Xte=a("strong"),EHe=o("data2vec-text"),CHe=o(" \u2014 "),$S=a("a"),wHe=o("Data2VecTextConfig"),AHe=o(" (Data2VecText model)"),LHe=l(),em=a("li"),zte=a("strong"),yHe=o("data2vec-vision"),xHe=o(" \u2014 "),kS=a("a"),$He=o("Data2VecVisionConfig"),kHe=o(" (Data2VecVision model)"),SHe=l(),om=a("li"),Qte=a("strong"),RHe=o("deberta"),PHe=o(" \u2014 "),SS=a("a"),BHe=o("DebertaConfig"),IHe=o(" (DeBERTa model)"),NHe=l(),rm=a("li"),Wte=a("strong"),qHe=o("deberta-v2"),jHe=o(" \u2014 "),RS=a("a"),DHe=o("DebertaV2Config"),GHe=o(" (DeBERTa-v2 model)"),OHe=l(),tm=a("li"),Hte=a("strong"),VHe=o("decision_transformer"),XHe=o(" \u2014 "),PS=a("a"),zHe=o("DecisionTransformerConfig"),QHe=o(" (Decision Transformer model)"),WHe=l(),am=a("li"),Ute=a("strong"),HHe=o("deit"),UHe=o(" \u2014 "),BS=a("a"),JHe=o("DeiTConfig"),YHe=o(" (DeiT model)"),KHe=l(),nm=a("li"),Jte=a("strong"),ZHe=o("detr"),eUe=o(" \u2014 "),IS=a("a"),oUe=o("DetrConfig"),rUe=o(" (DETR model)"),tUe=l(),sm=a("li"),Yte=a("strong"),aUe=o("distilbert"),nUe=o(" \u2014 "),NS=a("a"),sUe=o("DistilBertConfig"),lUe=o(" (DistilBERT model)"),iUe=l(),lm=a("li"),Kte=a("strong"),dUe=o("dpr"),cUe=o(" \u2014 "),qS=a("a"),fUe=o("DPRConfig"),mUe=o(" (DPR model)"),gUe=l(),im=a("li"),Zte=a("strong"),hUe=o("dpt"),pUe=o(" \u2014 "),jS=a("a"),_Ue=o("DPTConfig"),uUe=o(" (DPT model)"),bUe=l(),dm=a("li"),eae=a("strong"),vUe=o("electra"),FUe=o(" \u2014 "),DS=a("a"),TUe=o("ElectraConfig"),MUe=o(" (ELECTRA model)"),EUe=l(),cm=a("li"),oae=a("strong"),CUe=o("encoder-decoder"),wUe=o(" \u2014 "),GS=a("a"),AUe=o("EncoderDecoderConfig"),LUe=o(" (Encoder decoder model)"),yUe=l(),fm=a("li"),rae=a("strong"),xUe=o("flaubert"),$Ue=o(" \u2014 "),OS=a("a"),kUe=o("FlaubertConfig"),SUe=o(" (FlauBERT model)"),RUe=l(),mm=a("li"),tae=a("strong"),PUe=o("flava"),BUe=o(" \u2014 "),VS=a("a"),IUe=o("FlavaConfig"),NUe=o(" (FLAVA model)"),qUe=l(),gm=a("li"),aae=a("strong"),jUe=o("fnet"),DUe=o(" \u2014 "),XS=a("a"),GUe=o("FNetConfig"),OUe=o(" (FNet model)"),VUe=l(),hm=a("li"),nae=a("strong"),XUe=o("fsmt"),zUe=o(" \u2014 "),zS=a("a"),QUe=o("FSMTConfig"),WUe=o(" (FairSeq Machine-Translation model)"),HUe=l(),pm=a("li"),sae=a("strong"),UUe=o("funnel"),JUe=o(" \u2014 "),QS=a("a"),YUe=o("FunnelConfig"),KUe=o(" (Funnel Transformer model)"),ZUe=l(),_m=a("li"),lae=a("strong"),eJe=o("glpn"),oJe=o(" \u2014 "),WS=a("a"),rJe=o("GLPNConfig"),tJe=o(" (GLPN model)"),aJe=l(),um=a("li"),iae=a("strong"),nJe=o("gpt2"),sJe=o(" \u2014 "),HS=a("a"),lJe=o("GPT2Config"),iJe=o(" (OpenAI GPT-2 model)"),dJe=l(),bm=a("li"),dae=a("strong"),cJe=o("gpt_neo"),fJe=o(" \u2014 "),US=a("a"),mJe=o("GPTNeoConfig"),gJe=o(" (GPT Neo model)"),hJe=l(),vm=a("li"),cae=a("strong"),pJe=o("gpt_neox"),_Je=o(" \u2014 "),JS=a("a"),uJe=o("GPTNeoXConfig"),bJe=o(" (GPT NeoX model)"),vJe=l(),Fm=a("li"),fae=a("strong"),FJe=o("gptj"),TJe=o(" \u2014 "),YS=a("a"),MJe=o("GPTJConfig"),EJe=o(" (GPT-J model)"),CJe=l(),Tm=a("li"),mae=a("strong"),wJe=o("hubert"),AJe=o(" \u2014 "),KS=a("a"),LJe=o("HubertConfig"),yJe=o(" (Hubert model)"),xJe=l(),Mm=a("li"),gae=a("strong"),$Je=o("ibert"),kJe=o(" \u2014 "),ZS=a("a"),SJe=o("IBertConfig"),RJe=o(" (I-BERT model)"),PJe=l(),Em=a("li"),hae=a("strong"),BJe=o("imagegpt"),IJe=o(" \u2014 "),eR=a("a"),NJe=o("ImageGPTConfig"),qJe=o(" (ImageGPT model)"),jJe=l(),Cm=a("li"),pae=a("strong"),DJe=o("jukebox"),GJe=o(" \u2014 "),oR=a("a"),OJe=o("JukeboxConfig"),VJe=o(" (Jukebox model)"),XJe=l(),wm=a("li"),_ae=a("strong"),zJe=o("layoutlm"),QJe=o(" \u2014 "),rR=a("a"),WJe=o("LayoutLMConfig"),HJe=o(" (LayoutLM model)"),UJe=l(),Am=a("li"),uae=a("strong"),JJe=o("layoutlmv2"),YJe=o(" \u2014 "),tR=a("a"),KJe=o("LayoutLMv2Config"),ZJe=o(" (LayoutLMv2 model)"),eYe=l(),Lm=a("li"),bae=a("strong"),oYe=o("layoutlmv3"),rYe=o(" \u2014 "),aR=a("a"),tYe=o("LayoutLMv3Config"),aYe=o(" (LayoutLMv3 model)"),nYe=l(),ym=a("li"),vae=a("strong"),sYe=o("led"),lYe=o(" \u2014 "),nR=a("a"),iYe=o("LEDConfig"),dYe=o(" (LED model)"),cYe=l(),xm=a("li"),Fae=a("strong"),fYe=o("levit"),mYe=o(" \u2014 "),sR=a("a"),gYe=o("LevitConfig"),hYe=o(" (LeViT model)"),pYe=l(),$m=a("li"),Tae=a("strong"),_Ye=o("longformer"),uYe=o(" \u2014 "),lR=a("a"),bYe=o("LongformerConfig"),vYe=o(" (Longformer model)"),FYe=l(),km=a("li"),Mae=a("strong"),TYe=o("longt5"),MYe=o(" \u2014 "),iR=a("a"),EYe=o("LongT5Config"),CYe=o(" (LongT5 model)"),wYe=l(),Sm=a("li"),Eae=a("strong"),AYe=o("luke"),LYe=o(" \u2014 "),dR=a("a"),yYe=o("LukeConfig"),xYe=o(" (LUKE model)"),$Ye=l(),Rm=a("li"),Cae=a("strong"),kYe=o("lxmert"),SYe=o(" \u2014 "),cR=a("a"),RYe=o("LxmertConfig"),PYe=o(" (LXMERT model)"),BYe=l(),Pm=a("li"),wae=a("strong"),IYe=o("m2m_100"),NYe=o(" \u2014 "),fR=a("a"),qYe=o("M2M100Config"),jYe=o(" (M2M100 model)"),DYe=l(),Bm=a("li"),Aae=a("strong"),GYe=o("marian"),OYe=o(" \u2014 "),mR=a("a"),VYe=o("MarianConfig"),XYe=o(" (Marian model)"),zYe=l(),Im=a("li"),Lae=a("strong"),QYe=o("maskformer"),WYe=o(" \u2014 "),gR=a("a"),HYe=o("MaskFormerConfig"),UYe=o(" (MaskFormer model)"),JYe=l(),Nm=a("li"),yae=a("strong"),YYe=o("mbart"),KYe=o(" \u2014 "),hR=a("a"),ZYe=o("MBartConfig"),eKe=o(" (mBART model)"),oKe=l(),qm=a("li"),xae=a("strong"),rKe=o("mctct"),tKe=o(" \u2014 "),pR=a("a"),aKe=o("MCTCTConfig"),nKe=o(" (M-CTC-T model)"),sKe=l(),jm=a("li"),$ae=a("strong"),lKe=o("megatron-bert"),iKe=o(" \u2014 "),_R=a("a"),dKe=o("MegatronBertConfig"),cKe=o(" (Megatron-BERT model)"),fKe=l(),Dm=a("li"),kae=a("strong"),mKe=o("mobilebert"),gKe=o(" \u2014 "),uR=a("a"),hKe=o("MobileBertConfig"),pKe=o(" (MobileBERT model)"),_Ke=l(),Gm=a("li"),Sae=a("strong"),uKe=o("mpnet"),bKe=o(" \u2014 "),bR=a("a"),vKe=o("MPNetConfig"),FKe=o(" (MPNet model)"),TKe=l(),Om=a("li"),Rae=a("strong"),MKe=o("mt5"),EKe=o(" \u2014 "),vR=a("a"),CKe=o("MT5Config"),wKe=o(" (MT5 model)"),AKe=l(),Vm=a("li"),Pae=a("strong"),LKe=o("nezha"),yKe=o(" \u2014 "),FR=a("a"),xKe=o("NezhaConfig"),$Ke=o(" (Nezha model)"),kKe=l(),Xm=a("li"),Bae=a("strong"),SKe=o("nystromformer"),RKe=o(" \u2014 "),TR=a("a"),PKe=o("NystromformerConfig"),BKe=o(" (Nystr\xF6mformer model)"),IKe=l(),zm=a("li"),Iae=a("strong"),NKe=o("openai-gpt"),qKe=o(" \u2014 "),MR=a("a"),jKe=o("OpenAIGPTConfig"),DKe=o(" (OpenAI GPT model)"),GKe=l(),Qm=a("li"),Nae=a("strong"),OKe=o("opt"),VKe=o(" \u2014 "),ER=a("a"),XKe=o("OPTConfig"),zKe=o(" (OPT model)"),QKe=l(),Wm=a("li"),qae=a("strong"),WKe=o("pegasus"),HKe=o(" \u2014 "),CR=a("a"),UKe=o("PegasusConfig"),JKe=o(" (Pegasus model)"),YKe=l(),Hm=a("li"),jae=a("strong"),KKe=o("perceiver"),ZKe=o(" \u2014 "),wR=a("a"),eZe=o("PerceiverConfig"),oZe=o(" (Perceiver model)"),rZe=l(),Um=a("li"),Dae=a("strong"),tZe=o("plbart"),aZe=o(" \u2014 "),AR=a("a"),nZe=o("PLBartConfig"),sZe=o(" (PLBart model)"),lZe=l(),Jm=a("li"),Gae=a("strong"),iZe=o("poolformer"),dZe=o(" \u2014 "),LR=a("a"),cZe=o("PoolFormerConfig"),fZe=o(" (PoolFormer model)"),mZe=l(),Ym=a("li"),Oae=a("strong"),gZe=o("prophetnet"),hZe=o(" \u2014 "),yR=a("a"),pZe=o("ProphetNetConfig"),_Ze=o(" (ProphetNet model)"),uZe=l(),Km=a("li"),Vae=a("strong"),bZe=o("qdqbert"),vZe=o(" \u2014 "),xR=a("a"),FZe=o("QDQBertConfig"),TZe=o(" (QDQBert model)"),MZe=l(),Zm=a("li"),Xae=a("strong"),EZe=o("rag"),CZe=o(" \u2014 "),$R=a("a"),wZe=o("RagConfig"),AZe=o(" (RAG model)"),LZe=l(),eg=a("li"),zae=a("strong"),yZe=o("realm"),xZe=o(" \u2014 "),kR=a("a"),$Ze=o("RealmConfig"),kZe=o(" (REALM model)"),SZe=l(),og=a("li"),Qae=a("strong"),RZe=o("reformer"),PZe=o(" \u2014 "),SR=a("a"),BZe=o("ReformerConfig"),IZe=o(" (Reformer model)"),NZe=l(),rg=a("li"),Wae=a("strong"),qZe=o("regnet"),jZe=o(" \u2014 "),RR=a("a"),DZe=o("RegNetConfig"),GZe=o(" (RegNet model)"),OZe=l(),tg=a("li"),Hae=a("strong"),VZe=o("rembert"),XZe=o(" \u2014 "),PR=a("a"),zZe=o("RemBertConfig"),QZe=o(" (RemBERT model)"),WZe=l(),ag=a("li"),Uae=a("strong"),HZe=o("resnet"),UZe=o(" \u2014 "),BR=a("a"),JZe=o("ResNetConfig"),YZe=o(" (ResNet model)"),KZe=l(),ng=a("li"),Jae=a("strong"),ZZe=o("retribert"),eeo=o(" \u2014 "),IR=a("a"),oeo=o("RetriBertConfig"),reo=o(" (RetriBERT model)"),teo=l(),sg=a("li"),Yae=a("strong"),aeo=o("roberta"),neo=o(" \u2014 "),NR=a("a"),seo=o("RobertaConfig"),leo=o(" (RoBERTa model)"),ieo=l(),lg=a("li"),Kae=a("strong"),deo=o("roformer"),ceo=o(" \u2014 "),qR=a("a"),feo=o("RoFormerConfig"),meo=o(" (RoFormer model)"),geo=l(),ig=a("li"),Zae=a("strong"),heo=o("segformer"),peo=o(" \u2014 "),jR=a("a"),_eo=o("SegformerConfig"),ueo=o(" (SegFormer model)"),beo=l(),dg=a("li"),ene=a("strong"),veo=o("sew"),Feo=o(" \u2014 "),DR=a("a"),Teo=o("SEWConfig"),Meo=o(" (SEW model)"),Eeo=l(),cg=a("li"),one=a("strong"),Ceo=o("sew-d"),weo=o(" \u2014 "),GR=a("a"),Aeo=o("SEWDConfig"),Leo=o(" (SEW-D model)"),yeo=l(),fg=a("li"),rne=a("strong"),xeo=o("speech-encoder-decoder"),$eo=o(" \u2014 "),OR=a("a"),keo=o("SpeechEncoderDecoderConfig"),Seo=o(" (Speech Encoder decoder model)"),Reo=l(),mg=a("li"),tne=a("strong"),Peo=o("speech_to_text"),Beo=o(" \u2014 "),VR=a("a"),Ieo=o("Speech2TextConfig"),Neo=o(" (Speech2Text model)"),qeo=l(),gg=a("li"),ane=a("strong"),jeo=o("speech_to_text_2"),Deo=o(" \u2014 "),XR=a("a"),Geo=o("Speech2Text2Config"),Oeo=o(" (Speech2Text2 model)"),Veo=l(),hg=a("li"),nne=a("strong"),Xeo=o("splinter"),zeo=o(" \u2014 "),zR=a("a"),Qeo=o("SplinterConfig"),Weo=o(" (Splinter model)"),Heo=l(),pg=a("li"),sne=a("strong"),Ueo=o("squeezebert"),Jeo=o(" \u2014 "),QR=a("a"),Yeo=o("SqueezeBertConfig"),Keo=o(" (SqueezeBERT model)"),Zeo=l(),_g=a("li"),lne=a("strong"),eoo=o("swin"),ooo=o(" \u2014 "),WR=a("a"),roo=o("SwinConfig"),too=o(" (Swin Transformer model)"),aoo=l(),ug=a("li"),ine=a("strong"),noo=o("t5"),soo=o(" \u2014 "),HR=a("a"),loo=o("T5Config"),ioo=o(" (T5 model)"),doo=l(),bg=a("li"),dne=a("strong"),coo=o("tapas"),foo=o(" \u2014 "),UR=a("a"),moo=o("TapasConfig"),goo=o(" (TAPAS model)"),hoo=l(),vg=a("li"),cne=a("strong"),poo=o("trajectory_transformer"),_oo=o(" \u2014 "),JR=a("a"),uoo=o("TrajectoryTransformerConfig"),boo=o(" (Trajectory Transformer model)"),voo=l(),Fg=a("li"),fne=a("strong"),Foo=o("transfo-xl"),Too=o(" \u2014 "),YR=a("a"),Moo=o("TransfoXLConfig"),Eoo=o(" (Transformer-XL model)"),Coo=l(),Tg=a("li"),mne=a("strong"),woo=o("trocr"),Aoo=o(" \u2014 "),KR=a("a"),Loo=o("TrOCRConfig"),yoo=o(" (TrOCR model)"),xoo=l(),Mg=a("li"),gne=a("strong"),$oo=o("unispeech"),koo=o(" \u2014 "),ZR=a("a"),Soo=o("UniSpeechConfig"),Roo=o(" (UniSpeech model)"),Poo=l(),Eg=a("li"),hne=a("strong"),Boo=o("unispeech-sat"),Ioo=o(" \u2014 "),eP=a("a"),Noo=o("UniSpeechSatConfig"),qoo=o(" (UniSpeechSat model)"),joo=l(),Cg=a("li"),pne=a("strong"),Doo=o("van"),Goo=o(" \u2014 "),oP=a("a"),Ooo=o("VanConfig"),Voo=o(" (VAN model)"),Xoo=l(),wg=a("li"),_ne=a("strong"),zoo=o("vilt"),Qoo=o(" \u2014 "),rP=a("a"),Woo=o("ViltConfig"),Hoo=o(" (ViLT model)"),Uoo=l(),Ag=a("li"),une=a("strong"),Joo=o("vision-encoder-decoder"),Yoo=o(" \u2014 "),tP=a("a"),Koo=o("VisionEncoderDecoderConfig"),Zoo=o(" (Vision Encoder decoder model)"),ero=l(),Lg=a("li"),bne=a("strong"),oro=o("vision-text-dual-encoder"),rro=o(" \u2014 "),aP=a("a"),tro=o("VisionTextDualEncoderConfig"),aro=o(" (VisionTextDualEncoder model)"),nro=l(),yg=a("li"),vne=a("strong"),sro=o("visual_bert"),lro=o(" \u2014 "),nP=a("a"),iro=o("VisualBertConfig"),dro=o(" (VisualBERT model)"),cro=l(),xg=a("li"),Fne=a("strong"),fro=o("vit"),mro=o(" \u2014 "),sP=a("a"),gro=o("ViTConfig"),hro=o(" (ViT model)"),pro=l(),$g=a("li"),Tne=a("strong"),_ro=o("vit_mae"),uro=o(" \u2014 "),lP=a("a"),bro=o("ViTMAEConfig"),vro=o(" (ViTMAE model)"),Fro=l(),kg=a("li"),Mne=a("strong"),Tro=o("wav2vec2"),Mro=o(" \u2014 "),iP=a("a"),Ero=o("Wav2Vec2Config"),Cro=o(" (Wav2Vec2 model)"),wro=l(),Sg=a("li"),Ene=a("strong"),Aro=o("wav2vec2-conformer"),Lro=o(" \u2014 "),dP=a("a"),yro=o("Wav2Vec2ConformerConfig"),xro=o(" (Wav2Vec2-Conformer model)"),$ro=l(),Rg=a("li"),Cne=a("strong"),kro=o("wavlm"),Sro=o(" \u2014 "),cP=a("a"),Rro=o("WavLMConfig"),Pro=o(" (WavLM model)"),Bro=l(),Pg=a("li"),wne=a("strong"),Iro=o("xglm"),Nro=o(" \u2014 "),fP=a("a"),qro=o("XGLMConfig"),jro=o(" (XGLM model)"),Dro=l(),Bg=a("li"),Ane=a("strong"),Gro=o("xlm"),Oro=o(" \u2014 "),mP=a("a"),Vro=o("XLMConfig"),Xro=o(" (XLM model)"),zro=l(),Ig=a("li"),Lne=a("strong"),Qro=o("xlm-prophetnet"),Wro=o(" \u2014 "),gP=a("a"),Hro=o("XLMProphetNetConfig"),Uro=o(" (XLM-ProphetNet model)"),Jro=l(),Ng=a("li"),yne=a("strong"),Yro=o("xlm-roberta"),Kro=o(" \u2014 "),hP=a("a"),Zro=o("XLMRobertaConfig"),eto=o(" (XLM-RoBERTa model)"),oto=l(),qg=a("li"),xne=a("strong"),rto=o("xlm-roberta-xl"),tto=o(" \u2014 "),pP=a("a"),ato=o("XLMRobertaXLConfig"),nto=o(" (XLM-RoBERTa-XL model)"),sto=l(),jg=a("li"),$ne=a("strong"),lto=o("xlnet"),ito=o(" \u2014 "),_P=a("a"),dto=o("XLNetConfig"),cto=o(" (XLNet model)"),fto=l(),Dg=a("li"),kne=a("strong"),mto=o("yolos"),gto=o(" \u2014 "),uP=a("a"),hto=o("YolosConfig"),pto=o(" (YOLOS model)"),_to=l(),Gg=a("li"),Sne=a("strong"),uto=o("yoso"),bto=o(" \u2014 "),bP=a("a"),vto=o("YosoConfig"),Fto=o(" (YOSO model)"),Tto=l(),F(Og.$$.fragment),Mto=l(),Vg=a("div"),F(jA.$$.fragment),Eto=l(),Rne=a("p"),Cto=o("Register a new configuration for this class."),aOe=l(),ki=a("h2"),Xg=a("a"),Pne=a("span"),F(DA.$$.fragment),wto=l(),Bne=a("span"),Ato=o("AutoTokenizer"),nOe=l(),Ao=a("div"),F(GA.$$.fragment),Lto=l(),OA=a("p"),yto=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),vP=a("a"),xto=o("AutoTokenizer.from_pretrained()"),$to=o(" class method."),kto=l(),VA=a("p"),Sto=o("This class cannot be instantiated directly using "),Ine=a("code"),Rto=o("__init__()"),Pto=o(" (throws an error)."),Bto=l(),Lr=a("div"),F(XA.$$.fragment),Ito=l(),Nne=a("p"),Nto=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),qto=l(),ka=a("p"),jto=o("The tokenizer class to instantiate is selected based on the "),qne=a("code"),Dto=o("model_type"),Gto=o(` property of the config object (either
passed as an argument or loaded from `),jne=a("code"),Oto=o("pretrained_model_name_or_path"),Vto=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dne=a("code"),Xto=o("pretrained_model_name_or_path"),zto=o(":"),Qto=l(),k=a("ul"),qn=a("li"),Gne=a("strong"),Wto=o("albert"),Hto=o(" \u2014 "),FP=a("a"),Uto=o("AlbertTokenizer"),Jto=o(" or "),TP=a("a"),Yto=o("AlbertTokenizerFast"),Kto=o(" (ALBERT model)"),Zto=l(),jn=a("li"),One=a("strong"),eao=o("bart"),oao=o(" \u2014 "),MP=a("a"),rao=o("BartTokenizer"),tao=o(" or "),EP=a("a"),aao=o("BartTokenizerFast"),nao=o(" (BART model)"),sao=l(),Dn=a("li"),Vne=a("strong"),lao=o("barthez"),iao=o(" \u2014 "),CP=a("a"),dao=o("BarthezTokenizer"),cao=o(" or "),wP=a("a"),fao=o("BarthezTokenizerFast"),mao=o(" (BARThez model)"),gao=l(),zg=a("li"),Xne=a("strong"),hao=o("bartpho"),pao=o(" \u2014 "),AP=a("a"),_ao=o("BartphoTokenizer"),uao=o(" (BARTpho model)"),bao=l(),Gn=a("li"),zne=a("strong"),vao=o("bert"),Fao=o(" \u2014 "),LP=a("a"),Tao=o("BertTokenizer"),Mao=o(" or "),yP=a("a"),Eao=o("BertTokenizerFast"),Cao=o(" (BERT model)"),wao=l(),Qg=a("li"),Qne=a("strong"),Aao=o("bert-generation"),Lao=o(" \u2014 "),xP=a("a"),yao=o("BertGenerationTokenizer"),xao=o(" (Bert Generation model)"),$ao=l(),Wg=a("li"),Wne=a("strong"),kao=o("bert-japanese"),Sao=o(" \u2014 "),$P=a("a"),Rao=o("BertJapaneseTokenizer"),Pao=o(" (BertJapanese model)"),Bao=l(),Hg=a("li"),Hne=a("strong"),Iao=o("bertweet"),Nao=o(" \u2014 "),kP=a("a"),qao=o("BertweetTokenizer"),jao=o(" (BERTweet model)"),Dao=l(),On=a("li"),Une=a("strong"),Gao=o("big_bird"),Oao=o(" \u2014 "),SP=a("a"),Vao=o("BigBirdTokenizer"),Xao=o(" or "),RP=a("a"),zao=o("BigBirdTokenizerFast"),Qao=o(" (BigBird model)"),Wao=l(),Vn=a("li"),Jne=a("strong"),Hao=o("bigbird_pegasus"),Uao=o(" \u2014 "),PP=a("a"),Jao=o("PegasusTokenizer"),Yao=o(" or "),BP=a("a"),Kao=o("PegasusTokenizerFast"),Zao=o(" (BigBird-Pegasus model)"),eno=l(),Xn=a("li"),Yne=a("strong"),ono=o("blenderbot"),rno=o(" \u2014 "),IP=a("a"),tno=o("BlenderbotTokenizer"),ano=o(" or "),NP=a("a"),nno=o("BlenderbotTokenizerFast"),sno=o(" (Blenderbot model)"),lno=l(),Ug=a("li"),Kne=a("strong"),ino=o("blenderbot-small"),dno=o(" \u2014 "),qP=a("a"),cno=o("BlenderbotSmallTokenizer"),fno=o(" (BlenderbotSmall model)"),mno=l(),Jg=a("li"),Zne=a("strong"),gno=o("bloom"),hno=o(" \u2014 "),jP=a("a"),pno=o("BloomTokenizerFast"),_no=o(" (BLOOM model)"),uno=l(),Yg=a("li"),ese=a("strong"),bno=o("byt5"),vno=o(" \u2014 "),DP=a("a"),Fno=o("ByT5Tokenizer"),Tno=o(" (ByT5 model)"),Mno=l(),zn=a("li"),ose=a("strong"),Eno=o("camembert"),Cno=o(" \u2014 "),GP=a("a"),wno=o("CamembertTokenizer"),Ano=o(" or "),OP=a("a"),Lno=o("CamembertTokenizerFast"),yno=o(" (CamemBERT model)"),xno=l(),Kg=a("li"),rse=a("strong"),$no=o("canine"),kno=o(" \u2014 "),VP=a("a"),Sno=o("CanineTokenizer"),Rno=o(" (CANINE model)"),Pno=l(),Qn=a("li"),tse=a("strong"),Bno=o("clip"),Ino=o(" \u2014 "),XP=a("a"),Nno=o("CLIPTokenizer"),qno=o(" or "),zP=a("a"),jno=o("CLIPTokenizerFast"),Dno=o(" (CLIP model)"),Gno=l(),Wn=a("li"),ase=a("strong"),Ono=o("convbert"),Vno=o(" \u2014 "),QP=a("a"),Xno=o("ConvBertTokenizer"),zno=o(" or "),WP=a("a"),Qno=o("ConvBertTokenizerFast"),Wno=o(" (ConvBERT model)"),Hno=l(),Hn=a("li"),nse=a("strong"),Uno=o("cpm"),Jno=o(" \u2014 "),HP=a("a"),Yno=o("CpmTokenizer"),Kno=o(" or "),UP=a("a"),Zno=o("CpmTokenizerFast"),eso=o(" (CPM model)"),oso=l(),Zg=a("li"),sse=a("strong"),rso=o("ctrl"),tso=o(" \u2014 "),JP=a("a"),aso=o("CTRLTokenizer"),nso=o(" (CTRL model)"),sso=l(),Un=a("li"),lse=a("strong"),lso=o("data2vec-text"),iso=o(" \u2014 "),YP=a("a"),dso=o("RobertaTokenizer"),cso=o(" or "),KP=a("a"),fso=o("RobertaTokenizerFast"),mso=o(" (Data2VecText model)"),gso=l(),Jn=a("li"),ise=a("strong"),hso=o("deberta"),pso=o(" \u2014 "),ZP=a("a"),_so=o("DebertaTokenizer"),uso=o(" or "),eB=a("a"),bso=o("DebertaTokenizerFast"),vso=o(" (DeBERTa model)"),Fso=l(),Yn=a("li"),dse=a("strong"),Tso=o("deberta-v2"),Mso=o(" \u2014 "),oB=a("a"),Eso=o("DebertaV2Tokenizer"),Cso=o(" or "),rB=a("a"),wso=o("DebertaV2TokenizerFast"),Aso=o(" (DeBERTa-v2 model)"),Lso=l(),Kn=a("li"),cse=a("strong"),yso=o("distilbert"),xso=o(" \u2014 "),tB=a("a"),$so=o("DistilBertTokenizer"),kso=o(" or "),aB=a("a"),Sso=o("DistilBertTokenizerFast"),Rso=o(" (DistilBERT model)"),Pso=l(),Zn=a("li"),fse=a("strong"),Bso=o("dpr"),Iso=o(" \u2014 "),nB=a("a"),Nso=o("DPRQuestionEncoderTokenizer"),qso=o(" or "),sB=a("a"),jso=o("DPRQuestionEncoderTokenizerFast"),Dso=o(" (DPR model)"),Gso=l(),es=a("li"),mse=a("strong"),Oso=o("electra"),Vso=o(" \u2014 "),lB=a("a"),Xso=o("ElectraTokenizer"),zso=o(" or "),iB=a("a"),Qso=o("ElectraTokenizerFast"),Wso=o(" (ELECTRA model)"),Hso=l(),eh=a("li"),gse=a("strong"),Uso=o("flaubert"),Jso=o(" \u2014 "),dB=a("a"),Yso=o("FlaubertTokenizer"),Kso=o(" (FlauBERT model)"),Zso=l(),os=a("li"),hse=a("strong"),elo=o("fnet"),olo=o(" \u2014 "),cB=a("a"),rlo=o("FNetTokenizer"),tlo=o(" or "),fB=a("a"),alo=o("FNetTokenizerFast"),nlo=o(" (FNet model)"),slo=l(),oh=a("li"),pse=a("strong"),llo=o("fsmt"),ilo=o(" \u2014 "),mB=a("a"),dlo=o("FSMTTokenizer"),clo=o(" (FairSeq Machine-Translation model)"),flo=l(),rs=a("li"),_se=a("strong"),mlo=o("funnel"),glo=o(" \u2014 "),gB=a("a"),hlo=o("FunnelTokenizer"),plo=o(" or "),hB=a("a"),_lo=o("FunnelTokenizerFast"),ulo=o(" (Funnel Transformer model)"),blo=l(),ts=a("li"),use=a("strong"),vlo=o("gpt2"),Flo=o(" \u2014 "),pB=a("a"),Tlo=o("GPT2Tokenizer"),Mlo=o(" or "),_B=a("a"),Elo=o("GPT2TokenizerFast"),Clo=o(" (OpenAI GPT-2 model)"),wlo=l(),as=a("li"),bse=a("strong"),Alo=o("gpt_neo"),Llo=o(" \u2014 "),uB=a("a"),ylo=o("GPT2Tokenizer"),xlo=o(" or "),bB=a("a"),$lo=o("GPT2TokenizerFast"),klo=o(" (GPT Neo model)"),Slo=l(),rh=a("li"),vse=a("strong"),Rlo=o("gpt_neox"),Plo=o(" \u2014 "),vB=a("a"),Blo=o("GPTNeoXTokenizerFast"),Ilo=o(" (GPT NeoX model)"),Nlo=l(),ns=a("li"),Fse=a("strong"),qlo=o("gptj"),jlo=o(" \u2014 "),FB=a("a"),Dlo=o("GPT2Tokenizer"),Glo=o(" or "),TB=a("a"),Olo=o("GPT2TokenizerFast"),Vlo=o(" (GPT-J model)"),Xlo=l(),ss=a("li"),Tse=a("strong"),zlo=o("herbert"),Qlo=o(" \u2014 "),MB=a("a"),Wlo=o("HerbertTokenizer"),Hlo=o(" or "),EB=a("a"),Ulo=o("HerbertTokenizerFast"),Jlo=o(" (HerBERT model)"),Ylo=l(),th=a("li"),Mse=a("strong"),Klo=o("hubert"),Zlo=o(" \u2014 "),CB=a("a"),eio=o("Wav2Vec2CTCTokenizer"),oio=o(" (Hubert model)"),rio=l(),ls=a("li"),Ese=a("strong"),tio=o("ibert"),aio=o(" \u2014 "),wB=a("a"),nio=o("RobertaTokenizer"),sio=o(" or "),AB=a("a"),lio=o("RobertaTokenizerFast"),iio=o(" (I-BERT model)"),dio=l(),ah=a("li"),Cse=a("strong"),cio=o("jukebox"),fio=o(" \u2014 "),wse=a("code"),mio=o("JukeboxTokenizer"),gio=o(" (Jukebox model)"),hio=l(),is=a("li"),Ase=a("strong"),pio=o("layoutlm"),_io=o(" \u2014 "),LB=a("a"),uio=o("LayoutLMTokenizer"),bio=o(" or "),yB=a("a"),vio=o("LayoutLMTokenizerFast"),Fio=o(" (LayoutLM model)"),Tio=l(),ds=a("li"),Lse=a("strong"),Mio=o("layoutlmv2"),Eio=o(" \u2014 "),xB=a("a"),Cio=o("LayoutLMv2Tokenizer"),wio=o(" or "),$B=a("a"),Aio=o("LayoutLMv2TokenizerFast"),Lio=o(" (LayoutLMv2 model)"),yio=l(),cs=a("li"),yse=a("strong"),xio=o("layoutlmv3"),$io=o(" \u2014 "),kB=a("a"),kio=o("LayoutLMv3Tokenizer"),Sio=o(" or "),SB=a("a"),Rio=o("LayoutLMv3TokenizerFast"),Pio=o(" (LayoutLMv3 model)"),Bio=l(),fs=a("li"),xse=a("strong"),Iio=o("layoutxlm"),Nio=o(" \u2014 "),RB=a("a"),qio=o("LayoutXLMTokenizer"),jio=o(" or "),PB=a("a"),Dio=o("LayoutXLMTokenizerFast"),Gio=o(" (LayoutXLM model)"),Oio=l(),ms=a("li"),$se=a("strong"),Vio=o("led"),Xio=o(" \u2014 "),BB=a("a"),zio=o("LEDTokenizer"),Qio=o(" or "),IB=a("a"),Wio=o("LEDTokenizerFast"),Hio=o(" (LED model)"),Uio=l(),gs=a("li"),kse=a("strong"),Jio=o("longformer"),Yio=o(" \u2014 "),NB=a("a"),Kio=o("LongformerTokenizer"),Zio=o(" or "),qB=a("a"),edo=o("LongformerTokenizerFast"),odo=o(" (Longformer model)"),rdo=l(),hs=a("li"),Sse=a("strong"),tdo=o("longt5"),ado=o(" \u2014 "),jB=a("a"),ndo=o("T5Tokenizer"),sdo=o(" or "),DB=a("a"),ldo=o("T5TokenizerFast"),ido=o(" (LongT5 model)"),ddo=l(),nh=a("li"),Rse=a("strong"),cdo=o("luke"),fdo=o(" \u2014 "),GB=a("a"),mdo=o("LukeTokenizer"),gdo=o(" (LUKE model)"),hdo=l(),ps=a("li"),Pse=a("strong"),pdo=o("lxmert"),_do=o(" \u2014 "),OB=a("a"),udo=o("LxmertTokenizer"),bdo=o(" or "),VB=a("a"),vdo=o("LxmertTokenizerFast"),Fdo=o(" (LXMERT model)"),Tdo=l(),sh=a("li"),Bse=a("strong"),Mdo=o("m2m_100"),Edo=o(" \u2014 "),XB=a("a"),Cdo=o("M2M100Tokenizer"),wdo=o(" (M2M100 model)"),Ado=l(),lh=a("li"),Ise=a("strong"),Ldo=o("marian"),ydo=o(" \u2014 "),zB=a("a"),xdo=o("MarianTokenizer"),$do=o(" (Marian model)"),kdo=l(),_s=a("li"),Nse=a("strong"),Sdo=o("mbart"),Rdo=o(" \u2014 "),QB=a("a"),Pdo=o("MBartTokenizer"),Bdo=o(" or "),WB=a("a"),Ido=o("MBartTokenizerFast"),Ndo=o(" (mBART model)"),qdo=l(),us=a("li"),qse=a("strong"),jdo=o("mbart50"),Ddo=o(" \u2014 "),HB=a("a"),Gdo=o("MBart50Tokenizer"),Odo=o(" or "),UB=a("a"),Vdo=o("MBart50TokenizerFast"),Xdo=o(" (mBART-50 model)"),zdo=l(),bs=a("li"),jse=a("strong"),Qdo=o("megatron-bert"),Wdo=o(" \u2014 "),JB=a("a"),Hdo=o("BertTokenizer"),Udo=o(" or "),YB=a("a"),Jdo=o("BertTokenizerFast"),Ydo=o(" (Megatron-BERT model)"),Kdo=l(),ih=a("li"),Dse=a("strong"),Zdo=o("mluke"),eco=o(" \u2014 "),KB=a("a"),oco=o("MLukeTokenizer"),rco=o(" (mLUKE model)"),tco=l(),vs=a("li"),Gse=a("strong"),aco=o("mobilebert"),nco=o(" \u2014 "),ZB=a("a"),sco=o("MobileBertTokenizer"),lco=o(" or "),eI=a("a"),ico=o("MobileBertTokenizerFast"),dco=o(" (MobileBERT model)"),cco=l(),Fs=a("li"),Ose=a("strong"),fco=o("mpnet"),mco=o(" \u2014 "),oI=a("a"),gco=o("MPNetTokenizer"),hco=o(" or "),rI=a("a"),pco=o("MPNetTokenizerFast"),_co=o(" (MPNet model)"),uco=l(),Ts=a("li"),Vse=a("strong"),bco=o("mt5"),vco=o(" \u2014 "),tI=a("a"),Fco=o("MT5Tokenizer"),Tco=o(" or "),aI=a("a"),Mco=o("MT5TokenizerFast"),Eco=o(" (MT5 model)"),Cco=l(),Ms=a("li"),Xse=a("strong"),wco=o("nezha"),Aco=o(" \u2014 "),nI=a("a"),Lco=o("BertTokenizer"),yco=o(" or "),sI=a("a"),xco=o("BertTokenizerFast"),$co=o(" (Nezha model)"),kco=l(),Es=a("li"),zse=a("strong"),Sco=o("nystromformer"),Rco=o(" \u2014 "),lI=a("a"),Pco=o("AlbertTokenizer"),Bco=o(" or "),iI=a("a"),Ico=o("AlbertTokenizerFast"),Nco=o(" (Nystr\xF6mformer model)"),qco=l(),Cs=a("li"),Qse=a("strong"),jco=o("openai-gpt"),Dco=o(" \u2014 "),dI=a("a"),Gco=o("OpenAIGPTTokenizer"),Oco=o(" or "),cI=a("a"),Vco=o("OpenAIGPTTokenizerFast"),Xco=o(" (OpenAI GPT model)"),zco=l(),dh=a("li"),Wse=a("strong"),Qco=o("opt"),Wco=o(" \u2014 "),fI=a("a"),Hco=o("GPT2Tokenizer"),Uco=o(" (OPT model)"),Jco=l(),ws=a("li"),Hse=a("strong"),Yco=o("pegasus"),Kco=o(" \u2014 "),mI=a("a"),Zco=o("PegasusTokenizer"),efo=o(" or "),gI=a("a"),ofo=o("PegasusTokenizerFast"),rfo=o(" (Pegasus model)"),tfo=l(),ch=a("li"),Use=a("strong"),afo=o("perceiver"),nfo=o(" \u2014 "),hI=a("a"),sfo=o("PerceiverTokenizer"),lfo=o(" (Perceiver model)"),ifo=l(),fh=a("li"),Jse=a("strong"),dfo=o("phobert"),cfo=o(" \u2014 "),pI=a("a"),ffo=o("PhobertTokenizer"),mfo=o(" (PhoBERT model)"),gfo=l(),mh=a("li"),Yse=a("strong"),hfo=o("plbart"),pfo=o(" \u2014 "),_I=a("a"),_fo=o("PLBartTokenizer"),ufo=o(" (PLBart model)"),bfo=l(),gh=a("li"),Kse=a("strong"),vfo=o("prophetnet"),Ffo=o(" \u2014 "),uI=a("a"),Tfo=o("ProphetNetTokenizer"),Mfo=o(" (ProphetNet model)"),Efo=l(),As=a("li"),Zse=a("strong"),Cfo=o("qdqbert"),wfo=o(" \u2014 "),bI=a("a"),Afo=o("BertTokenizer"),Lfo=o(" or "),vI=a("a"),yfo=o("BertTokenizerFast"),xfo=o(" (QDQBert model)"),$fo=l(),hh=a("li"),ele=a("strong"),kfo=o("rag"),Sfo=o(" \u2014 "),FI=a("a"),Rfo=o("RagTokenizer"),Pfo=o(" (RAG model)"),Bfo=l(),Ls=a("li"),ole=a("strong"),Ifo=o("realm"),Nfo=o(" \u2014 "),TI=a("a"),qfo=o("RealmTokenizer"),jfo=o(" or "),MI=a("a"),Dfo=o("RealmTokenizerFast"),Gfo=o(" (REALM model)"),Ofo=l(),ys=a("li"),rle=a("strong"),Vfo=o("reformer"),Xfo=o(" \u2014 "),EI=a("a"),zfo=o("ReformerTokenizer"),Qfo=o(" or "),CI=a("a"),Wfo=o("ReformerTokenizerFast"),Hfo=o(" (Reformer model)"),Ufo=l(),xs=a("li"),tle=a("strong"),Jfo=o("rembert"),Yfo=o(" \u2014 "),wI=a("a"),Kfo=o("RemBertTokenizer"),Zfo=o(" or "),AI=a("a"),emo=o("RemBertTokenizerFast"),omo=o(" (RemBERT model)"),rmo=l(),$s=a("li"),ale=a("strong"),tmo=o("retribert"),amo=o(" \u2014 "),LI=a("a"),nmo=o("RetriBertTokenizer"),smo=o(" or "),yI=a("a"),lmo=o("RetriBertTokenizerFast"),imo=o(" (RetriBERT model)"),dmo=l(),ks=a("li"),nle=a("strong"),cmo=o("roberta"),fmo=o(" \u2014 "),xI=a("a"),mmo=o("RobertaTokenizer"),gmo=o(" or "),$I=a("a"),hmo=o("RobertaTokenizerFast"),pmo=o(" (RoBERTa model)"),_mo=l(),Ss=a("li"),sle=a("strong"),umo=o("roformer"),bmo=o(" \u2014 "),kI=a("a"),vmo=o("RoFormerTokenizer"),Fmo=o(" or "),SI=a("a"),Tmo=o("RoFormerTokenizerFast"),Mmo=o(" (RoFormer model)"),Emo=l(),ph=a("li"),lle=a("strong"),Cmo=o("speech_to_text"),wmo=o(" \u2014 "),RI=a("a"),Amo=o("Speech2TextTokenizer"),Lmo=o(" (Speech2Text model)"),ymo=l(),_h=a("li"),ile=a("strong"),xmo=o("speech_to_text_2"),$mo=o(" \u2014 "),PI=a("a"),kmo=o("Speech2Text2Tokenizer"),Smo=o(" (Speech2Text2 model)"),Rmo=l(),Rs=a("li"),dle=a("strong"),Pmo=o("splinter"),Bmo=o(" \u2014 "),BI=a("a"),Imo=o("SplinterTokenizer"),Nmo=o(" or "),II=a("a"),qmo=o("SplinterTokenizerFast"),jmo=o(" (Splinter model)"),Dmo=l(),Ps=a("li"),cle=a("strong"),Gmo=o("squeezebert"),Omo=o(" \u2014 "),NI=a("a"),Vmo=o("SqueezeBertTokenizer"),Xmo=o(" or "),qI=a("a"),zmo=o("SqueezeBertTokenizerFast"),Qmo=o(" (SqueezeBERT model)"),Wmo=l(),Bs=a("li"),fle=a("strong"),Hmo=o("t5"),Umo=o(" \u2014 "),jI=a("a"),Jmo=o("T5Tokenizer"),Ymo=o(" or "),DI=a("a"),Kmo=o("T5TokenizerFast"),Zmo=o(" (T5 model)"),ego=l(),uh=a("li"),mle=a("strong"),ogo=o("tapas"),rgo=o(" \u2014 "),GI=a("a"),tgo=o("TapasTokenizer"),ago=o(" (TAPAS model)"),ngo=l(),bh=a("li"),gle=a("strong"),sgo=o("tapex"),lgo=o(" \u2014 "),OI=a("a"),igo=o("TapexTokenizer"),dgo=o(" (TAPEX model)"),cgo=l(),vh=a("li"),hle=a("strong"),fgo=o("transfo-xl"),mgo=o(" \u2014 "),VI=a("a"),ggo=o("TransfoXLTokenizer"),hgo=o(" (Transformer-XL model)"),pgo=l(),Is=a("li"),ple=a("strong"),_go=o("vilt"),ugo=o(" \u2014 "),XI=a("a"),bgo=o("BertTokenizer"),vgo=o(" or "),zI=a("a"),Fgo=o("BertTokenizerFast"),Tgo=o(" (ViLT model)"),Mgo=l(),Ns=a("li"),_le=a("strong"),Ego=o("visual_bert"),Cgo=o(" \u2014 "),QI=a("a"),wgo=o("BertTokenizer"),Ago=o(" or "),WI=a("a"),Lgo=o("BertTokenizerFast"),ygo=o(" (VisualBERT model)"),xgo=l(),Fh=a("li"),ule=a("strong"),$go=o("wav2vec2"),kgo=o(" \u2014 "),HI=a("a"),Sgo=o("Wav2Vec2CTCTokenizer"),Rgo=o(" (Wav2Vec2 model)"),Pgo=l(),Th=a("li"),ble=a("strong"),Bgo=o("wav2vec2-conformer"),Igo=o(" \u2014 "),UI=a("a"),Ngo=o("Wav2Vec2CTCTokenizer"),qgo=o(" (Wav2Vec2-Conformer model)"),jgo=l(),Mh=a("li"),vle=a("strong"),Dgo=o("wav2vec2_phoneme"),Ggo=o(" \u2014 "),JI=a("a"),Ogo=o("Wav2Vec2PhonemeCTCTokenizer"),Vgo=o(" (Wav2Vec2Phoneme model)"),Xgo=l(),qs=a("li"),Fle=a("strong"),zgo=o("xglm"),Qgo=o(" \u2014 "),YI=a("a"),Wgo=o("XGLMTokenizer"),Hgo=o(" or "),KI=a("a"),Ugo=o("XGLMTokenizerFast"),Jgo=o(" (XGLM model)"),Ygo=l(),Eh=a("li"),Tle=a("strong"),Kgo=o("xlm"),Zgo=o(" \u2014 "),ZI=a("a"),eho=o("XLMTokenizer"),oho=o(" (XLM model)"),rho=l(),Ch=a("li"),Mle=a("strong"),tho=o("xlm-prophetnet"),aho=o(" \u2014 "),eN=a("a"),nho=o("XLMProphetNetTokenizer"),sho=o(" (XLM-ProphetNet model)"),lho=l(),js=a("li"),Ele=a("strong"),iho=o("xlm-roberta"),dho=o(" \u2014 "),oN=a("a"),cho=o("XLMRobertaTokenizer"),fho=o(" or "),rN=a("a"),mho=o("XLMRobertaTokenizerFast"),gho=o(" (XLM-RoBERTa model)"),hho=l(),Ds=a("li"),Cle=a("strong"),pho=o("xlm-roberta-xl"),_ho=o(" \u2014 "),tN=a("a"),uho=o("RobertaTokenizer"),bho=o(" or "),aN=a("a"),vho=o("RobertaTokenizerFast"),Fho=o(" (XLM-RoBERTa-XL model)"),Tho=l(),Gs=a("li"),wle=a("strong"),Mho=o("xlnet"),Eho=o(" \u2014 "),nN=a("a"),Cho=o("XLNetTokenizer"),who=o(" or "),sN=a("a"),Aho=o("XLNetTokenizerFast"),Lho=o(" (XLNet model)"),yho=l(),Os=a("li"),Ale=a("strong"),xho=o("yoso"),$ho=o(" \u2014 "),lN=a("a"),kho=o("AlbertTokenizer"),Sho=o(" or "),iN=a("a"),Rho=o("AlbertTokenizerFast"),Pho=o(" (YOSO model)"),Bho=l(),F(wh.$$.fragment),Iho=l(),Ah=a("div"),F(zA.$$.fragment),Nho=l(),Lle=a("p"),qho=o("Register a new tokenizer in this mapping."),sOe=l(),Si=a("h2"),Lh=a("a"),yle=a("span"),F(QA.$$.fragment),jho=l(),xle=a("span"),Dho=o("AutoFeatureExtractor"),lOe=l(),Lo=a("div"),F(WA.$$.fragment),Gho=l(),HA=a("p"),Oho=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),dN=a("a"),Vho=o("AutoFeatureExtractor.from_pretrained()"),Xho=o(" class method."),zho=l(),UA=a("p"),Qho=o("This class cannot be instantiated directly using "),$le=a("code"),Who=o("__init__()"),Hho=o(" (throws an error)."),Uho=l(),He=a("div"),F(JA.$$.fragment),Jho=l(),kle=a("p"),Yho=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Kho=l(),Sa=a("p"),Zho=o("The feature extractor class to instantiate is selected based on the "),Sle=a("code"),epo=o("model_type"),opo=o(` property of the config object
(either passed as an argument or loaded from `),Rle=a("code"),rpo=o("pretrained_model_name_or_path"),tpo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ple=a("code"),apo=o("pretrained_model_name_or_path"),npo=o(":"),spo=l(),Y=a("ul"),yh=a("li"),Ble=a("strong"),lpo=o("beit"),ipo=o(" \u2014 "),cN=a("a"),dpo=o("BeitFeatureExtractor"),cpo=o(" (BEiT model)"),fpo=l(),xh=a("li"),Ile=a("strong"),mpo=o("clip"),gpo=o(" \u2014 "),fN=a("a"),hpo=o("CLIPFeatureExtractor"),ppo=o(" (CLIP model)"),_po=l(),$h=a("li"),Nle=a("strong"),upo=o("convnext"),bpo=o(" \u2014 "),mN=a("a"),vpo=o("ConvNextFeatureExtractor"),Fpo=o(" (ConvNeXT model)"),Tpo=l(),kh=a("li"),qle=a("strong"),Mpo=o("cvt"),Epo=o(" \u2014 "),gN=a("a"),Cpo=o("ConvNextFeatureExtractor"),wpo=o(" (CvT model)"),Apo=l(),Sh=a("li"),jle=a("strong"),Lpo=o("data2vec-audio"),ypo=o(" \u2014 "),hN=a("a"),xpo=o("Wav2Vec2FeatureExtractor"),$po=o(" (Data2VecAudio model)"),kpo=l(),Rh=a("li"),Dle=a("strong"),Spo=o("data2vec-vision"),Rpo=o(" \u2014 "),pN=a("a"),Ppo=o("BeitFeatureExtractor"),Bpo=o(" (Data2VecVision model)"),Ipo=l(),Ph=a("li"),Gle=a("strong"),Npo=o("deit"),qpo=o(" \u2014 "),_N=a("a"),jpo=o("DeiTFeatureExtractor"),Dpo=o(" (DeiT model)"),Gpo=l(),Bh=a("li"),Ole=a("strong"),Opo=o("detr"),Vpo=o(" \u2014 "),uN=a("a"),Xpo=o("DetrFeatureExtractor"),zpo=o(" (DETR model)"),Qpo=l(),Ih=a("li"),Vle=a("strong"),Wpo=o("dpt"),Hpo=o(" \u2014 "),bN=a("a"),Upo=o("DPTFeatureExtractor"),Jpo=o(" (DPT model)"),Ypo=l(),Nh=a("li"),Xle=a("strong"),Kpo=o("flava"),Zpo=o(" \u2014 "),vN=a("a"),e_o=o("FlavaFeatureExtractor"),o_o=o(" (FLAVA model)"),r_o=l(),qh=a("li"),zle=a("strong"),t_o=o("glpn"),a_o=o(" \u2014 "),FN=a("a"),n_o=o("GLPNFeatureExtractor"),s_o=o(" (GLPN model)"),l_o=l(),jh=a("li"),Qle=a("strong"),i_o=o("hubert"),d_o=o(" \u2014 "),TN=a("a"),c_o=o("Wav2Vec2FeatureExtractor"),f_o=o(" (Hubert model)"),m_o=l(),Dh=a("li"),Wle=a("strong"),g_o=o("imagegpt"),h_o=o(" \u2014 "),MN=a("a"),p_o=o("ImageGPTFeatureExtractor"),__o=o(" (ImageGPT model)"),u_o=l(),Gh=a("li"),Hle=a("strong"),b_o=o("layoutlmv2"),v_o=o(" \u2014 "),EN=a("a"),F_o=o("LayoutLMv2FeatureExtractor"),T_o=o(" (LayoutLMv2 model)"),M_o=l(),Oh=a("li"),Ule=a("strong"),E_o=o("layoutlmv3"),C_o=o(" \u2014 "),CN=a("a"),w_o=o("LayoutLMv3FeatureExtractor"),A_o=o(" (LayoutLMv3 model)"),L_o=l(),Vh=a("li"),Jle=a("strong"),y_o=o("levit"),x_o=o(" \u2014 "),wN=a("a"),$_o=o("LevitFeatureExtractor"),k_o=o(" (LeViT model)"),S_o=l(),Xh=a("li"),Yle=a("strong"),R_o=o("maskformer"),P_o=o(" \u2014 "),AN=a("a"),B_o=o("MaskFormerFeatureExtractor"),I_o=o(" (MaskFormer model)"),N_o=l(),zh=a("li"),Kle=a("strong"),q_o=o("mctct"),j_o=o(" \u2014 "),LN=a("a"),D_o=o("MCTCTFeatureExtractor"),G_o=o(" (M-CTC-T model)"),O_o=l(),Qh=a("li"),Zle=a("strong"),V_o=o("perceiver"),X_o=o(" \u2014 "),yN=a("a"),z_o=o("PerceiverFeatureExtractor"),Q_o=o(" (Perceiver model)"),W_o=l(),Wh=a("li"),eie=a("strong"),H_o=o("poolformer"),U_o=o(" \u2014 "),xN=a("a"),J_o=o("PoolFormerFeatureExtractor"),Y_o=o(" (PoolFormer model)"),K_o=l(),Hh=a("li"),oie=a("strong"),Z_o=o("regnet"),euo=o(" \u2014 "),$N=a("a"),ouo=o("ConvNextFeatureExtractor"),ruo=o(" (RegNet model)"),tuo=l(),Uh=a("li"),rie=a("strong"),auo=o("resnet"),nuo=o(" \u2014 "),kN=a("a"),suo=o("ConvNextFeatureExtractor"),luo=o(" (ResNet model)"),iuo=l(),Jh=a("li"),tie=a("strong"),duo=o("segformer"),cuo=o(" \u2014 "),SN=a("a"),fuo=o("SegformerFeatureExtractor"),muo=o(" (SegFormer model)"),guo=l(),Yh=a("li"),aie=a("strong"),huo=o("speech_to_text"),puo=o(" \u2014 "),RN=a("a"),_uo=o("Speech2TextFeatureExtractor"),uuo=o(" (Speech2Text model)"),buo=l(),Kh=a("li"),nie=a("strong"),vuo=o("swin"),Fuo=o(" \u2014 "),PN=a("a"),Tuo=o("ViTFeatureExtractor"),Muo=o(" (Swin Transformer model)"),Euo=l(),Zh=a("li"),sie=a("strong"),Cuo=o("van"),wuo=o(" \u2014 "),BN=a("a"),Auo=o("ConvNextFeatureExtractor"),Luo=o(" (VAN model)"),yuo=l(),ep=a("li"),lie=a("strong"),xuo=o("vilt"),$uo=o(" \u2014 "),IN=a("a"),kuo=o("ViltFeatureExtractor"),Suo=o(" (ViLT model)"),Ruo=l(),op=a("li"),iie=a("strong"),Puo=o("vit"),Buo=o(" \u2014 "),NN=a("a"),Iuo=o("ViTFeatureExtractor"),Nuo=o(" (ViT model)"),quo=l(),rp=a("li"),die=a("strong"),juo=o("vit_mae"),Duo=o(" \u2014 "),qN=a("a"),Guo=o("ViTFeatureExtractor"),Ouo=o(" (ViTMAE model)"),Vuo=l(),tp=a("li"),cie=a("strong"),Xuo=o("wav2vec2"),zuo=o(" \u2014 "),jN=a("a"),Quo=o("Wav2Vec2FeatureExtractor"),Wuo=o(" (Wav2Vec2 model)"),Huo=l(),ap=a("li"),fie=a("strong"),Uuo=o("wav2vec2-conformer"),Juo=o(" \u2014 "),DN=a("a"),Yuo=o("Wav2Vec2FeatureExtractor"),Kuo=o(" (Wav2Vec2-Conformer model)"),Zuo=l(),np=a("li"),mie=a("strong"),e2o=o("yolos"),o2o=o(" \u2014 "),GN=a("a"),r2o=o("YolosFeatureExtractor"),t2o=o(" (YOLOS model)"),a2o=l(),F(sp.$$.fragment),n2o=l(),F(lp.$$.fragment),s2o=l(),ip=a("div"),F(YA.$$.fragment),l2o=l(),gie=a("p"),i2o=o("Register a new feature extractor for this class."),iOe=l(),Ri=a("h2"),dp=a("a"),hie=a("span"),F(KA.$$.fragment),d2o=l(),pie=a("span"),c2o=o("AutoProcessor"),dOe=l(),yo=a("div"),F(ZA.$$.fragment),f2o=l(),eL=a("p"),m2o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),ON=a("a"),g2o=o("AutoProcessor.from_pretrained()"),h2o=o(" class method."),p2o=l(),oL=a("p"),_2o=o("This class cannot be instantiated directly using "),_ie=a("code"),u2o=o("__init__()"),b2o=o(" (throws an error)."),v2o=l(),Ue=a("div"),F(rL.$$.fragment),F2o=l(),uie=a("p"),T2o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),M2o=l(),Pi=a("p"),E2o=o("The processor class to instantiate is selected based on the "),bie=a("code"),C2o=o("model_type"),w2o=o(` property of the config object (either
passed as an argument or loaded from `),vie=a("code"),A2o=o("pretrained_model_name_or_path"),L2o=o(" if possible):"),y2o=l(),he=a("ul"),cp=a("li"),Fie=a("strong"),x2o=o("clip"),$2o=o(" \u2014 "),VN=a("a"),k2o=o("CLIPProcessor"),S2o=o(" (CLIP model)"),R2o=l(),fp=a("li"),Tie=a("strong"),P2o=o("flava"),B2o=o(" \u2014 "),Mie=a("code"),I2o=o("FLAVAProcessor"),N2o=o(" (FLAVA model)"),q2o=l(),mp=a("li"),Eie=a("strong"),j2o=o("layoutlmv2"),D2o=o(" \u2014 "),XN=a("a"),G2o=o("LayoutLMv2Processor"),O2o=o(" (LayoutLMv2 model)"),V2o=l(),gp=a("li"),Cie=a("strong"),X2o=o("layoutlmv3"),z2o=o(" \u2014 "),zN=a("a"),Q2o=o("LayoutLMv3Processor"),W2o=o(" (LayoutLMv3 model)"),H2o=l(),hp=a("li"),wie=a("strong"),U2o=o("layoutxlm"),J2o=o(" \u2014 "),QN=a("a"),Y2o=o("LayoutXLMProcessor"),K2o=o(" (LayoutXLM model)"),Z2o=l(),pp=a("li"),Aie=a("strong"),e1o=o("sew"),o1o=o(" \u2014 "),WN=a("a"),r1o=o("Wav2Vec2Processor"),t1o=o(" (SEW model)"),a1o=l(),_p=a("li"),Lie=a("strong"),n1o=o("sew-d"),s1o=o(" \u2014 "),HN=a("a"),l1o=o("Wav2Vec2Processor"),i1o=o(" (SEW-D model)"),d1o=l(),up=a("li"),yie=a("strong"),c1o=o("speech_to_text"),f1o=o(" \u2014 "),UN=a("a"),m1o=o("Speech2TextProcessor"),g1o=o(" (Speech2Text model)"),h1o=l(),bp=a("li"),xie=a("strong"),p1o=o("speech_to_text_2"),_1o=o(" \u2014 "),JN=a("a"),u1o=o("Speech2Text2Processor"),b1o=o(" (Speech2Text2 model)"),v1o=l(),vp=a("li"),$ie=a("strong"),F1o=o("trocr"),T1o=o(" \u2014 "),YN=a("a"),M1o=o("TrOCRProcessor"),E1o=o(" (TrOCR model)"),C1o=l(),Fp=a("li"),kie=a("strong"),w1o=o("unispeech"),A1o=o(" \u2014 "),KN=a("a"),L1o=o("Wav2Vec2Processor"),y1o=o(" (UniSpeech model)"),x1o=l(),Tp=a("li"),Sie=a("strong"),$1o=o("unispeech-sat"),k1o=o(" \u2014 "),ZN=a("a"),S1o=o("Wav2Vec2Processor"),R1o=o(" (UniSpeechSat model)"),P1o=l(),Mp=a("li"),Rie=a("strong"),B1o=o("vilt"),I1o=o(" \u2014 "),eq=a("a"),N1o=o("ViltProcessor"),q1o=o(" (ViLT model)"),j1o=l(),Ep=a("li"),Pie=a("strong"),D1o=o("vision-text-dual-encoder"),G1o=o(" \u2014 "),oq=a("a"),O1o=o("VisionTextDualEncoderProcessor"),V1o=o(" (VisionTextDualEncoder model)"),X1o=l(),Cp=a("li"),Bie=a("strong"),z1o=o("wav2vec2"),Q1o=o(" \u2014 "),rq=a("a"),W1o=o("Wav2Vec2Processor"),H1o=o(" (Wav2Vec2 model)"),U1o=l(),wp=a("li"),Iie=a("strong"),J1o=o("wav2vec2-conformer"),Y1o=o(" \u2014 "),tq=a("a"),K1o=o("Wav2Vec2Processor"),Z1o=o(" (Wav2Vec2-Conformer model)"),ebo=l(),Ap=a("li"),Nie=a("strong"),obo=o("wavlm"),rbo=o(" \u2014 "),aq=a("a"),tbo=o("Wav2Vec2Processor"),abo=o(" (WavLM model)"),nbo=l(),F(Lp.$$.fragment),sbo=l(),F(yp.$$.fragment),lbo=l(),xp=a("div"),F(tL.$$.fragment),ibo=l(),qie=a("p"),dbo=o("Register a new processor for this class."),cOe=l(),Bi=a("h2"),$p=a("a"),jie=a("span"),F(aL.$$.fragment),cbo=l(),Die=a("span"),fbo=o("AutoModel"),fOe=l(),xo=a("div"),F(nL.$$.fragment),mbo=l(),Ii=a("p"),gbo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nq=a("a"),hbo=o("from_pretrained()"),pbo=o(" class method or the "),sq=a("a"),_bo=o("from_config()"),ubo=o(` class
method.`),bbo=l(),sL=a("p"),vbo=o("This class cannot be instantiated directly using "),Gie=a("code"),Fbo=o("__init__()"),Tbo=o(" (throws an error)."),Mbo=l(),nt=a("div"),F(lL.$$.fragment),Ebo=l(),Oie=a("p"),Cbo=o("Instantiates one of the base model classes of the library from a configuration."),wbo=l(),Ni=a("p"),Abo=o(`Note:
Loading a model from its configuration file does `),Vie=a("strong"),Lbo=o("not"),ybo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lq=a("a"),xbo=o("from_pretrained()"),$bo=o(" to load the model weights."),kbo=l(),F(kp.$$.fragment),Sbo=l(),Je=a("div"),F(iL.$$.fragment),Rbo=l(),Xie=a("p"),Pbo=o("Instantiate one of the base model classes of the library from a pretrained model."),Bbo=l(),Ra=a("p"),Ibo=o("The model class to instantiate is selected based on the "),zie=a("code"),Nbo=o("model_type"),qbo=o(` property of the config object (either
passed as an argument or loaded from `),Qie=a("code"),jbo=o("pretrained_model_name_or_path"),Dbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wie=a("code"),Gbo=o("pretrained_model_name_or_path"),Obo=o(":"),Vbo=l(),y=a("ul"),Sp=a("li"),Hie=a("strong"),Xbo=o("albert"),zbo=o(" \u2014 "),iq=a("a"),Qbo=o("AlbertModel"),Wbo=o(" (ALBERT model)"),Hbo=l(),Rp=a("li"),Uie=a("strong"),Ubo=o("bart"),Jbo=o(" \u2014 "),dq=a("a"),Ybo=o("BartModel"),Kbo=o(" (BART model)"),Zbo=l(),Pp=a("li"),Jie=a("strong"),evo=o("beit"),ovo=o(" \u2014 "),cq=a("a"),rvo=o("BeitModel"),tvo=o(" (BEiT model)"),avo=l(),Bp=a("li"),Yie=a("strong"),nvo=o("bert"),svo=o(" \u2014 "),fq=a("a"),lvo=o("BertModel"),ivo=o(" (BERT model)"),dvo=l(),Ip=a("li"),Kie=a("strong"),cvo=o("bert-generation"),fvo=o(" \u2014 "),mq=a("a"),mvo=o("BertGenerationEncoder"),gvo=o(" (Bert Generation model)"),hvo=l(),Np=a("li"),Zie=a("strong"),pvo=o("big_bird"),_vo=o(" \u2014 "),gq=a("a"),uvo=o("BigBirdModel"),bvo=o(" (BigBird model)"),vvo=l(),qp=a("li"),ede=a("strong"),Fvo=o("bigbird_pegasus"),Tvo=o(" \u2014 "),hq=a("a"),Mvo=o("BigBirdPegasusModel"),Evo=o(" (BigBird-Pegasus model)"),Cvo=l(),jp=a("li"),ode=a("strong"),wvo=o("blenderbot"),Avo=o(" \u2014 "),pq=a("a"),Lvo=o("BlenderbotModel"),yvo=o(" (Blenderbot model)"),xvo=l(),Dp=a("li"),rde=a("strong"),$vo=o("blenderbot-small"),kvo=o(" \u2014 "),_q=a("a"),Svo=o("BlenderbotSmallModel"),Rvo=o(" (BlenderbotSmall model)"),Pvo=l(),Gp=a("li"),tde=a("strong"),Bvo=o("bloom"),Ivo=o(" \u2014 "),uq=a("a"),Nvo=o("BloomModel"),qvo=o(" (BLOOM model)"),jvo=l(),Op=a("li"),ade=a("strong"),Dvo=o("camembert"),Gvo=o(" \u2014 "),bq=a("a"),Ovo=o("CamembertModel"),Vvo=o(" (CamemBERT model)"),Xvo=l(),Vp=a("li"),nde=a("strong"),zvo=o("canine"),Qvo=o(" \u2014 "),vq=a("a"),Wvo=o("CanineModel"),Hvo=o(" (CANINE model)"),Uvo=l(),Xp=a("li"),sde=a("strong"),Jvo=o("clip"),Yvo=o(" \u2014 "),Fq=a("a"),Kvo=o("CLIPModel"),Zvo=o(" (CLIP model)"),eFo=l(),zp=a("li"),lde=a("strong"),oFo=o("convbert"),rFo=o(" \u2014 "),Tq=a("a"),tFo=o("ConvBertModel"),aFo=o(" (ConvBERT model)"),nFo=l(),Qp=a("li"),ide=a("strong"),sFo=o("convnext"),lFo=o(" \u2014 "),Mq=a("a"),iFo=o("ConvNextModel"),dFo=o(" (ConvNeXT model)"),cFo=l(),Wp=a("li"),dde=a("strong"),fFo=o("ctrl"),mFo=o(" \u2014 "),Eq=a("a"),gFo=o("CTRLModel"),hFo=o(" (CTRL model)"),pFo=l(),Hp=a("li"),cde=a("strong"),_Fo=o("cvt"),uFo=o(" \u2014 "),Cq=a("a"),bFo=o("CvtModel"),vFo=o(" (CvT model)"),FFo=l(),Up=a("li"),fde=a("strong"),TFo=o("data2vec-audio"),MFo=o(" \u2014 "),wq=a("a"),EFo=o("Data2VecAudioModel"),CFo=o(" (Data2VecAudio model)"),wFo=l(),Jp=a("li"),mde=a("strong"),AFo=o("data2vec-text"),LFo=o(" \u2014 "),Aq=a("a"),yFo=o("Data2VecTextModel"),xFo=o(" (Data2VecText model)"),$Fo=l(),Yp=a("li"),gde=a("strong"),kFo=o("data2vec-vision"),SFo=o(" \u2014 "),Lq=a("a"),RFo=o("Data2VecVisionModel"),PFo=o(" (Data2VecVision model)"),BFo=l(),Kp=a("li"),hde=a("strong"),IFo=o("deberta"),NFo=o(" \u2014 "),yq=a("a"),qFo=o("DebertaModel"),jFo=o(" (DeBERTa model)"),DFo=l(),Zp=a("li"),pde=a("strong"),GFo=o("deberta-v2"),OFo=o(" \u2014 "),xq=a("a"),VFo=o("DebertaV2Model"),XFo=o(" (DeBERTa-v2 model)"),zFo=l(),e_=a("li"),_de=a("strong"),QFo=o("decision_transformer"),WFo=o(" \u2014 "),$q=a("a"),HFo=o("DecisionTransformerModel"),UFo=o(" (Decision Transformer model)"),JFo=l(),o_=a("li"),ude=a("strong"),YFo=o("deit"),KFo=o(" \u2014 "),kq=a("a"),ZFo=o("DeiTModel"),e6o=o(" (DeiT model)"),o6o=l(),r_=a("li"),bde=a("strong"),r6o=o("detr"),t6o=o(" \u2014 "),Sq=a("a"),a6o=o("DetrModel"),n6o=o(" (DETR model)"),s6o=l(),t_=a("li"),vde=a("strong"),l6o=o("distilbert"),i6o=o(" \u2014 "),Rq=a("a"),d6o=o("DistilBertModel"),c6o=o(" (DistilBERT model)"),f6o=l(),a_=a("li"),Fde=a("strong"),m6o=o("dpr"),g6o=o(" \u2014 "),Pq=a("a"),h6o=o("DPRQuestionEncoder"),p6o=o(" (DPR model)"),_6o=l(),n_=a("li"),Tde=a("strong"),u6o=o("dpt"),b6o=o(" \u2014 "),Bq=a("a"),v6o=o("DPTModel"),F6o=o(" (DPT model)"),T6o=l(),s_=a("li"),Mde=a("strong"),M6o=o("electra"),E6o=o(" \u2014 "),Iq=a("a"),C6o=o("ElectraModel"),w6o=o(" (ELECTRA model)"),A6o=l(),l_=a("li"),Ede=a("strong"),L6o=o("flaubert"),y6o=o(" \u2014 "),Nq=a("a"),x6o=o("FlaubertModel"),$6o=o(" (FlauBERT model)"),k6o=l(),i_=a("li"),Cde=a("strong"),S6o=o("flava"),R6o=o(" \u2014 "),qq=a("a"),P6o=o("FlavaModel"),B6o=o(" (FLAVA model)"),I6o=l(),d_=a("li"),wde=a("strong"),N6o=o("fnet"),q6o=o(" \u2014 "),jq=a("a"),j6o=o("FNetModel"),D6o=o(" (FNet model)"),G6o=l(),c_=a("li"),Ade=a("strong"),O6o=o("fsmt"),V6o=o(" \u2014 "),Dq=a("a"),X6o=o("FSMTModel"),z6o=o(" (FairSeq Machine-Translation model)"),Q6o=l(),Vs=a("li"),Lde=a("strong"),W6o=o("funnel"),H6o=o(" \u2014 "),Gq=a("a"),U6o=o("FunnelModel"),J6o=o(" or "),Oq=a("a"),Y6o=o("FunnelBaseModel"),K6o=o(" (Funnel Transformer model)"),Z6o=l(),f_=a("li"),yde=a("strong"),eTo=o("glpn"),oTo=o(" \u2014 "),Vq=a("a"),rTo=o("GLPNModel"),tTo=o(" (GLPN model)"),aTo=l(),m_=a("li"),xde=a("strong"),nTo=o("gpt2"),sTo=o(" \u2014 "),Xq=a("a"),lTo=o("GPT2Model"),iTo=o(" (OpenAI GPT-2 model)"),dTo=l(),g_=a("li"),$de=a("strong"),cTo=o("gpt_neo"),fTo=o(" \u2014 "),zq=a("a"),mTo=o("GPTNeoModel"),gTo=o(" (GPT Neo model)"),hTo=l(),h_=a("li"),kde=a("strong"),pTo=o("gpt_neox"),_To=o(" \u2014 "),Qq=a("a"),uTo=o("GPTNeoXModel"),bTo=o(" (GPT NeoX model)"),vTo=l(),p_=a("li"),Sde=a("strong"),FTo=o("gptj"),TTo=o(" \u2014 "),Wq=a("a"),MTo=o("GPTJModel"),ETo=o(" (GPT-J model)"),CTo=l(),__=a("li"),Rde=a("strong"),wTo=o("hubert"),ATo=o(" \u2014 "),Hq=a("a"),LTo=o("HubertModel"),yTo=o(" (Hubert model)"),xTo=l(),u_=a("li"),Pde=a("strong"),$To=o("ibert"),kTo=o(" \u2014 "),Uq=a("a"),STo=o("IBertModel"),RTo=o(" (I-BERT model)"),PTo=l(),b_=a("li"),Bde=a("strong"),BTo=o("imagegpt"),ITo=o(" \u2014 "),Jq=a("a"),NTo=o("ImageGPTModel"),qTo=o(" (ImageGPT model)"),jTo=l(),v_=a("li"),Ide=a("strong"),DTo=o("jukebox"),GTo=o(" \u2014 "),Nde=a("code"),OTo=o("JukeboxModel"),VTo=o(" (Jukebox model)"),XTo=l(),F_=a("li"),qde=a("strong"),zTo=o("layoutlm"),QTo=o(" \u2014 "),Yq=a("a"),WTo=o("LayoutLMModel"),HTo=o(" (LayoutLM model)"),UTo=l(),T_=a("li"),jde=a("strong"),JTo=o("layoutlmv2"),YTo=o(" \u2014 "),Kq=a("a"),KTo=o("LayoutLMv2Model"),ZTo=o(" (LayoutLMv2 model)"),e7o=l(),M_=a("li"),Dde=a("strong"),o7o=o("layoutlmv3"),r7o=o(" \u2014 "),Zq=a("a"),t7o=o("LayoutLMv3Model"),a7o=o(" (LayoutLMv3 model)"),n7o=l(),E_=a("li"),Gde=a("strong"),s7o=o("led"),l7o=o(" \u2014 "),ej=a("a"),i7o=o("LEDModel"),d7o=o(" (LED model)"),c7o=l(),C_=a("li"),Ode=a("strong"),f7o=o("levit"),m7o=o(" \u2014 "),oj=a("a"),g7o=o("LevitModel"),h7o=o(" (LeViT model)"),p7o=l(),w_=a("li"),Vde=a("strong"),_7o=o("longformer"),u7o=o(" \u2014 "),rj=a("a"),b7o=o("LongformerModel"),v7o=o(" (Longformer model)"),F7o=l(),A_=a("li"),Xde=a("strong"),T7o=o("longt5"),M7o=o(" \u2014 "),tj=a("a"),E7o=o("LongT5Model"),C7o=o(" (LongT5 model)"),w7o=l(),L_=a("li"),zde=a("strong"),A7o=o("luke"),L7o=o(" \u2014 "),aj=a("a"),y7o=o("LukeModel"),x7o=o(" (LUKE model)"),$7o=l(),y_=a("li"),Qde=a("strong"),k7o=o("lxmert"),S7o=o(" \u2014 "),nj=a("a"),R7o=o("LxmertModel"),P7o=o(" (LXMERT model)"),B7o=l(),x_=a("li"),Wde=a("strong"),I7o=o("m2m_100"),N7o=o(" \u2014 "),sj=a("a"),q7o=o("M2M100Model"),j7o=o(" (M2M100 model)"),D7o=l(),$_=a("li"),Hde=a("strong"),G7o=o("marian"),O7o=o(" \u2014 "),lj=a("a"),V7o=o("MarianModel"),X7o=o(" (Marian model)"),z7o=l(),k_=a("li"),Ude=a("strong"),Q7o=o("maskformer"),W7o=o(" \u2014 "),ij=a("a"),H7o=o("MaskFormerModel"),U7o=o(" (MaskFormer model)"),J7o=l(),S_=a("li"),Jde=a("strong"),Y7o=o("mbart"),K7o=o(" \u2014 "),dj=a("a"),Z7o=o("MBartModel"),e8o=o(" (mBART model)"),o8o=l(),R_=a("li"),Yde=a("strong"),r8o=o("mctct"),t8o=o(" \u2014 "),cj=a("a"),a8o=o("MCTCTModel"),n8o=o(" (M-CTC-T model)"),s8o=l(),P_=a("li"),Kde=a("strong"),l8o=o("megatron-bert"),i8o=o(" \u2014 "),fj=a("a"),d8o=o("MegatronBertModel"),c8o=o(" (Megatron-BERT model)"),f8o=l(),B_=a("li"),Zde=a("strong"),m8o=o("mobilebert"),g8o=o(" \u2014 "),mj=a("a"),h8o=o("MobileBertModel"),p8o=o(" (MobileBERT model)"),_8o=l(),I_=a("li"),ece=a("strong"),u8o=o("mpnet"),b8o=o(" \u2014 "),gj=a("a"),v8o=o("MPNetModel"),F8o=o(" (MPNet model)"),T8o=l(),N_=a("li"),oce=a("strong"),M8o=o("mt5"),E8o=o(" \u2014 "),hj=a("a"),C8o=o("MT5Model"),w8o=o(" (MT5 model)"),A8o=l(),q_=a("li"),rce=a("strong"),L8o=o("nezha"),y8o=o(" \u2014 "),pj=a("a"),x8o=o("NezhaModel"),$8o=o(" (Nezha model)"),k8o=l(),j_=a("li"),tce=a("strong"),S8o=o("nystromformer"),R8o=o(" \u2014 "),_j=a("a"),P8o=o("NystromformerModel"),B8o=o(" (Nystr\xF6mformer model)"),I8o=l(),D_=a("li"),ace=a("strong"),N8o=o("openai-gpt"),q8o=o(" \u2014 "),uj=a("a"),j8o=o("OpenAIGPTModel"),D8o=o(" (OpenAI GPT model)"),G8o=l(),G_=a("li"),nce=a("strong"),O8o=o("opt"),V8o=o(" \u2014 "),bj=a("a"),X8o=o("OPTModel"),z8o=o(" (OPT model)"),Q8o=l(),O_=a("li"),sce=a("strong"),W8o=o("pegasus"),H8o=o(" \u2014 "),vj=a("a"),U8o=o("PegasusModel"),J8o=o(" (Pegasus model)"),Y8o=l(),V_=a("li"),lce=a("strong"),K8o=o("perceiver"),Z8o=o(" \u2014 "),Fj=a("a"),eMo=o("PerceiverModel"),oMo=o(" (Perceiver model)"),rMo=l(),X_=a("li"),ice=a("strong"),tMo=o("plbart"),aMo=o(" \u2014 "),Tj=a("a"),nMo=o("PLBartModel"),sMo=o(" (PLBart model)"),lMo=l(),z_=a("li"),dce=a("strong"),iMo=o("poolformer"),dMo=o(" \u2014 "),Mj=a("a"),cMo=o("PoolFormerModel"),fMo=o(" (PoolFormer model)"),mMo=l(),Q_=a("li"),cce=a("strong"),gMo=o("prophetnet"),hMo=o(" \u2014 "),Ej=a("a"),pMo=o("ProphetNetModel"),_Mo=o(" (ProphetNet model)"),uMo=l(),W_=a("li"),fce=a("strong"),bMo=o("qdqbert"),vMo=o(" \u2014 "),Cj=a("a"),FMo=o("QDQBertModel"),TMo=o(" (QDQBert model)"),MMo=l(),H_=a("li"),mce=a("strong"),EMo=o("reformer"),CMo=o(" \u2014 "),wj=a("a"),wMo=o("ReformerModel"),AMo=o(" (Reformer model)"),LMo=l(),U_=a("li"),gce=a("strong"),yMo=o("regnet"),xMo=o(" \u2014 "),Aj=a("a"),$Mo=o("RegNetModel"),kMo=o(" (RegNet model)"),SMo=l(),J_=a("li"),hce=a("strong"),RMo=o("rembert"),PMo=o(" \u2014 "),Lj=a("a"),BMo=o("RemBertModel"),IMo=o(" (RemBERT model)"),NMo=l(),Y_=a("li"),pce=a("strong"),qMo=o("resnet"),jMo=o(" \u2014 "),yj=a("a"),DMo=o("ResNetModel"),GMo=o(" (ResNet model)"),OMo=l(),K_=a("li"),_ce=a("strong"),VMo=o("retribert"),XMo=o(" \u2014 "),xj=a("a"),zMo=o("RetriBertModel"),QMo=o(" (RetriBERT model)"),WMo=l(),Z_=a("li"),uce=a("strong"),HMo=o("roberta"),UMo=o(" \u2014 "),$j=a("a"),JMo=o("RobertaModel"),YMo=o(" (RoBERTa model)"),KMo=l(),eu=a("li"),bce=a("strong"),ZMo=o("roformer"),eEo=o(" \u2014 "),kj=a("a"),oEo=o("RoFormerModel"),rEo=o(" (RoFormer model)"),tEo=l(),ou=a("li"),vce=a("strong"),aEo=o("segformer"),nEo=o(" \u2014 "),Sj=a("a"),sEo=o("SegformerModel"),lEo=o(" (SegFormer model)"),iEo=l(),ru=a("li"),Fce=a("strong"),dEo=o("sew"),cEo=o(" \u2014 "),Rj=a("a"),fEo=o("SEWModel"),mEo=o(" (SEW model)"),gEo=l(),tu=a("li"),Tce=a("strong"),hEo=o("sew-d"),pEo=o(" \u2014 "),Pj=a("a"),_Eo=o("SEWDModel"),uEo=o(" (SEW-D model)"),bEo=l(),au=a("li"),Mce=a("strong"),vEo=o("speech_to_text"),FEo=o(" \u2014 "),Bj=a("a"),TEo=o("Speech2TextModel"),MEo=o(" (Speech2Text model)"),EEo=l(),nu=a("li"),Ece=a("strong"),CEo=o("splinter"),wEo=o(" \u2014 "),Ij=a("a"),AEo=o("SplinterModel"),LEo=o(" (Splinter model)"),yEo=l(),su=a("li"),Cce=a("strong"),xEo=o("squeezebert"),$Eo=o(" \u2014 "),Nj=a("a"),kEo=o("SqueezeBertModel"),SEo=o(" (SqueezeBERT model)"),REo=l(),lu=a("li"),wce=a("strong"),PEo=o("swin"),BEo=o(" \u2014 "),qj=a("a"),IEo=o("SwinModel"),NEo=o(" (Swin Transformer model)"),qEo=l(),iu=a("li"),Ace=a("strong"),jEo=o("t5"),DEo=o(" \u2014 "),jj=a("a"),GEo=o("T5Model"),OEo=o(" (T5 model)"),VEo=l(),du=a("li"),Lce=a("strong"),XEo=o("tapas"),zEo=o(" \u2014 "),Dj=a("a"),QEo=o("TapasModel"),WEo=o(" (TAPAS model)"),HEo=l(),cu=a("li"),yce=a("strong"),UEo=o("trajectory_transformer"),JEo=o(" \u2014 "),Gj=a("a"),YEo=o("TrajectoryTransformerModel"),KEo=o(" (Trajectory Transformer model)"),ZEo=l(),fu=a("li"),xce=a("strong"),e4o=o("transfo-xl"),o4o=o(" \u2014 "),Oj=a("a"),r4o=o("TransfoXLModel"),t4o=o(" (Transformer-XL model)"),a4o=l(),mu=a("li"),$ce=a("strong"),n4o=o("unispeech"),s4o=o(" \u2014 "),Vj=a("a"),l4o=o("UniSpeechModel"),i4o=o(" (UniSpeech model)"),d4o=l(),gu=a("li"),kce=a("strong"),c4o=o("unispeech-sat"),f4o=o(" \u2014 "),Xj=a("a"),m4o=o("UniSpeechSatModel"),g4o=o(" (UniSpeechSat model)"),h4o=l(),hu=a("li"),Sce=a("strong"),p4o=o("van"),_4o=o(" \u2014 "),zj=a("a"),u4o=o("VanModel"),b4o=o(" (VAN model)"),v4o=l(),pu=a("li"),Rce=a("strong"),F4o=o("vilt"),T4o=o(" \u2014 "),Qj=a("a"),M4o=o("ViltModel"),E4o=o(" (ViLT model)"),C4o=l(),_u=a("li"),Pce=a("strong"),w4o=o("vision-text-dual-encoder"),A4o=o(" \u2014 "),Wj=a("a"),L4o=o("VisionTextDualEncoderModel"),y4o=o(" (VisionTextDualEncoder model)"),x4o=l(),uu=a("li"),Bce=a("strong"),$4o=o("visual_bert"),k4o=o(" \u2014 "),Hj=a("a"),S4o=o("VisualBertModel"),R4o=o(" (VisualBERT model)"),P4o=l(),bu=a("li"),Ice=a("strong"),B4o=o("vit"),I4o=o(" \u2014 "),Uj=a("a"),N4o=o("ViTModel"),q4o=o(" (ViT model)"),j4o=l(),vu=a("li"),Nce=a("strong"),D4o=o("vit_mae"),G4o=o(" \u2014 "),Jj=a("a"),O4o=o("ViTMAEModel"),V4o=o(" (ViTMAE model)"),X4o=l(),Fu=a("li"),qce=a("strong"),z4o=o("wav2vec2"),Q4o=o(" \u2014 "),Yj=a("a"),W4o=o("Wav2Vec2Model"),H4o=o(" (Wav2Vec2 model)"),U4o=l(),Tu=a("li"),jce=a("strong"),J4o=o("wav2vec2-conformer"),Y4o=o(" \u2014 "),Kj=a("a"),K4o=o("Wav2Vec2ConformerModel"),Z4o=o(" (Wav2Vec2-Conformer model)"),eCo=l(),Mu=a("li"),Dce=a("strong"),oCo=o("wavlm"),rCo=o(" \u2014 "),Zj=a("a"),tCo=o("WavLMModel"),aCo=o(" (WavLM model)"),nCo=l(),Eu=a("li"),Gce=a("strong"),sCo=o("xglm"),lCo=o(" \u2014 "),eD=a("a"),iCo=o("XGLMModel"),dCo=o(" (XGLM model)"),cCo=l(),Cu=a("li"),Oce=a("strong"),fCo=o("xlm"),mCo=o(" \u2014 "),oD=a("a"),gCo=o("XLMModel"),hCo=o(" (XLM model)"),pCo=l(),wu=a("li"),Vce=a("strong"),_Co=o("xlm-prophetnet"),uCo=o(" \u2014 "),rD=a("a"),bCo=o("XLMProphetNetModel"),vCo=o(" (XLM-ProphetNet model)"),FCo=l(),Au=a("li"),Xce=a("strong"),TCo=o("xlm-roberta"),MCo=o(" \u2014 "),tD=a("a"),ECo=o("XLMRobertaModel"),CCo=o(" (XLM-RoBERTa model)"),wCo=l(),Lu=a("li"),zce=a("strong"),ACo=o("xlm-roberta-xl"),LCo=o(" \u2014 "),aD=a("a"),yCo=o("XLMRobertaXLModel"),xCo=o(" (XLM-RoBERTa-XL model)"),$Co=l(),yu=a("li"),Qce=a("strong"),kCo=o("xlnet"),SCo=o(" \u2014 "),nD=a("a"),RCo=o("XLNetModel"),PCo=o(" (XLNet model)"),BCo=l(),xu=a("li"),Wce=a("strong"),ICo=o("yolos"),NCo=o(" \u2014 "),sD=a("a"),qCo=o("YolosModel"),jCo=o(" (YOLOS model)"),DCo=l(),$u=a("li"),Hce=a("strong"),GCo=o("yoso"),OCo=o(" \u2014 "),lD=a("a"),VCo=o("YosoModel"),XCo=o(" (YOSO model)"),zCo=l(),ku=a("p"),QCo=o("The model is set in evaluation mode by default using "),Uce=a("code"),WCo=o("model.eval()"),HCo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jce=a("code"),UCo=o("model.train()"),JCo=l(),F(Su.$$.fragment),mOe=l(),qi=a("h2"),Ru=a("a"),Yce=a("span"),F(dL.$$.fragment),YCo=l(),Kce=a("span"),KCo=o("AutoModelForPreTraining"),gOe=l(),$o=a("div"),F(cL.$$.fragment),ZCo=l(),ji=a("p"),e5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),iD=a("a"),o5o=o("from_pretrained()"),r5o=o(" class method or the "),dD=a("a"),t5o=o("from_config()"),a5o=o(` class
method.`),n5o=l(),fL=a("p"),s5o=o("This class cannot be instantiated directly using "),Zce=a("code"),l5o=o("__init__()"),i5o=o(" (throws an error)."),d5o=l(),st=a("div"),F(mL.$$.fragment),c5o=l(),efe=a("p"),f5o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),m5o=l(),Di=a("p"),g5o=o(`Note:
Loading a model from its configuration file does `),ofe=a("strong"),h5o=o("not"),p5o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cD=a("a"),_5o=o("from_pretrained()"),u5o=o(" to load the model weights."),b5o=l(),F(Pu.$$.fragment),v5o=l(),Ye=a("div"),F(gL.$$.fragment),F5o=l(),rfe=a("p"),T5o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),M5o=l(),Pa=a("p"),E5o=o("The model class to instantiate is selected based on the "),tfe=a("code"),C5o=o("model_type"),w5o=o(` property of the config object (either
passed as an argument or loaded from `),afe=a("code"),A5o=o("pretrained_model_name_or_path"),L5o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nfe=a("code"),y5o=o("pretrained_model_name_or_path"),x5o=o(":"),$5o=l(),G=a("ul"),Bu=a("li"),sfe=a("strong"),k5o=o("albert"),S5o=o(" \u2014 "),fD=a("a"),R5o=o("AlbertForPreTraining"),P5o=o(" (ALBERT model)"),B5o=l(),Iu=a("li"),lfe=a("strong"),I5o=o("bart"),N5o=o(" \u2014 "),mD=a("a"),q5o=o("BartForConditionalGeneration"),j5o=o(" (BART model)"),D5o=l(),Nu=a("li"),ife=a("strong"),G5o=o("bert"),O5o=o(" \u2014 "),gD=a("a"),V5o=o("BertForPreTraining"),X5o=o(" (BERT model)"),z5o=l(),qu=a("li"),dfe=a("strong"),Q5o=o("big_bird"),W5o=o(" \u2014 "),hD=a("a"),H5o=o("BigBirdForPreTraining"),U5o=o(" (BigBird model)"),J5o=l(),ju=a("li"),cfe=a("strong"),Y5o=o("bloom"),K5o=o(" \u2014 "),pD=a("a"),Z5o=o("BloomForCausalLM"),e3o=o(" (BLOOM model)"),o3o=l(),Du=a("li"),ffe=a("strong"),r3o=o("camembert"),t3o=o(" \u2014 "),_D=a("a"),a3o=o("CamembertForMaskedLM"),n3o=o(" (CamemBERT model)"),s3o=l(),Gu=a("li"),mfe=a("strong"),l3o=o("ctrl"),i3o=o(" \u2014 "),uD=a("a"),d3o=o("CTRLLMHeadModel"),c3o=o(" (CTRL model)"),f3o=l(),Ou=a("li"),gfe=a("strong"),m3o=o("data2vec-text"),g3o=o(" \u2014 "),bD=a("a"),h3o=o("Data2VecTextForMaskedLM"),p3o=o(" (Data2VecText model)"),_3o=l(),Vu=a("li"),hfe=a("strong"),u3o=o("deberta"),b3o=o(" \u2014 "),vD=a("a"),v3o=o("DebertaForMaskedLM"),F3o=o(" (DeBERTa model)"),T3o=l(),Xu=a("li"),pfe=a("strong"),M3o=o("deberta-v2"),E3o=o(" \u2014 "),FD=a("a"),C3o=o("DebertaV2ForMaskedLM"),w3o=o(" (DeBERTa-v2 model)"),A3o=l(),zu=a("li"),_fe=a("strong"),L3o=o("distilbert"),y3o=o(" \u2014 "),TD=a("a"),x3o=o("DistilBertForMaskedLM"),$3o=o(" (DistilBERT model)"),k3o=l(),Qu=a("li"),ufe=a("strong"),S3o=o("electra"),R3o=o(" \u2014 "),MD=a("a"),P3o=o("ElectraForPreTraining"),B3o=o(" (ELECTRA model)"),I3o=l(),Wu=a("li"),bfe=a("strong"),N3o=o("flaubert"),q3o=o(" \u2014 "),ED=a("a"),j3o=o("FlaubertWithLMHeadModel"),D3o=o(" (FlauBERT model)"),G3o=l(),Hu=a("li"),vfe=a("strong"),O3o=o("flava"),V3o=o(" \u2014 "),CD=a("a"),X3o=o("FlavaForPreTraining"),z3o=o(" (FLAVA model)"),Q3o=l(),Uu=a("li"),Ffe=a("strong"),W3o=o("fnet"),H3o=o(" \u2014 "),wD=a("a"),U3o=o("FNetForPreTraining"),J3o=o(" (FNet model)"),Y3o=l(),Ju=a("li"),Tfe=a("strong"),K3o=o("fsmt"),Z3o=o(" \u2014 "),AD=a("a"),e0o=o("FSMTForConditionalGeneration"),o0o=o(" (FairSeq Machine-Translation model)"),r0o=l(),Yu=a("li"),Mfe=a("strong"),t0o=o("funnel"),a0o=o(" \u2014 "),LD=a("a"),n0o=o("FunnelForPreTraining"),s0o=o(" (Funnel Transformer model)"),l0o=l(),Ku=a("li"),Efe=a("strong"),i0o=o("gpt2"),d0o=o(" \u2014 "),yD=a("a"),c0o=o("GPT2LMHeadModel"),f0o=o(" (OpenAI GPT-2 model)"),m0o=l(),Zu=a("li"),Cfe=a("strong"),g0o=o("ibert"),h0o=o(" \u2014 "),xD=a("a"),p0o=o("IBertForMaskedLM"),_0o=o(" (I-BERT model)"),u0o=l(),e2=a("li"),wfe=a("strong"),b0o=o("layoutlm"),v0o=o(" \u2014 "),$D=a("a"),F0o=o("LayoutLMForMaskedLM"),T0o=o(" (LayoutLM model)"),M0o=l(),o2=a("li"),Afe=a("strong"),E0o=o("longformer"),C0o=o(" \u2014 "),kD=a("a"),w0o=o("LongformerForMaskedLM"),A0o=o(" (Longformer model)"),L0o=l(),r2=a("li"),Lfe=a("strong"),y0o=o("lxmert"),x0o=o(" \u2014 "),SD=a("a"),$0o=o("LxmertForPreTraining"),k0o=o(" (LXMERT model)"),S0o=l(),t2=a("li"),yfe=a("strong"),R0o=o("megatron-bert"),P0o=o(" \u2014 "),RD=a("a"),B0o=o("MegatronBertForPreTraining"),I0o=o(" (Megatron-BERT model)"),N0o=l(),a2=a("li"),xfe=a("strong"),q0o=o("mobilebert"),j0o=o(" \u2014 "),PD=a("a"),D0o=o("MobileBertForPreTraining"),G0o=o(" (MobileBERT model)"),O0o=l(),n2=a("li"),$fe=a("strong"),V0o=o("mpnet"),X0o=o(" \u2014 "),BD=a("a"),z0o=o("MPNetForMaskedLM"),Q0o=o(" (MPNet model)"),W0o=l(),s2=a("li"),kfe=a("strong"),H0o=o("nezha"),U0o=o(" \u2014 "),ID=a("a"),J0o=o("NezhaForPreTraining"),Y0o=o(" (Nezha model)"),K0o=l(),l2=a("li"),Sfe=a("strong"),Z0o=o("openai-gpt"),ewo=o(" \u2014 "),ND=a("a"),owo=o("OpenAIGPTLMHeadModel"),rwo=o(" (OpenAI GPT model)"),two=l(),i2=a("li"),Rfe=a("strong"),awo=o("retribert"),nwo=o(" \u2014 "),qD=a("a"),swo=o("RetriBertModel"),lwo=o(" (RetriBERT model)"),iwo=l(),d2=a("li"),Pfe=a("strong"),dwo=o("roberta"),cwo=o(" \u2014 "),jD=a("a"),fwo=o("RobertaForMaskedLM"),mwo=o(" (RoBERTa model)"),gwo=l(),c2=a("li"),Bfe=a("strong"),hwo=o("splinter"),pwo=o(" \u2014 "),DD=a("a"),_wo=o("SplinterForPreTraining"),uwo=o(" (Splinter model)"),bwo=l(),f2=a("li"),Ife=a("strong"),vwo=o("squeezebert"),Fwo=o(" \u2014 "),GD=a("a"),Two=o("SqueezeBertForMaskedLM"),Mwo=o(" (SqueezeBERT model)"),Ewo=l(),m2=a("li"),Nfe=a("strong"),Cwo=o("t5"),wwo=o(" \u2014 "),OD=a("a"),Awo=o("T5ForConditionalGeneration"),Lwo=o(" (T5 model)"),ywo=l(),g2=a("li"),qfe=a("strong"),xwo=o("tapas"),$wo=o(" \u2014 "),VD=a("a"),kwo=o("TapasForMaskedLM"),Swo=o(" (TAPAS model)"),Rwo=l(),h2=a("li"),jfe=a("strong"),Pwo=o("transfo-xl"),Bwo=o(" \u2014 "),XD=a("a"),Iwo=o("TransfoXLLMHeadModel"),Nwo=o(" (Transformer-XL model)"),qwo=l(),p2=a("li"),Dfe=a("strong"),jwo=o("unispeech"),Dwo=o(" \u2014 "),zD=a("a"),Gwo=o("UniSpeechForPreTraining"),Owo=o(" (UniSpeech model)"),Vwo=l(),_2=a("li"),Gfe=a("strong"),Xwo=o("unispeech-sat"),zwo=o(" \u2014 "),QD=a("a"),Qwo=o("UniSpeechSatForPreTraining"),Wwo=o(" (UniSpeechSat model)"),Hwo=l(),u2=a("li"),Ofe=a("strong"),Uwo=o("visual_bert"),Jwo=o(" \u2014 "),WD=a("a"),Ywo=o("VisualBertForPreTraining"),Kwo=o(" (VisualBERT model)"),Zwo=l(),b2=a("li"),Vfe=a("strong"),eAo=o("vit_mae"),oAo=o(" \u2014 "),HD=a("a"),rAo=o("ViTMAEForPreTraining"),tAo=o(" (ViTMAE model)"),aAo=l(),v2=a("li"),Xfe=a("strong"),nAo=o("wav2vec2"),sAo=o(" \u2014 "),UD=a("a"),lAo=o("Wav2Vec2ForPreTraining"),iAo=o(" (Wav2Vec2 model)"),dAo=l(),F2=a("li"),zfe=a("strong"),cAo=o("wav2vec2-conformer"),fAo=o(" \u2014 "),JD=a("a"),mAo=o("Wav2Vec2ConformerForPreTraining"),gAo=o(" (Wav2Vec2-Conformer model)"),hAo=l(),T2=a("li"),Qfe=a("strong"),pAo=o("xlm"),_Ao=o(" \u2014 "),YD=a("a"),uAo=o("XLMWithLMHeadModel"),bAo=o(" (XLM model)"),vAo=l(),M2=a("li"),Wfe=a("strong"),FAo=o("xlm-roberta"),TAo=o(" \u2014 "),KD=a("a"),MAo=o("XLMRobertaForMaskedLM"),EAo=o(" (XLM-RoBERTa model)"),CAo=l(),E2=a("li"),Hfe=a("strong"),wAo=o("xlm-roberta-xl"),AAo=o(" \u2014 "),ZD=a("a"),LAo=o("XLMRobertaXLForMaskedLM"),yAo=o(" (XLM-RoBERTa-XL model)"),xAo=l(),C2=a("li"),Ufe=a("strong"),$Ao=o("xlnet"),kAo=o(" \u2014 "),eG=a("a"),SAo=o("XLNetLMHeadModel"),RAo=o(" (XLNet model)"),PAo=l(),w2=a("p"),BAo=o("The model is set in evaluation mode by default using "),Jfe=a("code"),IAo=o("model.eval()"),NAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yfe=a("code"),qAo=o("model.train()"),jAo=l(),F(A2.$$.fragment),hOe=l(),Gi=a("h2"),L2=a("a"),Kfe=a("span"),F(hL.$$.fragment),DAo=l(),Zfe=a("span"),GAo=o("AutoModelForCausalLM"),pOe=l(),ko=a("div"),F(pL.$$.fragment),OAo=l(),Oi=a("p"),VAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),oG=a("a"),XAo=o("from_pretrained()"),zAo=o(" class method or the "),rG=a("a"),QAo=o("from_config()"),WAo=o(` class
method.`),HAo=l(),_L=a("p"),UAo=o("This class cannot be instantiated directly using "),eme=a("code"),JAo=o("__init__()"),YAo=o(" (throws an error)."),KAo=l(),lt=a("div"),F(uL.$$.fragment),ZAo=l(),ome=a("p"),eLo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),oLo=l(),Vi=a("p"),rLo=o(`Note:
Loading a model from its configuration file does `),rme=a("strong"),tLo=o("not"),aLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tG=a("a"),nLo=o("from_pretrained()"),sLo=o(" to load the model weights."),lLo=l(),F(y2.$$.fragment),iLo=l(),Ke=a("div"),F(bL.$$.fragment),dLo=l(),tme=a("p"),cLo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),fLo=l(),Ba=a("p"),mLo=o("The model class to instantiate is selected based on the "),ame=a("code"),gLo=o("model_type"),hLo=o(` property of the config object (either
passed as an argument or loaded from `),nme=a("code"),pLo=o("pretrained_model_name_or_path"),_Lo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sme=a("code"),uLo=o("pretrained_model_name_or_path"),bLo=o(":"),vLo=l(),z=a("ul"),x2=a("li"),lme=a("strong"),FLo=o("bart"),TLo=o(" \u2014 "),aG=a("a"),MLo=o("BartForCausalLM"),ELo=o(" (BART model)"),CLo=l(),$2=a("li"),ime=a("strong"),wLo=o("bert"),ALo=o(" \u2014 "),nG=a("a"),LLo=o("BertLMHeadModel"),yLo=o(" (BERT model)"),xLo=l(),k2=a("li"),dme=a("strong"),$Lo=o("bert-generation"),kLo=o(" \u2014 "),sG=a("a"),SLo=o("BertGenerationDecoder"),RLo=o(" (Bert Generation model)"),PLo=l(),S2=a("li"),cme=a("strong"),BLo=o("big_bird"),ILo=o(" \u2014 "),lG=a("a"),NLo=o("BigBirdForCausalLM"),qLo=o(" (BigBird model)"),jLo=l(),R2=a("li"),fme=a("strong"),DLo=o("bigbird_pegasus"),GLo=o(" \u2014 "),iG=a("a"),OLo=o("BigBirdPegasusForCausalLM"),VLo=o(" (BigBird-Pegasus model)"),XLo=l(),P2=a("li"),mme=a("strong"),zLo=o("blenderbot"),QLo=o(" \u2014 "),dG=a("a"),WLo=o("BlenderbotForCausalLM"),HLo=o(" (Blenderbot model)"),ULo=l(),B2=a("li"),gme=a("strong"),JLo=o("blenderbot-small"),YLo=o(" \u2014 "),cG=a("a"),KLo=o("BlenderbotSmallForCausalLM"),ZLo=o(" (BlenderbotSmall model)"),eyo=l(),I2=a("li"),hme=a("strong"),oyo=o("bloom"),ryo=o(" \u2014 "),fG=a("a"),tyo=o("BloomForCausalLM"),ayo=o(" (BLOOM model)"),nyo=l(),N2=a("li"),pme=a("strong"),syo=o("camembert"),lyo=o(" \u2014 "),mG=a("a"),iyo=o("CamembertForCausalLM"),dyo=o(" (CamemBERT model)"),cyo=l(),q2=a("li"),_me=a("strong"),fyo=o("ctrl"),myo=o(" \u2014 "),gG=a("a"),gyo=o("CTRLLMHeadModel"),hyo=o(" (CTRL model)"),pyo=l(),j2=a("li"),ume=a("strong"),_yo=o("data2vec-text"),uyo=o(" \u2014 "),hG=a("a"),byo=o("Data2VecTextForCausalLM"),vyo=o(" (Data2VecText model)"),Fyo=l(),D2=a("li"),bme=a("strong"),Tyo=o("electra"),Myo=o(" \u2014 "),pG=a("a"),Eyo=o("ElectraForCausalLM"),Cyo=o(" (ELECTRA model)"),wyo=l(),G2=a("li"),vme=a("strong"),Ayo=o("gpt2"),Lyo=o(" \u2014 "),_G=a("a"),yyo=o("GPT2LMHeadModel"),xyo=o(" (OpenAI GPT-2 model)"),$yo=l(),O2=a("li"),Fme=a("strong"),kyo=o("gpt_neo"),Syo=o(" \u2014 "),uG=a("a"),Ryo=o("GPTNeoForCausalLM"),Pyo=o(" (GPT Neo model)"),Byo=l(),V2=a("li"),Tme=a("strong"),Iyo=o("gpt_neox"),Nyo=o(" \u2014 "),bG=a("a"),qyo=o("GPTNeoXForCausalLM"),jyo=o(" (GPT NeoX model)"),Dyo=l(),X2=a("li"),Mme=a("strong"),Gyo=o("gptj"),Oyo=o(" \u2014 "),vG=a("a"),Vyo=o("GPTJForCausalLM"),Xyo=o(" (GPT-J model)"),zyo=l(),z2=a("li"),Eme=a("strong"),Qyo=o("marian"),Wyo=o(" \u2014 "),FG=a("a"),Hyo=o("MarianForCausalLM"),Uyo=o(" (Marian model)"),Jyo=l(),Q2=a("li"),Cme=a("strong"),Yyo=o("mbart"),Kyo=o(" \u2014 "),TG=a("a"),Zyo=o("MBartForCausalLM"),e9o=o(" (mBART model)"),o9o=l(),W2=a("li"),wme=a("strong"),r9o=o("megatron-bert"),t9o=o(" \u2014 "),MG=a("a"),a9o=o("MegatronBertForCausalLM"),n9o=o(" (Megatron-BERT model)"),s9o=l(),H2=a("li"),Ame=a("strong"),l9o=o("openai-gpt"),i9o=o(" \u2014 "),EG=a("a"),d9o=o("OpenAIGPTLMHeadModel"),c9o=o(" (OpenAI GPT model)"),f9o=l(),U2=a("li"),Lme=a("strong"),m9o=o("opt"),g9o=o(" \u2014 "),CG=a("a"),h9o=o("OPTForCausalLM"),p9o=o(" (OPT model)"),_9o=l(),J2=a("li"),yme=a("strong"),u9o=o("pegasus"),b9o=o(" \u2014 "),wG=a("a"),v9o=o("PegasusForCausalLM"),F9o=o(" (Pegasus model)"),T9o=l(),Y2=a("li"),xme=a("strong"),M9o=o("plbart"),E9o=o(" \u2014 "),AG=a("a"),C9o=o("PLBartForCausalLM"),w9o=o(" (PLBart model)"),A9o=l(),K2=a("li"),$me=a("strong"),L9o=o("prophetnet"),y9o=o(" \u2014 "),LG=a("a"),x9o=o("ProphetNetForCausalLM"),$9o=o(" (ProphetNet model)"),k9o=l(),Z2=a("li"),kme=a("strong"),S9o=o("qdqbert"),R9o=o(" \u2014 "),yG=a("a"),P9o=o("QDQBertLMHeadModel"),B9o=o(" (QDQBert model)"),I9o=l(),e1=a("li"),Sme=a("strong"),N9o=o("reformer"),q9o=o(" \u2014 "),xG=a("a"),j9o=o("ReformerModelWithLMHead"),D9o=o(" (Reformer model)"),G9o=l(),o1=a("li"),Rme=a("strong"),O9o=o("rembert"),V9o=o(" \u2014 "),$G=a("a"),X9o=o("RemBertForCausalLM"),z9o=o(" (RemBERT model)"),Q9o=l(),r1=a("li"),Pme=a("strong"),W9o=o("roberta"),H9o=o(" \u2014 "),kG=a("a"),U9o=o("RobertaForCausalLM"),J9o=o(" (RoBERTa model)"),Y9o=l(),t1=a("li"),Bme=a("strong"),K9o=o("roformer"),Z9o=o(" \u2014 "),SG=a("a"),exo=o("RoFormerForCausalLM"),oxo=o(" (RoFormer model)"),rxo=l(),a1=a("li"),Ime=a("strong"),txo=o("speech_to_text_2"),axo=o(" \u2014 "),RG=a("a"),nxo=o("Speech2Text2ForCausalLM"),sxo=o(" (Speech2Text2 model)"),lxo=l(),n1=a("li"),Nme=a("strong"),ixo=o("transfo-xl"),dxo=o(" \u2014 "),PG=a("a"),cxo=o("TransfoXLLMHeadModel"),fxo=o(" (Transformer-XL model)"),mxo=l(),s1=a("li"),qme=a("strong"),gxo=o("trocr"),hxo=o(" \u2014 "),BG=a("a"),pxo=o("TrOCRForCausalLM"),_xo=o(" (TrOCR model)"),uxo=l(),l1=a("li"),jme=a("strong"),bxo=o("xglm"),vxo=o(" \u2014 "),IG=a("a"),Fxo=o("XGLMForCausalLM"),Txo=o(" (XGLM model)"),Mxo=l(),i1=a("li"),Dme=a("strong"),Exo=o("xlm"),Cxo=o(" \u2014 "),NG=a("a"),wxo=o("XLMWithLMHeadModel"),Axo=o(" (XLM model)"),Lxo=l(),d1=a("li"),Gme=a("strong"),yxo=o("xlm-prophetnet"),xxo=o(" \u2014 "),qG=a("a"),$xo=o("XLMProphetNetForCausalLM"),kxo=o(" (XLM-ProphetNet model)"),Sxo=l(),c1=a("li"),Ome=a("strong"),Rxo=o("xlm-roberta"),Pxo=o(" \u2014 "),jG=a("a"),Bxo=o("XLMRobertaForCausalLM"),Ixo=o(" (XLM-RoBERTa model)"),Nxo=l(),f1=a("li"),Vme=a("strong"),qxo=o("xlm-roberta-xl"),jxo=o(" \u2014 "),DG=a("a"),Dxo=o("XLMRobertaXLForCausalLM"),Gxo=o(" (XLM-RoBERTa-XL model)"),Oxo=l(),m1=a("li"),Xme=a("strong"),Vxo=o("xlnet"),Xxo=o(" \u2014 "),GG=a("a"),zxo=o("XLNetLMHeadModel"),Qxo=o(" (XLNet model)"),Wxo=l(),g1=a("p"),Hxo=o("The model is set in evaluation mode by default using "),zme=a("code"),Uxo=o("model.eval()"),Jxo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qme=a("code"),Yxo=o("model.train()"),Kxo=l(),F(h1.$$.fragment),_Oe=l(),Xi=a("h2"),p1=a("a"),Wme=a("span"),F(vL.$$.fragment),Zxo=l(),Hme=a("span"),e$o=o("AutoModelForMaskedLM"),uOe=l(),So=a("div"),F(FL.$$.fragment),o$o=l(),zi=a("p"),r$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),OG=a("a"),t$o=o("from_pretrained()"),a$o=o(" class method or the "),VG=a("a"),n$o=o("from_config()"),s$o=o(` class
method.`),l$o=l(),TL=a("p"),i$o=o("This class cannot be instantiated directly using "),Ume=a("code"),d$o=o("__init__()"),c$o=o(" (throws an error)."),f$o=l(),it=a("div"),F(ML.$$.fragment),m$o=l(),Jme=a("p"),g$o=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),h$o=l(),Qi=a("p"),p$o=o(`Note:
Loading a model from its configuration file does `),Yme=a("strong"),_$o=o("not"),u$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XG=a("a"),b$o=o("from_pretrained()"),v$o=o(" to load the model weights."),F$o=l(),F(_1.$$.fragment),T$o=l(),Ze=a("div"),F(EL.$$.fragment),M$o=l(),Kme=a("p"),E$o=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),C$o=l(),Ia=a("p"),w$o=o("The model class to instantiate is selected based on the "),Zme=a("code"),A$o=o("model_type"),L$o=o(` property of the config object (either
passed as an argument or loaded from `),ege=a("code"),y$o=o("pretrained_model_name_or_path"),x$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oge=a("code"),$$o=o("pretrained_model_name_or_path"),k$o=o(":"),S$o=l(),Q=a("ul"),u1=a("li"),rge=a("strong"),R$o=o("albert"),P$o=o(" \u2014 "),zG=a("a"),B$o=o("AlbertForMaskedLM"),I$o=o(" (ALBERT model)"),N$o=l(),b1=a("li"),tge=a("strong"),q$o=o("bart"),j$o=o(" \u2014 "),QG=a("a"),D$o=o("BartForConditionalGeneration"),G$o=o(" (BART model)"),O$o=l(),v1=a("li"),age=a("strong"),V$o=o("bert"),X$o=o(" \u2014 "),WG=a("a"),z$o=o("BertForMaskedLM"),Q$o=o(" (BERT model)"),W$o=l(),F1=a("li"),nge=a("strong"),H$o=o("big_bird"),U$o=o(" \u2014 "),HG=a("a"),J$o=o("BigBirdForMaskedLM"),Y$o=o(" (BigBird model)"),K$o=l(),T1=a("li"),sge=a("strong"),Z$o=o("camembert"),eko=o(" \u2014 "),UG=a("a"),oko=o("CamembertForMaskedLM"),rko=o(" (CamemBERT model)"),tko=l(),M1=a("li"),lge=a("strong"),ako=o("convbert"),nko=o(" \u2014 "),JG=a("a"),sko=o("ConvBertForMaskedLM"),lko=o(" (ConvBERT model)"),iko=l(),E1=a("li"),ige=a("strong"),dko=o("data2vec-text"),cko=o(" \u2014 "),YG=a("a"),fko=o("Data2VecTextForMaskedLM"),mko=o(" (Data2VecText model)"),gko=l(),C1=a("li"),dge=a("strong"),hko=o("deberta"),pko=o(" \u2014 "),KG=a("a"),_ko=o("DebertaForMaskedLM"),uko=o(" (DeBERTa model)"),bko=l(),w1=a("li"),cge=a("strong"),vko=o("deberta-v2"),Fko=o(" \u2014 "),ZG=a("a"),Tko=o("DebertaV2ForMaskedLM"),Mko=o(" (DeBERTa-v2 model)"),Eko=l(),A1=a("li"),fge=a("strong"),Cko=o("distilbert"),wko=o(" \u2014 "),eO=a("a"),Ako=o("DistilBertForMaskedLM"),Lko=o(" (DistilBERT model)"),yko=l(),L1=a("li"),mge=a("strong"),xko=o("electra"),$ko=o(" \u2014 "),oO=a("a"),kko=o("ElectraForMaskedLM"),Sko=o(" (ELECTRA model)"),Rko=l(),y1=a("li"),gge=a("strong"),Pko=o("flaubert"),Bko=o(" \u2014 "),rO=a("a"),Iko=o("FlaubertWithLMHeadModel"),Nko=o(" (FlauBERT model)"),qko=l(),x1=a("li"),hge=a("strong"),jko=o("fnet"),Dko=o(" \u2014 "),tO=a("a"),Gko=o("FNetForMaskedLM"),Oko=o(" (FNet model)"),Vko=l(),$1=a("li"),pge=a("strong"),Xko=o("funnel"),zko=o(" \u2014 "),aO=a("a"),Qko=o("FunnelForMaskedLM"),Wko=o(" (Funnel Transformer model)"),Hko=l(),k1=a("li"),_ge=a("strong"),Uko=o("ibert"),Jko=o(" \u2014 "),nO=a("a"),Yko=o("IBertForMaskedLM"),Kko=o(" (I-BERT model)"),Zko=l(),S1=a("li"),uge=a("strong"),eSo=o("layoutlm"),oSo=o(" \u2014 "),sO=a("a"),rSo=o("LayoutLMForMaskedLM"),tSo=o(" (LayoutLM model)"),aSo=l(),R1=a("li"),bge=a("strong"),nSo=o("longformer"),sSo=o(" \u2014 "),lO=a("a"),lSo=o("LongformerForMaskedLM"),iSo=o(" (Longformer model)"),dSo=l(),P1=a("li"),vge=a("strong"),cSo=o("luke"),fSo=o(" \u2014 "),iO=a("a"),mSo=o("LukeForMaskedLM"),gSo=o(" (LUKE model)"),hSo=l(),B1=a("li"),Fge=a("strong"),pSo=o("mbart"),_So=o(" \u2014 "),dO=a("a"),uSo=o("MBartForConditionalGeneration"),bSo=o(" (mBART model)"),vSo=l(),I1=a("li"),Tge=a("strong"),FSo=o("megatron-bert"),TSo=o(" \u2014 "),cO=a("a"),MSo=o("MegatronBertForMaskedLM"),ESo=o(" (Megatron-BERT model)"),CSo=l(),N1=a("li"),Mge=a("strong"),wSo=o("mobilebert"),ASo=o(" \u2014 "),fO=a("a"),LSo=o("MobileBertForMaskedLM"),ySo=o(" (MobileBERT model)"),xSo=l(),q1=a("li"),Ege=a("strong"),$So=o("mpnet"),kSo=o(" \u2014 "),mO=a("a"),SSo=o("MPNetForMaskedLM"),RSo=o(" (MPNet model)"),PSo=l(),j1=a("li"),Cge=a("strong"),BSo=o("nezha"),ISo=o(" \u2014 "),gO=a("a"),NSo=o("NezhaForMaskedLM"),qSo=o(" (Nezha model)"),jSo=l(),D1=a("li"),wge=a("strong"),DSo=o("nystromformer"),GSo=o(" \u2014 "),hO=a("a"),OSo=o("NystromformerForMaskedLM"),VSo=o(" (Nystr\xF6mformer model)"),XSo=l(),G1=a("li"),Age=a("strong"),zSo=o("perceiver"),QSo=o(" \u2014 "),pO=a("a"),WSo=o("PerceiverForMaskedLM"),HSo=o(" (Perceiver model)"),USo=l(),O1=a("li"),Lge=a("strong"),JSo=o("qdqbert"),YSo=o(" \u2014 "),_O=a("a"),KSo=o("QDQBertForMaskedLM"),ZSo=o(" (QDQBert model)"),eRo=l(),V1=a("li"),yge=a("strong"),oRo=o("reformer"),rRo=o(" \u2014 "),uO=a("a"),tRo=o("ReformerForMaskedLM"),aRo=o(" (Reformer model)"),nRo=l(),X1=a("li"),xge=a("strong"),sRo=o("rembert"),lRo=o(" \u2014 "),bO=a("a"),iRo=o("RemBertForMaskedLM"),dRo=o(" (RemBERT model)"),cRo=l(),z1=a("li"),$ge=a("strong"),fRo=o("roberta"),mRo=o(" \u2014 "),vO=a("a"),gRo=o("RobertaForMaskedLM"),hRo=o(" (RoBERTa model)"),pRo=l(),Q1=a("li"),kge=a("strong"),_Ro=o("roformer"),uRo=o(" \u2014 "),FO=a("a"),bRo=o("RoFormerForMaskedLM"),vRo=o(" (RoFormer model)"),FRo=l(),W1=a("li"),Sge=a("strong"),TRo=o("squeezebert"),MRo=o(" \u2014 "),TO=a("a"),ERo=o("SqueezeBertForMaskedLM"),CRo=o(" (SqueezeBERT model)"),wRo=l(),H1=a("li"),Rge=a("strong"),ARo=o("tapas"),LRo=o(" \u2014 "),MO=a("a"),yRo=o("TapasForMaskedLM"),xRo=o(" (TAPAS model)"),$Ro=l(),U1=a("li"),Pge=a("strong"),kRo=o("wav2vec2"),SRo=o(" \u2014 "),Bge=a("code"),RRo=o("Wav2Vec2ForMaskedLM"),PRo=o(" (Wav2Vec2 model)"),BRo=l(),J1=a("li"),Ige=a("strong"),IRo=o("xlm"),NRo=o(" \u2014 "),EO=a("a"),qRo=o("XLMWithLMHeadModel"),jRo=o(" (XLM model)"),DRo=l(),Y1=a("li"),Nge=a("strong"),GRo=o("xlm-roberta"),ORo=o(" \u2014 "),CO=a("a"),VRo=o("XLMRobertaForMaskedLM"),XRo=o(" (XLM-RoBERTa model)"),zRo=l(),K1=a("li"),qge=a("strong"),QRo=o("xlm-roberta-xl"),WRo=o(" \u2014 "),wO=a("a"),HRo=o("XLMRobertaXLForMaskedLM"),URo=o(" (XLM-RoBERTa-XL model)"),JRo=l(),Z1=a("li"),jge=a("strong"),YRo=o("yoso"),KRo=o(" \u2014 "),AO=a("a"),ZRo=o("YosoForMaskedLM"),ePo=o(" (YOSO model)"),oPo=l(),eb=a("p"),rPo=o("The model is set in evaluation mode by default using "),Dge=a("code"),tPo=o("model.eval()"),aPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gge=a("code"),nPo=o("model.train()"),sPo=l(),F(ob.$$.fragment),bOe=l(),Wi=a("h2"),rb=a("a"),Oge=a("span"),F(CL.$$.fragment),lPo=l(),Vge=a("span"),iPo=o("AutoModelForSeq2SeqLM"),vOe=l(),Ro=a("div"),F(wL.$$.fragment),dPo=l(),Hi=a("p"),cPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),LO=a("a"),fPo=o("from_pretrained()"),mPo=o(" class method or the "),yO=a("a"),gPo=o("from_config()"),hPo=o(` class
method.`),pPo=l(),AL=a("p"),_Po=o("This class cannot be instantiated directly using "),Xge=a("code"),uPo=o("__init__()"),bPo=o(" (throws an error)."),vPo=l(),dt=a("div"),F(LL.$$.fragment),FPo=l(),zge=a("p"),TPo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),MPo=l(),Ui=a("p"),EPo=o(`Note:
Loading a model from its configuration file does `),Qge=a("strong"),CPo=o("not"),wPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xO=a("a"),APo=o("from_pretrained()"),LPo=o(" to load the model weights."),yPo=l(),F(tb.$$.fragment),xPo=l(),eo=a("div"),F(yL.$$.fragment),$Po=l(),Wge=a("p"),kPo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),SPo=l(),Na=a("p"),RPo=o("The model class to instantiate is selected based on the "),Hge=a("code"),PPo=o("model_type"),BPo=o(` property of the config object (either
passed as an argument or loaded from `),Uge=a("code"),IPo=o("pretrained_model_name_or_path"),NPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jge=a("code"),qPo=o("pretrained_model_name_or_path"),jPo=o(":"),DPo=l(),pe=a("ul"),ab=a("li"),Yge=a("strong"),GPo=o("bart"),OPo=o(" \u2014 "),$O=a("a"),VPo=o("BartForConditionalGeneration"),XPo=o(" (BART model)"),zPo=l(),nb=a("li"),Kge=a("strong"),QPo=o("bigbird_pegasus"),WPo=o(" \u2014 "),kO=a("a"),HPo=o("BigBirdPegasusForConditionalGeneration"),UPo=o(" (BigBird-Pegasus model)"),JPo=l(),sb=a("li"),Zge=a("strong"),YPo=o("blenderbot"),KPo=o(" \u2014 "),SO=a("a"),ZPo=o("BlenderbotForConditionalGeneration"),eBo=o(" (Blenderbot model)"),oBo=l(),lb=a("li"),ehe=a("strong"),rBo=o("blenderbot-small"),tBo=o(" \u2014 "),RO=a("a"),aBo=o("BlenderbotSmallForConditionalGeneration"),nBo=o(" (BlenderbotSmall model)"),sBo=l(),ib=a("li"),ohe=a("strong"),lBo=o("encoder-decoder"),iBo=o(" \u2014 "),PO=a("a"),dBo=o("EncoderDecoderModel"),cBo=o(" (Encoder decoder model)"),fBo=l(),db=a("li"),rhe=a("strong"),mBo=o("fsmt"),gBo=o(" \u2014 "),BO=a("a"),hBo=o("FSMTForConditionalGeneration"),pBo=o(" (FairSeq Machine-Translation model)"),_Bo=l(),cb=a("li"),the=a("strong"),uBo=o("led"),bBo=o(" \u2014 "),IO=a("a"),vBo=o("LEDForConditionalGeneration"),FBo=o(" (LED model)"),TBo=l(),fb=a("li"),ahe=a("strong"),MBo=o("longt5"),EBo=o(" \u2014 "),NO=a("a"),CBo=o("LongT5ForConditionalGeneration"),wBo=o(" (LongT5 model)"),ABo=l(),mb=a("li"),nhe=a("strong"),LBo=o("m2m_100"),yBo=o(" \u2014 "),qO=a("a"),xBo=o("M2M100ForConditionalGeneration"),$Bo=o(" (M2M100 model)"),kBo=l(),gb=a("li"),she=a("strong"),SBo=o("marian"),RBo=o(" \u2014 "),jO=a("a"),PBo=o("MarianMTModel"),BBo=o(" (Marian model)"),IBo=l(),hb=a("li"),lhe=a("strong"),NBo=o("mbart"),qBo=o(" \u2014 "),DO=a("a"),jBo=o("MBartForConditionalGeneration"),DBo=o(" (mBART model)"),GBo=l(),pb=a("li"),ihe=a("strong"),OBo=o("mt5"),VBo=o(" \u2014 "),GO=a("a"),XBo=o("MT5ForConditionalGeneration"),zBo=o(" (MT5 model)"),QBo=l(),_b=a("li"),dhe=a("strong"),WBo=o("pegasus"),HBo=o(" \u2014 "),OO=a("a"),UBo=o("PegasusForConditionalGeneration"),JBo=o(" (Pegasus model)"),YBo=l(),ub=a("li"),che=a("strong"),KBo=o("plbart"),ZBo=o(" \u2014 "),VO=a("a"),eIo=o("PLBartForConditionalGeneration"),oIo=o(" (PLBart model)"),rIo=l(),bb=a("li"),fhe=a("strong"),tIo=o("prophetnet"),aIo=o(" \u2014 "),XO=a("a"),nIo=o("ProphetNetForConditionalGeneration"),sIo=o(" (ProphetNet model)"),lIo=l(),vb=a("li"),mhe=a("strong"),iIo=o("t5"),dIo=o(" \u2014 "),zO=a("a"),cIo=o("T5ForConditionalGeneration"),fIo=o(" (T5 model)"),mIo=l(),Fb=a("li"),ghe=a("strong"),gIo=o("xlm-prophetnet"),hIo=o(" \u2014 "),QO=a("a"),pIo=o("XLMProphetNetForConditionalGeneration"),_Io=o(" (XLM-ProphetNet model)"),uIo=l(),Tb=a("p"),bIo=o("The model is set in evaluation mode by default using "),hhe=a("code"),vIo=o("model.eval()"),FIo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),phe=a("code"),TIo=o("model.train()"),MIo=l(),F(Mb.$$.fragment),FOe=l(),Ji=a("h2"),Eb=a("a"),_he=a("span"),F(xL.$$.fragment),EIo=l(),uhe=a("span"),CIo=o("AutoModelForSequenceClassification"),TOe=l(),Po=a("div"),F($L.$$.fragment),wIo=l(),Yi=a("p"),AIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),WO=a("a"),LIo=o("from_pretrained()"),yIo=o(" class method or the "),HO=a("a"),xIo=o("from_config()"),$Io=o(` class
method.`),kIo=l(),kL=a("p"),SIo=o("This class cannot be instantiated directly using "),bhe=a("code"),RIo=o("__init__()"),PIo=o(" (throws an error)."),BIo=l(),ct=a("div"),F(SL.$$.fragment),IIo=l(),vhe=a("p"),NIo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),qIo=l(),Ki=a("p"),jIo=o(`Note:
Loading a model from its configuration file does `),Fhe=a("strong"),DIo=o("not"),GIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UO=a("a"),OIo=o("from_pretrained()"),VIo=o(" to load the model weights."),XIo=l(),F(Cb.$$.fragment),zIo=l(),oo=a("div"),F(RL.$$.fragment),QIo=l(),The=a("p"),WIo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),HIo=l(),qa=a("p"),UIo=o("The model class to instantiate is selected based on the "),Mhe=a("code"),JIo=o("model_type"),YIo=o(` property of the config object (either
passed as an argument or loaded from `),Ehe=a("code"),KIo=o("pretrained_model_name_or_path"),ZIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Che=a("code"),eNo=o("pretrained_model_name_or_path"),oNo=o(":"),rNo=l(),N=a("ul"),wb=a("li"),whe=a("strong"),tNo=o("albert"),aNo=o(" \u2014 "),JO=a("a"),nNo=o("AlbertForSequenceClassification"),sNo=o(" (ALBERT model)"),lNo=l(),Ab=a("li"),Ahe=a("strong"),iNo=o("bart"),dNo=o(" \u2014 "),YO=a("a"),cNo=o("BartForSequenceClassification"),fNo=o(" (BART model)"),mNo=l(),Lb=a("li"),Lhe=a("strong"),gNo=o("bert"),hNo=o(" \u2014 "),KO=a("a"),pNo=o("BertForSequenceClassification"),_No=o(" (BERT model)"),uNo=l(),yb=a("li"),yhe=a("strong"),bNo=o("big_bird"),vNo=o(" \u2014 "),ZO=a("a"),FNo=o("BigBirdForSequenceClassification"),TNo=o(" (BigBird model)"),MNo=l(),xb=a("li"),xhe=a("strong"),ENo=o("bigbird_pegasus"),CNo=o(" \u2014 "),eV=a("a"),wNo=o("BigBirdPegasusForSequenceClassification"),ANo=o(" (BigBird-Pegasus model)"),LNo=l(),$b=a("li"),$he=a("strong"),yNo=o("bloom"),xNo=o(" \u2014 "),oV=a("a"),$No=o("BloomForSequenceClassification"),kNo=o(" (BLOOM model)"),SNo=l(),kb=a("li"),khe=a("strong"),RNo=o("camembert"),PNo=o(" \u2014 "),rV=a("a"),BNo=o("CamembertForSequenceClassification"),INo=o(" (CamemBERT model)"),NNo=l(),Sb=a("li"),She=a("strong"),qNo=o("canine"),jNo=o(" \u2014 "),tV=a("a"),DNo=o("CanineForSequenceClassification"),GNo=o(" (CANINE model)"),ONo=l(),Rb=a("li"),Rhe=a("strong"),VNo=o("convbert"),XNo=o(" \u2014 "),aV=a("a"),zNo=o("ConvBertForSequenceClassification"),QNo=o(" (ConvBERT model)"),WNo=l(),Pb=a("li"),Phe=a("strong"),HNo=o("ctrl"),UNo=o(" \u2014 "),nV=a("a"),JNo=o("CTRLForSequenceClassification"),YNo=o(" (CTRL model)"),KNo=l(),Bb=a("li"),Bhe=a("strong"),ZNo=o("data2vec-text"),eqo=o(" \u2014 "),sV=a("a"),oqo=o("Data2VecTextForSequenceClassification"),rqo=o(" (Data2VecText model)"),tqo=l(),Ib=a("li"),Ihe=a("strong"),aqo=o("deberta"),nqo=o(" \u2014 "),lV=a("a"),sqo=o("DebertaForSequenceClassification"),lqo=o(" (DeBERTa model)"),iqo=l(),Nb=a("li"),Nhe=a("strong"),dqo=o("deberta-v2"),cqo=o(" \u2014 "),iV=a("a"),fqo=o("DebertaV2ForSequenceClassification"),mqo=o(" (DeBERTa-v2 model)"),gqo=l(),qb=a("li"),qhe=a("strong"),hqo=o("distilbert"),pqo=o(" \u2014 "),dV=a("a"),_qo=o("DistilBertForSequenceClassification"),uqo=o(" (DistilBERT model)"),bqo=l(),jb=a("li"),jhe=a("strong"),vqo=o("electra"),Fqo=o(" \u2014 "),cV=a("a"),Tqo=o("ElectraForSequenceClassification"),Mqo=o(" (ELECTRA model)"),Eqo=l(),Db=a("li"),Dhe=a("strong"),Cqo=o("flaubert"),wqo=o(" \u2014 "),fV=a("a"),Aqo=o("FlaubertForSequenceClassification"),Lqo=o(" (FlauBERT model)"),yqo=l(),Gb=a("li"),Ghe=a("strong"),xqo=o("fnet"),$qo=o(" \u2014 "),mV=a("a"),kqo=o("FNetForSequenceClassification"),Sqo=o(" (FNet model)"),Rqo=l(),Ob=a("li"),Ohe=a("strong"),Pqo=o("funnel"),Bqo=o(" \u2014 "),gV=a("a"),Iqo=o("FunnelForSequenceClassification"),Nqo=o(" (Funnel Transformer model)"),qqo=l(),Vb=a("li"),Vhe=a("strong"),jqo=o("gpt2"),Dqo=o(" \u2014 "),hV=a("a"),Gqo=o("GPT2ForSequenceClassification"),Oqo=o(" (OpenAI GPT-2 model)"),Vqo=l(),Xb=a("li"),Xhe=a("strong"),Xqo=o("gpt_neo"),zqo=o(" \u2014 "),pV=a("a"),Qqo=o("GPTNeoForSequenceClassification"),Wqo=o(" (GPT Neo model)"),Hqo=l(),zb=a("li"),zhe=a("strong"),Uqo=o("gptj"),Jqo=o(" \u2014 "),_V=a("a"),Yqo=o("GPTJForSequenceClassification"),Kqo=o(" (GPT-J model)"),Zqo=l(),Qb=a("li"),Qhe=a("strong"),ejo=o("ibert"),ojo=o(" \u2014 "),uV=a("a"),rjo=o("IBertForSequenceClassification"),tjo=o(" (I-BERT model)"),ajo=l(),Wb=a("li"),Whe=a("strong"),njo=o("layoutlm"),sjo=o(" \u2014 "),bV=a("a"),ljo=o("LayoutLMForSequenceClassification"),ijo=o(" (LayoutLM model)"),djo=l(),Hb=a("li"),Hhe=a("strong"),cjo=o("layoutlmv2"),fjo=o(" \u2014 "),vV=a("a"),mjo=o("LayoutLMv2ForSequenceClassification"),gjo=o(" (LayoutLMv2 model)"),hjo=l(),Ub=a("li"),Uhe=a("strong"),pjo=o("layoutlmv3"),_jo=o(" \u2014 "),FV=a("a"),ujo=o("LayoutLMv3ForSequenceClassification"),bjo=o(" (LayoutLMv3 model)"),vjo=l(),Jb=a("li"),Jhe=a("strong"),Fjo=o("led"),Tjo=o(" \u2014 "),TV=a("a"),Mjo=o("LEDForSequenceClassification"),Ejo=o(" (LED model)"),Cjo=l(),Yb=a("li"),Yhe=a("strong"),wjo=o("longformer"),Ajo=o(" \u2014 "),MV=a("a"),Ljo=o("LongformerForSequenceClassification"),yjo=o(" (Longformer model)"),xjo=l(),Kb=a("li"),Khe=a("strong"),$jo=o("mbart"),kjo=o(" \u2014 "),EV=a("a"),Sjo=o("MBartForSequenceClassification"),Rjo=o(" (mBART model)"),Pjo=l(),Zb=a("li"),Zhe=a("strong"),Bjo=o("megatron-bert"),Ijo=o(" \u2014 "),CV=a("a"),Njo=o("MegatronBertForSequenceClassification"),qjo=o(" (Megatron-BERT model)"),jjo=l(),ev=a("li"),epe=a("strong"),Djo=o("mobilebert"),Gjo=o(" \u2014 "),wV=a("a"),Ojo=o("MobileBertForSequenceClassification"),Vjo=o(" (MobileBERT model)"),Xjo=l(),ov=a("li"),ope=a("strong"),zjo=o("mpnet"),Qjo=o(" \u2014 "),AV=a("a"),Wjo=o("MPNetForSequenceClassification"),Hjo=o(" (MPNet model)"),Ujo=l(),rv=a("li"),rpe=a("strong"),Jjo=o("nezha"),Yjo=o(" \u2014 "),LV=a("a"),Kjo=o("NezhaForSequenceClassification"),Zjo=o(" (Nezha model)"),eDo=l(),tv=a("li"),tpe=a("strong"),oDo=o("nystromformer"),rDo=o(" \u2014 "),yV=a("a"),tDo=o("NystromformerForSequenceClassification"),aDo=o(" (Nystr\xF6mformer model)"),nDo=l(),av=a("li"),ape=a("strong"),sDo=o("openai-gpt"),lDo=o(" \u2014 "),xV=a("a"),iDo=o("OpenAIGPTForSequenceClassification"),dDo=o(" (OpenAI GPT model)"),cDo=l(),nv=a("li"),npe=a("strong"),fDo=o("perceiver"),mDo=o(" \u2014 "),$V=a("a"),gDo=o("PerceiverForSequenceClassification"),hDo=o(" (Perceiver model)"),pDo=l(),sv=a("li"),spe=a("strong"),_Do=o("plbart"),uDo=o(" \u2014 "),kV=a("a"),bDo=o("PLBartForSequenceClassification"),vDo=o(" (PLBart model)"),FDo=l(),lv=a("li"),lpe=a("strong"),TDo=o("qdqbert"),MDo=o(" \u2014 "),SV=a("a"),EDo=o("QDQBertForSequenceClassification"),CDo=o(" (QDQBert model)"),wDo=l(),iv=a("li"),ipe=a("strong"),ADo=o("reformer"),LDo=o(" \u2014 "),RV=a("a"),yDo=o("ReformerForSequenceClassification"),xDo=o(" (Reformer model)"),$Do=l(),dv=a("li"),dpe=a("strong"),kDo=o("rembert"),SDo=o(" \u2014 "),PV=a("a"),RDo=o("RemBertForSequenceClassification"),PDo=o(" (RemBERT model)"),BDo=l(),cv=a("li"),cpe=a("strong"),IDo=o("roberta"),NDo=o(" \u2014 "),BV=a("a"),qDo=o("RobertaForSequenceClassification"),jDo=o(" (RoBERTa model)"),DDo=l(),fv=a("li"),fpe=a("strong"),GDo=o("roformer"),ODo=o(" \u2014 "),IV=a("a"),VDo=o("RoFormerForSequenceClassification"),XDo=o(" (RoFormer model)"),zDo=l(),mv=a("li"),mpe=a("strong"),QDo=o("squeezebert"),WDo=o(" \u2014 "),NV=a("a"),HDo=o("SqueezeBertForSequenceClassification"),UDo=o(" (SqueezeBERT model)"),JDo=l(),gv=a("li"),gpe=a("strong"),YDo=o("tapas"),KDo=o(" \u2014 "),qV=a("a"),ZDo=o("TapasForSequenceClassification"),eGo=o(" (TAPAS model)"),oGo=l(),hv=a("li"),hpe=a("strong"),rGo=o("transfo-xl"),tGo=o(" \u2014 "),jV=a("a"),aGo=o("TransfoXLForSequenceClassification"),nGo=o(" (Transformer-XL model)"),sGo=l(),pv=a("li"),ppe=a("strong"),lGo=o("xlm"),iGo=o(" \u2014 "),DV=a("a"),dGo=o("XLMForSequenceClassification"),cGo=o(" (XLM model)"),fGo=l(),_v=a("li"),_pe=a("strong"),mGo=o("xlm-roberta"),gGo=o(" \u2014 "),GV=a("a"),hGo=o("XLMRobertaForSequenceClassification"),pGo=o(" (XLM-RoBERTa model)"),_Go=l(),uv=a("li"),upe=a("strong"),uGo=o("xlm-roberta-xl"),bGo=o(" \u2014 "),OV=a("a"),vGo=o("XLMRobertaXLForSequenceClassification"),FGo=o(" (XLM-RoBERTa-XL model)"),TGo=l(),bv=a("li"),bpe=a("strong"),MGo=o("xlnet"),EGo=o(" \u2014 "),VV=a("a"),CGo=o("XLNetForSequenceClassification"),wGo=o(" (XLNet model)"),AGo=l(),vv=a("li"),vpe=a("strong"),LGo=o("yoso"),yGo=o(" \u2014 "),XV=a("a"),xGo=o("YosoForSequenceClassification"),$Go=o(" (YOSO model)"),kGo=l(),Fv=a("p"),SGo=o("The model is set in evaluation mode by default using "),Fpe=a("code"),RGo=o("model.eval()"),PGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tpe=a("code"),BGo=o("model.train()"),IGo=l(),F(Tv.$$.fragment),MOe=l(),Zi=a("h2"),Mv=a("a"),Mpe=a("span"),F(PL.$$.fragment),NGo=l(),Epe=a("span"),qGo=o("AutoModelForMultipleChoice"),EOe=l(),Bo=a("div"),F(BL.$$.fragment),jGo=l(),ed=a("p"),DGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zV=a("a"),GGo=o("from_pretrained()"),OGo=o(" class method or the "),QV=a("a"),VGo=o("from_config()"),XGo=o(` class
method.`),zGo=l(),IL=a("p"),QGo=o("This class cannot be instantiated directly using "),Cpe=a("code"),WGo=o("__init__()"),HGo=o(" (throws an error)."),UGo=l(),ft=a("div"),F(NL.$$.fragment),JGo=l(),wpe=a("p"),YGo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),KGo=l(),od=a("p"),ZGo=o(`Note:
Loading a model from its configuration file does `),Ape=a("strong"),eOo=o("not"),oOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WV=a("a"),rOo=o("from_pretrained()"),tOo=o(" to load the model weights."),aOo=l(),F(Ev.$$.fragment),nOo=l(),ro=a("div"),F(qL.$$.fragment),sOo=l(),Lpe=a("p"),lOo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),iOo=l(),ja=a("p"),dOo=o("The model class to instantiate is selected based on the "),ype=a("code"),cOo=o("model_type"),fOo=o(` property of the config object (either
passed as an argument or loaded from `),xpe=a("code"),mOo=o("pretrained_model_name_or_path"),gOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$pe=a("code"),hOo=o("pretrained_model_name_or_path"),pOo=o(":"),_Oo=l(),Z=a("ul"),Cv=a("li"),kpe=a("strong"),uOo=o("albert"),bOo=o(" \u2014 "),HV=a("a"),vOo=o("AlbertForMultipleChoice"),FOo=o(" (ALBERT model)"),TOo=l(),wv=a("li"),Spe=a("strong"),MOo=o("bert"),EOo=o(" \u2014 "),UV=a("a"),COo=o("BertForMultipleChoice"),wOo=o(" (BERT model)"),AOo=l(),Av=a("li"),Rpe=a("strong"),LOo=o("big_bird"),yOo=o(" \u2014 "),JV=a("a"),xOo=o("BigBirdForMultipleChoice"),$Oo=o(" (BigBird model)"),kOo=l(),Lv=a("li"),Ppe=a("strong"),SOo=o("camembert"),ROo=o(" \u2014 "),YV=a("a"),POo=o("CamembertForMultipleChoice"),BOo=o(" (CamemBERT model)"),IOo=l(),yv=a("li"),Bpe=a("strong"),NOo=o("canine"),qOo=o(" \u2014 "),KV=a("a"),jOo=o("CanineForMultipleChoice"),DOo=o(" (CANINE model)"),GOo=l(),xv=a("li"),Ipe=a("strong"),OOo=o("convbert"),VOo=o(" \u2014 "),ZV=a("a"),XOo=o("ConvBertForMultipleChoice"),zOo=o(" (ConvBERT model)"),QOo=l(),$v=a("li"),Npe=a("strong"),WOo=o("data2vec-text"),HOo=o(" \u2014 "),eX=a("a"),UOo=o("Data2VecTextForMultipleChoice"),JOo=o(" (Data2VecText model)"),YOo=l(),kv=a("li"),qpe=a("strong"),KOo=o("deberta-v2"),ZOo=o(" \u2014 "),oX=a("a"),eVo=o("DebertaV2ForMultipleChoice"),oVo=o(" (DeBERTa-v2 model)"),rVo=l(),Sv=a("li"),jpe=a("strong"),tVo=o("distilbert"),aVo=o(" \u2014 "),rX=a("a"),nVo=o("DistilBertForMultipleChoice"),sVo=o(" (DistilBERT model)"),lVo=l(),Rv=a("li"),Dpe=a("strong"),iVo=o("electra"),dVo=o(" \u2014 "),tX=a("a"),cVo=o("ElectraForMultipleChoice"),fVo=o(" (ELECTRA model)"),mVo=l(),Pv=a("li"),Gpe=a("strong"),gVo=o("flaubert"),hVo=o(" \u2014 "),aX=a("a"),pVo=o("FlaubertForMultipleChoice"),_Vo=o(" (FlauBERT model)"),uVo=l(),Bv=a("li"),Ope=a("strong"),bVo=o("fnet"),vVo=o(" \u2014 "),nX=a("a"),FVo=o("FNetForMultipleChoice"),TVo=o(" (FNet model)"),MVo=l(),Iv=a("li"),Vpe=a("strong"),EVo=o("funnel"),CVo=o(" \u2014 "),sX=a("a"),wVo=o("FunnelForMultipleChoice"),AVo=o(" (Funnel Transformer model)"),LVo=l(),Nv=a("li"),Xpe=a("strong"),yVo=o("ibert"),xVo=o(" \u2014 "),lX=a("a"),$Vo=o("IBertForMultipleChoice"),kVo=o(" (I-BERT model)"),SVo=l(),qv=a("li"),zpe=a("strong"),RVo=o("longformer"),PVo=o(" \u2014 "),iX=a("a"),BVo=o("LongformerForMultipleChoice"),IVo=o(" (Longformer model)"),NVo=l(),jv=a("li"),Qpe=a("strong"),qVo=o("megatron-bert"),jVo=o(" \u2014 "),dX=a("a"),DVo=o("MegatronBertForMultipleChoice"),GVo=o(" (Megatron-BERT model)"),OVo=l(),Dv=a("li"),Wpe=a("strong"),VVo=o("mobilebert"),XVo=o(" \u2014 "),cX=a("a"),zVo=o("MobileBertForMultipleChoice"),QVo=o(" (MobileBERT model)"),WVo=l(),Gv=a("li"),Hpe=a("strong"),HVo=o("mpnet"),UVo=o(" \u2014 "),fX=a("a"),JVo=o("MPNetForMultipleChoice"),YVo=o(" (MPNet model)"),KVo=l(),Ov=a("li"),Upe=a("strong"),ZVo=o("nezha"),eXo=o(" \u2014 "),mX=a("a"),oXo=o("NezhaForMultipleChoice"),rXo=o(" (Nezha model)"),tXo=l(),Vv=a("li"),Jpe=a("strong"),aXo=o("nystromformer"),nXo=o(" \u2014 "),gX=a("a"),sXo=o("NystromformerForMultipleChoice"),lXo=o(" (Nystr\xF6mformer model)"),iXo=l(),Xv=a("li"),Ype=a("strong"),dXo=o("qdqbert"),cXo=o(" \u2014 "),hX=a("a"),fXo=o("QDQBertForMultipleChoice"),mXo=o(" (QDQBert model)"),gXo=l(),zv=a("li"),Kpe=a("strong"),hXo=o("rembert"),pXo=o(" \u2014 "),pX=a("a"),_Xo=o("RemBertForMultipleChoice"),uXo=o(" (RemBERT model)"),bXo=l(),Qv=a("li"),Zpe=a("strong"),vXo=o("roberta"),FXo=o(" \u2014 "),_X=a("a"),TXo=o("RobertaForMultipleChoice"),MXo=o(" (RoBERTa model)"),EXo=l(),Wv=a("li"),e_e=a("strong"),CXo=o("roformer"),wXo=o(" \u2014 "),uX=a("a"),AXo=o("RoFormerForMultipleChoice"),LXo=o(" (RoFormer model)"),yXo=l(),Hv=a("li"),o_e=a("strong"),xXo=o("squeezebert"),$Xo=o(" \u2014 "),bX=a("a"),kXo=o("SqueezeBertForMultipleChoice"),SXo=o(" (SqueezeBERT model)"),RXo=l(),Uv=a("li"),r_e=a("strong"),PXo=o("xlm"),BXo=o(" \u2014 "),vX=a("a"),IXo=o("XLMForMultipleChoice"),NXo=o(" (XLM model)"),qXo=l(),Jv=a("li"),t_e=a("strong"),jXo=o("xlm-roberta"),DXo=o(" \u2014 "),FX=a("a"),GXo=o("XLMRobertaForMultipleChoice"),OXo=o(" (XLM-RoBERTa model)"),VXo=l(),Yv=a("li"),a_e=a("strong"),XXo=o("xlm-roberta-xl"),zXo=o(" \u2014 "),TX=a("a"),QXo=o("XLMRobertaXLForMultipleChoice"),WXo=o(" (XLM-RoBERTa-XL model)"),HXo=l(),Kv=a("li"),n_e=a("strong"),UXo=o("xlnet"),JXo=o(" \u2014 "),MX=a("a"),YXo=o("XLNetForMultipleChoice"),KXo=o(" (XLNet model)"),ZXo=l(),Zv=a("li"),s_e=a("strong"),ezo=o("yoso"),ozo=o(" \u2014 "),EX=a("a"),rzo=o("YosoForMultipleChoice"),tzo=o(" (YOSO model)"),azo=l(),eF=a("p"),nzo=o("The model is set in evaluation mode by default using "),l_e=a("code"),szo=o("model.eval()"),lzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),i_e=a("code"),izo=o("model.train()"),dzo=l(),F(oF.$$.fragment),COe=l(),rd=a("h2"),rF=a("a"),d_e=a("span"),F(jL.$$.fragment),czo=l(),c_e=a("span"),fzo=o("AutoModelForNextSentencePrediction"),wOe=l(),Io=a("div"),F(DL.$$.fragment),mzo=l(),td=a("p"),gzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),CX=a("a"),hzo=o("from_pretrained()"),pzo=o(" class method or the "),wX=a("a"),_zo=o("from_config()"),uzo=o(` class
method.`),bzo=l(),GL=a("p"),vzo=o("This class cannot be instantiated directly using "),f_e=a("code"),Fzo=o("__init__()"),Tzo=o(" (throws an error)."),Mzo=l(),mt=a("div"),F(OL.$$.fragment),Ezo=l(),m_e=a("p"),Czo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),wzo=l(),ad=a("p"),Azo=o(`Note:
Loading a model from its configuration file does `),g_e=a("strong"),Lzo=o("not"),yzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AX=a("a"),xzo=o("from_pretrained()"),$zo=o(" to load the model weights."),kzo=l(),F(tF.$$.fragment),Szo=l(),to=a("div"),F(VL.$$.fragment),Rzo=l(),h_e=a("p"),Pzo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Bzo=l(),Da=a("p"),Izo=o("The model class to instantiate is selected based on the "),p_e=a("code"),Nzo=o("model_type"),qzo=o(` property of the config object (either
passed as an argument or loaded from `),__e=a("code"),jzo=o("pretrained_model_name_or_path"),Dzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u_e=a("code"),Gzo=o("pretrained_model_name_or_path"),Ozo=o(":"),Vzo=l(),No=a("ul"),aF=a("li"),b_e=a("strong"),Xzo=o("bert"),zzo=o(" \u2014 "),LX=a("a"),Qzo=o("BertForNextSentencePrediction"),Wzo=o(" (BERT model)"),Hzo=l(),nF=a("li"),v_e=a("strong"),Uzo=o("fnet"),Jzo=o(" \u2014 "),yX=a("a"),Yzo=o("FNetForNextSentencePrediction"),Kzo=o(" (FNet model)"),Zzo=l(),sF=a("li"),F_e=a("strong"),eQo=o("megatron-bert"),oQo=o(" \u2014 "),xX=a("a"),rQo=o("MegatronBertForNextSentencePrediction"),tQo=o(" (Megatron-BERT model)"),aQo=l(),lF=a("li"),T_e=a("strong"),nQo=o("mobilebert"),sQo=o(" \u2014 "),$X=a("a"),lQo=o("MobileBertForNextSentencePrediction"),iQo=o(" (MobileBERT model)"),dQo=l(),iF=a("li"),M_e=a("strong"),cQo=o("nezha"),fQo=o(" \u2014 "),kX=a("a"),mQo=o("NezhaForNextSentencePrediction"),gQo=o(" (Nezha model)"),hQo=l(),dF=a("li"),E_e=a("strong"),pQo=o("qdqbert"),_Qo=o(" \u2014 "),SX=a("a"),uQo=o("QDQBertForNextSentencePrediction"),bQo=o(" (QDQBert model)"),vQo=l(),cF=a("p"),FQo=o("The model is set in evaluation mode by default using "),C_e=a("code"),TQo=o("model.eval()"),MQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w_e=a("code"),EQo=o("model.train()"),CQo=l(),F(fF.$$.fragment),AOe=l(),nd=a("h2"),mF=a("a"),A_e=a("span"),F(XL.$$.fragment),wQo=l(),L_e=a("span"),AQo=o("AutoModelForTokenClassification"),LOe=l(),qo=a("div"),F(zL.$$.fragment),LQo=l(),sd=a("p"),yQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),RX=a("a"),xQo=o("from_pretrained()"),$Qo=o(" class method or the "),PX=a("a"),kQo=o("from_config()"),SQo=o(` class
method.`),RQo=l(),QL=a("p"),PQo=o("This class cannot be instantiated directly using "),y_e=a("code"),BQo=o("__init__()"),IQo=o(" (throws an error)."),NQo=l(),gt=a("div"),F(WL.$$.fragment),qQo=l(),x_e=a("p"),jQo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DQo=l(),ld=a("p"),GQo=o(`Note:
Loading a model from its configuration file does `),$_e=a("strong"),OQo=o("not"),VQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BX=a("a"),XQo=o("from_pretrained()"),zQo=o(" to load the model weights."),QQo=l(),F(gF.$$.fragment),WQo=l(),ao=a("div"),F(HL.$$.fragment),HQo=l(),k_e=a("p"),UQo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),JQo=l(),Ga=a("p"),YQo=o("The model class to instantiate is selected based on the "),S_e=a("code"),KQo=o("model_type"),ZQo=o(` property of the config object (either
passed as an argument or loaded from `),R_e=a("code"),eWo=o("pretrained_model_name_or_path"),oWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P_e=a("code"),rWo=o("pretrained_model_name_or_path"),tWo=o(":"),aWo=l(),H=a("ul"),hF=a("li"),B_e=a("strong"),nWo=o("albert"),sWo=o(" \u2014 "),IX=a("a"),lWo=o("AlbertForTokenClassification"),iWo=o(" (ALBERT model)"),dWo=l(),pF=a("li"),I_e=a("strong"),cWo=o("bert"),fWo=o(" \u2014 "),NX=a("a"),mWo=o("BertForTokenClassification"),gWo=o(" (BERT model)"),hWo=l(),_F=a("li"),N_e=a("strong"),pWo=o("big_bird"),_Wo=o(" \u2014 "),qX=a("a"),uWo=o("BigBirdForTokenClassification"),bWo=o(" (BigBird model)"),vWo=l(),uF=a("li"),q_e=a("strong"),FWo=o("bloom"),TWo=o(" \u2014 "),jX=a("a"),MWo=o("BloomForTokenClassification"),EWo=o(" (BLOOM model)"),CWo=l(),bF=a("li"),j_e=a("strong"),wWo=o("camembert"),AWo=o(" \u2014 "),DX=a("a"),LWo=o("CamembertForTokenClassification"),yWo=o(" (CamemBERT model)"),xWo=l(),vF=a("li"),D_e=a("strong"),$Wo=o("canine"),kWo=o(" \u2014 "),GX=a("a"),SWo=o("CanineForTokenClassification"),RWo=o(" (CANINE model)"),PWo=l(),FF=a("li"),G_e=a("strong"),BWo=o("convbert"),IWo=o(" \u2014 "),OX=a("a"),NWo=o("ConvBertForTokenClassification"),qWo=o(" (ConvBERT model)"),jWo=l(),TF=a("li"),O_e=a("strong"),DWo=o("data2vec-text"),GWo=o(" \u2014 "),VX=a("a"),OWo=o("Data2VecTextForTokenClassification"),VWo=o(" (Data2VecText model)"),XWo=l(),MF=a("li"),V_e=a("strong"),zWo=o("deberta"),QWo=o(" \u2014 "),XX=a("a"),WWo=o("DebertaForTokenClassification"),HWo=o(" (DeBERTa model)"),UWo=l(),EF=a("li"),X_e=a("strong"),JWo=o("deberta-v2"),YWo=o(" \u2014 "),zX=a("a"),KWo=o("DebertaV2ForTokenClassification"),ZWo=o(" (DeBERTa-v2 model)"),eHo=l(),CF=a("li"),z_e=a("strong"),oHo=o("distilbert"),rHo=o(" \u2014 "),QX=a("a"),tHo=o("DistilBertForTokenClassification"),aHo=o(" (DistilBERT model)"),nHo=l(),wF=a("li"),Q_e=a("strong"),sHo=o("electra"),lHo=o(" \u2014 "),WX=a("a"),iHo=o("ElectraForTokenClassification"),dHo=o(" (ELECTRA model)"),cHo=l(),AF=a("li"),W_e=a("strong"),fHo=o("flaubert"),mHo=o(" \u2014 "),HX=a("a"),gHo=o("FlaubertForTokenClassification"),hHo=o(" (FlauBERT model)"),pHo=l(),LF=a("li"),H_e=a("strong"),_Ho=o("fnet"),uHo=o(" \u2014 "),UX=a("a"),bHo=o("FNetForTokenClassification"),vHo=o(" (FNet model)"),FHo=l(),yF=a("li"),U_e=a("strong"),THo=o("funnel"),MHo=o(" \u2014 "),JX=a("a"),EHo=o("FunnelForTokenClassification"),CHo=o(" (Funnel Transformer model)"),wHo=l(),xF=a("li"),J_e=a("strong"),AHo=o("gpt2"),LHo=o(" \u2014 "),YX=a("a"),yHo=o("GPT2ForTokenClassification"),xHo=o(" (OpenAI GPT-2 model)"),$Ho=l(),$F=a("li"),Y_e=a("strong"),kHo=o("ibert"),SHo=o(" \u2014 "),KX=a("a"),RHo=o("IBertForTokenClassification"),PHo=o(" (I-BERT model)"),BHo=l(),kF=a("li"),K_e=a("strong"),IHo=o("layoutlm"),NHo=o(" \u2014 "),ZX=a("a"),qHo=o("LayoutLMForTokenClassification"),jHo=o(" (LayoutLM model)"),DHo=l(),SF=a("li"),Z_e=a("strong"),GHo=o("layoutlmv2"),OHo=o(" \u2014 "),ez=a("a"),VHo=o("LayoutLMv2ForTokenClassification"),XHo=o(" (LayoutLMv2 model)"),zHo=l(),RF=a("li"),eue=a("strong"),QHo=o("layoutlmv3"),WHo=o(" \u2014 "),oz=a("a"),HHo=o("LayoutLMv3ForTokenClassification"),UHo=o(" (LayoutLMv3 model)"),JHo=l(),PF=a("li"),oue=a("strong"),YHo=o("longformer"),KHo=o(" \u2014 "),rz=a("a"),ZHo=o("LongformerForTokenClassification"),eUo=o(" (Longformer model)"),oUo=l(),BF=a("li"),rue=a("strong"),rUo=o("megatron-bert"),tUo=o(" \u2014 "),tz=a("a"),aUo=o("MegatronBertForTokenClassification"),nUo=o(" (Megatron-BERT model)"),sUo=l(),IF=a("li"),tue=a("strong"),lUo=o("mobilebert"),iUo=o(" \u2014 "),az=a("a"),dUo=o("MobileBertForTokenClassification"),cUo=o(" (MobileBERT model)"),fUo=l(),NF=a("li"),aue=a("strong"),mUo=o("mpnet"),gUo=o(" \u2014 "),nz=a("a"),hUo=o("MPNetForTokenClassification"),pUo=o(" (MPNet model)"),_Uo=l(),qF=a("li"),nue=a("strong"),uUo=o("nezha"),bUo=o(" \u2014 "),sz=a("a"),vUo=o("NezhaForTokenClassification"),FUo=o(" (Nezha model)"),TUo=l(),jF=a("li"),sue=a("strong"),MUo=o("nystromformer"),EUo=o(" \u2014 "),lz=a("a"),CUo=o("NystromformerForTokenClassification"),wUo=o(" (Nystr\xF6mformer model)"),AUo=l(),DF=a("li"),lue=a("strong"),LUo=o("qdqbert"),yUo=o(" \u2014 "),iz=a("a"),xUo=o("QDQBertForTokenClassification"),$Uo=o(" (QDQBert model)"),kUo=l(),GF=a("li"),iue=a("strong"),SUo=o("rembert"),RUo=o(" \u2014 "),dz=a("a"),PUo=o("RemBertForTokenClassification"),BUo=o(" (RemBERT model)"),IUo=l(),OF=a("li"),due=a("strong"),NUo=o("roberta"),qUo=o(" \u2014 "),cz=a("a"),jUo=o("RobertaForTokenClassification"),DUo=o(" (RoBERTa model)"),GUo=l(),VF=a("li"),cue=a("strong"),OUo=o("roformer"),VUo=o(" \u2014 "),fz=a("a"),XUo=o("RoFormerForTokenClassification"),zUo=o(" (RoFormer model)"),QUo=l(),XF=a("li"),fue=a("strong"),WUo=o("squeezebert"),HUo=o(" \u2014 "),mz=a("a"),UUo=o("SqueezeBertForTokenClassification"),JUo=o(" (SqueezeBERT model)"),YUo=l(),zF=a("li"),mue=a("strong"),KUo=o("xlm"),ZUo=o(" \u2014 "),gz=a("a"),eJo=o("XLMForTokenClassification"),oJo=o(" (XLM model)"),rJo=l(),QF=a("li"),gue=a("strong"),tJo=o("xlm-roberta"),aJo=o(" \u2014 "),hz=a("a"),nJo=o("XLMRobertaForTokenClassification"),sJo=o(" (XLM-RoBERTa model)"),lJo=l(),WF=a("li"),hue=a("strong"),iJo=o("xlm-roberta-xl"),dJo=o(" \u2014 "),pz=a("a"),cJo=o("XLMRobertaXLForTokenClassification"),fJo=o(" (XLM-RoBERTa-XL model)"),mJo=l(),HF=a("li"),pue=a("strong"),gJo=o("xlnet"),hJo=o(" \u2014 "),_z=a("a"),pJo=o("XLNetForTokenClassification"),_Jo=o(" (XLNet model)"),uJo=l(),UF=a("li"),_ue=a("strong"),bJo=o("yoso"),vJo=o(" \u2014 "),uz=a("a"),FJo=o("YosoForTokenClassification"),TJo=o(" (YOSO model)"),MJo=l(),JF=a("p"),EJo=o("The model is set in evaluation mode by default using "),uue=a("code"),CJo=o("model.eval()"),wJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=a("code"),AJo=o("model.train()"),LJo=l(),F(YF.$$.fragment),yOe=l(),id=a("h2"),KF=a("a"),vue=a("span"),F(UL.$$.fragment),yJo=l(),Fue=a("span"),xJo=o("AutoModelForQuestionAnswering"),xOe=l(),jo=a("div"),F(JL.$$.fragment),$Jo=l(),dd=a("p"),kJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),bz=a("a"),SJo=o("from_pretrained()"),RJo=o(" class method or the "),vz=a("a"),PJo=o("from_config()"),BJo=o(` class
method.`),IJo=l(),YL=a("p"),NJo=o("This class cannot be instantiated directly using "),Tue=a("code"),qJo=o("__init__()"),jJo=o(" (throws an error)."),DJo=l(),ht=a("div"),F(KL.$$.fragment),GJo=l(),Mue=a("p"),OJo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),VJo=l(),cd=a("p"),XJo=o(`Note:
Loading a model from its configuration file does `),Eue=a("strong"),zJo=o("not"),QJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),WJo=o("from_pretrained()"),HJo=o(" to load the model weights."),UJo=l(),F(ZF.$$.fragment),JJo=l(),no=a("div"),F(ZL.$$.fragment),YJo=l(),Cue=a("p"),KJo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ZJo=l(),Oa=a("p"),eYo=o("The model class to instantiate is selected based on the "),wue=a("code"),oYo=o("model_type"),rYo=o(` property of the config object (either
passed as an argument or loaded from `),Aue=a("code"),tYo=o("pretrained_model_name_or_path"),aYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lue=a("code"),nYo=o("pretrained_model_name_or_path"),sYo=o(":"),lYo=l(),V=a("ul"),e6=a("li"),yue=a("strong"),iYo=o("albert"),dYo=o(" \u2014 "),Tz=a("a"),cYo=o("AlbertForQuestionAnswering"),fYo=o(" (ALBERT model)"),mYo=l(),o6=a("li"),xue=a("strong"),gYo=o("bart"),hYo=o(" \u2014 "),Mz=a("a"),pYo=o("BartForQuestionAnswering"),_Yo=o(" (BART model)"),uYo=l(),r6=a("li"),$ue=a("strong"),bYo=o("bert"),vYo=o(" \u2014 "),Ez=a("a"),FYo=o("BertForQuestionAnswering"),TYo=o(" (BERT model)"),MYo=l(),t6=a("li"),kue=a("strong"),EYo=o("big_bird"),CYo=o(" \u2014 "),Cz=a("a"),wYo=o("BigBirdForQuestionAnswering"),AYo=o(" (BigBird model)"),LYo=l(),a6=a("li"),Sue=a("strong"),yYo=o("bigbird_pegasus"),xYo=o(" \u2014 "),wz=a("a"),$Yo=o("BigBirdPegasusForQuestionAnswering"),kYo=o(" (BigBird-Pegasus model)"),SYo=l(),n6=a("li"),Rue=a("strong"),RYo=o("camembert"),PYo=o(" \u2014 "),Az=a("a"),BYo=o("CamembertForQuestionAnswering"),IYo=o(" (CamemBERT model)"),NYo=l(),s6=a("li"),Pue=a("strong"),qYo=o("canine"),jYo=o(" \u2014 "),Lz=a("a"),DYo=o("CanineForQuestionAnswering"),GYo=o(" (CANINE model)"),OYo=l(),l6=a("li"),Bue=a("strong"),VYo=o("convbert"),XYo=o(" \u2014 "),yz=a("a"),zYo=o("ConvBertForQuestionAnswering"),QYo=o(" (ConvBERT model)"),WYo=l(),i6=a("li"),Iue=a("strong"),HYo=o("data2vec-text"),UYo=o(" \u2014 "),xz=a("a"),JYo=o("Data2VecTextForQuestionAnswering"),YYo=o(" (Data2VecText model)"),KYo=l(),d6=a("li"),Nue=a("strong"),ZYo=o("deberta"),eKo=o(" \u2014 "),$z=a("a"),oKo=o("DebertaForQuestionAnswering"),rKo=o(" (DeBERTa model)"),tKo=l(),c6=a("li"),que=a("strong"),aKo=o("deberta-v2"),nKo=o(" \u2014 "),kz=a("a"),sKo=o("DebertaV2ForQuestionAnswering"),lKo=o(" (DeBERTa-v2 model)"),iKo=l(),f6=a("li"),jue=a("strong"),dKo=o("distilbert"),cKo=o(" \u2014 "),Sz=a("a"),fKo=o("DistilBertForQuestionAnswering"),mKo=o(" (DistilBERT model)"),gKo=l(),m6=a("li"),Due=a("strong"),hKo=o("electra"),pKo=o(" \u2014 "),Rz=a("a"),_Ko=o("ElectraForQuestionAnswering"),uKo=o(" (ELECTRA model)"),bKo=l(),g6=a("li"),Gue=a("strong"),vKo=o("flaubert"),FKo=o(" \u2014 "),Pz=a("a"),TKo=o("FlaubertForQuestionAnsweringSimple"),MKo=o(" (FlauBERT model)"),EKo=l(),h6=a("li"),Oue=a("strong"),CKo=o("fnet"),wKo=o(" \u2014 "),Bz=a("a"),AKo=o("FNetForQuestionAnswering"),LKo=o(" (FNet model)"),yKo=l(),p6=a("li"),Vue=a("strong"),xKo=o("funnel"),$Ko=o(" \u2014 "),Iz=a("a"),kKo=o("FunnelForQuestionAnswering"),SKo=o(" (Funnel Transformer model)"),RKo=l(),_6=a("li"),Xue=a("strong"),PKo=o("gptj"),BKo=o(" \u2014 "),Nz=a("a"),IKo=o("GPTJForQuestionAnswering"),NKo=o(" (GPT-J model)"),qKo=l(),u6=a("li"),zue=a("strong"),jKo=o("ibert"),DKo=o(" \u2014 "),qz=a("a"),GKo=o("IBertForQuestionAnswering"),OKo=o(" (I-BERT model)"),VKo=l(),b6=a("li"),Que=a("strong"),XKo=o("layoutlmv2"),zKo=o(" \u2014 "),jz=a("a"),QKo=o("LayoutLMv2ForQuestionAnswering"),WKo=o(" (LayoutLMv2 model)"),HKo=l(),v6=a("li"),Wue=a("strong"),UKo=o("layoutlmv3"),JKo=o(" \u2014 "),Dz=a("a"),YKo=o("LayoutLMv3ForQuestionAnswering"),KKo=o(" (LayoutLMv3 model)"),ZKo=l(),F6=a("li"),Hue=a("strong"),eZo=o("led"),oZo=o(" \u2014 "),Gz=a("a"),rZo=o("LEDForQuestionAnswering"),tZo=o(" (LED model)"),aZo=l(),T6=a("li"),Uue=a("strong"),nZo=o("longformer"),sZo=o(" \u2014 "),Oz=a("a"),lZo=o("LongformerForQuestionAnswering"),iZo=o(" (Longformer model)"),dZo=l(),M6=a("li"),Jue=a("strong"),cZo=o("lxmert"),fZo=o(" \u2014 "),Vz=a("a"),mZo=o("LxmertForQuestionAnswering"),gZo=o(" (LXMERT model)"),hZo=l(),E6=a("li"),Yue=a("strong"),pZo=o("mbart"),_Zo=o(" \u2014 "),Xz=a("a"),uZo=o("MBartForQuestionAnswering"),bZo=o(" (mBART model)"),vZo=l(),C6=a("li"),Kue=a("strong"),FZo=o("megatron-bert"),TZo=o(" \u2014 "),zz=a("a"),MZo=o("MegatronBertForQuestionAnswering"),EZo=o(" (Megatron-BERT model)"),CZo=l(),w6=a("li"),Zue=a("strong"),wZo=o("mobilebert"),AZo=o(" \u2014 "),Qz=a("a"),LZo=o("MobileBertForQuestionAnswering"),yZo=o(" (MobileBERT model)"),xZo=l(),A6=a("li"),e2e=a("strong"),$Zo=o("mpnet"),kZo=o(" \u2014 "),Wz=a("a"),SZo=o("MPNetForQuestionAnswering"),RZo=o(" (MPNet model)"),PZo=l(),L6=a("li"),o2e=a("strong"),BZo=o("nezha"),IZo=o(" \u2014 "),Hz=a("a"),NZo=o("NezhaForQuestionAnswering"),qZo=o(" (Nezha model)"),jZo=l(),y6=a("li"),r2e=a("strong"),DZo=o("nystromformer"),GZo=o(" \u2014 "),Uz=a("a"),OZo=o("NystromformerForQuestionAnswering"),VZo=o(" (Nystr\xF6mformer model)"),XZo=l(),x6=a("li"),t2e=a("strong"),zZo=o("qdqbert"),QZo=o(" \u2014 "),Jz=a("a"),WZo=o("QDQBertForQuestionAnswering"),HZo=o(" (QDQBert model)"),UZo=l(),$6=a("li"),a2e=a("strong"),JZo=o("reformer"),YZo=o(" \u2014 "),Yz=a("a"),KZo=o("ReformerForQuestionAnswering"),ZZo=o(" (Reformer model)"),eer=l(),k6=a("li"),n2e=a("strong"),oer=o("rembert"),rer=o(" \u2014 "),Kz=a("a"),ter=o("RemBertForQuestionAnswering"),aer=o(" (RemBERT model)"),ner=l(),S6=a("li"),s2e=a("strong"),ser=o("roberta"),ler=o(" \u2014 "),Zz=a("a"),ier=o("RobertaForQuestionAnswering"),der=o(" (RoBERTa model)"),cer=l(),R6=a("li"),l2e=a("strong"),fer=o("roformer"),mer=o(" \u2014 "),eQ=a("a"),ger=o("RoFormerForQuestionAnswering"),her=o(" (RoFormer model)"),per=l(),P6=a("li"),i2e=a("strong"),_er=o("splinter"),uer=o(" \u2014 "),oQ=a("a"),ber=o("SplinterForQuestionAnswering"),ver=o(" (Splinter model)"),Fer=l(),B6=a("li"),d2e=a("strong"),Ter=o("squeezebert"),Mer=o(" \u2014 "),rQ=a("a"),Eer=o("SqueezeBertForQuestionAnswering"),Cer=o(" (SqueezeBERT model)"),wer=l(),I6=a("li"),c2e=a("strong"),Aer=o("xlm"),Ler=o(" \u2014 "),tQ=a("a"),yer=o("XLMForQuestionAnsweringSimple"),xer=o(" (XLM model)"),$er=l(),N6=a("li"),f2e=a("strong"),ker=o("xlm-roberta"),Ser=o(" \u2014 "),aQ=a("a"),Rer=o("XLMRobertaForQuestionAnswering"),Per=o(" (XLM-RoBERTa model)"),Ber=l(),q6=a("li"),m2e=a("strong"),Ier=o("xlm-roberta-xl"),Ner=o(" \u2014 "),nQ=a("a"),qer=o("XLMRobertaXLForQuestionAnswering"),jer=o(" (XLM-RoBERTa-XL model)"),Der=l(),j6=a("li"),g2e=a("strong"),Ger=o("xlnet"),Oer=o(" \u2014 "),sQ=a("a"),Ver=o("XLNetForQuestionAnsweringSimple"),Xer=o(" (XLNet model)"),zer=l(),D6=a("li"),h2e=a("strong"),Qer=o("yoso"),Wer=o(" \u2014 "),lQ=a("a"),Her=o("YosoForQuestionAnswering"),Uer=o(" (YOSO model)"),Jer=l(),G6=a("p"),Yer=o("The model is set in evaluation mode by default using "),p2e=a("code"),Ker=o("model.eval()"),Zer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_2e=a("code"),eor=o("model.train()"),oor=l(),F(O6.$$.fragment),$Oe=l(),fd=a("h2"),V6=a("a"),u2e=a("span"),F(ey.$$.fragment),ror=l(),b2e=a("span"),tor=o("AutoModelForTableQuestionAnswering"),kOe=l(),Do=a("div"),F(oy.$$.fragment),aor=l(),md=a("p"),nor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),iQ=a("a"),sor=o("from_pretrained()"),lor=o(" class method or the "),dQ=a("a"),ior=o("from_config()"),dor=o(` class
method.`),cor=l(),ry=a("p"),mor=o("This class cannot be instantiated directly using "),v2e=a("code"),gor=o("__init__()"),hor=o(" (throws an error)."),por=l(),pt=a("div"),F(ty.$$.fragment),_or=l(),F2e=a("p"),uor=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),bor=l(),gd=a("p"),vor=o(`Note:
Loading a model from its configuration file does `),T2e=a("strong"),For=o("not"),Tor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),Mor=o("from_pretrained()"),Eor=o(" to load the model weights."),Cor=l(),F(X6.$$.fragment),wor=l(),so=a("div"),F(ay.$$.fragment),Aor=l(),M2e=a("p"),Lor=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),yor=l(),Va=a("p"),xor=o("The model class to instantiate is selected based on the "),E2e=a("code"),$or=o("model_type"),kor=o(` property of the config object (either
passed as an argument or loaded from `),C2e=a("code"),Sor=o("pretrained_model_name_or_path"),Ror=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w2e=a("code"),Por=o("pretrained_model_name_or_path"),Bor=o(":"),Ior=l(),A2e=a("ul"),z6=a("li"),L2e=a("strong"),Nor=o("tapas"),qor=o(" \u2014 "),fQ=a("a"),jor=o("TapasForQuestionAnswering"),Dor=o(" (TAPAS model)"),Gor=l(),Q6=a("p"),Oor=o("The model is set in evaluation mode by default using "),y2e=a("code"),Vor=o("model.eval()"),Xor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x2e=a("code"),zor=o("model.train()"),Qor=l(),F(W6.$$.fragment),SOe=l(),hd=a("h2"),H6=a("a"),$2e=a("span"),F(ny.$$.fragment),Wor=l(),k2e=a("span"),Hor=o("AutoModelForImageClassification"),ROe=l(),Go=a("div"),F(sy.$$.fragment),Uor=l(),pd=a("p"),Jor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),mQ=a("a"),Yor=o("from_pretrained()"),Kor=o(" class method or the "),gQ=a("a"),Zor=o("from_config()"),err=o(` class
method.`),orr=l(),ly=a("p"),rrr=o("This class cannot be instantiated directly using "),S2e=a("code"),trr=o("__init__()"),arr=o(" (throws an error)."),nrr=l(),_t=a("div"),F(iy.$$.fragment),srr=l(),R2e=a("p"),lrr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),irr=l(),_d=a("p"),drr=o(`Note:
Loading a model from its configuration file does `),P2e=a("strong"),crr=o("not"),frr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hQ=a("a"),mrr=o("from_pretrained()"),grr=o(" to load the model weights."),hrr=l(),F(U6.$$.fragment),prr=l(),lo=a("div"),F(dy.$$.fragment),_rr=l(),B2e=a("p"),urr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),brr=l(),Xa=a("p"),vrr=o("The model class to instantiate is selected based on the "),I2e=a("code"),Frr=o("model_type"),Trr=o(` property of the config object (either
passed as an argument or loaded from `),N2e=a("code"),Mrr=o("pretrained_model_name_or_path"),Err=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q2e=a("code"),Crr=o("pretrained_model_name_or_path"),wrr=o(":"),Arr=l(),Fe=a("ul"),J6=a("li"),j2e=a("strong"),Lrr=o("beit"),yrr=o(" \u2014 "),pQ=a("a"),xrr=o("BeitForImageClassification"),$rr=o(" (BEiT model)"),krr=l(),Y6=a("li"),D2e=a("strong"),Srr=o("convnext"),Rrr=o(" \u2014 "),_Q=a("a"),Prr=o("ConvNextForImageClassification"),Brr=o(" (ConvNeXT model)"),Irr=l(),K6=a("li"),G2e=a("strong"),Nrr=o("cvt"),qrr=o(" \u2014 "),uQ=a("a"),jrr=o("CvtForImageClassification"),Drr=o(" (CvT model)"),Grr=l(),Z6=a("li"),O2e=a("strong"),Orr=o("data2vec-vision"),Vrr=o(" \u2014 "),bQ=a("a"),Xrr=o("Data2VecVisionForImageClassification"),zrr=o(" (Data2VecVision model)"),Qrr=l(),Xs=a("li"),V2e=a("strong"),Wrr=o("deit"),Hrr=o(" \u2014 "),vQ=a("a"),Urr=o("DeiTForImageClassification"),Jrr=o(" or "),FQ=a("a"),Yrr=o("DeiTForImageClassificationWithTeacher"),Krr=o(" (DeiT model)"),Zrr=l(),eT=a("li"),X2e=a("strong"),etr=o("imagegpt"),otr=o(" \u2014 "),TQ=a("a"),rtr=o("ImageGPTForImageClassification"),ttr=o(" (ImageGPT model)"),atr=l(),zs=a("li"),z2e=a("strong"),ntr=o("levit"),str=o(" \u2014 "),MQ=a("a"),ltr=o("LevitForImageClassification"),itr=o(" or "),EQ=a("a"),dtr=o("LevitForImageClassificationWithTeacher"),ctr=o(" (LeViT model)"),ftr=l(),ut=a("li"),Q2e=a("strong"),mtr=o("perceiver"),gtr=o(" \u2014 "),CQ=a("a"),htr=o("PerceiverForImageClassificationLearned"),ptr=o(" or "),wQ=a("a"),_tr=o("PerceiverForImageClassificationFourier"),utr=o(" or "),AQ=a("a"),btr=o("PerceiverForImageClassificationConvProcessing"),vtr=o(" (Perceiver model)"),Ftr=l(),oT=a("li"),W2e=a("strong"),Ttr=o("poolformer"),Mtr=o(" \u2014 "),LQ=a("a"),Etr=o("PoolFormerForImageClassification"),Ctr=o(" (PoolFormer model)"),wtr=l(),rT=a("li"),H2e=a("strong"),Atr=o("regnet"),Ltr=o(" \u2014 "),yQ=a("a"),ytr=o("RegNetForImageClassification"),xtr=o(" (RegNet model)"),$tr=l(),tT=a("li"),U2e=a("strong"),ktr=o("resnet"),Str=o(" \u2014 "),xQ=a("a"),Rtr=o("ResNetForImageClassification"),Ptr=o(" (ResNet model)"),Btr=l(),aT=a("li"),J2e=a("strong"),Itr=o("segformer"),Ntr=o(" \u2014 "),$Q=a("a"),qtr=o("SegformerForImageClassification"),jtr=o(" (SegFormer model)"),Dtr=l(),nT=a("li"),Y2e=a("strong"),Gtr=o("swin"),Otr=o(" \u2014 "),kQ=a("a"),Vtr=o("SwinForImageClassification"),Xtr=o(" (Swin Transformer model)"),ztr=l(),sT=a("li"),K2e=a("strong"),Qtr=o("van"),Wtr=o(" \u2014 "),SQ=a("a"),Htr=o("VanForImageClassification"),Utr=o(" (VAN model)"),Jtr=l(),lT=a("li"),Z2e=a("strong"),Ytr=o("vit"),Ktr=o(" \u2014 "),RQ=a("a"),Ztr=o("ViTForImageClassification"),ear=o(" (ViT model)"),oar=l(),iT=a("p"),rar=o("The model is set in evaluation mode by default using "),e1e=a("code"),tar=o("model.eval()"),aar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o1e=a("code"),nar=o("model.train()"),sar=l(),F(dT.$$.fragment),POe=l(),ud=a("h2"),cT=a("a"),r1e=a("span"),F(cy.$$.fragment),lar=l(),t1e=a("span"),iar=o("AutoModelForVision2Seq"),BOe=l(),Oo=a("div"),F(fy.$$.fragment),dar=l(),bd=a("p"),car=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),PQ=a("a"),far=o("from_pretrained()"),mar=o(" class method or the "),BQ=a("a"),gar=o("from_config()"),har=o(` class
method.`),par=l(),my=a("p"),_ar=o("This class cannot be instantiated directly using "),a1e=a("code"),uar=o("__init__()"),bar=o(" (throws an error)."),Far=l(),bt=a("div"),F(gy.$$.fragment),Tar=l(),n1e=a("p"),Mar=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ear=l(),vd=a("p"),Car=o(`Note:
Loading a model from its configuration file does `),s1e=a("strong"),war=o("not"),Aar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),Lar=o("from_pretrained()"),yar=o(" to load the model weights."),xar=l(),F(fT.$$.fragment),$ar=l(),io=a("div"),F(hy.$$.fragment),kar=l(),l1e=a("p"),Sar=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Rar=l(),za=a("p"),Par=o("The model class to instantiate is selected based on the "),i1e=a("code"),Bar=o("model_type"),Iar=o(` property of the config object (either
passed as an argument or loaded from `),d1e=a("code"),Nar=o("pretrained_model_name_or_path"),qar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c1e=a("code"),jar=o("pretrained_model_name_or_path"),Dar=o(":"),Gar=l(),f1e=a("ul"),mT=a("li"),m1e=a("strong"),Oar=o("vision-encoder-decoder"),Var=o(" \u2014 "),NQ=a("a"),Xar=o("VisionEncoderDecoderModel"),zar=o(" (Vision Encoder decoder model)"),Qar=l(),gT=a("p"),War=o("The model is set in evaluation mode by default using "),g1e=a("code"),Har=o("model.eval()"),Uar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=a("code"),Jar=o("model.train()"),Yar=l(),F(hT.$$.fragment),IOe=l(),Fd=a("h2"),pT=a("a"),p1e=a("span"),F(py.$$.fragment),Kar=l(),_1e=a("span"),Zar=o("AutoModelForVisualQuestionAnswering"),NOe=l(),Vo=a("div"),F(_y.$$.fragment),enr=l(),Td=a("p"),onr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),qQ=a("a"),rnr=o("from_pretrained()"),tnr=o(" class method or the "),jQ=a("a"),anr=o("from_config()"),nnr=o(` class
method.`),snr=l(),uy=a("p"),lnr=o("This class cannot be instantiated directly using "),u1e=a("code"),inr=o("__init__()"),dnr=o(" (throws an error)."),cnr=l(),vt=a("div"),F(by.$$.fragment),fnr=l(),b1e=a("p"),mnr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),gnr=l(),Md=a("p"),hnr=o(`Note:
Loading a model from its configuration file does `),v1e=a("strong"),pnr=o("not"),_nr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),unr=o("from_pretrained()"),bnr=o(" to load the model weights."),vnr=l(),F(_T.$$.fragment),Fnr=l(),co=a("div"),F(vy.$$.fragment),Tnr=l(),F1e=a("p"),Mnr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Enr=l(),Qa=a("p"),Cnr=o("The model class to instantiate is selected based on the "),T1e=a("code"),wnr=o("model_type"),Anr=o(` property of the config object (either
passed as an argument or loaded from `),M1e=a("code"),Lnr=o("pretrained_model_name_or_path"),ynr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=a("code"),xnr=o("pretrained_model_name_or_path"),$nr=o(":"),knr=l(),C1e=a("ul"),uT=a("li"),w1e=a("strong"),Snr=o("vilt"),Rnr=o(" \u2014 "),GQ=a("a"),Pnr=o("ViltForQuestionAnswering"),Bnr=o(" (ViLT model)"),Inr=l(),bT=a("p"),Nnr=o("The model is set in evaluation mode by default using "),A1e=a("code"),qnr=o("model.eval()"),jnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L1e=a("code"),Dnr=o("model.train()"),Gnr=l(),F(vT.$$.fragment),qOe=l(),Ed=a("h2"),FT=a("a"),y1e=a("span"),F(Fy.$$.fragment),Onr=l(),x1e=a("span"),Vnr=o("AutoModelForAudioClassification"),jOe=l(),Xo=a("div"),F(Ty.$$.fragment),Xnr=l(),Cd=a("p"),znr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),OQ=a("a"),Qnr=o("from_pretrained()"),Wnr=o(" class method or the "),VQ=a("a"),Hnr=o("from_config()"),Unr=o(` class
method.`),Jnr=l(),My=a("p"),Ynr=o("This class cannot be instantiated directly using "),$1e=a("code"),Knr=o("__init__()"),Znr=o(" (throws an error)."),esr=l(),Ft=a("div"),F(Ey.$$.fragment),osr=l(),k1e=a("p"),rsr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),tsr=l(),wd=a("p"),asr=o(`Note:
Loading a model from its configuration file does `),S1e=a("strong"),nsr=o("not"),ssr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XQ=a("a"),lsr=o("from_pretrained()"),isr=o(" to load the model weights."),dsr=l(),F(TT.$$.fragment),csr=l(),fo=a("div"),F(Cy.$$.fragment),fsr=l(),R1e=a("p"),msr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),gsr=l(),Wa=a("p"),hsr=o("The model class to instantiate is selected based on the "),P1e=a("code"),psr=o("model_type"),_sr=o(` property of the config object (either
passed as an argument or loaded from `),B1e=a("code"),usr=o("pretrained_model_name_or_path"),bsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=a("code"),vsr=o("pretrained_model_name_or_path"),Fsr=o(":"),Tsr=l(),Pe=a("ul"),MT=a("li"),N1e=a("strong"),Msr=o("data2vec-audio"),Esr=o(" \u2014 "),zQ=a("a"),Csr=o("Data2VecAudioForSequenceClassification"),wsr=o(" (Data2VecAudio model)"),Asr=l(),ET=a("li"),q1e=a("strong"),Lsr=o("hubert"),ysr=o(" \u2014 "),QQ=a("a"),xsr=o("HubertForSequenceClassification"),$sr=o(" (Hubert model)"),ksr=l(),CT=a("li"),j1e=a("strong"),Ssr=o("sew"),Rsr=o(" \u2014 "),WQ=a("a"),Psr=o("SEWForSequenceClassification"),Bsr=o(" (SEW model)"),Isr=l(),wT=a("li"),D1e=a("strong"),Nsr=o("sew-d"),qsr=o(" \u2014 "),HQ=a("a"),jsr=o("SEWDForSequenceClassification"),Dsr=o(" (SEW-D model)"),Gsr=l(),AT=a("li"),G1e=a("strong"),Osr=o("unispeech"),Vsr=o(" \u2014 "),UQ=a("a"),Xsr=o("UniSpeechForSequenceClassification"),zsr=o(" (UniSpeech model)"),Qsr=l(),LT=a("li"),O1e=a("strong"),Wsr=o("unispeech-sat"),Hsr=o(" \u2014 "),JQ=a("a"),Usr=o("UniSpeechSatForSequenceClassification"),Jsr=o(" (UniSpeechSat model)"),Ysr=l(),yT=a("li"),V1e=a("strong"),Ksr=o("wav2vec2"),Zsr=o(" \u2014 "),YQ=a("a"),elr=o("Wav2Vec2ForSequenceClassification"),olr=o(" (Wav2Vec2 model)"),rlr=l(),xT=a("li"),X1e=a("strong"),tlr=o("wav2vec2-conformer"),alr=o(" \u2014 "),KQ=a("a"),nlr=o("Wav2Vec2ConformerForSequenceClassification"),slr=o(" (Wav2Vec2-Conformer model)"),llr=l(),$T=a("li"),z1e=a("strong"),ilr=o("wavlm"),dlr=o(" \u2014 "),ZQ=a("a"),clr=o("WavLMForSequenceClassification"),flr=o(" (WavLM model)"),mlr=l(),kT=a("p"),glr=o("The model is set in evaluation mode by default using "),Q1e=a("code"),hlr=o("model.eval()"),plr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W1e=a("code"),_lr=o("model.train()"),ulr=l(),F(ST.$$.fragment),DOe=l(),Ad=a("h2"),RT=a("a"),H1e=a("span"),F(wy.$$.fragment),blr=l(),U1e=a("span"),vlr=o("AutoModelForAudioFrameClassification"),GOe=l(),zo=a("div"),F(Ay.$$.fragment),Flr=l(),Ld=a("p"),Tlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),eW=a("a"),Mlr=o("from_pretrained()"),Elr=o(" class method or the "),oW=a("a"),Clr=o("from_config()"),wlr=o(` class
method.`),Alr=l(),Ly=a("p"),Llr=o("This class cannot be instantiated directly using "),J1e=a("code"),ylr=o("__init__()"),xlr=o(" (throws an error)."),$lr=l(),Tt=a("div"),F(yy.$$.fragment),klr=l(),Y1e=a("p"),Slr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Rlr=l(),yd=a("p"),Plr=o(`Note:
Loading a model from its configuration file does `),K1e=a("strong"),Blr=o("not"),Ilr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=a("a"),Nlr=o("from_pretrained()"),qlr=o(" to load the model weights."),jlr=l(),F(PT.$$.fragment),Dlr=l(),mo=a("div"),F(xy.$$.fragment),Glr=l(),Z1e=a("p"),Olr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Vlr=l(),Ha=a("p"),Xlr=o("The model class to instantiate is selected based on the "),ebe=a("code"),zlr=o("model_type"),Qlr=o(` property of the config object (either
passed as an argument or loaded from `),obe=a("code"),Wlr=o("pretrained_model_name_or_path"),Hlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rbe=a("code"),Ulr=o("pretrained_model_name_or_path"),Jlr=o(":"),Ylr=l(),et=a("ul"),BT=a("li"),tbe=a("strong"),Klr=o("data2vec-audio"),Zlr=o(" \u2014 "),tW=a("a"),eir=o("Data2VecAudioForAudioFrameClassification"),oir=o(" (Data2VecAudio model)"),rir=l(),IT=a("li"),abe=a("strong"),tir=o("unispeech-sat"),air=o(" \u2014 "),aW=a("a"),nir=o("UniSpeechSatForAudioFrameClassification"),sir=o(" (UniSpeechSat model)"),lir=l(),NT=a("li"),nbe=a("strong"),iir=o("wav2vec2"),dir=o(" \u2014 "),nW=a("a"),cir=o("Wav2Vec2ForAudioFrameClassification"),fir=o(" (Wav2Vec2 model)"),mir=l(),qT=a("li"),sbe=a("strong"),gir=o("wav2vec2-conformer"),hir=o(" \u2014 "),sW=a("a"),pir=o("Wav2Vec2ConformerForAudioFrameClassification"),_ir=o(" (Wav2Vec2-Conformer model)"),uir=l(),jT=a("li"),lbe=a("strong"),bir=o("wavlm"),vir=o(" \u2014 "),lW=a("a"),Fir=o("WavLMForAudioFrameClassification"),Tir=o(" (WavLM model)"),Mir=l(),DT=a("p"),Eir=o("The model is set in evaluation mode by default using "),ibe=a("code"),Cir=o("model.eval()"),wir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dbe=a("code"),Air=o("model.train()"),Lir=l(),F(GT.$$.fragment),OOe=l(),xd=a("h2"),OT=a("a"),cbe=a("span"),F($y.$$.fragment),yir=l(),fbe=a("span"),xir=o("AutoModelForCTC"),VOe=l(),Qo=a("div"),F(ky.$$.fragment),$ir=l(),$d=a("p"),kir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),iW=a("a"),Sir=o("from_pretrained()"),Rir=o(" class method or the "),dW=a("a"),Pir=o("from_config()"),Bir=o(` class
method.`),Iir=l(),Sy=a("p"),Nir=o("This class cannot be instantiated directly using "),mbe=a("code"),qir=o("__init__()"),jir=o(" (throws an error)."),Dir=l(),Mt=a("div"),F(Ry.$$.fragment),Gir=l(),gbe=a("p"),Oir=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Vir=l(),kd=a("p"),Xir=o(`Note:
Loading a model from its configuration file does `),hbe=a("strong"),zir=o("not"),Qir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cW=a("a"),Wir=o("from_pretrained()"),Hir=o(" to load the model weights."),Uir=l(),F(VT.$$.fragment),Jir=l(),go=a("div"),F(Py.$$.fragment),Yir=l(),pbe=a("p"),Kir=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Zir=l(),Ua=a("p"),edr=o("The model class to instantiate is selected based on the "),_be=a("code"),odr=o("model_type"),rdr=o(` property of the config object (either
passed as an argument or loaded from `),ube=a("code"),tdr=o("pretrained_model_name_or_path"),adr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bbe=a("code"),ndr=o("pretrained_model_name_or_path"),sdr=o(":"),ldr=l(),Le=a("ul"),XT=a("li"),vbe=a("strong"),idr=o("data2vec-audio"),ddr=o(" \u2014 "),fW=a("a"),cdr=o("Data2VecAudioForCTC"),fdr=o(" (Data2VecAudio model)"),mdr=l(),zT=a("li"),Fbe=a("strong"),gdr=o("hubert"),hdr=o(" \u2014 "),mW=a("a"),pdr=o("HubertForCTC"),_dr=o(" (Hubert model)"),udr=l(),QT=a("li"),Tbe=a("strong"),bdr=o("mctct"),vdr=o(" \u2014 "),gW=a("a"),Fdr=o("MCTCTForCTC"),Tdr=o(" (M-CTC-T model)"),Mdr=l(),WT=a("li"),Mbe=a("strong"),Edr=o("sew"),Cdr=o(" \u2014 "),hW=a("a"),wdr=o("SEWForCTC"),Adr=o(" (SEW model)"),Ldr=l(),HT=a("li"),Ebe=a("strong"),ydr=o("sew-d"),xdr=o(" \u2014 "),pW=a("a"),$dr=o("SEWDForCTC"),kdr=o(" (SEW-D model)"),Sdr=l(),UT=a("li"),Cbe=a("strong"),Rdr=o("unispeech"),Pdr=o(" \u2014 "),_W=a("a"),Bdr=o("UniSpeechForCTC"),Idr=o(" (UniSpeech model)"),Ndr=l(),JT=a("li"),wbe=a("strong"),qdr=o("unispeech-sat"),jdr=o(" \u2014 "),uW=a("a"),Ddr=o("UniSpeechSatForCTC"),Gdr=o(" (UniSpeechSat model)"),Odr=l(),YT=a("li"),Abe=a("strong"),Vdr=o("wav2vec2"),Xdr=o(" \u2014 "),bW=a("a"),zdr=o("Wav2Vec2ForCTC"),Qdr=o(" (Wav2Vec2 model)"),Wdr=l(),KT=a("li"),Lbe=a("strong"),Hdr=o("wav2vec2-conformer"),Udr=o(" \u2014 "),vW=a("a"),Jdr=o("Wav2Vec2ConformerForCTC"),Ydr=o(" (Wav2Vec2-Conformer model)"),Kdr=l(),ZT=a("li"),ybe=a("strong"),Zdr=o("wavlm"),ecr=o(" \u2014 "),FW=a("a"),ocr=o("WavLMForCTC"),rcr=o(" (WavLM model)"),tcr=l(),e7=a("p"),acr=o("The model is set in evaluation mode by default using "),xbe=a("code"),ncr=o("model.eval()"),scr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$be=a("code"),lcr=o("model.train()"),icr=l(),F(o7.$$.fragment),XOe=l(),Sd=a("h2"),r7=a("a"),kbe=a("span"),F(By.$$.fragment),dcr=l(),Sbe=a("span"),ccr=o("AutoModelForSpeechSeq2Seq"),zOe=l(),Wo=a("div"),F(Iy.$$.fragment),fcr=l(),Rd=a("p"),mcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),TW=a("a"),gcr=o("from_pretrained()"),hcr=o(" class method or the "),MW=a("a"),pcr=o("from_config()"),_cr=o(` class
method.`),ucr=l(),Ny=a("p"),bcr=o("This class cannot be instantiated directly using "),Rbe=a("code"),vcr=o("__init__()"),Fcr=o(" (throws an error)."),Tcr=l(),Et=a("div"),F(qy.$$.fragment),Mcr=l(),Pbe=a("p"),Ecr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ccr=l(),Pd=a("p"),wcr=o(`Note:
Loading a model from its configuration file does `),Bbe=a("strong"),Acr=o("not"),Lcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EW=a("a"),ycr=o("from_pretrained()"),xcr=o(" to load the model weights."),$cr=l(),F(t7.$$.fragment),kcr=l(),ho=a("div"),F(jy.$$.fragment),Scr=l(),Ibe=a("p"),Rcr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Pcr=l(),Ja=a("p"),Bcr=o("The model class to instantiate is selected based on the "),Nbe=a("code"),Icr=o("model_type"),Ncr=o(` property of the config object (either
passed as an argument or loaded from `),qbe=a("code"),qcr=o("pretrained_model_name_or_path"),jcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jbe=a("code"),Dcr=o("pretrained_model_name_or_path"),Gcr=o(":"),Ocr=l(),Dy=a("ul"),a7=a("li"),Dbe=a("strong"),Vcr=o("speech-encoder-decoder"),Xcr=o(" \u2014 "),CW=a("a"),zcr=o("SpeechEncoderDecoderModel"),Qcr=o(" (Speech Encoder decoder model)"),Wcr=l(),n7=a("li"),Gbe=a("strong"),Hcr=o("speech_to_text"),Ucr=o(" \u2014 "),wW=a("a"),Jcr=o("Speech2TextForConditionalGeneration"),Ycr=o(" (Speech2Text model)"),Kcr=l(),s7=a("p"),Zcr=o("The model is set in evaluation mode by default using "),Obe=a("code"),efr=o("model.eval()"),ofr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vbe=a("code"),rfr=o("model.train()"),tfr=l(),F(l7.$$.fragment),QOe=l(),Bd=a("h2"),i7=a("a"),Xbe=a("span"),F(Gy.$$.fragment),afr=l(),zbe=a("span"),nfr=o("AutoModelForAudioXVector"),WOe=l(),Ho=a("div"),F(Oy.$$.fragment),sfr=l(),Id=a("p"),lfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),AW=a("a"),ifr=o("from_pretrained()"),dfr=o(" class method or the "),LW=a("a"),cfr=o("from_config()"),ffr=o(` class
method.`),mfr=l(),Vy=a("p"),gfr=o("This class cannot be instantiated directly using "),Qbe=a("code"),hfr=o("__init__()"),pfr=o(" (throws an error)."),_fr=l(),Ct=a("div"),F(Xy.$$.fragment),ufr=l(),Wbe=a("p"),bfr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),vfr=l(),Nd=a("p"),Ffr=o(`Note:
Loading a model from its configuration file does `),Hbe=a("strong"),Tfr=o("not"),Mfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yW=a("a"),Efr=o("from_pretrained()"),Cfr=o(" to load the model weights."),wfr=l(),F(d7.$$.fragment),Afr=l(),po=a("div"),F(zy.$$.fragment),Lfr=l(),Ube=a("p"),yfr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),xfr=l(),Ya=a("p"),$fr=o("The model class to instantiate is selected based on the "),Jbe=a("code"),kfr=o("model_type"),Sfr=o(` property of the config object (either
passed as an argument or loaded from `),Ybe=a("code"),Rfr=o("pretrained_model_name_or_path"),Pfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kbe=a("code"),Bfr=o("pretrained_model_name_or_path"),Ifr=o(":"),Nfr=l(),ot=a("ul"),c7=a("li"),Zbe=a("strong"),qfr=o("data2vec-audio"),jfr=o(" \u2014 "),xW=a("a"),Dfr=o("Data2VecAudioForXVector"),Gfr=o(" (Data2VecAudio model)"),Ofr=l(),f7=a("li"),eve=a("strong"),Vfr=o("unispeech-sat"),Xfr=o(" \u2014 "),$W=a("a"),zfr=o("UniSpeechSatForXVector"),Qfr=o(" (UniSpeechSat model)"),Wfr=l(),m7=a("li"),ove=a("strong"),Hfr=o("wav2vec2"),Ufr=o(" \u2014 "),kW=a("a"),Jfr=o("Wav2Vec2ForXVector"),Yfr=o(" (Wav2Vec2 model)"),Kfr=l(),g7=a("li"),rve=a("strong"),Zfr=o("wav2vec2-conformer"),emr=o(" \u2014 "),SW=a("a"),omr=o("Wav2Vec2ConformerForXVector"),rmr=o(" (Wav2Vec2-Conformer model)"),tmr=l(),h7=a("li"),tve=a("strong"),amr=o("wavlm"),nmr=o(" \u2014 "),RW=a("a"),smr=o("WavLMForXVector"),lmr=o(" (WavLM model)"),imr=l(),p7=a("p"),dmr=o("The model is set in evaluation mode by default using "),ave=a("code"),cmr=o("model.eval()"),fmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nve=a("code"),mmr=o("model.train()"),gmr=l(),F(_7.$$.fragment),HOe=l(),qd=a("h2"),u7=a("a"),sve=a("span"),F(Qy.$$.fragment),hmr=l(),lve=a("span"),pmr=o("AutoModelForMaskedImageModeling"),UOe=l(),Uo=a("div"),F(Wy.$$.fragment),_mr=l(),jd=a("p"),umr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),PW=a("a"),bmr=o("from_pretrained()"),vmr=o(" class method or the "),BW=a("a"),Fmr=o("from_config()"),Tmr=o(` class
method.`),Mmr=l(),Hy=a("p"),Emr=o("This class cannot be instantiated directly using "),ive=a("code"),Cmr=o("__init__()"),wmr=o(" (throws an error)."),Amr=l(),wt=a("div"),F(Uy.$$.fragment),Lmr=l(),dve=a("p"),ymr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),xmr=l(),Dd=a("p"),$mr=o(`Note:
Loading a model from its configuration file does `),cve=a("strong"),kmr=o("not"),Smr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IW=a("a"),Rmr=o("from_pretrained()"),Pmr=o(" to load the model weights."),Bmr=l(),F(b7.$$.fragment),Imr=l(),_o=a("div"),F(Jy.$$.fragment),Nmr=l(),fve=a("p"),qmr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),jmr=l(),Ka=a("p"),Dmr=o("The model class to instantiate is selected based on the "),mve=a("code"),Gmr=o("model_type"),Omr=o(` property of the config object (either
passed as an argument or loaded from `),gve=a("code"),Vmr=o("pretrained_model_name_or_path"),Xmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hve=a("code"),zmr=o("pretrained_model_name_or_path"),Qmr=o(":"),Wmr=l(),Gd=a("ul"),v7=a("li"),pve=a("strong"),Hmr=o("deit"),Umr=o(" \u2014 "),NW=a("a"),Jmr=o("DeiTForMaskedImageModeling"),Ymr=o(" (DeiT model)"),Kmr=l(),F7=a("li"),_ve=a("strong"),Zmr=o("swin"),egr=o(" \u2014 "),qW=a("a"),ogr=o("SwinForMaskedImageModeling"),rgr=o(" (Swin Transformer model)"),tgr=l(),T7=a("li"),uve=a("strong"),agr=o("vit"),ngr=o(" \u2014 "),jW=a("a"),sgr=o("ViTForMaskedImageModeling"),lgr=o(" (ViT model)"),igr=l(),M7=a("p"),dgr=o("The model is set in evaluation mode by default using "),bve=a("code"),cgr=o("model.eval()"),fgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vve=a("code"),mgr=o("model.train()"),ggr=l(),F(E7.$$.fragment),JOe=l(),Od=a("h2"),C7=a("a"),Fve=a("span"),F(Yy.$$.fragment),hgr=l(),Tve=a("span"),pgr=o("AutoModelForObjectDetection"),YOe=l(),Jo=a("div"),F(Ky.$$.fragment),_gr=l(),Vd=a("p"),ugr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),DW=a("a"),bgr=o("from_pretrained()"),vgr=o(" class method or the "),GW=a("a"),Fgr=o("from_config()"),Tgr=o(` class
method.`),Mgr=l(),Zy=a("p"),Egr=o("This class cannot be instantiated directly using "),Mve=a("code"),Cgr=o("__init__()"),wgr=o(" (throws an error)."),Agr=l(),At=a("div"),F(e9.$$.fragment),Lgr=l(),Eve=a("p"),ygr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),xgr=l(),Xd=a("p"),$gr=o(`Note:
Loading a model from its configuration file does `),Cve=a("strong"),kgr=o("not"),Sgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=a("a"),Rgr=o("from_pretrained()"),Pgr=o(" to load the model weights."),Bgr=l(),F(w7.$$.fragment),Igr=l(),uo=a("div"),F(o9.$$.fragment),Ngr=l(),wve=a("p"),qgr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),jgr=l(),Za=a("p"),Dgr=o("The model class to instantiate is selected based on the "),Ave=a("code"),Ggr=o("model_type"),Ogr=o(` property of the config object (either
passed as an argument or loaded from `),Lve=a("code"),Vgr=o("pretrained_model_name_or_path"),Xgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yve=a("code"),zgr=o("pretrained_model_name_or_path"),Qgr=o(":"),Wgr=l(),r9=a("ul"),A7=a("li"),xve=a("strong"),Hgr=o("detr"),Ugr=o(" \u2014 "),VW=a("a"),Jgr=o("DetrForObjectDetection"),Ygr=o(" (DETR model)"),Kgr=l(),L7=a("li"),$ve=a("strong"),Zgr=o("yolos"),ehr=o(" \u2014 "),XW=a("a"),ohr=o("YolosForObjectDetection"),rhr=o(" (YOLOS model)"),thr=l(),y7=a("p"),ahr=o("The model is set in evaluation mode by default using "),kve=a("code"),nhr=o("model.eval()"),shr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sve=a("code"),lhr=o("model.train()"),ihr=l(),F(x7.$$.fragment),KOe=l(),zd=a("h2"),$7=a("a"),Rve=a("span"),F(t9.$$.fragment),dhr=l(),Pve=a("span"),chr=o("AutoModelForImageSegmentation"),ZOe=l(),Yo=a("div"),F(a9.$$.fragment),fhr=l(),Qd=a("p"),mhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),zW=a("a"),ghr=o("from_pretrained()"),hhr=o(" class method or the "),QW=a("a"),phr=o("from_config()"),_hr=o(` class
method.`),uhr=l(),n9=a("p"),bhr=o("This class cannot be instantiated directly using "),Bve=a("code"),vhr=o("__init__()"),Fhr=o(" (throws an error)."),Thr=l(),Lt=a("div"),F(s9.$$.fragment),Mhr=l(),Ive=a("p"),Ehr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Chr=l(),Wd=a("p"),whr=o(`Note:
Loading a model from its configuration file does `),Nve=a("strong"),Ahr=o("not"),Lhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),yhr=o("from_pretrained()"),xhr=o(" to load the model weights."),$hr=l(),F(k7.$$.fragment),khr=l(),bo=a("div"),F(l9.$$.fragment),Shr=l(),qve=a("p"),Rhr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Phr=l(),en=a("p"),Bhr=o("The model class to instantiate is selected based on the "),jve=a("code"),Ihr=o("model_type"),Nhr=o(` property of the config object (either
passed as an argument or loaded from `),Dve=a("code"),qhr=o("pretrained_model_name_or_path"),jhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gve=a("code"),Dhr=o("pretrained_model_name_or_path"),Ghr=o(":"),Ohr=l(),Ove=a("ul"),S7=a("li"),Vve=a("strong"),Vhr=o("detr"),Xhr=o(" \u2014 "),HW=a("a"),zhr=o("DetrForSegmentation"),Qhr=o(" (DETR model)"),Whr=l(),R7=a("p"),Hhr=o("The model is set in evaluation mode by default using "),Xve=a("code"),Uhr=o("model.eval()"),Jhr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zve=a("code"),Yhr=o("model.train()"),Khr=l(),F(P7.$$.fragment),eVe=l(),Hd=a("h2"),B7=a("a"),Qve=a("span"),F(i9.$$.fragment),Zhr=l(),Wve=a("span"),epr=o("AutoModelForSemanticSegmentation"),oVe=l(),Ko=a("div"),F(d9.$$.fragment),opr=l(),Ud=a("p"),rpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),UW=a("a"),tpr=o("from_pretrained()"),apr=o(" class method or the "),JW=a("a"),npr=o("from_config()"),spr=o(` class
method.`),lpr=l(),c9=a("p"),ipr=o("This class cannot be instantiated directly using "),Hve=a("code"),dpr=o("__init__()"),cpr=o(" (throws an error)."),fpr=l(),yt=a("div"),F(f9.$$.fragment),mpr=l(),Uve=a("p"),gpr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),hpr=l(),Jd=a("p"),ppr=o(`Note:
Loading a model from its configuration file does `),Jve=a("strong"),_pr=o("not"),upr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),bpr=o("from_pretrained()"),vpr=o(" to load the model weights."),Fpr=l(),F(I7.$$.fragment),Tpr=l(),vo=a("div"),F(m9.$$.fragment),Mpr=l(),Yve=a("p"),Epr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Cpr=l(),on=a("p"),wpr=o("The model class to instantiate is selected based on the "),Kve=a("code"),Apr=o("model_type"),Lpr=o(` property of the config object (either
passed as an argument or loaded from `),Zve=a("code"),ypr=o("pretrained_model_name_or_path"),xpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eFe=a("code"),$pr=o("pretrained_model_name_or_path"),kpr=o(":"),Spr=l(),rn=a("ul"),N7=a("li"),oFe=a("strong"),Rpr=o("beit"),Ppr=o(" \u2014 "),KW=a("a"),Bpr=o("BeitForSemanticSegmentation"),Ipr=o(" (BEiT model)"),Npr=l(),q7=a("li"),rFe=a("strong"),qpr=o("data2vec-vision"),jpr=o(" \u2014 "),ZW=a("a"),Dpr=o("Data2VecVisionForSemanticSegmentation"),Gpr=o(" (Data2VecVision model)"),Opr=l(),j7=a("li"),tFe=a("strong"),Vpr=o("dpt"),Xpr=o(" \u2014 "),eH=a("a"),zpr=o("DPTForSemanticSegmentation"),Qpr=o(" (DPT model)"),Wpr=l(),D7=a("li"),aFe=a("strong"),Hpr=o("segformer"),Upr=o(" \u2014 "),oH=a("a"),Jpr=o("SegformerForSemanticSegmentation"),Ypr=o(" (SegFormer model)"),Kpr=l(),G7=a("p"),Zpr=o("The model is set in evaluation mode by default using "),nFe=a("code"),e_r=o("model.eval()"),o_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sFe=a("code"),r_r=o("model.train()"),t_r=l(),F(O7.$$.fragment),rVe=l(),Yd=a("h2"),V7=a("a"),lFe=a("span"),F(g9.$$.fragment),a_r=l(),iFe=a("span"),n_r=o("AutoModelForInstanceSegmentation"),tVe=l(),Zo=a("div"),F(h9.$$.fragment),s_r=l(),Kd=a("p"),l_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),rH=a("a"),i_r=o("from_pretrained()"),d_r=o(" class method or the "),tH=a("a"),c_r=o("from_config()"),f_r=o(` class
method.`),m_r=l(),p9=a("p"),g_r=o("This class cannot be instantiated directly using "),dFe=a("code"),h_r=o("__init__()"),p_r=o(" (throws an error)."),__r=l(),xt=a("div"),F(_9.$$.fragment),u_r=l(),cFe=a("p"),b_r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),v_r=l(),Zd=a("p"),F_r=o(`Note:
Loading a model from its configuration file does `),fFe=a("strong"),T_r=o("not"),M_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),E_r=o("from_pretrained()"),C_r=o(" to load the model weights."),w_r=l(),F(X7.$$.fragment),A_r=l(),Fo=a("div"),F(u9.$$.fragment),L_r=l(),mFe=a("p"),y_r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),x_r=l(),tn=a("p"),$_r=o("The model class to instantiate is selected based on the "),gFe=a("code"),k_r=o("model_type"),S_r=o(` property of the config object (either
passed as an argument or loaded from `),hFe=a("code"),R_r=o("pretrained_model_name_or_path"),P_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pFe=a("code"),B_r=o("pretrained_model_name_or_path"),I_r=o(":"),N_r=l(),_Fe=a("ul"),z7=a("li"),uFe=a("strong"),q_r=o("maskformer"),j_r=o(" \u2014 "),nH=a("a"),D_r=o("MaskFormerForInstanceSegmentation"),G_r=o(" (MaskFormer model)"),O_r=l(),Q7=a("p"),V_r=o("The model is set in evaluation mode by default using "),bFe=a("code"),X_r=o("model.eval()"),z_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vFe=a("code"),Q_r=o("model.train()"),W_r=l(),F(W7.$$.fragment),aVe=l(),ec=a("h2"),H7=a("a"),FFe=a("span"),F(b9.$$.fragment),H_r=l(),TFe=a("span"),U_r=o("TFAutoModel"),nVe=l(),er=a("div"),F(v9.$$.fragment),J_r=l(),oc=a("p"),Y_r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sH=a("a"),K_r=o("from_pretrained()"),Z_r=o(" class method or the "),lH=a("a"),eur=o("from_config()"),our=o(` class
method.`),rur=l(),F9=a("p"),tur=o("This class cannot be instantiated directly using "),MFe=a("code"),aur=o("__init__()"),nur=o(" (throws an error)."),sur=l(),$t=a("div"),F(T9.$$.fragment),lur=l(),EFe=a("p"),iur=o("Instantiates one of the base model classes of the library from a configuration."),dur=l(),rc=a("p"),cur=o(`Note:
Loading a model from its configuration file does `),CFe=a("strong"),fur=o("not"),mur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iH=a("a"),gur=o("from_pretrained()"),hur=o(" to load the model weights."),pur=l(),F(U7.$$.fragment),_ur=l(),yr=a("div"),F(M9.$$.fragment),uur=l(),wFe=a("p"),bur=o("Instantiate one of the base model classes of the library from a pretrained model."),vur=l(),an=a("p"),Fur=o("The model class to instantiate is selected based on the "),AFe=a("code"),Tur=o("model_type"),Mur=o(` property of the config object (either
passed as an argument or loaded from `),LFe=a("code"),Eur=o("pretrained_model_name_or_path"),Cur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yFe=a("code"),wur=o("pretrained_model_name_or_path"),Aur=o(":"),Lur=l(),j=a("ul"),J7=a("li"),xFe=a("strong"),yur=o("albert"),xur=o(" \u2014 "),dH=a("a"),$ur=o("TFAlbertModel"),kur=o(" (ALBERT model)"),Sur=l(),Y7=a("li"),$Fe=a("strong"),Rur=o("bart"),Pur=o(" \u2014 "),cH=a("a"),Bur=o("TFBartModel"),Iur=o(" (BART model)"),Nur=l(),K7=a("li"),kFe=a("strong"),qur=o("bert"),jur=o(" \u2014 "),fH=a("a"),Dur=o("TFBertModel"),Gur=o(" (BERT model)"),Our=l(),Z7=a("li"),SFe=a("strong"),Vur=o("blenderbot"),Xur=o(" \u2014 "),mH=a("a"),zur=o("TFBlenderbotModel"),Qur=o(" (Blenderbot model)"),Wur=l(),e8=a("li"),RFe=a("strong"),Hur=o("blenderbot-small"),Uur=o(" \u2014 "),gH=a("a"),Jur=o("TFBlenderbotSmallModel"),Yur=o(" (BlenderbotSmall model)"),Kur=l(),o8=a("li"),PFe=a("strong"),Zur=o("camembert"),e2r=o(" \u2014 "),hH=a("a"),o2r=o("TFCamembertModel"),r2r=o(" (CamemBERT model)"),t2r=l(),r8=a("li"),BFe=a("strong"),a2r=o("clip"),n2r=o(" \u2014 "),pH=a("a"),s2r=o("TFCLIPModel"),l2r=o(" (CLIP model)"),i2r=l(),t8=a("li"),IFe=a("strong"),d2r=o("convbert"),c2r=o(" \u2014 "),_H=a("a"),f2r=o("TFConvBertModel"),m2r=o(" (ConvBERT model)"),g2r=l(),a8=a("li"),NFe=a("strong"),h2r=o("convnext"),p2r=o(" \u2014 "),uH=a("a"),_2r=o("TFConvNextModel"),u2r=o(" (ConvNeXT model)"),b2r=l(),n8=a("li"),qFe=a("strong"),v2r=o("ctrl"),F2r=o(" \u2014 "),bH=a("a"),T2r=o("TFCTRLModel"),M2r=o(" (CTRL model)"),E2r=l(),s8=a("li"),jFe=a("strong"),C2r=o("data2vec-vision"),w2r=o(" \u2014 "),vH=a("a"),A2r=o("TFData2VecVisionModel"),L2r=o(" (Data2VecVision model)"),y2r=l(),l8=a("li"),DFe=a("strong"),x2r=o("deberta"),$2r=o(" \u2014 "),FH=a("a"),k2r=o("TFDebertaModel"),S2r=o(" (DeBERTa model)"),R2r=l(),i8=a("li"),GFe=a("strong"),P2r=o("deberta-v2"),B2r=o(" \u2014 "),TH=a("a"),I2r=o("TFDebertaV2Model"),N2r=o(" (DeBERTa-v2 model)"),q2r=l(),d8=a("li"),OFe=a("strong"),j2r=o("distilbert"),D2r=o(" \u2014 "),MH=a("a"),G2r=o("TFDistilBertModel"),O2r=o(" (DistilBERT model)"),V2r=l(),c8=a("li"),VFe=a("strong"),X2r=o("dpr"),z2r=o(" \u2014 "),EH=a("a"),Q2r=o("TFDPRQuestionEncoder"),W2r=o(" (DPR model)"),H2r=l(),f8=a("li"),XFe=a("strong"),U2r=o("electra"),J2r=o(" \u2014 "),CH=a("a"),Y2r=o("TFElectraModel"),K2r=o(" (ELECTRA model)"),Z2r=l(),m8=a("li"),zFe=a("strong"),e1r=o("flaubert"),o1r=o(" \u2014 "),wH=a("a"),r1r=o("TFFlaubertModel"),t1r=o(" (FlauBERT model)"),a1r=l(),Qs=a("li"),QFe=a("strong"),n1r=o("funnel"),s1r=o(" \u2014 "),AH=a("a"),l1r=o("TFFunnelModel"),i1r=o(" or "),LH=a("a"),d1r=o("TFFunnelBaseModel"),c1r=o(" (Funnel Transformer model)"),f1r=l(),g8=a("li"),WFe=a("strong"),m1r=o("gpt2"),g1r=o(" \u2014 "),yH=a("a"),h1r=o("TFGPT2Model"),p1r=o(" (OpenAI GPT-2 model)"),_1r=l(),h8=a("li"),HFe=a("strong"),u1r=o("gptj"),b1r=o(" \u2014 "),xH=a("a"),v1r=o("TFGPTJModel"),F1r=o(" (GPT-J model)"),T1r=l(),p8=a("li"),UFe=a("strong"),M1r=o("hubert"),E1r=o(" \u2014 "),$H=a("a"),C1r=o("TFHubertModel"),w1r=o(" (Hubert model)"),A1r=l(),_8=a("li"),JFe=a("strong"),L1r=o("layoutlm"),y1r=o(" \u2014 "),kH=a("a"),x1r=o("TFLayoutLMModel"),$1r=o(" (LayoutLM model)"),k1r=l(),u8=a("li"),YFe=a("strong"),S1r=o("led"),R1r=o(" \u2014 "),SH=a("a"),P1r=o("TFLEDModel"),B1r=o(" (LED model)"),I1r=l(),b8=a("li"),KFe=a("strong"),N1r=o("longformer"),q1r=o(" \u2014 "),RH=a("a"),j1r=o("TFLongformerModel"),D1r=o(" (Longformer model)"),G1r=l(),v8=a("li"),ZFe=a("strong"),O1r=o("lxmert"),V1r=o(" \u2014 "),PH=a("a"),X1r=o("TFLxmertModel"),z1r=o(" (LXMERT model)"),Q1r=l(),F8=a("li"),e6e=a("strong"),W1r=o("marian"),H1r=o(" \u2014 "),BH=a("a"),U1r=o("TFMarianModel"),J1r=o(" (Marian model)"),Y1r=l(),T8=a("li"),o6e=a("strong"),K1r=o("mbart"),Z1r=o(" \u2014 "),IH=a("a"),ebr=o("TFMBartModel"),obr=o(" (mBART model)"),rbr=l(),M8=a("li"),r6e=a("strong"),tbr=o("mobilebert"),abr=o(" \u2014 "),NH=a("a"),nbr=o("TFMobileBertModel"),sbr=o(" (MobileBERT model)"),lbr=l(),E8=a("li"),t6e=a("strong"),ibr=o("mpnet"),dbr=o(" \u2014 "),qH=a("a"),cbr=o("TFMPNetModel"),fbr=o(" (MPNet model)"),mbr=l(),C8=a("li"),a6e=a("strong"),gbr=o("mt5"),hbr=o(" \u2014 "),jH=a("a"),pbr=o("TFMT5Model"),_br=o(" (MT5 model)"),ubr=l(),w8=a("li"),n6e=a("strong"),bbr=o("openai-gpt"),vbr=o(" \u2014 "),DH=a("a"),Fbr=o("TFOpenAIGPTModel"),Tbr=o(" (OpenAI GPT model)"),Mbr=l(),A8=a("li"),s6e=a("strong"),Ebr=o("opt"),Cbr=o(" \u2014 "),GH=a("a"),wbr=o("TFOPTModel"),Abr=o(" (OPT model)"),Lbr=l(),L8=a("li"),l6e=a("strong"),ybr=o("pegasus"),xbr=o(" \u2014 "),OH=a("a"),$br=o("TFPegasusModel"),kbr=o(" (Pegasus model)"),Sbr=l(),y8=a("li"),i6e=a("strong"),Rbr=o("rembert"),Pbr=o(" \u2014 "),VH=a("a"),Bbr=o("TFRemBertModel"),Ibr=o(" (RemBERT model)"),Nbr=l(),x8=a("li"),d6e=a("strong"),qbr=o("roberta"),jbr=o(" \u2014 "),XH=a("a"),Dbr=o("TFRobertaModel"),Gbr=o(" (RoBERTa model)"),Obr=l(),$8=a("li"),c6e=a("strong"),Vbr=o("roformer"),Xbr=o(" \u2014 "),zH=a("a"),zbr=o("TFRoFormerModel"),Qbr=o(" (RoFormer model)"),Wbr=l(),k8=a("li"),f6e=a("strong"),Hbr=o("speech_to_text"),Ubr=o(" \u2014 "),QH=a("a"),Jbr=o("TFSpeech2TextModel"),Ybr=o(" (Speech2Text model)"),Kbr=l(),S8=a("li"),m6e=a("strong"),Zbr=o("swin"),evr=o(" \u2014 "),WH=a("a"),ovr=o("TFSwinModel"),rvr=o(" (Swin Transformer model)"),tvr=l(),R8=a("li"),g6e=a("strong"),avr=o("t5"),nvr=o(" \u2014 "),HH=a("a"),svr=o("TFT5Model"),lvr=o(" (T5 model)"),ivr=l(),P8=a("li"),h6e=a("strong"),dvr=o("tapas"),cvr=o(" \u2014 "),UH=a("a"),fvr=o("TFTapasModel"),mvr=o(" (TAPAS model)"),gvr=l(),B8=a("li"),p6e=a("strong"),hvr=o("transfo-xl"),pvr=o(" \u2014 "),JH=a("a"),_vr=o("TFTransfoXLModel"),uvr=o(" (Transformer-XL model)"),bvr=l(),I8=a("li"),_6e=a("strong"),vvr=o("vit"),Fvr=o(" \u2014 "),YH=a("a"),Tvr=o("TFViTModel"),Mvr=o(" (ViT model)"),Evr=l(),N8=a("li"),u6e=a("strong"),Cvr=o("vit_mae"),wvr=o(" \u2014 "),KH=a("a"),Avr=o("TFViTMAEModel"),Lvr=o(" (ViTMAE model)"),yvr=l(),q8=a("li"),b6e=a("strong"),xvr=o("wav2vec2"),$vr=o(" \u2014 "),ZH=a("a"),kvr=o("TFWav2Vec2Model"),Svr=o(" (Wav2Vec2 model)"),Rvr=l(),j8=a("li"),v6e=a("strong"),Pvr=o("xlm"),Bvr=o(" \u2014 "),eU=a("a"),Ivr=o("TFXLMModel"),Nvr=o(" (XLM model)"),qvr=l(),D8=a("li"),F6e=a("strong"),jvr=o("xlm-roberta"),Dvr=o(" \u2014 "),oU=a("a"),Gvr=o("TFXLMRobertaModel"),Ovr=o(" (XLM-RoBERTa model)"),Vvr=l(),G8=a("li"),T6e=a("strong"),Xvr=o("xlnet"),zvr=o(" \u2014 "),rU=a("a"),Qvr=o("TFXLNetModel"),Wvr=o(" (XLNet model)"),Hvr=l(),F(O8.$$.fragment),sVe=l(),tc=a("h2"),V8=a("a"),M6e=a("span"),F(E9.$$.fragment),Uvr=l(),E6e=a("span"),Jvr=o("TFAutoModelForPreTraining"),lVe=l(),or=a("div"),F(C9.$$.fragment),Yvr=l(),ac=a("p"),Kvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),tU=a("a"),Zvr=o("from_pretrained()"),eFr=o(" class method or the "),aU=a("a"),oFr=o("from_config()"),rFr=o(` class
method.`),tFr=l(),w9=a("p"),aFr=o("This class cannot be instantiated directly using "),C6e=a("code"),nFr=o("__init__()"),sFr=o(" (throws an error)."),lFr=l(),kt=a("div"),F(A9.$$.fragment),iFr=l(),w6e=a("p"),dFr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cFr=l(),nc=a("p"),fFr=o(`Note:
Loading a model from its configuration file does `),A6e=a("strong"),mFr=o("not"),gFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=a("a"),hFr=o("from_pretrained()"),pFr=o(" to load the model weights."),_Fr=l(),F(X8.$$.fragment),uFr=l(),xr=a("div"),F(L9.$$.fragment),bFr=l(),L6e=a("p"),vFr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FFr=l(),nn=a("p"),TFr=o("The model class to instantiate is selected based on the "),y6e=a("code"),MFr=o("model_type"),EFr=o(` property of the config object (either
passed as an argument or loaded from `),x6e=a("code"),CFr=o("pretrained_model_name_or_path"),wFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$6e=a("code"),AFr=o("pretrained_model_name_or_path"),LFr=o(":"),yFr=l(),se=a("ul"),z8=a("li"),k6e=a("strong"),xFr=o("albert"),$Fr=o(" \u2014 "),sU=a("a"),kFr=o("TFAlbertForPreTraining"),SFr=o(" (ALBERT model)"),RFr=l(),Q8=a("li"),S6e=a("strong"),PFr=o("bart"),BFr=o(" \u2014 "),lU=a("a"),IFr=o("TFBartForConditionalGeneration"),NFr=o(" (BART model)"),qFr=l(),W8=a("li"),R6e=a("strong"),jFr=o("bert"),DFr=o(" \u2014 "),iU=a("a"),GFr=o("TFBertForPreTraining"),OFr=o(" (BERT model)"),VFr=l(),H8=a("li"),P6e=a("strong"),XFr=o("camembert"),zFr=o(" \u2014 "),dU=a("a"),QFr=o("TFCamembertForMaskedLM"),WFr=o(" (CamemBERT model)"),HFr=l(),U8=a("li"),B6e=a("strong"),UFr=o("ctrl"),JFr=o(" \u2014 "),cU=a("a"),YFr=o("TFCTRLLMHeadModel"),KFr=o(" (CTRL model)"),ZFr=l(),J8=a("li"),I6e=a("strong"),e6r=o("distilbert"),o6r=o(" \u2014 "),fU=a("a"),r6r=o("TFDistilBertForMaskedLM"),t6r=o(" (DistilBERT model)"),a6r=l(),Y8=a("li"),N6e=a("strong"),n6r=o("electra"),s6r=o(" \u2014 "),mU=a("a"),l6r=o("TFElectraForPreTraining"),i6r=o(" (ELECTRA model)"),d6r=l(),K8=a("li"),q6e=a("strong"),c6r=o("flaubert"),f6r=o(" \u2014 "),gU=a("a"),m6r=o("TFFlaubertWithLMHeadModel"),g6r=o(" (FlauBERT model)"),h6r=l(),Z8=a("li"),j6e=a("strong"),p6r=o("funnel"),_6r=o(" \u2014 "),hU=a("a"),u6r=o("TFFunnelForPreTraining"),b6r=o(" (Funnel Transformer model)"),v6r=l(),eM=a("li"),D6e=a("strong"),F6r=o("gpt2"),T6r=o(" \u2014 "),pU=a("a"),M6r=o("TFGPT2LMHeadModel"),E6r=o(" (OpenAI GPT-2 model)"),C6r=l(),oM=a("li"),G6e=a("strong"),w6r=o("layoutlm"),A6r=o(" \u2014 "),_U=a("a"),L6r=o("TFLayoutLMForMaskedLM"),y6r=o(" (LayoutLM model)"),x6r=l(),rM=a("li"),O6e=a("strong"),$6r=o("lxmert"),k6r=o(" \u2014 "),uU=a("a"),S6r=o("TFLxmertForPreTraining"),R6r=o(" (LXMERT model)"),P6r=l(),tM=a("li"),V6e=a("strong"),B6r=o("mobilebert"),I6r=o(" \u2014 "),bU=a("a"),N6r=o("TFMobileBertForPreTraining"),q6r=o(" (MobileBERT model)"),j6r=l(),aM=a("li"),X6e=a("strong"),D6r=o("mpnet"),G6r=o(" \u2014 "),vU=a("a"),O6r=o("TFMPNetForMaskedLM"),V6r=o(" (MPNet model)"),X6r=l(),nM=a("li"),z6e=a("strong"),z6r=o("openai-gpt"),Q6r=o(" \u2014 "),FU=a("a"),W6r=o("TFOpenAIGPTLMHeadModel"),H6r=o(" (OpenAI GPT model)"),U6r=l(),sM=a("li"),Q6e=a("strong"),J6r=o("roberta"),Y6r=o(" \u2014 "),TU=a("a"),K6r=o("TFRobertaForMaskedLM"),Z6r=o(" (RoBERTa model)"),eTr=l(),lM=a("li"),W6e=a("strong"),oTr=o("t5"),rTr=o(" \u2014 "),MU=a("a"),tTr=o("TFT5ForConditionalGeneration"),aTr=o(" (T5 model)"),nTr=l(),iM=a("li"),H6e=a("strong"),sTr=o("tapas"),lTr=o(" \u2014 "),EU=a("a"),iTr=o("TFTapasForMaskedLM"),dTr=o(" (TAPAS model)"),cTr=l(),dM=a("li"),U6e=a("strong"),fTr=o("transfo-xl"),mTr=o(" \u2014 "),CU=a("a"),gTr=o("TFTransfoXLLMHeadModel"),hTr=o(" (Transformer-XL model)"),pTr=l(),cM=a("li"),J6e=a("strong"),_Tr=o("vit_mae"),uTr=o(" \u2014 "),wU=a("a"),bTr=o("TFViTMAEForPreTraining"),vTr=o(" (ViTMAE model)"),FTr=l(),fM=a("li"),Y6e=a("strong"),TTr=o("xlm"),MTr=o(" \u2014 "),AU=a("a"),ETr=o("TFXLMWithLMHeadModel"),CTr=o(" (XLM model)"),wTr=l(),mM=a("li"),K6e=a("strong"),ATr=o("xlm-roberta"),LTr=o(" \u2014 "),LU=a("a"),yTr=o("TFXLMRobertaForMaskedLM"),xTr=o(" (XLM-RoBERTa model)"),$Tr=l(),gM=a("li"),Z6e=a("strong"),kTr=o("xlnet"),STr=o(" \u2014 "),yU=a("a"),RTr=o("TFXLNetLMHeadModel"),PTr=o(" (XLNet model)"),BTr=l(),F(hM.$$.fragment),iVe=l(),sc=a("h2"),pM=a("a"),eTe=a("span"),F(y9.$$.fragment),ITr=l(),oTe=a("span"),NTr=o("TFAutoModelForCausalLM"),dVe=l(),rr=a("div"),F(x9.$$.fragment),qTr=l(),lc=a("p"),jTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),xU=a("a"),DTr=o("from_pretrained()"),GTr=o(" class method or the "),$U=a("a"),OTr=o("from_config()"),VTr=o(` class
method.`),XTr=l(),$9=a("p"),zTr=o("This class cannot be instantiated directly using "),rTe=a("code"),QTr=o("__init__()"),WTr=o(" (throws an error)."),HTr=l(),St=a("div"),F(k9.$$.fragment),UTr=l(),tTe=a("p"),JTr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),YTr=l(),ic=a("p"),KTr=o(`Note:
Loading a model from its configuration file does `),aTe=a("strong"),ZTr=o("not"),e7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kU=a("a"),o7r=o("from_pretrained()"),r7r=o(" to load the model weights."),t7r=l(),F(_M.$$.fragment),a7r=l(),$r=a("div"),F(S9.$$.fragment),n7r=l(),nTe=a("p"),s7r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),l7r=l(),sn=a("p"),i7r=o("The model class to instantiate is selected based on the "),sTe=a("code"),d7r=o("model_type"),c7r=o(` property of the config object (either
passed as an argument or loaded from `),lTe=a("code"),f7r=o("pretrained_model_name_or_path"),m7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=a("code"),g7r=o("pretrained_model_name_or_path"),h7r=o(":"),p7r=l(),Me=a("ul"),uM=a("li"),dTe=a("strong"),_7r=o("bert"),u7r=o(" \u2014 "),SU=a("a"),b7r=o("TFBertLMHeadModel"),v7r=o(" (BERT model)"),F7r=l(),bM=a("li"),cTe=a("strong"),T7r=o("camembert"),M7r=o(" \u2014 "),RU=a("a"),E7r=o("TFCamembertForCausalLM"),C7r=o(" (CamemBERT model)"),w7r=l(),vM=a("li"),fTe=a("strong"),A7r=o("ctrl"),L7r=o(" \u2014 "),PU=a("a"),y7r=o("TFCTRLLMHeadModel"),x7r=o(" (CTRL model)"),$7r=l(),FM=a("li"),mTe=a("strong"),k7r=o("gpt2"),S7r=o(" \u2014 "),BU=a("a"),R7r=o("TFGPT2LMHeadModel"),P7r=o(" (OpenAI GPT-2 model)"),B7r=l(),TM=a("li"),gTe=a("strong"),I7r=o("gptj"),N7r=o(" \u2014 "),IU=a("a"),q7r=o("TFGPTJForCausalLM"),j7r=o(" (GPT-J model)"),D7r=l(),MM=a("li"),hTe=a("strong"),G7r=o("openai-gpt"),O7r=o(" \u2014 "),NU=a("a"),V7r=o("TFOpenAIGPTLMHeadModel"),X7r=o(" (OpenAI GPT model)"),z7r=l(),EM=a("li"),pTe=a("strong"),Q7r=o("opt"),W7r=o(" \u2014 "),qU=a("a"),H7r=o("TFOPTForCausalLM"),U7r=o(" (OPT model)"),J7r=l(),CM=a("li"),_Te=a("strong"),Y7r=o("rembert"),K7r=o(" \u2014 "),jU=a("a"),Z7r=o("TFRemBertForCausalLM"),e8r=o(" (RemBERT model)"),o8r=l(),wM=a("li"),uTe=a("strong"),r8r=o("roberta"),t8r=o(" \u2014 "),DU=a("a"),a8r=o("TFRobertaForCausalLM"),n8r=o(" (RoBERTa model)"),s8r=l(),AM=a("li"),bTe=a("strong"),l8r=o("roformer"),i8r=o(" \u2014 "),GU=a("a"),d8r=o("TFRoFormerForCausalLM"),c8r=o(" (RoFormer model)"),f8r=l(),LM=a("li"),vTe=a("strong"),m8r=o("transfo-xl"),g8r=o(" \u2014 "),OU=a("a"),h8r=o("TFTransfoXLLMHeadModel"),p8r=o(" (Transformer-XL model)"),_8r=l(),yM=a("li"),FTe=a("strong"),u8r=o("xlm"),b8r=o(" \u2014 "),VU=a("a"),v8r=o("TFXLMWithLMHeadModel"),F8r=o(" (XLM model)"),T8r=l(),xM=a("li"),TTe=a("strong"),M8r=o("xlnet"),E8r=o(" \u2014 "),XU=a("a"),C8r=o("TFXLNetLMHeadModel"),w8r=o(" (XLNet model)"),A8r=l(),F($M.$$.fragment),cVe=l(),dc=a("h2"),kM=a("a"),MTe=a("span"),F(R9.$$.fragment),L8r=l(),ETe=a("span"),y8r=o("TFAutoModelForImageClassification"),fVe=l(),tr=a("div"),F(P9.$$.fragment),x8r=l(),cc=a("p"),$8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),zU=a("a"),k8r=o("from_pretrained()"),S8r=o(" class method or the "),QU=a("a"),R8r=o("from_config()"),P8r=o(` class
method.`),B8r=l(),B9=a("p"),I8r=o("This class cannot be instantiated directly using "),CTe=a("code"),N8r=o("__init__()"),q8r=o(" (throws an error)."),j8r=l(),Rt=a("div"),F(I9.$$.fragment),D8r=l(),wTe=a("p"),G8r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),O8r=l(),fc=a("p"),V8r=o(`Note:
Loading a model from its configuration file does `),ATe=a("strong"),X8r=o("not"),z8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=a("a"),Q8r=o("from_pretrained()"),W8r=o(" to load the model weights."),H8r=l(),F(SM.$$.fragment),U8r=l(),kr=a("div"),F(N9.$$.fragment),J8r=l(),LTe=a("p"),Y8r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),K8r=l(),ln=a("p"),Z8r=o("The model class to instantiate is selected based on the "),yTe=a("code"),eMr=o("model_type"),oMr=o(` property of the config object (either
passed as an argument or loaded from `),xTe=a("code"),rMr=o("pretrained_model_name_or_path"),tMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Te=a("code"),aMr=o("pretrained_model_name_or_path"),nMr=o(":"),sMr=l(),dn=a("ul"),RM=a("li"),kTe=a("strong"),lMr=o("convnext"),iMr=o(" \u2014 "),HU=a("a"),dMr=o("TFConvNextForImageClassification"),cMr=o(" (ConvNeXT model)"),fMr=l(),PM=a("li"),STe=a("strong"),mMr=o("data2vec-vision"),gMr=o(" \u2014 "),UU=a("a"),hMr=o("TFData2VecVisionForImageClassification"),pMr=o(" (Data2VecVision model)"),_Mr=l(),BM=a("li"),RTe=a("strong"),uMr=o("swin"),bMr=o(" \u2014 "),JU=a("a"),vMr=o("TFSwinForImageClassification"),FMr=o(" (Swin Transformer model)"),TMr=l(),IM=a("li"),PTe=a("strong"),MMr=o("vit"),EMr=o(" \u2014 "),YU=a("a"),CMr=o("TFViTForImageClassification"),wMr=o(" (ViT model)"),AMr=l(),F(NM.$$.fragment),mVe=l(),mc=a("h2"),qM=a("a"),BTe=a("span"),F(q9.$$.fragment),LMr=l(),ITe=a("span"),yMr=o("TFAutoModelForMaskedLM"),gVe=l(),ar=a("div"),F(j9.$$.fragment),xMr=l(),gc=a("p"),$Mr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KU=a("a"),kMr=o("from_pretrained()"),SMr=o(" class method or the "),ZU=a("a"),RMr=o("from_config()"),PMr=o(` class
method.`),BMr=l(),D9=a("p"),IMr=o("This class cannot be instantiated directly using "),NTe=a("code"),NMr=o("__init__()"),qMr=o(" (throws an error)."),jMr=l(),Pt=a("div"),F(G9.$$.fragment),DMr=l(),qTe=a("p"),GMr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),OMr=l(),hc=a("p"),VMr=o(`Note:
Loading a model from its configuration file does `),jTe=a("strong"),XMr=o("not"),zMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=a("a"),QMr=o("from_pretrained()"),WMr=o(" to load the model weights."),HMr=l(),F(jM.$$.fragment),UMr=l(),Sr=a("div"),F(O9.$$.fragment),JMr=l(),DTe=a("p"),YMr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),KMr=l(),cn=a("p"),ZMr=o("The model class to instantiate is selected based on the "),GTe=a("code"),eEr=o("model_type"),oEr=o(` property of the config object (either
passed as an argument or loaded from `),OTe=a("code"),rEr=o("pretrained_model_name_or_path"),tEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VTe=a("code"),aEr=o("pretrained_model_name_or_path"),nEr=o(":"),sEr=l(),ie=a("ul"),DM=a("li"),XTe=a("strong"),lEr=o("albert"),iEr=o(" \u2014 "),oJ=a("a"),dEr=o("TFAlbertForMaskedLM"),cEr=o(" (ALBERT model)"),fEr=l(),GM=a("li"),zTe=a("strong"),mEr=o("bert"),gEr=o(" \u2014 "),rJ=a("a"),hEr=o("TFBertForMaskedLM"),pEr=o(" (BERT model)"),_Er=l(),OM=a("li"),QTe=a("strong"),uEr=o("camembert"),bEr=o(" \u2014 "),tJ=a("a"),vEr=o("TFCamembertForMaskedLM"),FEr=o(" (CamemBERT model)"),TEr=l(),VM=a("li"),WTe=a("strong"),MEr=o("convbert"),EEr=o(" \u2014 "),aJ=a("a"),CEr=o("TFConvBertForMaskedLM"),wEr=o(" (ConvBERT model)"),AEr=l(),XM=a("li"),HTe=a("strong"),LEr=o("deberta"),yEr=o(" \u2014 "),nJ=a("a"),xEr=o("TFDebertaForMaskedLM"),$Er=o(" (DeBERTa model)"),kEr=l(),zM=a("li"),UTe=a("strong"),SEr=o("deberta-v2"),REr=o(" \u2014 "),sJ=a("a"),PEr=o("TFDebertaV2ForMaskedLM"),BEr=o(" (DeBERTa-v2 model)"),IEr=l(),QM=a("li"),JTe=a("strong"),NEr=o("distilbert"),qEr=o(" \u2014 "),lJ=a("a"),jEr=o("TFDistilBertForMaskedLM"),DEr=o(" (DistilBERT model)"),GEr=l(),WM=a("li"),YTe=a("strong"),OEr=o("electra"),VEr=o(" \u2014 "),iJ=a("a"),XEr=o("TFElectraForMaskedLM"),zEr=o(" (ELECTRA model)"),QEr=l(),HM=a("li"),KTe=a("strong"),WEr=o("flaubert"),HEr=o(" \u2014 "),dJ=a("a"),UEr=o("TFFlaubertWithLMHeadModel"),JEr=o(" (FlauBERT model)"),YEr=l(),UM=a("li"),ZTe=a("strong"),KEr=o("funnel"),ZEr=o(" \u2014 "),cJ=a("a"),e4r=o("TFFunnelForMaskedLM"),o4r=o(" (Funnel Transformer model)"),r4r=l(),JM=a("li"),e7e=a("strong"),t4r=o("layoutlm"),a4r=o(" \u2014 "),fJ=a("a"),n4r=o("TFLayoutLMForMaskedLM"),s4r=o(" (LayoutLM model)"),l4r=l(),YM=a("li"),o7e=a("strong"),i4r=o("longformer"),d4r=o(" \u2014 "),mJ=a("a"),c4r=o("TFLongformerForMaskedLM"),f4r=o(" (Longformer model)"),m4r=l(),KM=a("li"),r7e=a("strong"),g4r=o("mobilebert"),h4r=o(" \u2014 "),gJ=a("a"),p4r=o("TFMobileBertForMaskedLM"),_4r=o(" (MobileBERT model)"),u4r=l(),ZM=a("li"),t7e=a("strong"),b4r=o("mpnet"),v4r=o(" \u2014 "),hJ=a("a"),F4r=o("TFMPNetForMaskedLM"),T4r=o(" (MPNet model)"),M4r=l(),eE=a("li"),a7e=a("strong"),E4r=o("rembert"),C4r=o(" \u2014 "),pJ=a("a"),w4r=o("TFRemBertForMaskedLM"),A4r=o(" (RemBERT model)"),L4r=l(),oE=a("li"),n7e=a("strong"),y4r=o("roberta"),x4r=o(" \u2014 "),_J=a("a"),$4r=o("TFRobertaForMaskedLM"),k4r=o(" (RoBERTa model)"),S4r=l(),rE=a("li"),s7e=a("strong"),R4r=o("roformer"),P4r=o(" \u2014 "),uJ=a("a"),B4r=o("TFRoFormerForMaskedLM"),I4r=o(" (RoFormer model)"),N4r=l(),tE=a("li"),l7e=a("strong"),q4r=o("tapas"),j4r=o(" \u2014 "),bJ=a("a"),D4r=o("TFTapasForMaskedLM"),G4r=o(" (TAPAS model)"),O4r=l(),aE=a("li"),i7e=a("strong"),V4r=o("xlm"),X4r=o(" \u2014 "),vJ=a("a"),z4r=o("TFXLMWithLMHeadModel"),Q4r=o(" (XLM model)"),W4r=l(),nE=a("li"),d7e=a("strong"),H4r=o("xlm-roberta"),U4r=o(" \u2014 "),FJ=a("a"),J4r=o("TFXLMRobertaForMaskedLM"),Y4r=o(" (XLM-RoBERTa model)"),K4r=l(),F(sE.$$.fragment),hVe=l(),pc=a("h2"),lE=a("a"),c7e=a("span"),F(V9.$$.fragment),Z4r=l(),f7e=a("span"),eCr=o("TFAutoModelForSeq2SeqLM"),pVe=l(),nr=a("div"),F(X9.$$.fragment),oCr=l(),_c=a("p"),rCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),TJ=a("a"),tCr=o("from_pretrained()"),aCr=o(" class method or the "),MJ=a("a"),nCr=o("from_config()"),sCr=o(` class
method.`),lCr=l(),z9=a("p"),iCr=o("This class cannot be instantiated directly using "),m7e=a("code"),dCr=o("__init__()"),cCr=o(" (throws an error)."),fCr=l(),Bt=a("div"),F(Q9.$$.fragment),mCr=l(),g7e=a("p"),gCr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hCr=l(),uc=a("p"),pCr=o(`Note:
Loading a model from its configuration file does `),h7e=a("strong"),_Cr=o("not"),uCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=a("a"),bCr=o("from_pretrained()"),vCr=o(" to load the model weights."),FCr=l(),F(iE.$$.fragment),TCr=l(),Rr=a("div"),F(W9.$$.fragment),MCr=l(),p7e=a("p"),ECr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),CCr=l(),fn=a("p"),wCr=o("The model class to instantiate is selected based on the "),_7e=a("code"),ACr=o("model_type"),LCr=o(` property of the config object (either
passed as an argument or loaded from `),u7e=a("code"),yCr=o("pretrained_model_name_or_path"),xCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b7e=a("code"),$Cr=o("pretrained_model_name_or_path"),kCr=o(":"),SCr=l(),ye=a("ul"),dE=a("li"),v7e=a("strong"),RCr=o("bart"),PCr=o(" \u2014 "),CJ=a("a"),BCr=o("TFBartForConditionalGeneration"),ICr=o(" (BART model)"),NCr=l(),cE=a("li"),F7e=a("strong"),qCr=o("blenderbot"),jCr=o(" \u2014 "),wJ=a("a"),DCr=o("TFBlenderbotForConditionalGeneration"),GCr=o(" (Blenderbot model)"),OCr=l(),fE=a("li"),T7e=a("strong"),VCr=o("blenderbot-small"),XCr=o(" \u2014 "),AJ=a("a"),zCr=o("TFBlenderbotSmallForConditionalGeneration"),QCr=o(" (BlenderbotSmall model)"),WCr=l(),mE=a("li"),M7e=a("strong"),HCr=o("encoder-decoder"),UCr=o(" \u2014 "),LJ=a("a"),JCr=o("TFEncoderDecoderModel"),YCr=o(" (Encoder decoder model)"),KCr=l(),gE=a("li"),E7e=a("strong"),ZCr=o("led"),e5r=o(" \u2014 "),yJ=a("a"),o5r=o("TFLEDForConditionalGeneration"),r5r=o(" (LED model)"),t5r=l(),hE=a("li"),C7e=a("strong"),a5r=o("marian"),n5r=o(" \u2014 "),xJ=a("a"),s5r=o("TFMarianMTModel"),l5r=o(" (Marian model)"),i5r=l(),pE=a("li"),w7e=a("strong"),d5r=o("mbart"),c5r=o(" \u2014 "),$J=a("a"),f5r=o("TFMBartForConditionalGeneration"),m5r=o(" (mBART model)"),g5r=l(),_E=a("li"),A7e=a("strong"),h5r=o("mt5"),p5r=o(" \u2014 "),kJ=a("a"),_5r=o("TFMT5ForConditionalGeneration"),u5r=o(" (MT5 model)"),b5r=l(),uE=a("li"),L7e=a("strong"),v5r=o("pegasus"),F5r=o(" \u2014 "),SJ=a("a"),T5r=o("TFPegasusForConditionalGeneration"),M5r=o(" (Pegasus model)"),E5r=l(),bE=a("li"),y7e=a("strong"),C5r=o("t5"),w5r=o(" \u2014 "),RJ=a("a"),A5r=o("TFT5ForConditionalGeneration"),L5r=o(" (T5 model)"),y5r=l(),F(vE.$$.fragment),_Ve=l(),bc=a("h2"),FE=a("a"),x7e=a("span"),F(H9.$$.fragment),x5r=l(),$7e=a("span"),$5r=o("TFAutoModelForSequenceClassification"),uVe=l(),sr=a("div"),F(U9.$$.fragment),k5r=l(),vc=a("p"),S5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),PJ=a("a"),R5r=o("from_pretrained()"),P5r=o(" class method or the "),BJ=a("a"),B5r=o("from_config()"),I5r=o(` class
method.`),N5r=l(),J9=a("p"),q5r=o("This class cannot be instantiated directly using "),k7e=a("code"),j5r=o("__init__()"),D5r=o(" (throws an error)."),G5r=l(),It=a("div"),F(Y9.$$.fragment),O5r=l(),S7e=a("p"),V5r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),X5r=l(),Fc=a("p"),z5r=o(`Note:
Loading a model from its configuration file does `),R7e=a("strong"),Q5r=o("not"),W5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=a("a"),H5r=o("from_pretrained()"),U5r=o(" to load the model weights."),J5r=l(),F(TE.$$.fragment),Y5r=l(),Pr=a("div"),F(K9.$$.fragment),K5r=l(),P7e=a("p"),Z5r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),e3r=l(),mn=a("p"),o3r=o("The model class to instantiate is selected based on the "),B7e=a("code"),r3r=o("model_type"),t3r=o(` property of the config object (either
passed as an argument or loaded from `),I7e=a("code"),a3r=o("pretrained_model_name_or_path"),n3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N7e=a("code"),s3r=o("pretrained_model_name_or_path"),l3r=o(":"),i3r=l(),te=a("ul"),ME=a("li"),q7e=a("strong"),d3r=o("albert"),c3r=o(" \u2014 "),NJ=a("a"),f3r=o("TFAlbertForSequenceClassification"),m3r=o(" (ALBERT model)"),g3r=l(),EE=a("li"),j7e=a("strong"),h3r=o("bert"),p3r=o(" \u2014 "),qJ=a("a"),_3r=o("TFBertForSequenceClassification"),u3r=o(" (BERT model)"),b3r=l(),CE=a("li"),D7e=a("strong"),v3r=o("camembert"),F3r=o(" \u2014 "),jJ=a("a"),T3r=o("TFCamembertForSequenceClassification"),M3r=o(" (CamemBERT model)"),E3r=l(),wE=a("li"),G7e=a("strong"),C3r=o("convbert"),w3r=o(" \u2014 "),DJ=a("a"),A3r=o("TFConvBertForSequenceClassification"),L3r=o(" (ConvBERT model)"),y3r=l(),AE=a("li"),O7e=a("strong"),x3r=o("ctrl"),$3r=o(" \u2014 "),GJ=a("a"),k3r=o("TFCTRLForSequenceClassification"),S3r=o(" (CTRL model)"),R3r=l(),LE=a("li"),V7e=a("strong"),P3r=o("deberta"),B3r=o(" \u2014 "),OJ=a("a"),I3r=o("TFDebertaForSequenceClassification"),N3r=o(" (DeBERTa model)"),q3r=l(),yE=a("li"),X7e=a("strong"),j3r=o("deberta-v2"),D3r=o(" \u2014 "),VJ=a("a"),G3r=o("TFDebertaV2ForSequenceClassification"),O3r=o(" (DeBERTa-v2 model)"),V3r=l(),xE=a("li"),z7e=a("strong"),X3r=o("distilbert"),z3r=o(" \u2014 "),XJ=a("a"),Q3r=o("TFDistilBertForSequenceClassification"),W3r=o(" (DistilBERT model)"),H3r=l(),$E=a("li"),Q7e=a("strong"),U3r=o("electra"),J3r=o(" \u2014 "),zJ=a("a"),Y3r=o("TFElectraForSequenceClassification"),K3r=o(" (ELECTRA model)"),Z3r=l(),kE=a("li"),W7e=a("strong"),e0r=o("flaubert"),o0r=o(" \u2014 "),QJ=a("a"),r0r=o("TFFlaubertForSequenceClassification"),t0r=o(" (FlauBERT model)"),a0r=l(),SE=a("li"),H7e=a("strong"),n0r=o("funnel"),s0r=o(" \u2014 "),WJ=a("a"),l0r=o("TFFunnelForSequenceClassification"),i0r=o(" (Funnel Transformer model)"),d0r=l(),RE=a("li"),U7e=a("strong"),c0r=o("gpt2"),f0r=o(" \u2014 "),HJ=a("a"),m0r=o("TFGPT2ForSequenceClassification"),g0r=o(" (OpenAI GPT-2 model)"),h0r=l(),PE=a("li"),J7e=a("strong"),p0r=o("gptj"),_0r=o(" \u2014 "),UJ=a("a"),u0r=o("TFGPTJForSequenceClassification"),b0r=o(" (GPT-J model)"),v0r=l(),BE=a("li"),Y7e=a("strong"),F0r=o("layoutlm"),T0r=o(" \u2014 "),JJ=a("a"),M0r=o("TFLayoutLMForSequenceClassification"),E0r=o(" (LayoutLM model)"),C0r=l(),IE=a("li"),K7e=a("strong"),w0r=o("longformer"),A0r=o(" \u2014 "),YJ=a("a"),L0r=o("TFLongformerForSequenceClassification"),y0r=o(" (Longformer model)"),x0r=l(),NE=a("li"),Z7e=a("strong"),$0r=o("mobilebert"),k0r=o(" \u2014 "),KJ=a("a"),S0r=o("TFMobileBertForSequenceClassification"),R0r=o(" (MobileBERT model)"),P0r=l(),qE=a("li"),e8e=a("strong"),B0r=o("mpnet"),I0r=o(" \u2014 "),ZJ=a("a"),N0r=o("TFMPNetForSequenceClassification"),q0r=o(" (MPNet model)"),j0r=l(),jE=a("li"),o8e=a("strong"),D0r=o("openai-gpt"),G0r=o(" \u2014 "),eY=a("a"),O0r=o("TFOpenAIGPTForSequenceClassification"),V0r=o(" (OpenAI GPT model)"),X0r=l(),DE=a("li"),r8e=a("strong"),z0r=o("rembert"),Q0r=o(" \u2014 "),oY=a("a"),W0r=o("TFRemBertForSequenceClassification"),H0r=o(" (RemBERT model)"),U0r=l(),GE=a("li"),t8e=a("strong"),J0r=o("roberta"),Y0r=o(" \u2014 "),rY=a("a"),K0r=o("TFRobertaForSequenceClassification"),Z0r=o(" (RoBERTa model)"),ewr=l(),OE=a("li"),a8e=a("strong"),owr=o("roformer"),rwr=o(" \u2014 "),tY=a("a"),twr=o("TFRoFormerForSequenceClassification"),awr=o(" (RoFormer model)"),nwr=l(),VE=a("li"),n8e=a("strong"),swr=o("tapas"),lwr=o(" \u2014 "),aY=a("a"),iwr=o("TFTapasForSequenceClassification"),dwr=o(" (TAPAS model)"),cwr=l(),XE=a("li"),s8e=a("strong"),fwr=o("transfo-xl"),mwr=o(" \u2014 "),nY=a("a"),gwr=o("TFTransfoXLForSequenceClassification"),hwr=o(" (Transformer-XL model)"),pwr=l(),zE=a("li"),l8e=a("strong"),_wr=o("xlm"),uwr=o(" \u2014 "),sY=a("a"),bwr=o("TFXLMForSequenceClassification"),vwr=o(" (XLM model)"),Fwr=l(),QE=a("li"),i8e=a("strong"),Twr=o("xlm-roberta"),Mwr=o(" \u2014 "),lY=a("a"),Ewr=o("TFXLMRobertaForSequenceClassification"),Cwr=o(" (XLM-RoBERTa model)"),wwr=l(),WE=a("li"),d8e=a("strong"),Awr=o("xlnet"),Lwr=o(" \u2014 "),iY=a("a"),ywr=o("TFXLNetForSequenceClassification"),xwr=o(" (XLNet model)"),$wr=l(),F(HE.$$.fragment),bVe=l(),Tc=a("h2"),UE=a("a"),c8e=a("span"),F(Z9.$$.fragment),kwr=l(),f8e=a("span"),Swr=o("TFAutoModelForMultipleChoice"),vVe=l(),lr=a("div"),F(ex.$$.fragment),Rwr=l(),Mc=a("p"),Pwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),dY=a("a"),Bwr=o("from_pretrained()"),Iwr=o(" class method or the "),cY=a("a"),Nwr=o("from_config()"),qwr=o(` class
method.`),jwr=l(),ox=a("p"),Dwr=o("This class cannot be instantiated directly using "),m8e=a("code"),Gwr=o("__init__()"),Owr=o(" (throws an error)."),Vwr=l(),Nt=a("div"),F(rx.$$.fragment),Xwr=l(),g8e=a("p"),zwr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Qwr=l(),Ec=a("p"),Wwr=o(`Note:
Loading a model from its configuration file does `),h8e=a("strong"),Hwr=o("not"),Uwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fY=a("a"),Jwr=o("from_pretrained()"),Ywr=o(" to load the model weights."),Kwr=l(),F(JE.$$.fragment),Zwr=l(),Br=a("div"),F(tx.$$.fragment),eAr=l(),p8e=a("p"),oAr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),rAr=l(),gn=a("p"),tAr=o("The model class to instantiate is selected based on the "),_8e=a("code"),aAr=o("model_type"),nAr=o(` property of the config object (either
passed as an argument or loaded from `),u8e=a("code"),sAr=o("pretrained_model_name_or_path"),lAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b8e=a("code"),iAr=o("pretrained_model_name_or_path"),dAr=o(":"),cAr=l(),_e=a("ul"),YE=a("li"),v8e=a("strong"),fAr=o("albert"),mAr=o(" \u2014 "),mY=a("a"),gAr=o("TFAlbertForMultipleChoice"),hAr=o(" (ALBERT model)"),pAr=l(),KE=a("li"),F8e=a("strong"),_Ar=o("bert"),uAr=o(" \u2014 "),gY=a("a"),bAr=o("TFBertForMultipleChoice"),vAr=o(" (BERT model)"),FAr=l(),ZE=a("li"),T8e=a("strong"),TAr=o("camembert"),MAr=o(" \u2014 "),hY=a("a"),EAr=o("TFCamembertForMultipleChoice"),CAr=o(" (CamemBERT model)"),wAr=l(),e4=a("li"),M8e=a("strong"),AAr=o("convbert"),LAr=o(" \u2014 "),pY=a("a"),yAr=o("TFConvBertForMultipleChoice"),xAr=o(" (ConvBERT model)"),$Ar=l(),o4=a("li"),E8e=a("strong"),kAr=o("distilbert"),SAr=o(" \u2014 "),_Y=a("a"),RAr=o("TFDistilBertForMultipleChoice"),PAr=o(" (DistilBERT model)"),BAr=l(),r4=a("li"),C8e=a("strong"),IAr=o("electra"),NAr=o(" \u2014 "),uY=a("a"),qAr=o("TFElectraForMultipleChoice"),jAr=o(" (ELECTRA model)"),DAr=l(),t4=a("li"),w8e=a("strong"),GAr=o("flaubert"),OAr=o(" \u2014 "),bY=a("a"),VAr=o("TFFlaubertForMultipleChoice"),XAr=o(" (FlauBERT model)"),zAr=l(),a4=a("li"),A8e=a("strong"),QAr=o("funnel"),WAr=o(" \u2014 "),vY=a("a"),HAr=o("TFFunnelForMultipleChoice"),UAr=o(" (Funnel Transformer model)"),JAr=l(),n4=a("li"),L8e=a("strong"),YAr=o("longformer"),KAr=o(" \u2014 "),FY=a("a"),ZAr=o("TFLongformerForMultipleChoice"),eLr=o(" (Longformer model)"),oLr=l(),s4=a("li"),y8e=a("strong"),rLr=o("mobilebert"),tLr=o(" \u2014 "),TY=a("a"),aLr=o("TFMobileBertForMultipleChoice"),nLr=o(" (MobileBERT model)"),sLr=l(),l4=a("li"),x8e=a("strong"),lLr=o("mpnet"),iLr=o(" \u2014 "),MY=a("a"),dLr=o("TFMPNetForMultipleChoice"),cLr=o(" (MPNet model)"),fLr=l(),i4=a("li"),$8e=a("strong"),mLr=o("rembert"),gLr=o(" \u2014 "),EY=a("a"),hLr=o("TFRemBertForMultipleChoice"),pLr=o(" (RemBERT model)"),_Lr=l(),d4=a("li"),k8e=a("strong"),uLr=o("roberta"),bLr=o(" \u2014 "),CY=a("a"),vLr=o("TFRobertaForMultipleChoice"),FLr=o(" (RoBERTa model)"),TLr=l(),c4=a("li"),S8e=a("strong"),MLr=o("roformer"),ELr=o(" \u2014 "),wY=a("a"),CLr=o("TFRoFormerForMultipleChoice"),wLr=o(" (RoFormer model)"),ALr=l(),f4=a("li"),R8e=a("strong"),LLr=o("xlm"),yLr=o(" \u2014 "),AY=a("a"),xLr=o("TFXLMForMultipleChoice"),$Lr=o(" (XLM model)"),kLr=l(),m4=a("li"),P8e=a("strong"),SLr=o("xlm-roberta"),RLr=o(" \u2014 "),LY=a("a"),PLr=o("TFXLMRobertaForMultipleChoice"),BLr=o(" (XLM-RoBERTa model)"),ILr=l(),g4=a("li"),B8e=a("strong"),NLr=o("xlnet"),qLr=o(" \u2014 "),yY=a("a"),jLr=o("TFXLNetForMultipleChoice"),DLr=o(" (XLNet model)"),GLr=l(),F(h4.$$.fragment),FVe=l(),Cc=a("h2"),p4=a("a"),I8e=a("span"),F(ax.$$.fragment),OLr=l(),N8e=a("span"),VLr=o("TFAutoModelForNextSentencePrediction"),TVe=l(),ir=a("div"),F(nx.$$.fragment),XLr=l(),wc=a("p"),zLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),xY=a("a"),QLr=o("from_pretrained()"),WLr=o(" class method or the "),$Y=a("a"),HLr=o("from_config()"),ULr=o(` class
method.`),JLr=l(),sx=a("p"),YLr=o("This class cannot be instantiated directly using "),q8e=a("code"),KLr=o("__init__()"),ZLr=o(" (throws an error)."),eyr=l(),qt=a("div"),F(lx.$$.fragment),oyr=l(),j8e=a("p"),ryr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),tyr=l(),Ac=a("p"),ayr=o(`Note:
Loading a model from its configuration file does `),D8e=a("strong"),nyr=o("not"),syr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=a("a"),lyr=o("from_pretrained()"),iyr=o(" to load the model weights."),dyr=l(),F(_4.$$.fragment),cyr=l(),Ir=a("div"),F(ix.$$.fragment),fyr=l(),G8e=a("p"),myr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),gyr=l(),hn=a("p"),hyr=o("The model class to instantiate is selected based on the "),O8e=a("code"),pyr=o("model_type"),_yr=o(` property of the config object (either
passed as an argument or loaded from `),V8e=a("code"),uyr=o("pretrained_model_name_or_path"),byr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X8e=a("code"),vyr=o("pretrained_model_name_or_path"),Fyr=o(":"),Tyr=l(),dx=a("ul"),u4=a("li"),z8e=a("strong"),Myr=o("bert"),Eyr=o(" \u2014 "),SY=a("a"),Cyr=o("TFBertForNextSentencePrediction"),wyr=o(" (BERT model)"),Ayr=l(),b4=a("li"),Q8e=a("strong"),Lyr=o("mobilebert"),yyr=o(" \u2014 "),RY=a("a"),xyr=o("TFMobileBertForNextSentencePrediction"),$yr=o(" (MobileBERT model)"),kyr=l(),F(v4.$$.fragment),MVe=l(),Lc=a("h2"),F4=a("a"),W8e=a("span"),F(cx.$$.fragment),Syr=l(),H8e=a("span"),Ryr=o("TFAutoModelForTableQuestionAnswering"),EVe=l(),dr=a("div"),F(fx.$$.fragment),Pyr=l(),yc=a("p"),Byr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PY=a("a"),Iyr=o("from_pretrained()"),Nyr=o(" class method or the "),BY=a("a"),qyr=o("from_config()"),jyr=o(` class
method.`),Dyr=l(),mx=a("p"),Gyr=o("This class cannot be instantiated directly using "),U8e=a("code"),Oyr=o("__init__()"),Vyr=o(" (throws an error)."),Xyr=l(),jt=a("div"),F(gx.$$.fragment),zyr=l(),J8e=a("p"),Qyr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Wyr=l(),xc=a("p"),Hyr=o(`Note:
Loading a model from its configuration file does `),Y8e=a("strong"),Uyr=o("not"),Jyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),Yyr=o("from_pretrained()"),Kyr=o(" to load the model weights."),Zyr=l(),F(T4.$$.fragment),e9r=l(),Nr=a("div"),F(hx.$$.fragment),o9r=l(),K8e=a("p"),r9r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),t9r=l(),pn=a("p"),a9r=o("The model class to instantiate is selected based on the "),Z8e=a("code"),n9r=o("model_type"),s9r=o(` property of the config object (either
passed as an argument or loaded from `),eMe=a("code"),l9r=o("pretrained_model_name_or_path"),i9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oMe=a("code"),d9r=o("pretrained_model_name_or_path"),c9r=o(":"),f9r=l(),rMe=a("ul"),M4=a("li"),tMe=a("strong"),m9r=o("tapas"),g9r=o(" \u2014 "),NY=a("a"),h9r=o("TFTapasForQuestionAnswering"),p9r=o(" (TAPAS model)"),_9r=l(),F(E4.$$.fragment),CVe=l(),$c=a("h2"),C4=a("a"),aMe=a("span"),F(px.$$.fragment),u9r=l(),nMe=a("span"),b9r=o("TFAutoModelForTokenClassification"),wVe=l(),cr=a("div"),F(_x.$$.fragment),v9r=l(),kc=a("p"),F9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),qY=a("a"),T9r=o("from_pretrained()"),M9r=o(" class method or the "),jY=a("a"),E9r=o("from_config()"),C9r=o(` class
method.`),w9r=l(),ux=a("p"),A9r=o("This class cannot be instantiated directly using "),sMe=a("code"),L9r=o("__init__()"),y9r=o(" (throws an error)."),x9r=l(),Dt=a("div"),F(bx.$$.fragment),$9r=l(),lMe=a("p"),k9r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),S9r=l(),Sc=a("p"),R9r=o(`Note:
Loading a model from its configuration file does `),iMe=a("strong"),P9r=o("not"),B9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=a("a"),I9r=o("from_pretrained()"),N9r=o(" to load the model weights."),q9r=l(),F(w4.$$.fragment),j9r=l(),qr=a("div"),F(vx.$$.fragment),D9r=l(),dMe=a("p"),G9r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),O9r=l(),_n=a("p"),V9r=o("The model class to instantiate is selected based on the "),cMe=a("code"),X9r=o("model_type"),z9r=o(` property of the config object (either
passed as an argument or loaded from `),fMe=a("code"),Q9r=o("pretrained_model_name_or_path"),W9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mMe=a("code"),H9r=o("pretrained_model_name_or_path"),U9r=o(":"),J9r=l(),de=a("ul"),A4=a("li"),gMe=a("strong"),Y9r=o("albert"),K9r=o(" \u2014 "),GY=a("a"),Z9r=o("TFAlbertForTokenClassification"),exr=o(" (ALBERT model)"),oxr=l(),L4=a("li"),hMe=a("strong"),rxr=o("bert"),txr=o(" \u2014 "),OY=a("a"),axr=o("TFBertForTokenClassification"),nxr=o(" (BERT model)"),sxr=l(),y4=a("li"),pMe=a("strong"),lxr=o("camembert"),ixr=o(" \u2014 "),VY=a("a"),dxr=o("TFCamembertForTokenClassification"),cxr=o(" (CamemBERT model)"),fxr=l(),x4=a("li"),_Me=a("strong"),mxr=o("convbert"),gxr=o(" \u2014 "),XY=a("a"),hxr=o("TFConvBertForTokenClassification"),pxr=o(" (ConvBERT model)"),_xr=l(),$4=a("li"),uMe=a("strong"),uxr=o("deberta"),bxr=o(" \u2014 "),zY=a("a"),vxr=o("TFDebertaForTokenClassification"),Fxr=o(" (DeBERTa model)"),Txr=l(),k4=a("li"),bMe=a("strong"),Mxr=o("deberta-v2"),Exr=o(" \u2014 "),QY=a("a"),Cxr=o("TFDebertaV2ForTokenClassification"),wxr=o(" (DeBERTa-v2 model)"),Axr=l(),S4=a("li"),vMe=a("strong"),Lxr=o("distilbert"),yxr=o(" \u2014 "),WY=a("a"),xxr=o("TFDistilBertForTokenClassification"),$xr=o(" (DistilBERT model)"),kxr=l(),R4=a("li"),FMe=a("strong"),Sxr=o("electra"),Rxr=o(" \u2014 "),HY=a("a"),Pxr=o("TFElectraForTokenClassification"),Bxr=o(" (ELECTRA model)"),Ixr=l(),P4=a("li"),TMe=a("strong"),Nxr=o("flaubert"),qxr=o(" \u2014 "),UY=a("a"),jxr=o("TFFlaubertForTokenClassification"),Dxr=o(" (FlauBERT model)"),Gxr=l(),B4=a("li"),MMe=a("strong"),Oxr=o("funnel"),Vxr=o(" \u2014 "),JY=a("a"),Xxr=o("TFFunnelForTokenClassification"),zxr=o(" (Funnel Transformer model)"),Qxr=l(),I4=a("li"),EMe=a("strong"),Wxr=o("layoutlm"),Hxr=o(" \u2014 "),YY=a("a"),Uxr=o("TFLayoutLMForTokenClassification"),Jxr=o(" (LayoutLM model)"),Yxr=l(),N4=a("li"),CMe=a("strong"),Kxr=o("longformer"),Zxr=o(" \u2014 "),KY=a("a"),e$r=o("TFLongformerForTokenClassification"),o$r=o(" (Longformer model)"),r$r=l(),q4=a("li"),wMe=a("strong"),t$r=o("mobilebert"),a$r=o(" \u2014 "),ZY=a("a"),n$r=o("TFMobileBertForTokenClassification"),s$r=o(" (MobileBERT model)"),l$r=l(),j4=a("li"),AMe=a("strong"),i$r=o("mpnet"),d$r=o(" \u2014 "),eK=a("a"),c$r=o("TFMPNetForTokenClassification"),f$r=o(" (MPNet model)"),m$r=l(),D4=a("li"),LMe=a("strong"),g$r=o("rembert"),h$r=o(" \u2014 "),oK=a("a"),p$r=o("TFRemBertForTokenClassification"),_$r=o(" (RemBERT model)"),u$r=l(),G4=a("li"),yMe=a("strong"),b$r=o("roberta"),v$r=o(" \u2014 "),rK=a("a"),F$r=o("TFRobertaForTokenClassification"),T$r=o(" (RoBERTa model)"),M$r=l(),O4=a("li"),xMe=a("strong"),E$r=o("roformer"),C$r=o(" \u2014 "),tK=a("a"),w$r=o("TFRoFormerForTokenClassification"),A$r=o(" (RoFormer model)"),L$r=l(),V4=a("li"),$Me=a("strong"),y$r=o("xlm"),x$r=o(" \u2014 "),aK=a("a"),$$r=o("TFXLMForTokenClassification"),k$r=o(" (XLM model)"),S$r=l(),X4=a("li"),kMe=a("strong"),R$r=o("xlm-roberta"),P$r=o(" \u2014 "),nK=a("a"),B$r=o("TFXLMRobertaForTokenClassification"),I$r=o(" (XLM-RoBERTa model)"),N$r=l(),z4=a("li"),SMe=a("strong"),q$r=o("xlnet"),j$r=o(" \u2014 "),sK=a("a"),D$r=o("TFXLNetForTokenClassification"),G$r=o(" (XLNet model)"),O$r=l(),F(Q4.$$.fragment),AVe=l(),Rc=a("h2"),W4=a("a"),RMe=a("span"),F(Fx.$$.fragment),V$r=l(),PMe=a("span"),X$r=o("TFAutoModelForQuestionAnswering"),LVe=l(),fr=a("div"),F(Tx.$$.fragment),z$r=l(),Pc=a("p"),Q$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),lK=a("a"),W$r=o("from_pretrained()"),H$r=o(" class method or the "),iK=a("a"),U$r=o("from_config()"),J$r=o(` class
method.`),Y$r=l(),Mx=a("p"),K$r=o("This class cannot be instantiated directly using "),BMe=a("code"),Z$r=o("__init__()"),ekr=o(" (throws an error)."),okr=l(),Gt=a("div"),F(Ex.$$.fragment),rkr=l(),IMe=a("p"),tkr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),akr=l(),Bc=a("p"),nkr=o(`Note:
Loading a model from its configuration file does `),NMe=a("strong"),skr=o("not"),lkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dK=a("a"),ikr=o("from_pretrained()"),dkr=o(" to load the model weights."),ckr=l(),F(H4.$$.fragment),fkr=l(),jr=a("div"),F(Cx.$$.fragment),mkr=l(),qMe=a("p"),gkr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),hkr=l(),un=a("p"),pkr=o("The model class to instantiate is selected based on the "),jMe=a("code"),_kr=o("model_type"),ukr=o(` property of the config object (either
passed as an argument or loaded from `),DMe=a("code"),bkr=o("pretrained_model_name_or_path"),vkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GMe=a("code"),Fkr=o("pretrained_model_name_or_path"),Tkr=o(":"),Mkr=l(),ce=a("ul"),U4=a("li"),OMe=a("strong"),Ekr=o("albert"),Ckr=o(" \u2014 "),cK=a("a"),wkr=o("TFAlbertForQuestionAnswering"),Akr=o(" (ALBERT model)"),Lkr=l(),J4=a("li"),VMe=a("strong"),ykr=o("bert"),xkr=o(" \u2014 "),fK=a("a"),$kr=o("TFBertForQuestionAnswering"),kkr=o(" (BERT model)"),Skr=l(),Y4=a("li"),XMe=a("strong"),Rkr=o("camembert"),Pkr=o(" \u2014 "),mK=a("a"),Bkr=o("TFCamembertForQuestionAnswering"),Ikr=o(" (CamemBERT model)"),Nkr=l(),K4=a("li"),zMe=a("strong"),qkr=o("convbert"),jkr=o(" \u2014 "),gK=a("a"),Dkr=o("TFConvBertForQuestionAnswering"),Gkr=o(" (ConvBERT model)"),Okr=l(),Z4=a("li"),QMe=a("strong"),Vkr=o("deberta"),Xkr=o(" \u2014 "),hK=a("a"),zkr=o("TFDebertaForQuestionAnswering"),Qkr=o(" (DeBERTa model)"),Wkr=l(),eC=a("li"),WMe=a("strong"),Hkr=o("deberta-v2"),Ukr=o(" \u2014 "),pK=a("a"),Jkr=o("TFDebertaV2ForQuestionAnswering"),Ykr=o(" (DeBERTa-v2 model)"),Kkr=l(),oC=a("li"),HMe=a("strong"),Zkr=o("distilbert"),eSr=o(" \u2014 "),_K=a("a"),oSr=o("TFDistilBertForQuestionAnswering"),rSr=o(" (DistilBERT model)"),tSr=l(),rC=a("li"),UMe=a("strong"),aSr=o("electra"),nSr=o(" \u2014 "),uK=a("a"),sSr=o("TFElectraForQuestionAnswering"),lSr=o(" (ELECTRA model)"),iSr=l(),tC=a("li"),JMe=a("strong"),dSr=o("flaubert"),cSr=o(" \u2014 "),bK=a("a"),fSr=o("TFFlaubertForQuestionAnsweringSimple"),mSr=o(" (FlauBERT model)"),gSr=l(),aC=a("li"),YMe=a("strong"),hSr=o("funnel"),pSr=o(" \u2014 "),vK=a("a"),_Sr=o("TFFunnelForQuestionAnswering"),uSr=o(" (Funnel Transformer model)"),bSr=l(),nC=a("li"),KMe=a("strong"),vSr=o("gptj"),FSr=o(" \u2014 "),FK=a("a"),TSr=o("TFGPTJForQuestionAnswering"),MSr=o(" (GPT-J model)"),ESr=l(),sC=a("li"),ZMe=a("strong"),CSr=o("longformer"),wSr=o(" \u2014 "),TK=a("a"),ASr=o("TFLongformerForQuestionAnswering"),LSr=o(" (Longformer model)"),ySr=l(),lC=a("li"),eEe=a("strong"),xSr=o("mobilebert"),$Sr=o(" \u2014 "),MK=a("a"),kSr=o("TFMobileBertForQuestionAnswering"),SSr=o(" (MobileBERT model)"),RSr=l(),iC=a("li"),oEe=a("strong"),PSr=o("mpnet"),BSr=o(" \u2014 "),EK=a("a"),ISr=o("TFMPNetForQuestionAnswering"),NSr=o(" (MPNet model)"),qSr=l(),dC=a("li"),rEe=a("strong"),jSr=o("rembert"),DSr=o(" \u2014 "),CK=a("a"),GSr=o("TFRemBertForQuestionAnswering"),OSr=o(" (RemBERT model)"),VSr=l(),cC=a("li"),tEe=a("strong"),XSr=o("roberta"),zSr=o(" \u2014 "),wK=a("a"),QSr=o("TFRobertaForQuestionAnswering"),WSr=o(" (RoBERTa model)"),HSr=l(),fC=a("li"),aEe=a("strong"),USr=o("roformer"),JSr=o(" \u2014 "),AK=a("a"),YSr=o("TFRoFormerForQuestionAnswering"),KSr=o(" (RoFormer model)"),ZSr=l(),mC=a("li"),nEe=a("strong"),eRr=o("xlm"),oRr=o(" \u2014 "),LK=a("a"),rRr=o("TFXLMForQuestionAnsweringSimple"),tRr=o(" (XLM model)"),aRr=l(),gC=a("li"),sEe=a("strong"),nRr=o("xlm-roberta"),sRr=o(" \u2014 "),yK=a("a"),lRr=o("TFXLMRobertaForQuestionAnswering"),iRr=o(" (XLM-RoBERTa model)"),dRr=l(),hC=a("li"),lEe=a("strong"),cRr=o("xlnet"),fRr=o(" \u2014 "),xK=a("a"),mRr=o("TFXLNetForQuestionAnsweringSimple"),gRr=o(" (XLNet model)"),hRr=l(),F(pC.$$.fragment),yVe=l(),Ic=a("h2"),_C=a("a"),iEe=a("span"),F(wx.$$.fragment),pRr=l(),dEe=a("span"),_Rr=o("TFAutoModelForVision2Seq"),xVe=l(),mr=a("div"),F(Ax.$$.fragment),uRr=l(),Nc=a("p"),bRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$K=a("a"),vRr=o("from_pretrained()"),FRr=o(" class method or the "),kK=a("a"),TRr=o("from_config()"),MRr=o(` class
method.`),ERr=l(),Lx=a("p"),CRr=o("This class cannot be instantiated directly using "),cEe=a("code"),wRr=o("__init__()"),ARr=o(" (throws an error)."),LRr=l(),Ot=a("div"),F(yx.$$.fragment),yRr=l(),fEe=a("p"),xRr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),$Rr=l(),qc=a("p"),kRr=o(`Note:
Loading a model from its configuration file does `),mEe=a("strong"),SRr=o("not"),RRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),PRr=o("from_pretrained()"),BRr=o(" to load the model weights."),IRr=l(),F(uC.$$.fragment),NRr=l(),Dr=a("div"),F(xx.$$.fragment),qRr=l(),gEe=a("p"),jRr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),DRr=l(),bn=a("p"),GRr=o("The model class to instantiate is selected based on the "),hEe=a("code"),ORr=o("model_type"),VRr=o(` property of the config object (either
passed as an argument or loaded from `),pEe=a("code"),XRr=o("pretrained_model_name_or_path"),zRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ee=a("code"),QRr=o("pretrained_model_name_or_path"),WRr=o(":"),HRr=l(),uEe=a("ul"),bC=a("li"),bEe=a("strong"),URr=o("vision-encoder-decoder"),JRr=o(" \u2014 "),RK=a("a"),YRr=o("TFVisionEncoderDecoderModel"),KRr=o(" (Vision Encoder decoder model)"),ZRr=l(),F(vC.$$.fragment),$Ve=l(),jc=a("h2"),FC=a("a"),vEe=a("span"),F($x.$$.fragment),ePr=l(),FEe=a("span"),oPr=o("TFAutoModelForSpeechSeq2Seq"),kVe=l(),gr=a("div"),F(kx.$$.fragment),rPr=l(),Dc=a("p"),tPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),PK=a("a"),aPr=o("from_pretrained()"),nPr=o(" class method or the "),BK=a("a"),sPr=o("from_config()"),lPr=o(` class
method.`),iPr=l(),Sx=a("p"),dPr=o("This class cannot be instantiated directly using "),TEe=a("code"),cPr=o("__init__()"),fPr=o(" (throws an error)."),mPr=l(),Vt=a("div"),F(Rx.$$.fragment),gPr=l(),MEe=a("p"),hPr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),pPr=l(),Gc=a("p"),_Pr=o(`Note:
Loading a model from its configuration file does `),EEe=a("strong"),uPr=o("not"),bPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),vPr=o("from_pretrained()"),FPr=o(" to load the model weights."),TPr=l(),F(TC.$$.fragment),MPr=l(),Gr=a("div"),F(Px.$$.fragment),EPr=l(),CEe=a("p"),CPr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),wPr=l(),vn=a("p"),APr=o("The model class to instantiate is selected based on the "),wEe=a("code"),LPr=o("model_type"),yPr=o(` property of the config object (either
passed as an argument or loaded from `),AEe=a("code"),xPr=o("pretrained_model_name_or_path"),$Pr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=a("code"),kPr=o("pretrained_model_name_or_path"),SPr=o(":"),RPr=l(),yEe=a("ul"),MC=a("li"),xEe=a("strong"),PPr=o("speech_to_text"),BPr=o(" \u2014 "),NK=a("a"),IPr=o("TFSpeech2TextForConditionalGeneration"),NPr=o(" (Speech2Text model)"),qPr=l(),F(EC.$$.fragment),SVe=l(),Oc=a("h2"),CC=a("a"),$Ee=a("span"),F(Bx.$$.fragment),jPr=l(),kEe=a("span"),DPr=o("FlaxAutoModel"),RVe=l(),hr=a("div"),F(Ix.$$.fragment),GPr=l(),Vc=a("p"),OPr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),qK=a("a"),VPr=o("from_pretrained()"),XPr=o(" class method or the "),jK=a("a"),zPr=o("from_config()"),QPr=o(` class
method.`),WPr=l(),Nx=a("p"),HPr=o("This class cannot be instantiated directly using "),SEe=a("code"),UPr=o("__init__()"),JPr=o(" (throws an error)."),YPr=l(),Xt=a("div"),F(qx.$$.fragment),KPr=l(),REe=a("p"),ZPr=o("Instantiates one of the base model classes of the library from a configuration."),eBr=l(),Xc=a("p"),oBr=o(`Note:
Loading a model from its configuration file does `),PEe=a("strong"),rBr=o("not"),tBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=a("a"),aBr=o("from_pretrained()"),nBr=o(" to load the model weights."),sBr=l(),F(wC.$$.fragment),lBr=l(),Or=a("div"),F(jx.$$.fragment),iBr=l(),BEe=a("p"),dBr=o("Instantiate one of the base model classes of the library from a pretrained model."),cBr=l(),Fn=a("p"),fBr=o("The model class to instantiate is selected based on the "),IEe=a("code"),mBr=o("model_type"),gBr=o(` property of the config object (either
passed as an argument or loaded from `),NEe=a("code"),hBr=o("pretrained_model_name_or_path"),pBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qEe=a("code"),_Br=o("pretrained_model_name_or_path"),uBr=o(":"),bBr=l(),oe=a("ul"),AC=a("li"),jEe=a("strong"),vBr=o("albert"),FBr=o(" \u2014 "),GK=a("a"),TBr=o("FlaxAlbertModel"),MBr=o(" (ALBERT model)"),EBr=l(),LC=a("li"),DEe=a("strong"),CBr=o("bart"),wBr=o(" \u2014 "),OK=a("a"),ABr=o("FlaxBartModel"),LBr=o(" (BART model)"),yBr=l(),yC=a("li"),GEe=a("strong"),xBr=o("beit"),$Br=o(" \u2014 "),VK=a("a"),kBr=o("FlaxBeitModel"),SBr=o(" (BEiT model)"),RBr=l(),xC=a("li"),OEe=a("strong"),PBr=o("bert"),BBr=o(" \u2014 "),XK=a("a"),IBr=o("FlaxBertModel"),NBr=o(" (BERT model)"),qBr=l(),$C=a("li"),VEe=a("strong"),jBr=o("big_bird"),DBr=o(" \u2014 "),zK=a("a"),GBr=o("FlaxBigBirdModel"),OBr=o(" (BigBird model)"),VBr=l(),kC=a("li"),XEe=a("strong"),XBr=o("blenderbot"),zBr=o(" \u2014 "),QK=a("a"),QBr=o("FlaxBlenderbotModel"),WBr=o(" (Blenderbot model)"),HBr=l(),SC=a("li"),zEe=a("strong"),UBr=o("blenderbot-small"),JBr=o(" \u2014 "),WK=a("a"),YBr=o("FlaxBlenderbotSmallModel"),KBr=o(" (BlenderbotSmall model)"),ZBr=l(),RC=a("li"),QEe=a("strong"),eIr=o("clip"),oIr=o(" \u2014 "),HK=a("a"),rIr=o("FlaxCLIPModel"),tIr=o(" (CLIP model)"),aIr=l(),PC=a("li"),WEe=a("strong"),nIr=o("distilbert"),sIr=o(" \u2014 "),UK=a("a"),lIr=o("FlaxDistilBertModel"),iIr=o(" (DistilBERT model)"),dIr=l(),BC=a("li"),HEe=a("strong"),cIr=o("electra"),fIr=o(" \u2014 "),JK=a("a"),mIr=o("FlaxElectraModel"),gIr=o(" (ELECTRA model)"),hIr=l(),IC=a("li"),UEe=a("strong"),pIr=o("gpt2"),_Ir=o(" \u2014 "),YK=a("a"),uIr=o("FlaxGPT2Model"),bIr=o(" (OpenAI GPT-2 model)"),vIr=l(),NC=a("li"),JEe=a("strong"),FIr=o("gpt_neo"),TIr=o(" \u2014 "),KK=a("a"),MIr=o("FlaxGPTNeoModel"),EIr=o(" (GPT Neo model)"),CIr=l(),qC=a("li"),YEe=a("strong"),wIr=o("gptj"),AIr=o(" \u2014 "),ZK=a("a"),LIr=o("FlaxGPTJModel"),yIr=o(" (GPT-J model)"),xIr=l(),jC=a("li"),KEe=a("strong"),$Ir=o("longt5"),kIr=o(" \u2014 "),eZ=a("a"),SIr=o("FlaxLongT5Model"),RIr=o(" (LongT5 model)"),PIr=l(),DC=a("li"),ZEe=a("strong"),BIr=o("marian"),IIr=o(" \u2014 "),oZ=a("a"),NIr=o("FlaxMarianModel"),qIr=o(" (Marian model)"),jIr=l(),GC=a("li"),e4e=a("strong"),DIr=o("mbart"),GIr=o(" \u2014 "),rZ=a("a"),OIr=o("FlaxMBartModel"),VIr=o(" (mBART model)"),XIr=l(),OC=a("li"),o4e=a("strong"),zIr=o("mt5"),QIr=o(" \u2014 "),tZ=a("a"),WIr=o("FlaxMT5Model"),HIr=o(" (MT5 model)"),UIr=l(),VC=a("li"),r4e=a("strong"),JIr=o("opt"),YIr=o(" \u2014 "),aZ=a("a"),KIr=o("FlaxOPTModel"),ZIr=o(" (OPT model)"),eNr=l(),XC=a("li"),t4e=a("strong"),oNr=o("pegasus"),rNr=o(" \u2014 "),nZ=a("a"),tNr=o("FlaxPegasusModel"),aNr=o(" (Pegasus model)"),nNr=l(),zC=a("li"),a4e=a("strong"),sNr=o("roberta"),lNr=o(" \u2014 "),sZ=a("a"),iNr=o("FlaxRobertaModel"),dNr=o(" (RoBERTa model)"),cNr=l(),QC=a("li"),n4e=a("strong"),fNr=o("roformer"),mNr=o(" \u2014 "),lZ=a("a"),gNr=o("FlaxRoFormerModel"),hNr=o(" (RoFormer model)"),pNr=l(),WC=a("li"),s4e=a("strong"),_Nr=o("t5"),uNr=o(" \u2014 "),iZ=a("a"),bNr=o("FlaxT5Model"),vNr=o(" (T5 model)"),FNr=l(),HC=a("li"),l4e=a("strong"),TNr=o("vision-text-dual-encoder"),MNr=o(" \u2014 "),dZ=a("a"),ENr=o("FlaxVisionTextDualEncoderModel"),CNr=o(" (VisionTextDualEncoder model)"),wNr=l(),UC=a("li"),i4e=a("strong"),ANr=o("vit"),LNr=o(" \u2014 "),cZ=a("a"),yNr=o("FlaxViTModel"),xNr=o(" (ViT model)"),$Nr=l(),JC=a("li"),d4e=a("strong"),kNr=o("wav2vec2"),SNr=o(" \u2014 "),fZ=a("a"),RNr=o("FlaxWav2Vec2Model"),PNr=o(" (Wav2Vec2 model)"),BNr=l(),YC=a("li"),c4e=a("strong"),INr=o("xglm"),NNr=o(" \u2014 "),mZ=a("a"),qNr=o("FlaxXGLMModel"),jNr=o(" (XGLM model)"),DNr=l(),KC=a("li"),f4e=a("strong"),GNr=o("xlm-roberta"),ONr=o(" \u2014 "),gZ=a("a"),VNr=o("FlaxXLMRobertaModel"),XNr=o(" (XLM-RoBERTa model)"),zNr=l(),F(ZC.$$.fragment),PVe=l(),zc=a("h2"),e5=a("a"),m4e=a("span"),F(Dx.$$.fragment),QNr=l(),g4e=a("span"),WNr=o("FlaxAutoModelForCausalLM"),BVe=l(),pr=a("div"),F(Gx.$$.fragment),HNr=l(),Qc=a("p"),UNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hZ=a("a"),JNr=o("from_pretrained()"),YNr=o(" class method or the "),pZ=a("a"),KNr=o("from_config()"),ZNr=o(` class
method.`),eqr=l(),Ox=a("p"),oqr=o("This class cannot be instantiated directly using "),h4e=a("code"),rqr=o("__init__()"),tqr=o(" (throws an error)."),aqr=l(),zt=a("div"),F(Vx.$$.fragment),nqr=l(),p4e=a("p"),sqr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lqr=l(),Wc=a("p"),iqr=o(`Note:
Loading a model from its configuration file does `),_4e=a("strong"),dqr=o("not"),cqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=a("a"),fqr=o("from_pretrained()"),mqr=o(" to load the model weights."),gqr=l(),F(o5.$$.fragment),hqr=l(),Vr=a("div"),F(Xx.$$.fragment),pqr=l(),u4e=a("p"),_qr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uqr=l(),Tn=a("p"),bqr=o("The model class to instantiate is selected based on the "),b4e=a("code"),vqr=o("model_type"),Fqr=o(` property of the config object (either
passed as an argument or loaded from `),v4e=a("code"),Tqr=o("pretrained_model_name_or_path"),Mqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F4e=a("code"),Eqr=o("pretrained_model_name_or_path"),Cqr=o(":"),wqr=l(),xe=a("ul"),r5=a("li"),T4e=a("strong"),Aqr=o("bart"),Lqr=o(" \u2014 "),uZ=a("a"),yqr=o("FlaxBartForCausalLM"),xqr=o(" (BART model)"),$qr=l(),t5=a("li"),M4e=a("strong"),kqr=o("bert"),Sqr=o(" \u2014 "),bZ=a("a"),Rqr=o("FlaxBertForCausalLM"),Pqr=o(" (BERT model)"),Bqr=l(),a5=a("li"),E4e=a("strong"),Iqr=o("big_bird"),Nqr=o(" \u2014 "),vZ=a("a"),qqr=o("FlaxBigBirdForCausalLM"),jqr=o(" (BigBird model)"),Dqr=l(),n5=a("li"),C4e=a("strong"),Gqr=o("electra"),Oqr=o(" \u2014 "),FZ=a("a"),Vqr=o("FlaxElectraForCausalLM"),Xqr=o(" (ELECTRA model)"),zqr=l(),s5=a("li"),w4e=a("strong"),Qqr=o("gpt2"),Wqr=o(" \u2014 "),TZ=a("a"),Hqr=o("FlaxGPT2LMHeadModel"),Uqr=o(" (OpenAI GPT-2 model)"),Jqr=l(),l5=a("li"),A4e=a("strong"),Yqr=o("gpt_neo"),Kqr=o(" \u2014 "),MZ=a("a"),Zqr=o("FlaxGPTNeoForCausalLM"),ejr=o(" (GPT Neo model)"),ojr=l(),i5=a("li"),L4e=a("strong"),rjr=o("gptj"),tjr=o(" \u2014 "),EZ=a("a"),ajr=o("FlaxGPTJForCausalLM"),njr=o(" (GPT-J model)"),sjr=l(),d5=a("li"),y4e=a("strong"),ljr=o("opt"),ijr=o(" \u2014 "),CZ=a("a"),djr=o("FlaxOPTForCausalLM"),cjr=o(" (OPT model)"),fjr=l(),c5=a("li"),x4e=a("strong"),mjr=o("roberta"),gjr=o(" \u2014 "),wZ=a("a"),hjr=o("FlaxRobertaForCausalLM"),pjr=o(" (RoBERTa model)"),_jr=l(),f5=a("li"),$4e=a("strong"),ujr=o("xglm"),bjr=o(" \u2014 "),AZ=a("a"),vjr=o("FlaxXGLMForCausalLM"),Fjr=o(" (XGLM model)"),Tjr=l(),F(m5.$$.fragment),IVe=l(),Hc=a("h2"),g5=a("a"),k4e=a("span"),F(zx.$$.fragment),Mjr=l(),S4e=a("span"),Ejr=o("FlaxAutoModelForPreTraining"),NVe=l(),_r=a("div"),F(Qx.$$.fragment),Cjr=l(),Uc=a("p"),wjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),LZ=a("a"),Ajr=o("from_pretrained()"),Ljr=o(" class method or the "),yZ=a("a"),yjr=o("from_config()"),xjr=o(` class
method.`),$jr=l(),Wx=a("p"),kjr=o("This class cannot be instantiated directly using "),R4e=a("code"),Sjr=o("__init__()"),Rjr=o(" (throws an error)."),Pjr=l(),Qt=a("div"),F(Hx.$$.fragment),Bjr=l(),P4e=a("p"),Ijr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Njr=l(),Jc=a("p"),qjr=o(`Note:
Loading a model from its configuration file does `),B4e=a("strong"),jjr=o("not"),Djr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xZ=a("a"),Gjr=o("from_pretrained()"),Ojr=o(" to load the model weights."),Vjr=l(),F(h5.$$.fragment),Xjr=l(),Xr=a("div"),F(Ux.$$.fragment),zjr=l(),I4e=a("p"),Qjr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Wjr=l(),Mn=a("p"),Hjr=o("The model class to instantiate is selected based on the "),N4e=a("code"),Ujr=o("model_type"),Jjr=o(` property of the config object (either
passed as an argument or loaded from `),q4e=a("code"),Yjr=o("pretrained_model_name_or_path"),Kjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j4e=a("code"),Zjr=o("pretrained_model_name_or_path"),eDr=o(":"),oDr=l(),Ee=a("ul"),p5=a("li"),D4e=a("strong"),rDr=o("albert"),tDr=o(" \u2014 "),$Z=a("a"),aDr=o("FlaxAlbertForPreTraining"),nDr=o(" (ALBERT model)"),sDr=l(),_5=a("li"),G4e=a("strong"),lDr=o("bart"),iDr=o(" \u2014 "),kZ=a("a"),dDr=o("FlaxBartForConditionalGeneration"),cDr=o(" (BART model)"),fDr=l(),u5=a("li"),O4e=a("strong"),mDr=o("bert"),gDr=o(" \u2014 "),SZ=a("a"),hDr=o("FlaxBertForPreTraining"),pDr=o(" (BERT model)"),_Dr=l(),b5=a("li"),V4e=a("strong"),uDr=o("big_bird"),bDr=o(" \u2014 "),RZ=a("a"),vDr=o("FlaxBigBirdForPreTraining"),FDr=o(" (BigBird model)"),TDr=l(),v5=a("li"),X4e=a("strong"),MDr=o("electra"),EDr=o(" \u2014 "),PZ=a("a"),CDr=o("FlaxElectraForPreTraining"),wDr=o(" (ELECTRA model)"),ADr=l(),F5=a("li"),z4e=a("strong"),LDr=o("longt5"),yDr=o(" \u2014 "),BZ=a("a"),xDr=o("FlaxLongT5ForConditionalGeneration"),$Dr=o(" (LongT5 model)"),kDr=l(),T5=a("li"),Q4e=a("strong"),SDr=o("mbart"),RDr=o(" \u2014 "),IZ=a("a"),PDr=o("FlaxMBartForConditionalGeneration"),BDr=o(" (mBART model)"),IDr=l(),M5=a("li"),W4e=a("strong"),NDr=o("mt5"),qDr=o(" \u2014 "),NZ=a("a"),jDr=o("FlaxMT5ForConditionalGeneration"),DDr=o(" (MT5 model)"),GDr=l(),E5=a("li"),H4e=a("strong"),ODr=o("roberta"),VDr=o(" \u2014 "),qZ=a("a"),XDr=o("FlaxRobertaForMaskedLM"),zDr=o(" (RoBERTa model)"),QDr=l(),C5=a("li"),U4e=a("strong"),WDr=o("roformer"),HDr=o(" \u2014 "),jZ=a("a"),UDr=o("FlaxRoFormerForMaskedLM"),JDr=o(" (RoFormer model)"),YDr=l(),w5=a("li"),J4e=a("strong"),KDr=o("t5"),ZDr=o(" \u2014 "),DZ=a("a"),eGr=o("FlaxT5ForConditionalGeneration"),oGr=o(" (T5 model)"),rGr=l(),A5=a("li"),Y4e=a("strong"),tGr=o("wav2vec2"),aGr=o(" \u2014 "),GZ=a("a"),nGr=o("FlaxWav2Vec2ForPreTraining"),sGr=o(" (Wav2Vec2 model)"),lGr=l(),L5=a("li"),K4e=a("strong"),iGr=o("xlm-roberta"),dGr=o(" \u2014 "),OZ=a("a"),cGr=o("FlaxXLMRobertaForMaskedLM"),fGr=o(" (XLM-RoBERTa model)"),mGr=l(),F(y5.$$.fragment),qVe=l(),Yc=a("h2"),x5=a("a"),Z4e=a("span"),F(Jx.$$.fragment),gGr=l(),eCe=a("span"),hGr=o("FlaxAutoModelForMaskedLM"),jVe=l(),ur=a("div"),F(Yx.$$.fragment),pGr=l(),Kc=a("p"),_Gr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),VZ=a("a"),uGr=o("from_pretrained()"),bGr=o(" class method or the "),XZ=a("a"),vGr=o("from_config()"),FGr=o(` class
method.`),TGr=l(),Kx=a("p"),MGr=o("This class cannot be instantiated directly using "),oCe=a("code"),EGr=o("__init__()"),CGr=o(" (throws an error)."),wGr=l(),Wt=a("div"),F(Zx.$$.fragment),AGr=l(),rCe=a("p"),LGr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),yGr=l(),Zc=a("p"),xGr=o(`Note:
Loading a model from its configuration file does `),tCe=a("strong"),$Gr=o("not"),kGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zZ=a("a"),SGr=o("from_pretrained()"),RGr=o(" to load the model weights."),PGr=l(),F($5.$$.fragment),BGr=l(),zr=a("div"),F(e$.$$.fragment),IGr=l(),aCe=a("p"),NGr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),qGr=l(),En=a("p"),jGr=o("The model class to instantiate is selected based on the "),nCe=a("code"),DGr=o("model_type"),GGr=o(` property of the config object (either
passed as an argument or loaded from `),sCe=a("code"),OGr=o("pretrained_model_name_or_path"),VGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lCe=a("code"),XGr=o("pretrained_model_name_or_path"),zGr=o(":"),QGr=l(),$e=a("ul"),k5=a("li"),iCe=a("strong"),WGr=o("albert"),HGr=o(" \u2014 "),QZ=a("a"),UGr=o("FlaxAlbertForMaskedLM"),JGr=o(" (ALBERT model)"),YGr=l(),S5=a("li"),dCe=a("strong"),KGr=o("bart"),ZGr=o(" \u2014 "),WZ=a("a"),eOr=o("FlaxBartForConditionalGeneration"),oOr=o(" (BART model)"),rOr=l(),R5=a("li"),cCe=a("strong"),tOr=o("bert"),aOr=o(" \u2014 "),HZ=a("a"),nOr=o("FlaxBertForMaskedLM"),sOr=o(" (BERT model)"),lOr=l(),P5=a("li"),fCe=a("strong"),iOr=o("big_bird"),dOr=o(" \u2014 "),UZ=a("a"),cOr=o("FlaxBigBirdForMaskedLM"),fOr=o(" (BigBird model)"),mOr=l(),B5=a("li"),mCe=a("strong"),gOr=o("distilbert"),hOr=o(" \u2014 "),JZ=a("a"),pOr=o("FlaxDistilBertForMaskedLM"),_Or=o(" (DistilBERT model)"),uOr=l(),I5=a("li"),gCe=a("strong"),bOr=o("electra"),vOr=o(" \u2014 "),YZ=a("a"),FOr=o("FlaxElectraForMaskedLM"),TOr=o(" (ELECTRA model)"),MOr=l(),N5=a("li"),hCe=a("strong"),EOr=o("mbart"),COr=o(" \u2014 "),KZ=a("a"),wOr=o("FlaxMBartForConditionalGeneration"),AOr=o(" (mBART model)"),LOr=l(),q5=a("li"),pCe=a("strong"),yOr=o("roberta"),xOr=o(" \u2014 "),ZZ=a("a"),$Or=o("FlaxRobertaForMaskedLM"),kOr=o(" (RoBERTa model)"),SOr=l(),j5=a("li"),_Ce=a("strong"),ROr=o("roformer"),POr=o(" \u2014 "),eee=a("a"),BOr=o("FlaxRoFormerForMaskedLM"),IOr=o(" (RoFormer model)"),NOr=l(),D5=a("li"),uCe=a("strong"),qOr=o("xlm-roberta"),jOr=o(" \u2014 "),oee=a("a"),DOr=o("FlaxXLMRobertaForMaskedLM"),GOr=o(" (XLM-RoBERTa model)"),OOr=l(),F(G5.$$.fragment),DVe=l(),ef=a("h2"),O5=a("a"),bCe=a("span"),F(o$.$$.fragment),VOr=l(),vCe=a("span"),XOr=o("FlaxAutoModelForSeq2SeqLM"),GVe=l(),br=a("div"),F(r$.$$.fragment),zOr=l(),of=a("p"),QOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ree=a("a"),WOr=o("from_pretrained()"),HOr=o(" class method or the "),tee=a("a"),UOr=o("from_config()"),JOr=o(` class
method.`),YOr=l(),t$=a("p"),KOr=o("This class cannot be instantiated directly using "),FCe=a("code"),ZOr=o("__init__()"),eVr=o(" (throws an error)."),oVr=l(),Ht=a("div"),F(a$.$$.fragment),rVr=l(),TCe=a("p"),tVr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),aVr=l(),rf=a("p"),nVr=o(`Note:
Loading a model from its configuration file does `),MCe=a("strong"),sVr=o("not"),lVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aee=a("a"),iVr=o("from_pretrained()"),dVr=o(" to load the model weights."),cVr=l(),F(V5.$$.fragment),fVr=l(),Qr=a("div"),F(n$.$$.fragment),mVr=l(),ECe=a("p"),gVr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),hVr=l(),Cn=a("p"),pVr=o("The model class to instantiate is selected based on the "),CCe=a("code"),_Vr=o("model_type"),uVr=o(` property of the config object (either
passed as an argument or loaded from `),wCe=a("code"),bVr=o("pretrained_model_name_or_path"),vVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ACe=a("code"),FVr=o("pretrained_model_name_or_path"),TVr=o(":"),MVr=l(),ke=a("ul"),X5=a("li"),LCe=a("strong"),EVr=o("bart"),CVr=o(" \u2014 "),nee=a("a"),wVr=o("FlaxBartForConditionalGeneration"),AVr=o(" (BART model)"),LVr=l(),z5=a("li"),yCe=a("strong"),yVr=o("blenderbot"),xVr=o(" \u2014 "),see=a("a"),$Vr=o("FlaxBlenderbotForConditionalGeneration"),kVr=o(" (Blenderbot model)"),SVr=l(),Q5=a("li"),xCe=a("strong"),RVr=o("blenderbot-small"),PVr=o(" \u2014 "),lee=a("a"),BVr=o("FlaxBlenderbotSmallForConditionalGeneration"),IVr=o(" (BlenderbotSmall model)"),NVr=l(),W5=a("li"),$Ce=a("strong"),qVr=o("encoder-decoder"),jVr=o(" \u2014 "),iee=a("a"),DVr=o("FlaxEncoderDecoderModel"),GVr=o(" (Encoder decoder model)"),OVr=l(),H5=a("li"),kCe=a("strong"),VVr=o("longt5"),XVr=o(" \u2014 "),dee=a("a"),zVr=o("FlaxLongT5ForConditionalGeneration"),QVr=o(" (LongT5 model)"),WVr=l(),U5=a("li"),SCe=a("strong"),HVr=o("marian"),UVr=o(" \u2014 "),cee=a("a"),JVr=o("FlaxMarianMTModel"),YVr=o(" (Marian model)"),KVr=l(),J5=a("li"),RCe=a("strong"),ZVr=o("mbart"),eXr=o(" \u2014 "),fee=a("a"),oXr=o("FlaxMBartForConditionalGeneration"),rXr=o(" (mBART model)"),tXr=l(),Y5=a("li"),PCe=a("strong"),aXr=o("mt5"),nXr=o(" \u2014 "),mee=a("a"),sXr=o("FlaxMT5ForConditionalGeneration"),lXr=o(" (MT5 model)"),iXr=l(),K5=a("li"),BCe=a("strong"),dXr=o("pegasus"),cXr=o(" \u2014 "),gee=a("a"),fXr=o("FlaxPegasusForConditionalGeneration"),mXr=o(" (Pegasus model)"),gXr=l(),Z5=a("li"),ICe=a("strong"),hXr=o("t5"),pXr=o(" \u2014 "),hee=a("a"),_Xr=o("FlaxT5ForConditionalGeneration"),uXr=o(" (T5 model)"),bXr=l(),F(e3.$$.fragment),OVe=l(),tf=a("h2"),o3=a("a"),NCe=a("span"),F(s$.$$.fragment),vXr=l(),qCe=a("span"),FXr=o("FlaxAutoModelForSequenceClassification"),VVe=l(),vr=a("div"),F(l$.$$.fragment),TXr=l(),af=a("p"),MXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pee=a("a"),EXr=o("from_pretrained()"),CXr=o(" class method or the "),_ee=a("a"),wXr=o("from_config()"),AXr=o(` class
method.`),LXr=l(),i$=a("p"),yXr=o("This class cannot be instantiated directly using "),jCe=a("code"),xXr=o("__init__()"),$Xr=o(" (throws an error)."),kXr=l(),Ut=a("div"),F(d$.$$.fragment),SXr=l(),DCe=a("p"),RXr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),PXr=l(),nf=a("p"),BXr=o(`Note:
Loading a model from its configuration file does `),GCe=a("strong"),IXr=o("not"),NXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=a("a"),qXr=o("from_pretrained()"),jXr=o(" to load the model weights."),DXr=l(),F(r3.$$.fragment),GXr=l(),Wr=a("div"),F(c$.$$.fragment),OXr=l(),OCe=a("p"),VXr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),XXr=l(),wn=a("p"),zXr=o("The model class to instantiate is selected based on the "),VCe=a("code"),QXr=o("model_type"),WXr=o(` property of the config object (either
passed as an argument or loaded from `),XCe=a("code"),HXr=o("pretrained_model_name_or_path"),UXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zCe=a("code"),JXr=o("pretrained_model_name_or_path"),YXr=o(":"),KXr=l(),Se=a("ul"),t3=a("li"),QCe=a("strong"),ZXr=o("albert"),ezr=o(" \u2014 "),bee=a("a"),ozr=o("FlaxAlbertForSequenceClassification"),rzr=o(" (ALBERT model)"),tzr=l(),a3=a("li"),WCe=a("strong"),azr=o("bart"),nzr=o(" \u2014 "),vee=a("a"),szr=o("FlaxBartForSequenceClassification"),lzr=o(" (BART model)"),izr=l(),n3=a("li"),HCe=a("strong"),dzr=o("bert"),czr=o(" \u2014 "),Fee=a("a"),fzr=o("FlaxBertForSequenceClassification"),mzr=o(" (BERT model)"),gzr=l(),s3=a("li"),UCe=a("strong"),hzr=o("big_bird"),pzr=o(" \u2014 "),Tee=a("a"),_zr=o("FlaxBigBirdForSequenceClassification"),uzr=o(" (BigBird model)"),bzr=l(),l3=a("li"),JCe=a("strong"),vzr=o("distilbert"),Fzr=o(" \u2014 "),Mee=a("a"),Tzr=o("FlaxDistilBertForSequenceClassification"),Mzr=o(" (DistilBERT model)"),Ezr=l(),i3=a("li"),YCe=a("strong"),Czr=o("electra"),wzr=o(" \u2014 "),Eee=a("a"),Azr=o("FlaxElectraForSequenceClassification"),Lzr=o(" (ELECTRA model)"),yzr=l(),d3=a("li"),KCe=a("strong"),xzr=o("mbart"),$zr=o(" \u2014 "),Cee=a("a"),kzr=o("FlaxMBartForSequenceClassification"),Szr=o(" (mBART model)"),Rzr=l(),c3=a("li"),ZCe=a("strong"),Pzr=o("roberta"),Bzr=o(" \u2014 "),wee=a("a"),Izr=o("FlaxRobertaForSequenceClassification"),Nzr=o(" (RoBERTa model)"),qzr=l(),f3=a("li"),e5e=a("strong"),jzr=o("roformer"),Dzr=o(" \u2014 "),Aee=a("a"),Gzr=o("FlaxRoFormerForSequenceClassification"),Ozr=o(" (RoFormer model)"),Vzr=l(),m3=a("li"),o5e=a("strong"),Xzr=o("xlm-roberta"),zzr=o(" \u2014 "),Lee=a("a"),Qzr=o("FlaxXLMRobertaForSequenceClassification"),Wzr=o(" (XLM-RoBERTa model)"),Hzr=l(),F(g3.$$.fragment),XVe=l(),sf=a("h2"),h3=a("a"),r5e=a("span"),F(f$.$$.fragment),Uzr=l(),t5e=a("span"),Jzr=o("FlaxAutoModelForQuestionAnswering"),zVe=l(),Fr=a("div"),F(m$.$$.fragment),Yzr=l(),lf=a("p"),Kzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),yee=a("a"),Zzr=o("from_pretrained()"),eQr=o(" class method or the "),xee=a("a"),oQr=o("from_config()"),rQr=o(` class
method.`),tQr=l(),g$=a("p"),aQr=o("This class cannot be instantiated directly using "),a5e=a("code"),nQr=o("__init__()"),sQr=o(" (throws an error)."),lQr=l(),Jt=a("div"),F(h$.$$.fragment),iQr=l(),n5e=a("p"),dQr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cQr=l(),df=a("p"),fQr=o(`Note:
Loading a model from its configuration file does `),s5e=a("strong"),mQr=o("not"),gQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ee=a("a"),hQr=o("from_pretrained()"),pQr=o(" to load the model weights."),_Qr=l(),F(p3.$$.fragment),uQr=l(),Hr=a("div"),F(p$.$$.fragment),bQr=l(),l5e=a("p"),vQr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),FQr=l(),An=a("p"),TQr=o("The model class to instantiate is selected based on the "),i5e=a("code"),MQr=o("model_type"),EQr=o(` property of the config object (either
passed as an argument or loaded from `),d5e=a("code"),CQr=o("pretrained_model_name_or_path"),wQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c5e=a("code"),AQr=o("pretrained_model_name_or_path"),LQr=o(":"),yQr=l(),Re=a("ul"),_3=a("li"),f5e=a("strong"),xQr=o("albert"),$Qr=o(" \u2014 "),kee=a("a"),kQr=o("FlaxAlbertForQuestionAnswering"),SQr=o(" (ALBERT model)"),RQr=l(),u3=a("li"),m5e=a("strong"),PQr=o("bart"),BQr=o(" \u2014 "),See=a("a"),IQr=o("FlaxBartForQuestionAnswering"),NQr=o(" (BART model)"),qQr=l(),b3=a("li"),g5e=a("strong"),jQr=o("bert"),DQr=o(" \u2014 "),Ree=a("a"),GQr=o("FlaxBertForQuestionAnswering"),OQr=o(" (BERT model)"),VQr=l(),v3=a("li"),h5e=a("strong"),XQr=o("big_bird"),zQr=o(" \u2014 "),Pee=a("a"),QQr=o("FlaxBigBirdForQuestionAnswering"),WQr=o(" (BigBird model)"),HQr=l(),F3=a("li"),p5e=a("strong"),UQr=o("distilbert"),JQr=o(" \u2014 "),Bee=a("a"),YQr=o("FlaxDistilBertForQuestionAnswering"),KQr=o(" (DistilBERT model)"),ZQr=l(),T3=a("li"),_5e=a("strong"),eWr=o("electra"),oWr=o(" \u2014 "),Iee=a("a"),rWr=o("FlaxElectraForQuestionAnswering"),tWr=o(" (ELECTRA model)"),aWr=l(),M3=a("li"),u5e=a("strong"),nWr=o("mbart"),sWr=o(" \u2014 "),Nee=a("a"),lWr=o("FlaxMBartForQuestionAnswering"),iWr=o(" (mBART model)"),dWr=l(),E3=a("li"),b5e=a("strong"),cWr=o("roberta"),fWr=o(" \u2014 "),qee=a("a"),mWr=o("FlaxRobertaForQuestionAnswering"),gWr=o(" (RoBERTa model)"),hWr=l(),C3=a("li"),v5e=a("strong"),pWr=o("roformer"),_Wr=o(" \u2014 "),jee=a("a"),uWr=o("FlaxRoFormerForQuestionAnswering"),bWr=o(" (RoFormer model)"),vWr=l(),w3=a("li"),F5e=a("strong"),FWr=o("xlm-roberta"),TWr=o(" \u2014 "),Dee=a("a"),MWr=o("FlaxXLMRobertaForQuestionAnswering"),EWr=o(" (XLM-RoBERTa model)"),CWr=l(),F(A3.$$.fragment),QVe=l(),cf=a("h2"),L3=a("a"),T5e=a("span"),F(_$.$$.fragment),wWr=l(),M5e=a("span"),AWr=o("FlaxAutoModelForTokenClassification"),WVe=l(),Tr=a("div"),F(u$.$$.fragment),LWr=l(),ff=a("p"),yWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Gee=a("a"),xWr=o("from_pretrained()"),$Wr=o(" class method or the "),Oee=a("a"),kWr=o("from_config()"),SWr=o(` class
method.`),RWr=l(),b$=a("p"),PWr=o("This class cannot be instantiated directly using "),E5e=a("code"),BWr=o("__init__()"),IWr=o(" (throws an error)."),NWr=l(),Yt=a("div"),F(v$.$$.fragment),qWr=l(),C5e=a("p"),jWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DWr=l(),mf=a("p"),GWr=o(`Note:
Loading a model from its configuration file does `),w5e=a("strong"),OWr=o("not"),VWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=a("a"),XWr=o("from_pretrained()"),zWr=o(" to load the model weights."),QWr=l(),F(y3.$$.fragment),WWr=l(),Ur=a("div"),F(F$.$$.fragment),HWr=l(),A5e=a("p"),UWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),JWr=l(),Ln=a("p"),YWr=o("The model class to instantiate is selected based on the "),L5e=a("code"),KWr=o("model_type"),ZWr=o(` property of the config object (either
passed as an argument or loaded from `),y5e=a("code"),eHr=o("pretrained_model_name_or_path"),oHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=a("code"),rHr=o("pretrained_model_name_or_path"),tHr=o(":"),aHr=l(),Ve=a("ul"),x3=a("li"),$5e=a("strong"),nHr=o("albert"),sHr=o(" \u2014 "),Xee=a("a"),lHr=o("FlaxAlbertForTokenClassification"),iHr=o(" (ALBERT model)"),dHr=l(),$3=a("li"),k5e=a("strong"),cHr=o("bert"),fHr=o(" \u2014 "),zee=a("a"),mHr=o("FlaxBertForTokenClassification"),gHr=o(" (BERT model)"),hHr=l(),k3=a("li"),S5e=a("strong"),pHr=o("big_bird"),_Hr=o(" \u2014 "),Qee=a("a"),uHr=o("FlaxBigBirdForTokenClassification"),bHr=o(" (BigBird model)"),vHr=l(),S3=a("li"),R5e=a("strong"),FHr=o("distilbert"),THr=o(" \u2014 "),Wee=a("a"),MHr=o("FlaxDistilBertForTokenClassification"),EHr=o(" (DistilBERT model)"),CHr=l(),R3=a("li"),P5e=a("strong"),wHr=o("electra"),AHr=o(" \u2014 "),Hee=a("a"),LHr=o("FlaxElectraForTokenClassification"),yHr=o(" (ELECTRA model)"),xHr=l(),P3=a("li"),B5e=a("strong"),$Hr=o("roberta"),kHr=o(" \u2014 "),Uee=a("a"),SHr=o("FlaxRobertaForTokenClassification"),RHr=o(" (RoBERTa model)"),PHr=l(),B3=a("li"),I5e=a("strong"),BHr=o("roformer"),IHr=o(" \u2014 "),Jee=a("a"),NHr=o("FlaxRoFormerForTokenClassification"),qHr=o(" (RoFormer model)"),jHr=l(),I3=a("li"),N5e=a("strong"),DHr=o("xlm-roberta"),GHr=o(" \u2014 "),Yee=a("a"),OHr=o("FlaxXLMRobertaForTokenClassification"),VHr=o(" (XLM-RoBERTa model)"),XHr=l(),F(N3.$$.fragment),HVe=l(),gf=a("h2"),q3=a("a"),q5e=a("span"),F(T$.$$.fragment),zHr=l(),j5e=a("span"),QHr=o("FlaxAutoModelForMultipleChoice"),UVe=l(),Mr=a("div"),F(M$.$$.fragment),WHr=l(),hf=a("p"),HHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Kee=a("a"),UHr=o("from_pretrained()"),JHr=o(" class method or the "),Zee=a("a"),YHr=o("from_config()"),KHr=o(` class
method.`),ZHr=l(),E$=a("p"),eUr=o("This class cannot be instantiated directly using "),D5e=a("code"),oUr=o("__init__()"),rUr=o(" (throws an error)."),tUr=l(),Kt=a("div"),F(C$.$$.fragment),aUr=l(),G5e=a("p"),nUr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),sUr=l(),pf=a("p"),lUr=o(`Note:
Loading a model from its configuration file does `),O5e=a("strong"),iUr=o("not"),dUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eoe=a("a"),cUr=o("from_pretrained()"),fUr=o(" to load the model weights."),mUr=l(),F(j3.$$.fragment),gUr=l(),Jr=a("div"),F(w$.$$.fragment),hUr=l(),V5e=a("p"),pUr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),_Ur=l(),yn=a("p"),uUr=o("The model class to instantiate is selected based on the "),X5e=a("code"),bUr=o("model_type"),vUr=o(` property of the config object (either
passed as an argument or loaded from `),z5e=a("code"),FUr=o("pretrained_model_name_or_path"),TUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q5e=a("code"),MUr=o("pretrained_model_name_or_path"),EUr=o(":"),CUr=l(),Xe=a("ul"),D3=a("li"),W5e=a("strong"),wUr=o("albert"),AUr=o(" \u2014 "),ooe=a("a"),LUr=o("FlaxAlbertForMultipleChoice"),yUr=o(" (ALBERT model)"),xUr=l(),G3=a("li"),H5e=a("strong"),$Ur=o("bert"),kUr=o(" \u2014 "),roe=a("a"),SUr=o("FlaxBertForMultipleChoice"),RUr=o(" (BERT model)"),PUr=l(),O3=a("li"),U5e=a("strong"),BUr=o("big_bird"),IUr=o(" \u2014 "),toe=a("a"),NUr=o("FlaxBigBirdForMultipleChoice"),qUr=o(" (BigBird model)"),jUr=l(),V3=a("li"),J5e=a("strong"),DUr=o("distilbert"),GUr=o(" \u2014 "),aoe=a("a"),OUr=o("FlaxDistilBertForMultipleChoice"),VUr=o(" (DistilBERT model)"),XUr=l(),X3=a("li"),Y5e=a("strong"),zUr=o("electra"),QUr=o(" \u2014 "),noe=a("a"),WUr=o("FlaxElectraForMultipleChoice"),HUr=o(" (ELECTRA model)"),UUr=l(),z3=a("li"),K5e=a("strong"),JUr=o("roberta"),YUr=o(" \u2014 "),soe=a("a"),KUr=o("FlaxRobertaForMultipleChoice"),ZUr=o(" (RoBERTa model)"),eJr=l(),Q3=a("li"),Z5e=a("strong"),oJr=o("roformer"),rJr=o(" \u2014 "),loe=a("a"),tJr=o("FlaxRoFormerForMultipleChoice"),aJr=o(" (RoFormer model)"),nJr=l(),W3=a("li"),e3e=a("strong"),sJr=o("xlm-roberta"),lJr=o(" \u2014 "),ioe=a("a"),iJr=o("FlaxXLMRobertaForMultipleChoice"),dJr=o(" (XLM-RoBERTa model)"),cJr=l(),F(H3.$$.fragment),JVe=l(),_f=a("h2"),U3=a("a"),o3e=a("span"),F(A$.$$.fragment),fJr=l(),r3e=a("span"),mJr=o("FlaxAutoModelForNextSentencePrediction"),YVe=l(),Er=a("div"),F(L$.$$.fragment),gJr=l(),uf=a("p"),hJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),doe=a("a"),pJr=o("from_pretrained()"),_Jr=o(" class method or the "),coe=a("a"),uJr=o("from_config()"),bJr=o(` class
method.`),vJr=l(),y$=a("p"),FJr=o("This class cannot be instantiated directly using "),t3e=a("code"),TJr=o("__init__()"),MJr=o(" (throws an error)."),EJr=l(),Zt=a("div"),F(x$.$$.fragment),CJr=l(),a3e=a("p"),wJr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),AJr=l(),bf=a("p"),LJr=o(`Note:
Loading a model from its configuration file does `),n3e=a("strong"),yJr=o("not"),xJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),$Jr=o("from_pretrained()"),kJr=o(" to load the model weights."),SJr=l(),F(J3.$$.fragment),RJr=l(),Yr=a("div"),F($$.$$.fragment),PJr=l(),s3e=a("p"),BJr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),IJr=l(),xn=a("p"),NJr=o("The model class to instantiate is selected based on the "),l3e=a("code"),qJr=o("model_type"),jJr=o(` property of the config object (either
passed as an argument or loaded from `),i3e=a("code"),DJr=o("pretrained_model_name_or_path"),GJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d3e=a("code"),OJr=o("pretrained_model_name_or_path"),VJr=o(":"),XJr=l(),c3e=a("ul"),Y3=a("li"),f3e=a("strong"),zJr=o("bert"),QJr=o(" \u2014 "),moe=a("a"),WJr=o("FlaxBertForNextSentencePrediction"),HJr=o(" (BERT model)"),UJr=l(),F(K3.$$.fragment),KVe=l(),vf=a("h2"),Z3=a("a"),m3e=a("span"),F(k$.$$.fragment),JJr=l(),g3e=a("span"),YJr=o("FlaxAutoModelForImageClassification"),ZVe=l(),Cr=a("div"),F(S$.$$.fragment),KJr=l(),Ff=a("p"),ZJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),goe=a("a"),eYr=o("from_pretrained()"),oYr=o(" class method or the "),hoe=a("a"),rYr=o("from_config()"),tYr=o(` class
method.`),aYr=l(),R$=a("p"),nYr=o("This class cannot be instantiated directly using "),h3e=a("code"),sYr=o("__init__()"),lYr=o(" (throws an error)."),iYr=l(),ea=a("div"),F(P$.$$.fragment),dYr=l(),p3e=a("p"),cYr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),fYr=l(),Tf=a("p"),mYr=o(`Note:
Loading a model from its configuration file does `),_3e=a("strong"),gYr=o("not"),hYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=a("a"),pYr=o("from_pretrained()"),_Yr=o(" to load the model weights."),uYr=l(),F(e0.$$.fragment),bYr=l(),Kr=a("div"),F(B$.$$.fragment),vYr=l(),u3e=a("p"),FYr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),TYr=l(),$n=a("p"),MYr=o("The model class to instantiate is selected based on the "),b3e=a("code"),EYr=o("model_type"),CYr=o(` property of the config object (either
passed as an argument or loaded from `),v3e=a("code"),wYr=o("pretrained_model_name_or_path"),AYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F3e=a("code"),LYr=o("pretrained_model_name_or_path"),yYr=o(":"),xYr=l(),I$=a("ul"),o0=a("li"),T3e=a("strong"),$Yr=o("beit"),kYr=o(" \u2014 "),_oe=a("a"),SYr=o("FlaxBeitForImageClassification"),RYr=o(" (BEiT model)"),PYr=l(),r0=a("li"),M3e=a("strong"),BYr=o("vit"),IYr=o(" \u2014 "),uoe=a("a"),NYr=o("FlaxViTForImageClassification"),qYr=o(" (ViT model)"),jYr=l(),F(t0.$$.fragment),eXe=l(),Mf=a("h2"),a0=a("a"),E3e=a("span"),F(N$.$$.fragment),DYr=l(),C3e=a("span"),GYr=o("FlaxAutoModelForVision2Seq"),oXe=l(),wr=a("div"),F(q$.$$.fragment),OYr=l(),Ef=a("p"),VYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),boe=a("a"),XYr=o("from_pretrained()"),zYr=o(" class method or the "),voe=a("a"),QYr=o("from_config()"),WYr=o(` class
method.`),HYr=l(),j$=a("p"),UYr=o("This class cannot be instantiated directly using "),w3e=a("code"),JYr=o("__init__()"),YYr=o(" (throws an error)."),KYr=l(),oa=a("div"),F(D$.$$.fragment),ZYr=l(),A3e=a("p"),eKr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),oKr=l(),Cf=a("p"),rKr=o(`Note:
Loading a model from its configuration file does `),L3e=a("strong"),tKr=o("not"),aKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Foe=a("a"),nKr=o("from_pretrained()"),sKr=o(" to load the model weights."),lKr=l(),F(n0.$$.fragment),iKr=l(),Zr=a("div"),F(G$.$$.fragment),dKr=l(),y3e=a("p"),cKr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),fKr=l(),kn=a("p"),mKr=o("The model class to instantiate is selected based on the "),x3e=a("code"),gKr=o("model_type"),hKr=o(` property of the config object (either
passed as an argument or loaded from `),$3e=a("code"),pKr=o("pretrained_model_name_or_path"),_Kr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k3e=a("code"),uKr=o("pretrained_model_name_or_path"),bKr=o(":"),vKr=l(),S3e=a("ul"),s0=a("li"),R3e=a("strong"),FKr=o("vision-encoder-decoder"),TKr=o(" \u2014 "),Toe=a("a"),MKr=o("FlaxVisionEncoderDecoderModel"),EKr=o(" (Vision Encoder decoder model)"),CKr=l(),F(l0.$$.fragment),this.h()},l(f){const u=oGt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var O$=s(p);m=n(O$,"A",{id:!0,class:!0,href:!0});var P3e=s(m);_=n(P3e,"SPAN",{});var B3e=s(_);T(d.$$.fragment,B3e),B3e.forEach(t),P3e.forEach(t),h=i(O$),Eo=n(O$,"SPAN",{});var I3e=s(Eo);Ti=r(I3e,"Auto Classes"),I3e.forEach(t),O$.forEach(t),yf=i(f),at=n(f,"P",{});var V$=s(at);Mi=r(V$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=n(V$,"CODE",{});var N3e=s(Ei);yA=r(N3e,"from_pretrained()"),N3e.forEach(t),xf=r(V$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),V$.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Sn=s(Qe);Ci=r(Sn,"Instantiating one of "),Rn=n(Sn,"A",{href:!0});var q3e=s(Rn);xA=r(q3e,"AutoConfig"),q3e.forEach(t),Pn=r(Sn,", "),Bn=n(Sn,"A",{href:!0});var j3e=s(Bn);$A=r(j3e,"AutoModel"),j3e.forEach(t),wi=r(Sn,`, and
`),In=n(Sn,"A",{href:!0});var D3e=s(In);kA=r(D3e,"AutoTokenizer"),D3e.forEach(t),Ai=r(Sn," will directly create a class of the relevant architecture. For instance"),Sn.forEach(t),$f=i(f),T(xa.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var X$=s(Ae);nS=r(X$,"will create a model that is an instance of "),Li=n(X$,"A",{href:!0});var G3e=s(Li);sS=r(G3e,"BertModel"),G3e.forEach(t),lS=r(X$,"."),X$.forEach(t),Co=i(f),$a=n(f,"P",{});var z$=s($a);iS=r(z$,"There is one class of "),kf=n(z$,"CODE",{});var O3e=s(kf);dS=r(O3e,"AutoModel"),O3e.forEach(t),mQe=r(z$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),z$.forEach(t),YGe=i(f),yi=n(f,"H2",{class:!0});var Q$=s(yi);Sf=n(Q$,"A",{id:!0,class:!0,href:!0});var V3e=s(Sf);_te=n(V3e,"SPAN",{});var X3e=s(_te);T(SA.$$.fragment,X3e),X3e.forEach(t),V3e.forEach(t),gQe=i(Q$),ute=n(Q$,"SPAN",{});var z3e=s(ute);hQe=r(z3e,"Extending the Auto Classes"),z3e.forEach(t),Q$.forEach(t),KGe=i(f),Nn=n(f,"P",{});var wf=s(Nn);pQe=r(wf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),bte=n(wf,"CODE",{});var Q3e=s(bte);_Qe=r(Q3e,"NewModel"),Q3e.forEach(t),uQe=r(wf,", make sure you have a "),vte=n(wf,"CODE",{});var W3e=s(vte);bQe=r(W3e,"NewModelConfig"),W3e.forEach(t),vQe=r(wf,` then you can add those to the auto
classes like this:`),wf.forEach(t),ZGe=i(f),T(RA.$$.fragment,f),eOe=i(f),cS=n(f,"P",{});var H3e=s(cS);FQe=r(H3e,"You will then be able to use the auto classes like you would usually do!"),H3e.forEach(t),oOe=i(f),T(Rf.$$.fragment,f),rOe=i(f),xi=n(f,"H2",{class:!0});var W$=s(xi);Pf=n(W$,"A",{id:!0,class:!0,href:!0});var U3e=s(Pf);Fte=n(U3e,"SPAN",{});var J3e=s(Fte);T(PA.$$.fragment,J3e),J3e.forEach(t),U3e.forEach(t),TQe=i(W$),Tte=n(W$,"SPAN",{});var Y3e=s(Tte);MQe=r(Y3e,"AutoConfig"),Y3e.forEach(t),W$.forEach(t),tOe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(BA.$$.fragment,rt),EQe=i(rt),IA=n(rt,"P",{});var H$=s(IA);CQe=r(H$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),fS=n(H$,"A",{href:!0});var K3e=s(fS);wQe=r(K3e,"from_pretrained()"),K3e.forEach(t),AQe=r(H$," class method."),H$.forEach(t),LQe=i(rt),NA=n(rt,"P",{});var U$=s(NA);yQe=r(U$,"This class cannot be instantiated directly using "),Mte=n(U$,"CODE",{});var Z3e=s(Mte);xQe=r(Z3e,"__init__()"),Z3e.forEach(t),$Qe=r(U$," (throws an error)."),U$.forEach(t),kQe=i(rt),Ar=n(rt,"DIV",{class:!0});var tt=s(Ar);T(qA.$$.fragment,tt),SQe=i(tt),Ete=n(tt,"P",{});var e0e=s(Ete);RQe=r(e0e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),e0e.forEach(t),PQe=i(tt),$i=n(tt,"P",{});var Af=s($i);BQe=r(Af,"The configuration class to instantiate is selected based on the "),Cte=n(Af,"CODE",{});var o0e=s(Cte);IQe=r(o0e,"model_type"),o0e.forEach(t),NQe=r(Af,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),wte=n(Af,"CODE",{});var r0e=s(wte);qQe=r(r0e,"pretrained_model_name_or_path"),r0e.forEach(t),jQe=r(Af,":"),Af.forEach(t),DQe=i(tt),A=n(tt,"UL",{});var L=s(A);Bf=n(L,"LI",{});var i0=s(Bf);Ate=n(i0,"STRONG",{});var t0e=s(Ate);GQe=r(t0e,"albert"),t0e.forEach(t),OQe=r(i0," \u2014 "),mS=n(i0,"A",{href:!0});var a0e=s(mS);VQe=r(a0e,"AlbertConfig"),a0e.forEach(t),XQe=r(i0," (ALBERT model)"),i0.forEach(t),zQe=i(L),If=n(L,"LI",{});var d0=s(If);Lte=n(d0,"STRONG",{});var n0e=s(Lte);QQe=r(n0e,"bart"),n0e.forEach(t),WQe=r(d0," \u2014 "),gS=n(d0,"A",{href:!0});var s0e=s(gS);HQe=r(s0e,"BartConfig"),s0e.forEach(t),UQe=r(d0," (BART model)"),d0.forEach(t),JQe=i(L),Nf=n(L,"LI",{});var c0=s(Nf);yte=n(c0,"STRONG",{});var l0e=s(yte);YQe=r(l0e,"beit"),l0e.forEach(t),KQe=r(c0," \u2014 "),hS=n(c0,"A",{href:!0});var i0e=s(hS);ZQe=r(i0e,"BeitConfig"),i0e.forEach(t),eWe=r(c0," (BEiT model)"),c0.forEach(t),oWe=i(L),qf=n(L,"LI",{});var f0=s(qf);xte=n(f0,"STRONG",{});var d0e=s(xte);rWe=r(d0e,"bert"),d0e.forEach(t),tWe=r(f0," \u2014 "),pS=n(f0,"A",{href:!0});var c0e=s(pS);aWe=r(c0e,"BertConfig"),c0e.forEach(t),nWe=r(f0," (BERT model)"),f0.forEach(t),sWe=i(L),jf=n(L,"LI",{});var m0=s(jf);$te=n(m0,"STRONG",{});var f0e=s($te);lWe=r(f0e,"bert-generation"),f0e.forEach(t),iWe=r(m0," \u2014 "),_S=n(m0,"A",{href:!0});var m0e=s(_S);dWe=r(m0e,"BertGenerationConfig"),m0e.forEach(t),cWe=r(m0," (Bert Generation model)"),m0.forEach(t),fWe=i(L),Df=n(L,"LI",{});var g0=s(Df);kte=n(g0,"STRONG",{});var g0e=s(kte);mWe=r(g0e,"big_bird"),g0e.forEach(t),gWe=r(g0," \u2014 "),uS=n(g0,"A",{href:!0});var h0e=s(uS);hWe=r(h0e,"BigBirdConfig"),h0e.forEach(t),pWe=r(g0," (BigBird model)"),g0.forEach(t),_We=i(L),Gf=n(L,"LI",{});var h0=s(Gf);Ste=n(h0,"STRONG",{});var p0e=s(Ste);uWe=r(p0e,"bigbird_pegasus"),p0e.forEach(t),bWe=r(h0," \u2014 "),bS=n(h0,"A",{href:!0});var _0e=s(bS);vWe=r(_0e,"BigBirdPegasusConfig"),_0e.forEach(t),FWe=r(h0," (BigBird-Pegasus model)"),h0.forEach(t),TWe=i(L),Of=n(L,"LI",{});var p0=s(Of);Rte=n(p0,"STRONG",{});var u0e=s(Rte);MWe=r(u0e,"blenderbot"),u0e.forEach(t),EWe=r(p0," \u2014 "),vS=n(p0,"A",{href:!0});var b0e=s(vS);CWe=r(b0e,"BlenderbotConfig"),b0e.forEach(t),wWe=r(p0," (Blenderbot model)"),p0.forEach(t),AWe=i(L),Vf=n(L,"LI",{});var _0=s(Vf);Pte=n(_0,"STRONG",{});var v0e=s(Pte);LWe=r(v0e,"blenderbot-small"),v0e.forEach(t),yWe=r(_0," \u2014 "),FS=n(_0,"A",{href:!0});var F0e=s(FS);xWe=r(F0e,"BlenderbotSmallConfig"),F0e.forEach(t),$We=r(_0," (BlenderbotSmall model)"),_0.forEach(t),kWe=i(L),Xf=n(L,"LI",{});var u0=s(Xf);Bte=n(u0,"STRONG",{});var T0e=s(Bte);SWe=r(T0e,"bloom"),T0e.forEach(t),RWe=r(u0," \u2014 "),TS=n(u0,"A",{href:!0});var M0e=s(TS);PWe=r(M0e,"BloomConfig"),M0e.forEach(t),BWe=r(u0," (BLOOM model)"),u0.forEach(t),IWe=i(L),zf=n(L,"LI",{});var b0=s(zf);Ite=n(b0,"STRONG",{});var E0e=s(Ite);NWe=r(E0e,"camembert"),E0e.forEach(t),qWe=r(b0," \u2014 "),MS=n(b0,"A",{href:!0});var C0e=s(MS);jWe=r(C0e,"CamembertConfig"),C0e.forEach(t),DWe=r(b0," (CamemBERT model)"),b0.forEach(t),GWe=i(L),Qf=n(L,"LI",{});var v0=s(Qf);Nte=n(v0,"STRONG",{});var w0e=s(Nte);OWe=r(w0e,"canine"),w0e.forEach(t),VWe=r(v0," \u2014 "),ES=n(v0,"A",{href:!0});var A0e=s(ES);XWe=r(A0e,"CanineConfig"),A0e.forEach(t),zWe=r(v0," (CANINE model)"),v0.forEach(t),QWe=i(L),Wf=n(L,"LI",{});var F0=s(Wf);qte=n(F0,"STRONG",{});var L0e=s(qte);WWe=r(L0e,"clip"),L0e.forEach(t),HWe=r(F0," \u2014 "),CS=n(F0,"A",{href:!0});var y0e=s(CS);UWe=r(y0e,"CLIPConfig"),y0e.forEach(t),JWe=r(F0," (CLIP model)"),F0.forEach(t),YWe=i(L),Hf=n(L,"LI",{});var T0=s(Hf);jte=n(T0,"STRONG",{});var x0e=s(jte);KWe=r(x0e,"convbert"),x0e.forEach(t),ZWe=r(T0," \u2014 "),wS=n(T0,"A",{href:!0});var $0e=s(wS);eHe=r($0e,"ConvBertConfig"),$0e.forEach(t),oHe=r(T0," (ConvBERT model)"),T0.forEach(t),rHe=i(L),Uf=n(L,"LI",{});var M0=s(Uf);Dte=n(M0,"STRONG",{});var k0e=s(Dte);tHe=r(k0e,"convnext"),k0e.forEach(t),aHe=r(M0," \u2014 "),AS=n(M0,"A",{href:!0});var S0e=s(AS);nHe=r(S0e,"ConvNextConfig"),S0e.forEach(t),sHe=r(M0," (ConvNeXT model)"),M0.forEach(t),lHe=i(L),Jf=n(L,"LI",{});var E0=s(Jf);Gte=n(E0,"STRONG",{});var R0e=s(Gte);iHe=r(R0e,"ctrl"),R0e.forEach(t),dHe=r(E0," \u2014 "),LS=n(E0,"A",{href:!0});var P0e=s(LS);cHe=r(P0e,"CTRLConfig"),P0e.forEach(t),fHe=r(E0," (CTRL model)"),E0.forEach(t),mHe=i(L),Yf=n(L,"LI",{});var C0=s(Yf);Ote=n(C0,"STRONG",{});var B0e=s(Ote);gHe=r(B0e,"cvt"),B0e.forEach(t),hHe=r(C0," \u2014 "),yS=n(C0,"A",{href:!0});var I0e=s(yS);pHe=r(I0e,"CvtConfig"),I0e.forEach(t),_He=r(C0," (CvT model)"),C0.forEach(t),uHe=i(L),Kf=n(L,"LI",{});var w0=s(Kf);Vte=n(w0,"STRONG",{});var N0e=s(Vte);bHe=r(N0e,"data2vec-audio"),N0e.forEach(t),vHe=r(w0," \u2014 "),xS=n(w0,"A",{href:!0});var q0e=s(xS);FHe=r(q0e,"Data2VecAudioConfig"),q0e.forEach(t),THe=r(w0," (Data2VecAudio model)"),w0.forEach(t),MHe=i(L),Zf=n(L,"LI",{});var A0=s(Zf);Xte=n(A0,"STRONG",{});var j0e=s(Xte);EHe=r(j0e,"data2vec-text"),j0e.forEach(t),CHe=r(A0," \u2014 "),$S=n(A0,"A",{href:!0});var D0e=s($S);wHe=r(D0e,"Data2VecTextConfig"),D0e.forEach(t),AHe=r(A0," (Data2VecText model)"),A0.forEach(t),LHe=i(L),em=n(L,"LI",{});var L0=s(em);zte=n(L0,"STRONG",{});var G0e=s(zte);yHe=r(G0e,"data2vec-vision"),G0e.forEach(t),xHe=r(L0," \u2014 "),kS=n(L0,"A",{href:!0});var O0e=s(kS);$He=r(O0e,"Data2VecVisionConfig"),O0e.forEach(t),kHe=r(L0," (Data2VecVision model)"),L0.forEach(t),SHe=i(L),om=n(L,"LI",{});var y0=s(om);Qte=n(y0,"STRONG",{});var V0e=s(Qte);RHe=r(V0e,"deberta"),V0e.forEach(t),PHe=r(y0," \u2014 "),SS=n(y0,"A",{href:!0});var X0e=s(SS);BHe=r(X0e,"DebertaConfig"),X0e.forEach(t),IHe=r(y0," (DeBERTa model)"),y0.forEach(t),NHe=i(L),rm=n(L,"LI",{});var x0=s(rm);Wte=n(x0,"STRONG",{});var z0e=s(Wte);qHe=r(z0e,"deberta-v2"),z0e.forEach(t),jHe=r(x0," \u2014 "),RS=n(x0,"A",{href:!0});var Q0e=s(RS);DHe=r(Q0e,"DebertaV2Config"),Q0e.forEach(t),GHe=r(x0," (DeBERTa-v2 model)"),x0.forEach(t),OHe=i(L),tm=n(L,"LI",{});var $0=s(tm);Hte=n($0,"STRONG",{});var W0e=s(Hte);VHe=r(W0e,"decision_transformer"),W0e.forEach(t),XHe=r($0," \u2014 "),PS=n($0,"A",{href:!0});var H0e=s(PS);zHe=r(H0e,"DecisionTransformerConfig"),H0e.forEach(t),QHe=r($0," (Decision Transformer model)"),$0.forEach(t),WHe=i(L),am=n(L,"LI",{});var k0=s(am);Ute=n(k0,"STRONG",{});var AKr=s(Ute);HHe=r(AKr,"deit"),AKr.forEach(t),UHe=r(k0," \u2014 "),BS=n(k0,"A",{href:!0});var LKr=s(BS);JHe=r(LKr,"DeiTConfig"),LKr.forEach(t),YHe=r(k0," (DeiT model)"),k0.forEach(t),KHe=i(L),nm=n(L,"LI",{});var U0e=s(nm);Jte=n(U0e,"STRONG",{});var yKr=s(Jte);ZHe=r(yKr,"detr"),yKr.forEach(t),eUe=r(U0e," \u2014 "),IS=n(U0e,"A",{href:!0});var xKr=s(IS);oUe=r(xKr,"DetrConfig"),xKr.forEach(t),rUe=r(U0e," (DETR model)"),U0e.forEach(t),tUe=i(L),sm=n(L,"LI",{});var J0e=s(sm);Yte=n(J0e,"STRONG",{});var $Kr=s(Yte);aUe=r($Kr,"distilbert"),$Kr.forEach(t),nUe=r(J0e," \u2014 "),NS=n(J0e,"A",{href:!0});var kKr=s(NS);sUe=r(kKr,"DistilBertConfig"),kKr.forEach(t),lUe=r(J0e," (DistilBERT model)"),J0e.forEach(t),iUe=i(L),lm=n(L,"LI",{});var Y0e=s(lm);Kte=n(Y0e,"STRONG",{});var SKr=s(Kte);dUe=r(SKr,"dpr"),SKr.forEach(t),cUe=r(Y0e," \u2014 "),qS=n(Y0e,"A",{href:!0});var RKr=s(qS);fUe=r(RKr,"DPRConfig"),RKr.forEach(t),mUe=r(Y0e," (DPR model)"),Y0e.forEach(t),gUe=i(L),im=n(L,"LI",{});var K0e=s(im);Zte=n(K0e,"STRONG",{});var PKr=s(Zte);hUe=r(PKr,"dpt"),PKr.forEach(t),pUe=r(K0e," \u2014 "),jS=n(K0e,"A",{href:!0});var BKr=s(jS);_Ue=r(BKr,"DPTConfig"),BKr.forEach(t),uUe=r(K0e," (DPT model)"),K0e.forEach(t),bUe=i(L),dm=n(L,"LI",{});var Z0e=s(dm);eae=n(Z0e,"STRONG",{});var IKr=s(eae);vUe=r(IKr,"electra"),IKr.forEach(t),FUe=r(Z0e," \u2014 "),DS=n(Z0e,"A",{href:!0});var NKr=s(DS);TUe=r(NKr,"ElectraConfig"),NKr.forEach(t),MUe=r(Z0e," (ELECTRA model)"),Z0e.forEach(t),EUe=i(L),cm=n(L,"LI",{});var ewe=s(cm);oae=n(ewe,"STRONG",{});var qKr=s(oae);CUe=r(qKr,"encoder-decoder"),qKr.forEach(t),wUe=r(ewe," \u2014 "),GS=n(ewe,"A",{href:!0});var jKr=s(GS);AUe=r(jKr,"EncoderDecoderConfig"),jKr.forEach(t),LUe=r(ewe," (Encoder decoder model)"),ewe.forEach(t),yUe=i(L),fm=n(L,"LI",{});var owe=s(fm);rae=n(owe,"STRONG",{});var DKr=s(rae);xUe=r(DKr,"flaubert"),DKr.forEach(t),$Ue=r(owe," \u2014 "),OS=n(owe,"A",{href:!0});var GKr=s(OS);kUe=r(GKr,"FlaubertConfig"),GKr.forEach(t),SUe=r(owe," (FlauBERT model)"),owe.forEach(t),RUe=i(L),mm=n(L,"LI",{});var rwe=s(mm);tae=n(rwe,"STRONG",{});var OKr=s(tae);PUe=r(OKr,"flava"),OKr.forEach(t),BUe=r(rwe," \u2014 "),VS=n(rwe,"A",{href:!0});var VKr=s(VS);IUe=r(VKr,"FlavaConfig"),VKr.forEach(t),NUe=r(rwe," (FLAVA model)"),rwe.forEach(t),qUe=i(L),gm=n(L,"LI",{});var twe=s(gm);aae=n(twe,"STRONG",{});var XKr=s(aae);jUe=r(XKr,"fnet"),XKr.forEach(t),DUe=r(twe," \u2014 "),XS=n(twe,"A",{href:!0});var zKr=s(XS);GUe=r(zKr,"FNetConfig"),zKr.forEach(t),OUe=r(twe," (FNet model)"),twe.forEach(t),VUe=i(L),hm=n(L,"LI",{});var awe=s(hm);nae=n(awe,"STRONG",{});var QKr=s(nae);XUe=r(QKr,"fsmt"),QKr.forEach(t),zUe=r(awe," \u2014 "),zS=n(awe,"A",{href:!0});var WKr=s(zS);QUe=r(WKr,"FSMTConfig"),WKr.forEach(t),WUe=r(awe," (FairSeq Machine-Translation model)"),awe.forEach(t),HUe=i(L),pm=n(L,"LI",{});var nwe=s(pm);sae=n(nwe,"STRONG",{});var HKr=s(sae);UUe=r(HKr,"funnel"),HKr.forEach(t),JUe=r(nwe," \u2014 "),QS=n(nwe,"A",{href:!0});var UKr=s(QS);YUe=r(UKr,"FunnelConfig"),UKr.forEach(t),KUe=r(nwe," (Funnel Transformer model)"),nwe.forEach(t),ZUe=i(L),_m=n(L,"LI",{});var swe=s(_m);lae=n(swe,"STRONG",{});var JKr=s(lae);eJe=r(JKr,"glpn"),JKr.forEach(t),oJe=r(swe," \u2014 "),WS=n(swe,"A",{href:!0});var YKr=s(WS);rJe=r(YKr,"GLPNConfig"),YKr.forEach(t),tJe=r(swe," (GLPN model)"),swe.forEach(t),aJe=i(L),um=n(L,"LI",{});var lwe=s(um);iae=n(lwe,"STRONG",{});var KKr=s(iae);nJe=r(KKr,"gpt2"),KKr.forEach(t),sJe=r(lwe," \u2014 "),HS=n(lwe,"A",{href:!0});var ZKr=s(HS);lJe=r(ZKr,"GPT2Config"),ZKr.forEach(t),iJe=r(lwe," (OpenAI GPT-2 model)"),lwe.forEach(t),dJe=i(L),bm=n(L,"LI",{});var iwe=s(bm);dae=n(iwe,"STRONG",{});var eZr=s(dae);cJe=r(eZr,"gpt_neo"),eZr.forEach(t),fJe=r(iwe," \u2014 "),US=n(iwe,"A",{href:!0});var oZr=s(US);mJe=r(oZr,"GPTNeoConfig"),oZr.forEach(t),gJe=r(iwe," (GPT Neo model)"),iwe.forEach(t),hJe=i(L),vm=n(L,"LI",{});var dwe=s(vm);cae=n(dwe,"STRONG",{});var rZr=s(cae);pJe=r(rZr,"gpt_neox"),rZr.forEach(t),_Je=r(dwe," \u2014 "),JS=n(dwe,"A",{href:!0});var tZr=s(JS);uJe=r(tZr,"GPTNeoXConfig"),tZr.forEach(t),bJe=r(dwe," (GPT NeoX model)"),dwe.forEach(t),vJe=i(L),Fm=n(L,"LI",{});var cwe=s(Fm);fae=n(cwe,"STRONG",{});var aZr=s(fae);FJe=r(aZr,"gptj"),aZr.forEach(t),TJe=r(cwe," \u2014 "),YS=n(cwe,"A",{href:!0});var nZr=s(YS);MJe=r(nZr,"GPTJConfig"),nZr.forEach(t),EJe=r(cwe," (GPT-J model)"),cwe.forEach(t),CJe=i(L),Tm=n(L,"LI",{});var fwe=s(Tm);mae=n(fwe,"STRONG",{});var sZr=s(mae);wJe=r(sZr,"hubert"),sZr.forEach(t),AJe=r(fwe," \u2014 "),KS=n(fwe,"A",{href:!0});var lZr=s(KS);LJe=r(lZr,"HubertConfig"),lZr.forEach(t),yJe=r(fwe," (Hubert model)"),fwe.forEach(t),xJe=i(L),Mm=n(L,"LI",{});var mwe=s(Mm);gae=n(mwe,"STRONG",{});var iZr=s(gae);$Je=r(iZr,"ibert"),iZr.forEach(t),kJe=r(mwe," \u2014 "),ZS=n(mwe,"A",{href:!0});var dZr=s(ZS);SJe=r(dZr,"IBertConfig"),dZr.forEach(t),RJe=r(mwe," (I-BERT model)"),mwe.forEach(t),PJe=i(L),Em=n(L,"LI",{});var gwe=s(Em);hae=n(gwe,"STRONG",{});var cZr=s(hae);BJe=r(cZr,"imagegpt"),cZr.forEach(t),IJe=r(gwe," \u2014 "),eR=n(gwe,"A",{href:!0});var fZr=s(eR);NJe=r(fZr,"ImageGPTConfig"),fZr.forEach(t),qJe=r(gwe," (ImageGPT model)"),gwe.forEach(t),jJe=i(L),Cm=n(L,"LI",{});var hwe=s(Cm);pae=n(hwe,"STRONG",{});var mZr=s(pae);DJe=r(mZr,"jukebox"),mZr.forEach(t),GJe=r(hwe," \u2014 "),oR=n(hwe,"A",{href:!0});var gZr=s(oR);OJe=r(gZr,"JukeboxConfig"),gZr.forEach(t),VJe=r(hwe," (Jukebox model)"),hwe.forEach(t),XJe=i(L),wm=n(L,"LI",{});var pwe=s(wm);_ae=n(pwe,"STRONG",{});var hZr=s(_ae);zJe=r(hZr,"layoutlm"),hZr.forEach(t),QJe=r(pwe," \u2014 "),rR=n(pwe,"A",{href:!0});var pZr=s(rR);WJe=r(pZr,"LayoutLMConfig"),pZr.forEach(t),HJe=r(pwe," (LayoutLM model)"),pwe.forEach(t),UJe=i(L),Am=n(L,"LI",{});var _we=s(Am);uae=n(_we,"STRONG",{});var _Zr=s(uae);JJe=r(_Zr,"layoutlmv2"),_Zr.forEach(t),YJe=r(_we," \u2014 "),tR=n(_we,"A",{href:!0});var uZr=s(tR);KJe=r(uZr,"LayoutLMv2Config"),uZr.forEach(t),ZJe=r(_we," (LayoutLMv2 model)"),_we.forEach(t),eYe=i(L),Lm=n(L,"LI",{});var uwe=s(Lm);bae=n(uwe,"STRONG",{});var bZr=s(bae);oYe=r(bZr,"layoutlmv3"),bZr.forEach(t),rYe=r(uwe," \u2014 "),aR=n(uwe,"A",{href:!0});var vZr=s(aR);tYe=r(vZr,"LayoutLMv3Config"),vZr.forEach(t),aYe=r(uwe," (LayoutLMv3 model)"),uwe.forEach(t),nYe=i(L),ym=n(L,"LI",{});var bwe=s(ym);vae=n(bwe,"STRONG",{});var FZr=s(vae);sYe=r(FZr,"led"),FZr.forEach(t),lYe=r(bwe," \u2014 "),nR=n(bwe,"A",{href:!0});var TZr=s(nR);iYe=r(TZr,"LEDConfig"),TZr.forEach(t),dYe=r(bwe," (LED model)"),bwe.forEach(t),cYe=i(L),xm=n(L,"LI",{});var vwe=s(xm);Fae=n(vwe,"STRONG",{});var MZr=s(Fae);fYe=r(MZr,"levit"),MZr.forEach(t),mYe=r(vwe," \u2014 "),sR=n(vwe,"A",{href:!0});var EZr=s(sR);gYe=r(EZr,"LevitConfig"),EZr.forEach(t),hYe=r(vwe," (LeViT model)"),vwe.forEach(t),pYe=i(L),$m=n(L,"LI",{});var Fwe=s($m);Tae=n(Fwe,"STRONG",{});var CZr=s(Tae);_Ye=r(CZr,"longformer"),CZr.forEach(t),uYe=r(Fwe," \u2014 "),lR=n(Fwe,"A",{href:!0});var wZr=s(lR);bYe=r(wZr,"LongformerConfig"),wZr.forEach(t),vYe=r(Fwe," (Longformer model)"),Fwe.forEach(t),FYe=i(L),km=n(L,"LI",{});var Twe=s(km);Mae=n(Twe,"STRONG",{});var AZr=s(Mae);TYe=r(AZr,"longt5"),AZr.forEach(t),MYe=r(Twe," \u2014 "),iR=n(Twe,"A",{href:!0});var LZr=s(iR);EYe=r(LZr,"LongT5Config"),LZr.forEach(t),CYe=r(Twe," (LongT5 model)"),Twe.forEach(t),wYe=i(L),Sm=n(L,"LI",{});var Mwe=s(Sm);Eae=n(Mwe,"STRONG",{});var yZr=s(Eae);AYe=r(yZr,"luke"),yZr.forEach(t),LYe=r(Mwe," \u2014 "),dR=n(Mwe,"A",{href:!0});var xZr=s(dR);yYe=r(xZr,"LukeConfig"),xZr.forEach(t),xYe=r(Mwe," (LUKE model)"),Mwe.forEach(t),$Ye=i(L),Rm=n(L,"LI",{});var Ewe=s(Rm);Cae=n(Ewe,"STRONG",{});var $Zr=s(Cae);kYe=r($Zr,"lxmert"),$Zr.forEach(t),SYe=r(Ewe," \u2014 "),cR=n(Ewe,"A",{href:!0});var kZr=s(cR);RYe=r(kZr,"LxmertConfig"),kZr.forEach(t),PYe=r(Ewe," (LXMERT model)"),Ewe.forEach(t),BYe=i(L),Pm=n(L,"LI",{});var Cwe=s(Pm);wae=n(Cwe,"STRONG",{});var SZr=s(wae);IYe=r(SZr,"m2m_100"),SZr.forEach(t),NYe=r(Cwe," \u2014 "),fR=n(Cwe,"A",{href:!0});var RZr=s(fR);qYe=r(RZr,"M2M100Config"),RZr.forEach(t),jYe=r(Cwe," (M2M100 model)"),Cwe.forEach(t),DYe=i(L),Bm=n(L,"LI",{});var wwe=s(Bm);Aae=n(wwe,"STRONG",{});var PZr=s(Aae);GYe=r(PZr,"marian"),PZr.forEach(t),OYe=r(wwe," \u2014 "),mR=n(wwe,"A",{href:!0});var BZr=s(mR);VYe=r(BZr,"MarianConfig"),BZr.forEach(t),XYe=r(wwe," (Marian model)"),wwe.forEach(t),zYe=i(L),Im=n(L,"LI",{});var Awe=s(Im);Lae=n(Awe,"STRONG",{});var IZr=s(Lae);QYe=r(IZr,"maskformer"),IZr.forEach(t),WYe=r(Awe," \u2014 "),gR=n(Awe,"A",{href:!0});var NZr=s(gR);HYe=r(NZr,"MaskFormerConfig"),NZr.forEach(t),UYe=r(Awe," (MaskFormer model)"),Awe.forEach(t),JYe=i(L),Nm=n(L,"LI",{});var Lwe=s(Nm);yae=n(Lwe,"STRONG",{});var qZr=s(yae);YYe=r(qZr,"mbart"),qZr.forEach(t),KYe=r(Lwe," \u2014 "),hR=n(Lwe,"A",{href:!0});var jZr=s(hR);ZYe=r(jZr,"MBartConfig"),jZr.forEach(t),eKe=r(Lwe," (mBART model)"),Lwe.forEach(t),oKe=i(L),qm=n(L,"LI",{});var ywe=s(qm);xae=n(ywe,"STRONG",{});var DZr=s(xae);rKe=r(DZr,"mctct"),DZr.forEach(t),tKe=r(ywe," \u2014 "),pR=n(ywe,"A",{href:!0});var GZr=s(pR);aKe=r(GZr,"MCTCTConfig"),GZr.forEach(t),nKe=r(ywe," (M-CTC-T model)"),ywe.forEach(t),sKe=i(L),jm=n(L,"LI",{});var xwe=s(jm);$ae=n(xwe,"STRONG",{});var OZr=s($ae);lKe=r(OZr,"megatron-bert"),OZr.forEach(t),iKe=r(xwe," \u2014 "),_R=n(xwe,"A",{href:!0});var VZr=s(_R);dKe=r(VZr,"MegatronBertConfig"),VZr.forEach(t),cKe=r(xwe," (Megatron-BERT model)"),xwe.forEach(t),fKe=i(L),Dm=n(L,"LI",{});var $we=s(Dm);kae=n($we,"STRONG",{});var XZr=s(kae);mKe=r(XZr,"mobilebert"),XZr.forEach(t),gKe=r($we," \u2014 "),uR=n($we,"A",{href:!0});var zZr=s(uR);hKe=r(zZr,"MobileBertConfig"),zZr.forEach(t),pKe=r($we," (MobileBERT model)"),$we.forEach(t),_Ke=i(L),Gm=n(L,"LI",{});var kwe=s(Gm);Sae=n(kwe,"STRONG",{});var QZr=s(Sae);uKe=r(QZr,"mpnet"),QZr.forEach(t),bKe=r(kwe," \u2014 "),bR=n(kwe,"A",{href:!0});var WZr=s(bR);vKe=r(WZr,"MPNetConfig"),WZr.forEach(t),FKe=r(kwe," (MPNet model)"),kwe.forEach(t),TKe=i(L),Om=n(L,"LI",{});var Swe=s(Om);Rae=n(Swe,"STRONG",{});var HZr=s(Rae);MKe=r(HZr,"mt5"),HZr.forEach(t),EKe=r(Swe," \u2014 "),vR=n(Swe,"A",{href:!0});var UZr=s(vR);CKe=r(UZr,"MT5Config"),UZr.forEach(t),wKe=r(Swe," (MT5 model)"),Swe.forEach(t),AKe=i(L),Vm=n(L,"LI",{});var Rwe=s(Vm);Pae=n(Rwe,"STRONG",{});var JZr=s(Pae);LKe=r(JZr,"nezha"),JZr.forEach(t),yKe=r(Rwe," \u2014 "),FR=n(Rwe,"A",{href:!0});var YZr=s(FR);xKe=r(YZr,"NezhaConfig"),YZr.forEach(t),$Ke=r(Rwe," (Nezha model)"),Rwe.forEach(t),kKe=i(L),Xm=n(L,"LI",{});var Pwe=s(Xm);Bae=n(Pwe,"STRONG",{});var KZr=s(Bae);SKe=r(KZr,"nystromformer"),KZr.forEach(t),RKe=r(Pwe," \u2014 "),TR=n(Pwe,"A",{href:!0});var ZZr=s(TR);PKe=r(ZZr,"NystromformerConfig"),ZZr.forEach(t),BKe=r(Pwe," (Nystr\xF6mformer model)"),Pwe.forEach(t),IKe=i(L),zm=n(L,"LI",{});var Bwe=s(zm);Iae=n(Bwe,"STRONG",{});var eet=s(Iae);NKe=r(eet,"openai-gpt"),eet.forEach(t),qKe=r(Bwe," \u2014 "),MR=n(Bwe,"A",{href:!0});var oet=s(MR);jKe=r(oet,"OpenAIGPTConfig"),oet.forEach(t),DKe=r(Bwe," (OpenAI GPT model)"),Bwe.forEach(t),GKe=i(L),Qm=n(L,"LI",{});var Iwe=s(Qm);Nae=n(Iwe,"STRONG",{});var ret=s(Nae);OKe=r(ret,"opt"),ret.forEach(t),VKe=r(Iwe," \u2014 "),ER=n(Iwe,"A",{href:!0});var tet=s(ER);XKe=r(tet,"OPTConfig"),tet.forEach(t),zKe=r(Iwe," (OPT model)"),Iwe.forEach(t),QKe=i(L),Wm=n(L,"LI",{});var Nwe=s(Wm);qae=n(Nwe,"STRONG",{});var aet=s(qae);WKe=r(aet,"pegasus"),aet.forEach(t),HKe=r(Nwe," \u2014 "),CR=n(Nwe,"A",{href:!0});var net=s(CR);UKe=r(net,"PegasusConfig"),net.forEach(t),JKe=r(Nwe," (Pegasus model)"),Nwe.forEach(t),YKe=i(L),Hm=n(L,"LI",{});var qwe=s(Hm);jae=n(qwe,"STRONG",{});var set=s(jae);KKe=r(set,"perceiver"),set.forEach(t),ZKe=r(qwe," \u2014 "),wR=n(qwe,"A",{href:!0});var iet=s(wR);eZe=r(iet,"PerceiverConfig"),iet.forEach(t),oZe=r(qwe," (Perceiver model)"),qwe.forEach(t),rZe=i(L),Um=n(L,"LI",{});var jwe=s(Um);Dae=n(jwe,"STRONG",{});var det=s(Dae);tZe=r(det,"plbart"),det.forEach(t),aZe=r(jwe," \u2014 "),AR=n(jwe,"A",{href:!0});var cet=s(AR);nZe=r(cet,"PLBartConfig"),cet.forEach(t),sZe=r(jwe," (PLBart model)"),jwe.forEach(t),lZe=i(L),Jm=n(L,"LI",{});var Dwe=s(Jm);Gae=n(Dwe,"STRONG",{});var fet=s(Gae);iZe=r(fet,"poolformer"),fet.forEach(t),dZe=r(Dwe," \u2014 "),LR=n(Dwe,"A",{href:!0});var met=s(LR);cZe=r(met,"PoolFormerConfig"),met.forEach(t),fZe=r(Dwe," (PoolFormer model)"),Dwe.forEach(t),mZe=i(L),Ym=n(L,"LI",{});var Gwe=s(Ym);Oae=n(Gwe,"STRONG",{});var get=s(Oae);gZe=r(get,"prophetnet"),get.forEach(t),hZe=r(Gwe," \u2014 "),yR=n(Gwe,"A",{href:!0});var het=s(yR);pZe=r(het,"ProphetNetConfig"),het.forEach(t),_Ze=r(Gwe," (ProphetNet model)"),Gwe.forEach(t),uZe=i(L),Km=n(L,"LI",{});var Owe=s(Km);Vae=n(Owe,"STRONG",{});var pet=s(Vae);bZe=r(pet,"qdqbert"),pet.forEach(t),vZe=r(Owe," \u2014 "),xR=n(Owe,"A",{href:!0});var _et=s(xR);FZe=r(_et,"QDQBertConfig"),_et.forEach(t),TZe=r(Owe," (QDQBert model)"),Owe.forEach(t),MZe=i(L),Zm=n(L,"LI",{});var Vwe=s(Zm);Xae=n(Vwe,"STRONG",{});var uet=s(Xae);EZe=r(uet,"rag"),uet.forEach(t),CZe=r(Vwe," \u2014 "),$R=n(Vwe,"A",{href:!0});var bet=s($R);wZe=r(bet,"RagConfig"),bet.forEach(t),AZe=r(Vwe," (RAG model)"),Vwe.forEach(t),LZe=i(L),eg=n(L,"LI",{});var Xwe=s(eg);zae=n(Xwe,"STRONG",{});var vet=s(zae);yZe=r(vet,"realm"),vet.forEach(t),xZe=r(Xwe," \u2014 "),kR=n(Xwe,"A",{href:!0});var Fet=s(kR);$Ze=r(Fet,"RealmConfig"),Fet.forEach(t),kZe=r(Xwe," (REALM model)"),Xwe.forEach(t),SZe=i(L),og=n(L,"LI",{});var zwe=s(og);Qae=n(zwe,"STRONG",{});var Tet=s(Qae);RZe=r(Tet,"reformer"),Tet.forEach(t),PZe=r(zwe," \u2014 "),SR=n(zwe,"A",{href:!0});var Met=s(SR);BZe=r(Met,"ReformerConfig"),Met.forEach(t),IZe=r(zwe," (Reformer model)"),zwe.forEach(t),NZe=i(L),rg=n(L,"LI",{});var Qwe=s(rg);Wae=n(Qwe,"STRONG",{});var Eet=s(Wae);qZe=r(Eet,"regnet"),Eet.forEach(t),jZe=r(Qwe," \u2014 "),RR=n(Qwe,"A",{href:!0});var Cet=s(RR);DZe=r(Cet,"RegNetConfig"),Cet.forEach(t),GZe=r(Qwe," (RegNet model)"),Qwe.forEach(t),OZe=i(L),tg=n(L,"LI",{});var Wwe=s(tg);Hae=n(Wwe,"STRONG",{});var wet=s(Hae);VZe=r(wet,"rembert"),wet.forEach(t),XZe=r(Wwe," \u2014 "),PR=n(Wwe,"A",{href:!0});var Aet=s(PR);zZe=r(Aet,"RemBertConfig"),Aet.forEach(t),QZe=r(Wwe," (RemBERT model)"),Wwe.forEach(t),WZe=i(L),ag=n(L,"LI",{});var Hwe=s(ag);Uae=n(Hwe,"STRONG",{});var Let=s(Uae);HZe=r(Let,"resnet"),Let.forEach(t),UZe=r(Hwe," \u2014 "),BR=n(Hwe,"A",{href:!0});var yet=s(BR);JZe=r(yet,"ResNetConfig"),yet.forEach(t),YZe=r(Hwe," (ResNet model)"),Hwe.forEach(t),KZe=i(L),ng=n(L,"LI",{});var Uwe=s(ng);Jae=n(Uwe,"STRONG",{});var xet=s(Jae);ZZe=r(xet,"retribert"),xet.forEach(t),eeo=r(Uwe," \u2014 "),IR=n(Uwe,"A",{href:!0});var $et=s(IR);oeo=r($et,"RetriBertConfig"),$et.forEach(t),reo=r(Uwe," (RetriBERT model)"),Uwe.forEach(t),teo=i(L),sg=n(L,"LI",{});var Jwe=s(sg);Yae=n(Jwe,"STRONG",{});var ket=s(Yae);aeo=r(ket,"roberta"),ket.forEach(t),neo=r(Jwe," \u2014 "),NR=n(Jwe,"A",{href:!0});var Set=s(NR);seo=r(Set,"RobertaConfig"),Set.forEach(t),leo=r(Jwe," (RoBERTa model)"),Jwe.forEach(t),ieo=i(L),lg=n(L,"LI",{});var Ywe=s(lg);Kae=n(Ywe,"STRONG",{});var Ret=s(Kae);deo=r(Ret,"roformer"),Ret.forEach(t),ceo=r(Ywe," \u2014 "),qR=n(Ywe,"A",{href:!0});var Pet=s(qR);feo=r(Pet,"RoFormerConfig"),Pet.forEach(t),meo=r(Ywe," (RoFormer model)"),Ywe.forEach(t),geo=i(L),ig=n(L,"LI",{});var Kwe=s(ig);Zae=n(Kwe,"STRONG",{});var Bet=s(Zae);heo=r(Bet,"segformer"),Bet.forEach(t),peo=r(Kwe," \u2014 "),jR=n(Kwe,"A",{href:!0});var Iet=s(jR);_eo=r(Iet,"SegformerConfig"),Iet.forEach(t),ueo=r(Kwe," (SegFormer model)"),Kwe.forEach(t),beo=i(L),dg=n(L,"LI",{});var Zwe=s(dg);ene=n(Zwe,"STRONG",{});var Net=s(ene);veo=r(Net,"sew"),Net.forEach(t),Feo=r(Zwe," \u2014 "),DR=n(Zwe,"A",{href:!0});var qet=s(DR);Teo=r(qet,"SEWConfig"),qet.forEach(t),Meo=r(Zwe," (SEW model)"),Zwe.forEach(t),Eeo=i(L),cg=n(L,"LI",{});var eAe=s(cg);one=n(eAe,"STRONG",{});var jet=s(one);Ceo=r(jet,"sew-d"),jet.forEach(t),weo=r(eAe," \u2014 "),GR=n(eAe,"A",{href:!0});var Det=s(GR);Aeo=r(Det,"SEWDConfig"),Det.forEach(t),Leo=r(eAe," (SEW-D model)"),eAe.forEach(t),yeo=i(L),fg=n(L,"LI",{});var oAe=s(fg);rne=n(oAe,"STRONG",{});var Get=s(rne);xeo=r(Get,"speech-encoder-decoder"),Get.forEach(t),$eo=r(oAe," \u2014 "),OR=n(oAe,"A",{href:!0});var Oet=s(OR);keo=r(Oet,"SpeechEncoderDecoderConfig"),Oet.forEach(t),Seo=r(oAe," (Speech Encoder decoder model)"),oAe.forEach(t),Reo=i(L),mg=n(L,"LI",{});var rAe=s(mg);tne=n(rAe,"STRONG",{});var Vet=s(tne);Peo=r(Vet,"speech_to_text"),Vet.forEach(t),Beo=r(rAe," \u2014 "),VR=n(rAe,"A",{href:!0});var Xet=s(VR);Ieo=r(Xet,"Speech2TextConfig"),Xet.forEach(t),Neo=r(rAe," (Speech2Text model)"),rAe.forEach(t),qeo=i(L),gg=n(L,"LI",{});var tAe=s(gg);ane=n(tAe,"STRONG",{});var zet=s(ane);jeo=r(zet,"speech_to_text_2"),zet.forEach(t),Deo=r(tAe," \u2014 "),XR=n(tAe,"A",{href:!0});var Qet=s(XR);Geo=r(Qet,"Speech2Text2Config"),Qet.forEach(t),Oeo=r(tAe," (Speech2Text2 model)"),tAe.forEach(t),Veo=i(L),hg=n(L,"LI",{});var aAe=s(hg);nne=n(aAe,"STRONG",{});var Wet=s(nne);Xeo=r(Wet,"splinter"),Wet.forEach(t),zeo=r(aAe," \u2014 "),zR=n(aAe,"A",{href:!0});var Het=s(zR);Qeo=r(Het,"SplinterConfig"),Het.forEach(t),Weo=r(aAe," (Splinter model)"),aAe.forEach(t),Heo=i(L),pg=n(L,"LI",{});var nAe=s(pg);sne=n(nAe,"STRONG",{});var Uet=s(sne);Ueo=r(Uet,"squeezebert"),Uet.forEach(t),Jeo=r(nAe," \u2014 "),QR=n(nAe,"A",{href:!0});var Jet=s(QR);Yeo=r(Jet,"SqueezeBertConfig"),Jet.forEach(t),Keo=r(nAe," (SqueezeBERT model)"),nAe.forEach(t),Zeo=i(L),_g=n(L,"LI",{});var sAe=s(_g);lne=n(sAe,"STRONG",{});var Yet=s(lne);eoo=r(Yet,"swin"),Yet.forEach(t),ooo=r(sAe," \u2014 "),WR=n(sAe,"A",{href:!0});var Ket=s(WR);roo=r(Ket,"SwinConfig"),Ket.forEach(t),too=r(sAe," (Swin Transformer model)"),sAe.forEach(t),aoo=i(L),ug=n(L,"LI",{});var lAe=s(ug);ine=n(lAe,"STRONG",{});var Zet=s(ine);noo=r(Zet,"t5"),Zet.forEach(t),soo=r(lAe," \u2014 "),HR=n(lAe,"A",{href:!0});var eot=s(HR);loo=r(eot,"T5Config"),eot.forEach(t),ioo=r(lAe," (T5 model)"),lAe.forEach(t),doo=i(L),bg=n(L,"LI",{});var iAe=s(bg);dne=n(iAe,"STRONG",{});var oot=s(dne);coo=r(oot,"tapas"),oot.forEach(t),foo=r(iAe," \u2014 "),UR=n(iAe,"A",{href:!0});var rot=s(UR);moo=r(rot,"TapasConfig"),rot.forEach(t),goo=r(iAe," (TAPAS model)"),iAe.forEach(t),hoo=i(L),vg=n(L,"LI",{});var dAe=s(vg);cne=n(dAe,"STRONG",{});var tot=s(cne);poo=r(tot,"trajectory_transformer"),tot.forEach(t),_oo=r(dAe," \u2014 "),JR=n(dAe,"A",{href:!0});var aot=s(JR);uoo=r(aot,"TrajectoryTransformerConfig"),aot.forEach(t),boo=r(dAe," (Trajectory Transformer model)"),dAe.forEach(t),voo=i(L),Fg=n(L,"LI",{});var cAe=s(Fg);fne=n(cAe,"STRONG",{});var not=s(fne);Foo=r(not,"transfo-xl"),not.forEach(t),Too=r(cAe," \u2014 "),YR=n(cAe,"A",{href:!0});var sot=s(YR);Moo=r(sot,"TransfoXLConfig"),sot.forEach(t),Eoo=r(cAe," (Transformer-XL model)"),cAe.forEach(t),Coo=i(L),Tg=n(L,"LI",{});var fAe=s(Tg);mne=n(fAe,"STRONG",{});var lot=s(mne);woo=r(lot,"trocr"),lot.forEach(t),Aoo=r(fAe," \u2014 "),KR=n(fAe,"A",{href:!0});var iot=s(KR);Loo=r(iot,"TrOCRConfig"),iot.forEach(t),yoo=r(fAe," (TrOCR model)"),fAe.forEach(t),xoo=i(L),Mg=n(L,"LI",{});var mAe=s(Mg);gne=n(mAe,"STRONG",{});var dot=s(gne);$oo=r(dot,"unispeech"),dot.forEach(t),koo=r(mAe," \u2014 "),ZR=n(mAe,"A",{href:!0});var cot=s(ZR);Soo=r(cot,"UniSpeechConfig"),cot.forEach(t),Roo=r(mAe," (UniSpeech model)"),mAe.forEach(t),Poo=i(L),Eg=n(L,"LI",{});var gAe=s(Eg);hne=n(gAe,"STRONG",{});var fot=s(hne);Boo=r(fot,"unispeech-sat"),fot.forEach(t),Ioo=r(gAe," \u2014 "),eP=n(gAe,"A",{href:!0});var mot=s(eP);Noo=r(mot,"UniSpeechSatConfig"),mot.forEach(t),qoo=r(gAe," (UniSpeechSat model)"),gAe.forEach(t),joo=i(L),Cg=n(L,"LI",{});var hAe=s(Cg);pne=n(hAe,"STRONG",{});var got=s(pne);Doo=r(got,"van"),got.forEach(t),Goo=r(hAe," \u2014 "),oP=n(hAe,"A",{href:!0});var hot=s(oP);Ooo=r(hot,"VanConfig"),hot.forEach(t),Voo=r(hAe," (VAN model)"),hAe.forEach(t),Xoo=i(L),wg=n(L,"LI",{});var pAe=s(wg);_ne=n(pAe,"STRONG",{});var pot=s(_ne);zoo=r(pot,"vilt"),pot.forEach(t),Qoo=r(pAe," \u2014 "),rP=n(pAe,"A",{href:!0});var _ot=s(rP);Woo=r(_ot,"ViltConfig"),_ot.forEach(t),Hoo=r(pAe," (ViLT model)"),pAe.forEach(t),Uoo=i(L),Ag=n(L,"LI",{});var _Ae=s(Ag);une=n(_Ae,"STRONG",{});var uot=s(une);Joo=r(uot,"vision-encoder-decoder"),uot.forEach(t),Yoo=r(_Ae," \u2014 "),tP=n(_Ae,"A",{href:!0});var bot=s(tP);Koo=r(bot,"VisionEncoderDecoderConfig"),bot.forEach(t),Zoo=r(_Ae," (Vision Encoder decoder model)"),_Ae.forEach(t),ero=i(L),Lg=n(L,"LI",{});var uAe=s(Lg);bne=n(uAe,"STRONG",{});var vot=s(bne);oro=r(vot,"vision-text-dual-encoder"),vot.forEach(t),rro=r(uAe," \u2014 "),aP=n(uAe,"A",{href:!0});var Fot=s(aP);tro=r(Fot,"VisionTextDualEncoderConfig"),Fot.forEach(t),aro=r(uAe," (VisionTextDualEncoder model)"),uAe.forEach(t),nro=i(L),yg=n(L,"LI",{});var bAe=s(yg);vne=n(bAe,"STRONG",{});var Tot=s(vne);sro=r(Tot,"visual_bert"),Tot.forEach(t),lro=r(bAe," \u2014 "),nP=n(bAe,"A",{href:!0});var Mot=s(nP);iro=r(Mot,"VisualBertConfig"),Mot.forEach(t),dro=r(bAe," (VisualBERT model)"),bAe.forEach(t),cro=i(L),xg=n(L,"LI",{});var vAe=s(xg);Fne=n(vAe,"STRONG",{});var Eot=s(Fne);fro=r(Eot,"vit"),Eot.forEach(t),mro=r(vAe," \u2014 "),sP=n(vAe,"A",{href:!0});var Cot=s(sP);gro=r(Cot,"ViTConfig"),Cot.forEach(t),hro=r(vAe," (ViT model)"),vAe.forEach(t),pro=i(L),$g=n(L,"LI",{});var FAe=s($g);Tne=n(FAe,"STRONG",{});var wot=s(Tne);_ro=r(wot,"vit_mae"),wot.forEach(t),uro=r(FAe," \u2014 "),lP=n(FAe,"A",{href:!0});var Aot=s(lP);bro=r(Aot,"ViTMAEConfig"),Aot.forEach(t),vro=r(FAe," (ViTMAE model)"),FAe.forEach(t),Fro=i(L),kg=n(L,"LI",{});var TAe=s(kg);Mne=n(TAe,"STRONG",{});var Lot=s(Mne);Tro=r(Lot,"wav2vec2"),Lot.forEach(t),Mro=r(TAe," \u2014 "),iP=n(TAe,"A",{href:!0});var yot=s(iP);Ero=r(yot,"Wav2Vec2Config"),yot.forEach(t),Cro=r(TAe," (Wav2Vec2 model)"),TAe.forEach(t),wro=i(L),Sg=n(L,"LI",{});var MAe=s(Sg);Ene=n(MAe,"STRONG",{});var xot=s(Ene);Aro=r(xot,"wav2vec2-conformer"),xot.forEach(t),Lro=r(MAe," \u2014 "),dP=n(MAe,"A",{href:!0});var $ot=s(dP);yro=r($ot,"Wav2Vec2ConformerConfig"),$ot.forEach(t),xro=r(MAe," (Wav2Vec2-Conformer model)"),MAe.forEach(t),$ro=i(L),Rg=n(L,"LI",{});var EAe=s(Rg);Cne=n(EAe,"STRONG",{});var kot=s(Cne);kro=r(kot,"wavlm"),kot.forEach(t),Sro=r(EAe," \u2014 "),cP=n(EAe,"A",{href:!0});var Sot=s(cP);Rro=r(Sot,"WavLMConfig"),Sot.forEach(t),Pro=r(EAe," (WavLM model)"),EAe.forEach(t),Bro=i(L),Pg=n(L,"LI",{});var CAe=s(Pg);wne=n(CAe,"STRONG",{});var Rot=s(wne);Iro=r(Rot,"xglm"),Rot.forEach(t),Nro=r(CAe," \u2014 "),fP=n(CAe,"A",{href:!0});var Pot=s(fP);qro=r(Pot,"XGLMConfig"),Pot.forEach(t),jro=r(CAe," (XGLM model)"),CAe.forEach(t),Dro=i(L),Bg=n(L,"LI",{});var wAe=s(Bg);Ane=n(wAe,"STRONG",{});var Bot=s(Ane);Gro=r(Bot,"xlm"),Bot.forEach(t),Oro=r(wAe," \u2014 "),mP=n(wAe,"A",{href:!0});var Iot=s(mP);Vro=r(Iot,"XLMConfig"),Iot.forEach(t),Xro=r(wAe," (XLM model)"),wAe.forEach(t),zro=i(L),Ig=n(L,"LI",{});var AAe=s(Ig);Lne=n(AAe,"STRONG",{});var Not=s(Lne);Qro=r(Not,"xlm-prophetnet"),Not.forEach(t),Wro=r(AAe," \u2014 "),gP=n(AAe,"A",{href:!0});var qot=s(gP);Hro=r(qot,"XLMProphetNetConfig"),qot.forEach(t),Uro=r(AAe," (XLM-ProphetNet model)"),AAe.forEach(t),Jro=i(L),Ng=n(L,"LI",{});var LAe=s(Ng);yne=n(LAe,"STRONG",{});var jot=s(yne);Yro=r(jot,"xlm-roberta"),jot.forEach(t),Kro=r(LAe," \u2014 "),hP=n(LAe,"A",{href:!0});var Dot=s(hP);Zro=r(Dot,"XLMRobertaConfig"),Dot.forEach(t),eto=r(LAe," (XLM-RoBERTa model)"),LAe.forEach(t),oto=i(L),qg=n(L,"LI",{});var yAe=s(qg);xne=n(yAe,"STRONG",{});var Got=s(xne);rto=r(Got,"xlm-roberta-xl"),Got.forEach(t),tto=r(yAe," \u2014 "),pP=n(yAe,"A",{href:!0});var Oot=s(pP);ato=r(Oot,"XLMRobertaXLConfig"),Oot.forEach(t),nto=r(yAe," (XLM-RoBERTa-XL model)"),yAe.forEach(t),sto=i(L),jg=n(L,"LI",{});var xAe=s(jg);$ne=n(xAe,"STRONG",{});var Vot=s($ne);lto=r(Vot,"xlnet"),Vot.forEach(t),ito=r(xAe," \u2014 "),_P=n(xAe,"A",{href:!0});var Xot=s(_P);dto=r(Xot,"XLNetConfig"),Xot.forEach(t),cto=r(xAe," (XLNet model)"),xAe.forEach(t),fto=i(L),Dg=n(L,"LI",{});var $Ae=s(Dg);kne=n($Ae,"STRONG",{});var zot=s(kne);mto=r(zot,"yolos"),zot.forEach(t),gto=r($Ae," \u2014 "),uP=n($Ae,"A",{href:!0});var Qot=s(uP);hto=r(Qot,"YolosConfig"),Qot.forEach(t),pto=r($Ae," (YOLOS model)"),$Ae.forEach(t),_to=i(L),Gg=n(L,"LI",{});var kAe=s(Gg);Sne=n(kAe,"STRONG",{});var Wot=s(Sne);uto=r(Wot,"yoso"),Wot.forEach(t),bto=r(kAe," \u2014 "),bP=n(kAe,"A",{href:!0});var Hot=s(bP);vto=r(Hot,"YosoConfig"),Hot.forEach(t),Fto=r(kAe," (YOSO model)"),kAe.forEach(t),L.forEach(t),Tto=i(tt),T(Og.$$.fragment,tt),tt.forEach(t),Mto=i(rt),Vg=n(rt,"DIV",{class:!0});var tXe=s(Vg);T(jA.$$.fragment,tXe),Eto=i(tXe),Rne=n(tXe,"P",{});var Uot=s(Rne);Cto=r(Uot,"Register a new configuration for this class."),Uot.forEach(t),tXe.forEach(t),rt.forEach(t),aOe=i(f),ki=n(f,"H2",{class:!0});var aXe=s(ki);Xg=n(aXe,"A",{id:!0,class:!0,href:!0});var Jot=s(Xg);Pne=n(Jot,"SPAN",{});var Yot=s(Pne);T(DA.$$.fragment,Yot),Yot.forEach(t),Jot.forEach(t),wto=i(aXe),Bne=n(aXe,"SPAN",{});var Kot=s(Bne);Ato=r(Kot,"AutoTokenizer"),Kot.forEach(t),aXe.forEach(t),nOe=i(f),Ao=n(f,"DIV",{class:!0});var Ws=s(Ao);T(GA.$$.fragment,Ws),Lto=i(Ws),OA=n(Ws,"P",{});var nXe=s(OA);yto=r(nXe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),vP=n(nXe,"A",{href:!0});var Zot=s(vP);xto=r(Zot,"AutoTokenizer.from_pretrained()"),Zot.forEach(t),$to=r(nXe," class method."),nXe.forEach(t),kto=i(Ws),VA=n(Ws,"P",{});var sXe=s(VA);Sto=r(sXe,"This class cannot be instantiated directly using "),Ine=n(sXe,"CODE",{});var ert=s(Ine);Rto=r(ert,"__init__()"),ert.forEach(t),Pto=r(sXe," (throws an error)."),sXe.forEach(t),Bto=i(Ws),Lr=n(Ws,"DIV",{class:!0});var Hs=s(Lr);T(XA.$$.fragment,Hs),Ito=i(Hs),Nne=n(Hs,"P",{});var ort=s(Nne);Nto=r(ort,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),ort.forEach(t),qto=i(Hs),ka=n(Hs,"P",{});var S0=s(ka);jto=r(S0,"The tokenizer class to instantiate is selected based on the "),qne=n(S0,"CODE",{});var rrt=s(qne);Dto=r(rrt,"model_type"),rrt.forEach(t),Gto=r(S0,` property of the config object (either
passed as an argument or loaded from `),jne=n(S0,"CODE",{});var trt=s(jne);Oto=r(trt,"pretrained_model_name_or_path"),trt.forEach(t),Vto=r(S0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dne=n(S0,"CODE",{});var art=s(Dne);Xto=r(art,"pretrained_model_name_or_path"),art.forEach(t),zto=r(S0,":"),S0.forEach(t),Qto=i(Hs),k=n(Hs,"UL",{});var S=s(k);qn=n(S,"LI",{});var J$=s(qn);Gne=n(J$,"STRONG",{});var nrt=s(Gne);Wto=r(nrt,"albert"),nrt.forEach(t),Hto=r(J$," \u2014 "),FP=n(J$,"A",{href:!0});var srt=s(FP);Uto=r(srt,"AlbertTokenizer"),srt.forEach(t),Jto=r(J$," or "),TP=n(J$,"A",{href:!0});var lrt=s(TP);Yto=r(lrt,"AlbertTokenizerFast"),lrt.forEach(t),Kto=r(J$," (ALBERT model)"),J$.forEach(t),Zto=i(S),jn=n(S,"LI",{});var Y$=s(jn);One=n(Y$,"STRONG",{});var irt=s(One);eao=r(irt,"bart"),irt.forEach(t),oao=r(Y$," \u2014 "),MP=n(Y$,"A",{href:!0});var drt=s(MP);rao=r(drt,"BartTokenizer"),drt.forEach(t),tao=r(Y$," or "),EP=n(Y$,"A",{href:!0});var crt=s(EP);aao=r(crt,"BartTokenizerFast"),crt.forEach(t),nao=r(Y$," (BART model)"),Y$.forEach(t),sao=i(S),Dn=n(S,"LI",{});var K$=s(Dn);Vne=n(K$,"STRONG",{});var frt=s(Vne);lao=r(frt,"barthez"),frt.forEach(t),iao=r(K$," \u2014 "),CP=n(K$,"A",{href:!0});var mrt=s(CP);dao=r(mrt,"BarthezTokenizer"),mrt.forEach(t),cao=r(K$," or "),wP=n(K$,"A",{href:!0});var grt=s(wP);fao=r(grt,"BarthezTokenizerFast"),grt.forEach(t),mao=r(K$," (BARThez model)"),K$.forEach(t),gao=i(S),zg=n(S,"LI",{});var SAe=s(zg);Xne=n(SAe,"STRONG",{});var hrt=s(Xne);hao=r(hrt,"bartpho"),hrt.forEach(t),pao=r(SAe," \u2014 "),AP=n(SAe,"A",{href:!0});var prt=s(AP);_ao=r(prt,"BartphoTokenizer"),prt.forEach(t),uao=r(SAe," (BARTpho model)"),SAe.forEach(t),bao=i(S),Gn=n(S,"LI",{});var Z$=s(Gn);zne=n(Z$,"STRONG",{});var _rt=s(zne);vao=r(_rt,"bert"),_rt.forEach(t),Fao=r(Z$," \u2014 "),LP=n(Z$,"A",{href:!0});var urt=s(LP);Tao=r(urt,"BertTokenizer"),urt.forEach(t),Mao=r(Z$," or "),yP=n(Z$,"A",{href:!0});var brt=s(yP);Eao=r(brt,"BertTokenizerFast"),brt.forEach(t),Cao=r(Z$," (BERT model)"),Z$.forEach(t),wao=i(S),Qg=n(S,"LI",{});var RAe=s(Qg);Qne=n(RAe,"STRONG",{});var vrt=s(Qne);Aao=r(vrt,"bert-generation"),vrt.forEach(t),Lao=r(RAe," \u2014 "),xP=n(RAe,"A",{href:!0});var Frt=s(xP);yao=r(Frt,"BertGenerationTokenizer"),Frt.forEach(t),xao=r(RAe," (Bert Generation model)"),RAe.forEach(t),$ao=i(S),Wg=n(S,"LI",{});var PAe=s(Wg);Wne=n(PAe,"STRONG",{});var Trt=s(Wne);kao=r(Trt,"bert-japanese"),Trt.forEach(t),Sao=r(PAe," \u2014 "),$P=n(PAe,"A",{href:!0});var Mrt=s($P);Rao=r(Mrt,"BertJapaneseTokenizer"),Mrt.forEach(t),Pao=r(PAe," (BertJapanese model)"),PAe.forEach(t),Bao=i(S),Hg=n(S,"LI",{});var BAe=s(Hg);Hne=n(BAe,"STRONG",{});var Ert=s(Hne);Iao=r(Ert,"bertweet"),Ert.forEach(t),Nao=r(BAe," \u2014 "),kP=n(BAe,"A",{href:!0});var Crt=s(kP);qao=r(Crt,"BertweetTokenizer"),Crt.forEach(t),jao=r(BAe," (BERTweet model)"),BAe.forEach(t),Dao=i(S),On=n(S,"LI",{});var ek=s(On);Une=n(ek,"STRONG",{});var wrt=s(Une);Gao=r(wrt,"big_bird"),wrt.forEach(t),Oao=r(ek," \u2014 "),SP=n(ek,"A",{href:!0});var Art=s(SP);Vao=r(Art,"BigBirdTokenizer"),Art.forEach(t),Xao=r(ek," or "),RP=n(ek,"A",{href:!0});var Lrt=s(RP);zao=r(Lrt,"BigBirdTokenizerFast"),Lrt.forEach(t),Qao=r(ek," (BigBird model)"),ek.forEach(t),Wao=i(S),Vn=n(S,"LI",{});var ok=s(Vn);Jne=n(ok,"STRONG",{});var yrt=s(Jne);Hao=r(yrt,"bigbird_pegasus"),yrt.forEach(t),Uao=r(ok," \u2014 "),PP=n(ok,"A",{href:!0});var xrt=s(PP);Jao=r(xrt,"PegasusTokenizer"),xrt.forEach(t),Yao=r(ok," or "),BP=n(ok,"A",{href:!0});var $rt=s(BP);Kao=r($rt,"PegasusTokenizerFast"),$rt.forEach(t),Zao=r(ok," (BigBird-Pegasus model)"),ok.forEach(t),eno=i(S),Xn=n(S,"LI",{});var rk=s(Xn);Yne=n(rk,"STRONG",{});var krt=s(Yne);ono=r(krt,"blenderbot"),krt.forEach(t),rno=r(rk," \u2014 "),IP=n(rk,"A",{href:!0});var Srt=s(IP);tno=r(Srt,"BlenderbotTokenizer"),Srt.forEach(t),ano=r(rk," or "),NP=n(rk,"A",{href:!0});var Rrt=s(NP);nno=r(Rrt,"BlenderbotTokenizerFast"),Rrt.forEach(t),sno=r(rk," (Blenderbot model)"),rk.forEach(t),lno=i(S),Ug=n(S,"LI",{});var IAe=s(Ug);Kne=n(IAe,"STRONG",{});var Prt=s(Kne);ino=r(Prt,"blenderbot-small"),Prt.forEach(t),dno=r(IAe," \u2014 "),qP=n(IAe,"A",{href:!0});var Brt=s(qP);cno=r(Brt,"BlenderbotSmallTokenizer"),Brt.forEach(t),fno=r(IAe," (BlenderbotSmall model)"),IAe.forEach(t),mno=i(S),Jg=n(S,"LI",{});var NAe=s(Jg);Zne=n(NAe,"STRONG",{});var Irt=s(Zne);gno=r(Irt,"bloom"),Irt.forEach(t),hno=r(NAe," \u2014 "),jP=n(NAe,"A",{href:!0});var Nrt=s(jP);pno=r(Nrt,"BloomTokenizerFast"),Nrt.forEach(t),_no=r(NAe," (BLOOM model)"),NAe.forEach(t),uno=i(S),Yg=n(S,"LI",{});var qAe=s(Yg);ese=n(qAe,"STRONG",{});var qrt=s(ese);bno=r(qrt,"byt5"),qrt.forEach(t),vno=r(qAe," \u2014 "),DP=n(qAe,"A",{href:!0});var jrt=s(DP);Fno=r(jrt,"ByT5Tokenizer"),jrt.forEach(t),Tno=r(qAe," (ByT5 model)"),qAe.forEach(t),Mno=i(S),zn=n(S,"LI",{});var tk=s(zn);ose=n(tk,"STRONG",{});var Drt=s(ose);Eno=r(Drt,"camembert"),Drt.forEach(t),Cno=r(tk," \u2014 "),GP=n(tk,"A",{href:!0});var Grt=s(GP);wno=r(Grt,"CamembertTokenizer"),Grt.forEach(t),Ano=r(tk," or "),OP=n(tk,"A",{href:!0});var Ort=s(OP);Lno=r(Ort,"CamembertTokenizerFast"),Ort.forEach(t),yno=r(tk," (CamemBERT model)"),tk.forEach(t),xno=i(S),Kg=n(S,"LI",{});var jAe=s(Kg);rse=n(jAe,"STRONG",{});var Vrt=s(rse);$no=r(Vrt,"canine"),Vrt.forEach(t),kno=r(jAe," \u2014 "),VP=n(jAe,"A",{href:!0});var Xrt=s(VP);Sno=r(Xrt,"CanineTokenizer"),Xrt.forEach(t),Rno=r(jAe," (CANINE model)"),jAe.forEach(t),Pno=i(S),Qn=n(S,"LI",{});var ak=s(Qn);tse=n(ak,"STRONG",{});var zrt=s(tse);Bno=r(zrt,"clip"),zrt.forEach(t),Ino=r(ak," \u2014 "),XP=n(ak,"A",{href:!0});var Qrt=s(XP);Nno=r(Qrt,"CLIPTokenizer"),Qrt.forEach(t),qno=r(ak," or "),zP=n(ak,"A",{href:!0});var Wrt=s(zP);jno=r(Wrt,"CLIPTokenizerFast"),Wrt.forEach(t),Dno=r(ak," (CLIP model)"),ak.forEach(t),Gno=i(S),Wn=n(S,"LI",{});var nk=s(Wn);ase=n(nk,"STRONG",{});var Hrt=s(ase);Ono=r(Hrt,"convbert"),Hrt.forEach(t),Vno=r(nk," \u2014 "),QP=n(nk,"A",{href:!0});var Urt=s(QP);Xno=r(Urt,"ConvBertTokenizer"),Urt.forEach(t),zno=r(nk," or "),WP=n(nk,"A",{href:!0});var Jrt=s(WP);Qno=r(Jrt,"ConvBertTokenizerFast"),Jrt.forEach(t),Wno=r(nk," (ConvBERT model)"),nk.forEach(t),Hno=i(S),Hn=n(S,"LI",{});var sk=s(Hn);nse=n(sk,"STRONG",{});var Yrt=s(nse);Uno=r(Yrt,"cpm"),Yrt.forEach(t),Jno=r(sk," \u2014 "),HP=n(sk,"A",{href:!0});var Krt=s(HP);Yno=r(Krt,"CpmTokenizer"),Krt.forEach(t),Kno=r(sk," or "),UP=n(sk,"A",{href:!0});var Zrt=s(UP);Zno=r(Zrt,"CpmTokenizerFast"),Zrt.forEach(t),eso=r(sk," (CPM model)"),sk.forEach(t),oso=i(S),Zg=n(S,"LI",{});var DAe=s(Zg);sse=n(DAe,"STRONG",{});var ett=s(sse);rso=r(ett,"ctrl"),ett.forEach(t),tso=r(DAe," \u2014 "),JP=n(DAe,"A",{href:!0});var ott=s(JP);aso=r(ott,"CTRLTokenizer"),ott.forEach(t),nso=r(DAe," (CTRL model)"),DAe.forEach(t),sso=i(S),Un=n(S,"LI",{});var lk=s(Un);lse=n(lk,"STRONG",{});var rtt=s(lse);lso=r(rtt,"data2vec-text"),rtt.forEach(t),iso=r(lk," \u2014 "),YP=n(lk,"A",{href:!0});var ttt=s(YP);dso=r(ttt,"RobertaTokenizer"),ttt.forEach(t),cso=r(lk," or "),KP=n(lk,"A",{href:!0});var att=s(KP);fso=r(att,"RobertaTokenizerFast"),att.forEach(t),mso=r(lk," (Data2VecText model)"),lk.forEach(t),gso=i(S),Jn=n(S,"LI",{});var ik=s(Jn);ise=n(ik,"STRONG",{});var ntt=s(ise);hso=r(ntt,"deberta"),ntt.forEach(t),pso=r(ik," \u2014 "),ZP=n(ik,"A",{href:!0});var stt=s(ZP);_so=r(stt,"DebertaTokenizer"),stt.forEach(t),uso=r(ik," or "),eB=n(ik,"A",{href:!0});var ltt=s(eB);bso=r(ltt,"DebertaTokenizerFast"),ltt.forEach(t),vso=r(ik," (DeBERTa model)"),ik.forEach(t),Fso=i(S),Yn=n(S,"LI",{});var dk=s(Yn);dse=n(dk,"STRONG",{});var itt=s(dse);Tso=r(itt,"deberta-v2"),itt.forEach(t),Mso=r(dk," \u2014 "),oB=n(dk,"A",{href:!0});var dtt=s(oB);Eso=r(dtt,"DebertaV2Tokenizer"),dtt.forEach(t),Cso=r(dk," or "),rB=n(dk,"A",{href:!0});var ctt=s(rB);wso=r(ctt,"DebertaV2TokenizerFast"),ctt.forEach(t),Aso=r(dk," (DeBERTa-v2 model)"),dk.forEach(t),Lso=i(S),Kn=n(S,"LI",{});var ck=s(Kn);cse=n(ck,"STRONG",{});var ftt=s(cse);yso=r(ftt,"distilbert"),ftt.forEach(t),xso=r(ck," \u2014 "),tB=n(ck,"A",{href:!0});var mtt=s(tB);$so=r(mtt,"DistilBertTokenizer"),mtt.forEach(t),kso=r(ck," or "),aB=n(ck,"A",{href:!0});var gtt=s(aB);Sso=r(gtt,"DistilBertTokenizerFast"),gtt.forEach(t),Rso=r(ck," (DistilBERT model)"),ck.forEach(t),Pso=i(S),Zn=n(S,"LI",{});var fk=s(Zn);fse=n(fk,"STRONG",{});var htt=s(fse);Bso=r(htt,"dpr"),htt.forEach(t),Iso=r(fk," \u2014 "),nB=n(fk,"A",{href:!0});var ptt=s(nB);Nso=r(ptt,"DPRQuestionEncoderTokenizer"),ptt.forEach(t),qso=r(fk," or "),sB=n(fk,"A",{href:!0});var _tt=s(sB);jso=r(_tt,"DPRQuestionEncoderTokenizerFast"),_tt.forEach(t),Dso=r(fk," (DPR model)"),fk.forEach(t),Gso=i(S),es=n(S,"LI",{});var mk=s(es);mse=n(mk,"STRONG",{});var utt=s(mse);Oso=r(utt,"electra"),utt.forEach(t),Vso=r(mk," \u2014 "),lB=n(mk,"A",{href:!0});var btt=s(lB);Xso=r(btt,"ElectraTokenizer"),btt.forEach(t),zso=r(mk," or "),iB=n(mk,"A",{href:!0});var vtt=s(iB);Qso=r(vtt,"ElectraTokenizerFast"),vtt.forEach(t),Wso=r(mk," (ELECTRA model)"),mk.forEach(t),Hso=i(S),eh=n(S,"LI",{});var GAe=s(eh);gse=n(GAe,"STRONG",{});var Ftt=s(gse);Uso=r(Ftt,"flaubert"),Ftt.forEach(t),Jso=r(GAe," \u2014 "),dB=n(GAe,"A",{href:!0});var Ttt=s(dB);Yso=r(Ttt,"FlaubertTokenizer"),Ttt.forEach(t),Kso=r(GAe," (FlauBERT model)"),GAe.forEach(t),Zso=i(S),os=n(S,"LI",{});var gk=s(os);hse=n(gk,"STRONG",{});var Mtt=s(hse);elo=r(Mtt,"fnet"),Mtt.forEach(t),olo=r(gk," \u2014 "),cB=n(gk,"A",{href:!0});var Ett=s(cB);rlo=r(Ett,"FNetTokenizer"),Ett.forEach(t),tlo=r(gk," or "),fB=n(gk,"A",{href:!0});var Ctt=s(fB);alo=r(Ctt,"FNetTokenizerFast"),Ctt.forEach(t),nlo=r(gk," (FNet model)"),gk.forEach(t),slo=i(S),oh=n(S,"LI",{});var OAe=s(oh);pse=n(OAe,"STRONG",{});var wtt=s(pse);llo=r(wtt,"fsmt"),wtt.forEach(t),ilo=r(OAe," \u2014 "),mB=n(OAe,"A",{href:!0});var Att=s(mB);dlo=r(Att,"FSMTTokenizer"),Att.forEach(t),clo=r(OAe," (FairSeq Machine-Translation model)"),OAe.forEach(t),flo=i(S),rs=n(S,"LI",{});var hk=s(rs);_se=n(hk,"STRONG",{});var Ltt=s(_se);mlo=r(Ltt,"funnel"),Ltt.forEach(t),glo=r(hk," \u2014 "),gB=n(hk,"A",{href:!0});var ytt=s(gB);hlo=r(ytt,"FunnelTokenizer"),ytt.forEach(t),plo=r(hk," or "),hB=n(hk,"A",{href:!0});var xtt=s(hB);_lo=r(xtt,"FunnelTokenizerFast"),xtt.forEach(t),ulo=r(hk," (Funnel Transformer model)"),hk.forEach(t),blo=i(S),ts=n(S,"LI",{});var pk=s(ts);use=n(pk,"STRONG",{});var $tt=s(use);vlo=r($tt,"gpt2"),$tt.forEach(t),Flo=r(pk," \u2014 "),pB=n(pk,"A",{href:!0});var ktt=s(pB);Tlo=r(ktt,"GPT2Tokenizer"),ktt.forEach(t),Mlo=r(pk," or "),_B=n(pk,"A",{href:!0});var Stt=s(_B);Elo=r(Stt,"GPT2TokenizerFast"),Stt.forEach(t),Clo=r(pk," (OpenAI GPT-2 model)"),pk.forEach(t),wlo=i(S),as=n(S,"LI",{});var _k=s(as);bse=n(_k,"STRONG",{});var Rtt=s(bse);Alo=r(Rtt,"gpt_neo"),Rtt.forEach(t),Llo=r(_k," \u2014 "),uB=n(_k,"A",{href:!0});var Ptt=s(uB);ylo=r(Ptt,"GPT2Tokenizer"),Ptt.forEach(t),xlo=r(_k," or "),bB=n(_k,"A",{href:!0});var Btt=s(bB);$lo=r(Btt,"GPT2TokenizerFast"),Btt.forEach(t),klo=r(_k," (GPT Neo model)"),_k.forEach(t),Slo=i(S),rh=n(S,"LI",{});var VAe=s(rh);vse=n(VAe,"STRONG",{});var Itt=s(vse);Rlo=r(Itt,"gpt_neox"),Itt.forEach(t),Plo=r(VAe," \u2014 "),vB=n(VAe,"A",{href:!0});var Ntt=s(vB);Blo=r(Ntt,"GPTNeoXTokenizerFast"),Ntt.forEach(t),Ilo=r(VAe," (GPT NeoX model)"),VAe.forEach(t),Nlo=i(S),ns=n(S,"LI",{});var uk=s(ns);Fse=n(uk,"STRONG",{});var qtt=s(Fse);qlo=r(qtt,"gptj"),qtt.forEach(t),jlo=r(uk," \u2014 "),FB=n(uk,"A",{href:!0});var jtt=s(FB);Dlo=r(jtt,"GPT2Tokenizer"),jtt.forEach(t),Glo=r(uk," or "),TB=n(uk,"A",{href:!0});var Dtt=s(TB);Olo=r(Dtt,"GPT2TokenizerFast"),Dtt.forEach(t),Vlo=r(uk," (GPT-J model)"),uk.forEach(t),Xlo=i(S),ss=n(S,"LI",{});var bk=s(ss);Tse=n(bk,"STRONG",{});var Gtt=s(Tse);zlo=r(Gtt,"herbert"),Gtt.forEach(t),Qlo=r(bk," \u2014 "),MB=n(bk,"A",{href:!0});var Ott=s(MB);Wlo=r(Ott,"HerbertTokenizer"),Ott.forEach(t),Hlo=r(bk," or "),EB=n(bk,"A",{href:!0});var Vtt=s(EB);Ulo=r(Vtt,"HerbertTokenizerFast"),Vtt.forEach(t),Jlo=r(bk," (HerBERT model)"),bk.forEach(t),Ylo=i(S),th=n(S,"LI",{});var XAe=s(th);Mse=n(XAe,"STRONG",{});var Xtt=s(Mse);Klo=r(Xtt,"hubert"),Xtt.forEach(t),Zlo=r(XAe," \u2014 "),CB=n(XAe,"A",{href:!0});var ztt=s(CB);eio=r(ztt,"Wav2Vec2CTCTokenizer"),ztt.forEach(t),oio=r(XAe," (Hubert model)"),XAe.forEach(t),rio=i(S),ls=n(S,"LI",{});var vk=s(ls);Ese=n(vk,"STRONG",{});var Qtt=s(Ese);tio=r(Qtt,"ibert"),Qtt.forEach(t),aio=r(vk," \u2014 "),wB=n(vk,"A",{href:!0});var Wtt=s(wB);nio=r(Wtt,"RobertaTokenizer"),Wtt.forEach(t),sio=r(vk," or "),AB=n(vk,"A",{href:!0});var Htt=s(AB);lio=r(Htt,"RobertaTokenizerFast"),Htt.forEach(t),iio=r(vk," (I-BERT model)"),vk.forEach(t),dio=i(S),ah=n(S,"LI",{});var zAe=s(ah);Cse=n(zAe,"STRONG",{});var Utt=s(Cse);cio=r(Utt,"jukebox"),Utt.forEach(t),fio=r(zAe," \u2014 "),wse=n(zAe,"CODE",{});var Jtt=s(wse);mio=r(Jtt,"JukeboxTokenizer"),Jtt.forEach(t),gio=r(zAe," (Jukebox model)"),zAe.forEach(t),hio=i(S),is=n(S,"LI",{});var Fk=s(is);Ase=n(Fk,"STRONG",{});var Ytt=s(Ase);pio=r(Ytt,"layoutlm"),Ytt.forEach(t),_io=r(Fk," \u2014 "),LB=n(Fk,"A",{href:!0});var Ktt=s(LB);uio=r(Ktt,"LayoutLMTokenizer"),Ktt.forEach(t),bio=r(Fk," or "),yB=n(Fk,"A",{href:!0});var Ztt=s(yB);vio=r(Ztt,"LayoutLMTokenizerFast"),Ztt.forEach(t),Fio=r(Fk," (LayoutLM model)"),Fk.forEach(t),Tio=i(S),ds=n(S,"LI",{});var Tk=s(ds);Lse=n(Tk,"STRONG",{});var eat=s(Lse);Mio=r(eat,"layoutlmv2"),eat.forEach(t),Eio=r(Tk," \u2014 "),xB=n(Tk,"A",{href:!0});var oat=s(xB);Cio=r(oat,"LayoutLMv2Tokenizer"),oat.forEach(t),wio=r(Tk," or "),$B=n(Tk,"A",{href:!0});var rat=s($B);Aio=r(rat,"LayoutLMv2TokenizerFast"),rat.forEach(t),Lio=r(Tk," (LayoutLMv2 model)"),Tk.forEach(t),yio=i(S),cs=n(S,"LI",{});var Mk=s(cs);yse=n(Mk,"STRONG",{});var tat=s(yse);xio=r(tat,"layoutlmv3"),tat.forEach(t),$io=r(Mk," \u2014 "),kB=n(Mk,"A",{href:!0});var aat=s(kB);kio=r(aat,"LayoutLMv3Tokenizer"),aat.forEach(t),Sio=r(Mk," or "),SB=n(Mk,"A",{href:!0});var nat=s(SB);Rio=r(nat,"LayoutLMv3TokenizerFast"),nat.forEach(t),Pio=r(Mk," (LayoutLMv3 model)"),Mk.forEach(t),Bio=i(S),fs=n(S,"LI",{});var Ek=s(fs);xse=n(Ek,"STRONG",{});var sat=s(xse);Iio=r(sat,"layoutxlm"),sat.forEach(t),Nio=r(Ek," \u2014 "),RB=n(Ek,"A",{href:!0});var lat=s(RB);qio=r(lat,"LayoutXLMTokenizer"),lat.forEach(t),jio=r(Ek," or "),PB=n(Ek,"A",{href:!0});var iat=s(PB);Dio=r(iat,"LayoutXLMTokenizerFast"),iat.forEach(t),Gio=r(Ek," (LayoutXLM model)"),Ek.forEach(t),Oio=i(S),ms=n(S,"LI",{});var Ck=s(ms);$se=n(Ck,"STRONG",{});var dat=s($se);Vio=r(dat,"led"),dat.forEach(t),Xio=r(Ck," \u2014 "),BB=n(Ck,"A",{href:!0});var cat=s(BB);zio=r(cat,"LEDTokenizer"),cat.forEach(t),Qio=r(Ck," or "),IB=n(Ck,"A",{href:!0});var fat=s(IB);Wio=r(fat,"LEDTokenizerFast"),fat.forEach(t),Hio=r(Ck," (LED model)"),Ck.forEach(t),Uio=i(S),gs=n(S,"LI",{});var wk=s(gs);kse=n(wk,"STRONG",{});var mat=s(kse);Jio=r(mat,"longformer"),mat.forEach(t),Yio=r(wk," \u2014 "),NB=n(wk,"A",{href:!0});var gat=s(NB);Kio=r(gat,"LongformerTokenizer"),gat.forEach(t),Zio=r(wk," or "),qB=n(wk,"A",{href:!0});var hat=s(qB);edo=r(hat,"LongformerTokenizerFast"),hat.forEach(t),odo=r(wk," (Longformer model)"),wk.forEach(t),rdo=i(S),hs=n(S,"LI",{});var Ak=s(hs);Sse=n(Ak,"STRONG",{});var pat=s(Sse);tdo=r(pat,"longt5"),pat.forEach(t),ado=r(Ak," \u2014 "),jB=n(Ak,"A",{href:!0});var _at=s(jB);ndo=r(_at,"T5Tokenizer"),_at.forEach(t),sdo=r(Ak," or "),DB=n(Ak,"A",{href:!0});var uat=s(DB);ldo=r(uat,"T5TokenizerFast"),uat.forEach(t),ido=r(Ak," (LongT5 model)"),Ak.forEach(t),ddo=i(S),nh=n(S,"LI",{});var QAe=s(nh);Rse=n(QAe,"STRONG",{});var bat=s(Rse);cdo=r(bat,"luke"),bat.forEach(t),fdo=r(QAe," \u2014 "),GB=n(QAe,"A",{href:!0});var vat=s(GB);mdo=r(vat,"LukeTokenizer"),vat.forEach(t),gdo=r(QAe," (LUKE model)"),QAe.forEach(t),hdo=i(S),ps=n(S,"LI",{});var Lk=s(ps);Pse=n(Lk,"STRONG",{});var Fat=s(Pse);pdo=r(Fat,"lxmert"),Fat.forEach(t),_do=r(Lk," \u2014 "),OB=n(Lk,"A",{href:!0});var Tat=s(OB);udo=r(Tat,"LxmertTokenizer"),Tat.forEach(t),bdo=r(Lk," or "),VB=n(Lk,"A",{href:!0});var Mat=s(VB);vdo=r(Mat,"LxmertTokenizerFast"),Mat.forEach(t),Fdo=r(Lk," (LXMERT model)"),Lk.forEach(t),Tdo=i(S),sh=n(S,"LI",{});var WAe=s(sh);Bse=n(WAe,"STRONG",{});var Eat=s(Bse);Mdo=r(Eat,"m2m_100"),Eat.forEach(t),Edo=r(WAe," \u2014 "),XB=n(WAe,"A",{href:!0});var Cat=s(XB);Cdo=r(Cat,"M2M100Tokenizer"),Cat.forEach(t),wdo=r(WAe," (M2M100 model)"),WAe.forEach(t),Ado=i(S),lh=n(S,"LI",{});var HAe=s(lh);Ise=n(HAe,"STRONG",{});var wat=s(Ise);Ldo=r(wat,"marian"),wat.forEach(t),ydo=r(HAe," \u2014 "),zB=n(HAe,"A",{href:!0});var Aat=s(zB);xdo=r(Aat,"MarianTokenizer"),Aat.forEach(t),$do=r(HAe," (Marian model)"),HAe.forEach(t),kdo=i(S),_s=n(S,"LI",{});var yk=s(_s);Nse=n(yk,"STRONG",{});var Lat=s(Nse);Sdo=r(Lat,"mbart"),Lat.forEach(t),Rdo=r(yk," \u2014 "),QB=n(yk,"A",{href:!0});var yat=s(QB);Pdo=r(yat,"MBartTokenizer"),yat.forEach(t),Bdo=r(yk," or "),WB=n(yk,"A",{href:!0});var xat=s(WB);Ido=r(xat,"MBartTokenizerFast"),xat.forEach(t),Ndo=r(yk," (mBART model)"),yk.forEach(t),qdo=i(S),us=n(S,"LI",{});var xk=s(us);qse=n(xk,"STRONG",{});var $at=s(qse);jdo=r($at,"mbart50"),$at.forEach(t),Ddo=r(xk," \u2014 "),HB=n(xk,"A",{href:!0});var kat=s(HB);Gdo=r(kat,"MBart50Tokenizer"),kat.forEach(t),Odo=r(xk," or "),UB=n(xk,"A",{href:!0});var Sat=s(UB);Vdo=r(Sat,"MBart50TokenizerFast"),Sat.forEach(t),Xdo=r(xk," (mBART-50 model)"),xk.forEach(t),zdo=i(S),bs=n(S,"LI",{});var $k=s(bs);jse=n($k,"STRONG",{});var Rat=s(jse);Qdo=r(Rat,"megatron-bert"),Rat.forEach(t),Wdo=r($k," \u2014 "),JB=n($k,"A",{href:!0});var Pat=s(JB);Hdo=r(Pat,"BertTokenizer"),Pat.forEach(t),Udo=r($k," or "),YB=n($k,"A",{href:!0});var Bat=s(YB);Jdo=r(Bat,"BertTokenizerFast"),Bat.forEach(t),Ydo=r($k," (Megatron-BERT model)"),$k.forEach(t),Kdo=i(S),ih=n(S,"LI",{});var UAe=s(ih);Dse=n(UAe,"STRONG",{});var Iat=s(Dse);Zdo=r(Iat,"mluke"),Iat.forEach(t),eco=r(UAe," \u2014 "),KB=n(UAe,"A",{href:!0});var Nat=s(KB);oco=r(Nat,"MLukeTokenizer"),Nat.forEach(t),rco=r(UAe," (mLUKE model)"),UAe.forEach(t),tco=i(S),vs=n(S,"LI",{});var kk=s(vs);Gse=n(kk,"STRONG",{});var qat=s(Gse);aco=r(qat,"mobilebert"),qat.forEach(t),nco=r(kk," \u2014 "),ZB=n(kk,"A",{href:!0});var jat=s(ZB);sco=r(jat,"MobileBertTokenizer"),jat.forEach(t),lco=r(kk," or "),eI=n(kk,"A",{href:!0});var Dat=s(eI);ico=r(Dat,"MobileBertTokenizerFast"),Dat.forEach(t),dco=r(kk," (MobileBERT model)"),kk.forEach(t),cco=i(S),Fs=n(S,"LI",{});var Sk=s(Fs);Ose=n(Sk,"STRONG",{});var Gat=s(Ose);fco=r(Gat,"mpnet"),Gat.forEach(t),mco=r(Sk," \u2014 "),oI=n(Sk,"A",{href:!0});var Oat=s(oI);gco=r(Oat,"MPNetTokenizer"),Oat.forEach(t),hco=r(Sk," or "),rI=n(Sk,"A",{href:!0});var Vat=s(rI);pco=r(Vat,"MPNetTokenizerFast"),Vat.forEach(t),_co=r(Sk," (MPNet model)"),Sk.forEach(t),uco=i(S),Ts=n(S,"LI",{});var Rk=s(Ts);Vse=n(Rk,"STRONG",{});var Xat=s(Vse);bco=r(Xat,"mt5"),Xat.forEach(t),vco=r(Rk," \u2014 "),tI=n(Rk,"A",{href:!0});var zat=s(tI);Fco=r(zat,"MT5Tokenizer"),zat.forEach(t),Tco=r(Rk," or "),aI=n(Rk,"A",{href:!0});var Qat=s(aI);Mco=r(Qat,"MT5TokenizerFast"),Qat.forEach(t),Eco=r(Rk," (MT5 model)"),Rk.forEach(t),Cco=i(S),Ms=n(S,"LI",{});var Pk=s(Ms);Xse=n(Pk,"STRONG",{});var Wat=s(Xse);wco=r(Wat,"nezha"),Wat.forEach(t),Aco=r(Pk," \u2014 "),nI=n(Pk,"A",{href:!0});var Hat=s(nI);Lco=r(Hat,"BertTokenizer"),Hat.forEach(t),yco=r(Pk," or "),sI=n(Pk,"A",{href:!0});var Uat=s(sI);xco=r(Uat,"BertTokenizerFast"),Uat.forEach(t),$co=r(Pk," (Nezha model)"),Pk.forEach(t),kco=i(S),Es=n(S,"LI",{});var Bk=s(Es);zse=n(Bk,"STRONG",{});var Jat=s(zse);Sco=r(Jat,"nystromformer"),Jat.forEach(t),Rco=r(Bk," \u2014 "),lI=n(Bk,"A",{href:!0});var Yat=s(lI);Pco=r(Yat,"AlbertTokenizer"),Yat.forEach(t),Bco=r(Bk," or "),iI=n(Bk,"A",{href:!0});var Kat=s(iI);Ico=r(Kat,"AlbertTokenizerFast"),Kat.forEach(t),Nco=r(Bk," (Nystr\xF6mformer model)"),Bk.forEach(t),qco=i(S),Cs=n(S,"LI",{});var Ik=s(Cs);Qse=n(Ik,"STRONG",{});var Zat=s(Qse);jco=r(Zat,"openai-gpt"),Zat.forEach(t),Dco=r(Ik," \u2014 "),dI=n(Ik,"A",{href:!0});var ent=s(dI);Gco=r(ent,"OpenAIGPTTokenizer"),ent.forEach(t),Oco=r(Ik," or "),cI=n(Ik,"A",{href:!0});var ont=s(cI);Vco=r(ont,"OpenAIGPTTokenizerFast"),ont.forEach(t),Xco=r(Ik," (OpenAI GPT model)"),Ik.forEach(t),zco=i(S),dh=n(S,"LI",{});var JAe=s(dh);Wse=n(JAe,"STRONG",{});var rnt=s(Wse);Qco=r(rnt,"opt"),rnt.forEach(t),Wco=r(JAe," \u2014 "),fI=n(JAe,"A",{href:!0});var tnt=s(fI);Hco=r(tnt,"GPT2Tokenizer"),tnt.forEach(t),Uco=r(JAe," (OPT model)"),JAe.forEach(t),Jco=i(S),ws=n(S,"LI",{});var Nk=s(ws);Hse=n(Nk,"STRONG",{});var ant=s(Hse);Yco=r(ant,"pegasus"),ant.forEach(t),Kco=r(Nk," \u2014 "),mI=n(Nk,"A",{href:!0});var nnt=s(mI);Zco=r(nnt,"PegasusTokenizer"),nnt.forEach(t),efo=r(Nk," or "),gI=n(Nk,"A",{href:!0});var snt=s(gI);ofo=r(snt,"PegasusTokenizerFast"),snt.forEach(t),rfo=r(Nk," (Pegasus model)"),Nk.forEach(t),tfo=i(S),ch=n(S,"LI",{});var YAe=s(ch);Use=n(YAe,"STRONG",{});var lnt=s(Use);afo=r(lnt,"perceiver"),lnt.forEach(t),nfo=r(YAe," \u2014 "),hI=n(YAe,"A",{href:!0});var int=s(hI);sfo=r(int,"PerceiverTokenizer"),int.forEach(t),lfo=r(YAe," (Perceiver model)"),YAe.forEach(t),ifo=i(S),fh=n(S,"LI",{});var KAe=s(fh);Jse=n(KAe,"STRONG",{});var dnt=s(Jse);dfo=r(dnt,"phobert"),dnt.forEach(t),cfo=r(KAe," \u2014 "),pI=n(KAe,"A",{href:!0});var cnt=s(pI);ffo=r(cnt,"PhobertTokenizer"),cnt.forEach(t),mfo=r(KAe," (PhoBERT model)"),KAe.forEach(t),gfo=i(S),mh=n(S,"LI",{});var ZAe=s(mh);Yse=n(ZAe,"STRONG",{});var fnt=s(Yse);hfo=r(fnt,"plbart"),fnt.forEach(t),pfo=r(ZAe," \u2014 "),_I=n(ZAe,"A",{href:!0});var mnt=s(_I);_fo=r(mnt,"PLBartTokenizer"),mnt.forEach(t),ufo=r(ZAe," (PLBart model)"),ZAe.forEach(t),bfo=i(S),gh=n(S,"LI",{});var eLe=s(gh);Kse=n(eLe,"STRONG",{});var gnt=s(Kse);vfo=r(gnt,"prophetnet"),gnt.forEach(t),Ffo=r(eLe," \u2014 "),uI=n(eLe,"A",{href:!0});var hnt=s(uI);Tfo=r(hnt,"ProphetNetTokenizer"),hnt.forEach(t),Mfo=r(eLe," (ProphetNet model)"),eLe.forEach(t),Efo=i(S),As=n(S,"LI",{});var qk=s(As);Zse=n(qk,"STRONG",{});var pnt=s(Zse);Cfo=r(pnt,"qdqbert"),pnt.forEach(t),wfo=r(qk," \u2014 "),bI=n(qk,"A",{href:!0});var _nt=s(bI);Afo=r(_nt,"BertTokenizer"),_nt.forEach(t),Lfo=r(qk," or "),vI=n(qk,"A",{href:!0});var unt=s(vI);yfo=r(unt,"BertTokenizerFast"),unt.forEach(t),xfo=r(qk," (QDQBert model)"),qk.forEach(t),$fo=i(S),hh=n(S,"LI",{});var oLe=s(hh);ele=n(oLe,"STRONG",{});var bnt=s(ele);kfo=r(bnt,"rag"),bnt.forEach(t),Sfo=r(oLe," \u2014 "),FI=n(oLe,"A",{href:!0});var vnt=s(FI);Rfo=r(vnt,"RagTokenizer"),vnt.forEach(t),Pfo=r(oLe," (RAG model)"),oLe.forEach(t),Bfo=i(S),Ls=n(S,"LI",{});var jk=s(Ls);ole=n(jk,"STRONG",{});var Fnt=s(ole);Ifo=r(Fnt,"realm"),Fnt.forEach(t),Nfo=r(jk," \u2014 "),TI=n(jk,"A",{href:!0});var Tnt=s(TI);qfo=r(Tnt,"RealmTokenizer"),Tnt.forEach(t),jfo=r(jk," or "),MI=n(jk,"A",{href:!0});var Mnt=s(MI);Dfo=r(Mnt,"RealmTokenizerFast"),Mnt.forEach(t),Gfo=r(jk," (REALM model)"),jk.forEach(t),Ofo=i(S),ys=n(S,"LI",{});var Dk=s(ys);rle=n(Dk,"STRONG",{});var Ent=s(rle);Vfo=r(Ent,"reformer"),Ent.forEach(t),Xfo=r(Dk," \u2014 "),EI=n(Dk,"A",{href:!0});var Cnt=s(EI);zfo=r(Cnt,"ReformerTokenizer"),Cnt.forEach(t),Qfo=r(Dk," or "),CI=n(Dk,"A",{href:!0});var wnt=s(CI);Wfo=r(wnt,"ReformerTokenizerFast"),wnt.forEach(t),Hfo=r(Dk," (Reformer model)"),Dk.forEach(t),Ufo=i(S),xs=n(S,"LI",{});var Gk=s(xs);tle=n(Gk,"STRONG",{});var Ant=s(tle);Jfo=r(Ant,"rembert"),Ant.forEach(t),Yfo=r(Gk," \u2014 "),wI=n(Gk,"A",{href:!0});var Lnt=s(wI);Kfo=r(Lnt,"RemBertTokenizer"),Lnt.forEach(t),Zfo=r(Gk," or "),AI=n(Gk,"A",{href:!0});var ynt=s(AI);emo=r(ynt,"RemBertTokenizerFast"),ynt.forEach(t),omo=r(Gk," (RemBERT model)"),Gk.forEach(t),rmo=i(S),$s=n(S,"LI",{});var Ok=s($s);ale=n(Ok,"STRONG",{});var xnt=s(ale);tmo=r(xnt,"retribert"),xnt.forEach(t),amo=r(Ok," \u2014 "),LI=n(Ok,"A",{href:!0});var $nt=s(LI);nmo=r($nt,"RetriBertTokenizer"),$nt.forEach(t),smo=r(Ok," or "),yI=n(Ok,"A",{href:!0});var knt=s(yI);lmo=r(knt,"RetriBertTokenizerFast"),knt.forEach(t),imo=r(Ok," (RetriBERT model)"),Ok.forEach(t),dmo=i(S),ks=n(S,"LI",{});var Vk=s(ks);nle=n(Vk,"STRONG",{});var Snt=s(nle);cmo=r(Snt,"roberta"),Snt.forEach(t),fmo=r(Vk," \u2014 "),xI=n(Vk,"A",{href:!0});var Rnt=s(xI);mmo=r(Rnt,"RobertaTokenizer"),Rnt.forEach(t),gmo=r(Vk," or "),$I=n(Vk,"A",{href:!0});var Pnt=s($I);hmo=r(Pnt,"RobertaTokenizerFast"),Pnt.forEach(t),pmo=r(Vk," (RoBERTa model)"),Vk.forEach(t),_mo=i(S),Ss=n(S,"LI",{});var Xk=s(Ss);sle=n(Xk,"STRONG",{});var Bnt=s(sle);umo=r(Bnt,"roformer"),Bnt.forEach(t),bmo=r(Xk," \u2014 "),kI=n(Xk,"A",{href:!0});var Int=s(kI);vmo=r(Int,"RoFormerTokenizer"),Int.forEach(t),Fmo=r(Xk," or "),SI=n(Xk,"A",{href:!0});var Nnt=s(SI);Tmo=r(Nnt,"RoFormerTokenizerFast"),Nnt.forEach(t),Mmo=r(Xk," (RoFormer model)"),Xk.forEach(t),Emo=i(S),ph=n(S,"LI",{});var rLe=s(ph);lle=n(rLe,"STRONG",{});var qnt=s(lle);Cmo=r(qnt,"speech_to_text"),qnt.forEach(t),wmo=r(rLe," \u2014 "),RI=n(rLe,"A",{href:!0});var jnt=s(RI);Amo=r(jnt,"Speech2TextTokenizer"),jnt.forEach(t),Lmo=r(rLe," (Speech2Text model)"),rLe.forEach(t),ymo=i(S),_h=n(S,"LI",{});var tLe=s(_h);ile=n(tLe,"STRONG",{});var Dnt=s(ile);xmo=r(Dnt,"speech_to_text_2"),Dnt.forEach(t),$mo=r(tLe," \u2014 "),PI=n(tLe,"A",{href:!0});var Gnt=s(PI);kmo=r(Gnt,"Speech2Text2Tokenizer"),Gnt.forEach(t),Smo=r(tLe," (Speech2Text2 model)"),tLe.forEach(t),Rmo=i(S),Rs=n(S,"LI",{});var zk=s(Rs);dle=n(zk,"STRONG",{});var Ont=s(dle);Pmo=r(Ont,"splinter"),Ont.forEach(t),Bmo=r(zk," \u2014 "),BI=n(zk,"A",{href:!0});var Vnt=s(BI);Imo=r(Vnt,"SplinterTokenizer"),Vnt.forEach(t),Nmo=r(zk," or "),II=n(zk,"A",{href:!0});var Xnt=s(II);qmo=r(Xnt,"SplinterTokenizerFast"),Xnt.forEach(t),jmo=r(zk," (Splinter model)"),zk.forEach(t),Dmo=i(S),Ps=n(S,"LI",{});var Qk=s(Ps);cle=n(Qk,"STRONG",{});var znt=s(cle);Gmo=r(znt,"squeezebert"),znt.forEach(t),Omo=r(Qk," \u2014 "),NI=n(Qk,"A",{href:!0});var Qnt=s(NI);Vmo=r(Qnt,"SqueezeBertTokenizer"),Qnt.forEach(t),Xmo=r(Qk," or "),qI=n(Qk,"A",{href:!0});var Wnt=s(qI);zmo=r(Wnt,"SqueezeBertTokenizerFast"),Wnt.forEach(t),Qmo=r(Qk," (SqueezeBERT model)"),Qk.forEach(t),Wmo=i(S),Bs=n(S,"LI",{});var Wk=s(Bs);fle=n(Wk,"STRONG",{});var Hnt=s(fle);Hmo=r(Hnt,"t5"),Hnt.forEach(t),Umo=r(Wk," \u2014 "),jI=n(Wk,"A",{href:!0});var Unt=s(jI);Jmo=r(Unt,"T5Tokenizer"),Unt.forEach(t),Ymo=r(Wk," or "),DI=n(Wk,"A",{href:!0});var Jnt=s(DI);Kmo=r(Jnt,"T5TokenizerFast"),Jnt.forEach(t),Zmo=r(Wk," (T5 model)"),Wk.forEach(t),ego=i(S),uh=n(S,"LI",{});var aLe=s(uh);mle=n(aLe,"STRONG",{});var Ynt=s(mle);ogo=r(Ynt,"tapas"),Ynt.forEach(t),rgo=r(aLe," \u2014 "),GI=n(aLe,"A",{href:!0});var Knt=s(GI);tgo=r(Knt,"TapasTokenizer"),Knt.forEach(t),ago=r(aLe," (TAPAS model)"),aLe.forEach(t),ngo=i(S),bh=n(S,"LI",{});var nLe=s(bh);gle=n(nLe,"STRONG",{});var Znt=s(gle);sgo=r(Znt,"tapex"),Znt.forEach(t),lgo=r(nLe," \u2014 "),OI=n(nLe,"A",{href:!0});var est=s(OI);igo=r(est,"TapexTokenizer"),est.forEach(t),dgo=r(nLe," (TAPEX model)"),nLe.forEach(t),cgo=i(S),vh=n(S,"LI",{});var sLe=s(vh);hle=n(sLe,"STRONG",{});var ost=s(hle);fgo=r(ost,"transfo-xl"),ost.forEach(t),mgo=r(sLe," \u2014 "),VI=n(sLe,"A",{href:!0});var rst=s(VI);ggo=r(rst,"TransfoXLTokenizer"),rst.forEach(t),hgo=r(sLe," (Transformer-XL model)"),sLe.forEach(t),pgo=i(S),Is=n(S,"LI",{});var Hk=s(Is);ple=n(Hk,"STRONG",{});var tst=s(ple);_go=r(tst,"vilt"),tst.forEach(t),ugo=r(Hk," \u2014 "),XI=n(Hk,"A",{href:!0});var ast=s(XI);bgo=r(ast,"BertTokenizer"),ast.forEach(t),vgo=r(Hk," or "),zI=n(Hk,"A",{href:!0});var nst=s(zI);Fgo=r(nst,"BertTokenizerFast"),nst.forEach(t),Tgo=r(Hk," (ViLT model)"),Hk.forEach(t),Mgo=i(S),Ns=n(S,"LI",{});var Uk=s(Ns);_le=n(Uk,"STRONG",{});var sst=s(_le);Ego=r(sst,"visual_bert"),sst.forEach(t),Cgo=r(Uk," \u2014 "),QI=n(Uk,"A",{href:!0});var lst=s(QI);wgo=r(lst,"BertTokenizer"),lst.forEach(t),Ago=r(Uk," or "),WI=n(Uk,"A",{href:!0});var ist=s(WI);Lgo=r(ist,"BertTokenizerFast"),ist.forEach(t),ygo=r(Uk," (VisualBERT model)"),Uk.forEach(t),xgo=i(S),Fh=n(S,"LI",{});var lLe=s(Fh);ule=n(lLe,"STRONG",{});var dst=s(ule);$go=r(dst,"wav2vec2"),dst.forEach(t),kgo=r(lLe," \u2014 "),HI=n(lLe,"A",{href:!0});var cst=s(HI);Sgo=r(cst,"Wav2Vec2CTCTokenizer"),cst.forEach(t),Rgo=r(lLe," (Wav2Vec2 model)"),lLe.forEach(t),Pgo=i(S),Th=n(S,"LI",{});var iLe=s(Th);ble=n(iLe,"STRONG",{});var fst=s(ble);Bgo=r(fst,"wav2vec2-conformer"),fst.forEach(t),Igo=r(iLe," \u2014 "),UI=n(iLe,"A",{href:!0});var mst=s(UI);Ngo=r(mst,"Wav2Vec2CTCTokenizer"),mst.forEach(t),qgo=r(iLe," (Wav2Vec2-Conformer model)"),iLe.forEach(t),jgo=i(S),Mh=n(S,"LI",{});var dLe=s(Mh);vle=n(dLe,"STRONG",{});var gst=s(vle);Dgo=r(gst,"wav2vec2_phoneme"),gst.forEach(t),Ggo=r(dLe," \u2014 "),JI=n(dLe,"A",{href:!0});var hst=s(JI);Ogo=r(hst,"Wav2Vec2PhonemeCTCTokenizer"),hst.forEach(t),Vgo=r(dLe," (Wav2Vec2Phoneme model)"),dLe.forEach(t),Xgo=i(S),qs=n(S,"LI",{});var Jk=s(qs);Fle=n(Jk,"STRONG",{});var pst=s(Fle);zgo=r(pst,"xglm"),pst.forEach(t),Qgo=r(Jk," \u2014 "),YI=n(Jk,"A",{href:!0});var _st=s(YI);Wgo=r(_st,"XGLMTokenizer"),_st.forEach(t),Hgo=r(Jk," or "),KI=n(Jk,"A",{href:!0});var ust=s(KI);Ugo=r(ust,"XGLMTokenizerFast"),ust.forEach(t),Jgo=r(Jk," (XGLM model)"),Jk.forEach(t),Ygo=i(S),Eh=n(S,"LI",{});var cLe=s(Eh);Tle=n(cLe,"STRONG",{});var bst=s(Tle);Kgo=r(bst,"xlm"),bst.forEach(t),Zgo=r(cLe," \u2014 "),ZI=n(cLe,"A",{href:!0});var vst=s(ZI);eho=r(vst,"XLMTokenizer"),vst.forEach(t),oho=r(cLe," (XLM model)"),cLe.forEach(t),rho=i(S),Ch=n(S,"LI",{});var fLe=s(Ch);Mle=n(fLe,"STRONG",{});var Fst=s(Mle);tho=r(Fst,"xlm-prophetnet"),Fst.forEach(t),aho=r(fLe," \u2014 "),eN=n(fLe,"A",{href:!0});var Tst=s(eN);nho=r(Tst,"XLMProphetNetTokenizer"),Tst.forEach(t),sho=r(fLe," (XLM-ProphetNet model)"),fLe.forEach(t),lho=i(S),js=n(S,"LI",{});var Yk=s(js);Ele=n(Yk,"STRONG",{});var Mst=s(Ele);iho=r(Mst,"xlm-roberta"),Mst.forEach(t),dho=r(Yk," \u2014 "),oN=n(Yk,"A",{href:!0});var Est=s(oN);cho=r(Est,"XLMRobertaTokenizer"),Est.forEach(t),fho=r(Yk," or "),rN=n(Yk,"A",{href:!0});var Cst=s(rN);mho=r(Cst,"XLMRobertaTokenizerFast"),Cst.forEach(t),gho=r(Yk," (XLM-RoBERTa model)"),Yk.forEach(t),hho=i(S),Ds=n(S,"LI",{});var Kk=s(Ds);Cle=n(Kk,"STRONG",{});var wst=s(Cle);pho=r(wst,"xlm-roberta-xl"),wst.forEach(t),_ho=r(Kk," \u2014 "),tN=n(Kk,"A",{href:!0});var Ast=s(tN);uho=r(Ast,"RobertaTokenizer"),Ast.forEach(t),bho=r(Kk," or "),aN=n(Kk,"A",{href:!0});var Lst=s(aN);vho=r(Lst,"RobertaTokenizerFast"),Lst.forEach(t),Fho=r(Kk," (XLM-RoBERTa-XL model)"),Kk.forEach(t),Tho=i(S),Gs=n(S,"LI",{});var Zk=s(Gs);wle=n(Zk,"STRONG",{});var yst=s(wle);Mho=r(yst,"xlnet"),yst.forEach(t),Eho=r(Zk," \u2014 "),nN=n(Zk,"A",{href:!0});var xst=s(nN);Cho=r(xst,"XLNetTokenizer"),xst.forEach(t),who=r(Zk," or "),sN=n(Zk,"A",{href:!0});var $st=s(sN);Aho=r($st,"XLNetTokenizerFast"),$st.forEach(t),Lho=r(Zk," (XLNet model)"),Zk.forEach(t),yho=i(S),Os=n(S,"LI",{});var eS=s(Os);Ale=n(eS,"STRONG",{});var kst=s(Ale);xho=r(kst,"yoso"),kst.forEach(t),$ho=r(eS," \u2014 "),lN=n(eS,"A",{href:!0});var Sst=s(lN);kho=r(Sst,"AlbertTokenizer"),Sst.forEach(t),Sho=r(eS," or "),iN=n(eS,"A",{href:!0});var Rst=s(iN);Rho=r(Rst,"AlbertTokenizerFast"),Rst.forEach(t),Pho=r(eS," (YOSO model)"),eS.forEach(t),S.forEach(t),Bho=i(Hs),T(wh.$$.fragment,Hs),Hs.forEach(t),Iho=i(Ws),Ah=n(Ws,"DIV",{class:!0});var lXe=s(Ah);T(zA.$$.fragment,lXe),Nho=i(lXe),Lle=n(lXe,"P",{});var Pst=s(Lle);qho=r(Pst,"Register a new tokenizer in this mapping."),Pst.forEach(t),lXe.forEach(t),Ws.forEach(t),sOe=i(f),Si=n(f,"H2",{class:!0});var iXe=s(Si);Lh=n(iXe,"A",{id:!0,class:!0,href:!0});var Bst=s(Lh);yle=n(Bst,"SPAN",{});var Ist=s(yle);T(QA.$$.fragment,Ist),Ist.forEach(t),Bst.forEach(t),jho=i(iXe),xle=n(iXe,"SPAN",{});var Nst=s(xle);Dho=r(Nst,"AutoFeatureExtractor"),Nst.forEach(t),iXe.forEach(t),lOe=i(f),Lo=n(f,"DIV",{class:!0});var Us=s(Lo);T(WA.$$.fragment,Us),Gho=i(Us),HA=n(Us,"P",{});var dXe=s(HA);Oho=r(dXe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),dN=n(dXe,"A",{href:!0});var qst=s(dN);Vho=r(qst,"AutoFeatureExtractor.from_pretrained()"),qst.forEach(t),Xho=r(dXe," class method."),dXe.forEach(t),zho=i(Us),UA=n(Us,"P",{});var cXe=s(UA);Qho=r(cXe,"This class cannot be instantiated directly using "),$le=n(cXe,"CODE",{});var jst=s($le);Who=r(jst,"__init__()"),jst.forEach(t),Hho=r(cXe," (throws an error)."),cXe.forEach(t),Uho=i(Us),He=n(Us,"DIV",{class:!0});var ra=s(He);T(JA.$$.fragment,ra),Jho=i(ra),kle=n(ra,"P",{});var Dst=s(kle);Yho=r(Dst,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Dst.forEach(t),Kho=i(ra),Sa=n(ra,"P",{});var R0=s(Sa);Zho=r(R0,"The feature extractor class to instantiate is selected based on the "),Sle=n(R0,"CODE",{});var Gst=s(Sle);epo=r(Gst,"model_type"),Gst.forEach(t),opo=r(R0,` property of the config object
(either passed as an argument or loaded from `),Rle=n(R0,"CODE",{});var Ost=s(Rle);rpo=r(Ost,"pretrained_model_name_or_path"),Ost.forEach(t),tpo=r(R0,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ple=n(R0,"CODE",{});var Vst=s(Ple);apo=r(Vst,"pretrained_model_name_or_path"),Vst.forEach(t),npo=r(R0,":"),R0.forEach(t),spo=i(ra),Y=n(ra,"UL",{});var K=s(Y);yh=n(K,"LI",{});var mLe=s(yh);Ble=n(mLe,"STRONG",{});var Xst=s(Ble);lpo=r(Xst,"beit"),Xst.forEach(t),ipo=r(mLe," \u2014 "),cN=n(mLe,"A",{href:!0});var zst=s(cN);dpo=r(zst,"BeitFeatureExtractor"),zst.forEach(t),cpo=r(mLe," (BEiT model)"),mLe.forEach(t),fpo=i(K),xh=n(K,"LI",{});var gLe=s(xh);Ile=n(gLe,"STRONG",{});var Qst=s(Ile);mpo=r(Qst,"clip"),Qst.forEach(t),gpo=r(gLe," \u2014 "),fN=n(gLe,"A",{href:!0});var Wst=s(fN);hpo=r(Wst,"CLIPFeatureExtractor"),Wst.forEach(t),ppo=r(gLe," (CLIP model)"),gLe.forEach(t),_po=i(K),$h=n(K,"LI",{});var hLe=s($h);Nle=n(hLe,"STRONG",{});var Hst=s(Nle);upo=r(Hst,"convnext"),Hst.forEach(t),bpo=r(hLe," \u2014 "),mN=n(hLe,"A",{href:!0});var Ust=s(mN);vpo=r(Ust,"ConvNextFeatureExtractor"),Ust.forEach(t),Fpo=r(hLe," (ConvNeXT model)"),hLe.forEach(t),Tpo=i(K),kh=n(K,"LI",{});var pLe=s(kh);qle=n(pLe,"STRONG",{});var Jst=s(qle);Mpo=r(Jst,"cvt"),Jst.forEach(t),Epo=r(pLe," \u2014 "),gN=n(pLe,"A",{href:!0});var Yst=s(gN);Cpo=r(Yst,"ConvNextFeatureExtractor"),Yst.forEach(t),wpo=r(pLe," (CvT model)"),pLe.forEach(t),Apo=i(K),Sh=n(K,"LI",{});var _Le=s(Sh);jle=n(_Le,"STRONG",{});var Kst=s(jle);Lpo=r(Kst,"data2vec-audio"),Kst.forEach(t),ypo=r(_Le," \u2014 "),hN=n(_Le,"A",{href:!0});var Zst=s(hN);xpo=r(Zst,"Wav2Vec2FeatureExtractor"),Zst.forEach(t),$po=r(_Le," (Data2VecAudio model)"),_Le.forEach(t),kpo=i(K),Rh=n(K,"LI",{});var uLe=s(Rh);Dle=n(uLe,"STRONG",{});var elt=s(Dle);Spo=r(elt,"data2vec-vision"),elt.forEach(t),Rpo=r(uLe," \u2014 "),pN=n(uLe,"A",{href:!0});var olt=s(pN);Ppo=r(olt,"BeitFeatureExtractor"),olt.forEach(t),Bpo=r(uLe," (Data2VecVision model)"),uLe.forEach(t),Ipo=i(K),Ph=n(K,"LI",{});var bLe=s(Ph);Gle=n(bLe,"STRONG",{});var rlt=s(Gle);Npo=r(rlt,"deit"),rlt.forEach(t),qpo=r(bLe," \u2014 "),_N=n(bLe,"A",{href:!0});var tlt=s(_N);jpo=r(tlt,"DeiTFeatureExtractor"),tlt.forEach(t),Dpo=r(bLe," (DeiT model)"),bLe.forEach(t),Gpo=i(K),Bh=n(K,"LI",{});var vLe=s(Bh);Ole=n(vLe,"STRONG",{});var alt=s(Ole);Opo=r(alt,"detr"),alt.forEach(t),Vpo=r(vLe," \u2014 "),uN=n(vLe,"A",{href:!0});var nlt=s(uN);Xpo=r(nlt,"DetrFeatureExtractor"),nlt.forEach(t),zpo=r(vLe," (DETR model)"),vLe.forEach(t),Qpo=i(K),Ih=n(K,"LI",{});var FLe=s(Ih);Vle=n(FLe,"STRONG",{});var slt=s(Vle);Wpo=r(slt,"dpt"),slt.forEach(t),Hpo=r(FLe," \u2014 "),bN=n(FLe,"A",{href:!0});var llt=s(bN);Upo=r(llt,"DPTFeatureExtractor"),llt.forEach(t),Jpo=r(FLe," (DPT model)"),FLe.forEach(t),Ypo=i(K),Nh=n(K,"LI",{});var TLe=s(Nh);Xle=n(TLe,"STRONG",{});var ilt=s(Xle);Kpo=r(ilt,"flava"),ilt.forEach(t),Zpo=r(TLe," \u2014 "),vN=n(TLe,"A",{href:!0});var dlt=s(vN);e_o=r(dlt,"FlavaFeatureExtractor"),dlt.forEach(t),o_o=r(TLe," (FLAVA model)"),TLe.forEach(t),r_o=i(K),qh=n(K,"LI",{});var MLe=s(qh);zle=n(MLe,"STRONG",{});var clt=s(zle);t_o=r(clt,"glpn"),clt.forEach(t),a_o=r(MLe," \u2014 "),FN=n(MLe,"A",{href:!0});var flt=s(FN);n_o=r(flt,"GLPNFeatureExtractor"),flt.forEach(t),s_o=r(MLe," (GLPN model)"),MLe.forEach(t),l_o=i(K),jh=n(K,"LI",{});var ELe=s(jh);Qle=n(ELe,"STRONG",{});var mlt=s(Qle);i_o=r(mlt,"hubert"),mlt.forEach(t),d_o=r(ELe," \u2014 "),TN=n(ELe,"A",{href:!0});var glt=s(TN);c_o=r(glt,"Wav2Vec2FeatureExtractor"),glt.forEach(t),f_o=r(ELe," (Hubert model)"),ELe.forEach(t),m_o=i(K),Dh=n(K,"LI",{});var CLe=s(Dh);Wle=n(CLe,"STRONG",{});var hlt=s(Wle);g_o=r(hlt,"imagegpt"),hlt.forEach(t),h_o=r(CLe," \u2014 "),MN=n(CLe,"A",{href:!0});var plt=s(MN);p_o=r(plt,"ImageGPTFeatureExtractor"),plt.forEach(t),__o=r(CLe," (ImageGPT model)"),CLe.forEach(t),u_o=i(K),Gh=n(K,"LI",{});var wLe=s(Gh);Hle=n(wLe,"STRONG",{});var _lt=s(Hle);b_o=r(_lt,"layoutlmv2"),_lt.forEach(t),v_o=r(wLe," \u2014 "),EN=n(wLe,"A",{href:!0});var ult=s(EN);F_o=r(ult,"LayoutLMv2FeatureExtractor"),ult.forEach(t),T_o=r(wLe," (LayoutLMv2 model)"),wLe.forEach(t),M_o=i(K),Oh=n(K,"LI",{});var ALe=s(Oh);Ule=n(ALe,"STRONG",{});var blt=s(Ule);E_o=r(blt,"layoutlmv3"),blt.forEach(t),C_o=r(ALe," \u2014 "),CN=n(ALe,"A",{href:!0});var vlt=s(CN);w_o=r(vlt,"LayoutLMv3FeatureExtractor"),vlt.forEach(t),A_o=r(ALe," (LayoutLMv3 model)"),ALe.forEach(t),L_o=i(K),Vh=n(K,"LI",{});var LLe=s(Vh);Jle=n(LLe,"STRONG",{});var Flt=s(Jle);y_o=r(Flt,"levit"),Flt.forEach(t),x_o=r(LLe," \u2014 "),wN=n(LLe,"A",{href:!0});var Tlt=s(wN);$_o=r(Tlt,"LevitFeatureExtractor"),Tlt.forEach(t),k_o=r(LLe," (LeViT model)"),LLe.forEach(t),S_o=i(K),Xh=n(K,"LI",{});var yLe=s(Xh);Yle=n(yLe,"STRONG",{});var Mlt=s(Yle);R_o=r(Mlt,"maskformer"),Mlt.forEach(t),P_o=r(yLe," \u2014 "),AN=n(yLe,"A",{href:!0});var Elt=s(AN);B_o=r(Elt,"MaskFormerFeatureExtractor"),Elt.forEach(t),I_o=r(yLe," (MaskFormer model)"),yLe.forEach(t),N_o=i(K),zh=n(K,"LI",{});var xLe=s(zh);Kle=n(xLe,"STRONG",{});var Clt=s(Kle);q_o=r(Clt,"mctct"),Clt.forEach(t),j_o=r(xLe," \u2014 "),LN=n(xLe,"A",{href:!0});var wlt=s(LN);D_o=r(wlt,"MCTCTFeatureExtractor"),wlt.forEach(t),G_o=r(xLe," (M-CTC-T model)"),xLe.forEach(t),O_o=i(K),Qh=n(K,"LI",{});var $Le=s(Qh);Zle=n($Le,"STRONG",{});var Alt=s(Zle);V_o=r(Alt,"perceiver"),Alt.forEach(t),X_o=r($Le," \u2014 "),yN=n($Le,"A",{href:!0});var Llt=s(yN);z_o=r(Llt,"PerceiverFeatureExtractor"),Llt.forEach(t),Q_o=r($Le," (Perceiver model)"),$Le.forEach(t),W_o=i(K),Wh=n(K,"LI",{});var kLe=s(Wh);eie=n(kLe,"STRONG",{});var ylt=s(eie);H_o=r(ylt,"poolformer"),ylt.forEach(t),U_o=r(kLe," \u2014 "),xN=n(kLe,"A",{href:!0});var xlt=s(xN);J_o=r(xlt,"PoolFormerFeatureExtractor"),xlt.forEach(t),Y_o=r(kLe," (PoolFormer model)"),kLe.forEach(t),K_o=i(K),Hh=n(K,"LI",{});var SLe=s(Hh);oie=n(SLe,"STRONG",{});var $lt=s(oie);Z_o=r($lt,"regnet"),$lt.forEach(t),euo=r(SLe," \u2014 "),$N=n(SLe,"A",{href:!0});var klt=s($N);ouo=r(klt,"ConvNextFeatureExtractor"),klt.forEach(t),ruo=r(SLe," (RegNet model)"),SLe.forEach(t),tuo=i(K),Uh=n(K,"LI",{});var RLe=s(Uh);rie=n(RLe,"STRONG",{});var Slt=s(rie);auo=r(Slt,"resnet"),Slt.forEach(t),nuo=r(RLe," \u2014 "),kN=n(RLe,"A",{href:!0});var Rlt=s(kN);suo=r(Rlt,"ConvNextFeatureExtractor"),Rlt.forEach(t),luo=r(RLe," (ResNet model)"),RLe.forEach(t),iuo=i(K),Jh=n(K,"LI",{});var PLe=s(Jh);tie=n(PLe,"STRONG",{});var Plt=s(tie);duo=r(Plt,"segformer"),Plt.forEach(t),cuo=r(PLe," \u2014 "),SN=n(PLe,"A",{href:!0});var Blt=s(SN);fuo=r(Blt,"SegformerFeatureExtractor"),Blt.forEach(t),muo=r(PLe," (SegFormer model)"),PLe.forEach(t),guo=i(K),Yh=n(K,"LI",{});var BLe=s(Yh);aie=n(BLe,"STRONG",{});var Ilt=s(aie);huo=r(Ilt,"speech_to_text"),Ilt.forEach(t),puo=r(BLe," \u2014 "),RN=n(BLe,"A",{href:!0});var Nlt=s(RN);_uo=r(Nlt,"Speech2TextFeatureExtractor"),Nlt.forEach(t),uuo=r(BLe," (Speech2Text model)"),BLe.forEach(t),buo=i(K),Kh=n(K,"LI",{});var ILe=s(Kh);nie=n(ILe,"STRONG",{});var qlt=s(nie);vuo=r(qlt,"swin"),qlt.forEach(t),Fuo=r(ILe," \u2014 "),PN=n(ILe,"A",{href:!0});var jlt=s(PN);Tuo=r(jlt,"ViTFeatureExtractor"),jlt.forEach(t),Muo=r(ILe," (Swin Transformer model)"),ILe.forEach(t),Euo=i(K),Zh=n(K,"LI",{});var NLe=s(Zh);sie=n(NLe,"STRONG",{});var Dlt=s(sie);Cuo=r(Dlt,"van"),Dlt.forEach(t),wuo=r(NLe," \u2014 "),BN=n(NLe,"A",{href:!0});var Glt=s(BN);Auo=r(Glt,"ConvNextFeatureExtractor"),Glt.forEach(t),Luo=r(NLe," (VAN model)"),NLe.forEach(t),yuo=i(K),ep=n(K,"LI",{});var qLe=s(ep);lie=n(qLe,"STRONG",{});var Olt=s(lie);xuo=r(Olt,"vilt"),Olt.forEach(t),$uo=r(qLe," \u2014 "),IN=n(qLe,"A",{href:!0});var Vlt=s(IN);kuo=r(Vlt,"ViltFeatureExtractor"),Vlt.forEach(t),Suo=r(qLe," (ViLT model)"),qLe.forEach(t),Ruo=i(K),op=n(K,"LI",{});var jLe=s(op);iie=n(jLe,"STRONG",{});var Xlt=s(iie);Puo=r(Xlt,"vit"),Xlt.forEach(t),Buo=r(jLe," \u2014 "),NN=n(jLe,"A",{href:!0});var zlt=s(NN);Iuo=r(zlt,"ViTFeatureExtractor"),zlt.forEach(t),Nuo=r(jLe," (ViT model)"),jLe.forEach(t),quo=i(K),rp=n(K,"LI",{});var DLe=s(rp);die=n(DLe,"STRONG",{});var Qlt=s(die);juo=r(Qlt,"vit_mae"),Qlt.forEach(t),Duo=r(DLe," \u2014 "),qN=n(DLe,"A",{href:!0});var Wlt=s(qN);Guo=r(Wlt,"ViTFeatureExtractor"),Wlt.forEach(t),Ouo=r(DLe," (ViTMAE model)"),DLe.forEach(t),Vuo=i(K),tp=n(K,"LI",{});var GLe=s(tp);cie=n(GLe,"STRONG",{});var Hlt=s(cie);Xuo=r(Hlt,"wav2vec2"),Hlt.forEach(t),zuo=r(GLe," \u2014 "),jN=n(GLe,"A",{href:!0});var Ult=s(jN);Quo=r(Ult,"Wav2Vec2FeatureExtractor"),Ult.forEach(t),Wuo=r(GLe," (Wav2Vec2 model)"),GLe.forEach(t),Huo=i(K),ap=n(K,"LI",{});var OLe=s(ap);fie=n(OLe,"STRONG",{});var Jlt=s(fie);Uuo=r(Jlt,"wav2vec2-conformer"),Jlt.forEach(t),Juo=r(OLe," \u2014 "),DN=n(OLe,"A",{href:!0});var Ylt=s(DN);Yuo=r(Ylt,"Wav2Vec2FeatureExtractor"),Ylt.forEach(t),Kuo=r(OLe," (Wav2Vec2-Conformer model)"),OLe.forEach(t),Zuo=i(K),np=n(K,"LI",{});var VLe=s(np);mie=n(VLe,"STRONG",{});var Klt=s(mie);e2o=r(Klt,"yolos"),Klt.forEach(t),o2o=r(VLe," \u2014 "),GN=n(VLe,"A",{href:!0});var Zlt=s(GN);r2o=r(Zlt,"YolosFeatureExtractor"),Zlt.forEach(t),t2o=r(VLe," (YOLOS model)"),VLe.forEach(t),K.forEach(t),a2o=i(ra),T(sp.$$.fragment,ra),n2o=i(ra),T(lp.$$.fragment,ra),ra.forEach(t),s2o=i(Us),ip=n(Us,"DIV",{class:!0});var fXe=s(ip);T(YA.$$.fragment,fXe),l2o=i(fXe),gie=n(fXe,"P",{});var eit=s(gie);i2o=r(eit,"Register a new feature extractor for this class."),eit.forEach(t),fXe.forEach(t),Us.forEach(t),iOe=i(f),Ri=n(f,"H2",{class:!0});var mXe=s(Ri);dp=n(mXe,"A",{id:!0,class:!0,href:!0});var oit=s(dp);hie=n(oit,"SPAN",{});var rit=s(hie);T(KA.$$.fragment,rit),rit.forEach(t),oit.forEach(t),d2o=i(mXe),pie=n(mXe,"SPAN",{});var tit=s(pie);c2o=r(tit,"AutoProcessor"),tit.forEach(t),mXe.forEach(t),dOe=i(f),yo=n(f,"DIV",{class:!0});var Js=s(yo);T(ZA.$$.fragment,Js),f2o=i(Js),eL=n(Js,"P",{});var gXe=s(eL);m2o=r(gXe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),ON=n(gXe,"A",{href:!0});var ait=s(ON);g2o=r(ait,"AutoProcessor.from_pretrained()"),ait.forEach(t),h2o=r(gXe," class method."),gXe.forEach(t),p2o=i(Js),oL=n(Js,"P",{});var hXe=s(oL);_2o=r(hXe,"This class cannot be instantiated directly using "),_ie=n(hXe,"CODE",{});var nit=s(_ie);u2o=r(nit,"__init__()"),nit.forEach(t),b2o=r(hXe," (throws an error)."),hXe.forEach(t),v2o=i(Js),Ue=n(Js,"DIV",{class:!0});var ta=s(Ue);T(rL.$$.fragment,ta),F2o=i(ta),uie=n(ta,"P",{});var sit=s(uie);T2o=r(sit,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),sit.forEach(t),M2o=i(ta),Pi=n(ta,"P",{});var Moe=s(Pi);E2o=r(Moe,"The processor class to instantiate is selected based on the "),bie=n(Moe,"CODE",{});var lit=s(bie);C2o=r(lit,"model_type"),lit.forEach(t),w2o=r(Moe,` property of the config object (either
passed as an argument or loaded from `),vie=n(Moe,"CODE",{});var iit=s(vie);A2o=r(iit,"pretrained_model_name_or_path"),iit.forEach(t),L2o=r(Moe," if possible):"),Moe.forEach(t),y2o=i(ta),he=n(ta,"UL",{});var ue=s(he);cp=n(ue,"LI",{});var XLe=s(cp);Fie=n(XLe,"STRONG",{});var dit=s(Fie);x2o=r(dit,"clip"),dit.forEach(t),$2o=r(XLe," \u2014 "),VN=n(XLe,"A",{href:!0});var cit=s(VN);k2o=r(cit,"CLIPProcessor"),cit.forEach(t),S2o=r(XLe," (CLIP model)"),XLe.forEach(t),R2o=i(ue),fp=n(ue,"LI",{});var zLe=s(fp);Tie=n(zLe,"STRONG",{});var fit=s(Tie);P2o=r(fit,"flava"),fit.forEach(t),B2o=r(zLe," \u2014 "),Mie=n(zLe,"CODE",{});var mit=s(Mie);I2o=r(mit,"FLAVAProcessor"),mit.forEach(t),N2o=r(zLe," (FLAVA model)"),zLe.forEach(t),q2o=i(ue),mp=n(ue,"LI",{});var QLe=s(mp);Eie=n(QLe,"STRONG",{});var git=s(Eie);j2o=r(git,"layoutlmv2"),git.forEach(t),D2o=r(QLe," \u2014 "),XN=n(QLe,"A",{href:!0});var hit=s(XN);G2o=r(hit,"LayoutLMv2Processor"),hit.forEach(t),O2o=r(QLe," (LayoutLMv2 model)"),QLe.forEach(t),V2o=i(ue),gp=n(ue,"LI",{});var WLe=s(gp);Cie=n(WLe,"STRONG",{});var pit=s(Cie);X2o=r(pit,"layoutlmv3"),pit.forEach(t),z2o=r(WLe," \u2014 "),zN=n(WLe,"A",{href:!0});var _it=s(zN);Q2o=r(_it,"LayoutLMv3Processor"),_it.forEach(t),W2o=r(WLe," (LayoutLMv3 model)"),WLe.forEach(t),H2o=i(ue),hp=n(ue,"LI",{});var HLe=s(hp);wie=n(HLe,"STRONG",{});var uit=s(wie);U2o=r(uit,"layoutxlm"),uit.forEach(t),J2o=r(HLe," \u2014 "),QN=n(HLe,"A",{href:!0});var bit=s(QN);Y2o=r(bit,"LayoutXLMProcessor"),bit.forEach(t),K2o=r(HLe," (LayoutXLM model)"),HLe.forEach(t),Z2o=i(ue),pp=n(ue,"LI",{});var ULe=s(pp);Aie=n(ULe,"STRONG",{});var vit=s(Aie);e1o=r(vit,"sew"),vit.forEach(t),o1o=r(ULe," \u2014 "),WN=n(ULe,"A",{href:!0});var Fit=s(WN);r1o=r(Fit,"Wav2Vec2Processor"),Fit.forEach(t),t1o=r(ULe," (SEW model)"),ULe.forEach(t),a1o=i(ue),_p=n(ue,"LI",{});var JLe=s(_p);Lie=n(JLe,"STRONG",{});var Tit=s(Lie);n1o=r(Tit,"sew-d"),Tit.forEach(t),s1o=r(JLe," \u2014 "),HN=n(JLe,"A",{href:!0});var Mit=s(HN);l1o=r(Mit,"Wav2Vec2Processor"),Mit.forEach(t),i1o=r(JLe," (SEW-D model)"),JLe.forEach(t),d1o=i(ue),up=n(ue,"LI",{});var YLe=s(up);yie=n(YLe,"STRONG",{});var Eit=s(yie);c1o=r(Eit,"speech_to_text"),Eit.forEach(t),f1o=r(YLe," \u2014 "),UN=n(YLe,"A",{href:!0});var Cit=s(UN);m1o=r(Cit,"Speech2TextProcessor"),Cit.forEach(t),g1o=r(YLe," (Speech2Text model)"),YLe.forEach(t),h1o=i(ue),bp=n(ue,"LI",{});var KLe=s(bp);xie=n(KLe,"STRONG",{});var wit=s(xie);p1o=r(wit,"speech_to_text_2"),wit.forEach(t),_1o=r(KLe," \u2014 "),JN=n(KLe,"A",{href:!0});var Ait=s(JN);u1o=r(Ait,"Speech2Text2Processor"),Ait.forEach(t),b1o=r(KLe," (Speech2Text2 model)"),KLe.forEach(t),v1o=i(ue),vp=n(ue,"LI",{});var ZLe=s(vp);$ie=n(ZLe,"STRONG",{});var Lit=s($ie);F1o=r(Lit,"trocr"),Lit.forEach(t),T1o=r(ZLe," \u2014 "),YN=n(ZLe,"A",{href:!0});var yit=s(YN);M1o=r(yit,"TrOCRProcessor"),yit.forEach(t),E1o=r(ZLe," (TrOCR model)"),ZLe.forEach(t),C1o=i(ue),Fp=n(ue,"LI",{});var eye=s(Fp);kie=n(eye,"STRONG",{});var xit=s(kie);w1o=r(xit,"unispeech"),xit.forEach(t),A1o=r(eye," \u2014 "),KN=n(eye,"A",{href:!0});var $it=s(KN);L1o=r($it,"Wav2Vec2Processor"),$it.forEach(t),y1o=r(eye," (UniSpeech model)"),eye.forEach(t),x1o=i(ue),Tp=n(ue,"LI",{});var oye=s(Tp);Sie=n(oye,"STRONG",{});var kit=s(Sie);$1o=r(kit,"unispeech-sat"),kit.forEach(t),k1o=r(oye," \u2014 "),ZN=n(oye,"A",{href:!0});var Sit=s(ZN);S1o=r(Sit,"Wav2Vec2Processor"),Sit.forEach(t),R1o=r(oye," (UniSpeechSat model)"),oye.forEach(t),P1o=i(ue),Mp=n(ue,"LI",{});var rye=s(Mp);Rie=n(rye,"STRONG",{});var Rit=s(Rie);B1o=r(Rit,"vilt"),Rit.forEach(t),I1o=r(rye," \u2014 "),eq=n(rye,"A",{href:!0});var Pit=s(eq);N1o=r(Pit,"ViltProcessor"),Pit.forEach(t),q1o=r(rye," (ViLT model)"),rye.forEach(t),j1o=i(ue),Ep=n(ue,"LI",{});var tye=s(Ep);Pie=n(tye,"STRONG",{});var Bit=s(Pie);D1o=r(Bit,"vision-text-dual-encoder"),Bit.forEach(t),G1o=r(tye," \u2014 "),oq=n(tye,"A",{href:!0});var Iit=s(oq);O1o=r(Iit,"VisionTextDualEncoderProcessor"),Iit.forEach(t),V1o=r(tye," (VisionTextDualEncoder model)"),tye.forEach(t),X1o=i(ue),Cp=n(ue,"LI",{});var aye=s(Cp);Bie=n(aye,"STRONG",{});var Nit=s(Bie);z1o=r(Nit,"wav2vec2"),Nit.forEach(t),Q1o=r(aye," \u2014 "),rq=n(aye,"A",{href:!0});var qit=s(rq);W1o=r(qit,"Wav2Vec2Processor"),qit.forEach(t),H1o=r(aye," (Wav2Vec2 model)"),aye.forEach(t),U1o=i(ue),wp=n(ue,"LI",{});var nye=s(wp);Iie=n(nye,"STRONG",{});var jit=s(Iie);J1o=r(jit,"wav2vec2-conformer"),jit.forEach(t),Y1o=r(nye," \u2014 "),tq=n(nye,"A",{href:!0});var Dit=s(tq);K1o=r(Dit,"Wav2Vec2Processor"),Dit.forEach(t),Z1o=r(nye," (Wav2Vec2-Conformer model)"),nye.forEach(t),ebo=i(ue),Ap=n(ue,"LI",{});var sye=s(Ap);Nie=n(sye,"STRONG",{});var Git=s(Nie);obo=r(Git,"wavlm"),Git.forEach(t),rbo=r(sye," \u2014 "),aq=n(sye,"A",{href:!0});var Oit=s(aq);tbo=r(Oit,"Wav2Vec2Processor"),Oit.forEach(t),abo=r(sye," (WavLM model)"),sye.forEach(t),ue.forEach(t),nbo=i(ta),T(Lp.$$.fragment,ta),sbo=i(ta),T(yp.$$.fragment,ta),ta.forEach(t),lbo=i(Js),xp=n(Js,"DIV",{class:!0});var pXe=s(xp);T(tL.$$.fragment,pXe),ibo=i(pXe),qie=n(pXe,"P",{});var Vit=s(qie);dbo=r(Vit,"Register a new processor for this class."),Vit.forEach(t),pXe.forEach(t),Js.forEach(t),cOe=i(f),Bi=n(f,"H2",{class:!0});var _Xe=s(Bi);$p=n(_Xe,"A",{id:!0,class:!0,href:!0});var Xit=s($p);jie=n(Xit,"SPAN",{});var zit=s(jie);T(aL.$$.fragment,zit),zit.forEach(t),Xit.forEach(t),cbo=i(_Xe),Die=n(_Xe,"SPAN",{});var Qit=s(Die);fbo=r(Qit,"AutoModel"),Qit.forEach(t),_Xe.forEach(t),fOe=i(f),xo=n(f,"DIV",{class:!0});var Ys=s(xo);T(nL.$$.fragment,Ys),mbo=i(Ys),Ii=n(Ys,"P",{});var Eoe=s(Ii);gbo=r(Eoe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nq=n(Eoe,"A",{href:!0});var Wit=s(nq);hbo=r(Wit,"from_pretrained()"),Wit.forEach(t),pbo=r(Eoe," class method or the "),sq=n(Eoe,"A",{href:!0});var Hit=s(sq);_bo=r(Hit,"from_config()"),Hit.forEach(t),ubo=r(Eoe,` class
method.`),Eoe.forEach(t),bbo=i(Ys),sL=n(Ys,"P",{});var uXe=s(sL);vbo=r(uXe,"This class cannot be instantiated directly using "),Gie=n(uXe,"CODE",{});var Uit=s(Gie);Fbo=r(Uit,"__init__()"),Uit.forEach(t),Tbo=r(uXe," (throws an error)."),uXe.forEach(t),Mbo=i(Ys),nt=n(Ys,"DIV",{class:!0});var P0=s(nt);T(lL.$$.fragment,P0),Ebo=i(P0),Oie=n(P0,"P",{});var Jit=s(Oie);Cbo=r(Jit,"Instantiates one of the base model classes of the library from a configuration."),Jit.forEach(t),wbo=i(P0),Ni=n(P0,"P",{});var Coe=s(Ni);Abo=r(Coe,`Note:
Loading a model from its configuration file does `),Vie=n(Coe,"STRONG",{});var Yit=s(Vie);Lbo=r(Yit,"not"),Yit.forEach(t),ybo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lq=n(Coe,"A",{href:!0});var Kit=s(lq);xbo=r(Kit,"from_pretrained()"),Kit.forEach(t),$bo=r(Coe," to load the model weights."),Coe.forEach(t),kbo=i(P0),T(kp.$$.fragment,P0),P0.forEach(t),Sbo=i(Ys),Je=n(Ys,"DIV",{class:!0});var aa=s(Je);T(iL.$$.fragment,aa),Rbo=i(aa),Xie=n(aa,"P",{});var Zit=s(Xie);Pbo=r(Zit,"Instantiate one of the base model classes of the library from a pretrained model."),Zit.forEach(t),Bbo=i(aa),Ra=n(aa,"P",{});var B0=s(Ra);Ibo=r(B0,"The model class to instantiate is selected based on the "),zie=n(B0,"CODE",{});var edt=s(zie);Nbo=r(edt,"model_type"),edt.forEach(t),qbo=r(B0,` property of the config object (either
passed as an argument or loaded from `),Qie=n(B0,"CODE",{});var odt=s(Qie);jbo=r(odt,"pretrained_model_name_or_path"),odt.forEach(t),Dbo=r(B0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wie=n(B0,"CODE",{});var rdt=s(Wie);Gbo=r(rdt,"pretrained_model_name_or_path"),rdt.forEach(t),Obo=r(B0,":"),B0.forEach(t),Vbo=i(aa),y=n(aa,"UL",{});var $=s(y);Sp=n($,"LI",{});var lye=s(Sp);Hie=n(lye,"STRONG",{});var tdt=s(Hie);Xbo=r(tdt,"albert"),tdt.forEach(t),zbo=r(lye," \u2014 "),iq=n(lye,"A",{href:!0});var adt=s(iq);Qbo=r(adt,"AlbertModel"),adt.forEach(t),Wbo=r(lye," (ALBERT model)"),lye.forEach(t),Hbo=i($),Rp=n($,"LI",{});var iye=s(Rp);Uie=n(iye,"STRONG",{});var ndt=s(Uie);Ubo=r(ndt,"bart"),ndt.forEach(t),Jbo=r(iye," \u2014 "),dq=n(iye,"A",{href:!0});var sdt=s(dq);Ybo=r(sdt,"BartModel"),sdt.forEach(t),Kbo=r(iye," (BART model)"),iye.forEach(t),Zbo=i($),Pp=n($,"LI",{});var dye=s(Pp);Jie=n(dye,"STRONG",{});var ldt=s(Jie);evo=r(ldt,"beit"),ldt.forEach(t),ovo=r(dye," \u2014 "),cq=n(dye,"A",{href:!0});var idt=s(cq);rvo=r(idt,"BeitModel"),idt.forEach(t),tvo=r(dye," (BEiT model)"),dye.forEach(t),avo=i($),Bp=n($,"LI",{});var cye=s(Bp);Yie=n(cye,"STRONG",{});var ddt=s(Yie);nvo=r(ddt,"bert"),ddt.forEach(t),svo=r(cye," \u2014 "),fq=n(cye,"A",{href:!0});var cdt=s(fq);lvo=r(cdt,"BertModel"),cdt.forEach(t),ivo=r(cye," (BERT model)"),cye.forEach(t),dvo=i($),Ip=n($,"LI",{});var fye=s(Ip);Kie=n(fye,"STRONG",{});var fdt=s(Kie);cvo=r(fdt,"bert-generation"),fdt.forEach(t),fvo=r(fye," \u2014 "),mq=n(fye,"A",{href:!0});var mdt=s(mq);mvo=r(mdt,"BertGenerationEncoder"),mdt.forEach(t),gvo=r(fye," (Bert Generation model)"),fye.forEach(t),hvo=i($),Np=n($,"LI",{});var mye=s(Np);Zie=n(mye,"STRONG",{});var gdt=s(Zie);pvo=r(gdt,"big_bird"),gdt.forEach(t),_vo=r(mye," \u2014 "),gq=n(mye,"A",{href:!0});var hdt=s(gq);uvo=r(hdt,"BigBirdModel"),hdt.forEach(t),bvo=r(mye," (BigBird model)"),mye.forEach(t),vvo=i($),qp=n($,"LI",{});var gye=s(qp);ede=n(gye,"STRONG",{});var pdt=s(ede);Fvo=r(pdt,"bigbird_pegasus"),pdt.forEach(t),Tvo=r(gye," \u2014 "),hq=n(gye,"A",{href:!0});var _dt=s(hq);Mvo=r(_dt,"BigBirdPegasusModel"),_dt.forEach(t),Evo=r(gye," (BigBird-Pegasus model)"),gye.forEach(t),Cvo=i($),jp=n($,"LI",{});var hye=s(jp);ode=n(hye,"STRONG",{});var udt=s(ode);wvo=r(udt,"blenderbot"),udt.forEach(t),Avo=r(hye," \u2014 "),pq=n(hye,"A",{href:!0});var bdt=s(pq);Lvo=r(bdt,"BlenderbotModel"),bdt.forEach(t),yvo=r(hye," (Blenderbot model)"),hye.forEach(t),xvo=i($),Dp=n($,"LI",{});var pye=s(Dp);rde=n(pye,"STRONG",{});var vdt=s(rde);$vo=r(vdt,"blenderbot-small"),vdt.forEach(t),kvo=r(pye," \u2014 "),_q=n(pye,"A",{href:!0});var Fdt=s(_q);Svo=r(Fdt,"BlenderbotSmallModel"),Fdt.forEach(t),Rvo=r(pye," (BlenderbotSmall model)"),pye.forEach(t),Pvo=i($),Gp=n($,"LI",{});var _ye=s(Gp);tde=n(_ye,"STRONG",{});var Tdt=s(tde);Bvo=r(Tdt,"bloom"),Tdt.forEach(t),Ivo=r(_ye," \u2014 "),uq=n(_ye,"A",{href:!0});var Mdt=s(uq);Nvo=r(Mdt,"BloomModel"),Mdt.forEach(t),qvo=r(_ye," (BLOOM model)"),_ye.forEach(t),jvo=i($),Op=n($,"LI",{});var uye=s(Op);ade=n(uye,"STRONG",{});var Edt=s(ade);Dvo=r(Edt,"camembert"),Edt.forEach(t),Gvo=r(uye," \u2014 "),bq=n(uye,"A",{href:!0});var Cdt=s(bq);Ovo=r(Cdt,"CamembertModel"),Cdt.forEach(t),Vvo=r(uye," (CamemBERT model)"),uye.forEach(t),Xvo=i($),Vp=n($,"LI",{});var bye=s(Vp);nde=n(bye,"STRONG",{});var wdt=s(nde);zvo=r(wdt,"canine"),wdt.forEach(t),Qvo=r(bye," \u2014 "),vq=n(bye,"A",{href:!0});var Adt=s(vq);Wvo=r(Adt,"CanineModel"),Adt.forEach(t),Hvo=r(bye," (CANINE model)"),bye.forEach(t),Uvo=i($),Xp=n($,"LI",{});var vye=s(Xp);sde=n(vye,"STRONG",{});var Ldt=s(sde);Jvo=r(Ldt,"clip"),Ldt.forEach(t),Yvo=r(vye," \u2014 "),Fq=n(vye,"A",{href:!0});var ydt=s(Fq);Kvo=r(ydt,"CLIPModel"),ydt.forEach(t),Zvo=r(vye," (CLIP model)"),vye.forEach(t),eFo=i($),zp=n($,"LI",{});var Fye=s(zp);lde=n(Fye,"STRONG",{});var xdt=s(lde);oFo=r(xdt,"convbert"),xdt.forEach(t),rFo=r(Fye," \u2014 "),Tq=n(Fye,"A",{href:!0});var $dt=s(Tq);tFo=r($dt,"ConvBertModel"),$dt.forEach(t),aFo=r(Fye," (ConvBERT model)"),Fye.forEach(t),nFo=i($),Qp=n($,"LI",{});var Tye=s(Qp);ide=n(Tye,"STRONG",{});var kdt=s(ide);sFo=r(kdt,"convnext"),kdt.forEach(t),lFo=r(Tye," \u2014 "),Mq=n(Tye,"A",{href:!0});var Sdt=s(Mq);iFo=r(Sdt,"ConvNextModel"),Sdt.forEach(t),dFo=r(Tye," (ConvNeXT model)"),Tye.forEach(t),cFo=i($),Wp=n($,"LI",{});var Mye=s(Wp);dde=n(Mye,"STRONG",{});var Rdt=s(dde);fFo=r(Rdt,"ctrl"),Rdt.forEach(t),mFo=r(Mye," \u2014 "),Eq=n(Mye,"A",{href:!0});var Pdt=s(Eq);gFo=r(Pdt,"CTRLModel"),Pdt.forEach(t),hFo=r(Mye," (CTRL model)"),Mye.forEach(t),pFo=i($),Hp=n($,"LI",{});var Eye=s(Hp);cde=n(Eye,"STRONG",{});var Bdt=s(cde);_Fo=r(Bdt,"cvt"),Bdt.forEach(t),uFo=r(Eye," \u2014 "),Cq=n(Eye,"A",{href:!0});var Idt=s(Cq);bFo=r(Idt,"CvtModel"),Idt.forEach(t),vFo=r(Eye," (CvT model)"),Eye.forEach(t),FFo=i($),Up=n($,"LI",{});var Cye=s(Up);fde=n(Cye,"STRONG",{});var Ndt=s(fde);TFo=r(Ndt,"data2vec-audio"),Ndt.forEach(t),MFo=r(Cye," \u2014 "),wq=n(Cye,"A",{href:!0});var qdt=s(wq);EFo=r(qdt,"Data2VecAudioModel"),qdt.forEach(t),CFo=r(Cye," (Data2VecAudio model)"),Cye.forEach(t),wFo=i($),Jp=n($,"LI",{});var wye=s(Jp);mde=n(wye,"STRONG",{});var jdt=s(mde);AFo=r(jdt,"data2vec-text"),jdt.forEach(t),LFo=r(wye," \u2014 "),Aq=n(wye,"A",{href:!0});var Ddt=s(Aq);yFo=r(Ddt,"Data2VecTextModel"),Ddt.forEach(t),xFo=r(wye," (Data2VecText model)"),wye.forEach(t),$Fo=i($),Yp=n($,"LI",{});var Aye=s(Yp);gde=n(Aye,"STRONG",{});var Gdt=s(gde);kFo=r(Gdt,"data2vec-vision"),Gdt.forEach(t),SFo=r(Aye," \u2014 "),Lq=n(Aye,"A",{href:!0});var Odt=s(Lq);RFo=r(Odt,"Data2VecVisionModel"),Odt.forEach(t),PFo=r(Aye," (Data2VecVision model)"),Aye.forEach(t),BFo=i($),Kp=n($,"LI",{});var Lye=s(Kp);hde=n(Lye,"STRONG",{});var Vdt=s(hde);IFo=r(Vdt,"deberta"),Vdt.forEach(t),NFo=r(Lye," \u2014 "),yq=n(Lye,"A",{href:!0});var Xdt=s(yq);qFo=r(Xdt,"DebertaModel"),Xdt.forEach(t),jFo=r(Lye," (DeBERTa model)"),Lye.forEach(t),DFo=i($),Zp=n($,"LI",{});var yye=s(Zp);pde=n(yye,"STRONG",{});var zdt=s(pde);GFo=r(zdt,"deberta-v2"),zdt.forEach(t),OFo=r(yye," \u2014 "),xq=n(yye,"A",{href:!0});var Qdt=s(xq);VFo=r(Qdt,"DebertaV2Model"),Qdt.forEach(t),XFo=r(yye," (DeBERTa-v2 model)"),yye.forEach(t),zFo=i($),e_=n($,"LI",{});var xye=s(e_);_de=n(xye,"STRONG",{});var Wdt=s(_de);QFo=r(Wdt,"decision_transformer"),Wdt.forEach(t),WFo=r(xye," \u2014 "),$q=n(xye,"A",{href:!0});var Hdt=s($q);HFo=r(Hdt,"DecisionTransformerModel"),Hdt.forEach(t),UFo=r(xye," (Decision Transformer model)"),xye.forEach(t),JFo=i($),o_=n($,"LI",{});var $ye=s(o_);ude=n($ye,"STRONG",{});var Udt=s(ude);YFo=r(Udt,"deit"),Udt.forEach(t),KFo=r($ye," \u2014 "),kq=n($ye,"A",{href:!0});var Jdt=s(kq);ZFo=r(Jdt,"DeiTModel"),Jdt.forEach(t),e6o=r($ye," (DeiT model)"),$ye.forEach(t),o6o=i($),r_=n($,"LI",{});var kye=s(r_);bde=n(kye,"STRONG",{});var Ydt=s(bde);r6o=r(Ydt,"detr"),Ydt.forEach(t),t6o=r(kye," \u2014 "),Sq=n(kye,"A",{href:!0});var Kdt=s(Sq);a6o=r(Kdt,"DetrModel"),Kdt.forEach(t),n6o=r(kye," (DETR model)"),kye.forEach(t),s6o=i($),t_=n($,"LI",{});var Sye=s(t_);vde=n(Sye,"STRONG",{});var Zdt=s(vde);l6o=r(Zdt,"distilbert"),Zdt.forEach(t),i6o=r(Sye," \u2014 "),Rq=n(Sye,"A",{href:!0});var ect=s(Rq);d6o=r(ect,"DistilBertModel"),ect.forEach(t),c6o=r(Sye," (DistilBERT model)"),Sye.forEach(t),f6o=i($),a_=n($,"LI",{});var Rye=s(a_);Fde=n(Rye,"STRONG",{});var oct=s(Fde);m6o=r(oct,"dpr"),oct.forEach(t),g6o=r(Rye," \u2014 "),Pq=n(Rye,"A",{href:!0});var rct=s(Pq);h6o=r(rct,"DPRQuestionEncoder"),rct.forEach(t),p6o=r(Rye," (DPR model)"),Rye.forEach(t),_6o=i($),n_=n($,"LI",{});var Pye=s(n_);Tde=n(Pye,"STRONG",{});var tct=s(Tde);u6o=r(tct,"dpt"),tct.forEach(t),b6o=r(Pye," \u2014 "),Bq=n(Pye,"A",{href:!0});var act=s(Bq);v6o=r(act,"DPTModel"),act.forEach(t),F6o=r(Pye," (DPT model)"),Pye.forEach(t),T6o=i($),s_=n($,"LI",{});var Bye=s(s_);Mde=n(Bye,"STRONG",{});var nct=s(Mde);M6o=r(nct,"electra"),nct.forEach(t),E6o=r(Bye," \u2014 "),Iq=n(Bye,"A",{href:!0});var sct=s(Iq);C6o=r(sct,"ElectraModel"),sct.forEach(t),w6o=r(Bye," (ELECTRA model)"),Bye.forEach(t),A6o=i($),l_=n($,"LI",{});var Iye=s(l_);Ede=n(Iye,"STRONG",{});var lct=s(Ede);L6o=r(lct,"flaubert"),lct.forEach(t),y6o=r(Iye," \u2014 "),Nq=n(Iye,"A",{href:!0});var ict=s(Nq);x6o=r(ict,"FlaubertModel"),ict.forEach(t),$6o=r(Iye," (FlauBERT model)"),Iye.forEach(t),k6o=i($),i_=n($,"LI",{});var Nye=s(i_);Cde=n(Nye,"STRONG",{});var dct=s(Cde);S6o=r(dct,"flava"),dct.forEach(t),R6o=r(Nye," \u2014 "),qq=n(Nye,"A",{href:!0});var cct=s(qq);P6o=r(cct,"FlavaModel"),cct.forEach(t),B6o=r(Nye," (FLAVA model)"),Nye.forEach(t),I6o=i($),d_=n($,"LI",{});var qye=s(d_);wde=n(qye,"STRONG",{});var fct=s(wde);N6o=r(fct,"fnet"),fct.forEach(t),q6o=r(qye," \u2014 "),jq=n(qye,"A",{href:!0});var mct=s(jq);j6o=r(mct,"FNetModel"),mct.forEach(t),D6o=r(qye," (FNet model)"),qye.forEach(t),G6o=i($),c_=n($,"LI",{});var jye=s(c_);Ade=n(jye,"STRONG",{});var gct=s(Ade);O6o=r(gct,"fsmt"),gct.forEach(t),V6o=r(jye," \u2014 "),Dq=n(jye,"A",{href:!0});var hct=s(Dq);X6o=r(hct,"FSMTModel"),hct.forEach(t),z6o=r(jye," (FairSeq Machine-Translation model)"),jye.forEach(t),Q6o=i($),Vs=n($,"LI",{});var oS=s(Vs);Lde=n(oS,"STRONG",{});var pct=s(Lde);W6o=r(pct,"funnel"),pct.forEach(t),H6o=r(oS," \u2014 "),Gq=n(oS,"A",{href:!0});var _ct=s(Gq);U6o=r(_ct,"FunnelModel"),_ct.forEach(t),J6o=r(oS," or "),Oq=n(oS,"A",{href:!0});var uct=s(Oq);Y6o=r(uct,"FunnelBaseModel"),uct.forEach(t),K6o=r(oS," (Funnel Transformer model)"),oS.forEach(t),Z6o=i($),f_=n($,"LI",{});var Dye=s(f_);yde=n(Dye,"STRONG",{});var bct=s(yde);eTo=r(bct,"glpn"),bct.forEach(t),oTo=r(Dye," \u2014 "),Vq=n(Dye,"A",{href:!0});var vct=s(Vq);rTo=r(vct,"GLPNModel"),vct.forEach(t),tTo=r(Dye," (GLPN model)"),Dye.forEach(t),aTo=i($),m_=n($,"LI",{});var Gye=s(m_);xde=n(Gye,"STRONG",{});var Fct=s(xde);nTo=r(Fct,"gpt2"),Fct.forEach(t),sTo=r(Gye," \u2014 "),Xq=n(Gye,"A",{href:!0});var Tct=s(Xq);lTo=r(Tct,"GPT2Model"),Tct.forEach(t),iTo=r(Gye," (OpenAI GPT-2 model)"),Gye.forEach(t),dTo=i($),g_=n($,"LI",{});var Oye=s(g_);$de=n(Oye,"STRONG",{});var Mct=s($de);cTo=r(Mct,"gpt_neo"),Mct.forEach(t),fTo=r(Oye," \u2014 "),zq=n(Oye,"A",{href:!0});var Ect=s(zq);mTo=r(Ect,"GPTNeoModel"),Ect.forEach(t),gTo=r(Oye," (GPT Neo model)"),Oye.forEach(t),hTo=i($),h_=n($,"LI",{});var Vye=s(h_);kde=n(Vye,"STRONG",{});var Cct=s(kde);pTo=r(Cct,"gpt_neox"),Cct.forEach(t),_To=r(Vye," \u2014 "),Qq=n(Vye,"A",{href:!0});var wct=s(Qq);uTo=r(wct,"GPTNeoXModel"),wct.forEach(t),bTo=r(Vye," (GPT NeoX model)"),Vye.forEach(t),vTo=i($),p_=n($,"LI",{});var Xye=s(p_);Sde=n(Xye,"STRONG",{});var Act=s(Sde);FTo=r(Act,"gptj"),Act.forEach(t),TTo=r(Xye," \u2014 "),Wq=n(Xye,"A",{href:!0});var Lct=s(Wq);MTo=r(Lct,"GPTJModel"),Lct.forEach(t),ETo=r(Xye," (GPT-J model)"),Xye.forEach(t),CTo=i($),__=n($,"LI",{});var zye=s(__);Rde=n(zye,"STRONG",{});var yct=s(Rde);wTo=r(yct,"hubert"),yct.forEach(t),ATo=r(zye," \u2014 "),Hq=n(zye,"A",{href:!0});var xct=s(Hq);LTo=r(xct,"HubertModel"),xct.forEach(t),yTo=r(zye," (Hubert model)"),zye.forEach(t),xTo=i($),u_=n($,"LI",{});var Qye=s(u_);Pde=n(Qye,"STRONG",{});var $ct=s(Pde);$To=r($ct,"ibert"),$ct.forEach(t),kTo=r(Qye," \u2014 "),Uq=n(Qye,"A",{href:!0});var kct=s(Uq);STo=r(kct,"IBertModel"),kct.forEach(t),RTo=r(Qye," (I-BERT model)"),Qye.forEach(t),PTo=i($),b_=n($,"LI",{});var Wye=s(b_);Bde=n(Wye,"STRONG",{});var Sct=s(Bde);BTo=r(Sct,"imagegpt"),Sct.forEach(t),ITo=r(Wye," \u2014 "),Jq=n(Wye,"A",{href:!0});var Rct=s(Jq);NTo=r(Rct,"ImageGPTModel"),Rct.forEach(t),qTo=r(Wye," (ImageGPT model)"),Wye.forEach(t),jTo=i($),v_=n($,"LI",{});var Hye=s(v_);Ide=n(Hye,"STRONG",{});var Pct=s(Ide);DTo=r(Pct,"jukebox"),Pct.forEach(t),GTo=r(Hye," \u2014 "),Nde=n(Hye,"CODE",{});var Bct=s(Nde);OTo=r(Bct,"JukeboxModel"),Bct.forEach(t),VTo=r(Hye," (Jukebox model)"),Hye.forEach(t),XTo=i($),F_=n($,"LI",{});var Uye=s(F_);qde=n(Uye,"STRONG",{});var Ict=s(qde);zTo=r(Ict,"layoutlm"),Ict.forEach(t),QTo=r(Uye," \u2014 "),Yq=n(Uye,"A",{href:!0});var Nct=s(Yq);WTo=r(Nct,"LayoutLMModel"),Nct.forEach(t),HTo=r(Uye," (LayoutLM model)"),Uye.forEach(t),UTo=i($),T_=n($,"LI",{});var Jye=s(T_);jde=n(Jye,"STRONG",{});var qct=s(jde);JTo=r(qct,"layoutlmv2"),qct.forEach(t),YTo=r(Jye," \u2014 "),Kq=n(Jye,"A",{href:!0});var jct=s(Kq);KTo=r(jct,"LayoutLMv2Model"),jct.forEach(t),ZTo=r(Jye," (LayoutLMv2 model)"),Jye.forEach(t),e7o=i($),M_=n($,"LI",{});var Yye=s(M_);Dde=n(Yye,"STRONG",{});var Dct=s(Dde);o7o=r(Dct,"layoutlmv3"),Dct.forEach(t),r7o=r(Yye," \u2014 "),Zq=n(Yye,"A",{href:!0});var Gct=s(Zq);t7o=r(Gct,"LayoutLMv3Model"),Gct.forEach(t),a7o=r(Yye," (LayoutLMv3 model)"),Yye.forEach(t),n7o=i($),E_=n($,"LI",{});var Kye=s(E_);Gde=n(Kye,"STRONG",{});var Oct=s(Gde);s7o=r(Oct,"led"),Oct.forEach(t),l7o=r(Kye," \u2014 "),ej=n(Kye,"A",{href:!0});var Vct=s(ej);i7o=r(Vct,"LEDModel"),Vct.forEach(t),d7o=r(Kye," (LED model)"),Kye.forEach(t),c7o=i($),C_=n($,"LI",{});var Zye=s(C_);Ode=n(Zye,"STRONG",{});var Xct=s(Ode);f7o=r(Xct,"levit"),Xct.forEach(t),m7o=r(Zye," \u2014 "),oj=n(Zye,"A",{href:!0});var zct=s(oj);g7o=r(zct,"LevitModel"),zct.forEach(t),h7o=r(Zye," (LeViT model)"),Zye.forEach(t),p7o=i($),w_=n($,"LI",{});var e9e=s(w_);Vde=n(e9e,"STRONG",{});var Qct=s(Vde);_7o=r(Qct,"longformer"),Qct.forEach(t),u7o=r(e9e," \u2014 "),rj=n(e9e,"A",{href:!0});var Wct=s(rj);b7o=r(Wct,"LongformerModel"),Wct.forEach(t),v7o=r(e9e," (Longformer model)"),e9e.forEach(t),F7o=i($),A_=n($,"LI",{});var o9e=s(A_);Xde=n(o9e,"STRONG",{});var Hct=s(Xde);T7o=r(Hct,"longt5"),Hct.forEach(t),M7o=r(o9e," \u2014 "),tj=n(o9e,"A",{href:!0});var Uct=s(tj);E7o=r(Uct,"LongT5Model"),Uct.forEach(t),C7o=r(o9e," (LongT5 model)"),o9e.forEach(t),w7o=i($),L_=n($,"LI",{});var r9e=s(L_);zde=n(r9e,"STRONG",{});var Jct=s(zde);A7o=r(Jct,"luke"),Jct.forEach(t),L7o=r(r9e," \u2014 "),aj=n(r9e,"A",{href:!0});var Yct=s(aj);y7o=r(Yct,"LukeModel"),Yct.forEach(t),x7o=r(r9e," (LUKE model)"),r9e.forEach(t),$7o=i($),y_=n($,"LI",{});var t9e=s(y_);Qde=n(t9e,"STRONG",{});var Kct=s(Qde);k7o=r(Kct,"lxmert"),Kct.forEach(t),S7o=r(t9e," \u2014 "),nj=n(t9e,"A",{href:!0});var Zct=s(nj);R7o=r(Zct,"LxmertModel"),Zct.forEach(t),P7o=r(t9e," (LXMERT model)"),t9e.forEach(t),B7o=i($),x_=n($,"LI",{});var a9e=s(x_);Wde=n(a9e,"STRONG",{});var eft=s(Wde);I7o=r(eft,"m2m_100"),eft.forEach(t),N7o=r(a9e," \u2014 "),sj=n(a9e,"A",{href:!0});var oft=s(sj);q7o=r(oft,"M2M100Model"),oft.forEach(t),j7o=r(a9e," (M2M100 model)"),a9e.forEach(t),D7o=i($),$_=n($,"LI",{});var n9e=s($_);Hde=n(n9e,"STRONG",{});var rft=s(Hde);G7o=r(rft,"marian"),rft.forEach(t),O7o=r(n9e," \u2014 "),lj=n(n9e,"A",{href:!0});var tft=s(lj);V7o=r(tft,"MarianModel"),tft.forEach(t),X7o=r(n9e," (Marian model)"),n9e.forEach(t),z7o=i($),k_=n($,"LI",{});var s9e=s(k_);Ude=n(s9e,"STRONG",{});var aft=s(Ude);Q7o=r(aft,"maskformer"),aft.forEach(t),W7o=r(s9e," \u2014 "),ij=n(s9e,"A",{href:!0});var nft=s(ij);H7o=r(nft,"MaskFormerModel"),nft.forEach(t),U7o=r(s9e," (MaskFormer model)"),s9e.forEach(t),J7o=i($),S_=n($,"LI",{});var l9e=s(S_);Jde=n(l9e,"STRONG",{});var sft=s(Jde);Y7o=r(sft,"mbart"),sft.forEach(t),K7o=r(l9e," \u2014 "),dj=n(l9e,"A",{href:!0});var lft=s(dj);Z7o=r(lft,"MBartModel"),lft.forEach(t),e8o=r(l9e," (mBART model)"),l9e.forEach(t),o8o=i($),R_=n($,"LI",{});var i9e=s(R_);Yde=n(i9e,"STRONG",{});var ift=s(Yde);r8o=r(ift,"mctct"),ift.forEach(t),t8o=r(i9e," \u2014 "),cj=n(i9e,"A",{href:!0});var dft=s(cj);a8o=r(dft,"MCTCTModel"),dft.forEach(t),n8o=r(i9e," (M-CTC-T model)"),i9e.forEach(t),s8o=i($),P_=n($,"LI",{});var d9e=s(P_);Kde=n(d9e,"STRONG",{});var cft=s(Kde);l8o=r(cft,"megatron-bert"),cft.forEach(t),i8o=r(d9e," \u2014 "),fj=n(d9e,"A",{href:!0});var fft=s(fj);d8o=r(fft,"MegatronBertModel"),fft.forEach(t),c8o=r(d9e," (Megatron-BERT model)"),d9e.forEach(t),f8o=i($),B_=n($,"LI",{});var c9e=s(B_);Zde=n(c9e,"STRONG",{});var mft=s(Zde);m8o=r(mft,"mobilebert"),mft.forEach(t),g8o=r(c9e," \u2014 "),mj=n(c9e,"A",{href:!0});var gft=s(mj);h8o=r(gft,"MobileBertModel"),gft.forEach(t),p8o=r(c9e," (MobileBERT model)"),c9e.forEach(t),_8o=i($),I_=n($,"LI",{});var f9e=s(I_);ece=n(f9e,"STRONG",{});var hft=s(ece);u8o=r(hft,"mpnet"),hft.forEach(t),b8o=r(f9e," \u2014 "),gj=n(f9e,"A",{href:!0});var pft=s(gj);v8o=r(pft,"MPNetModel"),pft.forEach(t),F8o=r(f9e," (MPNet model)"),f9e.forEach(t),T8o=i($),N_=n($,"LI",{});var m9e=s(N_);oce=n(m9e,"STRONG",{});var _ft=s(oce);M8o=r(_ft,"mt5"),_ft.forEach(t),E8o=r(m9e," \u2014 "),hj=n(m9e,"A",{href:!0});var uft=s(hj);C8o=r(uft,"MT5Model"),uft.forEach(t),w8o=r(m9e," (MT5 model)"),m9e.forEach(t),A8o=i($),q_=n($,"LI",{});var g9e=s(q_);rce=n(g9e,"STRONG",{});var bft=s(rce);L8o=r(bft,"nezha"),bft.forEach(t),y8o=r(g9e," \u2014 "),pj=n(g9e,"A",{href:!0});var vft=s(pj);x8o=r(vft,"NezhaModel"),vft.forEach(t),$8o=r(g9e," (Nezha model)"),g9e.forEach(t),k8o=i($),j_=n($,"LI",{});var h9e=s(j_);tce=n(h9e,"STRONG",{});var Fft=s(tce);S8o=r(Fft,"nystromformer"),Fft.forEach(t),R8o=r(h9e," \u2014 "),_j=n(h9e,"A",{href:!0});var Tft=s(_j);P8o=r(Tft,"NystromformerModel"),Tft.forEach(t),B8o=r(h9e," (Nystr\xF6mformer model)"),h9e.forEach(t),I8o=i($),D_=n($,"LI",{});var p9e=s(D_);ace=n(p9e,"STRONG",{});var Mft=s(ace);N8o=r(Mft,"openai-gpt"),Mft.forEach(t),q8o=r(p9e," \u2014 "),uj=n(p9e,"A",{href:!0});var Eft=s(uj);j8o=r(Eft,"OpenAIGPTModel"),Eft.forEach(t),D8o=r(p9e," (OpenAI GPT model)"),p9e.forEach(t),G8o=i($),G_=n($,"LI",{});var _9e=s(G_);nce=n(_9e,"STRONG",{});var Cft=s(nce);O8o=r(Cft,"opt"),Cft.forEach(t),V8o=r(_9e," \u2014 "),bj=n(_9e,"A",{href:!0});var wft=s(bj);X8o=r(wft,"OPTModel"),wft.forEach(t),z8o=r(_9e," (OPT model)"),_9e.forEach(t),Q8o=i($),O_=n($,"LI",{});var u9e=s(O_);sce=n(u9e,"STRONG",{});var Aft=s(sce);W8o=r(Aft,"pegasus"),Aft.forEach(t),H8o=r(u9e," \u2014 "),vj=n(u9e,"A",{href:!0});var Lft=s(vj);U8o=r(Lft,"PegasusModel"),Lft.forEach(t),J8o=r(u9e," (Pegasus model)"),u9e.forEach(t),Y8o=i($),V_=n($,"LI",{});var b9e=s(V_);lce=n(b9e,"STRONG",{});var yft=s(lce);K8o=r(yft,"perceiver"),yft.forEach(t),Z8o=r(b9e," \u2014 "),Fj=n(b9e,"A",{href:!0});var xft=s(Fj);eMo=r(xft,"PerceiverModel"),xft.forEach(t),oMo=r(b9e," (Perceiver model)"),b9e.forEach(t),rMo=i($),X_=n($,"LI",{});var v9e=s(X_);ice=n(v9e,"STRONG",{});var $ft=s(ice);tMo=r($ft,"plbart"),$ft.forEach(t),aMo=r(v9e," \u2014 "),Tj=n(v9e,"A",{href:!0});var kft=s(Tj);nMo=r(kft,"PLBartModel"),kft.forEach(t),sMo=r(v9e," (PLBart model)"),v9e.forEach(t),lMo=i($),z_=n($,"LI",{});var F9e=s(z_);dce=n(F9e,"STRONG",{});var Sft=s(dce);iMo=r(Sft,"poolformer"),Sft.forEach(t),dMo=r(F9e," \u2014 "),Mj=n(F9e,"A",{href:!0});var Rft=s(Mj);cMo=r(Rft,"PoolFormerModel"),Rft.forEach(t),fMo=r(F9e," (PoolFormer model)"),F9e.forEach(t),mMo=i($),Q_=n($,"LI",{});var T9e=s(Q_);cce=n(T9e,"STRONG",{});var Pft=s(cce);gMo=r(Pft,"prophetnet"),Pft.forEach(t),hMo=r(T9e," \u2014 "),Ej=n(T9e,"A",{href:!0});var Bft=s(Ej);pMo=r(Bft,"ProphetNetModel"),Bft.forEach(t),_Mo=r(T9e," (ProphetNet model)"),T9e.forEach(t),uMo=i($),W_=n($,"LI",{});var M9e=s(W_);fce=n(M9e,"STRONG",{});var Ift=s(fce);bMo=r(Ift,"qdqbert"),Ift.forEach(t),vMo=r(M9e," \u2014 "),Cj=n(M9e,"A",{href:!0});var Nft=s(Cj);FMo=r(Nft,"QDQBertModel"),Nft.forEach(t),TMo=r(M9e," (QDQBert model)"),M9e.forEach(t),MMo=i($),H_=n($,"LI",{});var E9e=s(H_);mce=n(E9e,"STRONG",{});var qft=s(mce);EMo=r(qft,"reformer"),qft.forEach(t),CMo=r(E9e," \u2014 "),wj=n(E9e,"A",{href:!0});var jft=s(wj);wMo=r(jft,"ReformerModel"),jft.forEach(t),AMo=r(E9e," (Reformer model)"),E9e.forEach(t),LMo=i($),U_=n($,"LI",{});var C9e=s(U_);gce=n(C9e,"STRONG",{});var Dft=s(gce);yMo=r(Dft,"regnet"),Dft.forEach(t),xMo=r(C9e," \u2014 "),Aj=n(C9e,"A",{href:!0});var Gft=s(Aj);$Mo=r(Gft,"RegNetModel"),Gft.forEach(t),kMo=r(C9e," (RegNet model)"),C9e.forEach(t),SMo=i($),J_=n($,"LI",{});var w9e=s(J_);hce=n(w9e,"STRONG",{});var Oft=s(hce);RMo=r(Oft,"rembert"),Oft.forEach(t),PMo=r(w9e," \u2014 "),Lj=n(w9e,"A",{href:!0});var Vft=s(Lj);BMo=r(Vft,"RemBertModel"),Vft.forEach(t),IMo=r(w9e," (RemBERT model)"),w9e.forEach(t),NMo=i($),Y_=n($,"LI",{});var A9e=s(Y_);pce=n(A9e,"STRONG",{});var Xft=s(pce);qMo=r(Xft,"resnet"),Xft.forEach(t),jMo=r(A9e," \u2014 "),yj=n(A9e,"A",{href:!0});var zft=s(yj);DMo=r(zft,"ResNetModel"),zft.forEach(t),GMo=r(A9e," (ResNet model)"),A9e.forEach(t),OMo=i($),K_=n($,"LI",{});var L9e=s(K_);_ce=n(L9e,"STRONG",{});var Qft=s(_ce);VMo=r(Qft,"retribert"),Qft.forEach(t),XMo=r(L9e," \u2014 "),xj=n(L9e,"A",{href:!0});var Wft=s(xj);zMo=r(Wft,"RetriBertModel"),Wft.forEach(t),QMo=r(L9e," (RetriBERT model)"),L9e.forEach(t),WMo=i($),Z_=n($,"LI",{});var y9e=s(Z_);uce=n(y9e,"STRONG",{});var Hft=s(uce);HMo=r(Hft,"roberta"),Hft.forEach(t),UMo=r(y9e," \u2014 "),$j=n(y9e,"A",{href:!0});var Uft=s($j);JMo=r(Uft,"RobertaModel"),Uft.forEach(t),YMo=r(y9e," (RoBERTa model)"),y9e.forEach(t),KMo=i($),eu=n($,"LI",{});var x9e=s(eu);bce=n(x9e,"STRONG",{});var Jft=s(bce);ZMo=r(Jft,"roformer"),Jft.forEach(t),eEo=r(x9e," \u2014 "),kj=n(x9e,"A",{href:!0});var Yft=s(kj);oEo=r(Yft,"RoFormerModel"),Yft.forEach(t),rEo=r(x9e," (RoFormer model)"),x9e.forEach(t),tEo=i($),ou=n($,"LI",{});var $9e=s(ou);vce=n($9e,"STRONG",{});var Kft=s(vce);aEo=r(Kft,"segformer"),Kft.forEach(t),nEo=r($9e," \u2014 "),Sj=n($9e,"A",{href:!0});var Zft=s(Sj);sEo=r(Zft,"SegformerModel"),Zft.forEach(t),lEo=r($9e," (SegFormer model)"),$9e.forEach(t),iEo=i($),ru=n($,"LI",{});var k9e=s(ru);Fce=n(k9e,"STRONG",{});var emt=s(Fce);dEo=r(emt,"sew"),emt.forEach(t),cEo=r(k9e," \u2014 "),Rj=n(k9e,"A",{href:!0});var omt=s(Rj);fEo=r(omt,"SEWModel"),omt.forEach(t),mEo=r(k9e," (SEW model)"),k9e.forEach(t),gEo=i($),tu=n($,"LI",{});var S9e=s(tu);Tce=n(S9e,"STRONG",{});var rmt=s(Tce);hEo=r(rmt,"sew-d"),rmt.forEach(t),pEo=r(S9e," \u2014 "),Pj=n(S9e,"A",{href:!0});var tmt=s(Pj);_Eo=r(tmt,"SEWDModel"),tmt.forEach(t),uEo=r(S9e," (SEW-D model)"),S9e.forEach(t),bEo=i($),au=n($,"LI",{});var R9e=s(au);Mce=n(R9e,"STRONG",{});var amt=s(Mce);vEo=r(amt,"speech_to_text"),amt.forEach(t),FEo=r(R9e," \u2014 "),Bj=n(R9e,"A",{href:!0});var nmt=s(Bj);TEo=r(nmt,"Speech2TextModel"),nmt.forEach(t),MEo=r(R9e," (Speech2Text model)"),R9e.forEach(t),EEo=i($),nu=n($,"LI",{});var P9e=s(nu);Ece=n(P9e,"STRONG",{});var smt=s(Ece);CEo=r(smt,"splinter"),smt.forEach(t),wEo=r(P9e," \u2014 "),Ij=n(P9e,"A",{href:!0});var lmt=s(Ij);AEo=r(lmt,"SplinterModel"),lmt.forEach(t),LEo=r(P9e," (Splinter model)"),P9e.forEach(t),yEo=i($),su=n($,"LI",{});var B9e=s(su);Cce=n(B9e,"STRONG",{});var imt=s(Cce);xEo=r(imt,"squeezebert"),imt.forEach(t),$Eo=r(B9e," \u2014 "),Nj=n(B9e,"A",{href:!0});var dmt=s(Nj);kEo=r(dmt,"SqueezeBertModel"),dmt.forEach(t),SEo=r(B9e," (SqueezeBERT model)"),B9e.forEach(t),REo=i($),lu=n($,"LI",{});var I9e=s(lu);wce=n(I9e,"STRONG",{});var cmt=s(wce);PEo=r(cmt,"swin"),cmt.forEach(t),BEo=r(I9e," \u2014 "),qj=n(I9e,"A",{href:!0});var fmt=s(qj);IEo=r(fmt,"SwinModel"),fmt.forEach(t),NEo=r(I9e," (Swin Transformer model)"),I9e.forEach(t),qEo=i($),iu=n($,"LI",{});var N9e=s(iu);Ace=n(N9e,"STRONG",{});var mmt=s(Ace);jEo=r(mmt,"t5"),mmt.forEach(t),DEo=r(N9e," \u2014 "),jj=n(N9e,"A",{href:!0});var gmt=s(jj);GEo=r(gmt,"T5Model"),gmt.forEach(t),OEo=r(N9e," (T5 model)"),N9e.forEach(t),VEo=i($),du=n($,"LI",{});var q9e=s(du);Lce=n(q9e,"STRONG",{});var hmt=s(Lce);XEo=r(hmt,"tapas"),hmt.forEach(t),zEo=r(q9e," \u2014 "),Dj=n(q9e,"A",{href:!0});var pmt=s(Dj);QEo=r(pmt,"TapasModel"),pmt.forEach(t),WEo=r(q9e," (TAPAS model)"),q9e.forEach(t),HEo=i($),cu=n($,"LI",{});var j9e=s(cu);yce=n(j9e,"STRONG",{});var _mt=s(yce);UEo=r(_mt,"trajectory_transformer"),_mt.forEach(t),JEo=r(j9e," \u2014 "),Gj=n(j9e,"A",{href:!0});var umt=s(Gj);YEo=r(umt,"TrajectoryTransformerModel"),umt.forEach(t),KEo=r(j9e," (Trajectory Transformer model)"),j9e.forEach(t),ZEo=i($),fu=n($,"LI",{});var D9e=s(fu);xce=n(D9e,"STRONG",{});var bmt=s(xce);e4o=r(bmt,"transfo-xl"),bmt.forEach(t),o4o=r(D9e," \u2014 "),Oj=n(D9e,"A",{href:!0});var vmt=s(Oj);r4o=r(vmt,"TransfoXLModel"),vmt.forEach(t),t4o=r(D9e," (Transformer-XL model)"),D9e.forEach(t),a4o=i($),mu=n($,"LI",{});var G9e=s(mu);$ce=n(G9e,"STRONG",{});var Fmt=s($ce);n4o=r(Fmt,"unispeech"),Fmt.forEach(t),s4o=r(G9e," \u2014 "),Vj=n(G9e,"A",{href:!0});var Tmt=s(Vj);l4o=r(Tmt,"UniSpeechModel"),Tmt.forEach(t),i4o=r(G9e," (UniSpeech model)"),G9e.forEach(t),d4o=i($),gu=n($,"LI",{});var O9e=s(gu);kce=n(O9e,"STRONG",{});var Mmt=s(kce);c4o=r(Mmt,"unispeech-sat"),Mmt.forEach(t),f4o=r(O9e," \u2014 "),Xj=n(O9e,"A",{href:!0});var Emt=s(Xj);m4o=r(Emt,"UniSpeechSatModel"),Emt.forEach(t),g4o=r(O9e," (UniSpeechSat model)"),O9e.forEach(t),h4o=i($),hu=n($,"LI",{});var V9e=s(hu);Sce=n(V9e,"STRONG",{});var Cmt=s(Sce);p4o=r(Cmt,"van"),Cmt.forEach(t),_4o=r(V9e," \u2014 "),zj=n(V9e,"A",{href:!0});var wmt=s(zj);u4o=r(wmt,"VanModel"),wmt.forEach(t),b4o=r(V9e," (VAN model)"),V9e.forEach(t),v4o=i($),pu=n($,"LI",{});var X9e=s(pu);Rce=n(X9e,"STRONG",{});var Amt=s(Rce);F4o=r(Amt,"vilt"),Amt.forEach(t),T4o=r(X9e," \u2014 "),Qj=n(X9e,"A",{href:!0});var Lmt=s(Qj);M4o=r(Lmt,"ViltModel"),Lmt.forEach(t),E4o=r(X9e," (ViLT model)"),X9e.forEach(t),C4o=i($),_u=n($,"LI",{});var z9e=s(_u);Pce=n(z9e,"STRONG",{});var ymt=s(Pce);w4o=r(ymt,"vision-text-dual-encoder"),ymt.forEach(t),A4o=r(z9e," \u2014 "),Wj=n(z9e,"A",{href:!0});var xmt=s(Wj);L4o=r(xmt,"VisionTextDualEncoderModel"),xmt.forEach(t),y4o=r(z9e," (VisionTextDualEncoder model)"),z9e.forEach(t),x4o=i($),uu=n($,"LI",{});var Q9e=s(uu);Bce=n(Q9e,"STRONG",{});var $mt=s(Bce);$4o=r($mt,"visual_bert"),$mt.forEach(t),k4o=r(Q9e," \u2014 "),Hj=n(Q9e,"A",{href:!0});var kmt=s(Hj);S4o=r(kmt,"VisualBertModel"),kmt.forEach(t),R4o=r(Q9e," (VisualBERT model)"),Q9e.forEach(t),P4o=i($),bu=n($,"LI",{});var W9e=s(bu);Ice=n(W9e,"STRONG",{});var Smt=s(Ice);B4o=r(Smt,"vit"),Smt.forEach(t),I4o=r(W9e," \u2014 "),Uj=n(W9e,"A",{href:!0});var Rmt=s(Uj);N4o=r(Rmt,"ViTModel"),Rmt.forEach(t),q4o=r(W9e," (ViT model)"),W9e.forEach(t),j4o=i($),vu=n($,"LI",{});var H9e=s(vu);Nce=n(H9e,"STRONG",{});var Pmt=s(Nce);D4o=r(Pmt,"vit_mae"),Pmt.forEach(t),G4o=r(H9e," \u2014 "),Jj=n(H9e,"A",{href:!0});var Bmt=s(Jj);O4o=r(Bmt,"ViTMAEModel"),Bmt.forEach(t),V4o=r(H9e," (ViTMAE model)"),H9e.forEach(t),X4o=i($),Fu=n($,"LI",{});var U9e=s(Fu);qce=n(U9e,"STRONG",{});var Imt=s(qce);z4o=r(Imt,"wav2vec2"),Imt.forEach(t),Q4o=r(U9e," \u2014 "),Yj=n(U9e,"A",{href:!0});var Nmt=s(Yj);W4o=r(Nmt,"Wav2Vec2Model"),Nmt.forEach(t),H4o=r(U9e," (Wav2Vec2 model)"),U9e.forEach(t),U4o=i($),Tu=n($,"LI",{});var J9e=s(Tu);jce=n(J9e,"STRONG",{});var qmt=s(jce);J4o=r(qmt,"wav2vec2-conformer"),qmt.forEach(t),Y4o=r(J9e," \u2014 "),Kj=n(J9e,"A",{href:!0});var jmt=s(Kj);K4o=r(jmt,"Wav2Vec2ConformerModel"),jmt.forEach(t),Z4o=r(J9e," (Wav2Vec2-Conformer model)"),J9e.forEach(t),eCo=i($),Mu=n($,"LI",{});var Y9e=s(Mu);Dce=n(Y9e,"STRONG",{});var Dmt=s(Dce);oCo=r(Dmt,"wavlm"),Dmt.forEach(t),rCo=r(Y9e," \u2014 "),Zj=n(Y9e,"A",{href:!0});var Gmt=s(Zj);tCo=r(Gmt,"WavLMModel"),Gmt.forEach(t),aCo=r(Y9e," (WavLM model)"),Y9e.forEach(t),nCo=i($),Eu=n($,"LI",{});var K9e=s(Eu);Gce=n(K9e,"STRONG",{});var Omt=s(Gce);sCo=r(Omt,"xglm"),Omt.forEach(t),lCo=r(K9e," \u2014 "),eD=n(K9e,"A",{href:!0});var Vmt=s(eD);iCo=r(Vmt,"XGLMModel"),Vmt.forEach(t),dCo=r(K9e," (XGLM model)"),K9e.forEach(t),cCo=i($),Cu=n($,"LI",{});var Z9e=s(Cu);Oce=n(Z9e,"STRONG",{});var Xmt=s(Oce);fCo=r(Xmt,"xlm"),Xmt.forEach(t),mCo=r(Z9e," \u2014 "),oD=n(Z9e,"A",{href:!0});var zmt=s(oD);gCo=r(zmt,"XLMModel"),zmt.forEach(t),hCo=r(Z9e," (XLM model)"),Z9e.forEach(t),pCo=i($),wu=n($,"LI",{});var exe=s(wu);Vce=n(exe,"STRONG",{});var Qmt=s(Vce);_Co=r(Qmt,"xlm-prophetnet"),Qmt.forEach(t),uCo=r(exe," \u2014 "),rD=n(exe,"A",{href:!0});var Wmt=s(rD);bCo=r(Wmt,"XLMProphetNetModel"),Wmt.forEach(t),vCo=r(exe," (XLM-ProphetNet model)"),exe.forEach(t),FCo=i($),Au=n($,"LI",{});var oxe=s(Au);Xce=n(oxe,"STRONG",{});var Hmt=s(Xce);TCo=r(Hmt,"xlm-roberta"),Hmt.forEach(t),MCo=r(oxe," \u2014 "),tD=n(oxe,"A",{href:!0});var Umt=s(tD);ECo=r(Umt,"XLMRobertaModel"),Umt.forEach(t),CCo=r(oxe," (XLM-RoBERTa model)"),oxe.forEach(t),wCo=i($),Lu=n($,"LI",{});var rxe=s(Lu);zce=n(rxe,"STRONG",{});var Jmt=s(zce);ACo=r(Jmt,"xlm-roberta-xl"),Jmt.forEach(t),LCo=r(rxe," \u2014 "),aD=n(rxe,"A",{href:!0});var Ymt=s(aD);yCo=r(Ymt,"XLMRobertaXLModel"),Ymt.forEach(t),xCo=r(rxe," (XLM-RoBERTa-XL model)"),rxe.forEach(t),$Co=i($),yu=n($,"LI",{});var txe=s(yu);Qce=n(txe,"STRONG",{});var Kmt=s(Qce);kCo=r(Kmt,"xlnet"),Kmt.forEach(t),SCo=r(txe," \u2014 "),nD=n(txe,"A",{href:!0});var Zmt=s(nD);RCo=r(Zmt,"XLNetModel"),Zmt.forEach(t),PCo=r(txe," (XLNet model)"),txe.forEach(t),BCo=i($),xu=n($,"LI",{});var axe=s(xu);Wce=n(axe,"STRONG",{});var egt=s(Wce);ICo=r(egt,"yolos"),egt.forEach(t),NCo=r(axe," \u2014 "),sD=n(axe,"A",{href:!0});var ogt=s(sD);qCo=r(ogt,"YolosModel"),ogt.forEach(t),jCo=r(axe," (YOLOS model)"),axe.forEach(t),DCo=i($),$u=n($,"LI",{});var nxe=s($u);Hce=n(nxe,"STRONG",{});var rgt=s(Hce);GCo=r(rgt,"yoso"),rgt.forEach(t),OCo=r(nxe," \u2014 "),lD=n(nxe,"A",{href:!0});var tgt=s(lD);VCo=r(tgt,"YosoModel"),tgt.forEach(t),XCo=r(nxe," (YOSO model)"),nxe.forEach(t),$.forEach(t),zCo=i(aa),ku=n(aa,"P",{});var sxe=s(ku);QCo=r(sxe,"The model is set in evaluation mode by default using "),Uce=n(sxe,"CODE",{});var agt=s(Uce);WCo=r(agt,"model.eval()"),agt.forEach(t),HCo=r(sxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jce=n(sxe,"CODE",{});var ngt=s(Jce);UCo=r(ngt,"model.train()"),ngt.forEach(t),sxe.forEach(t),JCo=i(aa),T(Su.$$.fragment,aa),aa.forEach(t),Ys.forEach(t),mOe=i(f),qi=n(f,"H2",{class:!0});var bXe=s(qi);Ru=n(bXe,"A",{id:!0,class:!0,href:!0});var sgt=s(Ru);Yce=n(sgt,"SPAN",{});var lgt=s(Yce);T(dL.$$.fragment,lgt),lgt.forEach(t),sgt.forEach(t),YCo=i(bXe),Kce=n(bXe,"SPAN",{});var igt=s(Kce);KCo=r(igt,"AutoModelForPreTraining"),igt.forEach(t),bXe.forEach(t),gOe=i(f),$o=n(f,"DIV",{class:!0});var Ks=s($o);T(cL.$$.fragment,Ks),ZCo=i(Ks),ji=n(Ks,"P",{});var woe=s(ji);e5o=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),iD=n(woe,"A",{href:!0});var dgt=s(iD);o5o=r(dgt,"from_pretrained()"),dgt.forEach(t),r5o=r(woe," class method or the "),dD=n(woe,"A",{href:!0});var cgt=s(dD);t5o=r(cgt,"from_config()"),cgt.forEach(t),a5o=r(woe,` class
method.`),woe.forEach(t),n5o=i(Ks),fL=n(Ks,"P",{});var vXe=s(fL);s5o=r(vXe,"This class cannot be instantiated directly using "),Zce=n(vXe,"CODE",{});var fgt=s(Zce);l5o=r(fgt,"__init__()"),fgt.forEach(t),i5o=r(vXe," (throws an error)."),vXe.forEach(t),d5o=i(Ks),st=n(Ks,"DIV",{class:!0});var I0=s(st);T(mL.$$.fragment,I0),c5o=i(I0),efe=n(I0,"P",{});var mgt=s(efe);f5o=r(mgt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),mgt.forEach(t),m5o=i(I0),Di=n(I0,"P",{});var Aoe=s(Di);g5o=r(Aoe,`Note:
Loading a model from its configuration file does `),ofe=n(Aoe,"STRONG",{});var ggt=s(ofe);h5o=r(ggt,"not"),ggt.forEach(t),p5o=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cD=n(Aoe,"A",{href:!0});var hgt=s(cD);_5o=r(hgt,"from_pretrained()"),hgt.forEach(t),u5o=r(Aoe," to load the model weights."),Aoe.forEach(t),b5o=i(I0),T(Pu.$$.fragment,I0),I0.forEach(t),v5o=i(Ks),Ye=n(Ks,"DIV",{class:!0});var na=s(Ye);T(gL.$$.fragment,na),F5o=i(na),rfe=n(na,"P",{});var pgt=s(rfe);T5o=r(pgt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),pgt.forEach(t),M5o=i(na),Pa=n(na,"P",{});var N0=s(Pa);E5o=r(N0,"The model class to instantiate is selected based on the "),tfe=n(N0,"CODE",{});var _gt=s(tfe);C5o=r(_gt,"model_type"),_gt.forEach(t),w5o=r(N0,` property of the config object (either
passed as an argument or loaded from `),afe=n(N0,"CODE",{});var ugt=s(afe);A5o=r(ugt,"pretrained_model_name_or_path"),ugt.forEach(t),L5o=r(N0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nfe=n(N0,"CODE",{});var bgt=s(nfe);y5o=r(bgt,"pretrained_model_name_or_path"),bgt.forEach(t),x5o=r(N0,":"),N0.forEach(t),$5o=i(na),G=n(na,"UL",{});var O=s(G);Bu=n(O,"LI",{});var lxe=s(Bu);sfe=n(lxe,"STRONG",{});var vgt=s(sfe);k5o=r(vgt,"albert"),vgt.forEach(t),S5o=r(lxe," \u2014 "),fD=n(lxe,"A",{href:!0});var Fgt=s(fD);R5o=r(Fgt,"AlbertForPreTraining"),Fgt.forEach(t),P5o=r(lxe," (ALBERT model)"),lxe.forEach(t),B5o=i(O),Iu=n(O,"LI",{});var ixe=s(Iu);lfe=n(ixe,"STRONG",{});var Tgt=s(lfe);I5o=r(Tgt,"bart"),Tgt.forEach(t),N5o=r(ixe," \u2014 "),mD=n(ixe,"A",{href:!0});var Mgt=s(mD);q5o=r(Mgt,"BartForConditionalGeneration"),Mgt.forEach(t),j5o=r(ixe," (BART model)"),ixe.forEach(t),D5o=i(O),Nu=n(O,"LI",{});var dxe=s(Nu);ife=n(dxe,"STRONG",{});var Egt=s(ife);G5o=r(Egt,"bert"),Egt.forEach(t),O5o=r(dxe," \u2014 "),gD=n(dxe,"A",{href:!0});var Cgt=s(gD);V5o=r(Cgt,"BertForPreTraining"),Cgt.forEach(t),X5o=r(dxe," (BERT model)"),dxe.forEach(t),z5o=i(O),qu=n(O,"LI",{});var cxe=s(qu);dfe=n(cxe,"STRONG",{});var wgt=s(dfe);Q5o=r(wgt,"big_bird"),wgt.forEach(t),W5o=r(cxe," \u2014 "),hD=n(cxe,"A",{href:!0});var Agt=s(hD);H5o=r(Agt,"BigBirdForPreTraining"),Agt.forEach(t),U5o=r(cxe," (BigBird model)"),cxe.forEach(t),J5o=i(O),ju=n(O,"LI",{});var fxe=s(ju);cfe=n(fxe,"STRONG",{});var Lgt=s(cfe);Y5o=r(Lgt,"bloom"),Lgt.forEach(t),K5o=r(fxe," \u2014 "),pD=n(fxe,"A",{href:!0});var ygt=s(pD);Z5o=r(ygt,"BloomForCausalLM"),ygt.forEach(t),e3o=r(fxe," (BLOOM model)"),fxe.forEach(t),o3o=i(O),Du=n(O,"LI",{});var mxe=s(Du);ffe=n(mxe,"STRONG",{});var xgt=s(ffe);r3o=r(xgt,"camembert"),xgt.forEach(t),t3o=r(mxe," \u2014 "),_D=n(mxe,"A",{href:!0});var $gt=s(_D);a3o=r($gt,"CamembertForMaskedLM"),$gt.forEach(t),n3o=r(mxe," (CamemBERT model)"),mxe.forEach(t),s3o=i(O),Gu=n(O,"LI",{});var gxe=s(Gu);mfe=n(gxe,"STRONG",{});var kgt=s(mfe);l3o=r(kgt,"ctrl"),kgt.forEach(t),i3o=r(gxe," \u2014 "),uD=n(gxe,"A",{href:!0});var Sgt=s(uD);d3o=r(Sgt,"CTRLLMHeadModel"),Sgt.forEach(t),c3o=r(gxe," (CTRL model)"),gxe.forEach(t),f3o=i(O),Ou=n(O,"LI",{});var hxe=s(Ou);gfe=n(hxe,"STRONG",{});var Rgt=s(gfe);m3o=r(Rgt,"data2vec-text"),Rgt.forEach(t),g3o=r(hxe," \u2014 "),bD=n(hxe,"A",{href:!0});var Pgt=s(bD);h3o=r(Pgt,"Data2VecTextForMaskedLM"),Pgt.forEach(t),p3o=r(hxe," (Data2VecText model)"),hxe.forEach(t),_3o=i(O),Vu=n(O,"LI",{});var pxe=s(Vu);hfe=n(pxe,"STRONG",{});var Bgt=s(hfe);u3o=r(Bgt,"deberta"),Bgt.forEach(t),b3o=r(pxe," \u2014 "),vD=n(pxe,"A",{href:!0});var Igt=s(vD);v3o=r(Igt,"DebertaForMaskedLM"),Igt.forEach(t),F3o=r(pxe," (DeBERTa model)"),pxe.forEach(t),T3o=i(O),Xu=n(O,"LI",{});var _xe=s(Xu);pfe=n(_xe,"STRONG",{});var Ngt=s(pfe);M3o=r(Ngt,"deberta-v2"),Ngt.forEach(t),E3o=r(_xe," \u2014 "),FD=n(_xe,"A",{href:!0});var qgt=s(FD);C3o=r(qgt,"DebertaV2ForMaskedLM"),qgt.forEach(t),w3o=r(_xe," (DeBERTa-v2 model)"),_xe.forEach(t),A3o=i(O),zu=n(O,"LI",{});var uxe=s(zu);_fe=n(uxe,"STRONG",{});var jgt=s(_fe);L3o=r(jgt,"distilbert"),jgt.forEach(t),y3o=r(uxe," \u2014 "),TD=n(uxe,"A",{href:!0});var Dgt=s(TD);x3o=r(Dgt,"DistilBertForMaskedLM"),Dgt.forEach(t),$3o=r(uxe," (DistilBERT model)"),uxe.forEach(t),k3o=i(O),Qu=n(O,"LI",{});var bxe=s(Qu);ufe=n(bxe,"STRONG",{});var Ggt=s(ufe);S3o=r(Ggt,"electra"),Ggt.forEach(t),R3o=r(bxe," \u2014 "),MD=n(bxe,"A",{href:!0});var Ogt=s(MD);P3o=r(Ogt,"ElectraForPreTraining"),Ogt.forEach(t),B3o=r(bxe," (ELECTRA model)"),bxe.forEach(t),I3o=i(O),Wu=n(O,"LI",{});var vxe=s(Wu);bfe=n(vxe,"STRONG",{});var Vgt=s(bfe);N3o=r(Vgt,"flaubert"),Vgt.forEach(t),q3o=r(vxe," \u2014 "),ED=n(vxe,"A",{href:!0});var Xgt=s(ED);j3o=r(Xgt,"FlaubertWithLMHeadModel"),Xgt.forEach(t),D3o=r(vxe," (FlauBERT model)"),vxe.forEach(t),G3o=i(O),Hu=n(O,"LI",{});var Fxe=s(Hu);vfe=n(Fxe,"STRONG",{});var zgt=s(vfe);O3o=r(zgt,"flava"),zgt.forEach(t),V3o=r(Fxe," \u2014 "),CD=n(Fxe,"A",{href:!0});var Qgt=s(CD);X3o=r(Qgt,"FlavaForPreTraining"),Qgt.forEach(t),z3o=r(Fxe," (FLAVA model)"),Fxe.forEach(t),Q3o=i(O),Uu=n(O,"LI",{});var Txe=s(Uu);Ffe=n(Txe,"STRONG",{});var Wgt=s(Ffe);W3o=r(Wgt,"fnet"),Wgt.forEach(t),H3o=r(Txe," \u2014 "),wD=n(Txe,"A",{href:!0});var Hgt=s(wD);U3o=r(Hgt,"FNetForPreTraining"),Hgt.forEach(t),J3o=r(Txe," (FNet model)"),Txe.forEach(t),Y3o=i(O),Ju=n(O,"LI",{});var Mxe=s(Ju);Tfe=n(Mxe,"STRONG",{});var Ugt=s(Tfe);K3o=r(Ugt,"fsmt"),Ugt.forEach(t),Z3o=r(Mxe," \u2014 "),AD=n(Mxe,"A",{href:!0});var Jgt=s(AD);e0o=r(Jgt,"FSMTForConditionalGeneration"),Jgt.forEach(t),o0o=r(Mxe," (FairSeq Machine-Translation model)"),Mxe.forEach(t),r0o=i(O),Yu=n(O,"LI",{});var Exe=s(Yu);Mfe=n(Exe,"STRONG",{});var Ygt=s(Mfe);t0o=r(Ygt,"funnel"),Ygt.forEach(t),a0o=r(Exe," \u2014 "),LD=n(Exe,"A",{href:!0});var Kgt=s(LD);n0o=r(Kgt,"FunnelForPreTraining"),Kgt.forEach(t),s0o=r(Exe," (Funnel Transformer model)"),Exe.forEach(t),l0o=i(O),Ku=n(O,"LI",{});var Cxe=s(Ku);Efe=n(Cxe,"STRONG",{});var Zgt=s(Efe);i0o=r(Zgt,"gpt2"),Zgt.forEach(t),d0o=r(Cxe," \u2014 "),yD=n(Cxe,"A",{href:!0});var eht=s(yD);c0o=r(eht,"GPT2LMHeadModel"),eht.forEach(t),f0o=r(Cxe," (OpenAI GPT-2 model)"),Cxe.forEach(t),m0o=i(O),Zu=n(O,"LI",{});var wxe=s(Zu);Cfe=n(wxe,"STRONG",{});var oht=s(Cfe);g0o=r(oht,"ibert"),oht.forEach(t),h0o=r(wxe," \u2014 "),xD=n(wxe,"A",{href:!0});var rht=s(xD);p0o=r(rht,"IBertForMaskedLM"),rht.forEach(t),_0o=r(wxe," (I-BERT model)"),wxe.forEach(t),u0o=i(O),e2=n(O,"LI",{});var Axe=s(e2);wfe=n(Axe,"STRONG",{});var tht=s(wfe);b0o=r(tht,"layoutlm"),tht.forEach(t),v0o=r(Axe," \u2014 "),$D=n(Axe,"A",{href:!0});var aht=s($D);F0o=r(aht,"LayoutLMForMaskedLM"),aht.forEach(t),T0o=r(Axe," (LayoutLM model)"),Axe.forEach(t),M0o=i(O),o2=n(O,"LI",{});var Lxe=s(o2);Afe=n(Lxe,"STRONG",{});var nht=s(Afe);E0o=r(nht,"longformer"),nht.forEach(t),C0o=r(Lxe," \u2014 "),kD=n(Lxe,"A",{href:!0});var sht=s(kD);w0o=r(sht,"LongformerForMaskedLM"),sht.forEach(t),A0o=r(Lxe," (Longformer model)"),Lxe.forEach(t),L0o=i(O),r2=n(O,"LI",{});var yxe=s(r2);Lfe=n(yxe,"STRONG",{});var lht=s(Lfe);y0o=r(lht,"lxmert"),lht.forEach(t),x0o=r(yxe," \u2014 "),SD=n(yxe,"A",{href:!0});var iht=s(SD);$0o=r(iht,"LxmertForPreTraining"),iht.forEach(t),k0o=r(yxe," (LXMERT model)"),yxe.forEach(t),S0o=i(O),t2=n(O,"LI",{});var xxe=s(t2);yfe=n(xxe,"STRONG",{});var dht=s(yfe);R0o=r(dht,"megatron-bert"),dht.forEach(t),P0o=r(xxe," \u2014 "),RD=n(xxe,"A",{href:!0});var cht=s(RD);B0o=r(cht,"MegatronBertForPreTraining"),cht.forEach(t),I0o=r(xxe," (Megatron-BERT model)"),xxe.forEach(t),N0o=i(O),a2=n(O,"LI",{});var $xe=s(a2);xfe=n($xe,"STRONG",{});var fht=s(xfe);q0o=r(fht,"mobilebert"),fht.forEach(t),j0o=r($xe," \u2014 "),PD=n($xe,"A",{href:!0});var mht=s(PD);D0o=r(mht,"MobileBertForPreTraining"),mht.forEach(t),G0o=r($xe," (MobileBERT model)"),$xe.forEach(t),O0o=i(O),n2=n(O,"LI",{});var kxe=s(n2);$fe=n(kxe,"STRONG",{});var ght=s($fe);V0o=r(ght,"mpnet"),ght.forEach(t),X0o=r(kxe," \u2014 "),BD=n(kxe,"A",{href:!0});var hht=s(BD);z0o=r(hht,"MPNetForMaskedLM"),hht.forEach(t),Q0o=r(kxe," (MPNet model)"),kxe.forEach(t),W0o=i(O),s2=n(O,"LI",{});var Sxe=s(s2);kfe=n(Sxe,"STRONG",{});var pht=s(kfe);H0o=r(pht,"nezha"),pht.forEach(t),U0o=r(Sxe," \u2014 "),ID=n(Sxe,"A",{href:!0});var _ht=s(ID);J0o=r(_ht,"NezhaForPreTraining"),_ht.forEach(t),Y0o=r(Sxe," (Nezha model)"),Sxe.forEach(t),K0o=i(O),l2=n(O,"LI",{});var Rxe=s(l2);Sfe=n(Rxe,"STRONG",{});var uht=s(Sfe);Z0o=r(uht,"openai-gpt"),uht.forEach(t),ewo=r(Rxe," \u2014 "),ND=n(Rxe,"A",{href:!0});var bht=s(ND);owo=r(bht,"OpenAIGPTLMHeadModel"),bht.forEach(t),rwo=r(Rxe," (OpenAI GPT model)"),Rxe.forEach(t),two=i(O),i2=n(O,"LI",{});var Pxe=s(i2);Rfe=n(Pxe,"STRONG",{});var vht=s(Rfe);awo=r(vht,"retribert"),vht.forEach(t),nwo=r(Pxe," \u2014 "),qD=n(Pxe,"A",{href:!0});var Fht=s(qD);swo=r(Fht,"RetriBertModel"),Fht.forEach(t),lwo=r(Pxe," (RetriBERT model)"),Pxe.forEach(t),iwo=i(O),d2=n(O,"LI",{});var Bxe=s(d2);Pfe=n(Bxe,"STRONG",{});var Tht=s(Pfe);dwo=r(Tht,"roberta"),Tht.forEach(t),cwo=r(Bxe," \u2014 "),jD=n(Bxe,"A",{href:!0});var Mht=s(jD);fwo=r(Mht,"RobertaForMaskedLM"),Mht.forEach(t),mwo=r(Bxe," (RoBERTa model)"),Bxe.forEach(t),gwo=i(O),c2=n(O,"LI",{});var Ixe=s(c2);Bfe=n(Ixe,"STRONG",{});var Eht=s(Bfe);hwo=r(Eht,"splinter"),Eht.forEach(t),pwo=r(Ixe," \u2014 "),DD=n(Ixe,"A",{href:!0});var Cht=s(DD);_wo=r(Cht,"SplinterForPreTraining"),Cht.forEach(t),uwo=r(Ixe," (Splinter model)"),Ixe.forEach(t),bwo=i(O),f2=n(O,"LI",{});var Nxe=s(f2);Ife=n(Nxe,"STRONG",{});var wht=s(Ife);vwo=r(wht,"squeezebert"),wht.forEach(t),Fwo=r(Nxe," \u2014 "),GD=n(Nxe,"A",{href:!0});var Aht=s(GD);Two=r(Aht,"SqueezeBertForMaskedLM"),Aht.forEach(t),Mwo=r(Nxe," (SqueezeBERT model)"),Nxe.forEach(t),Ewo=i(O),m2=n(O,"LI",{});var qxe=s(m2);Nfe=n(qxe,"STRONG",{});var Lht=s(Nfe);Cwo=r(Lht,"t5"),Lht.forEach(t),wwo=r(qxe," \u2014 "),OD=n(qxe,"A",{href:!0});var yht=s(OD);Awo=r(yht,"T5ForConditionalGeneration"),yht.forEach(t),Lwo=r(qxe," (T5 model)"),qxe.forEach(t),ywo=i(O),g2=n(O,"LI",{});var jxe=s(g2);qfe=n(jxe,"STRONG",{});var xht=s(qfe);xwo=r(xht,"tapas"),xht.forEach(t),$wo=r(jxe," \u2014 "),VD=n(jxe,"A",{href:!0});var $ht=s(VD);kwo=r($ht,"TapasForMaskedLM"),$ht.forEach(t),Swo=r(jxe," (TAPAS model)"),jxe.forEach(t),Rwo=i(O),h2=n(O,"LI",{});var Dxe=s(h2);jfe=n(Dxe,"STRONG",{});var kht=s(jfe);Pwo=r(kht,"transfo-xl"),kht.forEach(t),Bwo=r(Dxe," \u2014 "),XD=n(Dxe,"A",{href:!0});var Sht=s(XD);Iwo=r(Sht,"TransfoXLLMHeadModel"),Sht.forEach(t),Nwo=r(Dxe," (Transformer-XL model)"),Dxe.forEach(t),qwo=i(O),p2=n(O,"LI",{});var Gxe=s(p2);Dfe=n(Gxe,"STRONG",{});var Rht=s(Dfe);jwo=r(Rht,"unispeech"),Rht.forEach(t),Dwo=r(Gxe," \u2014 "),zD=n(Gxe,"A",{href:!0});var Pht=s(zD);Gwo=r(Pht,"UniSpeechForPreTraining"),Pht.forEach(t),Owo=r(Gxe," (UniSpeech model)"),Gxe.forEach(t),Vwo=i(O),_2=n(O,"LI",{});var Oxe=s(_2);Gfe=n(Oxe,"STRONG",{});var Bht=s(Gfe);Xwo=r(Bht,"unispeech-sat"),Bht.forEach(t),zwo=r(Oxe," \u2014 "),QD=n(Oxe,"A",{href:!0});var Iht=s(QD);Qwo=r(Iht,"UniSpeechSatForPreTraining"),Iht.forEach(t),Wwo=r(Oxe," (UniSpeechSat model)"),Oxe.forEach(t),Hwo=i(O),u2=n(O,"LI",{});var Vxe=s(u2);Ofe=n(Vxe,"STRONG",{});var Nht=s(Ofe);Uwo=r(Nht,"visual_bert"),Nht.forEach(t),Jwo=r(Vxe," \u2014 "),WD=n(Vxe,"A",{href:!0});var qht=s(WD);Ywo=r(qht,"VisualBertForPreTraining"),qht.forEach(t),Kwo=r(Vxe," (VisualBERT model)"),Vxe.forEach(t),Zwo=i(O),b2=n(O,"LI",{});var Xxe=s(b2);Vfe=n(Xxe,"STRONG",{});var jht=s(Vfe);eAo=r(jht,"vit_mae"),jht.forEach(t),oAo=r(Xxe," \u2014 "),HD=n(Xxe,"A",{href:!0});var Dht=s(HD);rAo=r(Dht,"ViTMAEForPreTraining"),Dht.forEach(t),tAo=r(Xxe," (ViTMAE model)"),Xxe.forEach(t),aAo=i(O),v2=n(O,"LI",{});var zxe=s(v2);Xfe=n(zxe,"STRONG",{});var Ght=s(Xfe);nAo=r(Ght,"wav2vec2"),Ght.forEach(t),sAo=r(zxe," \u2014 "),UD=n(zxe,"A",{href:!0});var Oht=s(UD);lAo=r(Oht,"Wav2Vec2ForPreTraining"),Oht.forEach(t),iAo=r(zxe," (Wav2Vec2 model)"),zxe.forEach(t),dAo=i(O),F2=n(O,"LI",{});var Qxe=s(F2);zfe=n(Qxe,"STRONG",{});var Vht=s(zfe);cAo=r(Vht,"wav2vec2-conformer"),Vht.forEach(t),fAo=r(Qxe," \u2014 "),JD=n(Qxe,"A",{href:!0});var Xht=s(JD);mAo=r(Xht,"Wav2Vec2ConformerForPreTraining"),Xht.forEach(t),gAo=r(Qxe," (Wav2Vec2-Conformer model)"),Qxe.forEach(t),hAo=i(O),T2=n(O,"LI",{});var Wxe=s(T2);Qfe=n(Wxe,"STRONG",{});var zht=s(Qfe);pAo=r(zht,"xlm"),zht.forEach(t),_Ao=r(Wxe," \u2014 "),YD=n(Wxe,"A",{href:!0});var Qht=s(YD);uAo=r(Qht,"XLMWithLMHeadModel"),Qht.forEach(t),bAo=r(Wxe," (XLM model)"),Wxe.forEach(t),vAo=i(O),M2=n(O,"LI",{});var Hxe=s(M2);Wfe=n(Hxe,"STRONG",{});var Wht=s(Wfe);FAo=r(Wht,"xlm-roberta"),Wht.forEach(t),TAo=r(Hxe," \u2014 "),KD=n(Hxe,"A",{href:!0});var Hht=s(KD);MAo=r(Hht,"XLMRobertaForMaskedLM"),Hht.forEach(t),EAo=r(Hxe," (XLM-RoBERTa model)"),Hxe.forEach(t),CAo=i(O),E2=n(O,"LI",{});var Uxe=s(E2);Hfe=n(Uxe,"STRONG",{});var Uht=s(Hfe);wAo=r(Uht,"xlm-roberta-xl"),Uht.forEach(t),AAo=r(Uxe," \u2014 "),ZD=n(Uxe,"A",{href:!0});var Jht=s(ZD);LAo=r(Jht,"XLMRobertaXLForMaskedLM"),Jht.forEach(t),yAo=r(Uxe," (XLM-RoBERTa-XL model)"),Uxe.forEach(t),xAo=i(O),C2=n(O,"LI",{});var Jxe=s(C2);Ufe=n(Jxe,"STRONG",{});var Yht=s(Ufe);$Ao=r(Yht,"xlnet"),Yht.forEach(t),kAo=r(Jxe," \u2014 "),eG=n(Jxe,"A",{href:!0});var Kht=s(eG);SAo=r(Kht,"XLNetLMHeadModel"),Kht.forEach(t),RAo=r(Jxe," (XLNet model)"),Jxe.forEach(t),O.forEach(t),PAo=i(na),w2=n(na,"P",{});var Yxe=s(w2);BAo=r(Yxe,"The model is set in evaluation mode by default using "),Jfe=n(Yxe,"CODE",{});var Zht=s(Jfe);IAo=r(Zht,"model.eval()"),Zht.forEach(t),NAo=r(Yxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yfe=n(Yxe,"CODE",{});var ept=s(Yfe);qAo=r(ept,"model.train()"),ept.forEach(t),Yxe.forEach(t),jAo=i(na),T(A2.$$.fragment,na),na.forEach(t),Ks.forEach(t),hOe=i(f),Gi=n(f,"H2",{class:!0});var FXe=s(Gi);L2=n(FXe,"A",{id:!0,class:!0,href:!0});var opt=s(L2);Kfe=n(opt,"SPAN",{});var rpt=s(Kfe);T(hL.$$.fragment,rpt),rpt.forEach(t),opt.forEach(t),DAo=i(FXe),Zfe=n(FXe,"SPAN",{});var tpt=s(Zfe);GAo=r(tpt,"AutoModelForCausalLM"),tpt.forEach(t),FXe.forEach(t),pOe=i(f),ko=n(f,"DIV",{class:!0});var Zs=s(ko);T(pL.$$.fragment,Zs),OAo=i(Zs),Oi=n(Zs,"P",{});var Loe=s(Oi);VAo=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),oG=n(Loe,"A",{href:!0});var apt=s(oG);XAo=r(apt,"from_pretrained()"),apt.forEach(t),zAo=r(Loe," class method or the "),rG=n(Loe,"A",{href:!0});var npt=s(rG);QAo=r(npt,"from_config()"),npt.forEach(t),WAo=r(Loe,` class
method.`),Loe.forEach(t),HAo=i(Zs),_L=n(Zs,"P",{});var TXe=s(_L);UAo=r(TXe,"This class cannot be instantiated directly using "),eme=n(TXe,"CODE",{});var spt=s(eme);JAo=r(spt,"__init__()"),spt.forEach(t),YAo=r(TXe," (throws an error)."),TXe.forEach(t),KAo=i(Zs),lt=n(Zs,"DIV",{class:!0});var q0=s(lt);T(uL.$$.fragment,q0),ZAo=i(q0),ome=n(q0,"P",{});var lpt=s(ome);eLo=r(lpt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lpt.forEach(t),oLo=i(q0),Vi=n(q0,"P",{});var yoe=s(Vi);rLo=r(yoe,`Note:
Loading a model from its configuration file does `),rme=n(yoe,"STRONG",{});var ipt=s(rme);tLo=r(ipt,"not"),ipt.forEach(t),aLo=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tG=n(yoe,"A",{href:!0});var dpt=s(tG);nLo=r(dpt,"from_pretrained()"),dpt.forEach(t),sLo=r(yoe," to load the model weights."),yoe.forEach(t),lLo=i(q0),T(y2.$$.fragment,q0),q0.forEach(t),iLo=i(Zs),Ke=n(Zs,"DIV",{class:!0});var sa=s(Ke);T(bL.$$.fragment,sa),dLo=i(sa),tme=n(sa,"P",{});var cpt=s(tme);cLo=r(cpt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cpt.forEach(t),fLo=i(sa),Ba=n(sa,"P",{});var j0=s(Ba);mLo=r(j0,"The model class to instantiate is selected based on the "),ame=n(j0,"CODE",{});var fpt=s(ame);gLo=r(fpt,"model_type"),fpt.forEach(t),hLo=r(j0,` property of the config object (either
passed as an argument or loaded from `),nme=n(j0,"CODE",{});var mpt=s(nme);pLo=r(mpt,"pretrained_model_name_or_path"),mpt.forEach(t),_Lo=r(j0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sme=n(j0,"CODE",{});var gpt=s(sme);uLo=r(gpt,"pretrained_model_name_or_path"),gpt.forEach(t),bLo=r(j0,":"),j0.forEach(t),vLo=i(sa),z=n(sa,"UL",{});var W=s(z);x2=n(W,"LI",{});var Kxe=s(x2);lme=n(Kxe,"STRONG",{});var hpt=s(lme);FLo=r(hpt,"bart"),hpt.forEach(t),TLo=r(Kxe," \u2014 "),aG=n(Kxe,"A",{href:!0});var ppt=s(aG);MLo=r(ppt,"BartForCausalLM"),ppt.forEach(t),ELo=r(Kxe," (BART model)"),Kxe.forEach(t),CLo=i(W),$2=n(W,"LI",{});var Zxe=s($2);ime=n(Zxe,"STRONG",{});var _pt=s(ime);wLo=r(_pt,"bert"),_pt.forEach(t),ALo=r(Zxe," \u2014 "),nG=n(Zxe,"A",{href:!0});var upt=s(nG);LLo=r(upt,"BertLMHeadModel"),upt.forEach(t),yLo=r(Zxe," (BERT model)"),Zxe.forEach(t),xLo=i(W),k2=n(W,"LI",{});var e$e=s(k2);dme=n(e$e,"STRONG",{});var bpt=s(dme);$Lo=r(bpt,"bert-generation"),bpt.forEach(t),kLo=r(e$e," \u2014 "),sG=n(e$e,"A",{href:!0});var vpt=s(sG);SLo=r(vpt,"BertGenerationDecoder"),vpt.forEach(t),RLo=r(e$e," (Bert Generation model)"),e$e.forEach(t),PLo=i(W),S2=n(W,"LI",{});var o$e=s(S2);cme=n(o$e,"STRONG",{});var Fpt=s(cme);BLo=r(Fpt,"big_bird"),Fpt.forEach(t),ILo=r(o$e," \u2014 "),lG=n(o$e,"A",{href:!0});var Tpt=s(lG);NLo=r(Tpt,"BigBirdForCausalLM"),Tpt.forEach(t),qLo=r(o$e," (BigBird model)"),o$e.forEach(t),jLo=i(W),R2=n(W,"LI",{});var r$e=s(R2);fme=n(r$e,"STRONG",{});var Mpt=s(fme);DLo=r(Mpt,"bigbird_pegasus"),Mpt.forEach(t),GLo=r(r$e," \u2014 "),iG=n(r$e,"A",{href:!0});var Ept=s(iG);OLo=r(Ept,"BigBirdPegasusForCausalLM"),Ept.forEach(t),VLo=r(r$e," (BigBird-Pegasus model)"),r$e.forEach(t),XLo=i(W),P2=n(W,"LI",{});var t$e=s(P2);mme=n(t$e,"STRONG",{});var Cpt=s(mme);zLo=r(Cpt,"blenderbot"),Cpt.forEach(t),QLo=r(t$e," \u2014 "),dG=n(t$e,"A",{href:!0});var wpt=s(dG);WLo=r(wpt,"BlenderbotForCausalLM"),wpt.forEach(t),HLo=r(t$e," (Blenderbot model)"),t$e.forEach(t),ULo=i(W),B2=n(W,"LI",{});var a$e=s(B2);gme=n(a$e,"STRONG",{});var Apt=s(gme);JLo=r(Apt,"blenderbot-small"),Apt.forEach(t),YLo=r(a$e," \u2014 "),cG=n(a$e,"A",{href:!0});var Lpt=s(cG);KLo=r(Lpt,"BlenderbotSmallForCausalLM"),Lpt.forEach(t),ZLo=r(a$e," (BlenderbotSmall model)"),a$e.forEach(t),eyo=i(W),I2=n(W,"LI",{});var n$e=s(I2);hme=n(n$e,"STRONG",{});var ypt=s(hme);oyo=r(ypt,"bloom"),ypt.forEach(t),ryo=r(n$e," \u2014 "),fG=n(n$e,"A",{href:!0});var xpt=s(fG);tyo=r(xpt,"BloomForCausalLM"),xpt.forEach(t),ayo=r(n$e," (BLOOM model)"),n$e.forEach(t),nyo=i(W),N2=n(W,"LI",{});var s$e=s(N2);pme=n(s$e,"STRONG",{});var $pt=s(pme);syo=r($pt,"camembert"),$pt.forEach(t),lyo=r(s$e," \u2014 "),mG=n(s$e,"A",{href:!0});var kpt=s(mG);iyo=r(kpt,"CamembertForCausalLM"),kpt.forEach(t),dyo=r(s$e," (CamemBERT model)"),s$e.forEach(t),cyo=i(W),q2=n(W,"LI",{});var l$e=s(q2);_me=n(l$e,"STRONG",{});var Spt=s(_me);fyo=r(Spt,"ctrl"),Spt.forEach(t),myo=r(l$e," \u2014 "),gG=n(l$e,"A",{href:!0});var Rpt=s(gG);gyo=r(Rpt,"CTRLLMHeadModel"),Rpt.forEach(t),hyo=r(l$e," (CTRL model)"),l$e.forEach(t),pyo=i(W),j2=n(W,"LI",{});var i$e=s(j2);ume=n(i$e,"STRONG",{});var Ppt=s(ume);_yo=r(Ppt,"data2vec-text"),Ppt.forEach(t),uyo=r(i$e," \u2014 "),hG=n(i$e,"A",{href:!0});var Bpt=s(hG);byo=r(Bpt,"Data2VecTextForCausalLM"),Bpt.forEach(t),vyo=r(i$e," (Data2VecText model)"),i$e.forEach(t),Fyo=i(W),D2=n(W,"LI",{});var d$e=s(D2);bme=n(d$e,"STRONG",{});var Ipt=s(bme);Tyo=r(Ipt,"electra"),Ipt.forEach(t),Myo=r(d$e," \u2014 "),pG=n(d$e,"A",{href:!0});var Npt=s(pG);Eyo=r(Npt,"ElectraForCausalLM"),Npt.forEach(t),Cyo=r(d$e," (ELECTRA model)"),d$e.forEach(t),wyo=i(W),G2=n(W,"LI",{});var c$e=s(G2);vme=n(c$e,"STRONG",{});var qpt=s(vme);Ayo=r(qpt,"gpt2"),qpt.forEach(t),Lyo=r(c$e," \u2014 "),_G=n(c$e,"A",{href:!0});var jpt=s(_G);yyo=r(jpt,"GPT2LMHeadModel"),jpt.forEach(t),xyo=r(c$e," (OpenAI GPT-2 model)"),c$e.forEach(t),$yo=i(W),O2=n(W,"LI",{});var f$e=s(O2);Fme=n(f$e,"STRONG",{});var Dpt=s(Fme);kyo=r(Dpt,"gpt_neo"),Dpt.forEach(t),Syo=r(f$e," \u2014 "),uG=n(f$e,"A",{href:!0});var Gpt=s(uG);Ryo=r(Gpt,"GPTNeoForCausalLM"),Gpt.forEach(t),Pyo=r(f$e," (GPT Neo model)"),f$e.forEach(t),Byo=i(W),V2=n(W,"LI",{});var m$e=s(V2);Tme=n(m$e,"STRONG",{});var Opt=s(Tme);Iyo=r(Opt,"gpt_neox"),Opt.forEach(t),Nyo=r(m$e," \u2014 "),bG=n(m$e,"A",{href:!0});var Vpt=s(bG);qyo=r(Vpt,"GPTNeoXForCausalLM"),Vpt.forEach(t),jyo=r(m$e," (GPT NeoX model)"),m$e.forEach(t),Dyo=i(W),X2=n(W,"LI",{});var g$e=s(X2);Mme=n(g$e,"STRONG",{});var Xpt=s(Mme);Gyo=r(Xpt,"gptj"),Xpt.forEach(t),Oyo=r(g$e," \u2014 "),vG=n(g$e,"A",{href:!0});var zpt=s(vG);Vyo=r(zpt,"GPTJForCausalLM"),zpt.forEach(t),Xyo=r(g$e," (GPT-J model)"),g$e.forEach(t),zyo=i(W),z2=n(W,"LI",{});var h$e=s(z2);Eme=n(h$e,"STRONG",{});var Qpt=s(Eme);Qyo=r(Qpt,"marian"),Qpt.forEach(t),Wyo=r(h$e," \u2014 "),FG=n(h$e,"A",{href:!0});var Wpt=s(FG);Hyo=r(Wpt,"MarianForCausalLM"),Wpt.forEach(t),Uyo=r(h$e," (Marian model)"),h$e.forEach(t),Jyo=i(W),Q2=n(W,"LI",{});var p$e=s(Q2);Cme=n(p$e,"STRONG",{});var Hpt=s(Cme);Yyo=r(Hpt,"mbart"),Hpt.forEach(t),Kyo=r(p$e," \u2014 "),TG=n(p$e,"A",{href:!0});var Upt=s(TG);Zyo=r(Upt,"MBartForCausalLM"),Upt.forEach(t),e9o=r(p$e," (mBART model)"),p$e.forEach(t),o9o=i(W),W2=n(W,"LI",{});var _$e=s(W2);wme=n(_$e,"STRONG",{});var Jpt=s(wme);r9o=r(Jpt,"megatron-bert"),Jpt.forEach(t),t9o=r(_$e," \u2014 "),MG=n(_$e,"A",{href:!0});var Ypt=s(MG);a9o=r(Ypt,"MegatronBertForCausalLM"),Ypt.forEach(t),n9o=r(_$e," (Megatron-BERT model)"),_$e.forEach(t),s9o=i(W),H2=n(W,"LI",{});var u$e=s(H2);Ame=n(u$e,"STRONG",{});var Kpt=s(Ame);l9o=r(Kpt,"openai-gpt"),Kpt.forEach(t),i9o=r(u$e," \u2014 "),EG=n(u$e,"A",{href:!0});var Zpt=s(EG);d9o=r(Zpt,"OpenAIGPTLMHeadModel"),Zpt.forEach(t),c9o=r(u$e," (OpenAI GPT model)"),u$e.forEach(t),f9o=i(W),U2=n(W,"LI",{});var b$e=s(U2);Lme=n(b$e,"STRONG",{});var e_t=s(Lme);m9o=r(e_t,"opt"),e_t.forEach(t),g9o=r(b$e," \u2014 "),CG=n(b$e,"A",{href:!0});var o_t=s(CG);h9o=r(o_t,"OPTForCausalLM"),o_t.forEach(t),p9o=r(b$e," (OPT model)"),b$e.forEach(t),_9o=i(W),J2=n(W,"LI",{});var v$e=s(J2);yme=n(v$e,"STRONG",{});var r_t=s(yme);u9o=r(r_t,"pegasus"),r_t.forEach(t),b9o=r(v$e," \u2014 "),wG=n(v$e,"A",{href:!0});var t_t=s(wG);v9o=r(t_t,"PegasusForCausalLM"),t_t.forEach(t),F9o=r(v$e," (Pegasus model)"),v$e.forEach(t),T9o=i(W),Y2=n(W,"LI",{});var F$e=s(Y2);xme=n(F$e,"STRONG",{});var a_t=s(xme);M9o=r(a_t,"plbart"),a_t.forEach(t),E9o=r(F$e," \u2014 "),AG=n(F$e,"A",{href:!0});var n_t=s(AG);C9o=r(n_t,"PLBartForCausalLM"),n_t.forEach(t),w9o=r(F$e," (PLBart model)"),F$e.forEach(t),A9o=i(W),K2=n(W,"LI",{});var T$e=s(K2);$me=n(T$e,"STRONG",{});var s_t=s($me);L9o=r(s_t,"prophetnet"),s_t.forEach(t),y9o=r(T$e," \u2014 "),LG=n(T$e,"A",{href:!0});var l_t=s(LG);x9o=r(l_t,"ProphetNetForCausalLM"),l_t.forEach(t),$9o=r(T$e," (ProphetNet model)"),T$e.forEach(t),k9o=i(W),Z2=n(W,"LI",{});var M$e=s(Z2);kme=n(M$e,"STRONG",{});var i_t=s(kme);S9o=r(i_t,"qdqbert"),i_t.forEach(t),R9o=r(M$e," \u2014 "),yG=n(M$e,"A",{href:!0});var d_t=s(yG);P9o=r(d_t,"QDQBertLMHeadModel"),d_t.forEach(t),B9o=r(M$e," (QDQBert model)"),M$e.forEach(t),I9o=i(W),e1=n(W,"LI",{});var E$e=s(e1);Sme=n(E$e,"STRONG",{});var c_t=s(Sme);N9o=r(c_t,"reformer"),c_t.forEach(t),q9o=r(E$e," \u2014 "),xG=n(E$e,"A",{href:!0});var f_t=s(xG);j9o=r(f_t,"ReformerModelWithLMHead"),f_t.forEach(t),D9o=r(E$e," (Reformer model)"),E$e.forEach(t),G9o=i(W),o1=n(W,"LI",{});var C$e=s(o1);Rme=n(C$e,"STRONG",{});var m_t=s(Rme);O9o=r(m_t,"rembert"),m_t.forEach(t),V9o=r(C$e," \u2014 "),$G=n(C$e,"A",{href:!0});var g_t=s($G);X9o=r(g_t,"RemBertForCausalLM"),g_t.forEach(t),z9o=r(C$e," (RemBERT model)"),C$e.forEach(t),Q9o=i(W),r1=n(W,"LI",{});var w$e=s(r1);Pme=n(w$e,"STRONG",{});var h_t=s(Pme);W9o=r(h_t,"roberta"),h_t.forEach(t),H9o=r(w$e," \u2014 "),kG=n(w$e,"A",{href:!0});var p_t=s(kG);U9o=r(p_t,"RobertaForCausalLM"),p_t.forEach(t),J9o=r(w$e," (RoBERTa model)"),w$e.forEach(t),Y9o=i(W),t1=n(W,"LI",{});var A$e=s(t1);Bme=n(A$e,"STRONG",{});var __t=s(Bme);K9o=r(__t,"roformer"),__t.forEach(t),Z9o=r(A$e," \u2014 "),SG=n(A$e,"A",{href:!0});var u_t=s(SG);exo=r(u_t,"RoFormerForCausalLM"),u_t.forEach(t),oxo=r(A$e," (RoFormer model)"),A$e.forEach(t),rxo=i(W),a1=n(W,"LI",{});var L$e=s(a1);Ime=n(L$e,"STRONG",{});var b_t=s(Ime);txo=r(b_t,"speech_to_text_2"),b_t.forEach(t),axo=r(L$e," \u2014 "),RG=n(L$e,"A",{href:!0});var v_t=s(RG);nxo=r(v_t,"Speech2Text2ForCausalLM"),v_t.forEach(t),sxo=r(L$e," (Speech2Text2 model)"),L$e.forEach(t),lxo=i(W),n1=n(W,"LI",{});var y$e=s(n1);Nme=n(y$e,"STRONG",{});var F_t=s(Nme);ixo=r(F_t,"transfo-xl"),F_t.forEach(t),dxo=r(y$e," \u2014 "),PG=n(y$e,"A",{href:!0});var T_t=s(PG);cxo=r(T_t,"TransfoXLLMHeadModel"),T_t.forEach(t),fxo=r(y$e," (Transformer-XL model)"),y$e.forEach(t),mxo=i(W),s1=n(W,"LI",{});var x$e=s(s1);qme=n(x$e,"STRONG",{});var M_t=s(qme);gxo=r(M_t,"trocr"),M_t.forEach(t),hxo=r(x$e," \u2014 "),BG=n(x$e,"A",{href:!0});var E_t=s(BG);pxo=r(E_t,"TrOCRForCausalLM"),E_t.forEach(t),_xo=r(x$e," (TrOCR model)"),x$e.forEach(t),uxo=i(W),l1=n(W,"LI",{});var $$e=s(l1);jme=n($$e,"STRONG",{});var C_t=s(jme);bxo=r(C_t,"xglm"),C_t.forEach(t),vxo=r($$e," \u2014 "),IG=n($$e,"A",{href:!0});var w_t=s(IG);Fxo=r(w_t,"XGLMForCausalLM"),w_t.forEach(t),Txo=r($$e," (XGLM model)"),$$e.forEach(t),Mxo=i(W),i1=n(W,"LI",{});var k$e=s(i1);Dme=n(k$e,"STRONG",{});var A_t=s(Dme);Exo=r(A_t,"xlm"),A_t.forEach(t),Cxo=r(k$e," \u2014 "),NG=n(k$e,"A",{href:!0});var L_t=s(NG);wxo=r(L_t,"XLMWithLMHeadModel"),L_t.forEach(t),Axo=r(k$e," (XLM model)"),k$e.forEach(t),Lxo=i(W),d1=n(W,"LI",{});var S$e=s(d1);Gme=n(S$e,"STRONG",{});var y_t=s(Gme);yxo=r(y_t,"xlm-prophetnet"),y_t.forEach(t),xxo=r(S$e," \u2014 "),qG=n(S$e,"A",{href:!0});var x_t=s(qG);$xo=r(x_t,"XLMProphetNetForCausalLM"),x_t.forEach(t),kxo=r(S$e," (XLM-ProphetNet model)"),S$e.forEach(t),Sxo=i(W),c1=n(W,"LI",{});var R$e=s(c1);Ome=n(R$e,"STRONG",{});var $_t=s(Ome);Rxo=r($_t,"xlm-roberta"),$_t.forEach(t),Pxo=r(R$e," \u2014 "),jG=n(R$e,"A",{href:!0});var k_t=s(jG);Bxo=r(k_t,"XLMRobertaForCausalLM"),k_t.forEach(t),Ixo=r(R$e," (XLM-RoBERTa model)"),R$e.forEach(t),Nxo=i(W),f1=n(W,"LI",{});var P$e=s(f1);Vme=n(P$e,"STRONG",{});var S_t=s(Vme);qxo=r(S_t,"xlm-roberta-xl"),S_t.forEach(t),jxo=r(P$e," \u2014 "),DG=n(P$e,"A",{href:!0});var R_t=s(DG);Dxo=r(R_t,"XLMRobertaXLForCausalLM"),R_t.forEach(t),Gxo=r(P$e," (XLM-RoBERTa-XL model)"),P$e.forEach(t),Oxo=i(W),m1=n(W,"LI",{});var B$e=s(m1);Xme=n(B$e,"STRONG",{});var P_t=s(Xme);Vxo=r(P_t,"xlnet"),P_t.forEach(t),Xxo=r(B$e," \u2014 "),GG=n(B$e,"A",{href:!0});var B_t=s(GG);zxo=r(B_t,"XLNetLMHeadModel"),B_t.forEach(t),Qxo=r(B$e," (XLNet model)"),B$e.forEach(t),W.forEach(t),Wxo=i(sa),g1=n(sa,"P",{});var I$e=s(g1);Hxo=r(I$e,"The model is set in evaluation mode by default using "),zme=n(I$e,"CODE",{});var I_t=s(zme);Uxo=r(I_t,"model.eval()"),I_t.forEach(t),Jxo=r(I$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qme=n(I$e,"CODE",{});var N_t=s(Qme);Yxo=r(N_t,"model.train()"),N_t.forEach(t),I$e.forEach(t),Kxo=i(sa),T(h1.$$.fragment,sa),sa.forEach(t),Zs.forEach(t),_Oe=i(f),Xi=n(f,"H2",{class:!0});var MXe=s(Xi);p1=n(MXe,"A",{id:!0,class:!0,href:!0});var q_t=s(p1);Wme=n(q_t,"SPAN",{});var j_t=s(Wme);T(vL.$$.fragment,j_t),j_t.forEach(t),q_t.forEach(t),Zxo=i(MXe),Hme=n(MXe,"SPAN",{});var D_t=s(Hme);e$o=r(D_t,"AutoModelForMaskedLM"),D_t.forEach(t),MXe.forEach(t),uOe=i(f),So=n(f,"DIV",{class:!0});var el=s(So);T(FL.$$.fragment,el),o$o=i(el),zi=n(el,"P",{});var xoe=s(zi);r$o=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),OG=n(xoe,"A",{href:!0});var G_t=s(OG);t$o=r(G_t,"from_pretrained()"),G_t.forEach(t),a$o=r(xoe," class method or the "),VG=n(xoe,"A",{href:!0});var O_t=s(VG);n$o=r(O_t,"from_config()"),O_t.forEach(t),s$o=r(xoe,` class
method.`),xoe.forEach(t),l$o=i(el),TL=n(el,"P",{});var EXe=s(TL);i$o=r(EXe,"This class cannot be instantiated directly using "),Ume=n(EXe,"CODE",{});var V_t=s(Ume);d$o=r(V_t,"__init__()"),V_t.forEach(t),c$o=r(EXe," (throws an error)."),EXe.forEach(t),f$o=i(el),it=n(el,"DIV",{class:!0});var D0=s(it);T(ML.$$.fragment,D0),m$o=i(D0),Jme=n(D0,"P",{});var X_t=s(Jme);g$o=r(X_t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),X_t.forEach(t),h$o=i(D0),Qi=n(D0,"P",{});var $oe=s(Qi);p$o=r($oe,`Note:
Loading a model from its configuration file does `),Yme=n($oe,"STRONG",{});var z_t=s(Yme);_$o=r(z_t,"not"),z_t.forEach(t),u$o=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),XG=n($oe,"A",{href:!0});var Q_t=s(XG);b$o=r(Q_t,"from_pretrained()"),Q_t.forEach(t),v$o=r($oe," to load the model weights."),$oe.forEach(t),F$o=i(D0),T(_1.$$.fragment,D0),D0.forEach(t),T$o=i(el),Ze=n(el,"DIV",{class:!0});var la=s(Ze);T(EL.$$.fragment,la),M$o=i(la),Kme=n(la,"P",{});var W_t=s(Kme);E$o=r(W_t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),W_t.forEach(t),C$o=i(la),Ia=n(la,"P",{});var G0=s(Ia);w$o=r(G0,"The model class to instantiate is selected based on the "),Zme=n(G0,"CODE",{});var H_t=s(Zme);A$o=r(H_t,"model_type"),H_t.forEach(t),L$o=r(G0,` property of the config object (either
passed as an argument or loaded from `),ege=n(G0,"CODE",{});var U_t=s(ege);y$o=r(U_t,"pretrained_model_name_or_path"),U_t.forEach(t),x$o=r(G0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oge=n(G0,"CODE",{});var J_t=s(oge);$$o=r(J_t,"pretrained_model_name_or_path"),J_t.forEach(t),k$o=r(G0,":"),G0.forEach(t),S$o=i(la),Q=n(la,"UL",{});var U=s(Q);u1=n(U,"LI",{});var N$e=s(u1);rge=n(N$e,"STRONG",{});var Y_t=s(rge);R$o=r(Y_t,"albert"),Y_t.forEach(t),P$o=r(N$e," \u2014 "),zG=n(N$e,"A",{href:!0});var K_t=s(zG);B$o=r(K_t,"AlbertForMaskedLM"),K_t.forEach(t),I$o=r(N$e," (ALBERT model)"),N$e.forEach(t),N$o=i(U),b1=n(U,"LI",{});var q$e=s(b1);tge=n(q$e,"STRONG",{});var Z_t=s(tge);q$o=r(Z_t,"bart"),Z_t.forEach(t),j$o=r(q$e," \u2014 "),QG=n(q$e,"A",{href:!0});var eut=s(QG);D$o=r(eut,"BartForConditionalGeneration"),eut.forEach(t),G$o=r(q$e," (BART model)"),q$e.forEach(t),O$o=i(U),v1=n(U,"LI",{});var j$e=s(v1);age=n(j$e,"STRONG",{});var out=s(age);V$o=r(out,"bert"),out.forEach(t),X$o=r(j$e," \u2014 "),WG=n(j$e,"A",{href:!0});var rut=s(WG);z$o=r(rut,"BertForMaskedLM"),rut.forEach(t),Q$o=r(j$e," (BERT model)"),j$e.forEach(t),W$o=i(U),F1=n(U,"LI",{});var D$e=s(F1);nge=n(D$e,"STRONG",{});var tut=s(nge);H$o=r(tut,"big_bird"),tut.forEach(t),U$o=r(D$e," \u2014 "),HG=n(D$e,"A",{href:!0});var aut=s(HG);J$o=r(aut,"BigBirdForMaskedLM"),aut.forEach(t),Y$o=r(D$e," (BigBird model)"),D$e.forEach(t),K$o=i(U),T1=n(U,"LI",{});var G$e=s(T1);sge=n(G$e,"STRONG",{});var nut=s(sge);Z$o=r(nut,"camembert"),nut.forEach(t),eko=r(G$e," \u2014 "),UG=n(G$e,"A",{href:!0});var sut=s(UG);oko=r(sut,"CamembertForMaskedLM"),sut.forEach(t),rko=r(G$e," (CamemBERT model)"),G$e.forEach(t),tko=i(U),M1=n(U,"LI",{});var O$e=s(M1);lge=n(O$e,"STRONG",{});var lut=s(lge);ako=r(lut,"convbert"),lut.forEach(t),nko=r(O$e," \u2014 "),JG=n(O$e,"A",{href:!0});var iut=s(JG);sko=r(iut,"ConvBertForMaskedLM"),iut.forEach(t),lko=r(O$e," (ConvBERT model)"),O$e.forEach(t),iko=i(U),E1=n(U,"LI",{});var V$e=s(E1);ige=n(V$e,"STRONG",{});var dut=s(ige);dko=r(dut,"data2vec-text"),dut.forEach(t),cko=r(V$e," \u2014 "),YG=n(V$e,"A",{href:!0});var cut=s(YG);fko=r(cut,"Data2VecTextForMaskedLM"),cut.forEach(t),mko=r(V$e," (Data2VecText model)"),V$e.forEach(t),gko=i(U),C1=n(U,"LI",{});var X$e=s(C1);dge=n(X$e,"STRONG",{});var fut=s(dge);hko=r(fut,"deberta"),fut.forEach(t),pko=r(X$e," \u2014 "),KG=n(X$e,"A",{href:!0});var mut=s(KG);_ko=r(mut,"DebertaForMaskedLM"),mut.forEach(t),uko=r(X$e," (DeBERTa model)"),X$e.forEach(t),bko=i(U),w1=n(U,"LI",{});var z$e=s(w1);cge=n(z$e,"STRONG",{});var gut=s(cge);vko=r(gut,"deberta-v2"),gut.forEach(t),Fko=r(z$e," \u2014 "),ZG=n(z$e,"A",{href:!0});var hut=s(ZG);Tko=r(hut,"DebertaV2ForMaskedLM"),hut.forEach(t),Mko=r(z$e," (DeBERTa-v2 model)"),z$e.forEach(t),Eko=i(U),A1=n(U,"LI",{});var Q$e=s(A1);fge=n(Q$e,"STRONG",{});var put=s(fge);Cko=r(put,"distilbert"),put.forEach(t),wko=r(Q$e," \u2014 "),eO=n(Q$e,"A",{href:!0});var _ut=s(eO);Ako=r(_ut,"DistilBertForMaskedLM"),_ut.forEach(t),Lko=r(Q$e," (DistilBERT model)"),Q$e.forEach(t),yko=i(U),L1=n(U,"LI",{});var W$e=s(L1);mge=n(W$e,"STRONG",{});var uut=s(mge);xko=r(uut,"electra"),uut.forEach(t),$ko=r(W$e," \u2014 "),oO=n(W$e,"A",{href:!0});var but=s(oO);kko=r(but,"ElectraForMaskedLM"),but.forEach(t),Sko=r(W$e," (ELECTRA model)"),W$e.forEach(t),Rko=i(U),y1=n(U,"LI",{});var H$e=s(y1);gge=n(H$e,"STRONG",{});var vut=s(gge);Pko=r(vut,"flaubert"),vut.forEach(t),Bko=r(H$e," \u2014 "),rO=n(H$e,"A",{href:!0});var Fut=s(rO);Iko=r(Fut,"FlaubertWithLMHeadModel"),Fut.forEach(t),Nko=r(H$e," (FlauBERT model)"),H$e.forEach(t),qko=i(U),x1=n(U,"LI",{});var U$e=s(x1);hge=n(U$e,"STRONG",{});var Tut=s(hge);jko=r(Tut,"fnet"),Tut.forEach(t),Dko=r(U$e," \u2014 "),tO=n(U$e,"A",{href:!0});var Mut=s(tO);Gko=r(Mut,"FNetForMaskedLM"),Mut.forEach(t),Oko=r(U$e," (FNet model)"),U$e.forEach(t),Vko=i(U),$1=n(U,"LI",{});var J$e=s($1);pge=n(J$e,"STRONG",{});var Eut=s(pge);Xko=r(Eut,"funnel"),Eut.forEach(t),zko=r(J$e," \u2014 "),aO=n(J$e,"A",{href:!0});var Cut=s(aO);Qko=r(Cut,"FunnelForMaskedLM"),Cut.forEach(t),Wko=r(J$e," (Funnel Transformer model)"),J$e.forEach(t),Hko=i(U),k1=n(U,"LI",{});var Y$e=s(k1);_ge=n(Y$e,"STRONG",{});var wut=s(_ge);Uko=r(wut,"ibert"),wut.forEach(t),Jko=r(Y$e," \u2014 "),nO=n(Y$e,"A",{href:!0});var Aut=s(nO);Yko=r(Aut,"IBertForMaskedLM"),Aut.forEach(t),Kko=r(Y$e," (I-BERT model)"),Y$e.forEach(t),Zko=i(U),S1=n(U,"LI",{});var K$e=s(S1);uge=n(K$e,"STRONG",{});var Lut=s(uge);eSo=r(Lut,"layoutlm"),Lut.forEach(t),oSo=r(K$e," \u2014 "),sO=n(K$e,"A",{href:!0});var yut=s(sO);rSo=r(yut,"LayoutLMForMaskedLM"),yut.forEach(t),tSo=r(K$e," (LayoutLM model)"),K$e.forEach(t),aSo=i(U),R1=n(U,"LI",{});var Z$e=s(R1);bge=n(Z$e,"STRONG",{});var xut=s(bge);nSo=r(xut,"longformer"),xut.forEach(t),sSo=r(Z$e," \u2014 "),lO=n(Z$e,"A",{href:!0});var $ut=s(lO);lSo=r($ut,"LongformerForMaskedLM"),$ut.forEach(t),iSo=r(Z$e," (Longformer model)"),Z$e.forEach(t),dSo=i(U),P1=n(U,"LI",{});var eke=s(P1);vge=n(eke,"STRONG",{});var kut=s(vge);cSo=r(kut,"luke"),kut.forEach(t),fSo=r(eke," \u2014 "),iO=n(eke,"A",{href:!0});var Sut=s(iO);mSo=r(Sut,"LukeForMaskedLM"),Sut.forEach(t),gSo=r(eke," (LUKE model)"),eke.forEach(t),hSo=i(U),B1=n(U,"LI",{});var oke=s(B1);Fge=n(oke,"STRONG",{});var Rut=s(Fge);pSo=r(Rut,"mbart"),Rut.forEach(t),_So=r(oke," \u2014 "),dO=n(oke,"A",{href:!0});var Put=s(dO);uSo=r(Put,"MBartForConditionalGeneration"),Put.forEach(t),bSo=r(oke," (mBART model)"),oke.forEach(t),vSo=i(U),I1=n(U,"LI",{});var rke=s(I1);Tge=n(rke,"STRONG",{});var But=s(Tge);FSo=r(But,"megatron-bert"),But.forEach(t),TSo=r(rke," \u2014 "),cO=n(rke,"A",{href:!0});var Iut=s(cO);MSo=r(Iut,"MegatronBertForMaskedLM"),Iut.forEach(t),ESo=r(rke," (Megatron-BERT model)"),rke.forEach(t),CSo=i(U),N1=n(U,"LI",{});var tke=s(N1);Mge=n(tke,"STRONG",{});var Nut=s(Mge);wSo=r(Nut,"mobilebert"),Nut.forEach(t),ASo=r(tke," \u2014 "),fO=n(tke,"A",{href:!0});var qut=s(fO);LSo=r(qut,"MobileBertForMaskedLM"),qut.forEach(t),ySo=r(tke," (MobileBERT model)"),tke.forEach(t),xSo=i(U),q1=n(U,"LI",{});var ake=s(q1);Ege=n(ake,"STRONG",{});var jut=s(Ege);$So=r(jut,"mpnet"),jut.forEach(t),kSo=r(ake," \u2014 "),mO=n(ake,"A",{href:!0});var Dut=s(mO);SSo=r(Dut,"MPNetForMaskedLM"),Dut.forEach(t),RSo=r(ake," (MPNet model)"),ake.forEach(t),PSo=i(U),j1=n(U,"LI",{});var nke=s(j1);Cge=n(nke,"STRONG",{});var Gut=s(Cge);BSo=r(Gut,"nezha"),Gut.forEach(t),ISo=r(nke," \u2014 "),gO=n(nke,"A",{href:!0});var Out=s(gO);NSo=r(Out,"NezhaForMaskedLM"),Out.forEach(t),qSo=r(nke," (Nezha model)"),nke.forEach(t),jSo=i(U),D1=n(U,"LI",{});var ske=s(D1);wge=n(ske,"STRONG",{});var Vut=s(wge);DSo=r(Vut,"nystromformer"),Vut.forEach(t),GSo=r(ske," \u2014 "),hO=n(ske,"A",{href:!0});var Xut=s(hO);OSo=r(Xut,"NystromformerForMaskedLM"),Xut.forEach(t),VSo=r(ske," (Nystr\xF6mformer model)"),ske.forEach(t),XSo=i(U),G1=n(U,"LI",{});var lke=s(G1);Age=n(lke,"STRONG",{});var zut=s(Age);zSo=r(zut,"perceiver"),zut.forEach(t),QSo=r(lke," \u2014 "),pO=n(lke,"A",{href:!0});var Qut=s(pO);WSo=r(Qut,"PerceiverForMaskedLM"),Qut.forEach(t),HSo=r(lke," (Perceiver model)"),lke.forEach(t),USo=i(U),O1=n(U,"LI",{});var ike=s(O1);Lge=n(ike,"STRONG",{});var Wut=s(Lge);JSo=r(Wut,"qdqbert"),Wut.forEach(t),YSo=r(ike," \u2014 "),_O=n(ike,"A",{href:!0});var Hut=s(_O);KSo=r(Hut,"QDQBertForMaskedLM"),Hut.forEach(t),ZSo=r(ike," (QDQBert model)"),ike.forEach(t),eRo=i(U),V1=n(U,"LI",{});var dke=s(V1);yge=n(dke,"STRONG",{});var Uut=s(yge);oRo=r(Uut,"reformer"),Uut.forEach(t),rRo=r(dke," \u2014 "),uO=n(dke,"A",{href:!0});var Jut=s(uO);tRo=r(Jut,"ReformerForMaskedLM"),Jut.forEach(t),aRo=r(dke," (Reformer model)"),dke.forEach(t),nRo=i(U),X1=n(U,"LI",{});var cke=s(X1);xge=n(cke,"STRONG",{});var Yut=s(xge);sRo=r(Yut,"rembert"),Yut.forEach(t),lRo=r(cke," \u2014 "),bO=n(cke,"A",{href:!0});var Kut=s(bO);iRo=r(Kut,"RemBertForMaskedLM"),Kut.forEach(t),dRo=r(cke," (RemBERT model)"),cke.forEach(t),cRo=i(U),z1=n(U,"LI",{});var fke=s(z1);$ge=n(fke,"STRONG",{});var Zut=s($ge);fRo=r(Zut,"roberta"),Zut.forEach(t),mRo=r(fke," \u2014 "),vO=n(fke,"A",{href:!0});var e2t=s(vO);gRo=r(e2t,"RobertaForMaskedLM"),e2t.forEach(t),hRo=r(fke," (RoBERTa model)"),fke.forEach(t),pRo=i(U),Q1=n(U,"LI",{});var mke=s(Q1);kge=n(mke,"STRONG",{});var o2t=s(kge);_Ro=r(o2t,"roformer"),o2t.forEach(t),uRo=r(mke," \u2014 "),FO=n(mke,"A",{href:!0});var r2t=s(FO);bRo=r(r2t,"RoFormerForMaskedLM"),r2t.forEach(t),vRo=r(mke," (RoFormer model)"),mke.forEach(t),FRo=i(U),W1=n(U,"LI",{});var gke=s(W1);Sge=n(gke,"STRONG",{});var t2t=s(Sge);TRo=r(t2t,"squeezebert"),t2t.forEach(t),MRo=r(gke," \u2014 "),TO=n(gke,"A",{href:!0});var a2t=s(TO);ERo=r(a2t,"SqueezeBertForMaskedLM"),a2t.forEach(t),CRo=r(gke," (SqueezeBERT model)"),gke.forEach(t),wRo=i(U),H1=n(U,"LI",{});var hke=s(H1);Rge=n(hke,"STRONG",{});var n2t=s(Rge);ARo=r(n2t,"tapas"),n2t.forEach(t),LRo=r(hke," \u2014 "),MO=n(hke,"A",{href:!0});var s2t=s(MO);yRo=r(s2t,"TapasForMaskedLM"),s2t.forEach(t),xRo=r(hke," (TAPAS model)"),hke.forEach(t),$Ro=i(U),U1=n(U,"LI",{});var pke=s(U1);Pge=n(pke,"STRONG",{});var l2t=s(Pge);kRo=r(l2t,"wav2vec2"),l2t.forEach(t),SRo=r(pke," \u2014 "),Bge=n(pke,"CODE",{});var i2t=s(Bge);RRo=r(i2t,"Wav2Vec2ForMaskedLM"),i2t.forEach(t),PRo=r(pke," (Wav2Vec2 model)"),pke.forEach(t),BRo=i(U),J1=n(U,"LI",{});var _ke=s(J1);Ige=n(_ke,"STRONG",{});var d2t=s(Ige);IRo=r(d2t,"xlm"),d2t.forEach(t),NRo=r(_ke," \u2014 "),EO=n(_ke,"A",{href:!0});var c2t=s(EO);qRo=r(c2t,"XLMWithLMHeadModel"),c2t.forEach(t),jRo=r(_ke," (XLM model)"),_ke.forEach(t),DRo=i(U),Y1=n(U,"LI",{});var uke=s(Y1);Nge=n(uke,"STRONG",{});var f2t=s(Nge);GRo=r(f2t,"xlm-roberta"),f2t.forEach(t),ORo=r(uke," \u2014 "),CO=n(uke,"A",{href:!0});var m2t=s(CO);VRo=r(m2t,"XLMRobertaForMaskedLM"),m2t.forEach(t),XRo=r(uke," (XLM-RoBERTa model)"),uke.forEach(t),zRo=i(U),K1=n(U,"LI",{});var bke=s(K1);qge=n(bke,"STRONG",{});var g2t=s(qge);QRo=r(g2t,"xlm-roberta-xl"),g2t.forEach(t),WRo=r(bke," \u2014 "),wO=n(bke,"A",{href:!0});var h2t=s(wO);HRo=r(h2t,"XLMRobertaXLForMaskedLM"),h2t.forEach(t),URo=r(bke," (XLM-RoBERTa-XL model)"),bke.forEach(t),JRo=i(U),Z1=n(U,"LI",{});var vke=s(Z1);jge=n(vke,"STRONG",{});var p2t=s(jge);YRo=r(p2t,"yoso"),p2t.forEach(t),KRo=r(vke," \u2014 "),AO=n(vke,"A",{href:!0});var _2t=s(AO);ZRo=r(_2t,"YosoForMaskedLM"),_2t.forEach(t),ePo=r(vke," (YOSO model)"),vke.forEach(t),U.forEach(t),oPo=i(la),eb=n(la,"P",{});var Fke=s(eb);rPo=r(Fke,"The model is set in evaluation mode by default using "),Dge=n(Fke,"CODE",{});var u2t=s(Dge);tPo=r(u2t,"model.eval()"),u2t.forEach(t),aPo=r(Fke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gge=n(Fke,"CODE",{});var b2t=s(Gge);nPo=r(b2t,"model.train()"),b2t.forEach(t),Fke.forEach(t),sPo=i(la),T(ob.$$.fragment,la),la.forEach(t),el.forEach(t),bOe=i(f),Wi=n(f,"H2",{class:!0});var CXe=s(Wi);rb=n(CXe,"A",{id:!0,class:!0,href:!0});var v2t=s(rb);Oge=n(v2t,"SPAN",{});var F2t=s(Oge);T(CL.$$.fragment,F2t),F2t.forEach(t),v2t.forEach(t),lPo=i(CXe),Vge=n(CXe,"SPAN",{});var T2t=s(Vge);iPo=r(T2t,"AutoModelForSeq2SeqLM"),T2t.forEach(t),CXe.forEach(t),vOe=i(f),Ro=n(f,"DIV",{class:!0});var ol=s(Ro);T(wL.$$.fragment,ol),dPo=i(ol),Hi=n(ol,"P",{});var koe=s(Hi);cPo=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),LO=n(koe,"A",{href:!0});var M2t=s(LO);fPo=r(M2t,"from_pretrained()"),M2t.forEach(t),mPo=r(koe," class method or the "),yO=n(koe,"A",{href:!0});var E2t=s(yO);gPo=r(E2t,"from_config()"),E2t.forEach(t),hPo=r(koe,` class
method.`),koe.forEach(t),pPo=i(ol),AL=n(ol,"P",{});var wXe=s(AL);_Po=r(wXe,"This class cannot be instantiated directly using "),Xge=n(wXe,"CODE",{});var C2t=s(Xge);uPo=r(C2t,"__init__()"),C2t.forEach(t),bPo=r(wXe," (throws an error)."),wXe.forEach(t),vPo=i(ol),dt=n(ol,"DIV",{class:!0});var O0=s(dt);T(LL.$$.fragment,O0),FPo=i(O0),zge=n(O0,"P",{});var w2t=s(zge);TPo=r(w2t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),w2t.forEach(t),MPo=i(O0),Ui=n(O0,"P",{});var Soe=s(Ui);EPo=r(Soe,`Note:
Loading a model from its configuration file does `),Qge=n(Soe,"STRONG",{});var A2t=s(Qge);CPo=r(A2t,"not"),A2t.forEach(t),wPo=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),xO=n(Soe,"A",{href:!0});var L2t=s(xO);APo=r(L2t,"from_pretrained()"),L2t.forEach(t),LPo=r(Soe," to load the model weights."),Soe.forEach(t),yPo=i(O0),T(tb.$$.fragment,O0),O0.forEach(t),xPo=i(ol),eo=n(ol,"DIV",{class:!0});var ia=s(eo);T(yL.$$.fragment,ia),$Po=i(ia),Wge=n(ia,"P",{});var y2t=s(Wge);kPo=r(y2t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),y2t.forEach(t),SPo=i(ia),Na=n(ia,"P",{});var V0=s(Na);RPo=r(V0,"The model class to instantiate is selected based on the "),Hge=n(V0,"CODE",{});var x2t=s(Hge);PPo=r(x2t,"model_type"),x2t.forEach(t),BPo=r(V0,` property of the config object (either
passed as an argument or loaded from `),Uge=n(V0,"CODE",{});var $2t=s(Uge);IPo=r($2t,"pretrained_model_name_or_path"),$2t.forEach(t),NPo=r(V0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jge=n(V0,"CODE",{});var k2t=s(Jge);qPo=r(k2t,"pretrained_model_name_or_path"),k2t.forEach(t),jPo=r(V0,":"),V0.forEach(t),DPo=i(ia),pe=n(ia,"UL",{});var be=s(pe);ab=n(be,"LI",{});var Tke=s(ab);Yge=n(Tke,"STRONG",{});var S2t=s(Yge);GPo=r(S2t,"bart"),S2t.forEach(t),OPo=r(Tke," \u2014 "),$O=n(Tke,"A",{href:!0});var R2t=s($O);VPo=r(R2t,"BartForConditionalGeneration"),R2t.forEach(t),XPo=r(Tke," (BART model)"),Tke.forEach(t),zPo=i(be),nb=n(be,"LI",{});var Mke=s(nb);Kge=n(Mke,"STRONG",{});var P2t=s(Kge);QPo=r(P2t,"bigbird_pegasus"),P2t.forEach(t),WPo=r(Mke," \u2014 "),kO=n(Mke,"A",{href:!0});var B2t=s(kO);HPo=r(B2t,"BigBirdPegasusForConditionalGeneration"),B2t.forEach(t),UPo=r(Mke," (BigBird-Pegasus model)"),Mke.forEach(t),JPo=i(be),sb=n(be,"LI",{});var Eke=s(sb);Zge=n(Eke,"STRONG",{});var I2t=s(Zge);YPo=r(I2t,"blenderbot"),I2t.forEach(t),KPo=r(Eke," \u2014 "),SO=n(Eke,"A",{href:!0});var N2t=s(SO);ZPo=r(N2t,"BlenderbotForConditionalGeneration"),N2t.forEach(t),eBo=r(Eke," (Blenderbot model)"),Eke.forEach(t),oBo=i(be),lb=n(be,"LI",{});var Cke=s(lb);ehe=n(Cke,"STRONG",{});var q2t=s(ehe);rBo=r(q2t,"blenderbot-small"),q2t.forEach(t),tBo=r(Cke," \u2014 "),RO=n(Cke,"A",{href:!0});var j2t=s(RO);aBo=r(j2t,"BlenderbotSmallForConditionalGeneration"),j2t.forEach(t),nBo=r(Cke," (BlenderbotSmall model)"),Cke.forEach(t),sBo=i(be),ib=n(be,"LI",{});var wke=s(ib);ohe=n(wke,"STRONG",{});var D2t=s(ohe);lBo=r(D2t,"encoder-decoder"),D2t.forEach(t),iBo=r(wke," \u2014 "),PO=n(wke,"A",{href:!0});var G2t=s(PO);dBo=r(G2t,"EncoderDecoderModel"),G2t.forEach(t),cBo=r(wke," (Encoder decoder model)"),wke.forEach(t),fBo=i(be),db=n(be,"LI",{});var Ake=s(db);rhe=n(Ake,"STRONG",{});var O2t=s(rhe);mBo=r(O2t,"fsmt"),O2t.forEach(t),gBo=r(Ake," \u2014 "),BO=n(Ake,"A",{href:!0});var V2t=s(BO);hBo=r(V2t,"FSMTForConditionalGeneration"),V2t.forEach(t),pBo=r(Ake," (FairSeq Machine-Translation model)"),Ake.forEach(t),_Bo=i(be),cb=n(be,"LI",{});var Lke=s(cb);the=n(Lke,"STRONG",{});var X2t=s(the);uBo=r(X2t,"led"),X2t.forEach(t),bBo=r(Lke," \u2014 "),IO=n(Lke,"A",{href:!0});var z2t=s(IO);vBo=r(z2t,"LEDForConditionalGeneration"),z2t.forEach(t),FBo=r(Lke," (LED model)"),Lke.forEach(t),TBo=i(be),fb=n(be,"LI",{});var yke=s(fb);ahe=n(yke,"STRONG",{});var Q2t=s(ahe);MBo=r(Q2t,"longt5"),Q2t.forEach(t),EBo=r(yke," \u2014 "),NO=n(yke,"A",{href:!0});var W2t=s(NO);CBo=r(W2t,"LongT5ForConditionalGeneration"),W2t.forEach(t),wBo=r(yke," (LongT5 model)"),yke.forEach(t),ABo=i(be),mb=n(be,"LI",{});var xke=s(mb);nhe=n(xke,"STRONG",{});var H2t=s(nhe);LBo=r(H2t,"m2m_100"),H2t.forEach(t),yBo=r(xke," \u2014 "),qO=n(xke,"A",{href:!0});var U2t=s(qO);xBo=r(U2t,"M2M100ForConditionalGeneration"),U2t.forEach(t),$Bo=r(xke," (M2M100 model)"),xke.forEach(t),kBo=i(be),gb=n(be,"LI",{});var $ke=s(gb);she=n($ke,"STRONG",{});var J2t=s(she);SBo=r(J2t,"marian"),J2t.forEach(t),RBo=r($ke," \u2014 "),jO=n($ke,"A",{href:!0});var Y2t=s(jO);PBo=r(Y2t,"MarianMTModel"),Y2t.forEach(t),BBo=r($ke," (Marian model)"),$ke.forEach(t),IBo=i(be),hb=n(be,"LI",{});var kke=s(hb);lhe=n(kke,"STRONG",{});var K2t=s(lhe);NBo=r(K2t,"mbart"),K2t.forEach(t),qBo=r(kke," \u2014 "),DO=n(kke,"A",{href:!0});var Z2t=s(DO);jBo=r(Z2t,"MBartForConditionalGeneration"),Z2t.forEach(t),DBo=r(kke," (mBART model)"),kke.forEach(t),GBo=i(be),pb=n(be,"LI",{});var Ske=s(pb);ihe=n(Ske,"STRONG",{});var e1t=s(ihe);OBo=r(e1t,"mt5"),e1t.forEach(t),VBo=r(Ske," \u2014 "),GO=n(Ske,"A",{href:!0});var o1t=s(GO);XBo=r(o1t,"MT5ForConditionalGeneration"),o1t.forEach(t),zBo=r(Ske," (MT5 model)"),Ske.forEach(t),QBo=i(be),_b=n(be,"LI",{});var Rke=s(_b);dhe=n(Rke,"STRONG",{});var r1t=s(dhe);WBo=r(r1t,"pegasus"),r1t.forEach(t),HBo=r(Rke," \u2014 "),OO=n(Rke,"A",{href:!0});var t1t=s(OO);UBo=r(t1t,"PegasusForConditionalGeneration"),t1t.forEach(t),JBo=r(Rke," (Pegasus model)"),Rke.forEach(t),YBo=i(be),ub=n(be,"LI",{});var Pke=s(ub);che=n(Pke,"STRONG",{});var a1t=s(che);KBo=r(a1t,"plbart"),a1t.forEach(t),ZBo=r(Pke," \u2014 "),VO=n(Pke,"A",{href:!0});var n1t=s(VO);eIo=r(n1t,"PLBartForConditionalGeneration"),n1t.forEach(t),oIo=r(Pke," (PLBart model)"),Pke.forEach(t),rIo=i(be),bb=n(be,"LI",{});var Bke=s(bb);fhe=n(Bke,"STRONG",{});var s1t=s(fhe);tIo=r(s1t,"prophetnet"),s1t.forEach(t),aIo=r(Bke," \u2014 "),XO=n(Bke,"A",{href:!0});var l1t=s(XO);nIo=r(l1t,"ProphetNetForConditionalGeneration"),l1t.forEach(t),sIo=r(Bke," (ProphetNet model)"),Bke.forEach(t),lIo=i(be),vb=n(be,"LI",{});var Ike=s(vb);mhe=n(Ike,"STRONG",{});var i1t=s(mhe);iIo=r(i1t,"t5"),i1t.forEach(t),dIo=r(Ike," \u2014 "),zO=n(Ike,"A",{href:!0});var d1t=s(zO);cIo=r(d1t,"T5ForConditionalGeneration"),d1t.forEach(t),fIo=r(Ike," (T5 model)"),Ike.forEach(t),mIo=i(be),Fb=n(be,"LI",{});var Nke=s(Fb);ghe=n(Nke,"STRONG",{});var c1t=s(ghe);gIo=r(c1t,"xlm-prophetnet"),c1t.forEach(t),hIo=r(Nke," \u2014 "),QO=n(Nke,"A",{href:!0});var f1t=s(QO);pIo=r(f1t,"XLMProphetNetForConditionalGeneration"),f1t.forEach(t),_Io=r(Nke," (XLM-ProphetNet model)"),Nke.forEach(t),be.forEach(t),uIo=i(ia),Tb=n(ia,"P",{});var qke=s(Tb);bIo=r(qke,"The model is set in evaluation mode by default using "),hhe=n(qke,"CODE",{});var m1t=s(hhe);vIo=r(m1t,"model.eval()"),m1t.forEach(t),FIo=r(qke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),phe=n(qke,"CODE",{});var g1t=s(phe);TIo=r(g1t,"model.train()"),g1t.forEach(t),qke.forEach(t),MIo=i(ia),T(Mb.$$.fragment,ia),ia.forEach(t),ol.forEach(t),FOe=i(f),Ji=n(f,"H2",{class:!0});var AXe=s(Ji);Eb=n(AXe,"A",{id:!0,class:!0,href:!0});var h1t=s(Eb);_he=n(h1t,"SPAN",{});var p1t=s(_he);T(xL.$$.fragment,p1t),p1t.forEach(t),h1t.forEach(t),EIo=i(AXe),uhe=n(AXe,"SPAN",{});var _1t=s(uhe);CIo=r(_1t,"AutoModelForSequenceClassification"),_1t.forEach(t),AXe.forEach(t),TOe=i(f),Po=n(f,"DIV",{class:!0});var rl=s(Po);T($L.$$.fragment,rl),wIo=i(rl),Yi=n(rl,"P",{});var Roe=s(Yi);AIo=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),WO=n(Roe,"A",{href:!0});var u1t=s(WO);LIo=r(u1t,"from_pretrained()"),u1t.forEach(t),yIo=r(Roe," class method or the "),HO=n(Roe,"A",{href:!0});var b1t=s(HO);xIo=r(b1t,"from_config()"),b1t.forEach(t),$Io=r(Roe,` class
method.`),Roe.forEach(t),kIo=i(rl),kL=n(rl,"P",{});var LXe=s(kL);SIo=r(LXe,"This class cannot be instantiated directly using "),bhe=n(LXe,"CODE",{});var v1t=s(bhe);RIo=r(v1t,"__init__()"),v1t.forEach(t),PIo=r(LXe," (throws an error)."),LXe.forEach(t),BIo=i(rl),ct=n(rl,"DIV",{class:!0});var X0=s(ct);T(SL.$$.fragment,X0),IIo=i(X0),vhe=n(X0,"P",{});var F1t=s(vhe);NIo=r(F1t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),F1t.forEach(t),qIo=i(X0),Ki=n(X0,"P",{});var Poe=s(Ki);jIo=r(Poe,`Note:
Loading a model from its configuration file does `),Fhe=n(Poe,"STRONG",{});var T1t=s(Fhe);DIo=r(T1t,"not"),T1t.forEach(t),GIo=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),UO=n(Poe,"A",{href:!0});var M1t=s(UO);OIo=r(M1t,"from_pretrained()"),M1t.forEach(t),VIo=r(Poe," to load the model weights."),Poe.forEach(t),XIo=i(X0),T(Cb.$$.fragment,X0),X0.forEach(t),zIo=i(rl),oo=n(rl,"DIV",{class:!0});var da=s(oo);T(RL.$$.fragment,da),QIo=i(da),The=n(da,"P",{});var E1t=s(The);WIo=r(E1t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),E1t.forEach(t),HIo=i(da),qa=n(da,"P",{});var z0=s(qa);UIo=r(z0,"The model class to instantiate is selected based on the "),Mhe=n(z0,"CODE",{});var C1t=s(Mhe);JIo=r(C1t,"model_type"),C1t.forEach(t),YIo=r(z0,` property of the config object (either
passed as an argument or loaded from `),Ehe=n(z0,"CODE",{});var w1t=s(Ehe);KIo=r(w1t,"pretrained_model_name_or_path"),w1t.forEach(t),ZIo=r(z0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Che=n(z0,"CODE",{});var A1t=s(Che);eNo=r(A1t,"pretrained_model_name_or_path"),A1t.forEach(t),oNo=r(z0,":"),z0.forEach(t),rNo=i(da),N=n(da,"UL",{});var q=s(N);wb=n(q,"LI",{});var jke=s(wb);whe=n(jke,"STRONG",{});var L1t=s(whe);tNo=r(L1t,"albert"),L1t.forEach(t),aNo=r(jke," \u2014 "),JO=n(jke,"A",{href:!0});var y1t=s(JO);nNo=r(y1t,"AlbertForSequenceClassification"),y1t.forEach(t),sNo=r(jke," (ALBERT model)"),jke.forEach(t),lNo=i(q),Ab=n(q,"LI",{});var Dke=s(Ab);Ahe=n(Dke,"STRONG",{});var x1t=s(Ahe);iNo=r(x1t,"bart"),x1t.forEach(t),dNo=r(Dke," \u2014 "),YO=n(Dke,"A",{href:!0});var $1t=s(YO);cNo=r($1t,"BartForSequenceClassification"),$1t.forEach(t),fNo=r(Dke," (BART model)"),Dke.forEach(t),mNo=i(q),Lb=n(q,"LI",{});var Gke=s(Lb);Lhe=n(Gke,"STRONG",{});var k1t=s(Lhe);gNo=r(k1t,"bert"),k1t.forEach(t),hNo=r(Gke," \u2014 "),KO=n(Gke,"A",{href:!0});var S1t=s(KO);pNo=r(S1t,"BertForSequenceClassification"),S1t.forEach(t),_No=r(Gke," (BERT model)"),Gke.forEach(t),uNo=i(q),yb=n(q,"LI",{});var Oke=s(yb);yhe=n(Oke,"STRONG",{});var R1t=s(yhe);bNo=r(R1t,"big_bird"),R1t.forEach(t),vNo=r(Oke," \u2014 "),ZO=n(Oke,"A",{href:!0});var P1t=s(ZO);FNo=r(P1t,"BigBirdForSequenceClassification"),P1t.forEach(t),TNo=r(Oke," (BigBird model)"),Oke.forEach(t),MNo=i(q),xb=n(q,"LI",{});var Vke=s(xb);xhe=n(Vke,"STRONG",{});var B1t=s(xhe);ENo=r(B1t,"bigbird_pegasus"),B1t.forEach(t),CNo=r(Vke," \u2014 "),eV=n(Vke,"A",{href:!0});var I1t=s(eV);wNo=r(I1t,"BigBirdPegasusForSequenceClassification"),I1t.forEach(t),ANo=r(Vke," (BigBird-Pegasus model)"),Vke.forEach(t),LNo=i(q),$b=n(q,"LI",{});var Xke=s($b);$he=n(Xke,"STRONG",{});var N1t=s($he);yNo=r(N1t,"bloom"),N1t.forEach(t),xNo=r(Xke," \u2014 "),oV=n(Xke,"A",{href:!0});var q1t=s(oV);$No=r(q1t,"BloomForSequenceClassification"),q1t.forEach(t),kNo=r(Xke," (BLOOM model)"),Xke.forEach(t),SNo=i(q),kb=n(q,"LI",{});var zke=s(kb);khe=n(zke,"STRONG",{});var j1t=s(khe);RNo=r(j1t,"camembert"),j1t.forEach(t),PNo=r(zke," \u2014 "),rV=n(zke,"A",{href:!0});var D1t=s(rV);BNo=r(D1t,"CamembertForSequenceClassification"),D1t.forEach(t),INo=r(zke," (CamemBERT model)"),zke.forEach(t),NNo=i(q),Sb=n(q,"LI",{});var Qke=s(Sb);She=n(Qke,"STRONG",{});var G1t=s(She);qNo=r(G1t,"canine"),G1t.forEach(t),jNo=r(Qke," \u2014 "),tV=n(Qke,"A",{href:!0});var O1t=s(tV);DNo=r(O1t,"CanineForSequenceClassification"),O1t.forEach(t),GNo=r(Qke," (CANINE model)"),Qke.forEach(t),ONo=i(q),Rb=n(q,"LI",{});var Wke=s(Rb);Rhe=n(Wke,"STRONG",{});var V1t=s(Rhe);VNo=r(V1t,"convbert"),V1t.forEach(t),XNo=r(Wke," \u2014 "),aV=n(Wke,"A",{href:!0});var X1t=s(aV);zNo=r(X1t,"ConvBertForSequenceClassification"),X1t.forEach(t),QNo=r(Wke," (ConvBERT model)"),Wke.forEach(t),WNo=i(q),Pb=n(q,"LI",{});var Hke=s(Pb);Phe=n(Hke,"STRONG",{});var z1t=s(Phe);HNo=r(z1t,"ctrl"),z1t.forEach(t),UNo=r(Hke," \u2014 "),nV=n(Hke,"A",{href:!0});var Q1t=s(nV);JNo=r(Q1t,"CTRLForSequenceClassification"),Q1t.forEach(t),YNo=r(Hke," (CTRL model)"),Hke.forEach(t),KNo=i(q),Bb=n(q,"LI",{});var Uke=s(Bb);Bhe=n(Uke,"STRONG",{});var W1t=s(Bhe);ZNo=r(W1t,"data2vec-text"),W1t.forEach(t),eqo=r(Uke," \u2014 "),sV=n(Uke,"A",{href:!0});var H1t=s(sV);oqo=r(H1t,"Data2VecTextForSequenceClassification"),H1t.forEach(t),rqo=r(Uke," (Data2VecText model)"),Uke.forEach(t),tqo=i(q),Ib=n(q,"LI",{});var Jke=s(Ib);Ihe=n(Jke,"STRONG",{});var U1t=s(Ihe);aqo=r(U1t,"deberta"),U1t.forEach(t),nqo=r(Jke," \u2014 "),lV=n(Jke,"A",{href:!0});var J1t=s(lV);sqo=r(J1t,"DebertaForSequenceClassification"),J1t.forEach(t),lqo=r(Jke," (DeBERTa model)"),Jke.forEach(t),iqo=i(q),Nb=n(q,"LI",{});var Yke=s(Nb);Nhe=n(Yke,"STRONG",{});var Y1t=s(Nhe);dqo=r(Y1t,"deberta-v2"),Y1t.forEach(t),cqo=r(Yke," \u2014 "),iV=n(Yke,"A",{href:!0});var K1t=s(iV);fqo=r(K1t,"DebertaV2ForSequenceClassification"),K1t.forEach(t),mqo=r(Yke," (DeBERTa-v2 model)"),Yke.forEach(t),gqo=i(q),qb=n(q,"LI",{});var Kke=s(qb);qhe=n(Kke,"STRONG",{});var Z1t=s(qhe);hqo=r(Z1t,"distilbert"),Z1t.forEach(t),pqo=r(Kke," \u2014 "),dV=n(Kke,"A",{href:!0});var ebt=s(dV);_qo=r(ebt,"DistilBertForSequenceClassification"),ebt.forEach(t),uqo=r(Kke," (DistilBERT model)"),Kke.forEach(t),bqo=i(q),jb=n(q,"LI",{});var Zke=s(jb);jhe=n(Zke,"STRONG",{});var obt=s(jhe);vqo=r(obt,"electra"),obt.forEach(t),Fqo=r(Zke," \u2014 "),cV=n(Zke,"A",{href:!0});var rbt=s(cV);Tqo=r(rbt,"ElectraForSequenceClassification"),rbt.forEach(t),Mqo=r(Zke," (ELECTRA model)"),Zke.forEach(t),Eqo=i(q),Db=n(q,"LI",{});var eSe=s(Db);Dhe=n(eSe,"STRONG",{});var tbt=s(Dhe);Cqo=r(tbt,"flaubert"),tbt.forEach(t),wqo=r(eSe," \u2014 "),fV=n(eSe,"A",{href:!0});var abt=s(fV);Aqo=r(abt,"FlaubertForSequenceClassification"),abt.forEach(t),Lqo=r(eSe," (FlauBERT model)"),eSe.forEach(t),yqo=i(q),Gb=n(q,"LI",{});var oSe=s(Gb);Ghe=n(oSe,"STRONG",{});var nbt=s(Ghe);xqo=r(nbt,"fnet"),nbt.forEach(t),$qo=r(oSe," \u2014 "),mV=n(oSe,"A",{href:!0});var sbt=s(mV);kqo=r(sbt,"FNetForSequenceClassification"),sbt.forEach(t),Sqo=r(oSe," (FNet model)"),oSe.forEach(t),Rqo=i(q),Ob=n(q,"LI",{});var rSe=s(Ob);Ohe=n(rSe,"STRONG",{});var lbt=s(Ohe);Pqo=r(lbt,"funnel"),lbt.forEach(t),Bqo=r(rSe," \u2014 "),gV=n(rSe,"A",{href:!0});var ibt=s(gV);Iqo=r(ibt,"FunnelForSequenceClassification"),ibt.forEach(t),Nqo=r(rSe," (Funnel Transformer model)"),rSe.forEach(t),qqo=i(q),Vb=n(q,"LI",{});var tSe=s(Vb);Vhe=n(tSe,"STRONG",{});var dbt=s(Vhe);jqo=r(dbt,"gpt2"),dbt.forEach(t),Dqo=r(tSe," \u2014 "),hV=n(tSe,"A",{href:!0});var cbt=s(hV);Gqo=r(cbt,"GPT2ForSequenceClassification"),cbt.forEach(t),Oqo=r(tSe," (OpenAI GPT-2 model)"),tSe.forEach(t),Vqo=i(q),Xb=n(q,"LI",{});var aSe=s(Xb);Xhe=n(aSe,"STRONG",{});var fbt=s(Xhe);Xqo=r(fbt,"gpt_neo"),fbt.forEach(t),zqo=r(aSe," \u2014 "),pV=n(aSe,"A",{href:!0});var mbt=s(pV);Qqo=r(mbt,"GPTNeoForSequenceClassification"),mbt.forEach(t),Wqo=r(aSe," (GPT Neo model)"),aSe.forEach(t),Hqo=i(q),zb=n(q,"LI",{});var nSe=s(zb);zhe=n(nSe,"STRONG",{});var gbt=s(zhe);Uqo=r(gbt,"gptj"),gbt.forEach(t),Jqo=r(nSe," \u2014 "),_V=n(nSe,"A",{href:!0});var hbt=s(_V);Yqo=r(hbt,"GPTJForSequenceClassification"),hbt.forEach(t),Kqo=r(nSe," (GPT-J model)"),nSe.forEach(t),Zqo=i(q),Qb=n(q,"LI",{});var sSe=s(Qb);Qhe=n(sSe,"STRONG",{});var pbt=s(Qhe);ejo=r(pbt,"ibert"),pbt.forEach(t),ojo=r(sSe," \u2014 "),uV=n(sSe,"A",{href:!0});var _bt=s(uV);rjo=r(_bt,"IBertForSequenceClassification"),_bt.forEach(t),tjo=r(sSe," (I-BERT model)"),sSe.forEach(t),ajo=i(q),Wb=n(q,"LI",{});var lSe=s(Wb);Whe=n(lSe,"STRONG",{});var ubt=s(Whe);njo=r(ubt,"layoutlm"),ubt.forEach(t),sjo=r(lSe," \u2014 "),bV=n(lSe,"A",{href:!0});var bbt=s(bV);ljo=r(bbt,"LayoutLMForSequenceClassification"),bbt.forEach(t),ijo=r(lSe," (LayoutLM model)"),lSe.forEach(t),djo=i(q),Hb=n(q,"LI",{});var iSe=s(Hb);Hhe=n(iSe,"STRONG",{});var vbt=s(Hhe);cjo=r(vbt,"layoutlmv2"),vbt.forEach(t),fjo=r(iSe," \u2014 "),vV=n(iSe,"A",{href:!0});var Fbt=s(vV);mjo=r(Fbt,"LayoutLMv2ForSequenceClassification"),Fbt.forEach(t),gjo=r(iSe," (LayoutLMv2 model)"),iSe.forEach(t),hjo=i(q),Ub=n(q,"LI",{});var dSe=s(Ub);Uhe=n(dSe,"STRONG",{});var Tbt=s(Uhe);pjo=r(Tbt,"layoutlmv3"),Tbt.forEach(t),_jo=r(dSe," \u2014 "),FV=n(dSe,"A",{href:!0});var Mbt=s(FV);ujo=r(Mbt,"LayoutLMv3ForSequenceClassification"),Mbt.forEach(t),bjo=r(dSe," (LayoutLMv3 model)"),dSe.forEach(t),vjo=i(q),Jb=n(q,"LI",{});var cSe=s(Jb);Jhe=n(cSe,"STRONG",{});var Ebt=s(Jhe);Fjo=r(Ebt,"led"),Ebt.forEach(t),Tjo=r(cSe," \u2014 "),TV=n(cSe,"A",{href:!0});var Cbt=s(TV);Mjo=r(Cbt,"LEDForSequenceClassification"),Cbt.forEach(t),Ejo=r(cSe," (LED model)"),cSe.forEach(t),Cjo=i(q),Yb=n(q,"LI",{});var fSe=s(Yb);Yhe=n(fSe,"STRONG",{});var wbt=s(Yhe);wjo=r(wbt,"longformer"),wbt.forEach(t),Ajo=r(fSe," \u2014 "),MV=n(fSe,"A",{href:!0});var Abt=s(MV);Ljo=r(Abt,"LongformerForSequenceClassification"),Abt.forEach(t),yjo=r(fSe," (Longformer model)"),fSe.forEach(t),xjo=i(q),Kb=n(q,"LI",{});var mSe=s(Kb);Khe=n(mSe,"STRONG",{});var Lbt=s(Khe);$jo=r(Lbt,"mbart"),Lbt.forEach(t),kjo=r(mSe," \u2014 "),EV=n(mSe,"A",{href:!0});var ybt=s(EV);Sjo=r(ybt,"MBartForSequenceClassification"),ybt.forEach(t),Rjo=r(mSe," (mBART model)"),mSe.forEach(t),Pjo=i(q),Zb=n(q,"LI",{});var gSe=s(Zb);Zhe=n(gSe,"STRONG",{});var xbt=s(Zhe);Bjo=r(xbt,"megatron-bert"),xbt.forEach(t),Ijo=r(gSe," \u2014 "),CV=n(gSe,"A",{href:!0});var $bt=s(CV);Njo=r($bt,"MegatronBertForSequenceClassification"),$bt.forEach(t),qjo=r(gSe," (Megatron-BERT model)"),gSe.forEach(t),jjo=i(q),ev=n(q,"LI",{});var hSe=s(ev);epe=n(hSe,"STRONG",{});var kbt=s(epe);Djo=r(kbt,"mobilebert"),kbt.forEach(t),Gjo=r(hSe," \u2014 "),wV=n(hSe,"A",{href:!0});var Sbt=s(wV);Ojo=r(Sbt,"MobileBertForSequenceClassification"),Sbt.forEach(t),Vjo=r(hSe," (MobileBERT model)"),hSe.forEach(t),Xjo=i(q),ov=n(q,"LI",{});var pSe=s(ov);ope=n(pSe,"STRONG",{});var Rbt=s(ope);zjo=r(Rbt,"mpnet"),Rbt.forEach(t),Qjo=r(pSe," \u2014 "),AV=n(pSe,"A",{href:!0});var Pbt=s(AV);Wjo=r(Pbt,"MPNetForSequenceClassification"),Pbt.forEach(t),Hjo=r(pSe," (MPNet model)"),pSe.forEach(t),Ujo=i(q),rv=n(q,"LI",{});var _Se=s(rv);rpe=n(_Se,"STRONG",{});var Bbt=s(rpe);Jjo=r(Bbt,"nezha"),Bbt.forEach(t),Yjo=r(_Se," \u2014 "),LV=n(_Se,"A",{href:!0});var Ibt=s(LV);Kjo=r(Ibt,"NezhaForSequenceClassification"),Ibt.forEach(t),Zjo=r(_Se," (Nezha model)"),_Se.forEach(t),eDo=i(q),tv=n(q,"LI",{});var uSe=s(tv);tpe=n(uSe,"STRONG",{});var Nbt=s(tpe);oDo=r(Nbt,"nystromformer"),Nbt.forEach(t),rDo=r(uSe," \u2014 "),yV=n(uSe,"A",{href:!0});var qbt=s(yV);tDo=r(qbt,"NystromformerForSequenceClassification"),qbt.forEach(t),aDo=r(uSe," (Nystr\xF6mformer model)"),uSe.forEach(t),nDo=i(q),av=n(q,"LI",{});var bSe=s(av);ape=n(bSe,"STRONG",{});var jbt=s(ape);sDo=r(jbt,"openai-gpt"),jbt.forEach(t),lDo=r(bSe," \u2014 "),xV=n(bSe,"A",{href:!0});var Dbt=s(xV);iDo=r(Dbt,"OpenAIGPTForSequenceClassification"),Dbt.forEach(t),dDo=r(bSe," (OpenAI GPT model)"),bSe.forEach(t),cDo=i(q),nv=n(q,"LI",{});var vSe=s(nv);npe=n(vSe,"STRONG",{});var Gbt=s(npe);fDo=r(Gbt,"perceiver"),Gbt.forEach(t),mDo=r(vSe," \u2014 "),$V=n(vSe,"A",{href:!0});var Obt=s($V);gDo=r(Obt,"PerceiverForSequenceClassification"),Obt.forEach(t),hDo=r(vSe," (Perceiver model)"),vSe.forEach(t),pDo=i(q),sv=n(q,"LI",{});var FSe=s(sv);spe=n(FSe,"STRONG",{});var Vbt=s(spe);_Do=r(Vbt,"plbart"),Vbt.forEach(t),uDo=r(FSe," \u2014 "),kV=n(FSe,"A",{href:!0});var Xbt=s(kV);bDo=r(Xbt,"PLBartForSequenceClassification"),Xbt.forEach(t),vDo=r(FSe," (PLBart model)"),FSe.forEach(t),FDo=i(q),lv=n(q,"LI",{});var TSe=s(lv);lpe=n(TSe,"STRONG",{});var zbt=s(lpe);TDo=r(zbt,"qdqbert"),zbt.forEach(t),MDo=r(TSe," \u2014 "),SV=n(TSe,"A",{href:!0});var Qbt=s(SV);EDo=r(Qbt,"QDQBertForSequenceClassification"),Qbt.forEach(t),CDo=r(TSe," (QDQBert model)"),TSe.forEach(t),wDo=i(q),iv=n(q,"LI",{});var MSe=s(iv);ipe=n(MSe,"STRONG",{});var Wbt=s(ipe);ADo=r(Wbt,"reformer"),Wbt.forEach(t),LDo=r(MSe," \u2014 "),RV=n(MSe,"A",{href:!0});var Hbt=s(RV);yDo=r(Hbt,"ReformerForSequenceClassification"),Hbt.forEach(t),xDo=r(MSe," (Reformer model)"),MSe.forEach(t),$Do=i(q),dv=n(q,"LI",{});var ESe=s(dv);dpe=n(ESe,"STRONG",{});var Ubt=s(dpe);kDo=r(Ubt,"rembert"),Ubt.forEach(t),SDo=r(ESe," \u2014 "),PV=n(ESe,"A",{href:!0});var Jbt=s(PV);RDo=r(Jbt,"RemBertForSequenceClassification"),Jbt.forEach(t),PDo=r(ESe," (RemBERT model)"),ESe.forEach(t),BDo=i(q),cv=n(q,"LI",{});var CSe=s(cv);cpe=n(CSe,"STRONG",{});var Ybt=s(cpe);IDo=r(Ybt,"roberta"),Ybt.forEach(t),NDo=r(CSe," \u2014 "),BV=n(CSe,"A",{href:!0});var Kbt=s(BV);qDo=r(Kbt,"RobertaForSequenceClassification"),Kbt.forEach(t),jDo=r(CSe," (RoBERTa model)"),CSe.forEach(t),DDo=i(q),fv=n(q,"LI",{});var wSe=s(fv);fpe=n(wSe,"STRONG",{});var Zbt=s(fpe);GDo=r(Zbt,"roformer"),Zbt.forEach(t),ODo=r(wSe," \u2014 "),IV=n(wSe,"A",{href:!0});var evt=s(IV);VDo=r(evt,"RoFormerForSequenceClassification"),evt.forEach(t),XDo=r(wSe," (RoFormer model)"),wSe.forEach(t),zDo=i(q),mv=n(q,"LI",{});var ASe=s(mv);mpe=n(ASe,"STRONG",{});var ovt=s(mpe);QDo=r(ovt,"squeezebert"),ovt.forEach(t),WDo=r(ASe," \u2014 "),NV=n(ASe,"A",{href:!0});var rvt=s(NV);HDo=r(rvt,"SqueezeBertForSequenceClassification"),rvt.forEach(t),UDo=r(ASe," (SqueezeBERT model)"),ASe.forEach(t),JDo=i(q),gv=n(q,"LI",{});var LSe=s(gv);gpe=n(LSe,"STRONG",{});var tvt=s(gpe);YDo=r(tvt,"tapas"),tvt.forEach(t),KDo=r(LSe," \u2014 "),qV=n(LSe,"A",{href:!0});var avt=s(qV);ZDo=r(avt,"TapasForSequenceClassification"),avt.forEach(t),eGo=r(LSe," (TAPAS model)"),LSe.forEach(t),oGo=i(q),hv=n(q,"LI",{});var ySe=s(hv);hpe=n(ySe,"STRONG",{});var nvt=s(hpe);rGo=r(nvt,"transfo-xl"),nvt.forEach(t),tGo=r(ySe," \u2014 "),jV=n(ySe,"A",{href:!0});var svt=s(jV);aGo=r(svt,"TransfoXLForSequenceClassification"),svt.forEach(t),nGo=r(ySe," (Transformer-XL model)"),ySe.forEach(t),sGo=i(q),pv=n(q,"LI",{});var xSe=s(pv);ppe=n(xSe,"STRONG",{});var lvt=s(ppe);lGo=r(lvt,"xlm"),lvt.forEach(t),iGo=r(xSe," \u2014 "),DV=n(xSe,"A",{href:!0});var ivt=s(DV);dGo=r(ivt,"XLMForSequenceClassification"),ivt.forEach(t),cGo=r(xSe," (XLM model)"),xSe.forEach(t),fGo=i(q),_v=n(q,"LI",{});var $Se=s(_v);_pe=n($Se,"STRONG",{});var dvt=s(_pe);mGo=r(dvt,"xlm-roberta"),dvt.forEach(t),gGo=r($Se," \u2014 "),GV=n($Se,"A",{href:!0});var cvt=s(GV);hGo=r(cvt,"XLMRobertaForSequenceClassification"),cvt.forEach(t),pGo=r($Se," (XLM-RoBERTa model)"),$Se.forEach(t),_Go=i(q),uv=n(q,"LI",{});var kSe=s(uv);upe=n(kSe,"STRONG",{});var fvt=s(upe);uGo=r(fvt,"xlm-roberta-xl"),fvt.forEach(t),bGo=r(kSe," \u2014 "),OV=n(kSe,"A",{href:!0});var mvt=s(OV);vGo=r(mvt,"XLMRobertaXLForSequenceClassification"),mvt.forEach(t),FGo=r(kSe," (XLM-RoBERTa-XL model)"),kSe.forEach(t),TGo=i(q),bv=n(q,"LI",{});var SSe=s(bv);bpe=n(SSe,"STRONG",{});var gvt=s(bpe);MGo=r(gvt,"xlnet"),gvt.forEach(t),EGo=r(SSe," \u2014 "),VV=n(SSe,"A",{href:!0});var hvt=s(VV);CGo=r(hvt,"XLNetForSequenceClassification"),hvt.forEach(t),wGo=r(SSe," (XLNet model)"),SSe.forEach(t),AGo=i(q),vv=n(q,"LI",{});var RSe=s(vv);vpe=n(RSe,"STRONG",{});var pvt=s(vpe);LGo=r(pvt,"yoso"),pvt.forEach(t),yGo=r(RSe," \u2014 "),XV=n(RSe,"A",{href:!0});var _vt=s(XV);xGo=r(_vt,"YosoForSequenceClassification"),_vt.forEach(t),$Go=r(RSe," (YOSO model)"),RSe.forEach(t),q.forEach(t),kGo=i(da),Fv=n(da,"P",{});var PSe=s(Fv);SGo=r(PSe,"The model is set in evaluation mode by default using "),Fpe=n(PSe,"CODE",{});var uvt=s(Fpe);RGo=r(uvt,"model.eval()"),uvt.forEach(t),PGo=r(PSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tpe=n(PSe,"CODE",{});var bvt=s(Tpe);BGo=r(bvt,"model.train()"),bvt.forEach(t),PSe.forEach(t),IGo=i(da),T(Tv.$$.fragment,da),da.forEach(t),rl.forEach(t),MOe=i(f),Zi=n(f,"H2",{class:!0});var yXe=s(Zi);Mv=n(yXe,"A",{id:!0,class:!0,href:!0});var vvt=s(Mv);Mpe=n(vvt,"SPAN",{});var Fvt=s(Mpe);T(PL.$$.fragment,Fvt),Fvt.forEach(t),vvt.forEach(t),NGo=i(yXe),Epe=n(yXe,"SPAN",{});var Tvt=s(Epe);qGo=r(Tvt,"AutoModelForMultipleChoice"),Tvt.forEach(t),yXe.forEach(t),EOe=i(f),Bo=n(f,"DIV",{class:!0});var tl=s(Bo);T(BL.$$.fragment,tl),jGo=i(tl),ed=n(tl,"P",{});var Boe=s(ed);DGo=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zV=n(Boe,"A",{href:!0});var Mvt=s(zV);GGo=r(Mvt,"from_pretrained()"),Mvt.forEach(t),OGo=r(Boe," class method or the "),QV=n(Boe,"A",{href:!0});var Evt=s(QV);VGo=r(Evt,"from_config()"),Evt.forEach(t),XGo=r(Boe,` class
method.`),Boe.forEach(t),zGo=i(tl),IL=n(tl,"P",{});var xXe=s(IL);QGo=r(xXe,"This class cannot be instantiated directly using "),Cpe=n(xXe,"CODE",{});var Cvt=s(Cpe);WGo=r(Cvt,"__init__()"),Cvt.forEach(t),HGo=r(xXe," (throws an error)."),xXe.forEach(t),UGo=i(tl),ft=n(tl,"DIV",{class:!0});var Q0=s(ft);T(NL.$$.fragment,Q0),JGo=i(Q0),wpe=n(Q0,"P",{});var wvt=s(wpe);YGo=r(wvt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wvt.forEach(t),KGo=i(Q0),od=n(Q0,"P",{});var Ioe=s(od);ZGo=r(Ioe,`Note:
Loading a model from its configuration file does `),Ape=n(Ioe,"STRONG",{});var Avt=s(Ape);eOo=r(Avt,"not"),Avt.forEach(t),oOo=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),WV=n(Ioe,"A",{href:!0});var Lvt=s(WV);rOo=r(Lvt,"from_pretrained()"),Lvt.forEach(t),tOo=r(Ioe," to load the model weights."),Ioe.forEach(t),aOo=i(Q0),T(Ev.$$.fragment,Q0),Q0.forEach(t),nOo=i(tl),ro=n(tl,"DIV",{class:!0});var ca=s(ro);T(qL.$$.fragment,ca),sOo=i(ca),Lpe=n(ca,"P",{});var yvt=s(Lpe);lOo=r(yvt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),yvt.forEach(t),iOo=i(ca),ja=n(ca,"P",{});var W0=s(ja);dOo=r(W0,"The model class to instantiate is selected based on the "),ype=n(W0,"CODE",{});var xvt=s(ype);cOo=r(xvt,"model_type"),xvt.forEach(t),fOo=r(W0,` property of the config object (either
passed as an argument or loaded from `),xpe=n(W0,"CODE",{});var $vt=s(xpe);mOo=r($vt,"pretrained_model_name_or_path"),$vt.forEach(t),gOo=r(W0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$pe=n(W0,"CODE",{});var kvt=s($pe);hOo=r(kvt,"pretrained_model_name_or_path"),kvt.forEach(t),pOo=r(W0,":"),W0.forEach(t),_Oo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);Cv=n(ee,"LI",{});var BSe=s(Cv);kpe=n(BSe,"STRONG",{});var Svt=s(kpe);uOo=r(Svt,"albert"),Svt.forEach(t),bOo=r(BSe," \u2014 "),HV=n(BSe,"A",{href:!0});var Rvt=s(HV);vOo=r(Rvt,"AlbertForMultipleChoice"),Rvt.forEach(t),FOo=r(BSe," (ALBERT model)"),BSe.forEach(t),TOo=i(ee),wv=n(ee,"LI",{});var ISe=s(wv);Spe=n(ISe,"STRONG",{});var Pvt=s(Spe);MOo=r(Pvt,"bert"),Pvt.forEach(t),EOo=r(ISe," \u2014 "),UV=n(ISe,"A",{href:!0});var Bvt=s(UV);COo=r(Bvt,"BertForMultipleChoice"),Bvt.forEach(t),wOo=r(ISe," (BERT model)"),ISe.forEach(t),AOo=i(ee),Av=n(ee,"LI",{});var NSe=s(Av);Rpe=n(NSe,"STRONG",{});var Ivt=s(Rpe);LOo=r(Ivt,"big_bird"),Ivt.forEach(t),yOo=r(NSe," \u2014 "),JV=n(NSe,"A",{href:!0});var Nvt=s(JV);xOo=r(Nvt,"BigBirdForMultipleChoice"),Nvt.forEach(t),$Oo=r(NSe," (BigBird model)"),NSe.forEach(t),kOo=i(ee),Lv=n(ee,"LI",{});var qSe=s(Lv);Ppe=n(qSe,"STRONG",{});var qvt=s(Ppe);SOo=r(qvt,"camembert"),qvt.forEach(t),ROo=r(qSe," \u2014 "),YV=n(qSe,"A",{href:!0});var jvt=s(YV);POo=r(jvt,"CamembertForMultipleChoice"),jvt.forEach(t),BOo=r(qSe," (CamemBERT model)"),qSe.forEach(t),IOo=i(ee),yv=n(ee,"LI",{});var jSe=s(yv);Bpe=n(jSe,"STRONG",{});var Dvt=s(Bpe);NOo=r(Dvt,"canine"),Dvt.forEach(t),qOo=r(jSe," \u2014 "),KV=n(jSe,"A",{href:!0});var Gvt=s(KV);jOo=r(Gvt,"CanineForMultipleChoice"),Gvt.forEach(t),DOo=r(jSe," (CANINE model)"),jSe.forEach(t),GOo=i(ee),xv=n(ee,"LI",{});var DSe=s(xv);Ipe=n(DSe,"STRONG",{});var Ovt=s(Ipe);OOo=r(Ovt,"convbert"),Ovt.forEach(t),VOo=r(DSe," \u2014 "),ZV=n(DSe,"A",{href:!0});var Vvt=s(ZV);XOo=r(Vvt,"ConvBertForMultipleChoice"),Vvt.forEach(t),zOo=r(DSe," (ConvBERT model)"),DSe.forEach(t),QOo=i(ee),$v=n(ee,"LI",{});var GSe=s($v);Npe=n(GSe,"STRONG",{});var Xvt=s(Npe);WOo=r(Xvt,"data2vec-text"),Xvt.forEach(t),HOo=r(GSe," \u2014 "),eX=n(GSe,"A",{href:!0});var zvt=s(eX);UOo=r(zvt,"Data2VecTextForMultipleChoice"),zvt.forEach(t),JOo=r(GSe," (Data2VecText model)"),GSe.forEach(t),YOo=i(ee),kv=n(ee,"LI",{});var OSe=s(kv);qpe=n(OSe,"STRONG",{});var Qvt=s(qpe);KOo=r(Qvt,"deberta-v2"),Qvt.forEach(t),ZOo=r(OSe," \u2014 "),oX=n(OSe,"A",{href:!0});var Wvt=s(oX);eVo=r(Wvt,"DebertaV2ForMultipleChoice"),Wvt.forEach(t),oVo=r(OSe," (DeBERTa-v2 model)"),OSe.forEach(t),rVo=i(ee),Sv=n(ee,"LI",{});var VSe=s(Sv);jpe=n(VSe,"STRONG",{});var Hvt=s(jpe);tVo=r(Hvt,"distilbert"),Hvt.forEach(t),aVo=r(VSe," \u2014 "),rX=n(VSe,"A",{href:!0});var Uvt=s(rX);nVo=r(Uvt,"DistilBertForMultipleChoice"),Uvt.forEach(t),sVo=r(VSe," (DistilBERT model)"),VSe.forEach(t),lVo=i(ee),Rv=n(ee,"LI",{});var XSe=s(Rv);Dpe=n(XSe,"STRONG",{});var Jvt=s(Dpe);iVo=r(Jvt,"electra"),Jvt.forEach(t),dVo=r(XSe," \u2014 "),tX=n(XSe,"A",{href:!0});var Yvt=s(tX);cVo=r(Yvt,"ElectraForMultipleChoice"),Yvt.forEach(t),fVo=r(XSe," (ELECTRA model)"),XSe.forEach(t),mVo=i(ee),Pv=n(ee,"LI",{});var zSe=s(Pv);Gpe=n(zSe,"STRONG",{});var Kvt=s(Gpe);gVo=r(Kvt,"flaubert"),Kvt.forEach(t),hVo=r(zSe," \u2014 "),aX=n(zSe,"A",{href:!0});var Zvt=s(aX);pVo=r(Zvt,"FlaubertForMultipleChoice"),Zvt.forEach(t),_Vo=r(zSe," (FlauBERT model)"),zSe.forEach(t),uVo=i(ee),Bv=n(ee,"LI",{});var QSe=s(Bv);Ope=n(QSe,"STRONG",{});var eFt=s(Ope);bVo=r(eFt,"fnet"),eFt.forEach(t),vVo=r(QSe," \u2014 "),nX=n(QSe,"A",{href:!0});var oFt=s(nX);FVo=r(oFt,"FNetForMultipleChoice"),oFt.forEach(t),TVo=r(QSe," (FNet model)"),QSe.forEach(t),MVo=i(ee),Iv=n(ee,"LI",{});var WSe=s(Iv);Vpe=n(WSe,"STRONG",{});var rFt=s(Vpe);EVo=r(rFt,"funnel"),rFt.forEach(t),CVo=r(WSe," \u2014 "),sX=n(WSe,"A",{href:!0});var tFt=s(sX);wVo=r(tFt,"FunnelForMultipleChoice"),tFt.forEach(t),AVo=r(WSe," (Funnel Transformer model)"),WSe.forEach(t),LVo=i(ee),Nv=n(ee,"LI",{});var HSe=s(Nv);Xpe=n(HSe,"STRONG",{});var aFt=s(Xpe);yVo=r(aFt,"ibert"),aFt.forEach(t),xVo=r(HSe," \u2014 "),lX=n(HSe,"A",{href:!0});var nFt=s(lX);$Vo=r(nFt,"IBertForMultipleChoice"),nFt.forEach(t),kVo=r(HSe," (I-BERT model)"),HSe.forEach(t),SVo=i(ee),qv=n(ee,"LI",{});var USe=s(qv);zpe=n(USe,"STRONG",{});var sFt=s(zpe);RVo=r(sFt,"longformer"),sFt.forEach(t),PVo=r(USe," \u2014 "),iX=n(USe,"A",{href:!0});var lFt=s(iX);BVo=r(lFt,"LongformerForMultipleChoice"),lFt.forEach(t),IVo=r(USe," (Longformer model)"),USe.forEach(t),NVo=i(ee),jv=n(ee,"LI",{});var JSe=s(jv);Qpe=n(JSe,"STRONG",{});var iFt=s(Qpe);qVo=r(iFt,"megatron-bert"),iFt.forEach(t),jVo=r(JSe," \u2014 "),dX=n(JSe,"A",{href:!0});var dFt=s(dX);DVo=r(dFt,"MegatronBertForMultipleChoice"),dFt.forEach(t),GVo=r(JSe," (Megatron-BERT model)"),JSe.forEach(t),OVo=i(ee),Dv=n(ee,"LI",{});var YSe=s(Dv);Wpe=n(YSe,"STRONG",{});var cFt=s(Wpe);VVo=r(cFt,"mobilebert"),cFt.forEach(t),XVo=r(YSe," \u2014 "),cX=n(YSe,"A",{href:!0});var fFt=s(cX);zVo=r(fFt,"MobileBertForMultipleChoice"),fFt.forEach(t),QVo=r(YSe," (MobileBERT model)"),YSe.forEach(t),WVo=i(ee),Gv=n(ee,"LI",{});var KSe=s(Gv);Hpe=n(KSe,"STRONG",{});var mFt=s(Hpe);HVo=r(mFt,"mpnet"),mFt.forEach(t),UVo=r(KSe," \u2014 "),fX=n(KSe,"A",{href:!0});var gFt=s(fX);JVo=r(gFt,"MPNetForMultipleChoice"),gFt.forEach(t),YVo=r(KSe," (MPNet model)"),KSe.forEach(t),KVo=i(ee),Ov=n(ee,"LI",{});var ZSe=s(Ov);Upe=n(ZSe,"STRONG",{});var hFt=s(Upe);ZVo=r(hFt,"nezha"),hFt.forEach(t),eXo=r(ZSe," \u2014 "),mX=n(ZSe,"A",{href:!0});var pFt=s(mX);oXo=r(pFt,"NezhaForMultipleChoice"),pFt.forEach(t),rXo=r(ZSe," (Nezha model)"),ZSe.forEach(t),tXo=i(ee),Vv=n(ee,"LI",{});var eRe=s(Vv);Jpe=n(eRe,"STRONG",{});var _Ft=s(Jpe);aXo=r(_Ft,"nystromformer"),_Ft.forEach(t),nXo=r(eRe," \u2014 "),gX=n(eRe,"A",{href:!0});var uFt=s(gX);sXo=r(uFt,"NystromformerForMultipleChoice"),uFt.forEach(t),lXo=r(eRe," (Nystr\xF6mformer model)"),eRe.forEach(t),iXo=i(ee),Xv=n(ee,"LI",{});var oRe=s(Xv);Ype=n(oRe,"STRONG",{});var bFt=s(Ype);dXo=r(bFt,"qdqbert"),bFt.forEach(t),cXo=r(oRe," \u2014 "),hX=n(oRe,"A",{href:!0});var vFt=s(hX);fXo=r(vFt,"QDQBertForMultipleChoice"),vFt.forEach(t),mXo=r(oRe," (QDQBert model)"),oRe.forEach(t),gXo=i(ee),zv=n(ee,"LI",{});var rRe=s(zv);Kpe=n(rRe,"STRONG",{});var FFt=s(Kpe);hXo=r(FFt,"rembert"),FFt.forEach(t),pXo=r(rRe," \u2014 "),pX=n(rRe,"A",{href:!0});var TFt=s(pX);_Xo=r(TFt,"RemBertForMultipleChoice"),TFt.forEach(t),uXo=r(rRe," (RemBERT model)"),rRe.forEach(t),bXo=i(ee),Qv=n(ee,"LI",{});var tRe=s(Qv);Zpe=n(tRe,"STRONG",{});var MFt=s(Zpe);vXo=r(MFt,"roberta"),MFt.forEach(t),FXo=r(tRe," \u2014 "),_X=n(tRe,"A",{href:!0});var EFt=s(_X);TXo=r(EFt,"RobertaForMultipleChoice"),EFt.forEach(t),MXo=r(tRe," (RoBERTa model)"),tRe.forEach(t),EXo=i(ee),Wv=n(ee,"LI",{});var aRe=s(Wv);e_e=n(aRe,"STRONG",{});var CFt=s(e_e);CXo=r(CFt,"roformer"),CFt.forEach(t),wXo=r(aRe," \u2014 "),uX=n(aRe,"A",{href:!0});var wFt=s(uX);AXo=r(wFt,"RoFormerForMultipleChoice"),wFt.forEach(t),LXo=r(aRe," (RoFormer model)"),aRe.forEach(t),yXo=i(ee),Hv=n(ee,"LI",{});var nRe=s(Hv);o_e=n(nRe,"STRONG",{});var AFt=s(o_e);xXo=r(AFt,"squeezebert"),AFt.forEach(t),$Xo=r(nRe," \u2014 "),bX=n(nRe,"A",{href:!0});var LFt=s(bX);kXo=r(LFt,"SqueezeBertForMultipleChoice"),LFt.forEach(t),SXo=r(nRe," (SqueezeBERT model)"),nRe.forEach(t),RXo=i(ee),Uv=n(ee,"LI",{});var sRe=s(Uv);r_e=n(sRe,"STRONG",{});var yFt=s(r_e);PXo=r(yFt,"xlm"),yFt.forEach(t),BXo=r(sRe," \u2014 "),vX=n(sRe,"A",{href:!0});var xFt=s(vX);IXo=r(xFt,"XLMForMultipleChoice"),xFt.forEach(t),NXo=r(sRe," (XLM model)"),sRe.forEach(t),qXo=i(ee),Jv=n(ee,"LI",{});var lRe=s(Jv);t_e=n(lRe,"STRONG",{});var $Ft=s(t_e);jXo=r($Ft,"xlm-roberta"),$Ft.forEach(t),DXo=r(lRe," \u2014 "),FX=n(lRe,"A",{href:!0});var kFt=s(FX);GXo=r(kFt,"XLMRobertaForMultipleChoice"),kFt.forEach(t),OXo=r(lRe," (XLM-RoBERTa model)"),lRe.forEach(t),VXo=i(ee),Yv=n(ee,"LI",{});var iRe=s(Yv);a_e=n(iRe,"STRONG",{});var SFt=s(a_e);XXo=r(SFt,"xlm-roberta-xl"),SFt.forEach(t),zXo=r(iRe," \u2014 "),TX=n(iRe,"A",{href:!0});var RFt=s(TX);QXo=r(RFt,"XLMRobertaXLForMultipleChoice"),RFt.forEach(t),WXo=r(iRe," (XLM-RoBERTa-XL model)"),iRe.forEach(t),HXo=i(ee),Kv=n(ee,"LI",{});var dRe=s(Kv);n_e=n(dRe,"STRONG",{});var PFt=s(n_e);UXo=r(PFt,"xlnet"),PFt.forEach(t),JXo=r(dRe," \u2014 "),MX=n(dRe,"A",{href:!0});var BFt=s(MX);YXo=r(BFt,"XLNetForMultipleChoice"),BFt.forEach(t),KXo=r(dRe," (XLNet model)"),dRe.forEach(t),ZXo=i(ee),Zv=n(ee,"LI",{});var cRe=s(Zv);s_e=n(cRe,"STRONG",{});var IFt=s(s_e);ezo=r(IFt,"yoso"),IFt.forEach(t),ozo=r(cRe," \u2014 "),EX=n(cRe,"A",{href:!0});var NFt=s(EX);rzo=r(NFt,"YosoForMultipleChoice"),NFt.forEach(t),tzo=r(cRe," (YOSO model)"),cRe.forEach(t),ee.forEach(t),azo=i(ca),eF=n(ca,"P",{});var fRe=s(eF);nzo=r(fRe,"The model is set in evaluation mode by default using "),l_e=n(fRe,"CODE",{});var qFt=s(l_e);szo=r(qFt,"model.eval()"),qFt.forEach(t),lzo=r(fRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),i_e=n(fRe,"CODE",{});var jFt=s(i_e);izo=r(jFt,"model.train()"),jFt.forEach(t),fRe.forEach(t),dzo=i(ca),T(oF.$$.fragment,ca),ca.forEach(t),tl.forEach(t),COe=i(f),rd=n(f,"H2",{class:!0});var $Xe=s(rd);rF=n($Xe,"A",{id:!0,class:!0,href:!0});var DFt=s(rF);d_e=n(DFt,"SPAN",{});var GFt=s(d_e);T(jL.$$.fragment,GFt),GFt.forEach(t),DFt.forEach(t),czo=i($Xe),c_e=n($Xe,"SPAN",{});var OFt=s(c_e);fzo=r(OFt,"AutoModelForNextSentencePrediction"),OFt.forEach(t),$Xe.forEach(t),wOe=i(f),Io=n(f,"DIV",{class:!0});var al=s(Io);T(DL.$$.fragment,al),mzo=i(al),td=n(al,"P",{});var Noe=s(td);gzo=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),CX=n(Noe,"A",{href:!0});var VFt=s(CX);hzo=r(VFt,"from_pretrained()"),VFt.forEach(t),pzo=r(Noe," class method or the "),wX=n(Noe,"A",{href:!0});var XFt=s(wX);_zo=r(XFt,"from_config()"),XFt.forEach(t),uzo=r(Noe,` class
method.`),Noe.forEach(t),bzo=i(al),GL=n(al,"P",{});var kXe=s(GL);vzo=r(kXe,"This class cannot be instantiated directly using "),f_e=n(kXe,"CODE",{});var zFt=s(f_e);Fzo=r(zFt,"__init__()"),zFt.forEach(t),Tzo=r(kXe," (throws an error)."),kXe.forEach(t),Mzo=i(al),mt=n(al,"DIV",{class:!0});var H0=s(mt);T(OL.$$.fragment,H0),Ezo=i(H0),m_e=n(H0,"P",{});var QFt=s(m_e);Czo=r(QFt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),QFt.forEach(t),wzo=i(H0),ad=n(H0,"P",{});var qoe=s(ad);Azo=r(qoe,`Note:
Loading a model from its configuration file does `),g_e=n(qoe,"STRONG",{});var WFt=s(g_e);Lzo=r(WFt,"not"),WFt.forEach(t),yzo=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),AX=n(qoe,"A",{href:!0});var HFt=s(AX);xzo=r(HFt,"from_pretrained()"),HFt.forEach(t),$zo=r(qoe," to load the model weights."),qoe.forEach(t),kzo=i(H0),T(tF.$$.fragment,H0),H0.forEach(t),Szo=i(al),to=n(al,"DIV",{class:!0});var fa=s(to);T(VL.$$.fragment,fa),Rzo=i(fa),h_e=n(fa,"P",{});var UFt=s(h_e);Pzo=r(UFt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),UFt.forEach(t),Bzo=i(fa),Da=n(fa,"P",{});var U0=s(Da);Izo=r(U0,"The model class to instantiate is selected based on the "),p_e=n(U0,"CODE",{});var JFt=s(p_e);Nzo=r(JFt,"model_type"),JFt.forEach(t),qzo=r(U0,` property of the config object (either
passed as an argument or loaded from `),__e=n(U0,"CODE",{});var YFt=s(__e);jzo=r(YFt,"pretrained_model_name_or_path"),YFt.forEach(t),Dzo=r(U0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u_e=n(U0,"CODE",{});var KFt=s(u_e);Gzo=r(KFt,"pretrained_model_name_or_path"),KFt.forEach(t),Ozo=r(U0,":"),U0.forEach(t),Vzo=i(fa),No=n(fa,"UL",{});var ma=s(No);aF=n(ma,"LI",{});var mRe=s(aF);b_e=n(mRe,"STRONG",{});var ZFt=s(b_e);Xzo=r(ZFt,"bert"),ZFt.forEach(t),zzo=r(mRe," \u2014 "),LX=n(mRe,"A",{href:!0});var e6t=s(LX);Qzo=r(e6t,"BertForNextSentencePrediction"),e6t.forEach(t),Wzo=r(mRe," (BERT model)"),mRe.forEach(t),Hzo=i(ma),nF=n(ma,"LI",{});var gRe=s(nF);v_e=n(gRe,"STRONG",{});var o6t=s(v_e);Uzo=r(o6t,"fnet"),o6t.forEach(t),Jzo=r(gRe," \u2014 "),yX=n(gRe,"A",{href:!0});var r6t=s(yX);Yzo=r(r6t,"FNetForNextSentencePrediction"),r6t.forEach(t),Kzo=r(gRe," (FNet model)"),gRe.forEach(t),Zzo=i(ma),sF=n(ma,"LI",{});var hRe=s(sF);F_e=n(hRe,"STRONG",{});var t6t=s(F_e);eQo=r(t6t,"megatron-bert"),t6t.forEach(t),oQo=r(hRe," \u2014 "),xX=n(hRe,"A",{href:!0});var a6t=s(xX);rQo=r(a6t,"MegatronBertForNextSentencePrediction"),a6t.forEach(t),tQo=r(hRe," (Megatron-BERT model)"),hRe.forEach(t),aQo=i(ma),lF=n(ma,"LI",{});var pRe=s(lF);T_e=n(pRe,"STRONG",{});var n6t=s(T_e);nQo=r(n6t,"mobilebert"),n6t.forEach(t),sQo=r(pRe," \u2014 "),$X=n(pRe,"A",{href:!0});var s6t=s($X);lQo=r(s6t,"MobileBertForNextSentencePrediction"),s6t.forEach(t),iQo=r(pRe," (MobileBERT model)"),pRe.forEach(t),dQo=i(ma),iF=n(ma,"LI",{});var _Re=s(iF);M_e=n(_Re,"STRONG",{});var l6t=s(M_e);cQo=r(l6t,"nezha"),l6t.forEach(t),fQo=r(_Re," \u2014 "),kX=n(_Re,"A",{href:!0});var i6t=s(kX);mQo=r(i6t,"NezhaForNextSentencePrediction"),i6t.forEach(t),gQo=r(_Re," (Nezha model)"),_Re.forEach(t),hQo=i(ma),dF=n(ma,"LI",{});var uRe=s(dF);E_e=n(uRe,"STRONG",{});var d6t=s(E_e);pQo=r(d6t,"qdqbert"),d6t.forEach(t),_Qo=r(uRe," \u2014 "),SX=n(uRe,"A",{href:!0});var c6t=s(SX);uQo=r(c6t,"QDQBertForNextSentencePrediction"),c6t.forEach(t),bQo=r(uRe," (QDQBert model)"),uRe.forEach(t),ma.forEach(t),vQo=i(fa),cF=n(fa,"P",{});var bRe=s(cF);FQo=r(bRe,"The model is set in evaluation mode by default using "),C_e=n(bRe,"CODE",{});var f6t=s(C_e);TQo=r(f6t,"model.eval()"),f6t.forEach(t),MQo=r(bRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w_e=n(bRe,"CODE",{});var m6t=s(w_e);EQo=r(m6t,"model.train()"),m6t.forEach(t),bRe.forEach(t),CQo=i(fa),T(fF.$$.fragment,fa),fa.forEach(t),al.forEach(t),AOe=i(f),nd=n(f,"H2",{class:!0});var SXe=s(nd);mF=n(SXe,"A",{id:!0,class:!0,href:!0});var g6t=s(mF);A_e=n(g6t,"SPAN",{});var h6t=s(A_e);T(XL.$$.fragment,h6t),h6t.forEach(t),g6t.forEach(t),wQo=i(SXe),L_e=n(SXe,"SPAN",{});var p6t=s(L_e);AQo=r(p6t,"AutoModelForTokenClassification"),p6t.forEach(t),SXe.forEach(t),LOe=i(f),qo=n(f,"DIV",{class:!0});var nl=s(qo);T(zL.$$.fragment,nl),LQo=i(nl),sd=n(nl,"P",{});var joe=s(sd);yQo=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),RX=n(joe,"A",{href:!0});var _6t=s(RX);xQo=r(_6t,"from_pretrained()"),_6t.forEach(t),$Qo=r(joe," class method or the "),PX=n(joe,"A",{href:!0});var u6t=s(PX);kQo=r(u6t,"from_config()"),u6t.forEach(t),SQo=r(joe,` class
method.`),joe.forEach(t),RQo=i(nl),QL=n(nl,"P",{});var RXe=s(QL);PQo=r(RXe,"This class cannot be instantiated directly using "),y_e=n(RXe,"CODE",{});var b6t=s(y_e);BQo=r(b6t,"__init__()"),b6t.forEach(t),IQo=r(RXe," (throws an error)."),RXe.forEach(t),NQo=i(nl),gt=n(nl,"DIV",{class:!0});var J0=s(gt);T(WL.$$.fragment,J0),qQo=i(J0),x_e=n(J0,"P",{});var v6t=s(x_e);jQo=r(v6t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),v6t.forEach(t),DQo=i(J0),ld=n(J0,"P",{});var Doe=s(ld);GQo=r(Doe,`Note:
Loading a model from its configuration file does `),$_e=n(Doe,"STRONG",{});var F6t=s($_e);OQo=r(F6t,"not"),F6t.forEach(t),VQo=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),BX=n(Doe,"A",{href:!0});var T6t=s(BX);XQo=r(T6t,"from_pretrained()"),T6t.forEach(t),zQo=r(Doe," to load the model weights."),Doe.forEach(t),QQo=i(J0),T(gF.$$.fragment,J0),J0.forEach(t),WQo=i(nl),ao=n(nl,"DIV",{class:!0});var ga=s(ao);T(HL.$$.fragment,ga),HQo=i(ga),k_e=n(ga,"P",{});var M6t=s(k_e);UQo=r(M6t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),M6t.forEach(t),JQo=i(ga),Ga=n(ga,"P",{});var Y0=s(Ga);YQo=r(Y0,"The model class to instantiate is selected based on the "),S_e=n(Y0,"CODE",{});var E6t=s(S_e);KQo=r(E6t,"model_type"),E6t.forEach(t),ZQo=r(Y0,` property of the config object (either
passed as an argument or loaded from `),R_e=n(Y0,"CODE",{});var C6t=s(R_e);eWo=r(C6t,"pretrained_model_name_or_path"),C6t.forEach(t),oWo=r(Y0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P_e=n(Y0,"CODE",{});var w6t=s(P_e);rWo=r(w6t,"pretrained_model_name_or_path"),w6t.forEach(t),tWo=r(Y0,":"),Y0.forEach(t),aWo=i(ga),H=n(ga,"UL",{});var J=s(H);hF=n(J,"LI",{});var vRe=s(hF);B_e=n(vRe,"STRONG",{});var A6t=s(B_e);nWo=r(A6t,"albert"),A6t.forEach(t),sWo=r(vRe," \u2014 "),IX=n(vRe,"A",{href:!0});var L6t=s(IX);lWo=r(L6t,"AlbertForTokenClassification"),L6t.forEach(t),iWo=r(vRe," (ALBERT model)"),vRe.forEach(t),dWo=i(J),pF=n(J,"LI",{});var FRe=s(pF);I_e=n(FRe,"STRONG",{});var y6t=s(I_e);cWo=r(y6t,"bert"),y6t.forEach(t),fWo=r(FRe," \u2014 "),NX=n(FRe,"A",{href:!0});var x6t=s(NX);mWo=r(x6t,"BertForTokenClassification"),x6t.forEach(t),gWo=r(FRe," (BERT model)"),FRe.forEach(t),hWo=i(J),_F=n(J,"LI",{});var TRe=s(_F);N_e=n(TRe,"STRONG",{});var $6t=s(N_e);pWo=r($6t,"big_bird"),$6t.forEach(t),_Wo=r(TRe," \u2014 "),qX=n(TRe,"A",{href:!0});var k6t=s(qX);uWo=r(k6t,"BigBirdForTokenClassification"),k6t.forEach(t),bWo=r(TRe," (BigBird model)"),TRe.forEach(t),vWo=i(J),uF=n(J,"LI",{});var MRe=s(uF);q_e=n(MRe,"STRONG",{});var S6t=s(q_e);FWo=r(S6t,"bloom"),S6t.forEach(t),TWo=r(MRe," \u2014 "),jX=n(MRe,"A",{href:!0});var R6t=s(jX);MWo=r(R6t,"BloomForTokenClassification"),R6t.forEach(t),EWo=r(MRe," (BLOOM model)"),MRe.forEach(t),CWo=i(J),bF=n(J,"LI",{});var ERe=s(bF);j_e=n(ERe,"STRONG",{});var P6t=s(j_e);wWo=r(P6t,"camembert"),P6t.forEach(t),AWo=r(ERe," \u2014 "),DX=n(ERe,"A",{href:!0});var B6t=s(DX);LWo=r(B6t,"CamembertForTokenClassification"),B6t.forEach(t),yWo=r(ERe," (CamemBERT model)"),ERe.forEach(t),xWo=i(J),vF=n(J,"LI",{});var CRe=s(vF);D_e=n(CRe,"STRONG",{});var I6t=s(D_e);$Wo=r(I6t,"canine"),I6t.forEach(t),kWo=r(CRe," \u2014 "),GX=n(CRe,"A",{href:!0});var N6t=s(GX);SWo=r(N6t,"CanineForTokenClassification"),N6t.forEach(t),RWo=r(CRe," (CANINE model)"),CRe.forEach(t),PWo=i(J),FF=n(J,"LI",{});var wRe=s(FF);G_e=n(wRe,"STRONG",{});var q6t=s(G_e);BWo=r(q6t,"convbert"),q6t.forEach(t),IWo=r(wRe," \u2014 "),OX=n(wRe,"A",{href:!0});var j6t=s(OX);NWo=r(j6t,"ConvBertForTokenClassification"),j6t.forEach(t),qWo=r(wRe," (ConvBERT model)"),wRe.forEach(t),jWo=i(J),TF=n(J,"LI",{});var ARe=s(TF);O_e=n(ARe,"STRONG",{});var D6t=s(O_e);DWo=r(D6t,"data2vec-text"),D6t.forEach(t),GWo=r(ARe," \u2014 "),VX=n(ARe,"A",{href:!0});var G6t=s(VX);OWo=r(G6t,"Data2VecTextForTokenClassification"),G6t.forEach(t),VWo=r(ARe," (Data2VecText model)"),ARe.forEach(t),XWo=i(J),MF=n(J,"LI",{});var LRe=s(MF);V_e=n(LRe,"STRONG",{});var O6t=s(V_e);zWo=r(O6t,"deberta"),O6t.forEach(t),QWo=r(LRe," \u2014 "),XX=n(LRe,"A",{href:!0});var V6t=s(XX);WWo=r(V6t,"DebertaForTokenClassification"),V6t.forEach(t),HWo=r(LRe," (DeBERTa model)"),LRe.forEach(t),UWo=i(J),EF=n(J,"LI",{});var yRe=s(EF);X_e=n(yRe,"STRONG",{});var X6t=s(X_e);JWo=r(X6t,"deberta-v2"),X6t.forEach(t),YWo=r(yRe," \u2014 "),zX=n(yRe,"A",{href:!0});var z6t=s(zX);KWo=r(z6t,"DebertaV2ForTokenClassification"),z6t.forEach(t),ZWo=r(yRe," (DeBERTa-v2 model)"),yRe.forEach(t),eHo=i(J),CF=n(J,"LI",{});var xRe=s(CF);z_e=n(xRe,"STRONG",{});var Q6t=s(z_e);oHo=r(Q6t,"distilbert"),Q6t.forEach(t),rHo=r(xRe," \u2014 "),QX=n(xRe,"A",{href:!0});var W6t=s(QX);tHo=r(W6t,"DistilBertForTokenClassification"),W6t.forEach(t),aHo=r(xRe," (DistilBERT model)"),xRe.forEach(t),nHo=i(J),wF=n(J,"LI",{});var $Re=s(wF);Q_e=n($Re,"STRONG",{});var H6t=s(Q_e);sHo=r(H6t,"electra"),H6t.forEach(t),lHo=r($Re," \u2014 "),WX=n($Re,"A",{href:!0});var U6t=s(WX);iHo=r(U6t,"ElectraForTokenClassification"),U6t.forEach(t),dHo=r($Re," (ELECTRA model)"),$Re.forEach(t),cHo=i(J),AF=n(J,"LI",{});var kRe=s(AF);W_e=n(kRe,"STRONG",{});var J6t=s(W_e);fHo=r(J6t,"flaubert"),J6t.forEach(t),mHo=r(kRe," \u2014 "),HX=n(kRe,"A",{href:!0});var Y6t=s(HX);gHo=r(Y6t,"FlaubertForTokenClassification"),Y6t.forEach(t),hHo=r(kRe," (FlauBERT model)"),kRe.forEach(t),pHo=i(J),LF=n(J,"LI",{});var SRe=s(LF);H_e=n(SRe,"STRONG",{});var K6t=s(H_e);_Ho=r(K6t,"fnet"),K6t.forEach(t),uHo=r(SRe," \u2014 "),UX=n(SRe,"A",{href:!0});var Z6t=s(UX);bHo=r(Z6t,"FNetForTokenClassification"),Z6t.forEach(t),vHo=r(SRe," (FNet model)"),SRe.forEach(t),FHo=i(J),yF=n(J,"LI",{});var RRe=s(yF);U_e=n(RRe,"STRONG",{});var eTt=s(U_e);THo=r(eTt,"funnel"),eTt.forEach(t),MHo=r(RRe," \u2014 "),JX=n(RRe,"A",{href:!0});var oTt=s(JX);EHo=r(oTt,"FunnelForTokenClassification"),oTt.forEach(t),CHo=r(RRe," (Funnel Transformer model)"),RRe.forEach(t),wHo=i(J),xF=n(J,"LI",{});var PRe=s(xF);J_e=n(PRe,"STRONG",{});var rTt=s(J_e);AHo=r(rTt,"gpt2"),rTt.forEach(t),LHo=r(PRe," \u2014 "),YX=n(PRe,"A",{href:!0});var tTt=s(YX);yHo=r(tTt,"GPT2ForTokenClassification"),tTt.forEach(t),xHo=r(PRe," (OpenAI GPT-2 model)"),PRe.forEach(t),$Ho=i(J),$F=n(J,"LI",{});var BRe=s($F);Y_e=n(BRe,"STRONG",{});var aTt=s(Y_e);kHo=r(aTt,"ibert"),aTt.forEach(t),SHo=r(BRe," \u2014 "),KX=n(BRe,"A",{href:!0});var nTt=s(KX);RHo=r(nTt,"IBertForTokenClassification"),nTt.forEach(t),PHo=r(BRe," (I-BERT model)"),BRe.forEach(t),BHo=i(J),kF=n(J,"LI",{});var IRe=s(kF);K_e=n(IRe,"STRONG",{});var sTt=s(K_e);IHo=r(sTt,"layoutlm"),sTt.forEach(t),NHo=r(IRe," \u2014 "),ZX=n(IRe,"A",{href:!0});var lTt=s(ZX);qHo=r(lTt,"LayoutLMForTokenClassification"),lTt.forEach(t),jHo=r(IRe," (LayoutLM model)"),IRe.forEach(t),DHo=i(J),SF=n(J,"LI",{});var NRe=s(SF);Z_e=n(NRe,"STRONG",{});var iTt=s(Z_e);GHo=r(iTt,"layoutlmv2"),iTt.forEach(t),OHo=r(NRe," \u2014 "),ez=n(NRe,"A",{href:!0});var dTt=s(ez);VHo=r(dTt,"LayoutLMv2ForTokenClassification"),dTt.forEach(t),XHo=r(NRe," (LayoutLMv2 model)"),NRe.forEach(t),zHo=i(J),RF=n(J,"LI",{});var qRe=s(RF);eue=n(qRe,"STRONG",{});var cTt=s(eue);QHo=r(cTt,"layoutlmv3"),cTt.forEach(t),WHo=r(qRe," \u2014 "),oz=n(qRe,"A",{href:!0});var fTt=s(oz);HHo=r(fTt,"LayoutLMv3ForTokenClassification"),fTt.forEach(t),UHo=r(qRe," (LayoutLMv3 model)"),qRe.forEach(t),JHo=i(J),PF=n(J,"LI",{});var jRe=s(PF);oue=n(jRe,"STRONG",{});var mTt=s(oue);YHo=r(mTt,"longformer"),mTt.forEach(t),KHo=r(jRe," \u2014 "),rz=n(jRe,"A",{href:!0});var gTt=s(rz);ZHo=r(gTt,"LongformerForTokenClassification"),gTt.forEach(t),eUo=r(jRe," (Longformer model)"),jRe.forEach(t),oUo=i(J),BF=n(J,"LI",{});var DRe=s(BF);rue=n(DRe,"STRONG",{});var hTt=s(rue);rUo=r(hTt,"megatron-bert"),hTt.forEach(t),tUo=r(DRe," \u2014 "),tz=n(DRe,"A",{href:!0});var pTt=s(tz);aUo=r(pTt,"MegatronBertForTokenClassification"),pTt.forEach(t),nUo=r(DRe," (Megatron-BERT model)"),DRe.forEach(t),sUo=i(J),IF=n(J,"LI",{});var GRe=s(IF);tue=n(GRe,"STRONG",{});var _Tt=s(tue);lUo=r(_Tt,"mobilebert"),_Tt.forEach(t),iUo=r(GRe," \u2014 "),az=n(GRe,"A",{href:!0});var uTt=s(az);dUo=r(uTt,"MobileBertForTokenClassification"),uTt.forEach(t),cUo=r(GRe," (MobileBERT model)"),GRe.forEach(t),fUo=i(J),NF=n(J,"LI",{});var ORe=s(NF);aue=n(ORe,"STRONG",{});var bTt=s(aue);mUo=r(bTt,"mpnet"),bTt.forEach(t),gUo=r(ORe," \u2014 "),nz=n(ORe,"A",{href:!0});var vTt=s(nz);hUo=r(vTt,"MPNetForTokenClassification"),vTt.forEach(t),pUo=r(ORe," (MPNet model)"),ORe.forEach(t),_Uo=i(J),qF=n(J,"LI",{});var VRe=s(qF);nue=n(VRe,"STRONG",{});var FTt=s(nue);uUo=r(FTt,"nezha"),FTt.forEach(t),bUo=r(VRe," \u2014 "),sz=n(VRe,"A",{href:!0});var TTt=s(sz);vUo=r(TTt,"NezhaForTokenClassification"),TTt.forEach(t),FUo=r(VRe," (Nezha model)"),VRe.forEach(t),TUo=i(J),jF=n(J,"LI",{});var XRe=s(jF);sue=n(XRe,"STRONG",{});var MTt=s(sue);MUo=r(MTt,"nystromformer"),MTt.forEach(t),EUo=r(XRe," \u2014 "),lz=n(XRe,"A",{href:!0});var ETt=s(lz);CUo=r(ETt,"NystromformerForTokenClassification"),ETt.forEach(t),wUo=r(XRe," (Nystr\xF6mformer model)"),XRe.forEach(t),AUo=i(J),DF=n(J,"LI",{});var zRe=s(DF);lue=n(zRe,"STRONG",{});var CTt=s(lue);LUo=r(CTt,"qdqbert"),CTt.forEach(t),yUo=r(zRe," \u2014 "),iz=n(zRe,"A",{href:!0});var wTt=s(iz);xUo=r(wTt,"QDQBertForTokenClassification"),wTt.forEach(t),$Uo=r(zRe," (QDQBert model)"),zRe.forEach(t),kUo=i(J),GF=n(J,"LI",{});var QRe=s(GF);iue=n(QRe,"STRONG",{});var ATt=s(iue);SUo=r(ATt,"rembert"),ATt.forEach(t),RUo=r(QRe," \u2014 "),dz=n(QRe,"A",{href:!0});var LTt=s(dz);PUo=r(LTt,"RemBertForTokenClassification"),LTt.forEach(t),BUo=r(QRe," (RemBERT model)"),QRe.forEach(t),IUo=i(J),OF=n(J,"LI",{});var WRe=s(OF);due=n(WRe,"STRONG",{});var yTt=s(due);NUo=r(yTt,"roberta"),yTt.forEach(t),qUo=r(WRe," \u2014 "),cz=n(WRe,"A",{href:!0});var xTt=s(cz);jUo=r(xTt,"RobertaForTokenClassification"),xTt.forEach(t),DUo=r(WRe," (RoBERTa model)"),WRe.forEach(t),GUo=i(J),VF=n(J,"LI",{});var HRe=s(VF);cue=n(HRe,"STRONG",{});var $Tt=s(cue);OUo=r($Tt,"roformer"),$Tt.forEach(t),VUo=r(HRe," \u2014 "),fz=n(HRe,"A",{href:!0});var kTt=s(fz);XUo=r(kTt,"RoFormerForTokenClassification"),kTt.forEach(t),zUo=r(HRe," (RoFormer model)"),HRe.forEach(t),QUo=i(J),XF=n(J,"LI",{});var URe=s(XF);fue=n(URe,"STRONG",{});var STt=s(fue);WUo=r(STt,"squeezebert"),STt.forEach(t),HUo=r(URe," \u2014 "),mz=n(URe,"A",{href:!0});var RTt=s(mz);UUo=r(RTt,"SqueezeBertForTokenClassification"),RTt.forEach(t),JUo=r(URe," (SqueezeBERT model)"),URe.forEach(t),YUo=i(J),zF=n(J,"LI",{});var JRe=s(zF);mue=n(JRe,"STRONG",{});var PTt=s(mue);KUo=r(PTt,"xlm"),PTt.forEach(t),ZUo=r(JRe," \u2014 "),gz=n(JRe,"A",{href:!0});var BTt=s(gz);eJo=r(BTt,"XLMForTokenClassification"),BTt.forEach(t),oJo=r(JRe," (XLM model)"),JRe.forEach(t),rJo=i(J),QF=n(J,"LI",{});var YRe=s(QF);gue=n(YRe,"STRONG",{});var ITt=s(gue);tJo=r(ITt,"xlm-roberta"),ITt.forEach(t),aJo=r(YRe," \u2014 "),hz=n(YRe,"A",{href:!0});var NTt=s(hz);nJo=r(NTt,"XLMRobertaForTokenClassification"),NTt.forEach(t),sJo=r(YRe," (XLM-RoBERTa model)"),YRe.forEach(t),lJo=i(J),WF=n(J,"LI",{});var KRe=s(WF);hue=n(KRe,"STRONG",{});var qTt=s(hue);iJo=r(qTt,"xlm-roberta-xl"),qTt.forEach(t),dJo=r(KRe," \u2014 "),pz=n(KRe,"A",{href:!0});var jTt=s(pz);cJo=r(jTt,"XLMRobertaXLForTokenClassification"),jTt.forEach(t),fJo=r(KRe," (XLM-RoBERTa-XL model)"),KRe.forEach(t),mJo=i(J),HF=n(J,"LI",{});var ZRe=s(HF);pue=n(ZRe,"STRONG",{});var DTt=s(pue);gJo=r(DTt,"xlnet"),DTt.forEach(t),hJo=r(ZRe," \u2014 "),_z=n(ZRe,"A",{href:!0});var GTt=s(_z);pJo=r(GTt,"XLNetForTokenClassification"),GTt.forEach(t),_Jo=r(ZRe," (XLNet model)"),ZRe.forEach(t),uJo=i(J),UF=n(J,"LI",{});var ePe=s(UF);_ue=n(ePe,"STRONG",{});var OTt=s(_ue);bJo=r(OTt,"yoso"),OTt.forEach(t),vJo=r(ePe," \u2014 "),uz=n(ePe,"A",{href:!0});var VTt=s(uz);FJo=r(VTt,"YosoForTokenClassification"),VTt.forEach(t),TJo=r(ePe," (YOSO model)"),ePe.forEach(t),J.forEach(t),MJo=i(ga),JF=n(ga,"P",{});var oPe=s(JF);EJo=r(oPe,"The model is set in evaluation mode by default using "),uue=n(oPe,"CODE",{});var XTt=s(uue);CJo=r(XTt,"model.eval()"),XTt.forEach(t),wJo=r(oPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=n(oPe,"CODE",{});var zTt=s(bue);AJo=r(zTt,"model.train()"),zTt.forEach(t),oPe.forEach(t),LJo=i(ga),T(YF.$$.fragment,ga),ga.forEach(t),nl.forEach(t),yOe=i(f),id=n(f,"H2",{class:!0});var PXe=s(id);KF=n(PXe,"A",{id:!0,class:!0,href:!0});var QTt=s(KF);vue=n(QTt,"SPAN",{});var WTt=s(vue);T(UL.$$.fragment,WTt),WTt.forEach(t),QTt.forEach(t),yJo=i(PXe),Fue=n(PXe,"SPAN",{});var HTt=s(Fue);xJo=r(HTt,"AutoModelForQuestionAnswering"),HTt.forEach(t),PXe.forEach(t),xOe=i(f),jo=n(f,"DIV",{class:!0});var sl=s(jo);T(JL.$$.fragment,sl),$Jo=i(sl),dd=n(sl,"P",{});var Goe=s(dd);kJo=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),bz=n(Goe,"A",{href:!0});var UTt=s(bz);SJo=r(UTt,"from_pretrained()"),UTt.forEach(t),RJo=r(Goe," class method or the "),vz=n(Goe,"A",{href:!0});var JTt=s(vz);PJo=r(JTt,"from_config()"),JTt.forEach(t),BJo=r(Goe,` class
method.`),Goe.forEach(t),IJo=i(sl),YL=n(sl,"P",{});var BXe=s(YL);NJo=r(BXe,"This class cannot be instantiated directly using "),Tue=n(BXe,"CODE",{});var YTt=s(Tue);qJo=r(YTt,"__init__()"),YTt.forEach(t),jJo=r(BXe," (throws an error)."),BXe.forEach(t),DJo=i(sl),ht=n(sl,"DIV",{class:!0});var K0=s(ht);T(KL.$$.fragment,K0),GJo=i(K0),Mue=n(K0,"P",{});var KTt=s(Mue);OJo=r(KTt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),KTt.forEach(t),VJo=i(K0),cd=n(K0,"P",{});var Ooe=s(cd);XJo=r(Ooe,`Note:
Loading a model from its configuration file does `),Eue=n(Ooe,"STRONG",{});var ZTt=s(Eue);zJo=r(ZTt,"not"),ZTt.forEach(t),QJo=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(Ooe,"A",{href:!0});var e7t=s(Fz);WJo=r(e7t,"from_pretrained()"),e7t.forEach(t),HJo=r(Ooe," to load the model weights."),Ooe.forEach(t),UJo=i(K0),T(ZF.$$.fragment,K0),K0.forEach(t),JJo=i(sl),no=n(sl,"DIV",{class:!0});var ha=s(no);T(ZL.$$.fragment,ha),YJo=i(ha),Cue=n(ha,"P",{});var o7t=s(Cue);KJo=r(o7t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),o7t.forEach(t),ZJo=i(ha),Oa=n(ha,"P",{});var Z0=s(Oa);eYo=r(Z0,"The model class to instantiate is selected based on the "),wue=n(Z0,"CODE",{});var r7t=s(wue);oYo=r(r7t,"model_type"),r7t.forEach(t),rYo=r(Z0,` property of the config object (either
passed as an argument or loaded from `),Aue=n(Z0,"CODE",{});var t7t=s(Aue);tYo=r(t7t,"pretrained_model_name_or_path"),t7t.forEach(t),aYo=r(Z0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lue=n(Z0,"CODE",{});var a7t=s(Lue);nYo=r(a7t,"pretrained_model_name_or_path"),a7t.forEach(t),sYo=r(Z0,":"),Z0.forEach(t),lYo=i(ha),V=n(ha,"UL",{});var X=s(V);e6=n(X,"LI",{});var rPe=s(e6);yue=n(rPe,"STRONG",{});var n7t=s(yue);iYo=r(n7t,"albert"),n7t.forEach(t),dYo=r(rPe," \u2014 "),Tz=n(rPe,"A",{href:!0});var s7t=s(Tz);cYo=r(s7t,"AlbertForQuestionAnswering"),s7t.forEach(t),fYo=r(rPe," (ALBERT model)"),rPe.forEach(t),mYo=i(X),o6=n(X,"LI",{});var tPe=s(o6);xue=n(tPe,"STRONG",{});var l7t=s(xue);gYo=r(l7t,"bart"),l7t.forEach(t),hYo=r(tPe," \u2014 "),Mz=n(tPe,"A",{href:!0});var i7t=s(Mz);pYo=r(i7t,"BartForQuestionAnswering"),i7t.forEach(t),_Yo=r(tPe," (BART model)"),tPe.forEach(t),uYo=i(X),r6=n(X,"LI",{});var aPe=s(r6);$ue=n(aPe,"STRONG",{});var d7t=s($ue);bYo=r(d7t,"bert"),d7t.forEach(t),vYo=r(aPe," \u2014 "),Ez=n(aPe,"A",{href:!0});var c7t=s(Ez);FYo=r(c7t,"BertForQuestionAnswering"),c7t.forEach(t),TYo=r(aPe," (BERT model)"),aPe.forEach(t),MYo=i(X),t6=n(X,"LI",{});var nPe=s(t6);kue=n(nPe,"STRONG",{});var f7t=s(kue);EYo=r(f7t,"big_bird"),f7t.forEach(t),CYo=r(nPe," \u2014 "),Cz=n(nPe,"A",{href:!0});var m7t=s(Cz);wYo=r(m7t,"BigBirdForQuestionAnswering"),m7t.forEach(t),AYo=r(nPe," (BigBird model)"),nPe.forEach(t),LYo=i(X),a6=n(X,"LI",{});var sPe=s(a6);Sue=n(sPe,"STRONG",{});var g7t=s(Sue);yYo=r(g7t,"bigbird_pegasus"),g7t.forEach(t),xYo=r(sPe," \u2014 "),wz=n(sPe,"A",{href:!0});var h7t=s(wz);$Yo=r(h7t,"BigBirdPegasusForQuestionAnswering"),h7t.forEach(t),kYo=r(sPe," (BigBird-Pegasus model)"),sPe.forEach(t),SYo=i(X),n6=n(X,"LI",{});var lPe=s(n6);Rue=n(lPe,"STRONG",{});var p7t=s(Rue);RYo=r(p7t,"camembert"),p7t.forEach(t),PYo=r(lPe," \u2014 "),Az=n(lPe,"A",{href:!0});var _7t=s(Az);BYo=r(_7t,"CamembertForQuestionAnswering"),_7t.forEach(t),IYo=r(lPe," (CamemBERT model)"),lPe.forEach(t),NYo=i(X),s6=n(X,"LI",{});var iPe=s(s6);Pue=n(iPe,"STRONG",{});var u7t=s(Pue);qYo=r(u7t,"canine"),u7t.forEach(t),jYo=r(iPe," \u2014 "),Lz=n(iPe,"A",{href:!0});var b7t=s(Lz);DYo=r(b7t,"CanineForQuestionAnswering"),b7t.forEach(t),GYo=r(iPe," (CANINE model)"),iPe.forEach(t),OYo=i(X),l6=n(X,"LI",{});var dPe=s(l6);Bue=n(dPe,"STRONG",{});var v7t=s(Bue);VYo=r(v7t,"convbert"),v7t.forEach(t),XYo=r(dPe," \u2014 "),yz=n(dPe,"A",{href:!0});var F7t=s(yz);zYo=r(F7t,"ConvBertForQuestionAnswering"),F7t.forEach(t),QYo=r(dPe," (ConvBERT model)"),dPe.forEach(t),WYo=i(X),i6=n(X,"LI",{});var cPe=s(i6);Iue=n(cPe,"STRONG",{});var T7t=s(Iue);HYo=r(T7t,"data2vec-text"),T7t.forEach(t),UYo=r(cPe," \u2014 "),xz=n(cPe,"A",{href:!0});var M7t=s(xz);JYo=r(M7t,"Data2VecTextForQuestionAnswering"),M7t.forEach(t),YYo=r(cPe," (Data2VecText model)"),cPe.forEach(t),KYo=i(X),d6=n(X,"LI",{});var fPe=s(d6);Nue=n(fPe,"STRONG",{});var E7t=s(Nue);ZYo=r(E7t,"deberta"),E7t.forEach(t),eKo=r(fPe," \u2014 "),$z=n(fPe,"A",{href:!0});var C7t=s($z);oKo=r(C7t,"DebertaForQuestionAnswering"),C7t.forEach(t),rKo=r(fPe," (DeBERTa model)"),fPe.forEach(t),tKo=i(X),c6=n(X,"LI",{});var mPe=s(c6);que=n(mPe,"STRONG",{});var w7t=s(que);aKo=r(w7t,"deberta-v2"),w7t.forEach(t),nKo=r(mPe," \u2014 "),kz=n(mPe,"A",{href:!0});var A7t=s(kz);sKo=r(A7t,"DebertaV2ForQuestionAnswering"),A7t.forEach(t),lKo=r(mPe," (DeBERTa-v2 model)"),mPe.forEach(t),iKo=i(X),f6=n(X,"LI",{});var gPe=s(f6);jue=n(gPe,"STRONG",{});var L7t=s(jue);dKo=r(L7t,"distilbert"),L7t.forEach(t),cKo=r(gPe," \u2014 "),Sz=n(gPe,"A",{href:!0});var y7t=s(Sz);fKo=r(y7t,"DistilBertForQuestionAnswering"),y7t.forEach(t),mKo=r(gPe," (DistilBERT model)"),gPe.forEach(t),gKo=i(X),m6=n(X,"LI",{});var hPe=s(m6);Due=n(hPe,"STRONG",{});var x7t=s(Due);hKo=r(x7t,"electra"),x7t.forEach(t),pKo=r(hPe," \u2014 "),Rz=n(hPe,"A",{href:!0});var $7t=s(Rz);_Ko=r($7t,"ElectraForQuestionAnswering"),$7t.forEach(t),uKo=r(hPe," (ELECTRA model)"),hPe.forEach(t),bKo=i(X),g6=n(X,"LI",{});var pPe=s(g6);Gue=n(pPe,"STRONG",{});var k7t=s(Gue);vKo=r(k7t,"flaubert"),k7t.forEach(t),FKo=r(pPe," \u2014 "),Pz=n(pPe,"A",{href:!0});var S7t=s(Pz);TKo=r(S7t,"FlaubertForQuestionAnsweringSimple"),S7t.forEach(t),MKo=r(pPe," (FlauBERT model)"),pPe.forEach(t),EKo=i(X),h6=n(X,"LI",{});var _Pe=s(h6);Oue=n(_Pe,"STRONG",{});var R7t=s(Oue);CKo=r(R7t,"fnet"),R7t.forEach(t),wKo=r(_Pe," \u2014 "),Bz=n(_Pe,"A",{href:!0});var P7t=s(Bz);AKo=r(P7t,"FNetForQuestionAnswering"),P7t.forEach(t),LKo=r(_Pe," (FNet model)"),_Pe.forEach(t),yKo=i(X),p6=n(X,"LI",{});var uPe=s(p6);Vue=n(uPe,"STRONG",{});var B7t=s(Vue);xKo=r(B7t,"funnel"),B7t.forEach(t),$Ko=r(uPe," \u2014 "),Iz=n(uPe,"A",{href:!0});var I7t=s(Iz);kKo=r(I7t,"FunnelForQuestionAnswering"),I7t.forEach(t),SKo=r(uPe," (Funnel Transformer model)"),uPe.forEach(t),RKo=i(X),_6=n(X,"LI",{});var bPe=s(_6);Xue=n(bPe,"STRONG",{});var N7t=s(Xue);PKo=r(N7t,"gptj"),N7t.forEach(t),BKo=r(bPe," \u2014 "),Nz=n(bPe,"A",{href:!0});var q7t=s(Nz);IKo=r(q7t,"GPTJForQuestionAnswering"),q7t.forEach(t),NKo=r(bPe," (GPT-J model)"),bPe.forEach(t),qKo=i(X),u6=n(X,"LI",{});var vPe=s(u6);zue=n(vPe,"STRONG",{});var j7t=s(zue);jKo=r(j7t,"ibert"),j7t.forEach(t),DKo=r(vPe," \u2014 "),qz=n(vPe,"A",{href:!0});var D7t=s(qz);GKo=r(D7t,"IBertForQuestionAnswering"),D7t.forEach(t),OKo=r(vPe," (I-BERT model)"),vPe.forEach(t),VKo=i(X),b6=n(X,"LI",{});var FPe=s(b6);Que=n(FPe,"STRONG",{});var G7t=s(Que);XKo=r(G7t,"layoutlmv2"),G7t.forEach(t),zKo=r(FPe," \u2014 "),jz=n(FPe,"A",{href:!0});var O7t=s(jz);QKo=r(O7t,"LayoutLMv2ForQuestionAnswering"),O7t.forEach(t),WKo=r(FPe," (LayoutLMv2 model)"),FPe.forEach(t),HKo=i(X),v6=n(X,"LI",{});var TPe=s(v6);Wue=n(TPe,"STRONG",{});var V7t=s(Wue);UKo=r(V7t,"layoutlmv3"),V7t.forEach(t),JKo=r(TPe," \u2014 "),Dz=n(TPe,"A",{href:!0});var X7t=s(Dz);YKo=r(X7t,"LayoutLMv3ForQuestionAnswering"),X7t.forEach(t),KKo=r(TPe," (LayoutLMv3 model)"),TPe.forEach(t),ZKo=i(X),F6=n(X,"LI",{});var MPe=s(F6);Hue=n(MPe,"STRONG",{});var z7t=s(Hue);eZo=r(z7t,"led"),z7t.forEach(t),oZo=r(MPe," \u2014 "),Gz=n(MPe,"A",{href:!0});var Q7t=s(Gz);rZo=r(Q7t,"LEDForQuestionAnswering"),Q7t.forEach(t),tZo=r(MPe," (LED model)"),MPe.forEach(t),aZo=i(X),T6=n(X,"LI",{});var EPe=s(T6);Uue=n(EPe,"STRONG",{});var W7t=s(Uue);nZo=r(W7t,"longformer"),W7t.forEach(t),sZo=r(EPe," \u2014 "),Oz=n(EPe,"A",{href:!0});var H7t=s(Oz);lZo=r(H7t,"LongformerForQuestionAnswering"),H7t.forEach(t),iZo=r(EPe," (Longformer model)"),EPe.forEach(t),dZo=i(X),M6=n(X,"LI",{});var CPe=s(M6);Jue=n(CPe,"STRONG",{});var U7t=s(Jue);cZo=r(U7t,"lxmert"),U7t.forEach(t),fZo=r(CPe," \u2014 "),Vz=n(CPe,"A",{href:!0});var J7t=s(Vz);mZo=r(J7t,"LxmertForQuestionAnswering"),J7t.forEach(t),gZo=r(CPe," (LXMERT model)"),CPe.forEach(t),hZo=i(X),E6=n(X,"LI",{});var wPe=s(E6);Yue=n(wPe,"STRONG",{});var Y7t=s(Yue);pZo=r(Y7t,"mbart"),Y7t.forEach(t),_Zo=r(wPe," \u2014 "),Xz=n(wPe,"A",{href:!0});var K7t=s(Xz);uZo=r(K7t,"MBartForQuestionAnswering"),K7t.forEach(t),bZo=r(wPe," (mBART model)"),wPe.forEach(t),vZo=i(X),C6=n(X,"LI",{});var APe=s(C6);Kue=n(APe,"STRONG",{});var Z7t=s(Kue);FZo=r(Z7t,"megatron-bert"),Z7t.forEach(t),TZo=r(APe," \u2014 "),zz=n(APe,"A",{href:!0});var e8t=s(zz);MZo=r(e8t,"MegatronBertForQuestionAnswering"),e8t.forEach(t),EZo=r(APe," (Megatron-BERT model)"),APe.forEach(t),CZo=i(X),w6=n(X,"LI",{});var LPe=s(w6);Zue=n(LPe,"STRONG",{});var o8t=s(Zue);wZo=r(o8t,"mobilebert"),o8t.forEach(t),AZo=r(LPe," \u2014 "),Qz=n(LPe,"A",{href:!0});var r8t=s(Qz);LZo=r(r8t,"MobileBertForQuestionAnswering"),r8t.forEach(t),yZo=r(LPe," (MobileBERT model)"),LPe.forEach(t),xZo=i(X),A6=n(X,"LI",{});var yPe=s(A6);e2e=n(yPe,"STRONG",{});var t8t=s(e2e);$Zo=r(t8t,"mpnet"),t8t.forEach(t),kZo=r(yPe," \u2014 "),Wz=n(yPe,"A",{href:!0});var a8t=s(Wz);SZo=r(a8t,"MPNetForQuestionAnswering"),a8t.forEach(t),RZo=r(yPe," (MPNet model)"),yPe.forEach(t),PZo=i(X),L6=n(X,"LI",{});var xPe=s(L6);o2e=n(xPe,"STRONG",{});var n8t=s(o2e);BZo=r(n8t,"nezha"),n8t.forEach(t),IZo=r(xPe," \u2014 "),Hz=n(xPe,"A",{href:!0});var s8t=s(Hz);NZo=r(s8t,"NezhaForQuestionAnswering"),s8t.forEach(t),qZo=r(xPe," (Nezha model)"),xPe.forEach(t),jZo=i(X),y6=n(X,"LI",{});var $Pe=s(y6);r2e=n($Pe,"STRONG",{});var l8t=s(r2e);DZo=r(l8t,"nystromformer"),l8t.forEach(t),GZo=r($Pe," \u2014 "),Uz=n($Pe,"A",{href:!0});var i8t=s(Uz);OZo=r(i8t,"NystromformerForQuestionAnswering"),i8t.forEach(t),VZo=r($Pe," (Nystr\xF6mformer model)"),$Pe.forEach(t),XZo=i(X),x6=n(X,"LI",{});var kPe=s(x6);t2e=n(kPe,"STRONG",{});var d8t=s(t2e);zZo=r(d8t,"qdqbert"),d8t.forEach(t),QZo=r(kPe," \u2014 "),Jz=n(kPe,"A",{href:!0});var c8t=s(Jz);WZo=r(c8t,"QDQBertForQuestionAnswering"),c8t.forEach(t),HZo=r(kPe," (QDQBert model)"),kPe.forEach(t),UZo=i(X),$6=n(X,"LI",{});var SPe=s($6);a2e=n(SPe,"STRONG",{});var f8t=s(a2e);JZo=r(f8t,"reformer"),f8t.forEach(t),YZo=r(SPe," \u2014 "),Yz=n(SPe,"A",{href:!0});var m8t=s(Yz);KZo=r(m8t,"ReformerForQuestionAnswering"),m8t.forEach(t),ZZo=r(SPe," (Reformer model)"),SPe.forEach(t),eer=i(X),k6=n(X,"LI",{});var RPe=s(k6);n2e=n(RPe,"STRONG",{});var g8t=s(n2e);oer=r(g8t,"rembert"),g8t.forEach(t),rer=r(RPe," \u2014 "),Kz=n(RPe,"A",{href:!0});var h8t=s(Kz);ter=r(h8t,"RemBertForQuestionAnswering"),h8t.forEach(t),aer=r(RPe," (RemBERT model)"),RPe.forEach(t),ner=i(X),S6=n(X,"LI",{});var PPe=s(S6);s2e=n(PPe,"STRONG",{});var p8t=s(s2e);ser=r(p8t,"roberta"),p8t.forEach(t),ler=r(PPe," \u2014 "),Zz=n(PPe,"A",{href:!0});var _8t=s(Zz);ier=r(_8t,"RobertaForQuestionAnswering"),_8t.forEach(t),der=r(PPe," (RoBERTa model)"),PPe.forEach(t),cer=i(X),R6=n(X,"LI",{});var BPe=s(R6);l2e=n(BPe,"STRONG",{});var u8t=s(l2e);fer=r(u8t,"roformer"),u8t.forEach(t),mer=r(BPe," \u2014 "),eQ=n(BPe,"A",{href:!0});var b8t=s(eQ);ger=r(b8t,"RoFormerForQuestionAnswering"),b8t.forEach(t),her=r(BPe," (RoFormer model)"),BPe.forEach(t),per=i(X),P6=n(X,"LI",{});var IPe=s(P6);i2e=n(IPe,"STRONG",{});var v8t=s(i2e);_er=r(v8t,"splinter"),v8t.forEach(t),uer=r(IPe," \u2014 "),oQ=n(IPe,"A",{href:!0});var F8t=s(oQ);ber=r(F8t,"SplinterForQuestionAnswering"),F8t.forEach(t),ver=r(IPe," (Splinter model)"),IPe.forEach(t),Fer=i(X),B6=n(X,"LI",{});var NPe=s(B6);d2e=n(NPe,"STRONG",{});var T8t=s(d2e);Ter=r(T8t,"squeezebert"),T8t.forEach(t),Mer=r(NPe," \u2014 "),rQ=n(NPe,"A",{href:!0});var M8t=s(rQ);Eer=r(M8t,"SqueezeBertForQuestionAnswering"),M8t.forEach(t),Cer=r(NPe," (SqueezeBERT model)"),NPe.forEach(t),wer=i(X),I6=n(X,"LI",{});var qPe=s(I6);c2e=n(qPe,"STRONG",{});var E8t=s(c2e);Aer=r(E8t,"xlm"),E8t.forEach(t),Ler=r(qPe," \u2014 "),tQ=n(qPe,"A",{href:!0});var C8t=s(tQ);yer=r(C8t,"XLMForQuestionAnsweringSimple"),C8t.forEach(t),xer=r(qPe," (XLM model)"),qPe.forEach(t),$er=i(X),N6=n(X,"LI",{});var jPe=s(N6);f2e=n(jPe,"STRONG",{});var w8t=s(f2e);ker=r(w8t,"xlm-roberta"),w8t.forEach(t),Ser=r(jPe," \u2014 "),aQ=n(jPe,"A",{href:!0});var A8t=s(aQ);Rer=r(A8t,"XLMRobertaForQuestionAnswering"),A8t.forEach(t),Per=r(jPe," (XLM-RoBERTa model)"),jPe.forEach(t),Ber=i(X),q6=n(X,"LI",{});var DPe=s(q6);m2e=n(DPe,"STRONG",{});var L8t=s(m2e);Ier=r(L8t,"xlm-roberta-xl"),L8t.forEach(t),Ner=r(DPe," \u2014 "),nQ=n(DPe,"A",{href:!0});var y8t=s(nQ);qer=r(y8t,"XLMRobertaXLForQuestionAnswering"),y8t.forEach(t),jer=r(DPe," (XLM-RoBERTa-XL model)"),DPe.forEach(t),Der=i(X),j6=n(X,"LI",{});var GPe=s(j6);g2e=n(GPe,"STRONG",{});var x8t=s(g2e);Ger=r(x8t,"xlnet"),x8t.forEach(t),Oer=r(GPe," \u2014 "),sQ=n(GPe,"A",{href:!0});var $8t=s(sQ);Ver=r($8t,"XLNetForQuestionAnsweringSimple"),$8t.forEach(t),Xer=r(GPe," (XLNet model)"),GPe.forEach(t),zer=i(X),D6=n(X,"LI",{});var OPe=s(D6);h2e=n(OPe,"STRONG",{});var k8t=s(h2e);Qer=r(k8t,"yoso"),k8t.forEach(t),Wer=r(OPe," \u2014 "),lQ=n(OPe,"A",{href:!0});var S8t=s(lQ);Her=r(S8t,"YosoForQuestionAnswering"),S8t.forEach(t),Uer=r(OPe," (YOSO model)"),OPe.forEach(t),X.forEach(t),Jer=i(ha),G6=n(ha,"P",{});var VPe=s(G6);Yer=r(VPe,"The model is set in evaluation mode by default using "),p2e=n(VPe,"CODE",{});var R8t=s(p2e);Ker=r(R8t,"model.eval()"),R8t.forEach(t),Zer=r(VPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_2e=n(VPe,"CODE",{});var P8t=s(_2e);eor=r(P8t,"model.train()"),P8t.forEach(t),VPe.forEach(t),oor=i(ha),T(O6.$$.fragment,ha),ha.forEach(t),sl.forEach(t),$Oe=i(f),fd=n(f,"H2",{class:!0});var IXe=s(fd);V6=n(IXe,"A",{id:!0,class:!0,href:!0});var B8t=s(V6);u2e=n(B8t,"SPAN",{});var I8t=s(u2e);T(ey.$$.fragment,I8t),I8t.forEach(t),B8t.forEach(t),ror=i(IXe),b2e=n(IXe,"SPAN",{});var N8t=s(b2e);tor=r(N8t,"AutoModelForTableQuestionAnswering"),N8t.forEach(t),IXe.forEach(t),kOe=i(f),Do=n(f,"DIV",{class:!0});var ll=s(Do);T(oy.$$.fragment,ll),aor=i(ll),md=n(ll,"P",{});var Voe=s(md);nor=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),iQ=n(Voe,"A",{href:!0});var q8t=s(iQ);sor=r(q8t,"from_pretrained()"),q8t.forEach(t),lor=r(Voe," class method or the "),dQ=n(Voe,"A",{href:!0});var j8t=s(dQ);ior=r(j8t,"from_config()"),j8t.forEach(t),dor=r(Voe,` class
method.`),Voe.forEach(t),cor=i(ll),ry=n(ll,"P",{});var NXe=s(ry);mor=r(NXe,"This class cannot be instantiated directly using "),v2e=n(NXe,"CODE",{});var D8t=s(v2e);gor=r(D8t,"__init__()"),D8t.forEach(t),hor=r(NXe," (throws an error)."),NXe.forEach(t),por=i(ll),pt=n(ll,"DIV",{class:!0});var ew=s(pt);T(ty.$$.fragment,ew),_or=i(ew),F2e=n(ew,"P",{});var G8t=s(F2e);uor=r(G8t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),G8t.forEach(t),bor=i(ew),gd=n(ew,"P",{});var Xoe=s(gd);vor=r(Xoe,`Note:
Loading a model from its configuration file does `),T2e=n(Xoe,"STRONG",{});var O8t=s(T2e);For=r(O8t,"not"),O8t.forEach(t),Tor=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(Xoe,"A",{href:!0});var V8t=s(cQ);Mor=r(V8t,"from_pretrained()"),V8t.forEach(t),Eor=r(Xoe," to load the model weights."),Xoe.forEach(t),Cor=i(ew),T(X6.$$.fragment,ew),ew.forEach(t),wor=i(ll),so=n(ll,"DIV",{class:!0});var pa=s(so);T(ay.$$.fragment,pa),Aor=i(pa),M2e=n(pa,"P",{});var X8t=s(M2e);Lor=r(X8t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),X8t.forEach(t),yor=i(pa),Va=n(pa,"P",{});var ow=s(Va);xor=r(ow,"The model class to instantiate is selected based on the "),E2e=n(ow,"CODE",{});var z8t=s(E2e);$or=r(z8t,"model_type"),z8t.forEach(t),kor=r(ow,` property of the config object (either
passed as an argument or loaded from `),C2e=n(ow,"CODE",{});var Q8t=s(C2e);Sor=r(Q8t,"pretrained_model_name_or_path"),Q8t.forEach(t),Ror=r(ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w2e=n(ow,"CODE",{});var W8t=s(w2e);Por=r(W8t,"pretrained_model_name_or_path"),W8t.forEach(t),Bor=r(ow,":"),ow.forEach(t),Ior=i(pa),A2e=n(pa,"UL",{});var H8t=s(A2e);z6=n(H8t,"LI",{});var XPe=s(z6);L2e=n(XPe,"STRONG",{});var U8t=s(L2e);Nor=r(U8t,"tapas"),U8t.forEach(t),qor=r(XPe," \u2014 "),fQ=n(XPe,"A",{href:!0});var J8t=s(fQ);jor=r(J8t,"TapasForQuestionAnswering"),J8t.forEach(t),Dor=r(XPe," (TAPAS model)"),XPe.forEach(t),H8t.forEach(t),Gor=i(pa),Q6=n(pa,"P",{});var zPe=s(Q6);Oor=r(zPe,"The model is set in evaluation mode by default using "),y2e=n(zPe,"CODE",{});var Y8t=s(y2e);Vor=r(Y8t,"model.eval()"),Y8t.forEach(t),Xor=r(zPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x2e=n(zPe,"CODE",{});var K8t=s(x2e);zor=r(K8t,"model.train()"),K8t.forEach(t),zPe.forEach(t),Qor=i(pa),T(W6.$$.fragment,pa),pa.forEach(t),ll.forEach(t),SOe=i(f),hd=n(f,"H2",{class:!0});var qXe=s(hd);H6=n(qXe,"A",{id:!0,class:!0,href:!0});var Z8t=s(H6);$2e=n(Z8t,"SPAN",{});var eMt=s($2e);T(ny.$$.fragment,eMt),eMt.forEach(t),Z8t.forEach(t),Wor=i(qXe),k2e=n(qXe,"SPAN",{});var oMt=s(k2e);Hor=r(oMt,"AutoModelForImageClassification"),oMt.forEach(t),qXe.forEach(t),ROe=i(f),Go=n(f,"DIV",{class:!0});var il=s(Go);T(sy.$$.fragment,il),Uor=i(il),pd=n(il,"P",{});var zoe=s(pd);Jor=r(zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),mQ=n(zoe,"A",{href:!0});var rMt=s(mQ);Yor=r(rMt,"from_pretrained()"),rMt.forEach(t),Kor=r(zoe," class method or the "),gQ=n(zoe,"A",{href:!0});var tMt=s(gQ);Zor=r(tMt,"from_config()"),tMt.forEach(t),err=r(zoe,` class
method.`),zoe.forEach(t),orr=i(il),ly=n(il,"P",{});var jXe=s(ly);rrr=r(jXe,"This class cannot be instantiated directly using "),S2e=n(jXe,"CODE",{});var aMt=s(S2e);trr=r(aMt,"__init__()"),aMt.forEach(t),arr=r(jXe," (throws an error)."),jXe.forEach(t),nrr=i(il),_t=n(il,"DIV",{class:!0});var rw=s(_t);T(iy.$$.fragment,rw),srr=i(rw),R2e=n(rw,"P",{});var nMt=s(R2e);lrr=r(nMt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),nMt.forEach(t),irr=i(rw),_d=n(rw,"P",{});var Qoe=s(_d);drr=r(Qoe,`Note:
Loading a model from its configuration file does `),P2e=n(Qoe,"STRONG",{});var sMt=s(P2e);crr=r(sMt,"not"),sMt.forEach(t),frr=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),hQ=n(Qoe,"A",{href:!0});var lMt=s(hQ);mrr=r(lMt,"from_pretrained()"),lMt.forEach(t),grr=r(Qoe," to load the model weights."),Qoe.forEach(t),hrr=i(rw),T(U6.$$.fragment,rw),rw.forEach(t),prr=i(il),lo=n(il,"DIV",{class:!0});var _a=s(lo);T(dy.$$.fragment,_a),_rr=i(_a),B2e=n(_a,"P",{});var iMt=s(B2e);urr=r(iMt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),iMt.forEach(t),brr=i(_a),Xa=n(_a,"P",{});var tw=s(Xa);vrr=r(tw,"The model class to instantiate is selected based on the "),I2e=n(tw,"CODE",{});var dMt=s(I2e);Frr=r(dMt,"model_type"),dMt.forEach(t),Trr=r(tw,` property of the config object (either
passed as an argument or loaded from `),N2e=n(tw,"CODE",{});var cMt=s(N2e);Mrr=r(cMt,"pretrained_model_name_or_path"),cMt.forEach(t),Err=r(tw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q2e=n(tw,"CODE",{});var fMt=s(q2e);Crr=r(fMt,"pretrained_model_name_or_path"),fMt.forEach(t),wrr=r(tw,":"),tw.forEach(t),Arr=i(_a),Fe=n(_a,"UL",{});var Te=s(Fe);J6=n(Te,"LI",{});var QPe=s(J6);j2e=n(QPe,"STRONG",{});var mMt=s(j2e);Lrr=r(mMt,"beit"),mMt.forEach(t),yrr=r(QPe," \u2014 "),pQ=n(QPe,"A",{href:!0});var gMt=s(pQ);xrr=r(gMt,"BeitForImageClassification"),gMt.forEach(t),$rr=r(QPe," (BEiT model)"),QPe.forEach(t),krr=i(Te),Y6=n(Te,"LI",{});var WPe=s(Y6);D2e=n(WPe,"STRONG",{});var hMt=s(D2e);Srr=r(hMt,"convnext"),hMt.forEach(t),Rrr=r(WPe," \u2014 "),_Q=n(WPe,"A",{href:!0});var pMt=s(_Q);Prr=r(pMt,"ConvNextForImageClassification"),pMt.forEach(t),Brr=r(WPe," (ConvNeXT model)"),WPe.forEach(t),Irr=i(Te),K6=n(Te,"LI",{});var HPe=s(K6);G2e=n(HPe,"STRONG",{});var _Mt=s(G2e);Nrr=r(_Mt,"cvt"),_Mt.forEach(t),qrr=r(HPe," \u2014 "),uQ=n(HPe,"A",{href:!0});var uMt=s(uQ);jrr=r(uMt,"CvtForImageClassification"),uMt.forEach(t),Drr=r(HPe," (CvT model)"),HPe.forEach(t),Grr=i(Te),Z6=n(Te,"LI",{});var UPe=s(Z6);O2e=n(UPe,"STRONG",{});var bMt=s(O2e);Orr=r(bMt,"data2vec-vision"),bMt.forEach(t),Vrr=r(UPe," \u2014 "),bQ=n(UPe,"A",{href:!0});var vMt=s(bQ);Xrr=r(vMt,"Data2VecVisionForImageClassification"),vMt.forEach(t),zrr=r(UPe," (Data2VecVision model)"),UPe.forEach(t),Qrr=i(Te),Xs=n(Te,"LI",{});var rS=s(Xs);V2e=n(rS,"STRONG",{});var FMt=s(V2e);Wrr=r(FMt,"deit"),FMt.forEach(t),Hrr=r(rS," \u2014 "),vQ=n(rS,"A",{href:!0});var TMt=s(vQ);Urr=r(TMt,"DeiTForImageClassification"),TMt.forEach(t),Jrr=r(rS," or "),FQ=n(rS,"A",{href:!0});var MMt=s(FQ);Yrr=r(MMt,"DeiTForImageClassificationWithTeacher"),MMt.forEach(t),Krr=r(rS," (DeiT model)"),rS.forEach(t),Zrr=i(Te),eT=n(Te,"LI",{});var JPe=s(eT);X2e=n(JPe,"STRONG",{});var EMt=s(X2e);etr=r(EMt,"imagegpt"),EMt.forEach(t),otr=r(JPe," \u2014 "),TQ=n(JPe,"A",{href:!0});var CMt=s(TQ);rtr=r(CMt,"ImageGPTForImageClassification"),CMt.forEach(t),ttr=r(JPe," (ImageGPT model)"),JPe.forEach(t),atr=i(Te),zs=n(Te,"LI",{});var tS=s(zs);z2e=n(tS,"STRONG",{});var wMt=s(z2e);ntr=r(wMt,"levit"),wMt.forEach(t),str=r(tS," \u2014 "),MQ=n(tS,"A",{href:!0});var AMt=s(MQ);ltr=r(AMt,"LevitForImageClassification"),AMt.forEach(t),itr=r(tS," or "),EQ=n(tS,"A",{href:!0});var LMt=s(EQ);dtr=r(LMt,"LevitForImageClassificationWithTeacher"),LMt.forEach(t),ctr=r(tS," (LeViT model)"),tS.forEach(t),ftr=i(Te),ut=n(Te,"LI",{});var Lf=s(ut);Q2e=n(Lf,"STRONG",{});var yMt=s(Q2e);mtr=r(yMt,"perceiver"),yMt.forEach(t),gtr=r(Lf," \u2014 "),CQ=n(Lf,"A",{href:!0});var xMt=s(CQ);htr=r(xMt,"PerceiverForImageClassificationLearned"),xMt.forEach(t),ptr=r(Lf," or "),wQ=n(Lf,"A",{href:!0});var $Mt=s(wQ);_tr=r($Mt,"PerceiverForImageClassificationFourier"),$Mt.forEach(t),utr=r(Lf," or "),AQ=n(Lf,"A",{href:!0});var kMt=s(AQ);btr=r(kMt,"PerceiverForImageClassificationConvProcessing"),kMt.forEach(t),vtr=r(Lf," (Perceiver model)"),Lf.forEach(t),Ftr=i(Te),oT=n(Te,"LI",{});var YPe=s(oT);W2e=n(YPe,"STRONG",{});var SMt=s(W2e);Ttr=r(SMt,"poolformer"),SMt.forEach(t),Mtr=r(YPe," \u2014 "),LQ=n(YPe,"A",{href:!0});var RMt=s(LQ);Etr=r(RMt,"PoolFormerForImageClassification"),RMt.forEach(t),Ctr=r(YPe," (PoolFormer model)"),YPe.forEach(t),wtr=i(Te),rT=n(Te,"LI",{});var KPe=s(rT);H2e=n(KPe,"STRONG",{});var PMt=s(H2e);Atr=r(PMt,"regnet"),PMt.forEach(t),Ltr=r(KPe," \u2014 "),yQ=n(KPe,"A",{href:!0});var BMt=s(yQ);ytr=r(BMt,"RegNetForImageClassification"),BMt.forEach(t),xtr=r(KPe," (RegNet model)"),KPe.forEach(t),$tr=i(Te),tT=n(Te,"LI",{});var ZPe=s(tT);U2e=n(ZPe,"STRONG",{});var IMt=s(U2e);ktr=r(IMt,"resnet"),IMt.forEach(t),Str=r(ZPe," \u2014 "),xQ=n(ZPe,"A",{href:!0});var NMt=s(xQ);Rtr=r(NMt,"ResNetForImageClassification"),NMt.forEach(t),Ptr=r(ZPe," (ResNet model)"),ZPe.forEach(t),Btr=i(Te),aT=n(Te,"LI",{});var eBe=s(aT);J2e=n(eBe,"STRONG",{});var qMt=s(J2e);Itr=r(qMt,"segformer"),qMt.forEach(t),Ntr=r(eBe," \u2014 "),$Q=n(eBe,"A",{href:!0});var jMt=s($Q);qtr=r(jMt,"SegformerForImageClassification"),jMt.forEach(t),jtr=r(eBe," (SegFormer model)"),eBe.forEach(t),Dtr=i(Te),nT=n(Te,"LI",{});var oBe=s(nT);Y2e=n(oBe,"STRONG",{});var DMt=s(Y2e);Gtr=r(DMt,"swin"),DMt.forEach(t),Otr=r(oBe," \u2014 "),kQ=n(oBe,"A",{href:!0});var GMt=s(kQ);Vtr=r(GMt,"SwinForImageClassification"),GMt.forEach(t),Xtr=r(oBe," (Swin Transformer model)"),oBe.forEach(t),ztr=i(Te),sT=n(Te,"LI",{});var rBe=s(sT);K2e=n(rBe,"STRONG",{});var OMt=s(K2e);Qtr=r(OMt,"van"),OMt.forEach(t),Wtr=r(rBe," \u2014 "),SQ=n(rBe,"A",{href:!0});var VMt=s(SQ);Htr=r(VMt,"VanForImageClassification"),VMt.forEach(t),Utr=r(rBe," (VAN model)"),rBe.forEach(t),Jtr=i(Te),lT=n(Te,"LI",{});var tBe=s(lT);Z2e=n(tBe,"STRONG",{});var XMt=s(Z2e);Ytr=r(XMt,"vit"),XMt.forEach(t),Ktr=r(tBe," \u2014 "),RQ=n(tBe,"A",{href:!0});var zMt=s(RQ);Ztr=r(zMt,"ViTForImageClassification"),zMt.forEach(t),ear=r(tBe," (ViT model)"),tBe.forEach(t),Te.forEach(t),oar=i(_a),iT=n(_a,"P",{});var aBe=s(iT);rar=r(aBe,"The model is set in evaluation mode by default using "),e1e=n(aBe,"CODE",{});var QMt=s(e1e);tar=r(QMt,"model.eval()"),QMt.forEach(t),aar=r(aBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o1e=n(aBe,"CODE",{});var WMt=s(o1e);nar=r(WMt,"model.train()"),WMt.forEach(t),aBe.forEach(t),sar=i(_a),T(dT.$$.fragment,_a),_a.forEach(t),il.forEach(t),POe=i(f),ud=n(f,"H2",{class:!0});var DXe=s(ud);cT=n(DXe,"A",{id:!0,class:!0,href:!0});var HMt=s(cT);r1e=n(HMt,"SPAN",{});var UMt=s(r1e);T(cy.$$.fragment,UMt),UMt.forEach(t),HMt.forEach(t),lar=i(DXe),t1e=n(DXe,"SPAN",{});var JMt=s(t1e);iar=r(JMt,"AutoModelForVision2Seq"),JMt.forEach(t),DXe.forEach(t),BOe=i(f),Oo=n(f,"DIV",{class:!0});var dl=s(Oo);T(fy.$$.fragment,dl),dar=i(dl),bd=n(dl,"P",{});var Woe=s(bd);car=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),PQ=n(Woe,"A",{href:!0});var YMt=s(PQ);far=r(YMt,"from_pretrained()"),YMt.forEach(t),mar=r(Woe," class method or the "),BQ=n(Woe,"A",{href:!0});var KMt=s(BQ);gar=r(KMt,"from_config()"),KMt.forEach(t),har=r(Woe,` class
method.`),Woe.forEach(t),par=i(dl),my=n(dl,"P",{});var GXe=s(my);_ar=r(GXe,"This class cannot be instantiated directly using "),a1e=n(GXe,"CODE",{});var ZMt=s(a1e);uar=r(ZMt,"__init__()"),ZMt.forEach(t),bar=r(GXe," (throws an error)."),GXe.forEach(t),Far=i(dl),bt=n(dl,"DIV",{class:!0});var aw=s(bt);T(gy.$$.fragment,aw),Tar=i(aw),n1e=n(aw,"P",{});var eEt=s(n1e);Mar=r(eEt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),eEt.forEach(t),Ear=i(aw),vd=n(aw,"P",{});var Hoe=s(vd);Car=r(Hoe,`Note:
Loading a model from its configuration file does `),s1e=n(Hoe,"STRONG",{});var oEt=s(s1e);war=r(oEt,"not"),oEt.forEach(t),Aar=r(Hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(Hoe,"A",{href:!0});var rEt=s(IQ);Lar=r(rEt,"from_pretrained()"),rEt.forEach(t),yar=r(Hoe," to load the model weights."),Hoe.forEach(t),xar=i(aw),T(fT.$$.fragment,aw),aw.forEach(t),$ar=i(dl),io=n(dl,"DIV",{class:!0});var ua=s(io);T(hy.$$.fragment,ua),kar=i(ua),l1e=n(ua,"P",{});var tEt=s(l1e);Sar=r(tEt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),tEt.forEach(t),Rar=i(ua),za=n(ua,"P",{});var nw=s(za);Par=r(nw,"The model class to instantiate is selected based on the "),i1e=n(nw,"CODE",{});var aEt=s(i1e);Bar=r(aEt,"model_type"),aEt.forEach(t),Iar=r(nw,` property of the config object (either
passed as an argument or loaded from `),d1e=n(nw,"CODE",{});var nEt=s(d1e);Nar=r(nEt,"pretrained_model_name_or_path"),nEt.forEach(t),qar=r(nw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c1e=n(nw,"CODE",{});var sEt=s(c1e);jar=r(sEt,"pretrained_model_name_or_path"),sEt.forEach(t),Dar=r(nw,":"),nw.forEach(t),Gar=i(ua),f1e=n(ua,"UL",{});var lEt=s(f1e);mT=n(lEt,"LI",{});var nBe=s(mT);m1e=n(nBe,"STRONG",{});var iEt=s(m1e);Oar=r(iEt,"vision-encoder-decoder"),iEt.forEach(t),Var=r(nBe," \u2014 "),NQ=n(nBe,"A",{href:!0});var dEt=s(NQ);Xar=r(dEt,"VisionEncoderDecoderModel"),dEt.forEach(t),zar=r(nBe," (Vision Encoder decoder model)"),nBe.forEach(t),lEt.forEach(t),Qar=i(ua),gT=n(ua,"P",{});var sBe=s(gT);War=r(sBe,"The model is set in evaluation mode by default using "),g1e=n(sBe,"CODE",{});var cEt=s(g1e);Har=r(cEt,"model.eval()"),cEt.forEach(t),Uar=r(sBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=n(sBe,"CODE",{});var fEt=s(h1e);Jar=r(fEt,"model.train()"),fEt.forEach(t),sBe.forEach(t),Yar=i(ua),T(hT.$$.fragment,ua),ua.forEach(t),dl.forEach(t),IOe=i(f),Fd=n(f,"H2",{class:!0});var OXe=s(Fd);pT=n(OXe,"A",{id:!0,class:!0,href:!0});var mEt=s(pT);p1e=n(mEt,"SPAN",{});var gEt=s(p1e);T(py.$$.fragment,gEt),gEt.forEach(t),mEt.forEach(t),Kar=i(OXe),_1e=n(OXe,"SPAN",{});var hEt=s(_1e);Zar=r(hEt,"AutoModelForVisualQuestionAnswering"),hEt.forEach(t),OXe.forEach(t),NOe=i(f),Vo=n(f,"DIV",{class:!0});var cl=s(Vo);T(_y.$$.fragment,cl),enr=i(cl),Td=n(cl,"P",{});var Uoe=s(Td);onr=r(Uoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),qQ=n(Uoe,"A",{href:!0});var pEt=s(qQ);rnr=r(pEt,"from_pretrained()"),pEt.forEach(t),tnr=r(Uoe," class method or the "),jQ=n(Uoe,"A",{href:!0});var _Et=s(jQ);anr=r(_Et,"from_config()"),_Et.forEach(t),nnr=r(Uoe,` class
method.`),Uoe.forEach(t),snr=i(cl),uy=n(cl,"P",{});var VXe=s(uy);lnr=r(VXe,"This class cannot be instantiated directly using "),u1e=n(VXe,"CODE",{});var uEt=s(u1e);inr=r(uEt,"__init__()"),uEt.forEach(t),dnr=r(VXe," (throws an error)."),VXe.forEach(t),cnr=i(cl),vt=n(cl,"DIV",{class:!0});var sw=s(vt);T(by.$$.fragment,sw),fnr=i(sw),b1e=n(sw,"P",{});var bEt=s(b1e);mnr=r(bEt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),bEt.forEach(t),gnr=i(sw),Md=n(sw,"P",{});var Joe=s(Md);hnr=r(Joe,`Note:
Loading a model from its configuration file does `),v1e=n(Joe,"STRONG",{});var vEt=s(v1e);pnr=r(vEt,"not"),vEt.forEach(t),_nr=r(Joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Joe,"A",{href:!0});var FEt=s(DQ);unr=r(FEt,"from_pretrained()"),FEt.forEach(t),bnr=r(Joe," to load the model weights."),Joe.forEach(t),vnr=i(sw),T(_T.$$.fragment,sw),sw.forEach(t),Fnr=i(cl),co=n(cl,"DIV",{class:!0});var ba=s(co);T(vy.$$.fragment,ba),Tnr=i(ba),F1e=n(ba,"P",{});var TEt=s(F1e);Mnr=r(TEt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),TEt.forEach(t),Enr=i(ba),Qa=n(ba,"P",{});var lw=s(Qa);Cnr=r(lw,"The model class to instantiate is selected based on the "),T1e=n(lw,"CODE",{});var MEt=s(T1e);wnr=r(MEt,"model_type"),MEt.forEach(t),Anr=r(lw,` property of the config object (either
passed as an argument or loaded from `),M1e=n(lw,"CODE",{});var EEt=s(M1e);Lnr=r(EEt,"pretrained_model_name_or_path"),EEt.forEach(t),ynr=r(lw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=n(lw,"CODE",{});var CEt=s(E1e);xnr=r(CEt,"pretrained_model_name_or_path"),CEt.forEach(t),$nr=r(lw,":"),lw.forEach(t),knr=i(ba),C1e=n(ba,"UL",{});var wEt=s(C1e);uT=n(wEt,"LI",{});var lBe=s(uT);w1e=n(lBe,"STRONG",{});var AEt=s(w1e);Snr=r(AEt,"vilt"),AEt.forEach(t),Rnr=r(lBe," \u2014 "),GQ=n(lBe,"A",{href:!0});var LEt=s(GQ);Pnr=r(LEt,"ViltForQuestionAnswering"),LEt.forEach(t),Bnr=r(lBe," (ViLT model)"),lBe.forEach(t),wEt.forEach(t),Inr=i(ba),bT=n(ba,"P",{});var iBe=s(bT);Nnr=r(iBe,"The model is set in evaluation mode by default using "),A1e=n(iBe,"CODE",{});var yEt=s(A1e);qnr=r(yEt,"model.eval()"),yEt.forEach(t),jnr=r(iBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L1e=n(iBe,"CODE",{});var xEt=s(L1e);Dnr=r(xEt,"model.train()"),xEt.forEach(t),iBe.forEach(t),Gnr=i(ba),T(vT.$$.fragment,ba),ba.forEach(t),cl.forEach(t),qOe=i(f),Ed=n(f,"H2",{class:!0});var XXe=s(Ed);FT=n(XXe,"A",{id:!0,class:!0,href:!0});var $Et=s(FT);y1e=n($Et,"SPAN",{});var kEt=s(y1e);T(Fy.$$.fragment,kEt),kEt.forEach(t),$Et.forEach(t),Onr=i(XXe),x1e=n(XXe,"SPAN",{});var SEt=s(x1e);Vnr=r(SEt,"AutoModelForAudioClassification"),SEt.forEach(t),XXe.forEach(t),jOe=i(f),Xo=n(f,"DIV",{class:!0});var fl=s(Xo);T(Ty.$$.fragment,fl),Xnr=i(fl),Cd=n(fl,"P",{});var Yoe=s(Cd);znr=r(Yoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),OQ=n(Yoe,"A",{href:!0});var REt=s(OQ);Qnr=r(REt,"from_pretrained()"),REt.forEach(t),Wnr=r(Yoe," class method or the "),VQ=n(Yoe,"A",{href:!0});var PEt=s(VQ);Hnr=r(PEt,"from_config()"),PEt.forEach(t),Unr=r(Yoe,` class
method.`),Yoe.forEach(t),Jnr=i(fl),My=n(fl,"P",{});var zXe=s(My);Ynr=r(zXe,"This class cannot be instantiated directly using "),$1e=n(zXe,"CODE",{});var BEt=s($1e);Knr=r(BEt,"__init__()"),BEt.forEach(t),Znr=r(zXe," (throws an error)."),zXe.forEach(t),esr=i(fl),Ft=n(fl,"DIV",{class:!0});var iw=s(Ft);T(Ey.$$.fragment,iw),osr=i(iw),k1e=n(iw,"P",{});var IEt=s(k1e);rsr=r(IEt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),IEt.forEach(t),tsr=i(iw),wd=n(iw,"P",{});var Koe=s(wd);asr=r(Koe,`Note:
Loading a model from its configuration file does `),S1e=n(Koe,"STRONG",{});var NEt=s(S1e);nsr=r(NEt,"not"),NEt.forEach(t),ssr=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),XQ=n(Koe,"A",{href:!0});var qEt=s(XQ);lsr=r(qEt,"from_pretrained()"),qEt.forEach(t),isr=r(Koe," to load the model weights."),Koe.forEach(t),dsr=i(iw),T(TT.$$.fragment,iw),iw.forEach(t),csr=i(fl),fo=n(fl,"DIV",{class:!0});var va=s(fo);T(Cy.$$.fragment,va),fsr=i(va),R1e=n(va,"P",{});var jEt=s(R1e);msr=r(jEt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),jEt.forEach(t),gsr=i(va),Wa=n(va,"P",{});var dw=s(Wa);hsr=r(dw,"The model class to instantiate is selected based on the "),P1e=n(dw,"CODE",{});var DEt=s(P1e);psr=r(DEt,"model_type"),DEt.forEach(t),_sr=r(dw,` property of the config object (either
passed as an argument or loaded from `),B1e=n(dw,"CODE",{});var GEt=s(B1e);usr=r(GEt,"pretrained_model_name_or_path"),GEt.forEach(t),bsr=r(dw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=n(dw,"CODE",{});var OEt=s(I1e);vsr=r(OEt,"pretrained_model_name_or_path"),OEt.forEach(t),Fsr=r(dw,":"),dw.forEach(t),Tsr=i(va),Pe=n(va,"UL",{});var ze=s(Pe);MT=n(ze,"LI",{});var dBe=s(MT);N1e=n(dBe,"STRONG",{});var VEt=s(N1e);Msr=r(VEt,"data2vec-audio"),VEt.forEach(t),Esr=r(dBe," \u2014 "),zQ=n(dBe,"A",{href:!0});var XEt=s(zQ);Csr=r(XEt,"Data2VecAudioForSequenceClassification"),XEt.forEach(t),wsr=r(dBe," (Data2VecAudio model)"),dBe.forEach(t),Asr=i(ze),ET=n(ze,"LI",{});var cBe=s(ET);q1e=n(cBe,"STRONG",{});var zEt=s(q1e);Lsr=r(zEt,"hubert"),zEt.forEach(t),ysr=r(cBe," \u2014 "),QQ=n(cBe,"A",{href:!0});var QEt=s(QQ);xsr=r(QEt,"HubertForSequenceClassification"),QEt.forEach(t),$sr=r(cBe," (Hubert model)"),cBe.forEach(t),ksr=i(ze),CT=n(ze,"LI",{});var fBe=s(CT);j1e=n(fBe,"STRONG",{});var WEt=s(j1e);Ssr=r(WEt,"sew"),WEt.forEach(t),Rsr=r(fBe," \u2014 "),WQ=n(fBe,"A",{href:!0});var HEt=s(WQ);Psr=r(HEt,"SEWForSequenceClassification"),HEt.forEach(t),Bsr=r(fBe," (SEW model)"),fBe.forEach(t),Isr=i(ze),wT=n(ze,"LI",{});var mBe=s(wT);D1e=n(mBe,"STRONG",{});var UEt=s(D1e);Nsr=r(UEt,"sew-d"),UEt.forEach(t),qsr=r(mBe," \u2014 "),HQ=n(mBe,"A",{href:!0});var JEt=s(HQ);jsr=r(JEt,"SEWDForSequenceClassification"),JEt.forEach(t),Dsr=r(mBe," (SEW-D model)"),mBe.forEach(t),Gsr=i(ze),AT=n(ze,"LI",{});var gBe=s(AT);G1e=n(gBe,"STRONG",{});var YEt=s(G1e);Osr=r(YEt,"unispeech"),YEt.forEach(t),Vsr=r(gBe," \u2014 "),UQ=n(gBe,"A",{href:!0});var KEt=s(UQ);Xsr=r(KEt,"UniSpeechForSequenceClassification"),KEt.forEach(t),zsr=r(gBe," (UniSpeech model)"),gBe.forEach(t),Qsr=i(ze),LT=n(ze,"LI",{});var hBe=s(LT);O1e=n(hBe,"STRONG",{});var ZEt=s(O1e);Wsr=r(ZEt,"unispeech-sat"),ZEt.forEach(t),Hsr=r(hBe," \u2014 "),JQ=n(hBe,"A",{href:!0});var e4t=s(JQ);Usr=r(e4t,"UniSpeechSatForSequenceClassification"),e4t.forEach(t),Jsr=r(hBe," (UniSpeechSat model)"),hBe.forEach(t),Ysr=i(ze),yT=n(ze,"LI",{});var pBe=s(yT);V1e=n(pBe,"STRONG",{});var o4t=s(V1e);Ksr=r(o4t,"wav2vec2"),o4t.forEach(t),Zsr=r(pBe," \u2014 "),YQ=n(pBe,"A",{href:!0});var r4t=s(YQ);elr=r(r4t,"Wav2Vec2ForSequenceClassification"),r4t.forEach(t),olr=r(pBe," (Wav2Vec2 model)"),pBe.forEach(t),rlr=i(ze),xT=n(ze,"LI",{});var _Be=s(xT);X1e=n(_Be,"STRONG",{});var t4t=s(X1e);tlr=r(t4t,"wav2vec2-conformer"),t4t.forEach(t),alr=r(_Be," \u2014 "),KQ=n(_Be,"A",{href:!0});var a4t=s(KQ);nlr=r(a4t,"Wav2Vec2ConformerForSequenceClassification"),a4t.forEach(t),slr=r(_Be," (Wav2Vec2-Conformer model)"),_Be.forEach(t),llr=i(ze),$T=n(ze,"LI",{});var uBe=s($T);z1e=n(uBe,"STRONG",{});var n4t=s(z1e);ilr=r(n4t,"wavlm"),n4t.forEach(t),dlr=r(uBe," \u2014 "),ZQ=n(uBe,"A",{href:!0});var s4t=s(ZQ);clr=r(s4t,"WavLMForSequenceClassification"),s4t.forEach(t),flr=r(uBe," (WavLM model)"),uBe.forEach(t),ze.forEach(t),mlr=i(va),kT=n(va,"P",{});var bBe=s(kT);glr=r(bBe,"The model is set in evaluation mode by default using "),Q1e=n(bBe,"CODE",{});var l4t=s(Q1e);hlr=r(l4t,"model.eval()"),l4t.forEach(t),plr=r(bBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W1e=n(bBe,"CODE",{});var i4t=s(W1e);_lr=r(i4t,"model.train()"),i4t.forEach(t),bBe.forEach(t),ulr=i(va),T(ST.$$.fragment,va),va.forEach(t),fl.forEach(t),DOe=i(f),Ad=n(f,"H2",{class:!0});var QXe=s(Ad);RT=n(QXe,"A",{id:!0,class:!0,href:!0});var d4t=s(RT);H1e=n(d4t,"SPAN",{});var c4t=s(H1e);T(wy.$$.fragment,c4t),c4t.forEach(t),d4t.forEach(t),blr=i(QXe),U1e=n(QXe,"SPAN",{});var f4t=s(U1e);vlr=r(f4t,"AutoModelForAudioFrameClassification"),f4t.forEach(t),QXe.forEach(t),GOe=i(f),zo=n(f,"DIV",{class:!0});var ml=s(zo);T(Ay.$$.fragment,ml),Flr=i(ml),Ld=n(ml,"P",{});var Zoe=s(Ld);Tlr=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),eW=n(Zoe,"A",{href:!0});var m4t=s(eW);Mlr=r(m4t,"from_pretrained()"),m4t.forEach(t),Elr=r(Zoe," class method or the "),oW=n(Zoe,"A",{href:!0});var g4t=s(oW);Clr=r(g4t,"from_config()"),g4t.forEach(t),wlr=r(Zoe,` class
method.`),Zoe.forEach(t),Alr=i(ml),Ly=n(ml,"P",{});var WXe=s(Ly);Llr=r(WXe,"This class cannot be instantiated directly using "),J1e=n(WXe,"CODE",{});var h4t=s(J1e);ylr=r(h4t,"__init__()"),h4t.forEach(t),xlr=r(WXe," (throws an error)."),WXe.forEach(t),$lr=i(ml),Tt=n(ml,"DIV",{class:!0});var cw=s(Tt);T(yy.$$.fragment,cw),klr=i(cw),Y1e=n(cw,"P",{});var p4t=s(Y1e);Slr=r(p4t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),p4t.forEach(t),Rlr=i(cw),yd=n(cw,"P",{});var ere=s(yd);Plr=r(ere,`Note:
Loading a model from its configuration file does `),K1e=n(ere,"STRONG",{});var _4t=s(K1e);Blr=r(_4t,"not"),_4t.forEach(t),Ilr=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=n(ere,"A",{href:!0});var u4t=s(rW);Nlr=r(u4t,"from_pretrained()"),u4t.forEach(t),qlr=r(ere," to load the model weights."),ere.forEach(t),jlr=i(cw),T(PT.$$.fragment,cw),cw.forEach(t),Dlr=i(ml),mo=n(ml,"DIV",{class:!0});var Fa=s(mo);T(xy.$$.fragment,Fa),Glr=i(Fa),Z1e=n(Fa,"P",{});var b4t=s(Z1e);Olr=r(b4t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),b4t.forEach(t),Vlr=i(Fa),Ha=n(Fa,"P",{});var fw=s(Ha);Xlr=r(fw,"The model class to instantiate is selected based on the "),ebe=n(fw,"CODE",{});var v4t=s(ebe);zlr=r(v4t,"model_type"),v4t.forEach(t),Qlr=r(fw,` property of the config object (either
passed as an argument or loaded from `),obe=n(fw,"CODE",{});var F4t=s(obe);Wlr=r(F4t,"pretrained_model_name_or_path"),F4t.forEach(t),Hlr=r(fw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rbe=n(fw,"CODE",{});var T4t=s(rbe);Ulr=r(T4t,"pretrained_model_name_or_path"),T4t.forEach(t),Jlr=r(fw,":"),fw.forEach(t),Ylr=i(Fa),et=n(Fa,"UL",{});var gl=s(et);BT=n(gl,"LI",{});var vBe=s(BT);tbe=n(vBe,"STRONG",{});var M4t=s(tbe);Klr=r(M4t,"data2vec-audio"),M4t.forEach(t),Zlr=r(vBe," \u2014 "),tW=n(vBe,"A",{href:!0});var E4t=s(tW);eir=r(E4t,"Data2VecAudioForAudioFrameClassification"),E4t.forEach(t),oir=r(vBe," (Data2VecAudio model)"),vBe.forEach(t),rir=i(gl),IT=n(gl,"LI",{});var FBe=s(IT);abe=n(FBe,"STRONG",{});var C4t=s(abe);tir=r(C4t,"unispeech-sat"),C4t.forEach(t),air=r(FBe," \u2014 "),aW=n(FBe,"A",{href:!0});var w4t=s(aW);nir=r(w4t,"UniSpeechSatForAudioFrameClassification"),w4t.forEach(t),sir=r(FBe," (UniSpeechSat model)"),FBe.forEach(t),lir=i(gl),NT=n(gl,"LI",{});var TBe=s(NT);nbe=n(TBe,"STRONG",{});var A4t=s(nbe);iir=r(A4t,"wav2vec2"),A4t.forEach(t),dir=r(TBe," \u2014 "),nW=n(TBe,"A",{href:!0});var L4t=s(nW);cir=r(L4t,"Wav2Vec2ForAudioFrameClassification"),L4t.forEach(t),fir=r(TBe," (Wav2Vec2 model)"),TBe.forEach(t),mir=i(gl),qT=n(gl,"LI",{});var MBe=s(qT);sbe=n(MBe,"STRONG",{});var y4t=s(sbe);gir=r(y4t,"wav2vec2-conformer"),y4t.forEach(t),hir=r(MBe," \u2014 "),sW=n(MBe,"A",{href:!0});var x4t=s(sW);pir=r(x4t,"Wav2Vec2ConformerForAudioFrameClassification"),x4t.forEach(t),_ir=r(MBe," (Wav2Vec2-Conformer model)"),MBe.forEach(t),uir=i(gl),jT=n(gl,"LI",{});var EBe=s(jT);lbe=n(EBe,"STRONG",{});var $4t=s(lbe);bir=r($4t,"wavlm"),$4t.forEach(t),vir=r(EBe," \u2014 "),lW=n(EBe,"A",{href:!0});var k4t=s(lW);Fir=r(k4t,"WavLMForAudioFrameClassification"),k4t.forEach(t),Tir=r(EBe," (WavLM model)"),EBe.forEach(t),gl.forEach(t),Mir=i(Fa),DT=n(Fa,"P",{});var CBe=s(DT);Eir=r(CBe,"The model is set in evaluation mode by default using "),ibe=n(CBe,"CODE",{});var S4t=s(ibe);Cir=r(S4t,"model.eval()"),S4t.forEach(t),wir=r(CBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dbe=n(CBe,"CODE",{});var R4t=s(dbe);Air=r(R4t,"model.train()"),R4t.forEach(t),CBe.forEach(t),Lir=i(Fa),T(GT.$$.fragment,Fa),Fa.forEach(t),ml.forEach(t),OOe=i(f),xd=n(f,"H2",{class:!0});var HXe=s(xd);OT=n(HXe,"A",{id:!0,class:!0,href:!0});var P4t=s(OT);cbe=n(P4t,"SPAN",{});var B4t=s(cbe);T($y.$$.fragment,B4t),B4t.forEach(t),P4t.forEach(t),yir=i(HXe),fbe=n(HXe,"SPAN",{});var I4t=s(fbe);xir=r(I4t,"AutoModelForCTC"),I4t.forEach(t),HXe.forEach(t),VOe=i(f),Qo=n(f,"DIV",{class:!0});var hl=s(Qo);T(ky.$$.fragment,hl),$ir=i(hl),$d=n(hl,"P",{});var ore=s($d);kir=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),iW=n(ore,"A",{href:!0});var N4t=s(iW);Sir=r(N4t,"from_pretrained()"),N4t.forEach(t),Rir=r(ore," class method or the "),dW=n(ore,"A",{href:!0});var q4t=s(dW);Pir=r(q4t,"from_config()"),q4t.forEach(t),Bir=r(ore,` class
method.`),ore.forEach(t),Iir=i(hl),Sy=n(hl,"P",{});var UXe=s(Sy);Nir=r(UXe,"This class cannot be instantiated directly using "),mbe=n(UXe,"CODE",{});var j4t=s(mbe);qir=r(j4t,"__init__()"),j4t.forEach(t),jir=r(UXe," (throws an error)."),UXe.forEach(t),Dir=i(hl),Mt=n(hl,"DIV",{class:!0});var mw=s(Mt);T(Ry.$$.fragment,mw),Gir=i(mw),gbe=n(mw,"P",{});var D4t=s(gbe);Oir=r(D4t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),D4t.forEach(t),Vir=i(mw),kd=n(mw,"P",{});var rre=s(kd);Xir=r(rre,`Note:
Loading a model from its configuration file does `),hbe=n(rre,"STRONG",{});var G4t=s(hbe);zir=r(G4t,"not"),G4t.forEach(t),Qir=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),cW=n(rre,"A",{href:!0});var O4t=s(cW);Wir=r(O4t,"from_pretrained()"),O4t.forEach(t),Hir=r(rre," to load the model weights."),rre.forEach(t),Uir=i(mw),T(VT.$$.fragment,mw),mw.forEach(t),Jir=i(hl),go=n(hl,"DIV",{class:!0});var Ta=s(go);T(Py.$$.fragment,Ta),Yir=i(Ta),pbe=n(Ta,"P",{});var V4t=s(pbe);Kir=r(V4t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),V4t.forEach(t),Zir=i(Ta),Ua=n(Ta,"P",{});var gw=s(Ua);edr=r(gw,"The model class to instantiate is selected based on the "),_be=n(gw,"CODE",{});var X4t=s(_be);odr=r(X4t,"model_type"),X4t.forEach(t),rdr=r(gw,` property of the config object (either
passed as an argument or loaded from `),ube=n(gw,"CODE",{});var z4t=s(ube);tdr=r(z4t,"pretrained_model_name_or_path"),z4t.forEach(t),adr=r(gw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bbe=n(gw,"CODE",{});var Q4t=s(bbe);ndr=r(Q4t,"pretrained_model_name_or_path"),Q4t.forEach(t),sdr=r(gw,":"),gw.forEach(t),ldr=i(Ta),Le=n(Ta,"UL",{});var Be=s(Le);XT=n(Be,"LI",{});var wBe=s(XT);vbe=n(wBe,"STRONG",{});var W4t=s(vbe);idr=r(W4t,"data2vec-audio"),W4t.forEach(t),ddr=r(wBe," \u2014 "),fW=n(wBe,"A",{href:!0});var H4t=s(fW);cdr=r(H4t,"Data2VecAudioForCTC"),H4t.forEach(t),fdr=r(wBe," (Data2VecAudio model)"),wBe.forEach(t),mdr=i(Be),zT=n(Be,"LI",{});var ABe=s(zT);Fbe=n(ABe,"STRONG",{});var U4t=s(Fbe);gdr=r(U4t,"hubert"),U4t.forEach(t),hdr=r(ABe," \u2014 "),mW=n(ABe,"A",{href:!0});var J4t=s(mW);pdr=r(J4t,"HubertForCTC"),J4t.forEach(t),_dr=r(ABe," (Hubert model)"),ABe.forEach(t),udr=i(Be),QT=n(Be,"LI",{});var LBe=s(QT);Tbe=n(LBe,"STRONG",{});var Y4t=s(Tbe);bdr=r(Y4t,"mctct"),Y4t.forEach(t),vdr=r(LBe," \u2014 "),gW=n(LBe,"A",{href:!0});var K4t=s(gW);Fdr=r(K4t,"MCTCTForCTC"),K4t.forEach(t),Tdr=r(LBe," (M-CTC-T model)"),LBe.forEach(t),Mdr=i(Be),WT=n(Be,"LI",{});var yBe=s(WT);Mbe=n(yBe,"STRONG",{});var Z4t=s(Mbe);Edr=r(Z4t,"sew"),Z4t.forEach(t),Cdr=r(yBe," \u2014 "),hW=n(yBe,"A",{href:!0});var eCt=s(hW);wdr=r(eCt,"SEWForCTC"),eCt.forEach(t),Adr=r(yBe," (SEW model)"),yBe.forEach(t),Ldr=i(Be),HT=n(Be,"LI",{});var xBe=s(HT);Ebe=n(xBe,"STRONG",{});var oCt=s(Ebe);ydr=r(oCt,"sew-d"),oCt.forEach(t),xdr=r(xBe," \u2014 "),pW=n(xBe,"A",{href:!0});var rCt=s(pW);$dr=r(rCt,"SEWDForCTC"),rCt.forEach(t),kdr=r(xBe," (SEW-D model)"),xBe.forEach(t),Sdr=i(Be),UT=n(Be,"LI",{});var $Be=s(UT);Cbe=n($Be,"STRONG",{});var tCt=s(Cbe);Rdr=r(tCt,"unispeech"),tCt.forEach(t),Pdr=r($Be," \u2014 "),_W=n($Be,"A",{href:!0});var aCt=s(_W);Bdr=r(aCt,"UniSpeechForCTC"),aCt.forEach(t),Idr=r($Be," (UniSpeech model)"),$Be.forEach(t),Ndr=i(Be),JT=n(Be,"LI",{});var kBe=s(JT);wbe=n(kBe,"STRONG",{});var nCt=s(wbe);qdr=r(nCt,"unispeech-sat"),nCt.forEach(t),jdr=r(kBe," \u2014 "),uW=n(kBe,"A",{href:!0});var sCt=s(uW);Ddr=r(sCt,"UniSpeechSatForCTC"),sCt.forEach(t),Gdr=r(kBe," (UniSpeechSat model)"),kBe.forEach(t),Odr=i(Be),YT=n(Be,"LI",{});var SBe=s(YT);Abe=n(SBe,"STRONG",{});var lCt=s(Abe);Vdr=r(lCt,"wav2vec2"),lCt.forEach(t),Xdr=r(SBe," \u2014 "),bW=n(SBe,"A",{href:!0});var iCt=s(bW);zdr=r(iCt,"Wav2Vec2ForCTC"),iCt.forEach(t),Qdr=r(SBe," (Wav2Vec2 model)"),SBe.forEach(t),Wdr=i(Be),KT=n(Be,"LI",{});var RBe=s(KT);Lbe=n(RBe,"STRONG",{});var dCt=s(Lbe);Hdr=r(dCt,"wav2vec2-conformer"),dCt.forEach(t),Udr=r(RBe," \u2014 "),vW=n(RBe,"A",{href:!0});var cCt=s(vW);Jdr=r(cCt,"Wav2Vec2ConformerForCTC"),cCt.forEach(t),Ydr=r(RBe," (Wav2Vec2-Conformer model)"),RBe.forEach(t),Kdr=i(Be),ZT=n(Be,"LI",{});var PBe=s(ZT);ybe=n(PBe,"STRONG",{});var fCt=s(ybe);Zdr=r(fCt,"wavlm"),fCt.forEach(t),ecr=r(PBe," \u2014 "),FW=n(PBe,"A",{href:!0});var mCt=s(FW);ocr=r(mCt,"WavLMForCTC"),mCt.forEach(t),rcr=r(PBe," (WavLM model)"),PBe.forEach(t),Be.forEach(t),tcr=i(Ta),e7=n(Ta,"P",{});var BBe=s(e7);acr=r(BBe,"The model is set in evaluation mode by default using "),xbe=n(BBe,"CODE",{});var gCt=s(xbe);ncr=r(gCt,"model.eval()"),gCt.forEach(t),scr=r(BBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$be=n(BBe,"CODE",{});var hCt=s($be);lcr=r(hCt,"model.train()"),hCt.forEach(t),BBe.forEach(t),icr=i(Ta),T(o7.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),XOe=i(f),Sd=n(f,"H2",{class:!0});var JXe=s(Sd);r7=n(JXe,"A",{id:!0,class:!0,href:!0});var pCt=s(r7);kbe=n(pCt,"SPAN",{});var _Ct=s(kbe);T(By.$$.fragment,_Ct),_Ct.forEach(t),pCt.forEach(t),dcr=i(JXe),Sbe=n(JXe,"SPAN",{});var uCt=s(Sbe);ccr=r(uCt,"AutoModelForSpeechSeq2Seq"),uCt.forEach(t),JXe.forEach(t),zOe=i(f),Wo=n(f,"DIV",{class:!0});var pl=s(Wo);T(Iy.$$.fragment,pl),fcr=i(pl),Rd=n(pl,"P",{});var tre=s(Rd);mcr=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),TW=n(tre,"A",{href:!0});var bCt=s(TW);gcr=r(bCt,"from_pretrained()"),bCt.forEach(t),hcr=r(tre," class method or the "),MW=n(tre,"A",{href:!0});var vCt=s(MW);pcr=r(vCt,"from_config()"),vCt.forEach(t),_cr=r(tre,` class
method.`),tre.forEach(t),ucr=i(pl),Ny=n(pl,"P",{});var YXe=s(Ny);bcr=r(YXe,"This class cannot be instantiated directly using "),Rbe=n(YXe,"CODE",{});var FCt=s(Rbe);vcr=r(FCt,"__init__()"),FCt.forEach(t),Fcr=r(YXe," (throws an error)."),YXe.forEach(t),Tcr=i(pl),Et=n(pl,"DIV",{class:!0});var hw=s(Et);T(qy.$$.fragment,hw),Mcr=i(hw),Pbe=n(hw,"P",{});var TCt=s(Pbe);Ecr=r(TCt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),TCt.forEach(t),Ccr=i(hw),Pd=n(hw,"P",{});var are=s(Pd);wcr=r(are,`Note:
Loading a model from its configuration file does `),Bbe=n(are,"STRONG",{});var MCt=s(Bbe);Acr=r(MCt,"not"),MCt.forEach(t),Lcr=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),EW=n(are,"A",{href:!0});var ECt=s(EW);ycr=r(ECt,"from_pretrained()"),ECt.forEach(t),xcr=r(are," to load the model weights."),are.forEach(t),$cr=i(hw),T(t7.$$.fragment,hw),hw.forEach(t),kcr=i(pl),ho=n(pl,"DIV",{class:!0});var Ma=s(ho);T(jy.$$.fragment,Ma),Scr=i(Ma),Ibe=n(Ma,"P",{});var CCt=s(Ibe);Rcr=r(CCt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),CCt.forEach(t),Pcr=i(Ma),Ja=n(Ma,"P",{});var pw=s(Ja);Bcr=r(pw,"The model class to instantiate is selected based on the "),Nbe=n(pw,"CODE",{});var wCt=s(Nbe);Icr=r(wCt,"model_type"),wCt.forEach(t),Ncr=r(pw,` property of the config object (either
passed as an argument or loaded from `),qbe=n(pw,"CODE",{});var ACt=s(qbe);qcr=r(ACt,"pretrained_model_name_or_path"),ACt.forEach(t),jcr=r(pw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jbe=n(pw,"CODE",{});var LCt=s(jbe);Dcr=r(LCt,"pretrained_model_name_or_path"),LCt.forEach(t),Gcr=r(pw,":"),pw.forEach(t),Ocr=i(Ma),Dy=n(Ma,"UL",{});var KXe=s(Dy);a7=n(KXe,"LI",{});var IBe=s(a7);Dbe=n(IBe,"STRONG",{});var yCt=s(Dbe);Vcr=r(yCt,"speech-encoder-decoder"),yCt.forEach(t),Xcr=r(IBe," \u2014 "),CW=n(IBe,"A",{href:!0});var xCt=s(CW);zcr=r(xCt,"SpeechEncoderDecoderModel"),xCt.forEach(t),Qcr=r(IBe," (Speech Encoder decoder model)"),IBe.forEach(t),Wcr=i(KXe),n7=n(KXe,"LI",{});var NBe=s(n7);Gbe=n(NBe,"STRONG",{});var $Ct=s(Gbe);Hcr=r($Ct,"speech_to_text"),$Ct.forEach(t),Ucr=r(NBe," \u2014 "),wW=n(NBe,"A",{href:!0});var kCt=s(wW);Jcr=r(kCt,"Speech2TextForConditionalGeneration"),kCt.forEach(t),Ycr=r(NBe," (Speech2Text model)"),NBe.forEach(t),KXe.forEach(t),Kcr=i(Ma),s7=n(Ma,"P",{});var qBe=s(s7);Zcr=r(qBe,"The model is set in evaluation mode by default using "),Obe=n(qBe,"CODE",{});var SCt=s(Obe);efr=r(SCt,"model.eval()"),SCt.forEach(t),ofr=r(qBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vbe=n(qBe,"CODE",{});var RCt=s(Vbe);rfr=r(RCt,"model.train()"),RCt.forEach(t),qBe.forEach(t),tfr=i(Ma),T(l7.$$.fragment,Ma),Ma.forEach(t),pl.forEach(t),QOe=i(f),Bd=n(f,"H2",{class:!0});var ZXe=s(Bd);i7=n(ZXe,"A",{id:!0,class:!0,href:!0});var PCt=s(i7);Xbe=n(PCt,"SPAN",{});var BCt=s(Xbe);T(Gy.$$.fragment,BCt),BCt.forEach(t),PCt.forEach(t),afr=i(ZXe),zbe=n(ZXe,"SPAN",{});var ICt=s(zbe);nfr=r(ICt,"AutoModelForAudioXVector"),ICt.forEach(t),ZXe.forEach(t),WOe=i(f),Ho=n(f,"DIV",{class:!0});var _l=s(Ho);T(Oy.$$.fragment,_l),sfr=i(_l),Id=n(_l,"P",{});var nre=s(Id);lfr=r(nre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),AW=n(nre,"A",{href:!0});var NCt=s(AW);ifr=r(NCt,"from_pretrained()"),NCt.forEach(t),dfr=r(nre," class method or the "),LW=n(nre,"A",{href:!0});var qCt=s(LW);cfr=r(qCt,"from_config()"),qCt.forEach(t),ffr=r(nre,` class
method.`),nre.forEach(t),mfr=i(_l),Vy=n(_l,"P",{});var eze=s(Vy);gfr=r(eze,"This class cannot be instantiated directly using "),Qbe=n(eze,"CODE",{});var jCt=s(Qbe);hfr=r(jCt,"__init__()"),jCt.forEach(t),pfr=r(eze," (throws an error)."),eze.forEach(t),_fr=i(_l),Ct=n(_l,"DIV",{class:!0});var _w=s(Ct);T(Xy.$$.fragment,_w),ufr=i(_w),Wbe=n(_w,"P",{});var DCt=s(Wbe);bfr=r(DCt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),DCt.forEach(t),vfr=i(_w),Nd=n(_w,"P",{});var sre=s(Nd);Ffr=r(sre,`Note:
Loading a model from its configuration file does `),Hbe=n(sre,"STRONG",{});var GCt=s(Hbe);Tfr=r(GCt,"not"),GCt.forEach(t),Mfr=r(sre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yW=n(sre,"A",{href:!0});var OCt=s(yW);Efr=r(OCt,"from_pretrained()"),OCt.forEach(t),Cfr=r(sre," to load the model weights."),sre.forEach(t),wfr=i(_w),T(d7.$$.fragment,_w),_w.forEach(t),Afr=i(_l),po=n(_l,"DIV",{class:!0});var Ea=s(po);T(zy.$$.fragment,Ea),Lfr=i(Ea),Ube=n(Ea,"P",{});var VCt=s(Ube);yfr=r(VCt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),VCt.forEach(t),xfr=i(Ea),Ya=n(Ea,"P",{});var uw=s(Ya);$fr=r(uw,"The model class to instantiate is selected based on the "),Jbe=n(uw,"CODE",{});var XCt=s(Jbe);kfr=r(XCt,"model_type"),XCt.forEach(t),Sfr=r(uw,` property of the config object (either
passed as an argument or loaded from `),Ybe=n(uw,"CODE",{});var zCt=s(Ybe);Rfr=r(zCt,"pretrained_model_name_or_path"),zCt.forEach(t),Pfr=r(uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kbe=n(uw,"CODE",{});var QCt=s(Kbe);Bfr=r(QCt,"pretrained_model_name_or_path"),QCt.forEach(t),Ifr=r(uw,":"),uw.forEach(t),Nfr=i(Ea),ot=n(Ea,"UL",{});var ul=s(ot);c7=n(ul,"LI",{});var jBe=s(c7);Zbe=n(jBe,"STRONG",{});var WCt=s(Zbe);qfr=r(WCt,"data2vec-audio"),WCt.forEach(t),jfr=r(jBe," \u2014 "),xW=n(jBe,"A",{href:!0});var HCt=s(xW);Dfr=r(HCt,"Data2VecAudioForXVector"),HCt.forEach(t),Gfr=r(jBe," (Data2VecAudio model)"),jBe.forEach(t),Ofr=i(ul),f7=n(ul,"LI",{});var DBe=s(f7);eve=n(DBe,"STRONG",{});var UCt=s(eve);Vfr=r(UCt,"unispeech-sat"),UCt.forEach(t),Xfr=r(DBe," \u2014 "),$W=n(DBe,"A",{href:!0});var JCt=s($W);zfr=r(JCt,"UniSpeechSatForXVector"),JCt.forEach(t),Qfr=r(DBe," (UniSpeechSat model)"),DBe.forEach(t),Wfr=i(ul),m7=n(ul,"LI",{});var GBe=s(m7);ove=n(GBe,"STRONG",{});var YCt=s(ove);Hfr=r(YCt,"wav2vec2"),YCt.forEach(t),Ufr=r(GBe," \u2014 "),kW=n(GBe,"A",{href:!0});var KCt=s(kW);Jfr=r(KCt,"Wav2Vec2ForXVector"),KCt.forEach(t),Yfr=r(GBe," (Wav2Vec2 model)"),GBe.forEach(t),Kfr=i(ul),g7=n(ul,"LI",{});var OBe=s(g7);rve=n(OBe,"STRONG",{});var ZCt=s(rve);Zfr=r(ZCt,"wav2vec2-conformer"),ZCt.forEach(t),emr=r(OBe," \u2014 "),SW=n(OBe,"A",{href:!0});var e5t=s(SW);omr=r(e5t,"Wav2Vec2ConformerForXVector"),e5t.forEach(t),rmr=r(OBe," (Wav2Vec2-Conformer model)"),OBe.forEach(t),tmr=i(ul),h7=n(ul,"LI",{});var VBe=s(h7);tve=n(VBe,"STRONG",{});var o5t=s(tve);amr=r(o5t,"wavlm"),o5t.forEach(t),nmr=r(VBe," \u2014 "),RW=n(VBe,"A",{href:!0});var r5t=s(RW);smr=r(r5t,"WavLMForXVector"),r5t.forEach(t),lmr=r(VBe," (WavLM model)"),VBe.forEach(t),ul.forEach(t),imr=i(Ea),p7=n(Ea,"P",{});var XBe=s(p7);dmr=r(XBe,"The model is set in evaluation mode by default using "),ave=n(XBe,"CODE",{});var t5t=s(ave);cmr=r(t5t,"model.eval()"),t5t.forEach(t),fmr=r(XBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nve=n(XBe,"CODE",{});var a5t=s(nve);mmr=r(a5t,"model.train()"),a5t.forEach(t),XBe.forEach(t),gmr=i(Ea),T(_7.$$.fragment,Ea),Ea.forEach(t),_l.forEach(t),HOe=i(f),qd=n(f,"H2",{class:!0});var oze=s(qd);u7=n(oze,"A",{id:!0,class:!0,href:!0});var n5t=s(u7);sve=n(n5t,"SPAN",{});var s5t=s(sve);T(Qy.$$.fragment,s5t),s5t.forEach(t),n5t.forEach(t),hmr=i(oze),lve=n(oze,"SPAN",{});var l5t=s(lve);pmr=r(l5t,"AutoModelForMaskedImageModeling"),l5t.forEach(t),oze.forEach(t),UOe=i(f),Uo=n(f,"DIV",{class:!0});var bl=s(Uo);T(Wy.$$.fragment,bl),_mr=i(bl),jd=n(bl,"P",{});var lre=s(jd);umr=r(lre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),PW=n(lre,"A",{href:!0});var i5t=s(PW);bmr=r(i5t,"from_pretrained()"),i5t.forEach(t),vmr=r(lre," class method or the "),BW=n(lre,"A",{href:!0});var d5t=s(BW);Fmr=r(d5t,"from_config()"),d5t.forEach(t),Tmr=r(lre,` class
method.`),lre.forEach(t),Mmr=i(bl),Hy=n(bl,"P",{});var rze=s(Hy);Emr=r(rze,"This class cannot be instantiated directly using "),ive=n(rze,"CODE",{});var c5t=s(ive);Cmr=r(c5t,"__init__()"),c5t.forEach(t),wmr=r(rze," (throws an error)."),rze.forEach(t),Amr=i(bl),wt=n(bl,"DIV",{class:!0});var bw=s(wt);T(Uy.$$.fragment,bw),Lmr=i(bw),dve=n(bw,"P",{});var f5t=s(dve);ymr=r(f5t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),f5t.forEach(t),xmr=i(bw),Dd=n(bw,"P",{});var ire=s(Dd);$mr=r(ire,`Note:
Loading a model from its configuration file does `),cve=n(ire,"STRONG",{});var m5t=s(cve);kmr=r(m5t,"not"),m5t.forEach(t),Smr=r(ire,` load the model weights. It only affects the
model\u2019s configuration. Use `),IW=n(ire,"A",{href:!0});var g5t=s(IW);Rmr=r(g5t,"from_pretrained()"),g5t.forEach(t),Pmr=r(ire," to load the model weights."),ire.forEach(t),Bmr=i(bw),T(b7.$$.fragment,bw),bw.forEach(t),Imr=i(bl),_o=n(bl,"DIV",{class:!0});var Ca=s(_o);T(Jy.$$.fragment,Ca),Nmr=i(Ca),fve=n(Ca,"P",{});var h5t=s(fve);qmr=r(h5t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),h5t.forEach(t),jmr=i(Ca),Ka=n(Ca,"P",{});var vw=s(Ka);Dmr=r(vw,"The model class to instantiate is selected based on the "),mve=n(vw,"CODE",{});var p5t=s(mve);Gmr=r(p5t,"model_type"),p5t.forEach(t),Omr=r(vw,` property of the config object (either
passed as an argument or loaded from `),gve=n(vw,"CODE",{});var _5t=s(gve);Vmr=r(_5t,"pretrained_model_name_or_path"),_5t.forEach(t),Xmr=r(vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hve=n(vw,"CODE",{});var u5t=s(hve);zmr=r(u5t,"pretrained_model_name_or_path"),u5t.forEach(t),Qmr=r(vw,":"),vw.forEach(t),Wmr=i(Ca),Gd=n(Ca,"UL",{});var dre=s(Gd);v7=n(dre,"LI",{});var zBe=s(v7);pve=n(zBe,"STRONG",{});var b5t=s(pve);Hmr=r(b5t,"deit"),b5t.forEach(t),Umr=r(zBe," \u2014 "),NW=n(zBe,"A",{href:!0});var v5t=s(NW);Jmr=r(v5t,"DeiTForMaskedImageModeling"),v5t.forEach(t),Ymr=r(zBe," (DeiT model)"),zBe.forEach(t),Kmr=i(dre),F7=n(dre,"LI",{});var QBe=s(F7);_ve=n(QBe,"STRONG",{});var F5t=s(_ve);Zmr=r(F5t,"swin"),F5t.forEach(t),egr=r(QBe," \u2014 "),qW=n(QBe,"A",{href:!0});var T5t=s(qW);ogr=r(T5t,"SwinForMaskedImageModeling"),T5t.forEach(t),rgr=r(QBe," (Swin Transformer model)"),QBe.forEach(t),tgr=i(dre),T7=n(dre,"LI",{});var WBe=s(T7);uve=n(WBe,"STRONG",{});var M5t=s(uve);agr=r(M5t,"vit"),M5t.forEach(t),ngr=r(WBe," \u2014 "),jW=n(WBe,"A",{href:!0});var E5t=s(jW);sgr=r(E5t,"ViTForMaskedImageModeling"),E5t.forEach(t),lgr=r(WBe," (ViT model)"),WBe.forEach(t),dre.forEach(t),igr=i(Ca),M7=n(Ca,"P",{});var HBe=s(M7);dgr=r(HBe,"The model is set in evaluation mode by default using "),bve=n(HBe,"CODE",{});var C5t=s(bve);cgr=r(C5t,"model.eval()"),C5t.forEach(t),fgr=r(HBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vve=n(HBe,"CODE",{});var w5t=s(vve);mgr=r(w5t,"model.train()"),w5t.forEach(t),HBe.forEach(t),ggr=i(Ca),T(E7.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),JOe=i(f),Od=n(f,"H2",{class:!0});var tze=s(Od);C7=n(tze,"A",{id:!0,class:!0,href:!0});var A5t=s(C7);Fve=n(A5t,"SPAN",{});var L5t=s(Fve);T(Yy.$$.fragment,L5t),L5t.forEach(t),A5t.forEach(t),hgr=i(tze),Tve=n(tze,"SPAN",{});var y5t=s(Tve);pgr=r(y5t,"AutoModelForObjectDetection"),y5t.forEach(t),tze.forEach(t),YOe=i(f),Jo=n(f,"DIV",{class:!0});var vl=s(Jo);T(Ky.$$.fragment,vl),_gr=i(vl),Vd=n(vl,"P",{});var cre=s(Vd);ugr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),DW=n(cre,"A",{href:!0});var x5t=s(DW);bgr=r(x5t,"from_pretrained()"),x5t.forEach(t),vgr=r(cre," class method or the "),GW=n(cre,"A",{href:!0});var $5t=s(GW);Fgr=r($5t,"from_config()"),$5t.forEach(t),Tgr=r(cre,` class
method.`),cre.forEach(t),Mgr=i(vl),Zy=n(vl,"P",{});var aze=s(Zy);Egr=r(aze,"This class cannot be instantiated directly using "),Mve=n(aze,"CODE",{});var k5t=s(Mve);Cgr=r(k5t,"__init__()"),k5t.forEach(t),wgr=r(aze," (throws an error)."),aze.forEach(t),Agr=i(vl),At=n(vl,"DIV",{class:!0});var Fw=s(At);T(e9.$$.fragment,Fw),Lgr=i(Fw),Eve=n(Fw,"P",{});var S5t=s(Eve);ygr=r(S5t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),S5t.forEach(t),xgr=i(Fw),Xd=n(Fw,"P",{});var fre=s(Xd);$gr=r(fre,`Note:
Loading a model from its configuration file does `),Cve=n(fre,"STRONG",{});var R5t=s(Cve);kgr=r(R5t,"not"),R5t.forEach(t),Sgr=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=n(fre,"A",{href:!0});var P5t=s(OW);Rgr=r(P5t,"from_pretrained()"),P5t.forEach(t),Pgr=r(fre," to load the model weights."),fre.forEach(t),Bgr=i(Fw),T(w7.$$.fragment,Fw),Fw.forEach(t),Igr=i(vl),uo=n(vl,"DIV",{class:!0});var wa=s(uo);T(o9.$$.fragment,wa),Ngr=i(wa),wve=n(wa,"P",{});var B5t=s(wve);qgr=r(B5t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),B5t.forEach(t),jgr=i(wa),Za=n(wa,"P",{});var Tw=s(Za);Dgr=r(Tw,"The model class to instantiate is selected based on the "),Ave=n(Tw,"CODE",{});var I5t=s(Ave);Ggr=r(I5t,"model_type"),I5t.forEach(t),Ogr=r(Tw,` property of the config object (either
passed as an argument or loaded from `),Lve=n(Tw,"CODE",{});var N5t=s(Lve);Vgr=r(N5t,"pretrained_model_name_or_path"),N5t.forEach(t),Xgr=r(Tw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yve=n(Tw,"CODE",{});var q5t=s(yve);zgr=r(q5t,"pretrained_model_name_or_path"),q5t.forEach(t),Qgr=r(Tw,":"),Tw.forEach(t),Wgr=i(wa),r9=n(wa,"UL",{});var nze=s(r9);A7=n(nze,"LI",{});var UBe=s(A7);xve=n(UBe,"STRONG",{});var j5t=s(xve);Hgr=r(j5t,"detr"),j5t.forEach(t),Ugr=r(UBe," \u2014 "),VW=n(UBe,"A",{href:!0});var D5t=s(VW);Jgr=r(D5t,"DetrForObjectDetection"),D5t.forEach(t),Ygr=r(UBe," (DETR model)"),UBe.forEach(t),Kgr=i(nze),L7=n(nze,"LI",{});var JBe=s(L7);$ve=n(JBe,"STRONG",{});var G5t=s($ve);Zgr=r(G5t,"yolos"),G5t.forEach(t),ehr=r(JBe," \u2014 "),XW=n(JBe,"A",{href:!0});var O5t=s(XW);ohr=r(O5t,"YolosForObjectDetection"),O5t.forEach(t),rhr=r(JBe," (YOLOS model)"),JBe.forEach(t),nze.forEach(t),thr=i(wa),y7=n(wa,"P",{});var YBe=s(y7);ahr=r(YBe,"The model is set in evaluation mode by default using "),kve=n(YBe,"CODE",{});var V5t=s(kve);nhr=r(V5t,"model.eval()"),V5t.forEach(t),shr=r(YBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sve=n(YBe,"CODE",{});var X5t=s(Sve);lhr=r(X5t,"model.train()"),X5t.forEach(t),YBe.forEach(t),ihr=i(wa),T(x7.$$.fragment,wa),wa.forEach(t),vl.forEach(t),KOe=i(f),zd=n(f,"H2",{class:!0});var sze=s(zd);$7=n(sze,"A",{id:!0,class:!0,href:!0});var z5t=s($7);Rve=n(z5t,"SPAN",{});var Q5t=s(Rve);T(t9.$$.fragment,Q5t),Q5t.forEach(t),z5t.forEach(t),dhr=i(sze),Pve=n(sze,"SPAN",{});var W5t=s(Pve);chr=r(W5t,"AutoModelForImageSegmentation"),W5t.forEach(t),sze.forEach(t),ZOe=i(f),Yo=n(f,"DIV",{class:!0});var Fl=s(Yo);T(a9.$$.fragment,Fl),fhr=i(Fl),Qd=n(Fl,"P",{});var mre=s(Qd);mhr=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),zW=n(mre,"A",{href:!0});var H5t=s(zW);ghr=r(H5t,"from_pretrained()"),H5t.forEach(t),hhr=r(mre," class method or the "),QW=n(mre,"A",{href:!0});var U5t=s(QW);phr=r(U5t,"from_config()"),U5t.forEach(t),_hr=r(mre,` class
method.`),mre.forEach(t),uhr=i(Fl),n9=n(Fl,"P",{});var lze=s(n9);bhr=r(lze,"This class cannot be instantiated directly using "),Bve=n(lze,"CODE",{});var J5t=s(Bve);vhr=r(J5t,"__init__()"),J5t.forEach(t),Fhr=r(lze," (throws an error)."),lze.forEach(t),Thr=i(Fl),Lt=n(Fl,"DIV",{class:!0});var Mw=s(Lt);T(s9.$$.fragment,Mw),Mhr=i(Mw),Ive=n(Mw,"P",{});var Y5t=s(Ive);Ehr=r(Y5t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Y5t.forEach(t),Chr=i(Mw),Wd=n(Mw,"P",{});var gre=s(Wd);whr=r(gre,`Note:
Loading a model from its configuration file does `),Nve=n(gre,"STRONG",{});var K5t=s(Nve);Ahr=r(K5t,"not"),K5t.forEach(t),Lhr=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(gre,"A",{href:!0});var Z5t=s(WW);yhr=r(Z5t,"from_pretrained()"),Z5t.forEach(t),xhr=r(gre," to load the model weights."),gre.forEach(t),$hr=i(Mw),T(k7.$$.fragment,Mw),Mw.forEach(t),khr=i(Fl),bo=n(Fl,"DIV",{class:!0});var Aa=s(bo);T(l9.$$.fragment,Aa),Shr=i(Aa),qve=n(Aa,"P",{});var e3t=s(qve);Rhr=r(e3t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),e3t.forEach(t),Phr=i(Aa),en=n(Aa,"P",{});var Ew=s(en);Bhr=r(Ew,"The model class to instantiate is selected based on the "),jve=n(Ew,"CODE",{});var o3t=s(jve);Ihr=r(o3t,"model_type"),o3t.forEach(t),Nhr=r(Ew,` property of the config object (either
passed as an argument or loaded from `),Dve=n(Ew,"CODE",{});var r3t=s(Dve);qhr=r(r3t,"pretrained_model_name_or_path"),r3t.forEach(t),jhr=r(Ew,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gve=n(Ew,"CODE",{});var t3t=s(Gve);Dhr=r(t3t,"pretrained_model_name_or_path"),t3t.forEach(t),Ghr=r(Ew,":"),Ew.forEach(t),Ohr=i(Aa),Ove=n(Aa,"UL",{});var a3t=s(Ove);S7=n(a3t,"LI",{});var KBe=s(S7);Vve=n(KBe,"STRONG",{});var n3t=s(Vve);Vhr=r(n3t,"detr"),n3t.forEach(t),Xhr=r(KBe," \u2014 "),HW=n(KBe,"A",{href:!0});var s3t=s(HW);zhr=r(s3t,"DetrForSegmentation"),s3t.forEach(t),Qhr=r(KBe," (DETR model)"),KBe.forEach(t),a3t.forEach(t),Whr=i(Aa),R7=n(Aa,"P",{});var ZBe=s(R7);Hhr=r(ZBe,"The model is set in evaluation mode by default using "),Xve=n(ZBe,"CODE",{});var l3t=s(Xve);Uhr=r(l3t,"model.eval()"),l3t.forEach(t),Jhr=r(ZBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zve=n(ZBe,"CODE",{});var i3t=s(zve);Yhr=r(i3t,"model.train()"),i3t.forEach(t),ZBe.forEach(t),Khr=i(Aa),T(P7.$$.fragment,Aa),Aa.forEach(t),Fl.forEach(t),eVe=i(f),Hd=n(f,"H2",{class:!0});var ize=s(Hd);B7=n(ize,"A",{id:!0,class:!0,href:!0});var d3t=s(B7);Qve=n(d3t,"SPAN",{});var c3t=s(Qve);T(i9.$$.fragment,c3t),c3t.forEach(t),d3t.forEach(t),Zhr=i(ize),Wve=n(ize,"SPAN",{});var f3t=s(Wve);epr=r(f3t,"AutoModelForSemanticSegmentation"),f3t.forEach(t),ize.forEach(t),oVe=i(f),Ko=n(f,"DIV",{class:!0});var Tl=s(Ko);T(d9.$$.fragment,Tl),opr=i(Tl),Ud=n(Tl,"P",{});var hre=s(Ud);rpr=r(hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),UW=n(hre,"A",{href:!0});var m3t=s(UW);tpr=r(m3t,"from_pretrained()"),m3t.forEach(t),apr=r(hre," class method or the "),JW=n(hre,"A",{href:!0});var g3t=s(JW);npr=r(g3t,"from_config()"),g3t.forEach(t),spr=r(hre,` class
method.`),hre.forEach(t),lpr=i(Tl),c9=n(Tl,"P",{});var dze=s(c9);ipr=r(dze,"This class cannot be instantiated directly using "),Hve=n(dze,"CODE",{});var h3t=s(Hve);dpr=r(h3t,"__init__()"),h3t.forEach(t),cpr=r(dze," (throws an error)."),dze.forEach(t),fpr=i(Tl),yt=n(Tl,"DIV",{class:!0});var Cw=s(yt);T(f9.$$.fragment,Cw),mpr=i(Cw),Uve=n(Cw,"P",{});var p3t=s(Uve);gpr=r(p3t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),p3t.forEach(t),hpr=i(Cw),Jd=n(Cw,"P",{});var pre=s(Jd);ppr=r(pre,`Note:
Loading a model from its configuration file does `),Jve=n(pre,"STRONG",{});var _3t=s(Jve);_pr=r(_3t,"not"),_3t.forEach(t),upr=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(pre,"A",{href:!0});var u3t=s(YW);bpr=r(u3t,"from_pretrained()"),u3t.forEach(t),vpr=r(pre," to load the model weights."),pre.forEach(t),Fpr=i(Cw),T(I7.$$.fragment,Cw),Cw.forEach(t),Tpr=i(Tl),vo=n(Tl,"DIV",{class:!0});var La=s(vo);T(m9.$$.fragment,La),Mpr=i(La),Yve=n(La,"P",{});var b3t=s(Yve);Epr=r(b3t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),b3t.forEach(t),Cpr=i(La),on=n(La,"P",{});var ww=s(on);wpr=r(ww,"The model class to instantiate is selected based on the "),Kve=n(ww,"CODE",{});var v3t=s(Kve);Apr=r(v3t,"model_type"),v3t.forEach(t),Lpr=r(ww,` property of the config object (either
passed as an argument or loaded from `),Zve=n(ww,"CODE",{});var F3t=s(Zve);ypr=r(F3t,"pretrained_model_name_or_path"),F3t.forEach(t),xpr=r(ww,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eFe=n(ww,"CODE",{});var T3t=s(eFe);$pr=r(T3t,"pretrained_model_name_or_path"),T3t.forEach(t),kpr=r(ww,":"),ww.forEach(t),Spr=i(La),rn=n(La,"UL",{});var Aw=s(rn);N7=n(Aw,"LI",{});var eIe=s(N7);oFe=n(eIe,"STRONG",{});var M3t=s(oFe);Rpr=r(M3t,"beit"),M3t.forEach(t),Ppr=r(eIe," \u2014 "),KW=n(eIe,"A",{href:!0});var E3t=s(KW);Bpr=r(E3t,"BeitForSemanticSegmentation"),E3t.forEach(t),Ipr=r(eIe," (BEiT model)"),eIe.forEach(t),Npr=i(Aw),q7=n(Aw,"LI",{});var oIe=s(q7);rFe=n(oIe,"STRONG",{});var C3t=s(rFe);qpr=r(C3t,"data2vec-vision"),C3t.forEach(t),jpr=r(oIe," \u2014 "),ZW=n(oIe,"A",{href:!0});var w3t=s(ZW);Dpr=r(w3t,"Data2VecVisionForSemanticSegmentation"),w3t.forEach(t),Gpr=r(oIe," (Data2VecVision model)"),oIe.forEach(t),Opr=i(Aw),j7=n(Aw,"LI",{});var rIe=s(j7);tFe=n(rIe,"STRONG",{});var A3t=s(tFe);Vpr=r(A3t,"dpt"),A3t.forEach(t),Xpr=r(rIe," \u2014 "),eH=n(rIe,"A",{href:!0});var L3t=s(eH);zpr=r(L3t,"DPTForSemanticSegmentation"),L3t.forEach(t),Qpr=r(rIe," (DPT model)"),rIe.forEach(t),Wpr=i(Aw),D7=n(Aw,"LI",{});var tIe=s(D7);aFe=n(tIe,"STRONG",{});var y3t=s(aFe);Hpr=r(y3t,"segformer"),y3t.forEach(t),Upr=r(tIe," \u2014 "),oH=n(tIe,"A",{href:!0});var x3t=s(oH);Jpr=r(x3t,"SegformerForSemanticSegmentation"),x3t.forEach(t),Ypr=r(tIe," (SegFormer model)"),tIe.forEach(t),Aw.forEach(t),Kpr=i(La),G7=n(La,"P",{});var aIe=s(G7);Zpr=r(aIe,"The model is set in evaluation mode by default using "),nFe=n(aIe,"CODE",{});var $3t=s(nFe);e_r=r($3t,"model.eval()"),$3t.forEach(t),o_r=r(aIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sFe=n(aIe,"CODE",{});var k3t=s(sFe);r_r=r(k3t,"model.train()"),k3t.forEach(t),aIe.forEach(t),t_r=i(La),T(O7.$$.fragment,La),La.forEach(t),Tl.forEach(t),rVe=i(f),Yd=n(f,"H2",{class:!0});var cze=s(Yd);V7=n(cze,"A",{id:!0,class:!0,href:!0});var S3t=s(V7);lFe=n(S3t,"SPAN",{});var R3t=s(lFe);T(g9.$$.fragment,R3t),R3t.forEach(t),S3t.forEach(t),a_r=i(cze),iFe=n(cze,"SPAN",{});var P3t=s(iFe);n_r=r(P3t,"AutoModelForInstanceSegmentation"),P3t.forEach(t),cze.forEach(t),tVe=i(f),Zo=n(f,"DIV",{class:!0});var Ml=s(Zo);T(h9.$$.fragment,Ml),s_r=i(Ml),Kd=n(Ml,"P",{});var _re=s(Kd);l_r=r(_re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),rH=n(_re,"A",{href:!0});var B3t=s(rH);i_r=r(B3t,"from_pretrained()"),B3t.forEach(t),d_r=r(_re," class method or the "),tH=n(_re,"A",{href:!0});var I3t=s(tH);c_r=r(I3t,"from_config()"),I3t.forEach(t),f_r=r(_re,` class
method.`),_re.forEach(t),m_r=i(Ml),p9=n(Ml,"P",{});var fze=s(p9);g_r=r(fze,"This class cannot be instantiated directly using "),dFe=n(fze,"CODE",{});var N3t=s(dFe);h_r=r(N3t,"__init__()"),N3t.forEach(t),p_r=r(fze," (throws an error)."),fze.forEach(t),__r=i(Ml),xt=n(Ml,"DIV",{class:!0});var Lw=s(xt);T(_9.$$.fragment,Lw),u_r=i(Lw),cFe=n(Lw,"P",{});var q3t=s(cFe);b_r=r(q3t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),q3t.forEach(t),v_r=i(Lw),Zd=n(Lw,"P",{});var ure=s(Zd);F_r=r(ure,`Note:
Loading a model from its configuration file does `),fFe=n(ure,"STRONG",{});var j3t=s(fFe);T_r=r(j3t,"not"),j3t.forEach(t),M_r=r(ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(ure,"A",{href:!0});var D3t=s(aH);E_r=r(D3t,"from_pretrained()"),D3t.forEach(t),C_r=r(ure," to load the model weights."),ure.forEach(t),w_r=i(Lw),T(X7.$$.fragment,Lw),Lw.forEach(t),A_r=i(Ml),Fo=n(Ml,"DIV",{class:!0});var ya=s(Fo);T(u9.$$.fragment,ya),L_r=i(ya),mFe=n(ya,"P",{});var G3t=s(mFe);y_r=r(G3t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),G3t.forEach(t),x_r=i(ya),tn=n(ya,"P",{});var yw=s(tn);$_r=r(yw,"The model class to instantiate is selected based on the "),gFe=n(yw,"CODE",{});var O3t=s(gFe);k_r=r(O3t,"model_type"),O3t.forEach(t),S_r=r(yw,` property of the config object (either
passed as an argument or loaded from `),hFe=n(yw,"CODE",{});var V3t=s(hFe);R_r=r(V3t,"pretrained_model_name_or_path"),V3t.forEach(t),P_r=r(yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pFe=n(yw,"CODE",{});var X3t=s(pFe);B_r=r(X3t,"pretrained_model_name_or_path"),X3t.forEach(t),I_r=r(yw,":"),yw.forEach(t),N_r=i(ya),_Fe=n(ya,"UL",{});var z3t=s(_Fe);z7=n(z3t,"LI",{});var nIe=s(z7);uFe=n(nIe,"STRONG",{});var Q3t=s(uFe);q_r=r(Q3t,"maskformer"),Q3t.forEach(t),j_r=r(nIe," \u2014 "),nH=n(nIe,"A",{href:!0});var W3t=s(nH);D_r=r(W3t,"MaskFormerForInstanceSegmentation"),W3t.forEach(t),G_r=r(nIe," (MaskFormer model)"),nIe.forEach(t),z3t.forEach(t),O_r=i(ya),Q7=n(ya,"P",{});var sIe=s(Q7);V_r=r(sIe,"The model is set in evaluation mode by default using "),bFe=n(sIe,"CODE",{});var H3t=s(bFe);X_r=r(H3t,"model.eval()"),H3t.forEach(t),z_r=r(sIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vFe=n(sIe,"CODE",{});var U3t=s(vFe);Q_r=r(U3t,"model.train()"),U3t.forEach(t),sIe.forEach(t),W_r=i(ya),T(W7.$$.fragment,ya),ya.forEach(t),Ml.forEach(t),aVe=i(f),ec=n(f,"H2",{class:!0});var mze=s(ec);H7=n(mze,"A",{id:!0,class:!0,href:!0});var J3t=s(H7);FFe=n(J3t,"SPAN",{});var Y3t=s(FFe);T(b9.$$.fragment,Y3t),Y3t.forEach(t),J3t.forEach(t),H_r=i(mze),TFe=n(mze,"SPAN",{});var K3t=s(TFe);U_r=r(K3t,"TFAutoModel"),K3t.forEach(t),mze.forEach(t),nVe=i(f),er=n(f,"DIV",{class:!0});var El=s(er);T(v9.$$.fragment,El),J_r=i(El),oc=n(El,"P",{});var bre=s(oc);Y_r=r(bre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sH=n(bre,"A",{href:!0});var Z3t=s(sH);K_r=r(Z3t,"from_pretrained()"),Z3t.forEach(t),Z_r=r(bre," class method or the "),lH=n(bre,"A",{href:!0});var e0t=s(lH);eur=r(e0t,"from_config()"),e0t.forEach(t),our=r(bre,` class
method.`),bre.forEach(t),rur=i(El),F9=n(El,"P",{});var gze=s(F9);tur=r(gze,"This class cannot be instantiated directly using "),MFe=n(gze,"CODE",{});var o0t=s(MFe);aur=r(o0t,"__init__()"),o0t.forEach(t),nur=r(gze," (throws an error)."),gze.forEach(t),sur=i(El),$t=n(El,"DIV",{class:!0});var xw=s($t);T(T9.$$.fragment,xw),lur=i(xw),EFe=n(xw,"P",{});var r0t=s(EFe);iur=r(r0t,"Instantiates one of the base model classes of the library from a configuration."),r0t.forEach(t),dur=i(xw),rc=n(xw,"P",{});var vre=s(rc);cur=r(vre,`Note:
Loading a model from its configuration file does `),CFe=n(vre,"STRONG",{});var t0t=s(CFe);fur=r(t0t,"not"),t0t.forEach(t),mur=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),iH=n(vre,"A",{href:!0});var a0t=s(iH);gur=r(a0t,"from_pretrained()"),a0t.forEach(t),hur=r(vre," to load the model weights."),vre.forEach(t),pur=i(xw),T(U7.$$.fragment,xw),xw.forEach(t),_ur=i(El),yr=n(El,"DIV",{class:!0});var Cl=s(yr);T(M9.$$.fragment,Cl),uur=i(Cl),wFe=n(Cl,"P",{});var n0t=s(wFe);bur=r(n0t,"Instantiate one of the base model classes of the library from a pretrained model."),n0t.forEach(t),vur=i(Cl),an=n(Cl,"P",{});var $w=s(an);Fur=r($w,"The model class to instantiate is selected based on the "),AFe=n($w,"CODE",{});var s0t=s(AFe);Tur=r(s0t,"model_type"),s0t.forEach(t),Mur=r($w,` property of the config object (either
passed as an argument or loaded from `),LFe=n($w,"CODE",{});var l0t=s(LFe);Eur=r(l0t,"pretrained_model_name_or_path"),l0t.forEach(t),Cur=r($w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yFe=n($w,"CODE",{});var i0t=s(yFe);wur=r(i0t,"pretrained_model_name_or_path"),i0t.forEach(t),Aur=r($w,":"),$w.forEach(t),Lur=i(Cl),j=n(Cl,"UL",{});var D=s(j);J7=n(D,"LI",{});var lIe=s(J7);xFe=n(lIe,"STRONG",{});var d0t=s(xFe);yur=r(d0t,"albert"),d0t.forEach(t),xur=r(lIe," \u2014 "),dH=n(lIe,"A",{href:!0});var c0t=s(dH);$ur=r(c0t,"TFAlbertModel"),c0t.forEach(t),kur=r(lIe," (ALBERT model)"),lIe.forEach(t),Sur=i(D),Y7=n(D,"LI",{});var iIe=s(Y7);$Fe=n(iIe,"STRONG",{});var f0t=s($Fe);Rur=r(f0t,"bart"),f0t.forEach(t),Pur=r(iIe," \u2014 "),cH=n(iIe,"A",{href:!0});var m0t=s(cH);Bur=r(m0t,"TFBartModel"),m0t.forEach(t),Iur=r(iIe," (BART model)"),iIe.forEach(t),Nur=i(D),K7=n(D,"LI",{});var dIe=s(K7);kFe=n(dIe,"STRONG",{});var g0t=s(kFe);qur=r(g0t,"bert"),g0t.forEach(t),jur=r(dIe," \u2014 "),fH=n(dIe,"A",{href:!0});var h0t=s(fH);Dur=r(h0t,"TFBertModel"),h0t.forEach(t),Gur=r(dIe," (BERT model)"),dIe.forEach(t),Our=i(D),Z7=n(D,"LI",{});var cIe=s(Z7);SFe=n(cIe,"STRONG",{});var p0t=s(SFe);Vur=r(p0t,"blenderbot"),p0t.forEach(t),Xur=r(cIe," \u2014 "),mH=n(cIe,"A",{href:!0});var _0t=s(mH);zur=r(_0t,"TFBlenderbotModel"),_0t.forEach(t),Qur=r(cIe," (Blenderbot model)"),cIe.forEach(t),Wur=i(D),e8=n(D,"LI",{});var fIe=s(e8);RFe=n(fIe,"STRONG",{});var u0t=s(RFe);Hur=r(u0t,"blenderbot-small"),u0t.forEach(t),Uur=r(fIe," \u2014 "),gH=n(fIe,"A",{href:!0});var b0t=s(gH);Jur=r(b0t,"TFBlenderbotSmallModel"),b0t.forEach(t),Yur=r(fIe," (BlenderbotSmall model)"),fIe.forEach(t),Kur=i(D),o8=n(D,"LI",{});var mIe=s(o8);PFe=n(mIe,"STRONG",{});var v0t=s(PFe);Zur=r(v0t,"camembert"),v0t.forEach(t),e2r=r(mIe," \u2014 "),hH=n(mIe,"A",{href:!0});var F0t=s(hH);o2r=r(F0t,"TFCamembertModel"),F0t.forEach(t),r2r=r(mIe," (CamemBERT model)"),mIe.forEach(t),t2r=i(D),r8=n(D,"LI",{});var gIe=s(r8);BFe=n(gIe,"STRONG",{});var T0t=s(BFe);a2r=r(T0t,"clip"),T0t.forEach(t),n2r=r(gIe," \u2014 "),pH=n(gIe,"A",{href:!0});var M0t=s(pH);s2r=r(M0t,"TFCLIPModel"),M0t.forEach(t),l2r=r(gIe," (CLIP model)"),gIe.forEach(t),i2r=i(D),t8=n(D,"LI",{});var hIe=s(t8);IFe=n(hIe,"STRONG",{});var E0t=s(IFe);d2r=r(E0t,"convbert"),E0t.forEach(t),c2r=r(hIe," \u2014 "),_H=n(hIe,"A",{href:!0});var C0t=s(_H);f2r=r(C0t,"TFConvBertModel"),C0t.forEach(t),m2r=r(hIe," (ConvBERT model)"),hIe.forEach(t),g2r=i(D),a8=n(D,"LI",{});var pIe=s(a8);NFe=n(pIe,"STRONG",{});var w0t=s(NFe);h2r=r(w0t,"convnext"),w0t.forEach(t),p2r=r(pIe," \u2014 "),uH=n(pIe,"A",{href:!0});var A0t=s(uH);_2r=r(A0t,"TFConvNextModel"),A0t.forEach(t),u2r=r(pIe," (ConvNeXT model)"),pIe.forEach(t),b2r=i(D),n8=n(D,"LI",{});var _Ie=s(n8);qFe=n(_Ie,"STRONG",{});var L0t=s(qFe);v2r=r(L0t,"ctrl"),L0t.forEach(t),F2r=r(_Ie," \u2014 "),bH=n(_Ie,"A",{href:!0});var y0t=s(bH);T2r=r(y0t,"TFCTRLModel"),y0t.forEach(t),M2r=r(_Ie," (CTRL model)"),_Ie.forEach(t),E2r=i(D),s8=n(D,"LI",{});var uIe=s(s8);jFe=n(uIe,"STRONG",{});var x0t=s(jFe);C2r=r(x0t,"data2vec-vision"),x0t.forEach(t),w2r=r(uIe," \u2014 "),vH=n(uIe,"A",{href:!0});var $0t=s(vH);A2r=r($0t,"TFData2VecVisionModel"),$0t.forEach(t),L2r=r(uIe," (Data2VecVision model)"),uIe.forEach(t),y2r=i(D),l8=n(D,"LI",{});var bIe=s(l8);DFe=n(bIe,"STRONG",{});var k0t=s(DFe);x2r=r(k0t,"deberta"),k0t.forEach(t),$2r=r(bIe," \u2014 "),FH=n(bIe,"A",{href:!0});var S0t=s(FH);k2r=r(S0t,"TFDebertaModel"),S0t.forEach(t),S2r=r(bIe," (DeBERTa model)"),bIe.forEach(t),R2r=i(D),i8=n(D,"LI",{});var vIe=s(i8);GFe=n(vIe,"STRONG",{});var R0t=s(GFe);P2r=r(R0t,"deberta-v2"),R0t.forEach(t),B2r=r(vIe," \u2014 "),TH=n(vIe,"A",{href:!0});var P0t=s(TH);I2r=r(P0t,"TFDebertaV2Model"),P0t.forEach(t),N2r=r(vIe," (DeBERTa-v2 model)"),vIe.forEach(t),q2r=i(D),d8=n(D,"LI",{});var FIe=s(d8);OFe=n(FIe,"STRONG",{});var B0t=s(OFe);j2r=r(B0t,"distilbert"),B0t.forEach(t),D2r=r(FIe," \u2014 "),MH=n(FIe,"A",{href:!0});var I0t=s(MH);G2r=r(I0t,"TFDistilBertModel"),I0t.forEach(t),O2r=r(FIe," (DistilBERT model)"),FIe.forEach(t),V2r=i(D),c8=n(D,"LI",{});var TIe=s(c8);VFe=n(TIe,"STRONG",{});var N0t=s(VFe);X2r=r(N0t,"dpr"),N0t.forEach(t),z2r=r(TIe," \u2014 "),EH=n(TIe,"A",{href:!0});var q0t=s(EH);Q2r=r(q0t,"TFDPRQuestionEncoder"),q0t.forEach(t),W2r=r(TIe," (DPR model)"),TIe.forEach(t),H2r=i(D),f8=n(D,"LI",{});var MIe=s(f8);XFe=n(MIe,"STRONG",{});var j0t=s(XFe);U2r=r(j0t,"electra"),j0t.forEach(t),J2r=r(MIe," \u2014 "),CH=n(MIe,"A",{href:!0});var D0t=s(CH);Y2r=r(D0t,"TFElectraModel"),D0t.forEach(t),K2r=r(MIe," (ELECTRA model)"),MIe.forEach(t),Z2r=i(D),m8=n(D,"LI",{});var EIe=s(m8);zFe=n(EIe,"STRONG",{});var G0t=s(zFe);e1r=r(G0t,"flaubert"),G0t.forEach(t),o1r=r(EIe," \u2014 "),wH=n(EIe,"A",{href:!0});var O0t=s(wH);r1r=r(O0t,"TFFlaubertModel"),O0t.forEach(t),t1r=r(EIe," (FlauBERT model)"),EIe.forEach(t),a1r=i(D),Qs=n(D,"LI",{});var aS=s(Qs);QFe=n(aS,"STRONG",{});var V0t=s(QFe);n1r=r(V0t,"funnel"),V0t.forEach(t),s1r=r(aS," \u2014 "),AH=n(aS,"A",{href:!0});var X0t=s(AH);l1r=r(X0t,"TFFunnelModel"),X0t.forEach(t),i1r=r(aS," or "),LH=n(aS,"A",{href:!0});var z0t=s(LH);d1r=r(z0t,"TFFunnelBaseModel"),z0t.forEach(t),c1r=r(aS," (Funnel Transformer model)"),aS.forEach(t),f1r=i(D),g8=n(D,"LI",{});var CIe=s(g8);WFe=n(CIe,"STRONG",{});var Q0t=s(WFe);m1r=r(Q0t,"gpt2"),Q0t.forEach(t),g1r=r(CIe," \u2014 "),yH=n(CIe,"A",{href:!0});var W0t=s(yH);h1r=r(W0t,"TFGPT2Model"),W0t.forEach(t),p1r=r(CIe," (OpenAI GPT-2 model)"),CIe.forEach(t),_1r=i(D),h8=n(D,"LI",{});var wIe=s(h8);HFe=n(wIe,"STRONG",{});var H0t=s(HFe);u1r=r(H0t,"gptj"),H0t.forEach(t),b1r=r(wIe," \u2014 "),xH=n(wIe,"A",{href:!0});var U0t=s(xH);v1r=r(U0t,"TFGPTJModel"),U0t.forEach(t),F1r=r(wIe," (GPT-J model)"),wIe.forEach(t),T1r=i(D),p8=n(D,"LI",{});var AIe=s(p8);UFe=n(AIe,"STRONG",{});var J0t=s(UFe);M1r=r(J0t,"hubert"),J0t.forEach(t),E1r=r(AIe," \u2014 "),$H=n(AIe,"A",{href:!0});var Y0t=s($H);C1r=r(Y0t,"TFHubertModel"),Y0t.forEach(t),w1r=r(AIe," (Hubert model)"),AIe.forEach(t),A1r=i(D),_8=n(D,"LI",{});var LIe=s(_8);JFe=n(LIe,"STRONG",{});var K0t=s(JFe);L1r=r(K0t,"layoutlm"),K0t.forEach(t),y1r=r(LIe," \u2014 "),kH=n(LIe,"A",{href:!0});var Z0t=s(kH);x1r=r(Z0t,"TFLayoutLMModel"),Z0t.forEach(t),$1r=r(LIe," (LayoutLM model)"),LIe.forEach(t),k1r=i(D),u8=n(D,"LI",{});var yIe=s(u8);YFe=n(yIe,"STRONG",{});var ewt=s(YFe);S1r=r(ewt,"led"),ewt.forEach(t),R1r=r(yIe," \u2014 "),SH=n(yIe,"A",{href:!0});var owt=s(SH);P1r=r(owt,"TFLEDModel"),owt.forEach(t),B1r=r(yIe," (LED model)"),yIe.forEach(t),I1r=i(D),b8=n(D,"LI",{});var xIe=s(b8);KFe=n(xIe,"STRONG",{});var rwt=s(KFe);N1r=r(rwt,"longformer"),rwt.forEach(t),q1r=r(xIe," \u2014 "),RH=n(xIe,"A",{href:!0});var twt=s(RH);j1r=r(twt,"TFLongformerModel"),twt.forEach(t),D1r=r(xIe," (Longformer model)"),xIe.forEach(t),G1r=i(D),v8=n(D,"LI",{});var $Ie=s(v8);ZFe=n($Ie,"STRONG",{});var awt=s(ZFe);O1r=r(awt,"lxmert"),awt.forEach(t),V1r=r($Ie," \u2014 "),PH=n($Ie,"A",{href:!0});var nwt=s(PH);X1r=r(nwt,"TFLxmertModel"),nwt.forEach(t),z1r=r($Ie," (LXMERT model)"),$Ie.forEach(t),Q1r=i(D),F8=n(D,"LI",{});var kIe=s(F8);e6e=n(kIe,"STRONG",{});var swt=s(e6e);W1r=r(swt,"marian"),swt.forEach(t),H1r=r(kIe," \u2014 "),BH=n(kIe,"A",{href:!0});var lwt=s(BH);U1r=r(lwt,"TFMarianModel"),lwt.forEach(t),J1r=r(kIe," (Marian model)"),kIe.forEach(t),Y1r=i(D),T8=n(D,"LI",{});var SIe=s(T8);o6e=n(SIe,"STRONG",{});var iwt=s(o6e);K1r=r(iwt,"mbart"),iwt.forEach(t),Z1r=r(SIe," \u2014 "),IH=n(SIe,"A",{href:!0});var dwt=s(IH);ebr=r(dwt,"TFMBartModel"),dwt.forEach(t),obr=r(SIe," (mBART model)"),SIe.forEach(t),rbr=i(D),M8=n(D,"LI",{});var RIe=s(M8);r6e=n(RIe,"STRONG",{});var cwt=s(r6e);tbr=r(cwt,"mobilebert"),cwt.forEach(t),abr=r(RIe," \u2014 "),NH=n(RIe,"A",{href:!0});var fwt=s(NH);nbr=r(fwt,"TFMobileBertModel"),fwt.forEach(t),sbr=r(RIe," (MobileBERT model)"),RIe.forEach(t),lbr=i(D),E8=n(D,"LI",{});var PIe=s(E8);t6e=n(PIe,"STRONG",{});var mwt=s(t6e);ibr=r(mwt,"mpnet"),mwt.forEach(t),dbr=r(PIe," \u2014 "),qH=n(PIe,"A",{href:!0});var gwt=s(qH);cbr=r(gwt,"TFMPNetModel"),gwt.forEach(t),fbr=r(PIe," (MPNet model)"),PIe.forEach(t),mbr=i(D),C8=n(D,"LI",{});var BIe=s(C8);a6e=n(BIe,"STRONG",{});var hwt=s(a6e);gbr=r(hwt,"mt5"),hwt.forEach(t),hbr=r(BIe," \u2014 "),jH=n(BIe,"A",{href:!0});var pwt=s(jH);pbr=r(pwt,"TFMT5Model"),pwt.forEach(t),_br=r(BIe," (MT5 model)"),BIe.forEach(t),ubr=i(D),w8=n(D,"LI",{});var IIe=s(w8);n6e=n(IIe,"STRONG",{});var _wt=s(n6e);bbr=r(_wt,"openai-gpt"),_wt.forEach(t),vbr=r(IIe," \u2014 "),DH=n(IIe,"A",{href:!0});var uwt=s(DH);Fbr=r(uwt,"TFOpenAIGPTModel"),uwt.forEach(t),Tbr=r(IIe," (OpenAI GPT model)"),IIe.forEach(t),Mbr=i(D),A8=n(D,"LI",{});var NIe=s(A8);s6e=n(NIe,"STRONG",{});var bwt=s(s6e);Ebr=r(bwt,"opt"),bwt.forEach(t),Cbr=r(NIe," \u2014 "),GH=n(NIe,"A",{href:!0});var vwt=s(GH);wbr=r(vwt,"TFOPTModel"),vwt.forEach(t),Abr=r(NIe," (OPT model)"),NIe.forEach(t),Lbr=i(D),L8=n(D,"LI",{});var qIe=s(L8);l6e=n(qIe,"STRONG",{});var Fwt=s(l6e);ybr=r(Fwt,"pegasus"),Fwt.forEach(t),xbr=r(qIe," \u2014 "),OH=n(qIe,"A",{href:!0});var Twt=s(OH);$br=r(Twt,"TFPegasusModel"),Twt.forEach(t),kbr=r(qIe," (Pegasus model)"),qIe.forEach(t),Sbr=i(D),y8=n(D,"LI",{});var jIe=s(y8);i6e=n(jIe,"STRONG",{});var Mwt=s(i6e);Rbr=r(Mwt,"rembert"),Mwt.forEach(t),Pbr=r(jIe," \u2014 "),VH=n(jIe,"A",{href:!0});var Ewt=s(VH);Bbr=r(Ewt,"TFRemBertModel"),Ewt.forEach(t),Ibr=r(jIe," (RemBERT model)"),jIe.forEach(t),Nbr=i(D),x8=n(D,"LI",{});var DIe=s(x8);d6e=n(DIe,"STRONG",{});var Cwt=s(d6e);qbr=r(Cwt,"roberta"),Cwt.forEach(t),jbr=r(DIe," \u2014 "),XH=n(DIe,"A",{href:!0});var wwt=s(XH);Dbr=r(wwt,"TFRobertaModel"),wwt.forEach(t),Gbr=r(DIe," (RoBERTa model)"),DIe.forEach(t),Obr=i(D),$8=n(D,"LI",{});var GIe=s($8);c6e=n(GIe,"STRONG",{});var Awt=s(c6e);Vbr=r(Awt,"roformer"),Awt.forEach(t),Xbr=r(GIe," \u2014 "),zH=n(GIe,"A",{href:!0});var Lwt=s(zH);zbr=r(Lwt,"TFRoFormerModel"),Lwt.forEach(t),Qbr=r(GIe," (RoFormer model)"),GIe.forEach(t),Wbr=i(D),k8=n(D,"LI",{});var OIe=s(k8);f6e=n(OIe,"STRONG",{});var ywt=s(f6e);Hbr=r(ywt,"speech_to_text"),ywt.forEach(t),Ubr=r(OIe," \u2014 "),QH=n(OIe,"A",{href:!0});var xwt=s(QH);Jbr=r(xwt,"TFSpeech2TextModel"),xwt.forEach(t),Ybr=r(OIe," (Speech2Text model)"),OIe.forEach(t),Kbr=i(D),S8=n(D,"LI",{});var VIe=s(S8);m6e=n(VIe,"STRONG",{});var $wt=s(m6e);Zbr=r($wt,"swin"),$wt.forEach(t),evr=r(VIe," \u2014 "),WH=n(VIe,"A",{href:!0});var kwt=s(WH);ovr=r(kwt,"TFSwinModel"),kwt.forEach(t),rvr=r(VIe," (Swin Transformer model)"),VIe.forEach(t),tvr=i(D),R8=n(D,"LI",{});var XIe=s(R8);g6e=n(XIe,"STRONG",{});var Swt=s(g6e);avr=r(Swt,"t5"),Swt.forEach(t),nvr=r(XIe," \u2014 "),HH=n(XIe,"A",{href:!0});var Rwt=s(HH);svr=r(Rwt,"TFT5Model"),Rwt.forEach(t),lvr=r(XIe," (T5 model)"),XIe.forEach(t),ivr=i(D),P8=n(D,"LI",{});var zIe=s(P8);h6e=n(zIe,"STRONG",{});var Pwt=s(h6e);dvr=r(Pwt,"tapas"),Pwt.forEach(t),cvr=r(zIe," \u2014 "),UH=n(zIe,"A",{href:!0});var Bwt=s(UH);fvr=r(Bwt,"TFTapasModel"),Bwt.forEach(t),mvr=r(zIe," (TAPAS model)"),zIe.forEach(t),gvr=i(D),B8=n(D,"LI",{});var QIe=s(B8);p6e=n(QIe,"STRONG",{});var Iwt=s(p6e);hvr=r(Iwt,"transfo-xl"),Iwt.forEach(t),pvr=r(QIe," \u2014 "),JH=n(QIe,"A",{href:!0});var Nwt=s(JH);_vr=r(Nwt,"TFTransfoXLModel"),Nwt.forEach(t),uvr=r(QIe," (Transformer-XL model)"),QIe.forEach(t),bvr=i(D),I8=n(D,"LI",{});var WIe=s(I8);_6e=n(WIe,"STRONG",{});var qwt=s(_6e);vvr=r(qwt,"vit"),qwt.forEach(t),Fvr=r(WIe," \u2014 "),YH=n(WIe,"A",{href:!0});var jwt=s(YH);Tvr=r(jwt,"TFViTModel"),jwt.forEach(t),Mvr=r(WIe," (ViT model)"),WIe.forEach(t),Evr=i(D),N8=n(D,"LI",{});var HIe=s(N8);u6e=n(HIe,"STRONG",{});var Dwt=s(u6e);Cvr=r(Dwt,"vit_mae"),Dwt.forEach(t),wvr=r(HIe," \u2014 "),KH=n(HIe,"A",{href:!0});var Gwt=s(KH);Avr=r(Gwt,"TFViTMAEModel"),Gwt.forEach(t),Lvr=r(HIe," (ViTMAE model)"),HIe.forEach(t),yvr=i(D),q8=n(D,"LI",{});var UIe=s(q8);b6e=n(UIe,"STRONG",{});var Owt=s(b6e);xvr=r(Owt,"wav2vec2"),Owt.forEach(t),$vr=r(UIe," \u2014 "),ZH=n(UIe,"A",{href:!0});var Vwt=s(ZH);kvr=r(Vwt,"TFWav2Vec2Model"),Vwt.forEach(t),Svr=r(UIe," (Wav2Vec2 model)"),UIe.forEach(t),Rvr=i(D),j8=n(D,"LI",{});var JIe=s(j8);v6e=n(JIe,"STRONG",{});var Xwt=s(v6e);Pvr=r(Xwt,"xlm"),Xwt.forEach(t),Bvr=r(JIe," \u2014 "),eU=n(JIe,"A",{href:!0});var zwt=s(eU);Ivr=r(zwt,"TFXLMModel"),zwt.forEach(t),Nvr=r(JIe," (XLM model)"),JIe.forEach(t),qvr=i(D),D8=n(D,"LI",{});var YIe=s(D8);F6e=n(YIe,"STRONG",{});var Qwt=s(F6e);jvr=r(Qwt,"xlm-roberta"),Qwt.forEach(t),Dvr=r(YIe," \u2014 "),oU=n(YIe,"A",{href:!0});var Wwt=s(oU);Gvr=r(Wwt,"TFXLMRobertaModel"),Wwt.forEach(t),Ovr=r(YIe," (XLM-RoBERTa model)"),YIe.forEach(t),Vvr=i(D),G8=n(D,"LI",{});var KIe=s(G8);T6e=n(KIe,"STRONG",{});var Hwt=s(T6e);Xvr=r(Hwt,"xlnet"),Hwt.forEach(t),zvr=r(KIe," \u2014 "),rU=n(KIe,"A",{href:!0});var Uwt=s(rU);Qvr=r(Uwt,"TFXLNetModel"),Uwt.forEach(t),Wvr=r(KIe," (XLNet model)"),KIe.forEach(t),D.forEach(t),Hvr=i(Cl),T(O8.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),sVe=i(f),tc=n(f,"H2",{class:!0});var hze=s(tc);V8=n(hze,"A",{id:!0,class:!0,href:!0});var Jwt=s(V8);M6e=n(Jwt,"SPAN",{});var Ywt=s(M6e);T(E9.$$.fragment,Ywt),Ywt.forEach(t),Jwt.forEach(t),Uvr=i(hze),E6e=n(hze,"SPAN",{});var Kwt=s(E6e);Jvr=r(Kwt,"TFAutoModelForPreTraining"),Kwt.forEach(t),hze.forEach(t),lVe=i(f),or=n(f,"DIV",{class:!0});var wl=s(or);T(C9.$$.fragment,wl),Yvr=i(wl),ac=n(wl,"P",{});var Fre=s(ac);Kvr=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),tU=n(Fre,"A",{href:!0});var Zwt=s(tU);Zvr=r(Zwt,"from_pretrained()"),Zwt.forEach(t),eFr=r(Fre," class method or the "),aU=n(Fre,"A",{href:!0});var eAt=s(aU);oFr=r(eAt,"from_config()"),eAt.forEach(t),rFr=r(Fre,` class
method.`),Fre.forEach(t),tFr=i(wl),w9=n(wl,"P",{});var pze=s(w9);aFr=r(pze,"This class cannot be instantiated directly using "),C6e=n(pze,"CODE",{});var oAt=s(C6e);nFr=r(oAt,"__init__()"),oAt.forEach(t),sFr=r(pze," (throws an error)."),pze.forEach(t),lFr=i(wl),kt=n(wl,"DIV",{class:!0});var kw=s(kt);T(A9.$$.fragment,kw),iFr=i(kw),w6e=n(kw,"P",{});var rAt=s(w6e);dFr=r(rAt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),rAt.forEach(t),cFr=i(kw),nc=n(kw,"P",{});var Tre=s(nc);fFr=r(Tre,`Note:
Loading a model from its configuration file does `),A6e=n(Tre,"STRONG",{});var tAt=s(A6e);mFr=r(tAt,"not"),tAt.forEach(t),gFr=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=n(Tre,"A",{href:!0});var aAt=s(nU);hFr=r(aAt,"from_pretrained()"),aAt.forEach(t),pFr=r(Tre," to load the model weights."),Tre.forEach(t),_Fr=i(kw),T(X8.$$.fragment,kw),kw.forEach(t),uFr=i(wl),xr=n(wl,"DIV",{class:!0});var Al=s(xr);T(L9.$$.fragment,Al),bFr=i(Al),L6e=n(Al,"P",{});var nAt=s(L6e);vFr=r(nAt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),nAt.forEach(t),FFr=i(Al),nn=n(Al,"P",{});var Sw=s(nn);TFr=r(Sw,"The model class to instantiate is selected based on the "),y6e=n(Sw,"CODE",{});var sAt=s(y6e);MFr=r(sAt,"model_type"),sAt.forEach(t),EFr=r(Sw,` property of the config object (either
passed as an argument or loaded from `),x6e=n(Sw,"CODE",{});var lAt=s(x6e);CFr=r(lAt,"pretrained_model_name_or_path"),lAt.forEach(t),wFr=r(Sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$6e=n(Sw,"CODE",{});var iAt=s($6e);AFr=r(iAt,"pretrained_model_name_or_path"),iAt.forEach(t),LFr=r(Sw,":"),Sw.forEach(t),yFr=i(Al),se=n(Al,"UL",{});var le=s(se);z8=n(le,"LI",{});var ZIe=s(z8);k6e=n(ZIe,"STRONG",{});var dAt=s(k6e);xFr=r(dAt,"albert"),dAt.forEach(t),$Fr=r(ZIe," \u2014 "),sU=n(ZIe,"A",{href:!0});var cAt=s(sU);kFr=r(cAt,"TFAlbertForPreTraining"),cAt.forEach(t),SFr=r(ZIe," (ALBERT model)"),ZIe.forEach(t),RFr=i(le),Q8=n(le,"LI",{});var eNe=s(Q8);S6e=n(eNe,"STRONG",{});var fAt=s(S6e);PFr=r(fAt,"bart"),fAt.forEach(t),BFr=r(eNe," \u2014 "),lU=n(eNe,"A",{href:!0});var mAt=s(lU);IFr=r(mAt,"TFBartForConditionalGeneration"),mAt.forEach(t),NFr=r(eNe," (BART model)"),eNe.forEach(t),qFr=i(le),W8=n(le,"LI",{});var oNe=s(W8);R6e=n(oNe,"STRONG",{});var gAt=s(R6e);jFr=r(gAt,"bert"),gAt.forEach(t),DFr=r(oNe," \u2014 "),iU=n(oNe,"A",{href:!0});var hAt=s(iU);GFr=r(hAt,"TFBertForPreTraining"),hAt.forEach(t),OFr=r(oNe," (BERT model)"),oNe.forEach(t),VFr=i(le),H8=n(le,"LI",{});var rNe=s(H8);P6e=n(rNe,"STRONG",{});var pAt=s(P6e);XFr=r(pAt,"camembert"),pAt.forEach(t),zFr=r(rNe," \u2014 "),dU=n(rNe,"A",{href:!0});var _At=s(dU);QFr=r(_At,"TFCamembertForMaskedLM"),_At.forEach(t),WFr=r(rNe," (CamemBERT model)"),rNe.forEach(t),HFr=i(le),U8=n(le,"LI",{});var tNe=s(U8);B6e=n(tNe,"STRONG",{});var uAt=s(B6e);UFr=r(uAt,"ctrl"),uAt.forEach(t),JFr=r(tNe," \u2014 "),cU=n(tNe,"A",{href:!0});var bAt=s(cU);YFr=r(bAt,"TFCTRLLMHeadModel"),bAt.forEach(t),KFr=r(tNe," (CTRL model)"),tNe.forEach(t),ZFr=i(le),J8=n(le,"LI",{});var aNe=s(J8);I6e=n(aNe,"STRONG",{});var vAt=s(I6e);e6r=r(vAt,"distilbert"),vAt.forEach(t),o6r=r(aNe," \u2014 "),fU=n(aNe,"A",{href:!0});var FAt=s(fU);r6r=r(FAt,"TFDistilBertForMaskedLM"),FAt.forEach(t),t6r=r(aNe," (DistilBERT model)"),aNe.forEach(t),a6r=i(le),Y8=n(le,"LI",{});var nNe=s(Y8);N6e=n(nNe,"STRONG",{});var TAt=s(N6e);n6r=r(TAt,"electra"),TAt.forEach(t),s6r=r(nNe," \u2014 "),mU=n(nNe,"A",{href:!0});var MAt=s(mU);l6r=r(MAt,"TFElectraForPreTraining"),MAt.forEach(t),i6r=r(nNe," (ELECTRA model)"),nNe.forEach(t),d6r=i(le),K8=n(le,"LI",{});var sNe=s(K8);q6e=n(sNe,"STRONG",{});var EAt=s(q6e);c6r=r(EAt,"flaubert"),EAt.forEach(t),f6r=r(sNe," \u2014 "),gU=n(sNe,"A",{href:!0});var CAt=s(gU);m6r=r(CAt,"TFFlaubertWithLMHeadModel"),CAt.forEach(t),g6r=r(sNe," (FlauBERT model)"),sNe.forEach(t),h6r=i(le),Z8=n(le,"LI",{});var lNe=s(Z8);j6e=n(lNe,"STRONG",{});var wAt=s(j6e);p6r=r(wAt,"funnel"),wAt.forEach(t),_6r=r(lNe," \u2014 "),hU=n(lNe,"A",{href:!0});var AAt=s(hU);u6r=r(AAt,"TFFunnelForPreTraining"),AAt.forEach(t),b6r=r(lNe," (Funnel Transformer model)"),lNe.forEach(t),v6r=i(le),eM=n(le,"LI",{});var iNe=s(eM);D6e=n(iNe,"STRONG",{});var LAt=s(D6e);F6r=r(LAt,"gpt2"),LAt.forEach(t),T6r=r(iNe," \u2014 "),pU=n(iNe,"A",{href:!0});var yAt=s(pU);M6r=r(yAt,"TFGPT2LMHeadModel"),yAt.forEach(t),E6r=r(iNe," (OpenAI GPT-2 model)"),iNe.forEach(t),C6r=i(le),oM=n(le,"LI",{});var dNe=s(oM);G6e=n(dNe,"STRONG",{});var xAt=s(G6e);w6r=r(xAt,"layoutlm"),xAt.forEach(t),A6r=r(dNe," \u2014 "),_U=n(dNe,"A",{href:!0});var $At=s(_U);L6r=r($At,"TFLayoutLMForMaskedLM"),$At.forEach(t),y6r=r(dNe," (LayoutLM model)"),dNe.forEach(t),x6r=i(le),rM=n(le,"LI",{});var cNe=s(rM);O6e=n(cNe,"STRONG",{});var kAt=s(O6e);$6r=r(kAt,"lxmert"),kAt.forEach(t),k6r=r(cNe," \u2014 "),uU=n(cNe,"A",{href:!0});var SAt=s(uU);S6r=r(SAt,"TFLxmertForPreTraining"),SAt.forEach(t),R6r=r(cNe," (LXMERT model)"),cNe.forEach(t),P6r=i(le),tM=n(le,"LI",{});var fNe=s(tM);V6e=n(fNe,"STRONG",{});var RAt=s(V6e);B6r=r(RAt,"mobilebert"),RAt.forEach(t),I6r=r(fNe," \u2014 "),bU=n(fNe,"A",{href:!0});var PAt=s(bU);N6r=r(PAt,"TFMobileBertForPreTraining"),PAt.forEach(t),q6r=r(fNe," (MobileBERT model)"),fNe.forEach(t),j6r=i(le),aM=n(le,"LI",{});var mNe=s(aM);X6e=n(mNe,"STRONG",{});var BAt=s(X6e);D6r=r(BAt,"mpnet"),BAt.forEach(t),G6r=r(mNe," \u2014 "),vU=n(mNe,"A",{href:!0});var IAt=s(vU);O6r=r(IAt,"TFMPNetForMaskedLM"),IAt.forEach(t),V6r=r(mNe," (MPNet model)"),mNe.forEach(t),X6r=i(le),nM=n(le,"LI",{});var gNe=s(nM);z6e=n(gNe,"STRONG",{});var NAt=s(z6e);z6r=r(NAt,"openai-gpt"),NAt.forEach(t),Q6r=r(gNe," \u2014 "),FU=n(gNe,"A",{href:!0});var qAt=s(FU);W6r=r(qAt,"TFOpenAIGPTLMHeadModel"),qAt.forEach(t),H6r=r(gNe," (OpenAI GPT model)"),gNe.forEach(t),U6r=i(le),sM=n(le,"LI",{});var hNe=s(sM);Q6e=n(hNe,"STRONG",{});var jAt=s(Q6e);J6r=r(jAt,"roberta"),jAt.forEach(t),Y6r=r(hNe," \u2014 "),TU=n(hNe,"A",{href:!0});var DAt=s(TU);K6r=r(DAt,"TFRobertaForMaskedLM"),DAt.forEach(t),Z6r=r(hNe," (RoBERTa model)"),hNe.forEach(t),eTr=i(le),lM=n(le,"LI",{});var pNe=s(lM);W6e=n(pNe,"STRONG",{});var GAt=s(W6e);oTr=r(GAt,"t5"),GAt.forEach(t),rTr=r(pNe," \u2014 "),MU=n(pNe,"A",{href:!0});var OAt=s(MU);tTr=r(OAt,"TFT5ForConditionalGeneration"),OAt.forEach(t),aTr=r(pNe," (T5 model)"),pNe.forEach(t),nTr=i(le),iM=n(le,"LI",{});var _Ne=s(iM);H6e=n(_Ne,"STRONG",{});var VAt=s(H6e);sTr=r(VAt,"tapas"),VAt.forEach(t),lTr=r(_Ne," \u2014 "),EU=n(_Ne,"A",{href:!0});var XAt=s(EU);iTr=r(XAt,"TFTapasForMaskedLM"),XAt.forEach(t),dTr=r(_Ne," (TAPAS model)"),_Ne.forEach(t),cTr=i(le),dM=n(le,"LI",{});var uNe=s(dM);U6e=n(uNe,"STRONG",{});var zAt=s(U6e);fTr=r(zAt,"transfo-xl"),zAt.forEach(t),mTr=r(uNe," \u2014 "),CU=n(uNe,"A",{href:!0});var QAt=s(CU);gTr=r(QAt,"TFTransfoXLLMHeadModel"),QAt.forEach(t),hTr=r(uNe," (Transformer-XL model)"),uNe.forEach(t),pTr=i(le),cM=n(le,"LI",{});var bNe=s(cM);J6e=n(bNe,"STRONG",{});var WAt=s(J6e);_Tr=r(WAt,"vit_mae"),WAt.forEach(t),uTr=r(bNe," \u2014 "),wU=n(bNe,"A",{href:!0});var HAt=s(wU);bTr=r(HAt,"TFViTMAEForPreTraining"),HAt.forEach(t),vTr=r(bNe," (ViTMAE model)"),bNe.forEach(t),FTr=i(le),fM=n(le,"LI",{});var vNe=s(fM);Y6e=n(vNe,"STRONG",{});var UAt=s(Y6e);TTr=r(UAt,"xlm"),UAt.forEach(t),MTr=r(vNe," \u2014 "),AU=n(vNe,"A",{href:!0});var JAt=s(AU);ETr=r(JAt,"TFXLMWithLMHeadModel"),JAt.forEach(t),CTr=r(vNe," (XLM model)"),vNe.forEach(t),wTr=i(le),mM=n(le,"LI",{});var FNe=s(mM);K6e=n(FNe,"STRONG",{});var YAt=s(K6e);ATr=r(YAt,"xlm-roberta"),YAt.forEach(t),LTr=r(FNe," \u2014 "),LU=n(FNe,"A",{href:!0});var KAt=s(LU);yTr=r(KAt,"TFXLMRobertaForMaskedLM"),KAt.forEach(t),xTr=r(FNe," (XLM-RoBERTa model)"),FNe.forEach(t),$Tr=i(le),gM=n(le,"LI",{});var TNe=s(gM);Z6e=n(TNe,"STRONG",{});var ZAt=s(Z6e);kTr=r(ZAt,"xlnet"),ZAt.forEach(t),STr=r(TNe," \u2014 "),yU=n(TNe,"A",{href:!0});var eLt=s(yU);RTr=r(eLt,"TFXLNetLMHeadModel"),eLt.forEach(t),PTr=r(TNe," (XLNet model)"),TNe.forEach(t),le.forEach(t),BTr=i(Al),T(hM.$$.fragment,Al),Al.forEach(t),wl.forEach(t),iVe=i(f),sc=n(f,"H2",{class:!0});var _ze=s(sc);pM=n(_ze,"A",{id:!0,class:!0,href:!0});var oLt=s(pM);eTe=n(oLt,"SPAN",{});var rLt=s(eTe);T(y9.$$.fragment,rLt),rLt.forEach(t),oLt.forEach(t),ITr=i(_ze),oTe=n(_ze,"SPAN",{});var tLt=s(oTe);NTr=r(tLt,"TFAutoModelForCausalLM"),tLt.forEach(t),_ze.forEach(t),dVe=i(f),rr=n(f,"DIV",{class:!0});var Ll=s(rr);T(x9.$$.fragment,Ll),qTr=i(Ll),lc=n(Ll,"P",{});var Mre=s(lc);jTr=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),xU=n(Mre,"A",{href:!0});var aLt=s(xU);DTr=r(aLt,"from_pretrained()"),aLt.forEach(t),GTr=r(Mre," class method or the "),$U=n(Mre,"A",{href:!0});var nLt=s($U);OTr=r(nLt,"from_config()"),nLt.forEach(t),VTr=r(Mre,` class
method.`),Mre.forEach(t),XTr=i(Ll),$9=n(Ll,"P",{});var uze=s($9);zTr=r(uze,"This class cannot be instantiated directly using "),rTe=n(uze,"CODE",{});var sLt=s(rTe);QTr=r(sLt,"__init__()"),sLt.forEach(t),WTr=r(uze," (throws an error)."),uze.forEach(t),HTr=i(Ll),St=n(Ll,"DIV",{class:!0});var Rw=s(St);T(k9.$$.fragment,Rw),UTr=i(Rw),tTe=n(Rw,"P",{});var lLt=s(tTe);JTr=r(lLt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lLt.forEach(t),YTr=i(Rw),ic=n(Rw,"P",{});var Ere=s(ic);KTr=r(Ere,`Note:
Loading a model from its configuration file does `),aTe=n(Ere,"STRONG",{});var iLt=s(aTe);ZTr=r(iLt,"not"),iLt.forEach(t),e7r=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),kU=n(Ere,"A",{href:!0});var dLt=s(kU);o7r=r(dLt,"from_pretrained()"),dLt.forEach(t),r7r=r(Ere," to load the model weights."),Ere.forEach(t),t7r=i(Rw),T(_M.$$.fragment,Rw),Rw.forEach(t),a7r=i(Ll),$r=n(Ll,"DIV",{class:!0});var yl=s($r);T(S9.$$.fragment,yl),n7r=i(yl),nTe=n(yl,"P",{});var cLt=s(nTe);s7r=r(cLt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cLt.forEach(t),l7r=i(yl),sn=n(yl,"P",{});var Pw=s(sn);i7r=r(Pw,"The model class to instantiate is selected based on the "),sTe=n(Pw,"CODE",{});var fLt=s(sTe);d7r=r(fLt,"model_type"),fLt.forEach(t),c7r=r(Pw,` property of the config object (either
passed as an argument or loaded from `),lTe=n(Pw,"CODE",{});var mLt=s(lTe);f7r=r(mLt,"pretrained_model_name_or_path"),mLt.forEach(t),m7r=r(Pw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=n(Pw,"CODE",{});var gLt=s(iTe);g7r=r(gLt,"pretrained_model_name_or_path"),gLt.forEach(t),h7r=r(Pw,":"),Pw.forEach(t),p7r=i(yl),Me=n(yl,"UL",{});var Ce=s(Me);uM=n(Ce,"LI",{});var MNe=s(uM);dTe=n(MNe,"STRONG",{});var hLt=s(dTe);_7r=r(hLt,"bert"),hLt.forEach(t),u7r=r(MNe," \u2014 "),SU=n(MNe,"A",{href:!0});var pLt=s(SU);b7r=r(pLt,"TFBertLMHeadModel"),pLt.forEach(t),v7r=r(MNe," (BERT model)"),MNe.forEach(t),F7r=i(Ce),bM=n(Ce,"LI",{});var ENe=s(bM);cTe=n(ENe,"STRONG",{});var _Lt=s(cTe);T7r=r(_Lt,"camembert"),_Lt.forEach(t),M7r=r(ENe," \u2014 "),RU=n(ENe,"A",{href:!0});var uLt=s(RU);E7r=r(uLt,"TFCamembertForCausalLM"),uLt.forEach(t),C7r=r(ENe," (CamemBERT model)"),ENe.forEach(t),w7r=i(Ce),vM=n(Ce,"LI",{});var CNe=s(vM);fTe=n(CNe,"STRONG",{});var bLt=s(fTe);A7r=r(bLt,"ctrl"),bLt.forEach(t),L7r=r(CNe," \u2014 "),PU=n(CNe,"A",{href:!0});var vLt=s(PU);y7r=r(vLt,"TFCTRLLMHeadModel"),vLt.forEach(t),x7r=r(CNe," (CTRL model)"),CNe.forEach(t),$7r=i(Ce),FM=n(Ce,"LI",{});var wNe=s(FM);mTe=n(wNe,"STRONG",{});var FLt=s(mTe);k7r=r(FLt,"gpt2"),FLt.forEach(t),S7r=r(wNe," \u2014 "),BU=n(wNe,"A",{href:!0});var TLt=s(BU);R7r=r(TLt,"TFGPT2LMHeadModel"),TLt.forEach(t),P7r=r(wNe," (OpenAI GPT-2 model)"),wNe.forEach(t),B7r=i(Ce),TM=n(Ce,"LI",{});var ANe=s(TM);gTe=n(ANe,"STRONG",{});var MLt=s(gTe);I7r=r(MLt,"gptj"),MLt.forEach(t),N7r=r(ANe," \u2014 "),IU=n(ANe,"A",{href:!0});var ELt=s(IU);q7r=r(ELt,"TFGPTJForCausalLM"),ELt.forEach(t),j7r=r(ANe," (GPT-J model)"),ANe.forEach(t),D7r=i(Ce),MM=n(Ce,"LI",{});var LNe=s(MM);hTe=n(LNe,"STRONG",{});var CLt=s(hTe);G7r=r(CLt,"openai-gpt"),CLt.forEach(t),O7r=r(LNe," \u2014 "),NU=n(LNe,"A",{href:!0});var wLt=s(NU);V7r=r(wLt,"TFOpenAIGPTLMHeadModel"),wLt.forEach(t),X7r=r(LNe," (OpenAI GPT model)"),LNe.forEach(t),z7r=i(Ce),EM=n(Ce,"LI",{});var yNe=s(EM);pTe=n(yNe,"STRONG",{});var ALt=s(pTe);Q7r=r(ALt,"opt"),ALt.forEach(t),W7r=r(yNe," \u2014 "),qU=n(yNe,"A",{href:!0});var LLt=s(qU);H7r=r(LLt,"TFOPTForCausalLM"),LLt.forEach(t),U7r=r(yNe," (OPT model)"),yNe.forEach(t),J7r=i(Ce),CM=n(Ce,"LI",{});var xNe=s(CM);_Te=n(xNe,"STRONG",{});var yLt=s(_Te);Y7r=r(yLt,"rembert"),yLt.forEach(t),K7r=r(xNe," \u2014 "),jU=n(xNe,"A",{href:!0});var xLt=s(jU);Z7r=r(xLt,"TFRemBertForCausalLM"),xLt.forEach(t),e8r=r(xNe," (RemBERT model)"),xNe.forEach(t),o8r=i(Ce),wM=n(Ce,"LI",{});var $Ne=s(wM);uTe=n($Ne,"STRONG",{});var $Lt=s(uTe);r8r=r($Lt,"roberta"),$Lt.forEach(t),t8r=r($Ne," \u2014 "),DU=n($Ne,"A",{href:!0});var kLt=s(DU);a8r=r(kLt,"TFRobertaForCausalLM"),kLt.forEach(t),n8r=r($Ne," (RoBERTa model)"),$Ne.forEach(t),s8r=i(Ce),AM=n(Ce,"LI",{});var kNe=s(AM);bTe=n(kNe,"STRONG",{});var SLt=s(bTe);l8r=r(SLt,"roformer"),SLt.forEach(t),i8r=r(kNe," \u2014 "),GU=n(kNe,"A",{href:!0});var RLt=s(GU);d8r=r(RLt,"TFRoFormerForCausalLM"),RLt.forEach(t),c8r=r(kNe," (RoFormer model)"),kNe.forEach(t),f8r=i(Ce),LM=n(Ce,"LI",{});var SNe=s(LM);vTe=n(SNe,"STRONG",{});var PLt=s(vTe);m8r=r(PLt,"transfo-xl"),PLt.forEach(t),g8r=r(SNe," \u2014 "),OU=n(SNe,"A",{href:!0});var BLt=s(OU);h8r=r(BLt,"TFTransfoXLLMHeadModel"),BLt.forEach(t),p8r=r(SNe," (Transformer-XL model)"),SNe.forEach(t),_8r=i(Ce),yM=n(Ce,"LI",{});var RNe=s(yM);FTe=n(RNe,"STRONG",{});var ILt=s(FTe);u8r=r(ILt,"xlm"),ILt.forEach(t),b8r=r(RNe," \u2014 "),VU=n(RNe,"A",{href:!0});var NLt=s(VU);v8r=r(NLt,"TFXLMWithLMHeadModel"),NLt.forEach(t),F8r=r(RNe," (XLM model)"),RNe.forEach(t),T8r=i(Ce),xM=n(Ce,"LI",{});var PNe=s(xM);TTe=n(PNe,"STRONG",{});var qLt=s(TTe);M8r=r(qLt,"xlnet"),qLt.forEach(t),E8r=r(PNe," \u2014 "),XU=n(PNe,"A",{href:!0});var jLt=s(XU);C8r=r(jLt,"TFXLNetLMHeadModel"),jLt.forEach(t),w8r=r(PNe," (XLNet model)"),PNe.forEach(t),Ce.forEach(t),A8r=i(yl),T($M.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),cVe=i(f),dc=n(f,"H2",{class:!0});var bze=s(dc);kM=n(bze,"A",{id:!0,class:!0,href:!0});var DLt=s(kM);MTe=n(DLt,"SPAN",{});var GLt=s(MTe);T(R9.$$.fragment,GLt),GLt.forEach(t),DLt.forEach(t),L8r=i(bze),ETe=n(bze,"SPAN",{});var OLt=s(ETe);y8r=r(OLt,"TFAutoModelForImageClassification"),OLt.forEach(t),bze.forEach(t),fVe=i(f),tr=n(f,"DIV",{class:!0});var xl=s(tr);T(P9.$$.fragment,xl),x8r=i(xl),cc=n(xl,"P",{});var Cre=s(cc);$8r=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),zU=n(Cre,"A",{href:!0});var VLt=s(zU);k8r=r(VLt,"from_pretrained()"),VLt.forEach(t),S8r=r(Cre," class method or the "),QU=n(Cre,"A",{href:!0});var XLt=s(QU);R8r=r(XLt,"from_config()"),XLt.forEach(t),P8r=r(Cre,` class
method.`),Cre.forEach(t),B8r=i(xl),B9=n(xl,"P",{});var vze=s(B9);I8r=r(vze,"This class cannot be instantiated directly using "),CTe=n(vze,"CODE",{});var zLt=s(CTe);N8r=r(zLt,"__init__()"),zLt.forEach(t),q8r=r(vze," (throws an error)."),vze.forEach(t),j8r=i(xl),Rt=n(xl,"DIV",{class:!0});var Bw=s(Rt);T(I9.$$.fragment,Bw),D8r=i(Bw),wTe=n(Bw,"P",{});var QLt=s(wTe);G8r=r(QLt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),QLt.forEach(t),O8r=i(Bw),fc=n(Bw,"P",{});var wre=s(fc);V8r=r(wre,`Note:
Loading a model from its configuration file does `),ATe=n(wre,"STRONG",{});var WLt=s(ATe);X8r=r(WLt,"not"),WLt.forEach(t),z8r=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=n(wre,"A",{href:!0});var HLt=s(WU);Q8r=r(HLt,"from_pretrained()"),HLt.forEach(t),W8r=r(wre," to load the model weights."),wre.forEach(t),H8r=i(Bw),T(SM.$$.fragment,Bw),Bw.forEach(t),U8r=i(xl),kr=n(xl,"DIV",{class:!0});var $l=s(kr);T(N9.$$.fragment,$l),J8r=i($l),LTe=n($l,"P",{});var ULt=s(LTe);Y8r=r(ULt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),ULt.forEach(t),K8r=i($l),ln=n($l,"P",{});var Iw=s(ln);Z8r=r(Iw,"The model class to instantiate is selected based on the "),yTe=n(Iw,"CODE",{});var JLt=s(yTe);eMr=r(JLt,"model_type"),JLt.forEach(t),oMr=r(Iw,` property of the config object (either
passed as an argument or loaded from `),xTe=n(Iw,"CODE",{});var YLt=s(xTe);rMr=r(YLt,"pretrained_model_name_or_path"),YLt.forEach(t),tMr=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Te=n(Iw,"CODE",{});var KLt=s($Te);aMr=r(KLt,"pretrained_model_name_or_path"),KLt.forEach(t),nMr=r(Iw,":"),Iw.forEach(t),sMr=i($l),dn=n($l,"UL",{});var Nw=s(dn);RM=n(Nw,"LI",{});var BNe=s(RM);kTe=n(BNe,"STRONG",{});var ZLt=s(kTe);lMr=r(ZLt,"convnext"),ZLt.forEach(t),iMr=r(BNe," \u2014 "),HU=n(BNe,"A",{href:!0});var eyt=s(HU);dMr=r(eyt,"TFConvNextForImageClassification"),eyt.forEach(t),cMr=r(BNe," (ConvNeXT model)"),BNe.forEach(t),fMr=i(Nw),PM=n(Nw,"LI",{});var INe=s(PM);STe=n(INe,"STRONG",{});var oyt=s(STe);mMr=r(oyt,"data2vec-vision"),oyt.forEach(t),gMr=r(INe," \u2014 "),UU=n(INe,"A",{href:!0});var ryt=s(UU);hMr=r(ryt,"TFData2VecVisionForImageClassification"),ryt.forEach(t),pMr=r(INe," (Data2VecVision model)"),INe.forEach(t),_Mr=i(Nw),BM=n(Nw,"LI",{});var NNe=s(BM);RTe=n(NNe,"STRONG",{});var tyt=s(RTe);uMr=r(tyt,"swin"),tyt.forEach(t),bMr=r(NNe," \u2014 "),JU=n(NNe,"A",{href:!0});var ayt=s(JU);vMr=r(ayt,"TFSwinForImageClassification"),ayt.forEach(t),FMr=r(NNe," (Swin Transformer model)"),NNe.forEach(t),TMr=i(Nw),IM=n(Nw,"LI",{});var qNe=s(IM);PTe=n(qNe,"STRONG",{});var nyt=s(PTe);MMr=r(nyt,"vit"),nyt.forEach(t),EMr=r(qNe," \u2014 "),YU=n(qNe,"A",{href:!0});var syt=s(YU);CMr=r(syt,"TFViTForImageClassification"),syt.forEach(t),wMr=r(qNe," (ViT model)"),qNe.forEach(t),Nw.forEach(t),AMr=i($l),T(NM.$$.fragment,$l),$l.forEach(t),xl.forEach(t),mVe=i(f),mc=n(f,"H2",{class:!0});var Fze=s(mc);qM=n(Fze,"A",{id:!0,class:!0,href:!0});var lyt=s(qM);BTe=n(lyt,"SPAN",{});var iyt=s(BTe);T(q9.$$.fragment,iyt),iyt.forEach(t),lyt.forEach(t),LMr=i(Fze),ITe=n(Fze,"SPAN",{});var dyt=s(ITe);yMr=r(dyt,"TFAutoModelForMaskedLM"),dyt.forEach(t),Fze.forEach(t),gVe=i(f),ar=n(f,"DIV",{class:!0});var kl=s(ar);T(j9.$$.fragment,kl),xMr=i(kl),gc=n(kl,"P",{});var Are=s(gc);$Mr=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KU=n(Are,"A",{href:!0});var cyt=s(KU);kMr=r(cyt,"from_pretrained()"),cyt.forEach(t),SMr=r(Are," class method or the "),ZU=n(Are,"A",{href:!0});var fyt=s(ZU);RMr=r(fyt,"from_config()"),fyt.forEach(t),PMr=r(Are,` class
method.`),Are.forEach(t),BMr=i(kl),D9=n(kl,"P",{});var Tze=s(D9);IMr=r(Tze,"This class cannot be instantiated directly using "),NTe=n(Tze,"CODE",{});var myt=s(NTe);NMr=r(myt,"__init__()"),myt.forEach(t),qMr=r(Tze," (throws an error)."),Tze.forEach(t),jMr=i(kl),Pt=n(kl,"DIV",{class:!0});var qw=s(Pt);T(G9.$$.fragment,qw),DMr=i(qw),qTe=n(qw,"P",{});var gyt=s(qTe);GMr=r(gyt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),gyt.forEach(t),OMr=i(qw),hc=n(qw,"P",{});var Lre=s(hc);VMr=r(Lre,`Note:
Loading a model from its configuration file does `),jTe=n(Lre,"STRONG",{});var hyt=s(jTe);XMr=r(hyt,"not"),hyt.forEach(t),zMr=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=n(Lre,"A",{href:!0});var pyt=s(eJ);QMr=r(pyt,"from_pretrained()"),pyt.forEach(t),WMr=r(Lre," to load the model weights."),Lre.forEach(t),HMr=i(qw),T(jM.$$.fragment,qw),qw.forEach(t),UMr=i(kl),Sr=n(kl,"DIV",{class:!0});var Sl=s(Sr);T(O9.$$.fragment,Sl),JMr=i(Sl),DTe=n(Sl,"P",{});var _yt=s(DTe);YMr=r(_yt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_yt.forEach(t),KMr=i(Sl),cn=n(Sl,"P",{});var jw=s(cn);ZMr=r(jw,"The model class to instantiate is selected based on the "),GTe=n(jw,"CODE",{});var uyt=s(GTe);eEr=r(uyt,"model_type"),uyt.forEach(t),oEr=r(jw,` property of the config object (either
passed as an argument or loaded from `),OTe=n(jw,"CODE",{});var byt=s(OTe);rEr=r(byt,"pretrained_model_name_or_path"),byt.forEach(t),tEr=r(jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VTe=n(jw,"CODE",{});var vyt=s(VTe);aEr=r(vyt,"pretrained_model_name_or_path"),vyt.forEach(t),nEr=r(jw,":"),jw.forEach(t),sEr=i(Sl),ie=n(Sl,"UL",{});var fe=s(ie);DM=n(fe,"LI",{});var jNe=s(DM);XTe=n(jNe,"STRONG",{});var Fyt=s(XTe);lEr=r(Fyt,"albert"),Fyt.forEach(t),iEr=r(jNe," \u2014 "),oJ=n(jNe,"A",{href:!0});var Tyt=s(oJ);dEr=r(Tyt,"TFAlbertForMaskedLM"),Tyt.forEach(t),cEr=r(jNe," (ALBERT model)"),jNe.forEach(t),fEr=i(fe),GM=n(fe,"LI",{});var DNe=s(GM);zTe=n(DNe,"STRONG",{});var Myt=s(zTe);mEr=r(Myt,"bert"),Myt.forEach(t),gEr=r(DNe," \u2014 "),rJ=n(DNe,"A",{href:!0});var Eyt=s(rJ);hEr=r(Eyt,"TFBertForMaskedLM"),Eyt.forEach(t),pEr=r(DNe," (BERT model)"),DNe.forEach(t),_Er=i(fe),OM=n(fe,"LI",{});var GNe=s(OM);QTe=n(GNe,"STRONG",{});var Cyt=s(QTe);uEr=r(Cyt,"camembert"),Cyt.forEach(t),bEr=r(GNe," \u2014 "),tJ=n(GNe,"A",{href:!0});var wyt=s(tJ);vEr=r(wyt,"TFCamembertForMaskedLM"),wyt.forEach(t),FEr=r(GNe," (CamemBERT model)"),GNe.forEach(t),TEr=i(fe),VM=n(fe,"LI",{});var ONe=s(VM);WTe=n(ONe,"STRONG",{});var Ayt=s(WTe);MEr=r(Ayt,"convbert"),Ayt.forEach(t),EEr=r(ONe," \u2014 "),aJ=n(ONe,"A",{href:!0});var Lyt=s(aJ);CEr=r(Lyt,"TFConvBertForMaskedLM"),Lyt.forEach(t),wEr=r(ONe," (ConvBERT model)"),ONe.forEach(t),AEr=i(fe),XM=n(fe,"LI",{});var VNe=s(XM);HTe=n(VNe,"STRONG",{});var yyt=s(HTe);LEr=r(yyt,"deberta"),yyt.forEach(t),yEr=r(VNe," \u2014 "),nJ=n(VNe,"A",{href:!0});var xyt=s(nJ);xEr=r(xyt,"TFDebertaForMaskedLM"),xyt.forEach(t),$Er=r(VNe," (DeBERTa model)"),VNe.forEach(t),kEr=i(fe),zM=n(fe,"LI",{});var XNe=s(zM);UTe=n(XNe,"STRONG",{});var $yt=s(UTe);SEr=r($yt,"deberta-v2"),$yt.forEach(t),REr=r(XNe," \u2014 "),sJ=n(XNe,"A",{href:!0});var kyt=s(sJ);PEr=r(kyt,"TFDebertaV2ForMaskedLM"),kyt.forEach(t),BEr=r(XNe," (DeBERTa-v2 model)"),XNe.forEach(t),IEr=i(fe),QM=n(fe,"LI",{});var zNe=s(QM);JTe=n(zNe,"STRONG",{});var Syt=s(JTe);NEr=r(Syt,"distilbert"),Syt.forEach(t),qEr=r(zNe," \u2014 "),lJ=n(zNe,"A",{href:!0});var Ryt=s(lJ);jEr=r(Ryt,"TFDistilBertForMaskedLM"),Ryt.forEach(t),DEr=r(zNe," (DistilBERT model)"),zNe.forEach(t),GEr=i(fe),WM=n(fe,"LI",{});var QNe=s(WM);YTe=n(QNe,"STRONG",{});var Pyt=s(YTe);OEr=r(Pyt,"electra"),Pyt.forEach(t),VEr=r(QNe," \u2014 "),iJ=n(QNe,"A",{href:!0});var Byt=s(iJ);XEr=r(Byt,"TFElectraForMaskedLM"),Byt.forEach(t),zEr=r(QNe," (ELECTRA model)"),QNe.forEach(t),QEr=i(fe),HM=n(fe,"LI",{});var WNe=s(HM);KTe=n(WNe,"STRONG",{});var Iyt=s(KTe);WEr=r(Iyt,"flaubert"),Iyt.forEach(t),HEr=r(WNe," \u2014 "),dJ=n(WNe,"A",{href:!0});var Nyt=s(dJ);UEr=r(Nyt,"TFFlaubertWithLMHeadModel"),Nyt.forEach(t),JEr=r(WNe," (FlauBERT model)"),WNe.forEach(t),YEr=i(fe),UM=n(fe,"LI",{});var HNe=s(UM);ZTe=n(HNe,"STRONG",{});var qyt=s(ZTe);KEr=r(qyt,"funnel"),qyt.forEach(t),ZEr=r(HNe," \u2014 "),cJ=n(HNe,"A",{href:!0});var jyt=s(cJ);e4r=r(jyt,"TFFunnelForMaskedLM"),jyt.forEach(t),o4r=r(HNe," (Funnel Transformer model)"),HNe.forEach(t),r4r=i(fe),JM=n(fe,"LI",{});var UNe=s(JM);e7e=n(UNe,"STRONG",{});var Dyt=s(e7e);t4r=r(Dyt,"layoutlm"),Dyt.forEach(t),a4r=r(UNe," \u2014 "),fJ=n(UNe,"A",{href:!0});var Gyt=s(fJ);n4r=r(Gyt,"TFLayoutLMForMaskedLM"),Gyt.forEach(t),s4r=r(UNe," (LayoutLM model)"),UNe.forEach(t),l4r=i(fe),YM=n(fe,"LI",{});var JNe=s(YM);o7e=n(JNe,"STRONG",{});var Oyt=s(o7e);i4r=r(Oyt,"longformer"),Oyt.forEach(t),d4r=r(JNe," \u2014 "),mJ=n(JNe,"A",{href:!0});var Vyt=s(mJ);c4r=r(Vyt,"TFLongformerForMaskedLM"),Vyt.forEach(t),f4r=r(JNe," (Longformer model)"),JNe.forEach(t),m4r=i(fe),KM=n(fe,"LI",{});var YNe=s(KM);r7e=n(YNe,"STRONG",{});var Xyt=s(r7e);g4r=r(Xyt,"mobilebert"),Xyt.forEach(t),h4r=r(YNe," \u2014 "),gJ=n(YNe,"A",{href:!0});var zyt=s(gJ);p4r=r(zyt,"TFMobileBertForMaskedLM"),zyt.forEach(t),_4r=r(YNe," (MobileBERT model)"),YNe.forEach(t),u4r=i(fe),ZM=n(fe,"LI",{});var KNe=s(ZM);t7e=n(KNe,"STRONG",{});var Qyt=s(t7e);b4r=r(Qyt,"mpnet"),Qyt.forEach(t),v4r=r(KNe," \u2014 "),hJ=n(KNe,"A",{href:!0});var Wyt=s(hJ);F4r=r(Wyt,"TFMPNetForMaskedLM"),Wyt.forEach(t),T4r=r(KNe," (MPNet model)"),KNe.forEach(t),M4r=i(fe),eE=n(fe,"LI",{});var ZNe=s(eE);a7e=n(ZNe,"STRONG",{});var Hyt=s(a7e);E4r=r(Hyt,"rembert"),Hyt.forEach(t),C4r=r(ZNe," \u2014 "),pJ=n(ZNe,"A",{href:!0});var Uyt=s(pJ);w4r=r(Uyt,"TFRemBertForMaskedLM"),Uyt.forEach(t),A4r=r(ZNe," (RemBERT model)"),ZNe.forEach(t),L4r=i(fe),oE=n(fe,"LI",{});var eqe=s(oE);n7e=n(eqe,"STRONG",{});var Jyt=s(n7e);y4r=r(Jyt,"roberta"),Jyt.forEach(t),x4r=r(eqe," \u2014 "),_J=n(eqe,"A",{href:!0});var Yyt=s(_J);$4r=r(Yyt,"TFRobertaForMaskedLM"),Yyt.forEach(t),k4r=r(eqe," (RoBERTa model)"),eqe.forEach(t),S4r=i(fe),rE=n(fe,"LI",{});var oqe=s(rE);s7e=n(oqe,"STRONG",{});var Kyt=s(s7e);R4r=r(Kyt,"roformer"),Kyt.forEach(t),P4r=r(oqe," \u2014 "),uJ=n(oqe,"A",{href:!0});var Zyt=s(uJ);B4r=r(Zyt,"TFRoFormerForMaskedLM"),Zyt.forEach(t),I4r=r(oqe," (RoFormer model)"),oqe.forEach(t),N4r=i(fe),tE=n(fe,"LI",{});var rqe=s(tE);l7e=n(rqe,"STRONG",{});var e9t=s(l7e);q4r=r(e9t,"tapas"),e9t.forEach(t),j4r=r(rqe," \u2014 "),bJ=n(rqe,"A",{href:!0});var o9t=s(bJ);D4r=r(o9t,"TFTapasForMaskedLM"),o9t.forEach(t),G4r=r(rqe," (TAPAS model)"),rqe.forEach(t),O4r=i(fe),aE=n(fe,"LI",{});var tqe=s(aE);i7e=n(tqe,"STRONG",{});var r9t=s(i7e);V4r=r(r9t,"xlm"),r9t.forEach(t),X4r=r(tqe," \u2014 "),vJ=n(tqe,"A",{href:!0});var t9t=s(vJ);z4r=r(t9t,"TFXLMWithLMHeadModel"),t9t.forEach(t),Q4r=r(tqe," (XLM model)"),tqe.forEach(t),W4r=i(fe),nE=n(fe,"LI",{});var aqe=s(nE);d7e=n(aqe,"STRONG",{});var a9t=s(d7e);H4r=r(a9t,"xlm-roberta"),a9t.forEach(t),U4r=r(aqe," \u2014 "),FJ=n(aqe,"A",{href:!0});var n9t=s(FJ);J4r=r(n9t,"TFXLMRobertaForMaskedLM"),n9t.forEach(t),Y4r=r(aqe," (XLM-RoBERTa model)"),aqe.forEach(t),fe.forEach(t),K4r=i(Sl),T(sE.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),hVe=i(f),pc=n(f,"H2",{class:!0});var Mze=s(pc);lE=n(Mze,"A",{id:!0,class:!0,href:!0});var s9t=s(lE);c7e=n(s9t,"SPAN",{});var l9t=s(c7e);T(V9.$$.fragment,l9t),l9t.forEach(t),s9t.forEach(t),Z4r=i(Mze),f7e=n(Mze,"SPAN",{});var i9t=s(f7e);eCr=r(i9t,"TFAutoModelForSeq2SeqLM"),i9t.forEach(t),Mze.forEach(t),pVe=i(f),nr=n(f,"DIV",{class:!0});var Rl=s(nr);T(X9.$$.fragment,Rl),oCr=i(Rl),_c=n(Rl,"P",{});var yre=s(_c);rCr=r(yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),TJ=n(yre,"A",{href:!0});var d9t=s(TJ);tCr=r(d9t,"from_pretrained()"),d9t.forEach(t),aCr=r(yre," class method or the "),MJ=n(yre,"A",{href:!0});var c9t=s(MJ);nCr=r(c9t,"from_config()"),c9t.forEach(t),sCr=r(yre,` class
method.`),yre.forEach(t),lCr=i(Rl),z9=n(Rl,"P",{});var Eze=s(z9);iCr=r(Eze,"This class cannot be instantiated directly using "),m7e=n(Eze,"CODE",{});var f9t=s(m7e);dCr=r(f9t,"__init__()"),f9t.forEach(t),cCr=r(Eze," (throws an error)."),Eze.forEach(t),fCr=i(Rl),Bt=n(Rl,"DIV",{class:!0});var Dw=s(Bt);T(Q9.$$.fragment,Dw),mCr=i(Dw),g7e=n(Dw,"P",{});var m9t=s(g7e);gCr=r(m9t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),m9t.forEach(t),hCr=i(Dw),uc=n(Dw,"P",{});var xre=s(uc);pCr=r(xre,`Note:
Loading a model from its configuration file does `),h7e=n(xre,"STRONG",{});var g9t=s(h7e);_Cr=r(g9t,"not"),g9t.forEach(t),uCr=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=n(xre,"A",{href:!0});var h9t=s(EJ);bCr=r(h9t,"from_pretrained()"),h9t.forEach(t),vCr=r(xre," to load the model weights."),xre.forEach(t),FCr=i(Dw),T(iE.$$.fragment,Dw),Dw.forEach(t),TCr=i(Rl),Rr=n(Rl,"DIV",{class:!0});var Pl=s(Rr);T(W9.$$.fragment,Pl),MCr=i(Pl),p7e=n(Pl,"P",{});var p9t=s(p7e);ECr=r(p9t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),p9t.forEach(t),CCr=i(Pl),fn=n(Pl,"P",{});var Gw=s(fn);wCr=r(Gw,"The model class to instantiate is selected based on the "),_7e=n(Gw,"CODE",{});var _9t=s(_7e);ACr=r(_9t,"model_type"),_9t.forEach(t),LCr=r(Gw,` property of the config object (either
passed as an argument or loaded from `),u7e=n(Gw,"CODE",{});var u9t=s(u7e);yCr=r(u9t,"pretrained_model_name_or_path"),u9t.forEach(t),xCr=r(Gw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b7e=n(Gw,"CODE",{});var b9t=s(b7e);$Cr=r(b9t,"pretrained_model_name_or_path"),b9t.forEach(t),kCr=r(Gw,":"),Gw.forEach(t),SCr=i(Pl),ye=n(Pl,"UL",{});var Ie=s(ye);dE=n(Ie,"LI",{});var nqe=s(dE);v7e=n(nqe,"STRONG",{});var v9t=s(v7e);RCr=r(v9t,"bart"),v9t.forEach(t),PCr=r(nqe," \u2014 "),CJ=n(nqe,"A",{href:!0});var F9t=s(CJ);BCr=r(F9t,"TFBartForConditionalGeneration"),F9t.forEach(t),ICr=r(nqe," (BART model)"),nqe.forEach(t),NCr=i(Ie),cE=n(Ie,"LI",{});var sqe=s(cE);F7e=n(sqe,"STRONG",{});var T9t=s(F7e);qCr=r(T9t,"blenderbot"),T9t.forEach(t),jCr=r(sqe," \u2014 "),wJ=n(sqe,"A",{href:!0});var M9t=s(wJ);DCr=r(M9t,"TFBlenderbotForConditionalGeneration"),M9t.forEach(t),GCr=r(sqe," (Blenderbot model)"),sqe.forEach(t),OCr=i(Ie),fE=n(Ie,"LI",{});var lqe=s(fE);T7e=n(lqe,"STRONG",{});var E9t=s(T7e);VCr=r(E9t,"blenderbot-small"),E9t.forEach(t),XCr=r(lqe," \u2014 "),AJ=n(lqe,"A",{href:!0});var C9t=s(AJ);zCr=r(C9t,"TFBlenderbotSmallForConditionalGeneration"),C9t.forEach(t),QCr=r(lqe," (BlenderbotSmall model)"),lqe.forEach(t),WCr=i(Ie),mE=n(Ie,"LI",{});var iqe=s(mE);M7e=n(iqe,"STRONG",{});var w9t=s(M7e);HCr=r(w9t,"encoder-decoder"),w9t.forEach(t),UCr=r(iqe," \u2014 "),LJ=n(iqe,"A",{href:!0});var A9t=s(LJ);JCr=r(A9t,"TFEncoderDecoderModel"),A9t.forEach(t),YCr=r(iqe," (Encoder decoder model)"),iqe.forEach(t),KCr=i(Ie),gE=n(Ie,"LI",{});var dqe=s(gE);E7e=n(dqe,"STRONG",{});var L9t=s(E7e);ZCr=r(L9t,"led"),L9t.forEach(t),e5r=r(dqe," \u2014 "),yJ=n(dqe,"A",{href:!0});var y9t=s(yJ);o5r=r(y9t,"TFLEDForConditionalGeneration"),y9t.forEach(t),r5r=r(dqe," (LED model)"),dqe.forEach(t),t5r=i(Ie),hE=n(Ie,"LI",{});var cqe=s(hE);C7e=n(cqe,"STRONG",{});var x9t=s(C7e);a5r=r(x9t,"marian"),x9t.forEach(t),n5r=r(cqe," \u2014 "),xJ=n(cqe,"A",{href:!0});var $9t=s(xJ);s5r=r($9t,"TFMarianMTModel"),$9t.forEach(t),l5r=r(cqe," (Marian model)"),cqe.forEach(t),i5r=i(Ie),pE=n(Ie,"LI",{});var fqe=s(pE);w7e=n(fqe,"STRONG",{});var k9t=s(w7e);d5r=r(k9t,"mbart"),k9t.forEach(t),c5r=r(fqe," \u2014 "),$J=n(fqe,"A",{href:!0});var S9t=s($J);f5r=r(S9t,"TFMBartForConditionalGeneration"),S9t.forEach(t),m5r=r(fqe," (mBART model)"),fqe.forEach(t),g5r=i(Ie),_E=n(Ie,"LI",{});var mqe=s(_E);A7e=n(mqe,"STRONG",{});var R9t=s(A7e);h5r=r(R9t,"mt5"),R9t.forEach(t),p5r=r(mqe," \u2014 "),kJ=n(mqe,"A",{href:!0});var P9t=s(kJ);_5r=r(P9t,"TFMT5ForConditionalGeneration"),P9t.forEach(t),u5r=r(mqe," (MT5 model)"),mqe.forEach(t),b5r=i(Ie),uE=n(Ie,"LI",{});var gqe=s(uE);L7e=n(gqe,"STRONG",{});var B9t=s(L7e);v5r=r(B9t,"pegasus"),B9t.forEach(t),F5r=r(gqe," \u2014 "),SJ=n(gqe,"A",{href:!0});var I9t=s(SJ);T5r=r(I9t,"TFPegasusForConditionalGeneration"),I9t.forEach(t),M5r=r(gqe," (Pegasus model)"),gqe.forEach(t),E5r=i(Ie),bE=n(Ie,"LI",{});var hqe=s(bE);y7e=n(hqe,"STRONG",{});var N9t=s(y7e);C5r=r(N9t,"t5"),N9t.forEach(t),w5r=r(hqe," \u2014 "),RJ=n(hqe,"A",{href:!0});var q9t=s(RJ);A5r=r(q9t,"TFT5ForConditionalGeneration"),q9t.forEach(t),L5r=r(hqe," (T5 model)"),hqe.forEach(t),Ie.forEach(t),y5r=i(Pl),T(vE.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),_Ve=i(f),bc=n(f,"H2",{class:!0});var Cze=s(bc);FE=n(Cze,"A",{id:!0,class:!0,href:!0});var j9t=s(FE);x7e=n(j9t,"SPAN",{});var D9t=s(x7e);T(H9.$$.fragment,D9t),D9t.forEach(t),j9t.forEach(t),x5r=i(Cze),$7e=n(Cze,"SPAN",{});var G9t=s($7e);$5r=r(G9t,"TFAutoModelForSequenceClassification"),G9t.forEach(t),Cze.forEach(t),uVe=i(f),sr=n(f,"DIV",{class:!0});var Bl=s(sr);T(U9.$$.fragment,Bl),k5r=i(Bl),vc=n(Bl,"P",{});var $re=s(vc);S5r=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),PJ=n($re,"A",{href:!0});var O9t=s(PJ);R5r=r(O9t,"from_pretrained()"),O9t.forEach(t),P5r=r($re," class method or the "),BJ=n($re,"A",{href:!0});var V9t=s(BJ);B5r=r(V9t,"from_config()"),V9t.forEach(t),I5r=r($re,` class
method.`),$re.forEach(t),N5r=i(Bl),J9=n(Bl,"P",{});var wze=s(J9);q5r=r(wze,"This class cannot be instantiated directly using "),k7e=n(wze,"CODE",{});var X9t=s(k7e);j5r=r(X9t,"__init__()"),X9t.forEach(t),D5r=r(wze," (throws an error)."),wze.forEach(t),G5r=i(Bl),It=n(Bl,"DIV",{class:!0});var Ow=s(It);T(Y9.$$.fragment,Ow),O5r=i(Ow),S7e=n(Ow,"P",{});var z9t=s(S7e);V5r=r(z9t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),z9t.forEach(t),X5r=i(Ow),Fc=n(Ow,"P",{});var kre=s(Fc);z5r=r(kre,`Note:
Loading a model from its configuration file does `),R7e=n(kre,"STRONG",{});var Q9t=s(R7e);Q5r=r(Q9t,"not"),Q9t.forEach(t),W5r=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=n(kre,"A",{href:!0});var W9t=s(IJ);H5r=r(W9t,"from_pretrained()"),W9t.forEach(t),U5r=r(kre," to load the model weights."),kre.forEach(t),J5r=i(Ow),T(TE.$$.fragment,Ow),Ow.forEach(t),Y5r=i(Bl),Pr=n(Bl,"DIV",{class:!0});var Il=s(Pr);T(K9.$$.fragment,Il),K5r=i(Il),P7e=n(Il,"P",{});var H9t=s(P7e);Z5r=r(H9t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),H9t.forEach(t),e3r=i(Il),mn=n(Il,"P",{});var Vw=s(mn);o3r=r(Vw,"The model class to instantiate is selected based on the "),B7e=n(Vw,"CODE",{});var U9t=s(B7e);r3r=r(U9t,"model_type"),U9t.forEach(t),t3r=r(Vw,` property of the config object (either
passed as an argument or loaded from `),I7e=n(Vw,"CODE",{});var J9t=s(I7e);a3r=r(J9t,"pretrained_model_name_or_path"),J9t.forEach(t),n3r=r(Vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N7e=n(Vw,"CODE",{});var Y9t=s(N7e);s3r=r(Y9t,"pretrained_model_name_or_path"),Y9t.forEach(t),l3r=r(Vw,":"),Vw.forEach(t),i3r=i(Il),te=n(Il,"UL",{});var ne=s(te);ME=n(ne,"LI",{});var pqe=s(ME);q7e=n(pqe,"STRONG",{});var K9t=s(q7e);d3r=r(K9t,"albert"),K9t.forEach(t),c3r=r(pqe," \u2014 "),NJ=n(pqe,"A",{href:!0});var Z9t=s(NJ);f3r=r(Z9t,"TFAlbertForSequenceClassification"),Z9t.forEach(t),m3r=r(pqe," (ALBERT model)"),pqe.forEach(t),g3r=i(ne),EE=n(ne,"LI",{});var _qe=s(EE);j7e=n(_qe,"STRONG",{});var ext=s(j7e);h3r=r(ext,"bert"),ext.forEach(t),p3r=r(_qe," \u2014 "),qJ=n(_qe,"A",{href:!0});var oxt=s(qJ);_3r=r(oxt,"TFBertForSequenceClassification"),oxt.forEach(t),u3r=r(_qe," (BERT model)"),_qe.forEach(t),b3r=i(ne),CE=n(ne,"LI",{});var uqe=s(CE);D7e=n(uqe,"STRONG",{});var rxt=s(D7e);v3r=r(rxt,"camembert"),rxt.forEach(t),F3r=r(uqe," \u2014 "),jJ=n(uqe,"A",{href:!0});var txt=s(jJ);T3r=r(txt,"TFCamembertForSequenceClassification"),txt.forEach(t),M3r=r(uqe," (CamemBERT model)"),uqe.forEach(t),E3r=i(ne),wE=n(ne,"LI",{});var bqe=s(wE);G7e=n(bqe,"STRONG",{});var axt=s(G7e);C3r=r(axt,"convbert"),axt.forEach(t),w3r=r(bqe," \u2014 "),DJ=n(bqe,"A",{href:!0});var nxt=s(DJ);A3r=r(nxt,"TFConvBertForSequenceClassification"),nxt.forEach(t),L3r=r(bqe," (ConvBERT model)"),bqe.forEach(t),y3r=i(ne),AE=n(ne,"LI",{});var vqe=s(AE);O7e=n(vqe,"STRONG",{});var sxt=s(O7e);x3r=r(sxt,"ctrl"),sxt.forEach(t),$3r=r(vqe," \u2014 "),GJ=n(vqe,"A",{href:!0});var lxt=s(GJ);k3r=r(lxt,"TFCTRLForSequenceClassification"),lxt.forEach(t),S3r=r(vqe," (CTRL model)"),vqe.forEach(t),R3r=i(ne),LE=n(ne,"LI",{});var Fqe=s(LE);V7e=n(Fqe,"STRONG",{});var ixt=s(V7e);P3r=r(ixt,"deberta"),ixt.forEach(t),B3r=r(Fqe," \u2014 "),OJ=n(Fqe,"A",{href:!0});var dxt=s(OJ);I3r=r(dxt,"TFDebertaForSequenceClassification"),dxt.forEach(t),N3r=r(Fqe," (DeBERTa model)"),Fqe.forEach(t),q3r=i(ne),yE=n(ne,"LI",{});var Tqe=s(yE);X7e=n(Tqe,"STRONG",{});var cxt=s(X7e);j3r=r(cxt,"deberta-v2"),cxt.forEach(t),D3r=r(Tqe," \u2014 "),VJ=n(Tqe,"A",{href:!0});var fxt=s(VJ);G3r=r(fxt,"TFDebertaV2ForSequenceClassification"),fxt.forEach(t),O3r=r(Tqe," (DeBERTa-v2 model)"),Tqe.forEach(t),V3r=i(ne),xE=n(ne,"LI",{});var Mqe=s(xE);z7e=n(Mqe,"STRONG",{});var mxt=s(z7e);X3r=r(mxt,"distilbert"),mxt.forEach(t),z3r=r(Mqe," \u2014 "),XJ=n(Mqe,"A",{href:!0});var gxt=s(XJ);Q3r=r(gxt,"TFDistilBertForSequenceClassification"),gxt.forEach(t),W3r=r(Mqe," (DistilBERT model)"),Mqe.forEach(t),H3r=i(ne),$E=n(ne,"LI",{});var Eqe=s($E);Q7e=n(Eqe,"STRONG",{});var hxt=s(Q7e);U3r=r(hxt,"electra"),hxt.forEach(t),J3r=r(Eqe," \u2014 "),zJ=n(Eqe,"A",{href:!0});var pxt=s(zJ);Y3r=r(pxt,"TFElectraForSequenceClassification"),pxt.forEach(t),K3r=r(Eqe," (ELECTRA model)"),Eqe.forEach(t),Z3r=i(ne),kE=n(ne,"LI",{});var Cqe=s(kE);W7e=n(Cqe,"STRONG",{});var _xt=s(W7e);e0r=r(_xt,"flaubert"),_xt.forEach(t),o0r=r(Cqe," \u2014 "),QJ=n(Cqe,"A",{href:!0});var uxt=s(QJ);r0r=r(uxt,"TFFlaubertForSequenceClassification"),uxt.forEach(t),t0r=r(Cqe," (FlauBERT model)"),Cqe.forEach(t),a0r=i(ne),SE=n(ne,"LI",{});var wqe=s(SE);H7e=n(wqe,"STRONG",{});var bxt=s(H7e);n0r=r(bxt,"funnel"),bxt.forEach(t),s0r=r(wqe," \u2014 "),WJ=n(wqe,"A",{href:!0});var vxt=s(WJ);l0r=r(vxt,"TFFunnelForSequenceClassification"),vxt.forEach(t),i0r=r(wqe," (Funnel Transformer model)"),wqe.forEach(t),d0r=i(ne),RE=n(ne,"LI",{});var Aqe=s(RE);U7e=n(Aqe,"STRONG",{});var Fxt=s(U7e);c0r=r(Fxt,"gpt2"),Fxt.forEach(t),f0r=r(Aqe," \u2014 "),HJ=n(Aqe,"A",{href:!0});var Txt=s(HJ);m0r=r(Txt,"TFGPT2ForSequenceClassification"),Txt.forEach(t),g0r=r(Aqe," (OpenAI GPT-2 model)"),Aqe.forEach(t),h0r=i(ne),PE=n(ne,"LI",{});var Lqe=s(PE);J7e=n(Lqe,"STRONG",{});var Mxt=s(J7e);p0r=r(Mxt,"gptj"),Mxt.forEach(t),_0r=r(Lqe," \u2014 "),UJ=n(Lqe,"A",{href:!0});var Ext=s(UJ);u0r=r(Ext,"TFGPTJForSequenceClassification"),Ext.forEach(t),b0r=r(Lqe," (GPT-J model)"),Lqe.forEach(t),v0r=i(ne),BE=n(ne,"LI",{});var yqe=s(BE);Y7e=n(yqe,"STRONG",{});var Cxt=s(Y7e);F0r=r(Cxt,"layoutlm"),Cxt.forEach(t),T0r=r(yqe," \u2014 "),JJ=n(yqe,"A",{href:!0});var wxt=s(JJ);M0r=r(wxt,"TFLayoutLMForSequenceClassification"),wxt.forEach(t),E0r=r(yqe," (LayoutLM model)"),yqe.forEach(t),C0r=i(ne),IE=n(ne,"LI",{});var xqe=s(IE);K7e=n(xqe,"STRONG",{});var Axt=s(K7e);w0r=r(Axt,"longformer"),Axt.forEach(t),A0r=r(xqe," \u2014 "),YJ=n(xqe,"A",{href:!0});var Lxt=s(YJ);L0r=r(Lxt,"TFLongformerForSequenceClassification"),Lxt.forEach(t),y0r=r(xqe," (Longformer model)"),xqe.forEach(t),x0r=i(ne),NE=n(ne,"LI",{});var $qe=s(NE);Z7e=n($qe,"STRONG",{});var yxt=s(Z7e);$0r=r(yxt,"mobilebert"),yxt.forEach(t),k0r=r($qe," \u2014 "),KJ=n($qe,"A",{href:!0});var xxt=s(KJ);S0r=r(xxt,"TFMobileBertForSequenceClassification"),xxt.forEach(t),R0r=r($qe," (MobileBERT model)"),$qe.forEach(t),P0r=i(ne),qE=n(ne,"LI",{});var kqe=s(qE);e8e=n(kqe,"STRONG",{});var $xt=s(e8e);B0r=r($xt,"mpnet"),$xt.forEach(t),I0r=r(kqe," \u2014 "),ZJ=n(kqe,"A",{href:!0});var kxt=s(ZJ);N0r=r(kxt,"TFMPNetForSequenceClassification"),kxt.forEach(t),q0r=r(kqe," (MPNet model)"),kqe.forEach(t),j0r=i(ne),jE=n(ne,"LI",{});var Sqe=s(jE);o8e=n(Sqe,"STRONG",{});var Sxt=s(o8e);D0r=r(Sxt,"openai-gpt"),Sxt.forEach(t),G0r=r(Sqe," \u2014 "),eY=n(Sqe,"A",{href:!0});var Rxt=s(eY);O0r=r(Rxt,"TFOpenAIGPTForSequenceClassification"),Rxt.forEach(t),V0r=r(Sqe," (OpenAI GPT model)"),Sqe.forEach(t),X0r=i(ne),DE=n(ne,"LI",{});var Rqe=s(DE);r8e=n(Rqe,"STRONG",{});var Pxt=s(r8e);z0r=r(Pxt,"rembert"),Pxt.forEach(t),Q0r=r(Rqe," \u2014 "),oY=n(Rqe,"A",{href:!0});var Bxt=s(oY);W0r=r(Bxt,"TFRemBertForSequenceClassification"),Bxt.forEach(t),H0r=r(Rqe," (RemBERT model)"),Rqe.forEach(t),U0r=i(ne),GE=n(ne,"LI",{});var Pqe=s(GE);t8e=n(Pqe,"STRONG",{});var Ixt=s(t8e);J0r=r(Ixt,"roberta"),Ixt.forEach(t),Y0r=r(Pqe," \u2014 "),rY=n(Pqe,"A",{href:!0});var Nxt=s(rY);K0r=r(Nxt,"TFRobertaForSequenceClassification"),Nxt.forEach(t),Z0r=r(Pqe," (RoBERTa model)"),Pqe.forEach(t),ewr=i(ne),OE=n(ne,"LI",{});var Bqe=s(OE);a8e=n(Bqe,"STRONG",{});var qxt=s(a8e);owr=r(qxt,"roformer"),qxt.forEach(t),rwr=r(Bqe," \u2014 "),tY=n(Bqe,"A",{href:!0});var jxt=s(tY);twr=r(jxt,"TFRoFormerForSequenceClassification"),jxt.forEach(t),awr=r(Bqe," (RoFormer model)"),Bqe.forEach(t),nwr=i(ne),VE=n(ne,"LI",{});var Iqe=s(VE);n8e=n(Iqe,"STRONG",{});var Dxt=s(n8e);swr=r(Dxt,"tapas"),Dxt.forEach(t),lwr=r(Iqe," \u2014 "),aY=n(Iqe,"A",{href:!0});var Gxt=s(aY);iwr=r(Gxt,"TFTapasForSequenceClassification"),Gxt.forEach(t),dwr=r(Iqe," (TAPAS model)"),Iqe.forEach(t),cwr=i(ne),XE=n(ne,"LI",{});var Nqe=s(XE);s8e=n(Nqe,"STRONG",{});var Oxt=s(s8e);fwr=r(Oxt,"transfo-xl"),Oxt.forEach(t),mwr=r(Nqe," \u2014 "),nY=n(Nqe,"A",{href:!0});var Vxt=s(nY);gwr=r(Vxt,"TFTransfoXLForSequenceClassification"),Vxt.forEach(t),hwr=r(Nqe," (Transformer-XL model)"),Nqe.forEach(t),pwr=i(ne),zE=n(ne,"LI",{});var qqe=s(zE);l8e=n(qqe,"STRONG",{});var Xxt=s(l8e);_wr=r(Xxt,"xlm"),Xxt.forEach(t),uwr=r(qqe," \u2014 "),sY=n(qqe,"A",{href:!0});var zxt=s(sY);bwr=r(zxt,"TFXLMForSequenceClassification"),zxt.forEach(t),vwr=r(qqe," (XLM model)"),qqe.forEach(t),Fwr=i(ne),QE=n(ne,"LI",{});var jqe=s(QE);i8e=n(jqe,"STRONG",{});var Qxt=s(i8e);Twr=r(Qxt,"xlm-roberta"),Qxt.forEach(t),Mwr=r(jqe," \u2014 "),lY=n(jqe,"A",{href:!0});var Wxt=s(lY);Ewr=r(Wxt,"TFXLMRobertaForSequenceClassification"),Wxt.forEach(t),Cwr=r(jqe," (XLM-RoBERTa model)"),jqe.forEach(t),wwr=i(ne),WE=n(ne,"LI",{});var Dqe=s(WE);d8e=n(Dqe,"STRONG",{});var Hxt=s(d8e);Awr=r(Hxt,"xlnet"),Hxt.forEach(t),Lwr=r(Dqe," \u2014 "),iY=n(Dqe,"A",{href:!0});var Uxt=s(iY);ywr=r(Uxt,"TFXLNetForSequenceClassification"),Uxt.forEach(t),xwr=r(Dqe," (XLNet model)"),Dqe.forEach(t),ne.forEach(t),$wr=i(Il),T(HE.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),bVe=i(f),Tc=n(f,"H2",{class:!0});var Aze=s(Tc);UE=n(Aze,"A",{id:!0,class:!0,href:!0});var Jxt=s(UE);c8e=n(Jxt,"SPAN",{});var Yxt=s(c8e);T(Z9.$$.fragment,Yxt),Yxt.forEach(t),Jxt.forEach(t),kwr=i(Aze),f8e=n(Aze,"SPAN",{});var Kxt=s(f8e);Swr=r(Kxt,"TFAutoModelForMultipleChoice"),Kxt.forEach(t),Aze.forEach(t),vVe=i(f),lr=n(f,"DIV",{class:!0});var Nl=s(lr);T(ex.$$.fragment,Nl),Rwr=i(Nl),Mc=n(Nl,"P",{});var Sre=s(Mc);Pwr=r(Sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),dY=n(Sre,"A",{href:!0});var Zxt=s(dY);Bwr=r(Zxt,"from_pretrained()"),Zxt.forEach(t),Iwr=r(Sre," class method or the "),cY=n(Sre,"A",{href:!0});var e$t=s(cY);Nwr=r(e$t,"from_config()"),e$t.forEach(t),qwr=r(Sre,` class
method.`),Sre.forEach(t),jwr=i(Nl),ox=n(Nl,"P",{});var Lze=s(ox);Dwr=r(Lze,"This class cannot be instantiated directly using "),m8e=n(Lze,"CODE",{});var o$t=s(m8e);Gwr=r(o$t,"__init__()"),o$t.forEach(t),Owr=r(Lze," (throws an error)."),Lze.forEach(t),Vwr=i(Nl),Nt=n(Nl,"DIV",{class:!0});var Xw=s(Nt);T(rx.$$.fragment,Xw),Xwr=i(Xw),g8e=n(Xw,"P",{});var r$t=s(g8e);zwr=r(r$t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),r$t.forEach(t),Qwr=i(Xw),Ec=n(Xw,"P",{});var Rre=s(Ec);Wwr=r(Rre,`Note:
Loading a model from its configuration file does `),h8e=n(Rre,"STRONG",{});var t$t=s(h8e);Hwr=r(t$t,"not"),t$t.forEach(t),Uwr=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),fY=n(Rre,"A",{href:!0});var a$t=s(fY);Jwr=r(a$t,"from_pretrained()"),a$t.forEach(t),Ywr=r(Rre," to load the model weights."),Rre.forEach(t),Kwr=i(Xw),T(JE.$$.fragment,Xw),Xw.forEach(t),Zwr=i(Nl),Br=n(Nl,"DIV",{class:!0});var ql=s(Br);T(tx.$$.fragment,ql),eAr=i(ql),p8e=n(ql,"P",{});var n$t=s(p8e);oAr=r(n$t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),n$t.forEach(t),rAr=i(ql),gn=n(ql,"P",{});var zw=s(gn);tAr=r(zw,"The model class to instantiate is selected based on the "),_8e=n(zw,"CODE",{});var s$t=s(_8e);aAr=r(s$t,"model_type"),s$t.forEach(t),nAr=r(zw,` property of the config object (either
passed as an argument or loaded from `),u8e=n(zw,"CODE",{});var l$t=s(u8e);sAr=r(l$t,"pretrained_model_name_or_path"),l$t.forEach(t),lAr=r(zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b8e=n(zw,"CODE",{});var i$t=s(b8e);iAr=r(i$t,"pretrained_model_name_or_path"),i$t.forEach(t),dAr=r(zw,":"),zw.forEach(t),cAr=i(ql),_e=n(ql,"UL",{});var ve=s(_e);YE=n(ve,"LI",{});var Gqe=s(YE);v8e=n(Gqe,"STRONG",{});var d$t=s(v8e);fAr=r(d$t,"albert"),d$t.forEach(t),mAr=r(Gqe," \u2014 "),mY=n(Gqe,"A",{href:!0});var c$t=s(mY);gAr=r(c$t,"TFAlbertForMultipleChoice"),c$t.forEach(t),hAr=r(Gqe," (ALBERT model)"),Gqe.forEach(t),pAr=i(ve),KE=n(ve,"LI",{});var Oqe=s(KE);F8e=n(Oqe,"STRONG",{});var f$t=s(F8e);_Ar=r(f$t,"bert"),f$t.forEach(t),uAr=r(Oqe," \u2014 "),gY=n(Oqe,"A",{href:!0});var m$t=s(gY);bAr=r(m$t,"TFBertForMultipleChoice"),m$t.forEach(t),vAr=r(Oqe," (BERT model)"),Oqe.forEach(t),FAr=i(ve),ZE=n(ve,"LI",{});var Vqe=s(ZE);T8e=n(Vqe,"STRONG",{});var g$t=s(T8e);TAr=r(g$t,"camembert"),g$t.forEach(t),MAr=r(Vqe," \u2014 "),hY=n(Vqe,"A",{href:!0});var h$t=s(hY);EAr=r(h$t,"TFCamembertForMultipleChoice"),h$t.forEach(t),CAr=r(Vqe," (CamemBERT model)"),Vqe.forEach(t),wAr=i(ve),e4=n(ve,"LI",{});var Xqe=s(e4);M8e=n(Xqe,"STRONG",{});var p$t=s(M8e);AAr=r(p$t,"convbert"),p$t.forEach(t),LAr=r(Xqe," \u2014 "),pY=n(Xqe,"A",{href:!0});var _$t=s(pY);yAr=r(_$t,"TFConvBertForMultipleChoice"),_$t.forEach(t),xAr=r(Xqe," (ConvBERT model)"),Xqe.forEach(t),$Ar=i(ve),o4=n(ve,"LI",{});var zqe=s(o4);E8e=n(zqe,"STRONG",{});var u$t=s(E8e);kAr=r(u$t,"distilbert"),u$t.forEach(t),SAr=r(zqe," \u2014 "),_Y=n(zqe,"A",{href:!0});var b$t=s(_Y);RAr=r(b$t,"TFDistilBertForMultipleChoice"),b$t.forEach(t),PAr=r(zqe," (DistilBERT model)"),zqe.forEach(t),BAr=i(ve),r4=n(ve,"LI",{});var Qqe=s(r4);C8e=n(Qqe,"STRONG",{});var v$t=s(C8e);IAr=r(v$t,"electra"),v$t.forEach(t),NAr=r(Qqe," \u2014 "),uY=n(Qqe,"A",{href:!0});var F$t=s(uY);qAr=r(F$t,"TFElectraForMultipleChoice"),F$t.forEach(t),jAr=r(Qqe," (ELECTRA model)"),Qqe.forEach(t),DAr=i(ve),t4=n(ve,"LI",{});var Wqe=s(t4);w8e=n(Wqe,"STRONG",{});var T$t=s(w8e);GAr=r(T$t,"flaubert"),T$t.forEach(t),OAr=r(Wqe," \u2014 "),bY=n(Wqe,"A",{href:!0});var M$t=s(bY);VAr=r(M$t,"TFFlaubertForMultipleChoice"),M$t.forEach(t),XAr=r(Wqe," (FlauBERT model)"),Wqe.forEach(t),zAr=i(ve),a4=n(ve,"LI",{});var Hqe=s(a4);A8e=n(Hqe,"STRONG",{});var E$t=s(A8e);QAr=r(E$t,"funnel"),E$t.forEach(t),WAr=r(Hqe," \u2014 "),vY=n(Hqe,"A",{href:!0});var C$t=s(vY);HAr=r(C$t,"TFFunnelForMultipleChoice"),C$t.forEach(t),UAr=r(Hqe," (Funnel Transformer model)"),Hqe.forEach(t),JAr=i(ve),n4=n(ve,"LI",{});var Uqe=s(n4);L8e=n(Uqe,"STRONG",{});var w$t=s(L8e);YAr=r(w$t,"longformer"),w$t.forEach(t),KAr=r(Uqe," \u2014 "),FY=n(Uqe,"A",{href:!0});var A$t=s(FY);ZAr=r(A$t,"TFLongformerForMultipleChoice"),A$t.forEach(t),eLr=r(Uqe," (Longformer model)"),Uqe.forEach(t),oLr=i(ve),s4=n(ve,"LI",{});var Jqe=s(s4);y8e=n(Jqe,"STRONG",{});var L$t=s(y8e);rLr=r(L$t,"mobilebert"),L$t.forEach(t),tLr=r(Jqe," \u2014 "),TY=n(Jqe,"A",{href:!0});var y$t=s(TY);aLr=r(y$t,"TFMobileBertForMultipleChoice"),y$t.forEach(t),nLr=r(Jqe," (MobileBERT model)"),Jqe.forEach(t),sLr=i(ve),l4=n(ve,"LI",{});var Yqe=s(l4);x8e=n(Yqe,"STRONG",{});var x$t=s(x8e);lLr=r(x$t,"mpnet"),x$t.forEach(t),iLr=r(Yqe," \u2014 "),MY=n(Yqe,"A",{href:!0});var $$t=s(MY);dLr=r($$t,"TFMPNetForMultipleChoice"),$$t.forEach(t),cLr=r(Yqe," (MPNet model)"),Yqe.forEach(t),fLr=i(ve),i4=n(ve,"LI",{});var Kqe=s(i4);$8e=n(Kqe,"STRONG",{});var k$t=s($8e);mLr=r(k$t,"rembert"),k$t.forEach(t),gLr=r(Kqe," \u2014 "),EY=n(Kqe,"A",{href:!0});var S$t=s(EY);hLr=r(S$t,"TFRemBertForMultipleChoice"),S$t.forEach(t),pLr=r(Kqe," (RemBERT model)"),Kqe.forEach(t),_Lr=i(ve),d4=n(ve,"LI",{});var Zqe=s(d4);k8e=n(Zqe,"STRONG",{});var R$t=s(k8e);uLr=r(R$t,"roberta"),R$t.forEach(t),bLr=r(Zqe," \u2014 "),CY=n(Zqe,"A",{href:!0});var P$t=s(CY);vLr=r(P$t,"TFRobertaForMultipleChoice"),P$t.forEach(t),FLr=r(Zqe," (RoBERTa model)"),Zqe.forEach(t),TLr=i(ve),c4=n(ve,"LI",{});var eje=s(c4);S8e=n(eje,"STRONG",{});var B$t=s(S8e);MLr=r(B$t,"roformer"),B$t.forEach(t),ELr=r(eje," \u2014 "),wY=n(eje,"A",{href:!0});var I$t=s(wY);CLr=r(I$t,"TFRoFormerForMultipleChoice"),I$t.forEach(t),wLr=r(eje," (RoFormer model)"),eje.forEach(t),ALr=i(ve),f4=n(ve,"LI",{});var oje=s(f4);R8e=n(oje,"STRONG",{});var N$t=s(R8e);LLr=r(N$t,"xlm"),N$t.forEach(t),yLr=r(oje," \u2014 "),AY=n(oje,"A",{href:!0});var q$t=s(AY);xLr=r(q$t,"TFXLMForMultipleChoice"),q$t.forEach(t),$Lr=r(oje," (XLM model)"),oje.forEach(t),kLr=i(ve),m4=n(ve,"LI",{});var rje=s(m4);P8e=n(rje,"STRONG",{});var j$t=s(P8e);SLr=r(j$t,"xlm-roberta"),j$t.forEach(t),RLr=r(rje," \u2014 "),LY=n(rje,"A",{href:!0});var D$t=s(LY);PLr=r(D$t,"TFXLMRobertaForMultipleChoice"),D$t.forEach(t),BLr=r(rje," (XLM-RoBERTa model)"),rje.forEach(t),ILr=i(ve),g4=n(ve,"LI",{});var tje=s(g4);B8e=n(tje,"STRONG",{});var G$t=s(B8e);NLr=r(G$t,"xlnet"),G$t.forEach(t),qLr=r(tje," \u2014 "),yY=n(tje,"A",{href:!0});var O$t=s(yY);jLr=r(O$t,"TFXLNetForMultipleChoice"),O$t.forEach(t),DLr=r(tje," (XLNet model)"),tje.forEach(t),ve.forEach(t),GLr=i(ql),T(h4.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),FVe=i(f),Cc=n(f,"H2",{class:!0});var yze=s(Cc);p4=n(yze,"A",{id:!0,class:!0,href:!0});var V$t=s(p4);I8e=n(V$t,"SPAN",{});var X$t=s(I8e);T(ax.$$.fragment,X$t),X$t.forEach(t),V$t.forEach(t),OLr=i(yze),N8e=n(yze,"SPAN",{});var z$t=s(N8e);VLr=r(z$t,"TFAutoModelForNextSentencePrediction"),z$t.forEach(t),yze.forEach(t),TVe=i(f),ir=n(f,"DIV",{class:!0});var jl=s(ir);T(nx.$$.fragment,jl),XLr=i(jl),wc=n(jl,"P",{});var Pre=s(wc);zLr=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),xY=n(Pre,"A",{href:!0});var Q$t=s(xY);QLr=r(Q$t,"from_pretrained()"),Q$t.forEach(t),WLr=r(Pre," class method or the "),$Y=n(Pre,"A",{href:!0});var W$t=s($Y);HLr=r(W$t,"from_config()"),W$t.forEach(t),ULr=r(Pre,` class
method.`),Pre.forEach(t),JLr=i(jl),sx=n(jl,"P",{});var xze=s(sx);YLr=r(xze,"This class cannot be instantiated directly using "),q8e=n(xze,"CODE",{});var H$t=s(q8e);KLr=r(H$t,"__init__()"),H$t.forEach(t),ZLr=r(xze," (throws an error)."),xze.forEach(t),eyr=i(jl),qt=n(jl,"DIV",{class:!0});var Qw=s(qt);T(lx.$$.fragment,Qw),oyr=i(Qw),j8e=n(Qw,"P",{});var U$t=s(j8e);ryr=r(U$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),U$t.forEach(t),tyr=i(Qw),Ac=n(Qw,"P",{});var Bre=s(Ac);ayr=r(Bre,`Note:
Loading a model from its configuration file does `),D8e=n(Bre,"STRONG",{});var J$t=s(D8e);nyr=r(J$t,"not"),J$t.forEach(t),syr=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=n(Bre,"A",{href:!0});var Y$t=s(kY);lyr=r(Y$t,"from_pretrained()"),Y$t.forEach(t),iyr=r(Bre," to load the model weights."),Bre.forEach(t),dyr=i(Qw),T(_4.$$.fragment,Qw),Qw.forEach(t),cyr=i(jl),Ir=n(jl,"DIV",{class:!0});var Dl=s(Ir);T(ix.$$.fragment,Dl),fyr=i(Dl),G8e=n(Dl,"P",{});var K$t=s(G8e);myr=r(K$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),K$t.forEach(t),gyr=i(Dl),hn=n(Dl,"P",{});var Ww=s(hn);hyr=r(Ww,"The model class to instantiate is selected based on the "),O8e=n(Ww,"CODE",{});var Z$t=s(O8e);pyr=r(Z$t,"model_type"),Z$t.forEach(t),_yr=r(Ww,` property of the config object (either
passed as an argument or loaded from `),V8e=n(Ww,"CODE",{});var ekt=s(V8e);uyr=r(ekt,"pretrained_model_name_or_path"),ekt.forEach(t),byr=r(Ww,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X8e=n(Ww,"CODE",{});var okt=s(X8e);vyr=r(okt,"pretrained_model_name_or_path"),okt.forEach(t),Fyr=r(Ww,":"),Ww.forEach(t),Tyr=i(Dl),dx=n(Dl,"UL",{});var $ze=s(dx);u4=n($ze,"LI",{});var aje=s(u4);z8e=n(aje,"STRONG",{});var rkt=s(z8e);Myr=r(rkt,"bert"),rkt.forEach(t),Eyr=r(aje," \u2014 "),SY=n(aje,"A",{href:!0});var tkt=s(SY);Cyr=r(tkt,"TFBertForNextSentencePrediction"),tkt.forEach(t),wyr=r(aje," (BERT model)"),aje.forEach(t),Ayr=i($ze),b4=n($ze,"LI",{});var nje=s(b4);Q8e=n(nje,"STRONG",{});var akt=s(Q8e);Lyr=r(akt,"mobilebert"),akt.forEach(t),yyr=r(nje," \u2014 "),RY=n(nje,"A",{href:!0});var nkt=s(RY);xyr=r(nkt,"TFMobileBertForNextSentencePrediction"),nkt.forEach(t),$yr=r(nje," (MobileBERT model)"),nje.forEach(t),$ze.forEach(t),kyr=i(Dl),T(v4.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),MVe=i(f),Lc=n(f,"H2",{class:!0});var kze=s(Lc);F4=n(kze,"A",{id:!0,class:!0,href:!0});var skt=s(F4);W8e=n(skt,"SPAN",{});var lkt=s(W8e);T(cx.$$.fragment,lkt),lkt.forEach(t),skt.forEach(t),Syr=i(kze),H8e=n(kze,"SPAN",{});var ikt=s(H8e);Ryr=r(ikt,"TFAutoModelForTableQuestionAnswering"),ikt.forEach(t),kze.forEach(t),EVe=i(f),dr=n(f,"DIV",{class:!0});var Gl=s(dr);T(fx.$$.fragment,Gl),Pyr=i(Gl),yc=n(Gl,"P",{});var Ire=s(yc);Byr=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PY=n(Ire,"A",{href:!0});var dkt=s(PY);Iyr=r(dkt,"from_pretrained()"),dkt.forEach(t),Nyr=r(Ire," class method or the "),BY=n(Ire,"A",{href:!0});var ckt=s(BY);qyr=r(ckt,"from_config()"),ckt.forEach(t),jyr=r(Ire,` class
method.`),Ire.forEach(t),Dyr=i(Gl),mx=n(Gl,"P",{});var Sze=s(mx);Gyr=r(Sze,"This class cannot be instantiated directly using "),U8e=n(Sze,"CODE",{});var fkt=s(U8e);Oyr=r(fkt,"__init__()"),fkt.forEach(t),Vyr=r(Sze," (throws an error)."),Sze.forEach(t),Xyr=i(Gl),jt=n(Gl,"DIV",{class:!0});var Hw=s(jt);T(gx.$$.fragment,Hw),zyr=i(Hw),J8e=n(Hw,"P",{});var mkt=s(J8e);Qyr=r(mkt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),mkt.forEach(t),Wyr=i(Hw),xc=n(Hw,"P",{});var Nre=s(xc);Hyr=r(Nre,`Note:
Loading a model from its configuration file does `),Y8e=n(Nre,"STRONG",{});var gkt=s(Y8e);Uyr=r(gkt,"not"),gkt.forEach(t),Jyr=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(Nre,"A",{href:!0});var hkt=s(IY);Yyr=r(hkt,"from_pretrained()"),hkt.forEach(t),Kyr=r(Nre," to load the model weights."),Nre.forEach(t),Zyr=i(Hw),T(T4.$$.fragment,Hw),Hw.forEach(t),e9r=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(hx.$$.fragment,Ol),o9r=i(Ol),K8e=n(Ol,"P",{});var pkt=s(K8e);r9r=r(pkt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),pkt.forEach(t),t9r=i(Ol),pn=n(Ol,"P",{});var Uw=s(pn);a9r=r(Uw,"The model class to instantiate is selected based on the "),Z8e=n(Uw,"CODE",{});var _kt=s(Z8e);n9r=r(_kt,"model_type"),_kt.forEach(t),s9r=r(Uw,` property of the config object (either
passed as an argument or loaded from `),eMe=n(Uw,"CODE",{});var ukt=s(eMe);l9r=r(ukt,"pretrained_model_name_or_path"),ukt.forEach(t),i9r=r(Uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oMe=n(Uw,"CODE",{});var bkt=s(oMe);d9r=r(bkt,"pretrained_model_name_or_path"),bkt.forEach(t),c9r=r(Uw,":"),Uw.forEach(t),f9r=i(Ol),rMe=n(Ol,"UL",{});var vkt=s(rMe);M4=n(vkt,"LI",{});var sje=s(M4);tMe=n(sje,"STRONG",{});var Fkt=s(tMe);m9r=r(Fkt,"tapas"),Fkt.forEach(t),g9r=r(sje," \u2014 "),NY=n(sje,"A",{href:!0});var Tkt=s(NY);h9r=r(Tkt,"TFTapasForQuestionAnswering"),Tkt.forEach(t),p9r=r(sje," (TAPAS model)"),sje.forEach(t),vkt.forEach(t),_9r=i(Ol),T(E4.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),CVe=i(f),$c=n(f,"H2",{class:!0});var Rze=s($c);C4=n(Rze,"A",{id:!0,class:!0,href:!0});var Mkt=s(C4);aMe=n(Mkt,"SPAN",{});var Ekt=s(aMe);T(px.$$.fragment,Ekt),Ekt.forEach(t),Mkt.forEach(t),u9r=i(Rze),nMe=n(Rze,"SPAN",{});var Ckt=s(nMe);b9r=r(Ckt,"TFAutoModelForTokenClassification"),Ckt.forEach(t),Rze.forEach(t),wVe=i(f),cr=n(f,"DIV",{class:!0});var Vl=s(cr);T(_x.$$.fragment,Vl),v9r=i(Vl),kc=n(Vl,"P",{});var qre=s(kc);F9r=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),qY=n(qre,"A",{href:!0});var wkt=s(qY);T9r=r(wkt,"from_pretrained()"),wkt.forEach(t),M9r=r(qre," class method or the "),jY=n(qre,"A",{href:!0});var Akt=s(jY);E9r=r(Akt,"from_config()"),Akt.forEach(t),C9r=r(qre,` class
method.`),qre.forEach(t),w9r=i(Vl),ux=n(Vl,"P",{});var Pze=s(ux);A9r=r(Pze,"This class cannot be instantiated directly using "),sMe=n(Pze,"CODE",{});var Lkt=s(sMe);L9r=r(Lkt,"__init__()"),Lkt.forEach(t),y9r=r(Pze," (throws an error)."),Pze.forEach(t),x9r=i(Vl),Dt=n(Vl,"DIV",{class:!0});var Jw=s(Dt);T(bx.$$.fragment,Jw),$9r=i(Jw),lMe=n(Jw,"P",{});var ykt=s(lMe);k9r=r(ykt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ykt.forEach(t),S9r=i(Jw),Sc=n(Jw,"P",{});var jre=s(Sc);R9r=r(jre,`Note:
Loading a model from its configuration file does `),iMe=n(jre,"STRONG",{});var xkt=s(iMe);P9r=r(xkt,"not"),xkt.forEach(t),B9r=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=n(jre,"A",{href:!0});var $kt=s(DY);I9r=r($kt,"from_pretrained()"),$kt.forEach(t),N9r=r(jre," to load the model weights."),jre.forEach(t),q9r=i(Jw),T(w4.$$.fragment,Jw),Jw.forEach(t),j9r=i(Vl),qr=n(Vl,"DIV",{class:!0});var Xl=s(qr);T(vx.$$.fragment,Xl),D9r=i(Xl),dMe=n(Xl,"P",{});var kkt=s(dMe);G9r=r(kkt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),kkt.forEach(t),O9r=i(Xl),_n=n(Xl,"P",{});var Yw=s(_n);V9r=r(Yw,"The model class to instantiate is selected based on the "),cMe=n(Yw,"CODE",{});var Skt=s(cMe);X9r=r(Skt,"model_type"),Skt.forEach(t),z9r=r(Yw,` property of the config object (either
passed as an argument or loaded from `),fMe=n(Yw,"CODE",{});var Rkt=s(fMe);Q9r=r(Rkt,"pretrained_model_name_or_path"),Rkt.forEach(t),W9r=r(Yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mMe=n(Yw,"CODE",{});var Pkt=s(mMe);H9r=r(Pkt,"pretrained_model_name_or_path"),Pkt.forEach(t),U9r=r(Yw,":"),Yw.forEach(t),J9r=i(Xl),de=n(Xl,"UL",{});var me=s(de);A4=n(me,"LI",{});var lje=s(A4);gMe=n(lje,"STRONG",{});var Bkt=s(gMe);Y9r=r(Bkt,"albert"),Bkt.forEach(t),K9r=r(lje," \u2014 "),GY=n(lje,"A",{href:!0});var Ikt=s(GY);Z9r=r(Ikt,"TFAlbertForTokenClassification"),Ikt.forEach(t),exr=r(lje," (ALBERT model)"),lje.forEach(t),oxr=i(me),L4=n(me,"LI",{});var ije=s(L4);hMe=n(ije,"STRONG",{});var Nkt=s(hMe);rxr=r(Nkt,"bert"),Nkt.forEach(t),txr=r(ije," \u2014 "),OY=n(ije,"A",{href:!0});var qkt=s(OY);axr=r(qkt,"TFBertForTokenClassification"),qkt.forEach(t),nxr=r(ije," (BERT model)"),ije.forEach(t),sxr=i(me),y4=n(me,"LI",{});var dje=s(y4);pMe=n(dje,"STRONG",{});var jkt=s(pMe);lxr=r(jkt,"camembert"),jkt.forEach(t),ixr=r(dje," \u2014 "),VY=n(dje,"A",{href:!0});var Dkt=s(VY);dxr=r(Dkt,"TFCamembertForTokenClassification"),Dkt.forEach(t),cxr=r(dje," (CamemBERT model)"),dje.forEach(t),fxr=i(me),x4=n(me,"LI",{});var cje=s(x4);_Me=n(cje,"STRONG",{});var Gkt=s(_Me);mxr=r(Gkt,"convbert"),Gkt.forEach(t),gxr=r(cje," \u2014 "),XY=n(cje,"A",{href:!0});var Okt=s(XY);hxr=r(Okt,"TFConvBertForTokenClassification"),Okt.forEach(t),pxr=r(cje," (ConvBERT model)"),cje.forEach(t),_xr=i(me),$4=n(me,"LI",{});var fje=s($4);uMe=n(fje,"STRONG",{});var Vkt=s(uMe);uxr=r(Vkt,"deberta"),Vkt.forEach(t),bxr=r(fje," \u2014 "),zY=n(fje,"A",{href:!0});var Xkt=s(zY);vxr=r(Xkt,"TFDebertaForTokenClassification"),Xkt.forEach(t),Fxr=r(fje," (DeBERTa model)"),fje.forEach(t),Txr=i(me),k4=n(me,"LI",{});var mje=s(k4);bMe=n(mje,"STRONG",{});var zkt=s(bMe);Mxr=r(zkt,"deberta-v2"),zkt.forEach(t),Exr=r(mje," \u2014 "),QY=n(mje,"A",{href:!0});var Qkt=s(QY);Cxr=r(Qkt,"TFDebertaV2ForTokenClassification"),Qkt.forEach(t),wxr=r(mje," (DeBERTa-v2 model)"),mje.forEach(t),Axr=i(me),S4=n(me,"LI",{});var gje=s(S4);vMe=n(gje,"STRONG",{});var Wkt=s(vMe);Lxr=r(Wkt,"distilbert"),Wkt.forEach(t),yxr=r(gje," \u2014 "),WY=n(gje,"A",{href:!0});var Hkt=s(WY);xxr=r(Hkt,"TFDistilBertForTokenClassification"),Hkt.forEach(t),$xr=r(gje," (DistilBERT model)"),gje.forEach(t),kxr=i(me),R4=n(me,"LI",{});var hje=s(R4);FMe=n(hje,"STRONG",{});var Ukt=s(FMe);Sxr=r(Ukt,"electra"),Ukt.forEach(t),Rxr=r(hje," \u2014 "),HY=n(hje,"A",{href:!0});var Jkt=s(HY);Pxr=r(Jkt,"TFElectraForTokenClassification"),Jkt.forEach(t),Bxr=r(hje," (ELECTRA model)"),hje.forEach(t),Ixr=i(me),P4=n(me,"LI",{});var pje=s(P4);TMe=n(pje,"STRONG",{});var Ykt=s(TMe);Nxr=r(Ykt,"flaubert"),Ykt.forEach(t),qxr=r(pje," \u2014 "),UY=n(pje,"A",{href:!0});var Kkt=s(UY);jxr=r(Kkt,"TFFlaubertForTokenClassification"),Kkt.forEach(t),Dxr=r(pje," (FlauBERT model)"),pje.forEach(t),Gxr=i(me),B4=n(me,"LI",{});var _je=s(B4);MMe=n(_je,"STRONG",{});var Zkt=s(MMe);Oxr=r(Zkt,"funnel"),Zkt.forEach(t),Vxr=r(_je," \u2014 "),JY=n(_je,"A",{href:!0});var eSt=s(JY);Xxr=r(eSt,"TFFunnelForTokenClassification"),eSt.forEach(t),zxr=r(_je," (Funnel Transformer model)"),_je.forEach(t),Qxr=i(me),I4=n(me,"LI",{});var uje=s(I4);EMe=n(uje,"STRONG",{});var oSt=s(EMe);Wxr=r(oSt,"layoutlm"),oSt.forEach(t),Hxr=r(uje," \u2014 "),YY=n(uje,"A",{href:!0});var rSt=s(YY);Uxr=r(rSt,"TFLayoutLMForTokenClassification"),rSt.forEach(t),Jxr=r(uje," (LayoutLM model)"),uje.forEach(t),Yxr=i(me),N4=n(me,"LI",{});var bje=s(N4);CMe=n(bje,"STRONG",{});var tSt=s(CMe);Kxr=r(tSt,"longformer"),tSt.forEach(t),Zxr=r(bje," \u2014 "),KY=n(bje,"A",{href:!0});var aSt=s(KY);e$r=r(aSt,"TFLongformerForTokenClassification"),aSt.forEach(t),o$r=r(bje," (Longformer model)"),bje.forEach(t),r$r=i(me),q4=n(me,"LI",{});var vje=s(q4);wMe=n(vje,"STRONG",{});var nSt=s(wMe);t$r=r(nSt,"mobilebert"),nSt.forEach(t),a$r=r(vje," \u2014 "),ZY=n(vje,"A",{href:!0});var sSt=s(ZY);n$r=r(sSt,"TFMobileBertForTokenClassification"),sSt.forEach(t),s$r=r(vje," (MobileBERT model)"),vje.forEach(t),l$r=i(me),j4=n(me,"LI",{});var Fje=s(j4);AMe=n(Fje,"STRONG",{});var lSt=s(AMe);i$r=r(lSt,"mpnet"),lSt.forEach(t),d$r=r(Fje," \u2014 "),eK=n(Fje,"A",{href:!0});var iSt=s(eK);c$r=r(iSt,"TFMPNetForTokenClassification"),iSt.forEach(t),f$r=r(Fje," (MPNet model)"),Fje.forEach(t),m$r=i(me),D4=n(me,"LI",{});var Tje=s(D4);LMe=n(Tje,"STRONG",{});var dSt=s(LMe);g$r=r(dSt,"rembert"),dSt.forEach(t),h$r=r(Tje," \u2014 "),oK=n(Tje,"A",{href:!0});var cSt=s(oK);p$r=r(cSt,"TFRemBertForTokenClassification"),cSt.forEach(t),_$r=r(Tje," (RemBERT model)"),Tje.forEach(t),u$r=i(me),G4=n(me,"LI",{});var Mje=s(G4);yMe=n(Mje,"STRONG",{});var fSt=s(yMe);b$r=r(fSt,"roberta"),fSt.forEach(t),v$r=r(Mje," \u2014 "),rK=n(Mje,"A",{href:!0});var mSt=s(rK);F$r=r(mSt,"TFRobertaForTokenClassification"),mSt.forEach(t),T$r=r(Mje," (RoBERTa model)"),Mje.forEach(t),M$r=i(me),O4=n(me,"LI",{});var Eje=s(O4);xMe=n(Eje,"STRONG",{});var gSt=s(xMe);E$r=r(gSt,"roformer"),gSt.forEach(t),C$r=r(Eje," \u2014 "),tK=n(Eje,"A",{href:!0});var hSt=s(tK);w$r=r(hSt,"TFRoFormerForTokenClassification"),hSt.forEach(t),A$r=r(Eje," (RoFormer model)"),Eje.forEach(t),L$r=i(me),V4=n(me,"LI",{});var Cje=s(V4);$Me=n(Cje,"STRONG",{});var pSt=s($Me);y$r=r(pSt,"xlm"),pSt.forEach(t),x$r=r(Cje," \u2014 "),aK=n(Cje,"A",{href:!0});var _St=s(aK);$$r=r(_St,"TFXLMForTokenClassification"),_St.forEach(t),k$r=r(Cje," (XLM model)"),Cje.forEach(t),S$r=i(me),X4=n(me,"LI",{});var wje=s(X4);kMe=n(wje,"STRONG",{});var uSt=s(kMe);R$r=r(uSt,"xlm-roberta"),uSt.forEach(t),P$r=r(wje," \u2014 "),nK=n(wje,"A",{href:!0});var bSt=s(nK);B$r=r(bSt,"TFXLMRobertaForTokenClassification"),bSt.forEach(t),I$r=r(wje," (XLM-RoBERTa model)"),wje.forEach(t),N$r=i(me),z4=n(me,"LI",{});var Aje=s(z4);SMe=n(Aje,"STRONG",{});var vSt=s(SMe);q$r=r(vSt,"xlnet"),vSt.forEach(t),j$r=r(Aje," \u2014 "),sK=n(Aje,"A",{href:!0});var FSt=s(sK);D$r=r(FSt,"TFXLNetForTokenClassification"),FSt.forEach(t),G$r=r(Aje," (XLNet model)"),Aje.forEach(t),me.forEach(t),O$r=i(Xl),T(Q4.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),AVe=i(f),Rc=n(f,"H2",{class:!0});var Bze=s(Rc);W4=n(Bze,"A",{id:!0,class:!0,href:!0});var TSt=s(W4);RMe=n(TSt,"SPAN",{});var MSt=s(RMe);T(Fx.$$.fragment,MSt),MSt.forEach(t),TSt.forEach(t),V$r=i(Bze),PMe=n(Bze,"SPAN",{});var ESt=s(PMe);X$r=r(ESt,"TFAutoModelForQuestionAnswering"),ESt.forEach(t),Bze.forEach(t),LVe=i(f),fr=n(f,"DIV",{class:!0});var zl=s(fr);T(Tx.$$.fragment,zl),z$r=i(zl),Pc=n(zl,"P",{});var Dre=s(Pc);Q$r=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),lK=n(Dre,"A",{href:!0});var CSt=s(lK);W$r=r(CSt,"from_pretrained()"),CSt.forEach(t),H$r=r(Dre," class method or the "),iK=n(Dre,"A",{href:!0});var wSt=s(iK);U$r=r(wSt,"from_config()"),wSt.forEach(t),J$r=r(Dre,` class
method.`),Dre.forEach(t),Y$r=i(zl),Mx=n(zl,"P",{});var Ize=s(Mx);K$r=r(Ize,"This class cannot be instantiated directly using "),BMe=n(Ize,"CODE",{});var ASt=s(BMe);Z$r=r(ASt,"__init__()"),ASt.forEach(t),ekr=r(Ize," (throws an error)."),Ize.forEach(t),okr=i(zl),Gt=n(zl,"DIV",{class:!0});var Kw=s(Gt);T(Ex.$$.fragment,Kw),rkr=i(Kw),IMe=n(Kw,"P",{});var LSt=s(IMe);tkr=r(LSt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),LSt.forEach(t),akr=i(Kw),Bc=n(Kw,"P",{});var Gre=s(Bc);nkr=r(Gre,`Note:
Loading a model from its configuration file does `),NMe=n(Gre,"STRONG",{});var ySt=s(NMe);skr=r(ySt,"not"),ySt.forEach(t),lkr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),dK=n(Gre,"A",{href:!0});var xSt=s(dK);ikr=r(xSt,"from_pretrained()"),xSt.forEach(t),dkr=r(Gre," to load the model weights."),Gre.forEach(t),ckr=i(Kw),T(H4.$$.fragment,Kw),Kw.forEach(t),fkr=i(zl),jr=n(zl,"DIV",{class:!0});var Ql=s(jr);T(Cx.$$.fragment,Ql),mkr=i(Ql),qMe=n(Ql,"P",{});var $St=s(qMe);gkr=r($St,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$St.forEach(t),hkr=i(Ql),un=n(Ql,"P",{});var Zw=s(un);pkr=r(Zw,"The model class to instantiate is selected based on the "),jMe=n(Zw,"CODE",{});var kSt=s(jMe);_kr=r(kSt,"model_type"),kSt.forEach(t),ukr=r(Zw,` property of the config object (either
passed as an argument or loaded from `),DMe=n(Zw,"CODE",{});var SSt=s(DMe);bkr=r(SSt,"pretrained_model_name_or_path"),SSt.forEach(t),vkr=r(Zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GMe=n(Zw,"CODE",{});var RSt=s(GMe);Fkr=r(RSt,"pretrained_model_name_or_path"),RSt.forEach(t),Tkr=r(Zw,":"),Zw.forEach(t),Mkr=i(Ql),ce=n(Ql,"UL",{});var ge=s(ce);U4=n(ge,"LI",{});var Lje=s(U4);OMe=n(Lje,"STRONG",{});var PSt=s(OMe);Ekr=r(PSt,"albert"),PSt.forEach(t),Ckr=r(Lje," \u2014 "),cK=n(Lje,"A",{href:!0});var BSt=s(cK);wkr=r(BSt,"TFAlbertForQuestionAnswering"),BSt.forEach(t),Akr=r(Lje," (ALBERT model)"),Lje.forEach(t),Lkr=i(ge),J4=n(ge,"LI",{});var yje=s(J4);VMe=n(yje,"STRONG",{});var ISt=s(VMe);ykr=r(ISt,"bert"),ISt.forEach(t),xkr=r(yje," \u2014 "),fK=n(yje,"A",{href:!0});var NSt=s(fK);$kr=r(NSt,"TFBertForQuestionAnswering"),NSt.forEach(t),kkr=r(yje," (BERT model)"),yje.forEach(t),Skr=i(ge),Y4=n(ge,"LI",{});var xje=s(Y4);XMe=n(xje,"STRONG",{});var qSt=s(XMe);Rkr=r(qSt,"camembert"),qSt.forEach(t),Pkr=r(xje," \u2014 "),mK=n(xje,"A",{href:!0});var jSt=s(mK);Bkr=r(jSt,"TFCamembertForQuestionAnswering"),jSt.forEach(t),Ikr=r(xje," (CamemBERT model)"),xje.forEach(t),Nkr=i(ge),K4=n(ge,"LI",{});var $je=s(K4);zMe=n($je,"STRONG",{});var DSt=s(zMe);qkr=r(DSt,"convbert"),DSt.forEach(t),jkr=r($je," \u2014 "),gK=n($je,"A",{href:!0});var GSt=s(gK);Dkr=r(GSt,"TFConvBertForQuestionAnswering"),GSt.forEach(t),Gkr=r($je," (ConvBERT model)"),$je.forEach(t),Okr=i(ge),Z4=n(ge,"LI",{});var kje=s(Z4);QMe=n(kje,"STRONG",{});var OSt=s(QMe);Vkr=r(OSt,"deberta"),OSt.forEach(t),Xkr=r(kje," \u2014 "),hK=n(kje,"A",{href:!0});var VSt=s(hK);zkr=r(VSt,"TFDebertaForQuestionAnswering"),VSt.forEach(t),Qkr=r(kje," (DeBERTa model)"),kje.forEach(t),Wkr=i(ge),eC=n(ge,"LI",{});var Sje=s(eC);WMe=n(Sje,"STRONG",{});var XSt=s(WMe);Hkr=r(XSt,"deberta-v2"),XSt.forEach(t),Ukr=r(Sje," \u2014 "),pK=n(Sje,"A",{href:!0});var zSt=s(pK);Jkr=r(zSt,"TFDebertaV2ForQuestionAnswering"),zSt.forEach(t),Ykr=r(Sje," (DeBERTa-v2 model)"),Sje.forEach(t),Kkr=i(ge),oC=n(ge,"LI",{});var Rje=s(oC);HMe=n(Rje,"STRONG",{});var QSt=s(HMe);Zkr=r(QSt,"distilbert"),QSt.forEach(t),eSr=r(Rje," \u2014 "),_K=n(Rje,"A",{href:!0});var WSt=s(_K);oSr=r(WSt,"TFDistilBertForQuestionAnswering"),WSt.forEach(t),rSr=r(Rje," (DistilBERT model)"),Rje.forEach(t),tSr=i(ge),rC=n(ge,"LI",{});var Pje=s(rC);UMe=n(Pje,"STRONG",{});var HSt=s(UMe);aSr=r(HSt,"electra"),HSt.forEach(t),nSr=r(Pje," \u2014 "),uK=n(Pje,"A",{href:!0});var USt=s(uK);sSr=r(USt,"TFElectraForQuestionAnswering"),USt.forEach(t),lSr=r(Pje," (ELECTRA model)"),Pje.forEach(t),iSr=i(ge),tC=n(ge,"LI",{});var Bje=s(tC);JMe=n(Bje,"STRONG",{});var JSt=s(JMe);dSr=r(JSt,"flaubert"),JSt.forEach(t),cSr=r(Bje," \u2014 "),bK=n(Bje,"A",{href:!0});var YSt=s(bK);fSr=r(YSt,"TFFlaubertForQuestionAnsweringSimple"),YSt.forEach(t),mSr=r(Bje," (FlauBERT model)"),Bje.forEach(t),gSr=i(ge),aC=n(ge,"LI",{});var Ije=s(aC);YMe=n(Ije,"STRONG",{});var KSt=s(YMe);hSr=r(KSt,"funnel"),KSt.forEach(t),pSr=r(Ije," \u2014 "),vK=n(Ije,"A",{href:!0});var ZSt=s(vK);_Sr=r(ZSt,"TFFunnelForQuestionAnswering"),ZSt.forEach(t),uSr=r(Ije," (Funnel Transformer model)"),Ije.forEach(t),bSr=i(ge),nC=n(ge,"LI",{});var Nje=s(nC);KMe=n(Nje,"STRONG",{});var eRt=s(KMe);vSr=r(eRt,"gptj"),eRt.forEach(t),FSr=r(Nje," \u2014 "),FK=n(Nje,"A",{href:!0});var oRt=s(FK);TSr=r(oRt,"TFGPTJForQuestionAnswering"),oRt.forEach(t),MSr=r(Nje," (GPT-J model)"),Nje.forEach(t),ESr=i(ge),sC=n(ge,"LI",{});var qje=s(sC);ZMe=n(qje,"STRONG",{});var rRt=s(ZMe);CSr=r(rRt,"longformer"),rRt.forEach(t),wSr=r(qje," \u2014 "),TK=n(qje,"A",{href:!0});var tRt=s(TK);ASr=r(tRt,"TFLongformerForQuestionAnswering"),tRt.forEach(t),LSr=r(qje," (Longformer model)"),qje.forEach(t),ySr=i(ge),lC=n(ge,"LI",{});var jje=s(lC);eEe=n(jje,"STRONG",{});var aRt=s(eEe);xSr=r(aRt,"mobilebert"),aRt.forEach(t),$Sr=r(jje," \u2014 "),MK=n(jje,"A",{href:!0});var nRt=s(MK);kSr=r(nRt,"TFMobileBertForQuestionAnswering"),nRt.forEach(t),SSr=r(jje," (MobileBERT model)"),jje.forEach(t),RSr=i(ge),iC=n(ge,"LI",{});var Dje=s(iC);oEe=n(Dje,"STRONG",{});var sRt=s(oEe);PSr=r(sRt,"mpnet"),sRt.forEach(t),BSr=r(Dje," \u2014 "),EK=n(Dje,"A",{href:!0});var lRt=s(EK);ISr=r(lRt,"TFMPNetForQuestionAnswering"),lRt.forEach(t),NSr=r(Dje," (MPNet model)"),Dje.forEach(t),qSr=i(ge),dC=n(ge,"LI",{});var Gje=s(dC);rEe=n(Gje,"STRONG",{});var iRt=s(rEe);jSr=r(iRt,"rembert"),iRt.forEach(t),DSr=r(Gje," \u2014 "),CK=n(Gje,"A",{href:!0});var dRt=s(CK);GSr=r(dRt,"TFRemBertForQuestionAnswering"),dRt.forEach(t),OSr=r(Gje," (RemBERT model)"),Gje.forEach(t),VSr=i(ge),cC=n(ge,"LI",{});var Oje=s(cC);tEe=n(Oje,"STRONG",{});var cRt=s(tEe);XSr=r(cRt,"roberta"),cRt.forEach(t),zSr=r(Oje," \u2014 "),wK=n(Oje,"A",{href:!0});var fRt=s(wK);QSr=r(fRt,"TFRobertaForQuestionAnswering"),fRt.forEach(t),WSr=r(Oje," (RoBERTa model)"),Oje.forEach(t),HSr=i(ge),fC=n(ge,"LI",{});var Vje=s(fC);aEe=n(Vje,"STRONG",{});var mRt=s(aEe);USr=r(mRt,"roformer"),mRt.forEach(t),JSr=r(Vje," \u2014 "),AK=n(Vje,"A",{href:!0});var gRt=s(AK);YSr=r(gRt,"TFRoFormerForQuestionAnswering"),gRt.forEach(t),KSr=r(Vje," (RoFormer model)"),Vje.forEach(t),ZSr=i(ge),mC=n(ge,"LI",{});var Xje=s(mC);nEe=n(Xje,"STRONG",{});var hRt=s(nEe);eRr=r(hRt,"xlm"),hRt.forEach(t),oRr=r(Xje," \u2014 "),LK=n(Xje,"A",{href:!0});var pRt=s(LK);rRr=r(pRt,"TFXLMForQuestionAnsweringSimple"),pRt.forEach(t),tRr=r(Xje," (XLM model)"),Xje.forEach(t),aRr=i(ge),gC=n(ge,"LI",{});var zje=s(gC);sEe=n(zje,"STRONG",{});var _Rt=s(sEe);nRr=r(_Rt,"xlm-roberta"),_Rt.forEach(t),sRr=r(zje," \u2014 "),yK=n(zje,"A",{href:!0});var uRt=s(yK);lRr=r(uRt,"TFXLMRobertaForQuestionAnswering"),uRt.forEach(t),iRr=r(zje," (XLM-RoBERTa model)"),zje.forEach(t),dRr=i(ge),hC=n(ge,"LI",{});var Qje=s(hC);lEe=n(Qje,"STRONG",{});var bRt=s(lEe);cRr=r(bRt,"xlnet"),bRt.forEach(t),fRr=r(Qje," \u2014 "),xK=n(Qje,"A",{href:!0});var vRt=s(xK);mRr=r(vRt,"TFXLNetForQuestionAnsweringSimple"),vRt.forEach(t),gRr=r(Qje," (XLNet model)"),Qje.forEach(t),ge.forEach(t),hRr=i(Ql),T(pC.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),yVe=i(f),Ic=n(f,"H2",{class:!0});var Nze=s(Ic);_C=n(Nze,"A",{id:!0,class:!0,href:!0});var FRt=s(_C);iEe=n(FRt,"SPAN",{});var TRt=s(iEe);T(wx.$$.fragment,TRt),TRt.forEach(t),FRt.forEach(t),pRr=i(Nze),dEe=n(Nze,"SPAN",{});var MRt=s(dEe);_Rr=r(MRt,"TFAutoModelForVision2Seq"),MRt.forEach(t),Nze.forEach(t),xVe=i(f),mr=n(f,"DIV",{class:!0});var Wl=s(mr);T(Ax.$$.fragment,Wl),uRr=i(Wl),Nc=n(Wl,"P",{});var Ore=s(Nc);bRr=r(Ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$K=n(Ore,"A",{href:!0});var ERt=s($K);vRr=r(ERt,"from_pretrained()"),ERt.forEach(t),FRr=r(Ore," class method or the "),kK=n(Ore,"A",{href:!0});var CRt=s(kK);TRr=r(CRt,"from_config()"),CRt.forEach(t),MRr=r(Ore,` class
method.`),Ore.forEach(t),ERr=i(Wl),Lx=n(Wl,"P",{});var qze=s(Lx);CRr=r(qze,"This class cannot be instantiated directly using "),cEe=n(qze,"CODE",{});var wRt=s(cEe);wRr=r(wRt,"__init__()"),wRt.forEach(t),ARr=r(qze," (throws an error)."),qze.forEach(t),LRr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var eA=s(Ot);T(yx.$$.fragment,eA),yRr=i(eA),fEe=n(eA,"P",{});var ARt=s(fEe);xRr=r(ARt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ARt.forEach(t),$Rr=i(eA),qc=n(eA,"P",{});var Vre=s(qc);kRr=r(Vre,`Note:
Loading a model from its configuration file does `),mEe=n(Vre,"STRONG",{});var LRt=s(mEe);SRr=r(LRt,"not"),LRt.forEach(t),RRr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(Vre,"A",{href:!0});var yRt=s(SK);PRr=r(yRt,"from_pretrained()"),yRt.forEach(t),BRr=r(Vre," to load the model weights."),Vre.forEach(t),IRr=i(eA),T(uC.$$.fragment,eA),eA.forEach(t),NRr=i(Wl),Dr=n(Wl,"DIV",{class:!0});var Hl=s(Dr);T(xx.$$.fragment,Hl),qRr=i(Hl),gEe=n(Hl,"P",{});var xRt=s(gEe);jRr=r(xRt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xRt.forEach(t),DRr=i(Hl),bn=n(Hl,"P",{});var oA=s(bn);GRr=r(oA,"The model class to instantiate is selected based on the "),hEe=n(oA,"CODE",{});var $Rt=s(hEe);ORr=r($Rt,"model_type"),$Rt.forEach(t),VRr=r(oA,` property of the config object (either
passed as an argument or loaded from `),pEe=n(oA,"CODE",{});var kRt=s(pEe);XRr=r(kRt,"pretrained_model_name_or_path"),kRt.forEach(t),zRr=r(oA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ee=n(oA,"CODE",{});var SRt=s(_Ee);QRr=r(SRt,"pretrained_model_name_or_path"),SRt.forEach(t),WRr=r(oA,":"),oA.forEach(t),HRr=i(Hl),uEe=n(Hl,"UL",{});var RRt=s(uEe);bC=n(RRt,"LI",{});var Wje=s(bC);bEe=n(Wje,"STRONG",{});var PRt=s(bEe);URr=r(PRt,"vision-encoder-decoder"),PRt.forEach(t),JRr=r(Wje," \u2014 "),RK=n(Wje,"A",{href:!0});var BRt=s(RK);YRr=r(BRt,"TFVisionEncoderDecoderModel"),BRt.forEach(t),KRr=r(Wje," (Vision Encoder decoder model)"),Wje.forEach(t),RRt.forEach(t),ZRr=i(Hl),T(vC.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),$Ve=i(f),jc=n(f,"H2",{class:!0});var jze=s(jc);FC=n(jze,"A",{id:!0,class:!0,href:!0});var IRt=s(FC);vEe=n(IRt,"SPAN",{});var NRt=s(vEe);T($x.$$.fragment,NRt),NRt.forEach(t),IRt.forEach(t),ePr=i(jze),FEe=n(jze,"SPAN",{});var qRt=s(FEe);oPr=r(qRt,"TFAutoModelForSpeechSeq2Seq"),qRt.forEach(t),jze.forEach(t),kVe=i(f),gr=n(f,"DIV",{class:!0});var Ul=s(gr);T(kx.$$.fragment,Ul),rPr=i(Ul),Dc=n(Ul,"P",{});var Xre=s(Dc);tPr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),PK=n(Xre,"A",{href:!0});var jRt=s(PK);aPr=r(jRt,"from_pretrained()"),jRt.forEach(t),nPr=r(Xre," class method or the "),BK=n(Xre,"A",{href:!0});var DRt=s(BK);sPr=r(DRt,"from_config()"),DRt.forEach(t),lPr=r(Xre,` class
method.`),Xre.forEach(t),iPr=i(Ul),Sx=n(Ul,"P",{});var Dze=s(Sx);dPr=r(Dze,"This class cannot be instantiated directly using "),TEe=n(Dze,"CODE",{});var GRt=s(TEe);cPr=r(GRt,"__init__()"),GRt.forEach(t),fPr=r(Dze," (throws an error)."),Dze.forEach(t),mPr=i(Ul),Vt=n(Ul,"DIV",{class:!0});var rA=s(Vt);T(Rx.$$.fragment,rA),gPr=i(rA),MEe=n(rA,"P",{});var ORt=s(MEe);hPr=r(ORt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ORt.forEach(t),pPr=i(rA),Gc=n(rA,"P",{});var zre=s(Gc);_Pr=r(zre,`Note:
Loading a model from its configuration file does `),EEe=n(zre,"STRONG",{});var VRt=s(EEe);uPr=r(VRt,"not"),VRt.forEach(t),bPr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(zre,"A",{href:!0});var XRt=s(IK);vPr=r(XRt,"from_pretrained()"),XRt.forEach(t),FPr=r(zre," to load the model weights."),zre.forEach(t),TPr=i(rA),T(TC.$$.fragment,rA),rA.forEach(t),MPr=i(Ul),Gr=n(Ul,"DIV",{class:!0});var Jl=s(Gr);T(Px.$$.fragment,Jl),EPr=i(Jl),CEe=n(Jl,"P",{});var zRt=s(CEe);CPr=r(zRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),zRt.forEach(t),wPr=i(Jl),vn=n(Jl,"P",{});var tA=s(vn);APr=r(tA,"The model class to instantiate is selected based on the "),wEe=n(tA,"CODE",{});var QRt=s(wEe);LPr=r(QRt,"model_type"),QRt.forEach(t),yPr=r(tA,` property of the config object (either
passed as an argument or loaded from `),AEe=n(tA,"CODE",{});var WRt=s(AEe);xPr=r(WRt,"pretrained_model_name_or_path"),WRt.forEach(t),$Pr=r(tA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=n(tA,"CODE",{});var HRt=s(LEe);kPr=r(HRt,"pretrained_model_name_or_path"),HRt.forEach(t),SPr=r(tA,":"),tA.forEach(t),RPr=i(Jl),yEe=n(Jl,"UL",{});var URt=s(yEe);MC=n(URt,"LI",{});var Hje=s(MC);xEe=n(Hje,"STRONG",{});var JRt=s(xEe);PPr=r(JRt,"speech_to_text"),JRt.forEach(t),BPr=r(Hje," \u2014 "),NK=n(Hje,"A",{href:!0});var YRt=s(NK);IPr=r(YRt,"TFSpeech2TextForConditionalGeneration"),YRt.forEach(t),NPr=r(Hje," (Speech2Text model)"),Hje.forEach(t),URt.forEach(t),qPr=i(Jl),T(EC.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),SVe=i(f),Oc=n(f,"H2",{class:!0});var Gze=s(Oc);CC=n(Gze,"A",{id:!0,class:!0,href:!0});var KRt=s(CC);$Ee=n(KRt,"SPAN",{});var ZRt=s($Ee);T(Bx.$$.fragment,ZRt),ZRt.forEach(t),KRt.forEach(t),jPr=i(Gze),kEe=n(Gze,"SPAN",{});var ePt=s(kEe);DPr=r(ePt,"FlaxAutoModel"),ePt.forEach(t),Gze.forEach(t),RVe=i(f),hr=n(f,"DIV",{class:!0});var Yl=s(hr);T(Ix.$$.fragment,Yl),GPr=i(Yl),Vc=n(Yl,"P",{});var Qre=s(Vc);OPr=r(Qre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),qK=n(Qre,"A",{href:!0});var oPt=s(qK);VPr=r(oPt,"from_pretrained()"),oPt.forEach(t),XPr=r(Qre," class method or the "),jK=n(Qre,"A",{href:!0});var rPt=s(jK);zPr=r(rPt,"from_config()"),rPt.forEach(t),QPr=r(Qre,` class
method.`),Qre.forEach(t),WPr=i(Yl),Nx=n(Yl,"P",{});var Oze=s(Nx);HPr=r(Oze,"This class cannot be instantiated directly using "),SEe=n(Oze,"CODE",{});var tPt=s(SEe);UPr=r(tPt,"__init__()"),tPt.forEach(t),JPr=r(Oze," (throws an error)."),Oze.forEach(t),YPr=i(Yl),Xt=n(Yl,"DIV",{class:!0});var aA=s(Xt);T(qx.$$.fragment,aA),KPr=i(aA),REe=n(aA,"P",{});var aPt=s(REe);ZPr=r(aPt,"Instantiates one of the base model classes of the library from a configuration."),aPt.forEach(t),eBr=i(aA),Xc=n(aA,"P",{});var Wre=s(Xc);oBr=r(Wre,`Note:
Loading a model from its configuration file does `),PEe=n(Wre,"STRONG",{});var nPt=s(PEe);rBr=r(nPt,"not"),nPt.forEach(t),tBr=r(Wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=n(Wre,"A",{href:!0});var sPt=s(DK);aBr=r(sPt,"from_pretrained()"),sPt.forEach(t),nBr=r(Wre," to load the model weights."),Wre.forEach(t),sBr=i(aA),T(wC.$$.fragment,aA),aA.forEach(t),lBr=i(Yl),Or=n(Yl,"DIV",{class:!0});var Kl=s(Or);T(jx.$$.fragment,Kl),iBr=i(Kl),BEe=n(Kl,"P",{});var lPt=s(BEe);dBr=r(lPt,"Instantiate one of the base model classes of the library from a pretrained model."),lPt.forEach(t),cBr=i(Kl),Fn=n(Kl,"P",{});var nA=s(Fn);fBr=r(nA,"The model class to instantiate is selected based on the "),IEe=n(nA,"CODE",{});var iPt=s(IEe);mBr=r(iPt,"model_type"),iPt.forEach(t),gBr=r(nA,` property of the config object (either
passed as an argument or loaded from `),NEe=n(nA,"CODE",{});var dPt=s(NEe);hBr=r(dPt,"pretrained_model_name_or_path"),dPt.forEach(t),pBr=r(nA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qEe=n(nA,"CODE",{});var cPt=s(qEe);_Br=r(cPt,"pretrained_model_name_or_path"),cPt.forEach(t),uBr=r(nA,":"),nA.forEach(t),bBr=i(Kl),oe=n(Kl,"UL",{});var ae=s(oe);AC=n(ae,"LI",{});var Uje=s(AC);jEe=n(Uje,"STRONG",{});var fPt=s(jEe);vBr=r(fPt,"albert"),fPt.forEach(t),FBr=r(Uje," \u2014 "),GK=n(Uje,"A",{href:!0});var mPt=s(GK);TBr=r(mPt,"FlaxAlbertModel"),mPt.forEach(t),MBr=r(Uje," (ALBERT model)"),Uje.forEach(t),EBr=i(ae),LC=n(ae,"LI",{});var Jje=s(LC);DEe=n(Jje,"STRONG",{});var gPt=s(DEe);CBr=r(gPt,"bart"),gPt.forEach(t),wBr=r(Jje," \u2014 "),OK=n(Jje,"A",{href:!0});var hPt=s(OK);ABr=r(hPt,"FlaxBartModel"),hPt.forEach(t),LBr=r(Jje," (BART model)"),Jje.forEach(t),yBr=i(ae),yC=n(ae,"LI",{});var Yje=s(yC);GEe=n(Yje,"STRONG",{});var pPt=s(GEe);xBr=r(pPt,"beit"),pPt.forEach(t),$Br=r(Yje," \u2014 "),VK=n(Yje,"A",{href:!0});var _Pt=s(VK);kBr=r(_Pt,"FlaxBeitModel"),_Pt.forEach(t),SBr=r(Yje," (BEiT model)"),Yje.forEach(t),RBr=i(ae),xC=n(ae,"LI",{});var Kje=s(xC);OEe=n(Kje,"STRONG",{});var uPt=s(OEe);PBr=r(uPt,"bert"),uPt.forEach(t),BBr=r(Kje," \u2014 "),XK=n(Kje,"A",{href:!0});var bPt=s(XK);IBr=r(bPt,"FlaxBertModel"),bPt.forEach(t),NBr=r(Kje," (BERT model)"),Kje.forEach(t),qBr=i(ae),$C=n(ae,"LI",{});var Zje=s($C);VEe=n(Zje,"STRONG",{});var vPt=s(VEe);jBr=r(vPt,"big_bird"),vPt.forEach(t),DBr=r(Zje," \u2014 "),zK=n(Zje,"A",{href:!0});var FPt=s(zK);GBr=r(FPt,"FlaxBigBirdModel"),FPt.forEach(t),OBr=r(Zje," (BigBird model)"),Zje.forEach(t),VBr=i(ae),kC=n(ae,"LI",{});var eDe=s(kC);XEe=n(eDe,"STRONG",{});var TPt=s(XEe);XBr=r(TPt,"blenderbot"),TPt.forEach(t),zBr=r(eDe," \u2014 "),QK=n(eDe,"A",{href:!0});var MPt=s(QK);QBr=r(MPt,"FlaxBlenderbotModel"),MPt.forEach(t),WBr=r(eDe," (Blenderbot model)"),eDe.forEach(t),HBr=i(ae),SC=n(ae,"LI",{});var oDe=s(SC);zEe=n(oDe,"STRONG",{});var EPt=s(zEe);UBr=r(EPt,"blenderbot-small"),EPt.forEach(t),JBr=r(oDe," \u2014 "),WK=n(oDe,"A",{href:!0});var CPt=s(WK);YBr=r(CPt,"FlaxBlenderbotSmallModel"),CPt.forEach(t),KBr=r(oDe," (BlenderbotSmall model)"),oDe.forEach(t),ZBr=i(ae),RC=n(ae,"LI",{});var rDe=s(RC);QEe=n(rDe,"STRONG",{});var wPt=s(QEe);eIr=r(wPt,"clip"),wPt.forEach(t),oIr=r(rDe," \u2014 "),HK=n(rDe,"A",{href:!0});var APt=s(HK);rIr=r(APt,"FlaxCLIPModel"),APt.forEach(t),tIr=r(rDe," (CLIP model)"),rDe.forEach(t),aIr=i(ae),PC=n(ae,"LI",{});var tDe=s(PC);WEe=n(tDe,"STRONG",{});var LPt=s(WEe);nIr=r(LPt,"distilbert"),LPt.forEach(t),sIr=r(tDe," \u2014 "),UK=n(tDe,"A",{href:!0});var yPt=s(UK);lIr=r(yPt,"FlaxDistilBertModel"),yPt.forEach(t),iIr=r(tDe," (DistilBERT model)"),tDe.forEach(t),dIr=i(ae),BC=n(ae,"LI",{});var aDe=s(BC);HEe=n(aDe,"STRONG",{});var xPt=s(HEe);cIr=r(xPt,"electra"),xPt.forEach(t),fIr=r(aDe," \u2014 "),JK=n(aDe,"A",{href:!0});var $Pt=s(JK);mIr=r($Pt,"FlaxElectraModel"),$Pt.forEach(t),gIr=r(aDe," (ELECTRA model)"),aDe.forEach(t),hIr=i(ae),IC=n(ae,"LI",{});var nDe=s(IC);UEe=n(nDe,"STRONG",{});var kPt=s(UEe);pIr=r(kPt,"gpt2"),kPt.forEach(t),_Ir=r(nDe," \u2014 "),YK=n(nDe,"A",{href:!0});var SPt=s(YK);uIr=r(SPt,"FlaxGPT2Model"),SPt.forEach(t),bIr=r(nDe," (OpenAI GPT-2 model)"),nDe.forEach(t),vIr=i(ae),NC=n(ae,"LI",{});var sDe=s(NC);JEe=n(sDe,"STRONG",{});var RPt=s(JEe);FIr=r(RPt,"gpt_neo"),RPt.forEach(t),TIr=r(sDe," \u2014 "),KK=n(sDe,"A",{href:!0});var PPt=s(KK);MIr=r(PPt,"FlaxGPTNeoModel"),PPt.forEach(t),EIr=r(sDe," (GPT Neo model)"),sDe.forEach(t),CIr=i(ae),qC=n(ae,"LI",{});var lDe=s(qC);YEe=n(lDe,"STRONG",{});var BPt=s(YEe);wIr=r(BPt,"gptj"),BPt.forEach(t),AIr=r(lDe," \u2014 "),ZK=n(lDe,"A",{href:!0});var IPt=s(ZK);LIr=r(IPt,"FlaxGPTJModel"),IPt.forEach(t),yIr=r(lDe," (GPT-J model)"),lDe.forEach(t),xIr=i(ae),jC=n(ae,"LI",{});var iDe=s(jC);KEe=n(iDe,"STRONG",{});var NPt=s(KEe);$Ir=r(NPt,"longt5"),NPt.forEach(t),kIr=r(iDe," \u2014 "),eZ=n(iDe,"A",{href:!0});var qPt=s(eZ);SIr=r(qPt,"FlaxLongT5Model"),qPt.forEach(t),RIr=r(iDe," (LongT5 model)"),iDe.forEach(t),PIr=i(ae),DC=n(ae,"LI",{});var dDe=s(DC);ZEe=n(dDe,"STRONG",{});var jPt=s(ZEe);BIr=r(jPt,"marian"),jPt.forEach(t),IIr=r(dDe," \u2014 "),oZ=n(dDe,"A",{href:!0});var DPt=s(oZ);NIr=r(DPt,"FlaxMarianModel"),DPt.forEach(t),qIr=r(dDe," (Marian model)"),dDe.forEach(t),jIr=i(ae),GC=n(ae,"LI",{});var cDe=s(GC);e4e=n(cDe,"STRONG",{});var GPt=s(e4e);DIr=r(GPt,"mbart"),GPt.forEach(t),GIr=r(cDe," \u2014 "),rZ=n(cDe,"A",{href:!0});var OPt=s(rZ);OIr=r(OPt,"FlaxMBartModel"),OPt.forEach(t),VIr=r(cDe," (mBART model)"),cDe.forEach(t),XIr=i(ae),OC=n(ae,"LI",{});var fDe=s(OC);o4e=n(fDe,"STRONG",{});var VPt=s(o4e);zIr=r(VPt,"mt5"),VPt.forEach(t),QIr=r(fDe," \u2014 "),tZ=n(fDe,"A",{href:!0});var XPt=s(tZ);WIr=r(XPt,"FlaxMT5Model"),XPt.forEach(t),HIr=r(fDe," (MT5 model)"),fDe.forEach(t),UIr=i(ae),VC=n(ae,"LI",{});var mDe=s(VC);r4e=n(mDe,"STRONG",{});var zPt=s(r4e);JIr=r(zPt,"opt"),zPt.forEach(t),YIr=r(mDe," \u2014 "),aZ=n(mDe,"A",{href:!0});var QPt=s(aZ);KIr=r(QPt,"FlaxOPTModel"),QPt.forEach(t),ZIr=r(mDe," (OPT model)"),mDe.forEach(t),eNr=i(ae),XC=n(ae,"LI",{});var gDe=s(XC);t4e=n(gDe,"STRONG",{});var WPt=s(t4e);oNr=r(WPt,"pegasus"),WPt.forEach(t),rNr=r(gDe," \u2014 "),nZ=n(gDe,"A",{href:!0});var HPt=s(nZ);tNr=r(HPt,"FlaxPegasusModel"),HPt.forEach(t),aNr=r(gDe," (Pegasus model)"),gDe.forEach(t),nNr=i(ae),zC=n(ae,"LI",{});var hDe=s(zC);a4e=n(hDe,"STRONG",{});var UPt=s(a4e);sNr=r(UPt,"roberta"),UPt.forEach(t),lNr=r(hDe," \u2014 "),sZ=n(hDe,"A",{href:!0});var JPt=s(sZ);iNr=r(JPt,"FlaxRobertaModel"),JPt.forEach(t),dNr=r(hDe," (RoBERTa model)"),hDe.forEach(t),cNr=i(ae),QC=n(ae,"LI",{});var pDe=s(QC);n4e=n(pDe,"STRONG",{});var YPt=s(n4e);fNr=r(YPt,"roformer"),YPt.forEach(t),mNr=r(pDe," \u2014 "),lZ=n(pDe,"A",{href:!0});var KPt=s(lZ);gNr=r(KPt,"FlaxRoFormerModel"),KPt.forEach(t),hNr=r(pDe," (RoFormer model)"),pDe.forEach(t),pNr=i(ae),WC=n(ae,"LI",{});var _De=s(WC);s4e=n(_De,"STRONG",{});var ZPt=s(s4e);_Nr=r(ZPt,"t5"),ZPt.forEach(t),uNr=r(_De," \u2014 "),iZ=n(_De,"A",{href:!0});var eBt=s(iZ);bNr=r(eBt,"FlaxT5Model"),eBt.forEach(t),vNr=r(_De," (T5 model)"),_De.forEach(t),FNr=i(ae),HC=n(ae,"LI",{});var uDe=s(HC);l4e=n(uDe,"STRONG",{});var oBt=s(l4e);TNr=r(oBt,"vision-text-dual-encoder"),oBt.forEach(t),MNr=r(uDe," \u2014 "),dZ=n(uDe,"A",{href:!0});var rBt=s(dZ);ENr=r(rBt,"FlaxVisionTextDualEncoderModel"),rBt.forEach(t),CNr=r(uDe," (VisionTextDualEncoder model)"),uDe.forEach(t),wNr=i(ae),UC=n(ae,"LI",{});var bDe=s(UC);i4e=n(bDe,"STRONG",{});var tBt=s(i4e);ANr=r(tBt,"vit"),tBt.forEach(t),LNr=r(bDe," \u2014 "),cZ=n(bDe,"A",{href:!0});var aBt=s(cZ);yNr=r(aBt,"FlaxViTModel"),aBt.forEach(t),xNr=r(bDe," (ViT model)"),bDe.forEach(t),$Nr=i(ae),JC=n(ae,"LI",{});var vDe=s(JC);d4e=n(vDe,"STRONG",{});var nBt=s(d4e);kNr=r(nBt,"wav2vec2"),nBt.forEach(t),SNr=r(vDe," \u2014 "),fZ=n(vDe,"A",{href:!0});var sBt=s(fZ);RNr=r(sBt,"FlaxWav2Vec2Model"),sBt.forEach(t),PNr=r(vDe," (Wav2Vec2 model)"),vDe.forEach(t),BNr=i(ae),YC=n(ae,"LI",{});var FDe=s(YC);c4e=n(FDe,"STRONG",{});var lBt=s(c4e);INr=r(lBt,"xglm"),lBt.forEach(t),NNr=r(FDe," \u2014 "),mZ=n(FDe,"A",{href:!0});var iBt=s(mZ);qNr=r(iBt,"FlaxXGLMModel"),iBt.forEach(t),jNr=r(FDe," (XGLM model)"),FDe.forEach(t),DNr=i(ae),KC=n(ae,"LI",{});var TDe=s(KC);f4e=n(TDe,"STRONG",{});var dBt=s(f4e);GNr=r(dBt,"xlm-roberta"),dBt.forEach(t),ONr=r(TDe," \u2014 "),gZ=n(TDe,"A",{href:!0});var cBt=s(gZ);VNr=r(cBt,"FlaxXLMRobertaModel"),cBt.forEach(t),XNr=r(TDe," (XLM-RoBERTa model)"),TDe.forEach(t),ae.forEach(t),zNr=i(Kl),T(ZC.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),PVe=i(f),zc=n(f,"H2",{class:!0});var Vze=s(zc);e5=n(Vze,"A",{id:!0,class:!0,href:!0});var fBt=s(e5);m4e=n(fBt,"SPAN",{});var mBt=s(m4e);T(Dx.$$.fragment,mBt),mBt.forEach(t),fBt.forEach(t),QNr=i(Vze),g4e=n(Vze,"SPAN",{});var gBt=s(g4e);WNr=r(gBt,"FlaxAutoModelForCausalLM"),gBt.forEach(t),Vze.forEach(t),BVe=i(f),pr=n(f,"DIV",{class:!0});var Zl=s(pr);T(Gx.$$.fragment,Zl),HNr=i(Zl),Qc=n(Zl,"P",{});var Hre=s(Qc);UNr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hZ=n(Hre,"A",{href:!0});var hBt=s(hZ);JNr=r(hBt,"from_pretrained()"),hBt.forEach(t),YNr=r(Hre," class method or the "),pZ=n(Hre,"A",{href:!0});var pBt=s(pZ);KNr=r(pBt,"from_config()"),pBt.forEach(t),ZNr=r(Hre,` class
method.`),Hre.forEach(t),eqr=i(Zl),Ox=n(Zl,"P",{});var Xze=s(Ox);oqr=r(Xze,"This class cannot be instantiated directly using "),h4e=n(Xze,"CODE",{});var _Bt=s(h4e);rqr=r(_Bt,"__init__()"),_Bt.forEach(t),tqr=r(Xze," (throws an error)."),Xze.forEach(t),aqr=i(Zl),zt=n(Zl,"DIV",{class:!0});var sA=s(zt);T(Vx.$$.fragment,sA),nqr=i(sA),p4e=n(sA,"P",{});var uBt=s(p4e);sqr=r(uBt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),uBt.forEach(t),lqr=i(sA),Wc=n(sA,"P",{});var Ure=s(Wc);iqr=r(Ure,`Note:
Loading a model from its configuration file does `),_4e=n(Ure,"STRONG",{});var bBt=s(_4e);dqr=r(bBt,"not"),bBt.forEach(t),cqr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=n(Ure,"A",{href:!0});var vBt=s(_Z);fqr=r(vBt,"from_pretrained()"),vBt.forEach(t),mqr=r(Ure," to load the model weights."),Ure.forEach(t),gqr=i(sA),T(o5.$$.fragment,sA),sA.forEach(t),hqr=i(Zl),Vr=n(Zl,"DIV",{class:!0});var ei=s(Vr);T(Xx.$$.fragment,ei),pqr=i(ei),u4e=n(ei,"P",{});var FBt=s(u4e);_qr=r(FBt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),FBt.forEach(t),uqr=i(ei),Tn=n(ei,"P",{});var lA=s(Tn);bqr=r(lA,"The model class to instantiate is selected based on the "),b4e=n(lA,"CODE",{});var TBt=s(b4e);vqr=r(TBt,"model_type"),TBt.forEach(t),Fqr=r(lA,` property of the config object (either
passed as an argument or loaded from `),v4e=n(lA,"CODE",{});var MBt=s(v4e);Tqr=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),Mqr=r(lA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F4e=n(lA,"CODE",{});var EBt=s(F4e);Eqr=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),Cqr=r(lA,":"),lA.forEach(t),wqr=i(ei),xe=n(ei,"UL",{});var Ne=s(xe);r5=n(Ne,"LI",{});var MDe=s(r5);T4e=n(MDe,"STRONG",{});var CBt=s(T4e);Aqr=r(CBt,"bart"),CBt.forEach(t),Lqr=r(MDe," \u2014 "),uZ=n(MDe,"A",{href:!0});var wBt=s(uZ);yqr=r(wBt,"FlaxBartForCausalLM"),wBt.forEach(t),xqr=r(MDe," (BART model)"),MDe.forEach(t),$qr=i(Ne),t5=n(Ne,"LI",{});var EDe=s(t5);M4e=n(EDe,"STRONG",{});var ABt=s(M4e);kqr=r(ABt,"bert"),ABt.forEach(t),Sqr=r(EDe," \u2014 "),bZ=n(EDe,"A",{href:!0});var LBt=s(bZ);Rqr=r(LBt,"FlaxBertForCausalLM"),LBt.forEach(t),Pqr=r(EDe," (BERT model)"),EDe.forEach(t),Bqr=i(Ne),a5=n(Ne,"LI",{});var CDe=s(a5);E4e=n(CDe,"STRONG",{});var yBt=s(E4e);Iqr=r(yBt,"big_bird"),yBt.forEach(t),Nqr=r(CDe," \u2014 "),vZ=n(CDe,"A",{href:!0});var xBt=s(vZ);qqr=r(xBt,"FlaxBigBirdForCausalLM"),xBt.forEach(t),jqr=r(CDe," (BigBird model)"),CDe.forEach(t),Dqr=i(Ne),n5=n(Ne,"LI",{});var wDe=s(n5);C4e=n(wDe,"STRONG",{});var $Bt=s(C4e);Gqr=r($Bt,"electra"),$Bt.forEach(t),Oqr=r(wDe," \u2014 "),FZ=n(wDe,"A",{href:!0});var kBt=s(FZ);Vqr=r(kBt,"FlaxElectraForCausalLM"),kBt.forEach(t),Xqr=r(wDe," (ELECTRA model)"),wDe.forEach(t),zqr=i(Ne),s5=n(Ne,"LI",{});var ADe=s(s5);w4e=n(ADe,"STRONG",{});var SBt=s(w4e);Qqr=r(SBt,"gpt2"),SBt.forEach(t),Wqr=r(ADe," \u2014 "),TZ=n(ADe,"A",{href:!0});var RBt=s(TZ);Hqr=r(RBt,"FlaxGPT2LMHeadModel"),RBt.forEach(t),Uqr=r(ADe," (OpenAI GPT-2 model)"),ADe.forEach(t),Jqr=i(Ne),l5=n(Ne,"LI",{});var LDe=s(l5);A4e=n(LDe,"STRONG",{});var PBt=s(A4e);Yqr=r(PBt,"gpt_neo"),PBt.forEach(t),Kqr=r(LDe," \u2014 "),MZ=n(LDe,"A",{href:!0});var BBt=s(MZ);Zqr=r(BBt,"FlaxGPTNeoForCausalLM"),BBt.forEach(t),ejr=r(LDe," (GPT Neo model)"),LDe.forEach(t),ojr=i(Ne),i5=n(Ne,"LI",{});var yDe=s(i5);L4e=n(yDe,"STRONG",{});var IBt=s(L4e);rjr=r(IBt,"gptj"),IBt.forEach(t),tjr=r(yDe," \u2014 "),EZ=n(yDe,"A",{href:!0});var NBt=s(EZ);ajr=r(NBt,"FlaxGPTJForCausalLM"),NBt.forEach(t),njr=r(yDe," (GPT-J model)"),yDe.forEach(t),sjr=i(Ne),d5=n(Ne,"LI",{});var xDe=s(d5);y4e=n(xDe,"STRONG",{});var qBt=s(y4e);ljr=r(qBt,"opt"),qBt.forEach(t),ijr=r(xDe," \u2014 "),CZ=n(xDe,"A",{href:!0});var jBt=s(CZ);djr=r(jBt,"FlaxOPTForCausalLM"),jBt.forEach(t),cjr=r(xDe," (OPT model)"),xDe.forEach(t),fjr=i(Ne),c5=n(Ne,"LI",{});var $De=s(c5);x4e=n($De,"STRONG",{});var DBt=s(x4e);mjr=r(DBt,"roberta"),DBt.forEach(t),gjr=r($De," \u2014 "),wZ=n($De,"A",{href:!0});var GBt=s(wZ);hjr=r(GBt,"FlaxRobertaForCausalLM"),GBt.forEach(t),pjr=r($De," (RoBERTa model)"),$De.forEach(t),_jr=i(Ne),f5=n(Ne,"LI",{});var kDe=s(f5);$4e=n(kDe,"STRONG",{});var OBt=s($4e);ujr=r(OBt,"xglm"),OBt.forEach(t),bjr=r(kDe," \u2014 "),AZ=n(kDe,"A",{href:!0});var VBt=s(AZ);vjr=r(VBt,"FlaxXGLMForCausalLM"),VBt.forEach(t),Fjr=r(kDe," (XGLM model)"),kDe.forEach(t),Ne.forEach(t),Tjr=i(ei),T(m5.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),IVe=i(f),Hc=n(f,"H2",{class:!0});var zze=s(Hc);g5=n(zze,"A",{id:!0,class:!0,href:!0});var XBt=s(g5);k4e=n(XBt,"SPAN",{});var zBt=s(k4e);T(zx.$$.fragment,zBt),zBt.forEach(t),XBt.forEach(t),Mjr=i(zze),S4e=n(zze,"SPAN",{});var QBt=s(S4e);Ejr=r(QBt,"FlaxAutoModelForPreTraining"),QBt.forEach(t),zze.forEach(t),NVe=i(f),_r=n(f,"DIV",{class:!0});var oi=s(_r);T(Qx.$$.fragment,oi),Cjr=i(oi),Uc=n(oi,"P",{});var Jre=s(Uc);wjr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),LZ=n(Jre,"A",{href:!0});var WBt=s(LZ);Ajr=r(WBt,"from_pretrained()"),WBt.forEach(t),Ljr=r(Jre," class method or the "),yZ=n(Jre,"A",{href:!0});var HBt=s(yZ);yjr=r(HBt,"from_config()"),HBt.forEach(t),xjr=r(Jre,` class
method.`),Jre.forEach(t),$jr=i(oi),Wx=n(oi,"P",{});var Qze=s(Wx);kjr=r(Qze,"This class cannot be instantiated directly using "),R4e=n(Qze,"CODE",{});var UBt=s(R4e);Sjr=r(UBt,"__init__()"),UBt.forEach(t),Rjr=r(Qze," (throws an error)."),Qze.forEach(t),Pjr=i(oi),Qt=n(oi,"DIV",{class:!0});var iA=s(Qt);T(Hx.$$.fragment,iA),Bjr=i(iA),P4e=n(iA,"P",{});var JBt=s(P4e);Ijr=r(JBt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),JBt.forEach(t),Njr=i(iA),Jc=n(iA,"P",{});var Yre=s(Jc);qjr=r(Yre,`Note:
Loading a model from its configuration file does `),B4e=n(Yre,"STRONG",{});var YBt=s(B4e);jjr=r(YBt,"not"),YBt.forEach(t),Djr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),xZ=n(Yre,"A",{href:!0});var KBt=s(xZ);Gjr=r(KBt,"from_pretrained()"),KBt.forEach(t),Ojr=r(Yre," to load the model weights."),Yre.forEach(t),Vjr=i(iA),T(h5.$$.fragment,iA),iA.forEach(t),Xjr=i(oi),Xr=n(oi,"DIV",{class:!0});var ri=s(Xr);T(Ux.$$.fragment,ri),zjr=i(ri),I4e=n(ri,"P",{});var ZBt=s(I4e);Qjr=r(ZBt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ZBt.forEach(t),Wjr=i(ri),Mn=n(ri,"P",{});var dA=s(Mn);Hjr=r(dA,"The model class to instantiate is selected based on the "),N4e=n(dA,"CODE",{});var eIt=s(N4e);Ujr=r(eIt,"model_type"),eIt.forEach(t),Jjr=r(dA,` property of the config object (either
passed as an argument or loaded from `),q4e=n(dA,"CODE",{});var oIt=s(q4e);Yjr=r(oIt,"pretrained_model_name_or_path"),oIt.forEach(t),Kjr=r(dA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j4e=n(dA,"CODE",{});var rIt=s(j4e);Zjr=r(rIt,"pretrained_model_name_or_path"),rIt.forEach(t),eDr=r(dA,":"),dA.forEach(t),oDr=i(ri),Ee=n(ri,"UL",{});var we=s(Ee);p5=n(we,"LI",{});var SDe=s(p5);D4e=n(SDe,"STRONG",{});var tIt=s(D4e);rDr=r(tIt,"albert"),tIt.forEach(t),tDr=r(SDe," \u2014 "),$Z=n(SDe,"A",{href:!0});var aIt=s($Z);aDr=r(aIt,"FlaxAlbertForPreTraining"),aIt.forEach(t),nDr=r(SDe," (ALBERT model)"),SDe.forEach(t),sDr=i(we),_5=n(we,"LI",{});var RDe=s(_5);G4e=n(RDe,"STRONG",{});var nIt=s(G4e);lDr=r(nIt,"bart"),nIt.forEach(t),iDr=r(RDe," \u2014 "),kZ=n(RDe,"A",{href:!0});var sIt=s(kZ);dDr=r(sIt,"FlaxBartForConditionalGeneration"),sIt.forEach(t),cDr=r(RDe," (BART model)"),RDe.forEach(t),fDr=i(we),u5=n(we,"LI",{});var PDe=s(u5);O4e=n(PDe,"STRONG",{});var lIt=s(O4e);mDr=r(lIt,"bert"),lIt.forEach(t),gDr=r(PDe," \u2014 "),SZ=n(PDe,"A",{href:!0});var iIt=s(SZ);hDr=r(iIt,"FlaxBertForPreTraining"),iIt.forEach(t),pDr=r(PDe," (BERT model)"),PDe.forEach(t),_Dr=i(we),b5=n(we,"LI",{});var BDe=s(b5);V4e=n(BDe,"STRONG",{});var dIt=s(V4e);uDr=r(dIt,"big_bird"),dIt.forEach(t),bDr=r(BDe," \u2014 "),RZ=n(BDe,"A",{href:!0});var cIt=s(RZ);vDr=r(cIt,"FlaxBigBirdForPreTraining"),cIt.forEach(t),FDr=r(BDe," (BigBird model)"),BDe.forEach(t),TDr=i(we),v5=n(we,"LI",{});var IDe=s(v5);X4e=n(IDe,"STRONG",{});var fIt=s(X4e);MDr=r(fIt,"electra"),fIt.forEach(t),EDr=r(IDe," \u2014 "),PZ=n(IDe,"A",{href:!0});var mIt=s(PZ);CDr=r(mIt,"FlaxElectraForPreTraining"),mIt.forEach(t),wDr=r(IDe," (ELECTRA model)"),IDe.forEach(t),ADr=i(we),F5=n(we,"LI",{});var NDe=s(F5);z4e=n(NDe,"STRONG",{});var gIt=s(z4e);LDr=r(gIt,"longt5"),gIt.forEach(t),yDr=r(NDe," \u2014 "),BZ=n(NDe,"A",{href:!0});var hIt=s(BZ);xDr=r(hIt,"FlaxLongT5ForConditionalGeneration"),hIt.forEach(t),$Dr=r(NDe," (LongT5 model)"),NDe.forEach(t),kDr=i(we),T5=n(we,"LI",{});var qDe=s(T5);Q4e=n(qDe,"STRONG",{});var pIt=s(Q4e);SDr=r(pIt,"mbart"),pIt.forEach(t),RDr=r(qDe," \u2014 "),IZ=n(qDe,"A",{href:!0});var _It=s(IZ);PDr=r(_It,"FlaxMBartForConditionalGeneration"),_It.forEach(t),BDr=r(qDe," (mBART model)"),qDe.forEach(t),IDr=i(we),M5=n(we,"LI",{});var jDe=s(M5);W4e=n(jDe,"STRONG",{});var uIt=s(W4e);NDr=r(uIt,"mt5"),uIt.forEach(t),qDr=r(jDe," \u2014 "),NZ=n(jDe,"A",{href:!0});var bIt=s(NZ);jDr=r(bIt,"FlaxMT5ForConditionalGeneration"),bIt.forEach(t),DDr=r(jDe," (MT5 model)"),jDe.forEach(t),GDr=i(we),E5=n(we,"LI",{});var DDe=s(E5);H4e=n(DDe,"STRONG",{});var vIt=s(H4e);ODr=r(vIt,"roberta"),vIt.forEach(t),VDr=r(DDe," \u2014 "),qZ=n(DDe,"A",{href:!0});var FIt=s(qZ);XDr=r(FIt,"FlaxRobertaForMaskedLM"),FIt.forEach(t),zDr=r(DDe," (RoBERTa model)"),DDe.forEach(t),QDr=i(we),C5=n(we,"LI",{});var GDe=s(C5);U4e=n(GDe,"STRONG",{});var TIt=s(U4e);WDr=r(TIt,"roformer"),TIt.forEach(t),HDr=r(GDe," \u2014 "),jZ=n(GDe,"A",{href:!0});var MIt=s(jZ);UDr=r(MIt,"FlaxRoFormerForMaskedLM"),MIt.forEach(t),JDr=r(GDe," (RoFormer model)"),GDe.forEach(t),YDr=i(we),w5=n(we,"LI",{});var ODe=s(w5);J4e=n(ODe,"STRONG",{});var EIt=s(J4e);KDr=r(EIt,"t5"),EIt.forEach(t),ZDr=r(ODe," \u2014 "),DZ=n(ODe,"A",{href:!0});var CIt=s(DZ);eGr=r(CIt,"FlaxT5ForConditionalGeneration"),CIt.forEach(t),oGr=r(ODe," (T5 model)"),ODe.forEach(t),rGr=i(we),A5=n(we,"LI",{});var VDe=s(A5);Y4e=n(VDe,"STRONG",{});var wIt=s(Y4e);tGr=r(wIt,"wav2vec2"),wIt.forEach(t),aGr=r(VDe," \u2014 "),GZ=n(VDe,"A",{href:!0});var AIt=s(GZ);nGr=r(AIt,"FlaxWav2Vec2ForPreTraining"),AIt.forEach(t),sGr=r(VDe," (Wav2Vec2 model)"),VDe.forEach(t),lGr=i(we),L5=n(we,"LI",{});var XDe=s(L5);K4e=n(XDe,"STRONG",{});var LIt=s(K4e);iGr=r(LIt,"xlm-roberta"),LIt.forEach(t),dGr=r(XDe," \u2014 "),OZ=n(XDe,"A",{href:!0});var yIt=s(OZ);cGr=r(yIt,"FlaxXLMRobertaForMaskedLM"),yIt.forEach(t),fGr=r(XDe," (XLM-RoBERTa model)"),XDe.forEach(t),we.forEach(t),mGr=i(ri),T(y5.$$.fragment,ri),ri.forEach(t),oi.forEach(t),qVe=i(f),Yc=n(f,"H2",{class:!0});var Wze=s(Yc);x5=n(Wze,"A",{id:!0,class:!0,href:!0});var xIt=s(x5);Z4e=n(xIt,"SPAN",{});var $It=s(Z4e);T(Jx.$$.fragment,$It),$It.forEach(t),xIt.forEach(t),gGr=i(Wze),eCe=n(Wze,"SPAN",{});var kIt=s(eCe);hGr=r(kIt,"FlaxAutoModelForMaskedLM"),kIt.forEach(t),Wze.forEach(t),jVe=i(f),ur=n(f,"DIV",{class:!0});var ti=s(ur);T(Yx.$$.fragment,ti),pGr=i(ti),Kc=n(ti,"P",{});var Kre=s(Kc);_Gr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),VZ=n(Kre,"A",{href:!0});var SIt=s(VZ);uGr=r(SIt,"from_pretrained()"),SIt.forEach(t),bGr=r(Kre," class method or the "),XZ=n(Kre,"A",{href:!0});var RIt=s(XZ);vGr=r(RIt,"from_config()"),RIt.forEach(t),FGr=r(Kre,` class
method.`),Kre.forEach(t),TGr=i(ti),Kx=n(ti,"P",{});var Hze=s(Kx);MGr=r(Hze,"This class cannot be instantiated directly using "),oCe=n(Hze,"CODE",{});var PIt=s(oCe);EGr=r(PIt,"__init__()"),PIt.forEach(t),CGr=r(Hze," (throws an error)."),Hze.forEach(t),wGr=i(ti),Wt=n(ti,"DIV",{class:!0});var cA=s(Wt);T(Zx.$$.fragment,cA),AGr=i(cA),rCe=n(cA,"P",{});var BIt=s(rCe);LGr=r(BIt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),BIt.forEach(t),yGr=i(cA),Zc=n(cA,"P",{});var Zre=s(Zc);xGr=r(Zre,`Note:
Loading a model from its configuration file does `),tCe=n(Zre,"STRONG",{});var IIt=s(tCe);$Gr=r(IIt,"not"),IIt.forEach(t),kGr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),zZ=n(Zre,"A",{href:!0});var NIt=s(zZ);SGr=r(NIt,"from_pretrained()"),NIt.forEach(t),RGr=r(Zre," to load the model weights."),Zre.forEach(t),PGr=i(cA),T($5.$$.fragment,cA),cA.forEach(t),BGr=i(ti),zr=n(ti,"DIV",{class:!0});var ai=s(zr);T(e$.$$.fragment,ai),IGr=i(ai),aCe=n(ai,"P",{});var qIt=s(aCe);NGr=r(qIt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),qIt.forEach(t),qGr=i(ai),En=n(ai,"P",{});var fA=s(En);jGr=r(fA,"The model class to instantiate is selected based on the "),nCe=n(fA,"CODE",{});var jIt=s(nCe);DGr=r(jIt,"model_type"),jIt.forEach(t),GGr=r(fA,` property of the config object (either
passed as an argument or loaded from `),sCe=n(fA,"CODE",{});var DIt=s(sCe);OGr=r(DIt,"pretrained_model_name_or_path"),DIt.forEach(t),VGr=r(fA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lCe=n(fA,"CODE",{});var GIt=s(lCe);XGr=r(GIt,"pretrained_model_name_or_path"),GIt.forEach(t),zGr=r(fA,":"),fA.forEach(t),QGr=i(ai),$e=n(ai,"UL",{});var qe=s($e);k5=n(qe,"LI",{});var zDe=s(k5);iCe=n(zDe,"STRONG",{});var OIt=s(iCe);WGr=r(OIt,"albert"),OIt.forEach(t),HGr=r(zDe," \u2014 "),QZ=n(zDe,"A",{href:!0});var VIt=s(QZ);UGr=r(VIt,"FlaxAlbertForMaskedLM"),VIt.forEach(t),JGr=r(zDe," (ALBERT model)"),zDe.forEach(t),YGr=i(qe),S5=n(qe,"LI",{});var QDe=s(S5);dCe=n(QDe,"STRONG",{});var XIt=s(dCe);KGr=r(XIt,"bart"),XIt.forEach(t),ZGr=r(QDe," \u2014 "),WZ=n(QDe,"A",{href:!0});var zIt=s(WZ);eOr=r(zIt,"FlaxBartForConditionalGeneration"),zIt.forEach(t),oOr=r(QDe," (BART model)"),QDe.forEach(t),rOr=i(qe),R5=n(qe,"LI",{});var WDe=s(R5);cCe=n(WDe,"STRONG",{});var QIt=s(cCe);tOr=r(QIt,"bert"),QIt.forEach(t),aOr=r(WDe," \u2014 "),HZ=n(WDe,"A",{href:!0});var WIt=s(HZ);nOr=r(WIt,"FlaxBertForMaskedLM"),WIt.forEach(t),sOr=r(WDe," (BERT model)"),WDe.forEach(t),lOr=i(qe),P5=n(qe,"LI",{});var HDe=s(P5);fCe=n(HDe,"STRONG",{});var HIt=s(fCe);iOr=r(HIt,"big_bird"),HIt.forEach(t),dOr=r(HDe," \u2014 "),UZ=n(HDe,"A",{href:!0});var UIt=s(UZ);cOr=r(UIt,"FlaxBigBirdForMaskedLM"),UIt.forEach(t),fOr=r(HDe," (BigBird model)"),HDe.forEach(t),mOr=i(qe),B5=n(qe,"LI",{});var UDe=s(B5);mCe=n(UDe,"STRONG",{});var JIt=s(mCe);gOr=r(JIt,"distilbert"),JIt.forEach(t),hOr=r(UDe," \u2014 "),JZ=n(UDe,"A",{href:!0});var YIt=s(JZ);pOr=r(YIt,"FlaxDistilBertForMaskedLM"),YIt.forEach(t),_Or=r(UDe," (DistilBERT model)"),UDe.forEach(t),uOr=i(qe),I5=n(qe,"LI",{});var JDe=s(I5);gCe=n(JDe,"STRONG",{});var KIt=s(gCe);bOr=r(KIt,"electra"),KIt.forEach(t),vOr=r(JDe," \u2014 "),YZ=n(JDe,"A",{href:!0});var ZIt=s(YZ);FOr=r(ZIt,"FlaxElectraForMaskedLM"),ZIt.forEach(t),TOr=r(JDe," (ELECTRA model)"),JDe.forEach(t),MOr=i(qe),N5=n(qe,"LI",{});var YDe=s(N5);hCe=n(YDe,"STRONG",{});var eNt=s(hCe);EOr=r(eNt,"mbart"),eNt.forEach(t),COr=r(YDe," \u2014 "),KZ=n(YDe,"A",{href:!0});var oNt=s(KZ);wOr=r(oNt,"FlaxMBartForConditionalGeneration"),oNt.forEach(t),AOr=r(YDe," (mBART model)"),YDe.forEach(t),LOr=i(qe),q5=n(qe,"LI",{});var KDe=s(q5);pCe=n(KDe,"STRONG",{});var rNt=s(pCe);yOr=r(rNt,"roberta"),rNt.forEach(t),xOr=r(KDe," \u2014 "),ZZ=n(KDe,"A",{href:!0});var tNt=s(ZZ);$Or=r(tNt,"FlaxRobertaForMaskedLM"),tNt.forEach(t),kOr=r(KDe," (RoBERTa model)"),KDe.forEach(t),SOr=i(qe),j5=n(qe,"LI",{});var ZDe=s(j5);_Ce=n(ZDe,"STRONG",{});var aNt=s(_Ce);ROr=r(aNt,"roformer"),aNt.forEach(t),POr=r(ZDe," \u2014 "),eee=n(ZDe,"A",{href:!0});var nNt=s(eee);BOr=r(nNt,"FlaxRoFormerForMaskedLM"),nNt.forEach(t),IOr=r(ZDe," (RoFormer model)"),ZDe.forEach(t),NOr=i(qe),D5=n(qe,"LI",{});var eGe=s(D5);uCe=n(eGe,"STRONG",{});var sNt=s(uCe);qOr=r(sNt,"xlm-roberta"),sNt.forEach(t),jOr=r(eGe," \u2014 "),oee=n(eGe,"A",{href:!0});var lNt=s(oee);DOr=r(lNt,"FlaxXLMRobertaForMaskedLM"),lNt.forEach(t),GOr=r(eGe," (XLM-RoBERTa model)"),eGe.forEach(t),qe.forEach(t),OOr=i(ai),T(G5.$$.fragment,ai),ai.forEach(t),ti.forEach(t),DVe=i(f),ef=n(f,"H2",{class:!0});var Uze=s(ef);O5=n(Uze,"A",{id:!0,class:!0,href:!0});var iNt=s(O5);bCe=n(iNt,"SPAN",{});var dNt=s(bCe);T(o$.$$.fragment,dNt),dNt.forEach(t),iNt.forEach(t),VOr=i(Uze),vCe=n(Uze,"SPAN",{});var cNt=s(vCe);XOr=r(cNt,"FlaxAutoModelForSeq2SeqLM"),cNt.forEach(t),Uze.forEach(t),GVe=i(f),br=n(f,"DIV",{class:!0});var ni=s(br);T(r$.$$.fragment,ni),zOr=i(ni),of=n(ni,"P",{});var ete=s(of);QOr=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ree=n(ete,"A",{href:!0});var fNt=s(ree);WOr=r(fNt,"from_pretrained()"),fNt.forEach(t),HOr=r(ete," class method or the "),tee=n(ete,"A",{href:!0});var mNt=s(tee);UOr=r(mNt,"from_config()"),mNt.forEach(t),JOr=r(ete,` class
method.`),ete.forEach(t),YOr=i(ni),t$=n(ni,"P",{});var Jze=s(t$);KOr=r(Jze,"This class cannot be instantiated directly using "),FCe=n(Jze,"CODE",{});var gNt=s(FCe);ZOr=r(gNt,"__init__()"),gNt.forEach(t),eVr=r(Jze," (throws an error)."),Jze.forEach(t),oVr=i(ni),Ht=n(ni,"DIV",{class:!0});var mA=s(Ht);T(a$.$$.fragment,mA),rVr=i(mA),TCe=n(mA,"P",{});var hNt=s(TCe);tVr=r(hNt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hNt.forEach(t),aVr=i(mA),rf=n(mA,"P",{});var ote=s(rf);nVr=r(ote,`Note:
Loading a model from its configuration file does `),MCe=n(ote,"STRONG",{});var pNt=s(MCe);sVr=r(pNt,"not"),pNt.forEach(t),lVr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),aee=n(ote,"A",{href:!0});var _Nt=s(aee);iVr=r(_Nt,"from_pretrained()"),_Nt.forEach(t),dVr=r(ote," to load the model weights."),ote.forEach(t),cVr=i(mA),T(V5.$$.fragment,mA),mA.forEach(t),fVr=i(ni),Qr=n(ni,"DIV",{class:!0});var si=s(Qr);T(n$.$$.fragment,si),mVr=i(si),ECe=n(si,"P",{});var uNt=s(ECe);gVr=r(uNt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),uNt.forEach(t),hVr=i(si),Cn=n(si,"P",{});var gA=s(Cn);pVr=r(gA,"The model class to instantiate is selected based on the "),CCe=n(gA,"CODE",{});var bNt=s(CCe);_Vr=r(bNt,"model_type"),bNt.forEach(t),uVr=r(gA,` property of the config object (either
passed as an argument or loaded from `),wCe=n(gA,"CODE",{});var vNt=s(wCe);bVr=r(vNt,"pretrained_model_name_or_path"),vNt.forEach(t),vVr=r(gA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ACe=n(gA,"CODE",{});var FNt=s(ACe);FVr=r(FNt,"pretrained_model_name_or_path"),FNt.forEach(t),TVr=r(gA,":"),gA.forEach(t),MVr=i(si),ke=n(si,"UL",{});var je=s(ke);X5=n(je,"LI",{});var oGe=s(X5);LCe=n(oGe,"STRONG",{});var TNt=s(LCe);EVr=r(TNt,"bart"),TNt.forEach(t),CVr=r(oGe," \u2014 "),nee=n(oGe,"A",{href:!0});var MNt=s(nee);wVr=r(MNt,"FlaxBartForConditionalGeneration"),MNt.forEach(t),AVr=r(oGe," (BART model)"),oGe.forEach(t),LVr=i(je),z5=n(je,"LI",{});var rGe=s(z5);yCe=n(rGe,"STRONG",{});var ENt=s(yCe);yVr=r(ENt,"blenderbot"),ENt.forEach(t),xVr=r(rGe," \u2014 "),see=n(rGe,"A",{href:!0});var CNt=s(see);$Vr=r(CNt,"FlaxBlenderbotForConditionalGeneration"),CNt.forEach(t),kVr=r(rGe," (Blenderbot model)"),rGe.forEach(t),SVr=i(je),Q5=n(je,"LI",{});var tGe=s(Q5);xCe=n(tGe,"STRONG",{});var wNt=s(xCe);RVr=r(wNt,"blenderbot-small"),wNt.forEach(t),PVr=r(tGe," \u2014 "),lee=n(tGe,"A",{href:!0});var ANt=s(lee);BVr=r(ANt,"FlaxBlenderbotSmallForConditionalGeneration"),ANt.forEach(t),IVr=r(tGe," (BlenderbotSmall model)"),tGe.forEach(t),NVr=i(je),W5=n(je,"LI",{});var aGe=s(W5);$Ce=n(aGe,"STRONG",{});var LNt=s($Ce);qVr=r(LNt,"encoder-decoder"),LNt.forEach(t),jVr=r(aGe," \u2014 "),iee=n(aGe,"A",{href:!0});var yNt=s(iee);DVr=r(yNt,"FlaxEncoderDecoderModel"),yNt.forEach(t),GVr=r(aGe," (Encoder decoder model)"),aGe.forEach(t),OVr=i(je),H5=n(je,"LI",{});var nGe=s(H5);kCe=n(nGe,"STRONG",{});var xNt=s(kCe);VVr=r(xNt,"longt5"),xNt.forEach(t),XVr=r(nGe," \u2014 "),dee=n(nGe,"A",{href:!0});var $Nt=s(dee);zVr=r($Nt,"FlaxLongT5ForConditionalGeneration"),$Nt.forEach(t),QVr=r(nGe," (LongT5 model)"),nGe.forEach(t),WVr=i(je),U5=n(je,"LI",{});var sGe=s(U5);SCe=n(sGe,"STRONG",{});var kNt=s(SCe);HVr=r(kNt,"marian"),kNt.forEach(t),UVr=r(sGe," \u2014 "),cee=n(sGe,"A",{href:!0});var SNt=s(cee);JVr=r(SNt,"FlaxMarianMTModel"),SNt.forEach(t),YVr=r(sGe," (Marian model)"),sGe.forEach(t),KVr=i(je),J5=n(je,"LI",{});var lGe=s(J5);RCe=n(lGe,"STRONG",{});var RNt=s(RCe);ZVr=r(RNt,"mbart"),RNt.forEach(t),eXr=r(lGe," \u2014 "),fee=n(lGe,"A",{href:!0});var PNt=s(fee);oXr=r(PNt,"FlaxMBartForConditionalGeneration"),PNt.forEach(t),rXr=r(lGe," (mBART model)"),lGe.forEach(t),tXr=i(je),Y5=n(je,"LI",{});var iGe=s(Y5);PCe=n(iGe,"STRONG",{});var BNt=s(PCe);aXr=r(BNt,"mt5"),BNt.forEach(t),nXr=r(iGe," \u2014 "),mee=n(iGe,"A",{href:!0});var INt=s(mee);sXr=r(INt,"FlaxMT5ForConditionalGeneration"),INt.forEach(t),lXr=r(iGe," (MT5 model)"),iGe.forEach(t),iXr=i(je),K5=n(je,"LI",{});var dGe=s(K5);BCe=n(dGe,"STRONG",{});var NNt=s(BCe);dXr=r(NNt,"pegasus"),NNt.forEach(t),cXr=r(dGe," \u2014 "),gee=n(dGe,"A",{href:!0});var qNt=s(gee);fXr=r(qNt,"FlaxPegasusForConditionalGeneration"),qNt.forEach(t),mXr=r(dGe," (Pegasus model)"),dGe.forEach(t),gXr=i(je),Z5=n(je,"LI",{});var cGe=s(Z5);ICe=n(cGe,"STRONG",{});var jNt=s(ICe);hXr=r(jNt,"t5"),jNt.forEach(t),pXr=r(cGe," \u2014 "),hee=n(cGe,"A",{href:!0});var DNt=s(hee);_Xr=r(DNt,"FlaxT5ForConditionalGeneration"),DNt.forEach(t),uXr=r(cGe," (T5 model)"),cGe.forEach(t),je.forEach(t),bXr=i(si),T(e3.$$.fragment,si),si.forEach(t),ni.forEach(t),OVe=i(f),tf=n(f,"H2",{class:!0});var Yze=s(tf);o3=n(Yze,"A",{id:!0,class:!0,href:!0});var GNt=s(o3);NCe=n(GNt,"SPAN",{});var ONt=s(NCe);T(s$.$$.fragment,ONt),ONt.forEach(t),GNt.forEach(t),vXr=i(Yze),qCe=n(Yze,"SPAN",{});var VNt=s(qCe);FXr=r(VNt,"FlaxAutoModelForSequenceClassification"),VNt.forEach(t),Yze.forEach(t),VVe=i(f),vr=n(f,"DIV",{class:!0});var li=s(vr);T(l$.$$.fragment,li),TXr=i(li),af=n(li,"P",{});var rte=s(af);MXr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pee=n(rte,"A",{href:!0});var XNt=s(pee);EXr=r(XNt,"from_pretrained()"),XNt.forEach(t),CXr=r(rte," class method or the "),_ee=n(rte,"A",{href:!0});var zNt=s(_ee);wXr=r(zNt,"from_config()"),zNt.forEach(t),AXr=r(rte,` class
method.`),rte.forEach(t),LXr=i(li),i$=n(li,"P",{});var Kze=s(i$);yXr=r(Kze,"This class cannot be instantiated directly using "),jCe=n(Kze,"CODE",{});var QNt=s(jCe);xXr=r(QNt,"__init__()"),QNt.forEach(t),$Xr=r(Kze," (throws an error)."),Kze.forEach(t),kXr=i(li),Ut=n(li,"DIV",{class:!0});var hA=s(Ut);T(d$.$$.fragment,hA),SXr=i(hA),DCe=n(hA,"P",{});var WNt=s(DCe);RXr=r(WNt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),WNt.forEach(t),PXr=i(hA),nf=n(hA,"P",{});var tte=s(nf);BXr=r(tte,`Note:
Loading a model from its configuration file does `),GCe=n(tte,"STRONG",{});var HNt=s(GCe);IXr=r(HNt,"not"),HNt.forEach(t),NXr=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=n(tte,"A",{href:!0});var UNt=s(uee);qXr=r(UNt,"from_pretrained()"),UNt.forEach(t),jXr=r(tte," to load the model weights."),tte.forEach(t),DXr=i(hA),T(r3.$$.fragment,hA),hA.forEach(t),GXr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(c$.$$.fragment,ii),OXr=i(ii),OCe=n(ii,"P",{});var JNt=s(OCe);VXr=r(JNt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),JNt.forEach(t),XXr=i(ii),wn=n(ii,"P",{});var pA=s(wn);zXr=r(pA,"The model class to instantiate is selected based on the "),VCe=n(pA,"CODE",{});var YNt=s(VCe);QXr=r(YNt,"model_type"),YNt.forEach(t),WXr=r(pA,` property of the config object (either
passed as an argument or loaded from `),XCe=n(pA,"CODE",{});var KNt=s(XCe);HXr=r(KNt,"pretrained_model_name_or_path"),KNt.forEach(t),UXr=r(pA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zCe=n(pA,"CODE",{});var ZNt=s(zCe);JXr=r(ZNt,"pretrained_model_name_or_path"),ZNt.forEach(t),YXr=r(pA,":"),pA.forEach(t),KXr=i(ii),Se=n(ii,"UL",{});var De=s(Se);t3=n(De,"LI",{});var fGe=s(t3);QCe=n(fGe,"STRONG",{});var eqt=s(QCe);ZXr=r(eqt,"albert"),eqt.forEach(t),ezr=r(fGe," \u2014 "),bee=n(fGe,"A",{href:!0});var oqt=s(bee);ozr=r(oqt,"FlaxAlbertForSequenceClassification"),oqt.forEach(t),rzr=r(fGe," (ALBERT model)"),fGe.forEach(t),tzr=i(De),a3=n(De,"LI",{});var mGe=s(a3);WCe=n(mGe,"STRONG",{});var rqt=s(WCe);azr=r(rqt,"bart"),rqt.forEach(t),nzr=r(mGe," \u2014 "),vee=n(mGe,"A",{href:!0});var tqt=s(vee);szr=r(tqt,"FlaxBartForSequenceClassification"),tqt.forEach(t),lzr=r(mGe," (BART model)"),mGe.forEach(t),izr=i(De),n3=n(De,"LI",{});var gGe=s(n3);HCe=n(gGe,"STRONG",{});var aqt=s(HCe);dzr=r(aqt,"bert"),aqt.forEach(t),czr=r(gGe," \u2014 "),Fee=n(gGe,"A",{href:!0});var nqt=s(Fee);fzr=r(nqt,"FlaxBertForSequenceClassification"),nqt.forEach(t),mzr=r(gGe," (BERT model)"),gGe.forEach(t),gzr=i(De),s3=n(De,"LI",{});var hGe=s(s3);UCe=n(hGe,"STRONG",{});var sqt=s(UCe);hzr=r(sqt,"big_bird"),sqt.forEach(t),pzr=r(hGe," \u2014 "),Tee=n(hGe,"A",{href:!0});var lqt=s(Tee);_zr=r(lqt,"FlaxBigBirdForSequenceClassification"),lqt.forEach(t),uzr=r(hGe," (BigBird model)"),hGe.forEach(t),bzr=i(De),l3=n(De,"LI",{});var pGe=s(l3);JCe=n(pGe,"STRONG",{});var iqt=s(JCe);vzr=r(iqt,"distilbert"),iqt.forEach(t),Fzr=r(pGe," \u2014 "),Mee=n(pGe,"A",{href:!0});var dqt=s(Mee);Tzr=r(dqt,"FlaxDistilBertForSequenceClassification"),dqt.forEach(t),Mzr=r(pGe," (DistilBERT model)"),pGe.forEach(t),Ezr=i(De),i3=n(De,"LI",{});var _Ge=s(i3);YCe=n(_Ge,"STRONG",{});var cqt=s(YCe);Czr=r(cqt,"electra"),cqt.forEach(t),wzr=r(_Ge," \u2014 "),Eee=n(_Ge,"A",{href:!0});var fqt=s(Eee);Azr=r(fqt,"FlaxElectraForSequenceClassification"),fqt.forEach(t),Lzr=r(_Ge," (ELECTRA model)"),_Ge.forEach(t),yzr=i(De),d3=n(De,"LI",{});var uGe=s(d3);KCe=n(uGe,"STRONG",{});var mqt=s(KCe);xzr=r(mqt,"mbart"),mqt.forEach(t),$zr=r(uGe," \u2014 "),Cee=n(uGe,"A",{href:!0});var gqt=s(Cee);kzr=r(gqt,"FlaxMBartForSequenceClassification"),gqt.forEach(t),Szr=r(uGe," (mBART model)"),uGe.forEach(t),Rzr=i(De),c3=n(De,"LI",{});var bGe=s(c3);ZCe=n(bGe,"STRONG",{});var hqt=s(ZCe);Pzr=r(hqt,"roberta"),hqt.forEach(t),Bzr=r(bGe," \u2014 "),wee=n(bGe,"A",{href:!0});var pqt=s(wee);Izr=r(pqt,"FlaxRobertaForSequenceClassification"),pqt.forEach(t),Nzr=r(bGe," (RoBERTa model)"),bGe.forEach(t),qzr=i(De),f3=n(De,"LI",{});var vGe=s(f3);e5e=n(vGe,"STRONG",{});var _qt=s(e5e);jzr=r(_qt,"roformer"),_qt.forEach(t),Dzr=r(vGe," \u2014 "),Aee=n(vGe,"A",{href:!0});var uqt=s(Aee);Gzr=r(uqt,"FlaxRoFormerForSequenceClassification"),uqt.forEach(t),Ozr=r(vGe," (RoFormer model)"),vGe.forEach(t),Vzr=i(De),m3=n(De,"LI",{});var FGe=s(m3);o5e=n(FGe,"STRONG",{});var bqt=s(o5e);Xzr=r(bqt,"xlm-roberta"),bqt.forEach(t),zzr=r(FGe," \u2014 "),Lee=n(FGe,"A",{href:!0});var vqt=s(Lee);Qzr=r(vqt,"FlaxXLMRobertaForSequenceClassification"),vqt.forEach(t),Wzr=r(FGe," (XLM-RoBERTa model)"),FGe.forEach(t),De.forEach(t),Hzr=i(ii),T(g3.$$.fragment,ii),ii.forEach(t),li.forEach(t),XVe=i(f),sf=n(f,"H2",{class:!0});var Zze=s(sf);h3=n(Zze,"A",{id:!0,class:!0,href:!0});var Fqt=s(h3);r5e=n(Fqt,"SPAN",{});var Tqt=s(r5e);T(f$.$$.fragment,Tqt),Tqt.forEach(t),Fqt.forEach(t),Uzr=i(Zze),t5e=n(Zze,"SPAN",{});var Mqt=s(t5e);Jzr=r(Mqt,"FlaxAutoModelForQuestionAnswering"),Mqt.forEach(t),Zze.forEach(t),zVe=i(f),Fr=n(f,"DIV",{class:!0});var di=s(Fr);T(m$.$$.fragment,di),Yzr=i(di),lf=n(di,"P",{});var ate=s(lf);Kzr=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),yee=n(ate,"A",{href:!0});var Eqt=s(yee);Zzr=r(Eqt,"from_pretrained()"),Eqt.forEach(t),eQr=r(ate," class method or the "),xee=n(ate,"A",{href:!0});var Cqt=s(xee);oQr=r(Cqt,"from_config()"),Cqt.forEach(t),rQr=r(ate,` class
method.`),ate.forEach(t),tQr=i(di),g$=n(di,"P",{});var eQe=s(g$);aQr=r(eQe,"This class cannot be instantiated directly using "),a5e=n(eQe,"CODE",{});var wqt=s(a5e);nQr=r(wqt,"__init__()"),wqt.forEach(t),sQr=r(eQe," (throws an error)."),eQe.forEach(t),lQr=i(di),Jt=n(di,"DIV",{class:!0});var _A=s(Jt);T(h$.$$.fragment,_A),iQr=i(_A),n5e=n(_A,"P",{});var Aqt=s(n5e);dQr=r(Aqt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Aqt.forEach(t),cQr=i(_A),df=n(_A,"P",{});var nte=s(df);fQr=r(nte,`Note:
Loading a model from its configuration file does `),s5e=n(nte,"STRONG",{});var Lqt=s(s5e);mQr=r(Lqt,"not"),Lqt.forEach(t),gQr=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ee=n(nte,"A",{href:!0});var yqt=s($ee);hQr=r(yqt,"from_pretrained()"),yqt.forEach(t),pQr=r(nte," to load the model weights."),nte.forEach(t),_Qr=i(_A),T(p3.$$.fragment,_A),_A.forEach(t),uQr=i(di),Hr=n(di,"DIV",{class:!0});var ci=s(Hr);T(p$.$$.fragment,ci),bQr=i(ci),l5e=n(ci,"P",{});var xqt=s(l5e);vQr=r(xqt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),xqt.forEach(t),FQr=i(ci),An=n(ci,"P",{});var uA=s(An);TQr=r(uA,"The model class to instantiate is selected based on the "),i5e=n(uA,"CODE",{});var $qt=s(i5e);MQr=r($qt,"model_type"),$qt.forEach(t),EQr=r(uA,` property of the config object (either
passed as an argument or loaded from `),d5e=n(uA,"CODE",{});var kqt=s(d5e);CQr=r(kqt,"pretrained_model_name_or_path"),kqt.forEach(t),wQr=r(uA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c5e=n(uA,"CODE",{});var Sqt=s(c5e);AQr=r(Sqt,"pretrained_model_name_or_path"),Sqt.forEach(t),LQr=r(uA,":"),uA.forEach(t),yQr=i(ci),Re=n(ci,"UL",{});var Ge=s(Re);_3=n(Ge,"LI",{});var TGe=s(_3);f5e=n(TGe,"STRONG",{});var Rqt=s(f5e);xQr=r(Rqt,"albert"),Rqt.forEach(t),$Qr=r(TGe," \u2014 "),kee=n(TGe,"A",{href:!0});var Pqt=s(kee);kQr=r(Pqt,"FlaxAlbertForQuestionAnswering"),Pqt.forEach(t),SQr=r(TGe," (ALBERT model)"),TGe.forEach(t),RQr=i(Ge),u3=n(Ge,"LI",{});var MGe=s(u3);m5e=n(MGe,"STRONG",{});var Bqt=s(m5e);PQr=r(Bqt,"bart"),Bqt.forEach(t),BQr=r(MGe," \u2014 "),See=n(MGe,"A",{href:!0});var Iqt=s(See);IQr=r(Iqt,"FlaxBartForQuestionAnswering"),Iqt.forEach(t),NQr=r(MGe," (BART model)"),MGe.forEach(t),qQr=i(Ge),b3=n(Ge,"LI",{});var EGe=s(b3);g5e=n(EGe,"STRONG",{});var Nqt=s(g5e);jQr=r(Nqt,"bert"),Nqt.forEach(t),DQr=r(EGe," \u2014 "),Ree=n(EGe,"A",{href:!0});var qqt=s(Ree);GQr=r(qqt,"FlaxBertForQuestionAnswering"),qqt.forEach(t),OQr=r(EGe," (BERT model)"),EGe.forEach(t),VQr=i(Ge),v3=n(Ge,"LI",{});var CGe=s(v3);h5e=n(CGe,"STRONG",{});var jqt=s(h5e);XQr=r(jqt,"big_bird"),jqt.forEach(t),zQr=r(CGe," \u2014 "),Pee=n(CGe,"A",{href:!0});var Dqt=s(Pee);QQr=r(Dqt,"FlaxBigBirdForQuestionAnswering"),Dqt.forEach(t),WQr=r(CGe," (BigBird model)"),CGe.forEach(t),HQr=i(Ge),F3=n(Ge,"LI",{});var wGe=s(F3);p5e=n(wGe,"STRONG",{});var Gqt=s(p5e);UQr=r(Gqt,"distilbert"),Gqt.forEach(t),JQr=r(wGe," \u2014 "),Bee=n(wGe,"A",{href:!0});var Oqt=s(Bee);YQr=r(Oqt,"FlaxDistilBertForQuestionAnswering"),Oqt.forEach(t),KQr=r(wGe," (DistilBERT model)"),wGe.forEach(t),ZQr=i(Ge),T3=n(Ge,"LI",{});var AGe=s(T3);_5e=n(AGe,"STRONG",{});var Vqt=s(_5e);eWr=r(Vqt,"electra"),Vqt.forEach(t),oWr=r(AGe," \u2014 "),Iee=n(AGe,"A",{href:!0});var Xqt=s(Iee);rWr=r(Xqt,"FlaxElectraForQuestionAnswering"),Xqt.forEach(t),tWr=r(AGe," (ELECTRA model)"),AGe.forEach(t),aWr=i(Ge),M3=n(Ge,"LI",{});var LGe=s(M3);u5e=n(LGe,"STRONG",{});var zqt=s(u5e);nWr=r(zqt,"mbart"),zqt.forEach(t),sWr=r(LGe," \u2014 "),Nee=n(LGe,"A",{href:!0});var Qqt=s(Nee);lWr=r(Qqt,"FlaxMBartForQuestionAnswering"),Qqt.forEach(t),iWr=r(LGe," (mBART model)"),LGe.forEach(t),dWr=i(Ge),E3=n(Ge,"LI",{});var yGe=s(E3);b5e=n(yGe,"STRONG",{});var Wqt=s(b5e);cWr=r(Wqt,"roberta"),Wqt.forEach(t),fWr=r(yGe," \u2014 "),qee=n(yGe,"A",{href:!0});var Hqt=s(qee);mWr=r(Hqt,"FlaxRobertaForQuestionAnswering"),Hqt.forEach(t),gWr=r(yGe," (RoBERTa model)"),yGe.forEach(t),hWr=i(Ge),C3=n(Ge,"LI",{});var xGe=s(C3);v5e=n(xGe,"STRONG",{});var Uqt=s(v5e);pWr=r(Uqt,"roformer"),Uqt.forEach(t),_Wr=r(xGe," \u2014 "),jee=n(xGe,"A",{href:!0});var Jqt=s(jee);uWr=r(Jqt,"FlaxRoFormerForQuestionAnswering"),Jqt.forEach(t),bWr=r(xGe," (RoFormer model)"),xGe.forEach(t),vWr=i(Ge),w3=n(Ge,"LI",{});var $Ge=s(w3);F5e=n($Ge,"STRONG",{});var Yqt=s(F5e);FWr=r(Yqt,"xlm-roberta"),Yqt.forEach(t),TWr=r($Ge," \u2014 "),Dee=n($Ge,"A",{href:!0});var Kqt=s(Dee);MWr=r(Kqt,"FlaxXLMRobertaForQuestionAnswering"),Kqt.forEach(t),EWr=r($Ge," (XLM-RoBERTa model)"),$Ge.forEach(t),Ge.forEach(t),CWr=i(ci),T(A3.$$.fragment,ci),ci.forEach(t),di.forEach(t),QVe=i(f),cf=n(f,"H2",{class:!0});var oQe=s(cf);L3=n(oQe,"A",{id:!0,class:!0,href:!0});var Zqt=s(L3);T5e=n(Zqt,"SPAN",{});var ejt=s(T5e);T(_$.$$.fragment,ejt),ejt.forEach(t),Zqt.forEach(t),wWr=i(oQe),M5e=n(oQe,"SPAN",{});var ojt=s(M5e);AWr=r(ojt,"FlaxAutoModelForTokenClassification"),ojt.forEach(t),oQe.forEach(t),WVe=i(f),Tr=n(f,"DIV",{class:!0});var fi=s(Tr);T(u$.$$.fragment,fi),LWr=i(fi),ff=n(fi,"P",{});var ste=s(ff);yWr=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Gee=n(ste,"A",{href:!0});var rjt=s(Gee);xWr=r(rjt,"from_pretrained()"),rjt.forEach(t),$Wr=r(ste," class method or the "),Oee=n(ste,"A",{href:!0});var tjt=s(Oee);kWr=r(tjt,"from_config()"),tjt.forEach(t),SWr=r(ste,` class
method.`),ste.forEach(t),RWr=i(fi),b$=n(fi,"P",{});var rQe=s(b$);PWr=r(rQe,"This class cannot be instantiated directly using "),E5e=n(rQe,"CODE",{});var ajt=s(E5e);BWr=r(ajt,"__init__()"),ajt.forEach(t),IWr=r(rQe," (throws an error)."),rQe.forEach(t),NWr=i(fi),Yt=n(fi,"DIV",{class:!0});var bA=s(Yt);T(v$.$$.fragment,bA),qWr=i(bA),C5e=n(bA,"P",{});var njt=s(C5e);jWr=r(njt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),njt.forEach(t),DWr=i(bA),mf=n(bA,"P",{});var lte=s(mf);GWr=r(lte,`Note:
Loading a model from its configuration file does `),w5e=n(lte,"STRONG",{});var sjt=s(w5e);OWr=r(sjt,"not"),sjt.forEach(t),VWr=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=n(lte,"A",{href:!0});var ljt=s(Vee);XWr=r(ljt,"from_pretrained()"),ljt.forEach(t),zWr=r(lte," to load the model weights."),lte.forEach(t),QWr=i(bA),T(y3.$$.fragment,bA),bA.forEach(t),WWr=i(fi),Ur=n(fi,"DIV",{class:!0});var mi=s(Ur);T(F$.$$.fragment,mi),HWr=i(mi),A5e=n(mi,"P",{});var ijt=s(A5e);UWr=r(ijt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),ijt.forEach(t),JWr=i(mi),Ln=n(mi,"P",{});var vA=s(Ln);YWr=r(vA,"The model class to instantiate is selected based on the "),L5e=n(vA,"CODE",{});var djt=s(L5e);KWr=r(djt,"model_type"),djt.forEach(t),ZWr=r(vA,` property of the config object (either
passed as an argument or loaded from `),y5e=n(vA,"CODE",{});var cjt=s(y5e);eHr=r(cjt,"pretrained_model_name_or_path"),cjt.forEach(t),oHr=r(vA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=n(vA,"CODE",{});var fjt=s(x5e);rHr=r(fjt,"pretrained_model_name_or_path"),fjt.forEach(t),tHr=r(vA,":"),vA.forEach(t),aHr=i(mi),Ve=n(mi,"UL",{});var To=s(Ve);x3=n(To,"LI",{});var kGe=s(x3);$5e=n(kGe,"STRONG",{});var mjt=s($5e);nHr=r(mjt,"albert"),mjt.forEach(t),sHr=r(kGe," \u2014 "),Xee=n(kGe,"A",{href:!0});var gjt=s(Xee);lHr=r(gjt,"FlaxAlbertForTokenClassification"),gjt.forEach(t),iHr=r(kGe," (ALBERT model)"),kGe.forEach(t),dHr=i(To),$3=n(To,"LI",{});var SGe=s($3);k5e=n(SGe,"STRONG",{});var hjt=s(k5e);cHr=r(hjt,"bert"),hjt.forEach(t),fHr=r(SGe," \u2014 "),zee=n(SGe,"A",{href:!0});var pjt=s(zee);mHr=r(pjt,"FlaxBertForTokenClassification"),pjt.forEach(t),gHr=r(SGe," (BERT model)"),SGe.forEach(t),hHr=i(To),k3=n(To,"LI",{});var RGe=s(k3);S5e=n(RGe,"STRONG",{});var _jt=s(S5e);pHr=r(_jt,"big_bird"),_jt.forEach(t),_Hr=r(RGe," \u2014 "),Qee=n(RGe,"A",{href:!0});var ujt=s(Qee);uHr=r(ujt,"FlaxBigBirdForTokenClassification"),ujt.forEach(t),bHr=r(RGe," (BigBird model)"),RGe.forEach(t),vHr=i(To),S3=n(To,"LI",{});var PGe=s(S3);R5e=n(PGe,"STRONG",{});var bjt=s(R5e);FHr=r(bjt,"distilbert"),bjt.forEach(t),THr=r(PGe," \u2014 "),Wee=n(PGe,"A",{href:!0});var vjt=s(Wee);MHr=r(vjt,"FlaxDistilBertForTokenClassification"),vjt.forEach(t),EHr=r(PGe," (DistilBERT model)"),PGe.forEach(t),CHr=i(To),R3=n(To,"LI",{});var BGe=s(R3);P5e=n(BGe,"STRONG",{});var Fjt=s(P5e);wHr=r(Fjt,"electra"),Fjt.forEach(t),AHr=r(BGe," \u2014 "),Hee=n(BGe,"A",{href:!0});var Tjt=s(Hee);LHr=r(Tjt,"FlaxElectraForTokenClassification"),Tjt.forEach(t),yHr=r(BGe," (ELECTRA model)"),BGe.forEach(t),xHr=i(To),P3=n(To,"LI",{});var IGe=s(P3);B5e=n(IGe,"STRONG",{});var Mjt=s(B5e);$Hr=r(Mjt,"roberta"),Mjt.forEach(t),kHr=r(IGe," \u2014 "),Uee=n(IGe,"A",{href:!0});var Ejt=s(Uee);SHr=r(Ejt,"FlaxRobertaForTokenClassification"),Ejt.forEach(t),RHr=r(IGe," (RoBERTa model)"),IGe.forEach(t),PHr=i(To),B3=n(To,"LI",{});var NGe=s(B3);I5e=n(NGe,"STRONG",{});var Cjt=s(I5e);BHr=r(Cjt,"roformer"),Cjt.forEach(t),IHr=r(NGe," \u2014 "),Jee=n(NGe,"A",{href:!0});var wjt=s(Jee);NHr=r(wjt,"FlaxRoFormerForTokenClassification"),wjt.forEach(t),qHr=r(NGe," (RoFormer model)"),NGe.forEach(t),jHr=i(To),I3=n(To,"LI",{});var qGe=s(I3);N5e=n(qGe,"STRONG",{});var Ajt=s(N5e);DHr=r(Ajt,"xlm-roberta"),Ajt.forEach(t),GHr=r(qGe," \u2014 "),Yee=n(qGe,"A",{href:!0});var Ljt=s(Yee);OHr=r(Ljt,"FlaxXLMRobertaForTokenClassification"),Ljt.forEach(t),VHr=r(qGe," (XLM-RoBERTa model)"),qGe.forEach(t),To.forEach(t),XHr=i(mi),T(N3.$$.fragment,mi),mi.forEach(t),fi.forEach(t),HVe=i(f),gf=n(f,"H2",{class:!0});var tQe=s(gf);q3=n(tQe,"A",{id:!0,class:!0,href:!0});var yjt=s(q3);q5e=n(yjt,"SPAN",{});var xjt=s(q5e);T(T$.$$.fragment,xjt),xjt.forEach(t),yjt.forEach(t),zHr=i(tQe),j5e=n(tQe,"SPAN",{});var $jt=s(j5e);QHr=r($jt,"FlaxAutoModelForMultipleChoice"),$jt.forEach(t),tQe.forEach(t),UVe=i(f),Mr=n(f,"DIV",{class:!0});var gi=s(Mr);T(M$.$$.fragment,gi),WHr=i(gi),hf=n(gi,"P",{});var ite=s(hf);HHr=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Kee=n(ite,"A",{href:!0});var kjt=s(Kee);UHr=r(kjt,"from_pretrained()"),kjt.forEach(t),JHr=r(ite," class method or the "),Zee=n(ite,"A",{href:!0});var Sjt=s(Zee);YHr=r(Sjt,"from_config()"),Sjt.forEach(t),KHr=r(ite,` class
method.`),ite.forEach(t),ZHr=i(gi),E$=n(gi,"P",{});var aQe=s(E$);eUr=r(aQe,"This class cannot be instantiated directly using "),D5e=n(aQe,"CODE",{});var Rjt=s(D5e);oUr=r(Rjt,"__init__()"),Rjt.forEach(t),rUr=r(aQe," (throws an error)."),aQe.forEach(t),tUr=i(gi),Kt=n(gi,"DIV",{class:!0});var FA=s(Kt);T(C$.$$.fragment,FA),aUr=i(FA),G5e=n(FA,"P",{});var Pjt=s(G5e);nUr=r(Pjt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Pjt.forEach(t),sUr=i(FA),pf=n(FA,"P",{});var dte=s(pf);lUr=r(dte,`Note:
Loading a model from its configuration file does `),O5e=n(dte,"STRONG",{});var Bjt=s(O5e);iUr=r(Bjt,"not"),Bjt.forEach(t),dUr=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),eoe=n(dte,"A",{href:!0});var Ijt=s(eoe);cUr=r(Ijt,"from_pretrained()"),Ijt.forEach(t),fUr=r(dte," to load the model weights."),dte.forEach(t),mUr=i(FA),T(j3.$$.fragment,FA),FA.forEach(t),gUr=i(gi),Jr=n(gi,"DIV",{class:!0});var hi=s(Jr);T(w$.$$.fragment,hi),hUr=i(hi),V5e=n(hi,"P",{});var Njt=s(V5e);pUr=r(Njt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Njt.forEach(t),_Ur=i(hi),yn=n(hi,"P",{});var TA=s(yn);uUr=r(TA,"The model class to instantiate is selected based on the "),X5e=n(TA,"CODE",{});var qjt=s(X5e);bUr=r(qjt,"model_type"),qjt.forEach(t),vUr=r(TA,` property of the config object (either
passed as an argument or loaded from `),z5e=n(TA,"CODE",{});var jjt=s(z5e);FUr=r(jjt,"pretrained_model_name_or_path"),jjt.forEach(t),TUr=r(TA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q5e=n(TA,"CODE",{});var Djt=s(Q5e);MUr=r(Djt,"pretrained_model_name_or_path"),Djt.forEach(t),EUr=r(TA,":"),TA.forEach(t),CUr=i(hi),Xe=n(hi,"UL",{});var Mo=s(Xe);D3=n(Mo,"LI",{});var jGe=s(D3);W5e=n(jGe,"STRONG",{});var Gjt=s(W5e);wUr=r(Gjt,"albert"),Gjt.forEach(t),AUr=r(jGe," \u2014 "),ooe=n(jGe,"A",{href:!0});var Ojt=s(ooe);LUr=r(Ojt,"FlaxAlbertForMultipleChoice"),Ojt.forEach(t),yUr=r(jGe," (ALBERT model)"),jGe.forEach(t),xUr=i(Mo),G3=n(Mo,"LI",{});var DGe=s(G3);H5e=n(DGe,"STRONG",{});var Vjt=s(H5e);$Ur=r(Vjt,"bert"),Vjt.forEach(t),kUr=r(DGe," \u2014 "),roe=n(DGe,"A",{href:!0});var Xjt=s(roe);SUr=r(Xjt,"FlaxBertForMultipleChoice"),Xjt.forEach(t),RUr=r(DGe," (BERT model)"),DGe.forEach(t),PUr=i(Mo),O3=n(Mo,"LI",{});var GGe=s(O3);U5e=n(GGe,"STRONG",{});var zjt=s(U5e);BUr=r(zjt,"big_bird"),zjt.forEach(t),IUr=r(GGe," \u2014 "),toe=n(GGe,"A",{href:!0});var Qjt=s(toe);NUr=r(Qjt,"FlaxBigBirdForMultipleChoice"),Qjt.forEach(t),qUr=r(GGe," (BigBird model)"),GGe.forEach(t),jUr=i(Mo),V3=n(Mo,"LI",{});var OGe=s(V3);J5e=n(OGe,"STRONG",{});var Wjt=s(J5e);DUr=r(Wjt,"distilbert"),Wjt.forEach(t),GUr=r(OGe," \u2014 "),aoe=n(OGe,"A",{href:!0});var Hjt=s(aoe);OUr=r(Hjt,"FlaxDistilBertForMultipleChoice"),Hjt.forEach(t),VUr=r(OGe," (DistilBERT model)"),OGe.forEach(t),XUr=i(Mo),X3=n(Mo,"LI",{});var VGe=s(X3);Y5e=n(VGe,"STRONG",{});var Ujt=s(Y5e);zUr=r(Ujt,"electra"),Ujt.forEach(t),QUr=r(VGe," \u2014 "),noe=n(VGe,"A",{href:!0});var Jjt=s(noe);WUr=r(Jjt,"FlaxElectraForMultipleChoice"),Jjt.forEach(t),HUr=r(VGe," (ELECTRA model)"),VGe.forEach(t),UUr=i(Mo),z3=n(Mo,"LI",{});var XGe=s(z3);K5e=n(XGe,"STRONG",{});var Yjt=s(K5e);JUr=r(Yjt,"roberta"),Yjt.forEach(t),YUr=r(XGe," \u2014 "),soe=n(XGe,"A",{href:!0});var Kjt=s(soe);KUr=r(Kjt,"FlaxRobertaForMultipleChoice"),Kjt.forEach(t),ZUr=r(XGe," (RoBERTa model)"),XGe.forEach(t),eJr=i(Mo),Q3=n(Mo,"LI",{});var zGe=s(Q3);Z5e=n(zGe,"STRONG",{});var Zjt=s(Z5e);oJr=r(Zjt,"roformer"),Zjt.forEach(t),rJr=r(zGe," \u2014 "),loe=n(zGe,"A",{href:!0});var eDt=s(loe);tJr=r(eDt,"FlaxRoFormerForMultipleChoice"),eDt.forEach(t),aJr=r(zGe," (RoFormer model)"),zGe.forEach(t),nJr=i(Mo),W3=n(Mo,"LI",{});var QGe=s(W3);e3e=n(QGe,"STRONG",{});var oDt=s(e3e);sJr=r(oDt,"xlm-roberta"),oDt.forEach(t),lJr=r(QGe," \u2014 "),ioe=n(QGe,"A",{href:!0});var rDt=s(ioe);iJr=r(rDt,"FlaxXLMRobertaForMultipleChoice"),rDt.forEach(t),dJr=r(QGe," (XLM-RoBERTa model)"),QGe.forEach(t),Mo.forEach(t),cJr=i(hi),T(H3.$$.fragment,hi),hi.forEach(t),gi.forEach(t),JVe=i(f),_f=n(f,"H2",{class:!0});var nQe=s(_f);U3=n(nQe,"A",{id:!0,class:!0,href:!0});var tDt=s(U3);o3e=n(tDt,"SPAN",{});var aDt=s(o3e);T(A$.$$.fragment,aDt),aDt.forEach(t),tDt.forEach(t),fJr=i(nQe),r3e=n(nQe,"SPAN",{});var nDt=s(r3e);mJr=r(nDt,"FlaxAutoModelForNextSentencePrediction"),nDt.forEach(t),nQe.forEach(t),YVe=i(f),Er=n(f,"DIV",{class:!0});var pi=s(Er);T(L$.$$.fragment,pi),gJr=i(pi),uf=n(pi,"P",{});var cte=s(uf);hJr=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),doe=n(cte,"A",{href:!0});var sDt=s(doe);pJr=r(sDt,"from_pretrained()"),sDt.forEach(t),_Jr=r(cte," class method or the "),coe=n(cte,"A",{href:!0});var lDt=s(coe);uJr=r(lDt,"from_config()"),lDt.forEach(t),bJr=r(cte,` class
method.`),cte.forEach(t),vJr=i(pi),y$=n(pi,"P",{});var sQe=s(y$);FJr=r(sQe,"This class cannot be instantiated directly using "),t3e=n(sQe,"CODE",{});var iDt=s(t3e);TJr=r(iDt,"__init__()"),iDt.forEach(t),MJr=r(sQe," (throws an error)."),sQe.forEach(t),EJr=i(pi),Zt=n(pi,"DIV",{class:!0});var MA=s(Zt);T(x$.$$.fragment,MA),CJr=i(MA),a3e=n(MA,"P",{});var dDt=s(a3e);wJr=r(dDt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),dDt.forEach(t),AJr=i(MA),bf=n(MA,"P",{});var fte=s(bf);LJr=r(fte,`Note:
Loading a model from its configuration file does `),n3e=n(fte,"STRONG",{});var cDt=s(n3e);yJr=r(cDt,"not"),cDt.forEach(t),xJr=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(fte,"A",{href:!0});var fDt=s(foe);$Jr=r(fDt,"from_pretrained()"),fDt.forEach(t),kJr=r(fte," to load the model weights."),fte.forEach(t),SJr=i(MA),T(J3.$$.fragment,MA),MA.forEach(t),RJr=i(pi),Yr=n(pi,"DIV",{class:!0});var _i=s(Yr);T($$.$$.fragment,_i),PJr=i(_i),s3e=n(_i,"P",{});var mDt=s(s3e);BJr=r(mDt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),mDt.forEach(t),IJr=i(_i),xn=n(_i,"P",{});var EA=s(xn);NJr=r(EA,"The model class to instantiate is selected based on the "),l3e=n(EA,"CODE",{});var gDt=s(l3e);qJr=r(gDt,"model_type"),gDt.forEach(t),jJr=r(EA,` property of the config object (either
passed as an argument or loaded from `),i3e=n(EA,"CODE",{});var hDt=s(i3e);DJr=r(hDt,"pretrained_model_name_or_path"),hDt.forEach(t),GJr=r(EA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d3e=n(EA,"CODE",{});var pDt=s(d3e);OJr=r(pDt,"pretrained_model_name_or_path"),pDt.forEach(t),VJr=r(EA,":"),EA.forEach(t),XJr=i(_i),c3e=n(_i,"UL",{});var _Dt=s(c3e);Y3=n(_Dt,"LI",{});var WGe=s(Y3);f3e=n(WGe,"STRONG",{});var uDt=s(f3e);zJr=r(uDt,"bert"),uDt.forEach(t),QJr=r(WGe," \u2014 "),moe=n(WGe,"A",{href:!0});var bDt=s(moe);WJr=r(bDt,"FlaxBertForNextSentencePrediction"),bDt.forEach(t),HJr=r(WGe," (BERT model)"),WGe.forEach(t),_Dt.forEach(t),UJr=i(_i),T(K3.$$.fragment,_i),_i.forEach(t),pi.forEach(t),KVe=i(f),vf=n(f,"H2",{class:!0});var lQe=s(vf);Z3=n(lQe,"A",{id:!0,class:!0,href:!0});var vDt=s(Z3);m3e=n(vDt,"SPAN",{});var FDt=s(m3e);T(k$.$$.fragment,FDt),FDt.forEach(t),vDt.forEach(t),JJr=i(lQe),g3e=n(lQe,"SPAN",{});var TDt=s(g3e);YJr=r(TDt,"FlaxAutoModelForImageClassification"),TDt.forEach(t),lQe.forEach(t),ZVe=i(f),Cr=n(f,"DIV",{class:!0});var ui=s(Cr);T(S$.$$.fragment,ui),KJr=i(ui),Ff=n(ui,"P",{});var mte=s(Ff);ZJr=r(mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),goe=n(mte,"A",{href:!0});var MDt=s(goe);eYr=r(MDt,"from_pretrained()"),MDt.forEach(t),oYr=r(mte," class method or the "),hoe=n(mte,"A",{href:!0});var EDt=s(hoe);rYr=r(EDt,"from_config()"),EDt.forEach(t),tYr=r(mte,` class
method.`),mte.forEach(t),aYr=i(ui),R$=n(ui,"P",{});var iQe=s(R$);nYr=r(iQe,"This class cannot be instantiated directly using "),h3e=n(iQe,"CODE",{});var CDt=s(h3e);sYr=r(CDt,"__init__()"),CDt.forEach(t),lYr=r(iQe," (throws an error)."),iQe.forEach(t),iYr=i(ui),ea=n(ui,"DIV",{class:!0});var CA=s(ea);T(P$.$$.fragment,CA),dYr=i(CA),p3e=n(CA,"P",{});var wDt=s(p3e);cYr=r(wDt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),wDt.forEach(t),fYr=i(CA),Tf=n(CA,"P",{});var gte=s(Tf);mYr=r(gte,`Note:
Loading a model from its configuration file does `),_3e=n(gte,"STRONG",{});var ADt=s(_3e);gYr=r(ADt,"not"),ADt.forEach(t),hYr=r(gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=n(gte,"A",{href:!0});var LDt=s(poe);pYr=r(LDt,"from_pretrained()"),LDt.forEach(t),_Yr=r(gte," to load the model weights."),gte.forEach(t),uYr=i(CA),T(e0.$$.fragment,CA),CA.forEach(t),bYr=i(ui),Kr=n(ui,"DIV",{class:!0});var bi=s(Kr);T(B$.$$.fragment,bi),vYr=i(bi),u3e=n(bi,"P",{});var yDt=s(u3e);FYr=r(yDt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),yDt.forEach(t),TYr=i(bi),$n=n(bi,"P",{});var wA=s($n);MYr=r(wA,"The model class to instantiate is selected based on the "),b3e=n(wA,"CODE",{});var xDt=s(b3e);EYr=r(xDt,"model_type"),xDt.forEach(t),CYr=r(wA,` property of the config object (either
passed as an argument or loaded from `),v3e=n(wA,"CODE",{});var $Dt=s(v3e);wYr=r($Dt,"pretrained_model_name_or_path"),$Dt.forEach(t),AYr=r(wA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F3e=n(wA,"CODE",{});var kDt=s(F3e);LYr=r(kDt,"pretrained_model_name_or_path"),kDt.forEach(t),yYr=r(wA,":"),wA.forEach(t),xYr=i(bi),I$=n(bi,"UL",{});var dQe=s(I$);o0=n(dQe,"LI",{});var HGe=s(o0);T3e=n(HGe,"STRONG",{});var SDt=s(T3e);$Yr=r(SDt,"beit"),SDt.forEach(t),kYr=r(HGe," \u2014 "),_oe=n(HGe,"A",{href:!0});var RDt=s(_oe);SYr=r(RDt,"FlaxBeitForImageClassification"),RDt.forEach(t),RYr=r(HGe," (BEiT model)"),HGe.forEach(t),PYr=i(dQe),r0=n(dQe,"LI",{});var UGe=s(r0);M3e=n(UGe,"STRONG",{});var PDt=s(M3e);BYr=r(PDt,"vit"),PDt.forEach(t),IYr=r(UGe," \u2014 "),uoe=n(UGe,"A",{href:!0});var BDt=s(uoe);NYr=r(BDt,"FlaxViTForImageClassification"),BDt.forEach(t),qYr=r(UGe," (ViT model)"),UGe.forEach(t),dQe.forEach(t),jYr=i(bi),T(t0.$$.fragment,bi),bi.forEach(t),ui.forEach(t),eXe=i(f),Mf=n(f,"H2",{class:!0});var cQe=s(Mf);a0=n(cQe,"A",{id:!0,class:!0,href:!0});var IDt=s(a0);E3e=n(IDt,"SPAN",{});var NDt=s(E3e);T(N$.$$.fragment,NDt),NDt.forEach(t),IDt.forEach(t),DYr=i(cQe),C3e=n(cQe,"SPAN",{});var qDt=s(C3e);GYr=r(qDt,"FlaxAutoModelForVision2Seq"),qDt.forEach(t),cQe.forEach(t),oXe=i(f),wr=n(f,"DIV",{class:!0});var vi=s(wr);T(q$.$$.fragment,vi),OYr=i(vi),Ef=n(vi,"P",{});var hte=s(Ef);VYr=r(hte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),boe=n(hte,"A",{href:!0});var jDt=s(boe);XYr=r(jDt,"from_pretrained()"),jDt.forEach(t),zYr=r(hte," class method or the "),voe=n(hte,"A",{href:!0});var DDt=s(voe);QYr=r(DDt,"from_config()"),DDt.forEach(t),WYr=r(hte,` class
method.`),hte.forEach(t),HYr=i(vi),j$=n(vi,"P",{});var fQe=s(j$);UYr=r(fQe,"This class cannot be instantiated directly using "),w3e=n(fQe,"CODE",{});var GDt=s(w3e);JYr=r(GDt,"__init__()"),GDt.forEach(t),YYr=r(fQe," (throws an error)."),fQe.forEach(t),KYr=i(vi),oa=n(vi,"DIV",{class:!0});var AA=s(oa);T(D$.$$.fragment,AA),ZYr=i(AA),A3e=n(AA,"P",{});var ODt=s(A3e);eKr=r(ODt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ODt.forEach(t),oKr=i(AA),Cf=n(AA,"P",{});var pte=s(Cf);rKr=r(pte,`Note:
Loading a model from its configuration file does `),L3e=n(pte,"STRONG",{});var VDt=s(L3e);tKr=r(VDt,"not"),VDt.forEach(t),aKr=r(pte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Foe=n(pte,"A",{href:!0});var XDt=s(Foe);nKr=r(XDt,"from_pretrained()"),XDt.forEach(t),sKr=r(pte," to load the model weights."),pte.forEach(t),lKr=i(AA),T(n0.$$.fragment,AA),AA.forEach(t),iKr=i(vi),Zr=n(vi,"DIV",{class:!0});var Fi=s(Zr);T(G$.$$.fragment,Fi),dKr=i(Fi),y3e=n(Fi,"P",{});var zDt=s(y3e);cKr=r(zDt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),zDt.forEach(t),fKr=i(Fi),kn=n(Fi,"P",{});var LA=s(kn);mKr=r(LA,"The model class to instantiate is selected based on the "),x3e=n(LA,"CODE",{});var QDt=s(x3e);gKr=r(QDt,"model_type"),QDt.forEach(t),hKr=r(LA,` property of the config object (either
passed as an argument or loaded from `),$3e=n(LA,"CODE",{});var WDt=s($3e);pKr=r(WDt,"pretrained_model_name_or_path"),WDt.forEach(t),_Kr=r(LA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k3e=n(LA,"CODE",{});var HDt=s(k3e);uKr=r(HDt,"pretrained_model_name_or_path"),HDt.forEach(t),bKr=r(LA,":"),LA.forEach(t),vKr=i(Fi),S3e=n(Fi,"UL",{});var UDt=s(S3e);s0=n(UDt,"LI",{});var JGe=s(s0);R3e=n(JGe,"STRONG",{});var JDt=s(R3e);FKr=r(JDt,"vision-encoder-decoder"),JDt.forEach(t),TKr=r(JGe," \u2014 "),Toe=n(JGe,"A",{href:!0});var YDt=s(Toe);MKr=r(YDt,"FlaxVisionEncoderDecoderModel"),YDt.forEach(t),EKr=r(JGe," (Vision Encoder decoder model)"),JGe.forEach(t),UDt.forEach(t),CKr=i(Fi),T(l0.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(tVt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Rn,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.AutoConfig"),c(Bn,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.AutoTokenizer"),c(Li,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertModel"),c(Sf,"id","extending-the-auto-classes"),c(Sf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sf,"href","#extending-the-auto-classes"),c(yi,"class","relative group"),c(Pf,"id","transformers.AutoConfig"),c(Pf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pf,"href","#transformers.AutoConfig"),c(xi,"class","relative group"),c(fS,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(mS,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertConfig"),c(gS,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartConfig"),c(hS,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitConfig"),c(pS,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertConfig"),c(_S,"href","/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(uS,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdConfig"),c(bS,"href","/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(vS,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(FS,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(TS,"href","/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomConfig"),c(MS,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertConfig"),c(ES,"href","/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineConfig"),c(CS,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPConfig"),c(wS,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertConfig"),c(AS,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextConfig"),c(LS,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLConfig"),c(yS,"href","/docs/transformers/pr_17826/en/model_doc/cvt#transformers.CvtConfig"),c(xS,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c($S,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(kS,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(SS,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaConfig"),c(RS,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(PS,"href","/docs/transformers/pr_17826/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(BS,"href","/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTConfig"),c(IS,"href","/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrConfig"),c(NS,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertConfig"),c(qS,"href","/docs/transformers/pr_17826/en/model_doc/dpr#transformers.DPRConfig"),c(jS,"href","/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTConfig"),c(DS,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraConfig"),c(GS,"href","/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(OS,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertConfig"),c(VS,"href","/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaConfig"),c(XS,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetConfig"),c(zS,"href","/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTConfig"),c(QS,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelConfig"),c(WS,"href","/docs/transformers/pr_17826/en/model_doc/glpn#transformers.GLPNConfig"),c(HS,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Config"),c(US,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(JS,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(YS,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJConfig"),c(KS,"href","/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertConfig"),c(ZS,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertConfig"),c(eR,"href","/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(oR,"href","/docs/transformers/pr_17826/en/model_doc/jukebox#transformers.JukeboxConfig"),c(rR,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(tR,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(aR,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(nR,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDConfig"),c(sR,"href","/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitConfig"),c(lR,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerConfig"),c(iR,"href","/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Config"),c(dR,"href","/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeConfig"),c(cR,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertConfig"),c(fR,"href","/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100Config"),c(mR,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianConfig"),c(gR,"href","/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(hR,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartConfig"),c(pR,"href","/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTConfig"),c(_R,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(uR,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(bR,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetConfig"),c(vR,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Config"),c(FR,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaConfig"),c(TR,"href","/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(MR,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(ER,"href","/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTConfig"),c(CR,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusConfig"),c(wR,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverConfig"),c(AR,"href","/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartConfig"),c(LR,"href","/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(yR,"href","/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(xR,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertConfig"),c($R,"href","/docs/transformers/pr_17826/en/model_doc/rag#transformers.RagConfig"),c(kR,"href","/docs/transformers/pr_17826/en/model_doc/realm#transformers.RealmConfig"),c(SR,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerConfig"),c(RR,"href","/docs/transformers/pr_17826/en/model_doc/regnet#transformers.RegNetConfig"),c(PR,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertConfig"),c(BR,"href","/docs/transformers/pr_17826/en/model_doc/resnet#transformers.ResNetConfig"),c(IR,"href","/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertConfig"),c(NR,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaConfig"),c(qR,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerConfig"),c(jR,"href","/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerConfig"),c(DR,"href","/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWConfig"),c(GR,"href","/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDConfig"),c(OR,"href","/docs/transformers/pr_17826/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(VR,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(XR,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(zR,"href","/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterConfig"),c(QR,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(WR,"href","/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinConfig"),c(HR,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Config"),c(UR,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasConfig"),c(JR,"href","/docs/transformers/pr_17826/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(YR,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(KR,"href","/docs/transformers/pr_17826/en/model_doc/trocr#transformers.TrOCRConfig"),c(ZR,"href","/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(eP,"href","/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(oP,"href","/docs/transformers/pr_17826/en/model_doc/van#transformers.VanConfig"),c(rP,"href","/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltConfig"),c(tP,"href","/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(aP,"href","/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(nP,"href","/docs/transformers/pr_17826/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(sP,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTConfig"),c(lP,"href","/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(iP,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(dP,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(cP,"href","/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMConfig"),c(fP,"href","/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMConfig"),c(mP,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMConfig"),c(gP,"href","/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(hP,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(pP,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(_P,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetConfig"),c(uP,"href","/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosConfig"),c(bP,"href","/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoConfig"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xg,"id","transformers.AutoTokenizer"),c(Xg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xg,"href","#transformers.AutoTokenizer"),c(ki,"class","relative group"),c(vP,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(FP,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertTokenizer"),c(TP,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(MP,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartTokenizer"),c(EP,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartTokenizerFast"),c(CP,"href","/docs/transformers/pr_17826/en/model_doc/barthez#transformers.BarthezTokenizer"),c(wP,"href","/docs/transformers/pr_17826/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(AP,"href","/docs/transformers/pr_17826/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(LP,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizer"),c(yP,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizerFast"),c(xP,"href","/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c($P,"href","/docs/transformers/pr_17826/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(kP,"href","/docs/transformers/pr_17826/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(SP,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(RP,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(PP,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(BP,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(IP,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(NP,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(qP,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(jP,"href","/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(DP,"href","/docs/transformers/pr_17826/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(GP,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertTokenizer"),c(OP,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(VP,"href","/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineTokenizer"),c(XP,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPTokenizer"),c(zP,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(QP,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(WP,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(HP,"href","/docs/transformers/pr_17826/en/model_doc/cpm#transformers.CpmTokenizer"),c(UP,"href","/docs/transformers/pr_17826/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(JP,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(YP,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizer"),c(KP,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(ZP,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaTokenizer"),c(eB,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(oB,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(rB,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(tB,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(aB,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(nB,"href","/docs/transformers/pr_17826/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(sB,"href","/docs/transformers/pr_17826/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(lB,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraTokenizer"),c(iB,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(dB,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(cB,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetTokenizer"),c(fB,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(mB,"href","/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(gB,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelTokenizer"),c(hB,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(pB,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(_B,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(uB,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(bB,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(vB,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(FB,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(TB,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(MB,"href","/docs/transformers/pr_17826/en/model_doc/herbert#transformers.HerbertTokenizer"),c(EB,"href","/docs/transformers/pr_17826/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(CB,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(wB,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizer"),c(AB,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LB,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(yB,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(xB,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c($B,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(kB,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(SB,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(RB,"href","/docs/transformers/pr_17826/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(PB,"href","/docs/transformers/pr_17826/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(BB,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDTokenizer"),c(IB,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDTokenizerFast"),c(NB,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerTokenizer"),c(qB,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(jB,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Tokenizer"),c(DB,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5TokenizerFast"),c(GB,"href","/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeTokenizer"),c(OB,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(VB,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(XB,"href","/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(zB,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianTokenizer"),c(QB,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartTokenizer"),c(WB,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(HB,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(UB,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(JB,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizer"),c(YB,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizerFast"),c(KB,"href","/docs/transformers/pr_17826/en/model_doc/mluke#transformers.MLukeTokenizer"),c(ZB,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(eI,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(oI,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(rI,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(tI,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Tokenizer"),c(aI,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5TokenizerFast"),c(nI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizer"),c(sI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizerFast"),c(lI,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertTokenizer"),c(iI,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(dI,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(cI,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(fI,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(mI,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(gI,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(hI,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(pI,"href","/docs/transformers/pr_17826/en/model_doc/phobert#transformers.PhobertTokenizer"),c(_I,"href","/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartTokenizer"),c(uI,"href","/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(bI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizer"),c(vI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizerFast"),c(FI,"href","/docs/transformers/pr_17826/en/model_doc/rag#transformers.RagTokenizer"),c(TI,"href","/docs/transformers/pr_17826/en/model_doc/realm#transformers.RealmTokenizer"),c(MI,"href","/docs/transformers/pr_17826/en/model_doc/realm#transformers.RealmTokenizerFast"),c(EI,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerTokenizer"),c(CI,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(wI,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertTokenizer"),c(AI,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(LI,"href","/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(yI,"href","/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(xI,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizer"),c($I,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(kI,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(SI,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(RI,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(PI,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(BI,"href","/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterTokenizer"),c(II,"href","/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(NI,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(qI,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(jI,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Tokenizer"),c(DI,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5TokenizerFast"),c(GI,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasTokenizer"),c(OI,"href","/docs/transformers/pr_17826/en/model_doc/tapex#transformers.TapexTokenizer"),c(VI,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(XI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizer"),c(zI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizerFast"),c(QI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizer"),c(WI,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertTokenizerFast"),c(HI,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(UI,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(JI,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(YI,"href","/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMTokenizer"),c(KI,"href","/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(ZI,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMTokenizer"),c(eN,"href","/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(oN,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(rN,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(tN,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizer"),c(aN,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(nN,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(sN,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(lN,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertTokenizer"),c(iN,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ah,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lh,"id","transformers.AutoFeatureExtractor"),c(Lh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lh,"href","#transformers.AutoFeatureExtractor"),c(Si,"class","relative group"),c(dN,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(cN,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(fN,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(mN,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(gN,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(hN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(pN,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(_N,"href","/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(uN,"href","/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(bN,"href","/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(vN,"href","/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(FN,"href","/docs/transformers/pr_17826/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(TN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(MN,"href","/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(EN,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(CN,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(wN,"href","/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(AN,"href","/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(LN,"href","/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(yN,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(xN,"href","/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c($N,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(kN,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SN,"href","/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(RN,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(PN,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BN,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(IN,"href","/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(NN,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(qN,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(jN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(DN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(GN,"href","/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ip,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dp,"id","transformers.AutoProcessor"),c(dp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dp,"href","#transformers.AutoProcessor"),c(Ri,"class","relative group"),c(ON,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(VN,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPProcessor"),c(XN,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(zN,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(QN,"href","/docs/transformers/pr_17826/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(WN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(HN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UN,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(JN,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(YN,"href","/docs/transformers/pr_17826/en/model_doc/trocr#transformers.TrOCRProcessor"),c(KN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZN,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eq,"href","/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltProcessor"),c(oq,"href","/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(rq,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(tq,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(aq,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($p,"id","transformers.AutoModel"),c($p,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($p,"href","#transformers.AutoModel"),c(Bi,"class","relative group"),c(nq,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sq,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lq,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iq,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertModel"),c(dq,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartModel"),c(cq,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitModel"),c(fq,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertModel"),c(mq,"href","/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(gq,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdModel"),c(hq,"href","/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(pq,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(_q,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(uq,"href","/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomModel"),c(bq,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertModel"),c(vq,"href","/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineModel"),c(Fq,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.CLIPModel"),c(Tq,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertModel"),c(Mq,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextModel"),c(Eq,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLModel"),c(Cq,"href","/docs/transformers/pr_17826/en/model_doc/cvt#transformers.CvtModel"),c(wq,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Aq,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Lq,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(yq,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaModel"),c(xq,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c($q,"href","/docs/transformers/pr_17826/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(kq,"href","/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTModel"),c(Sq,"href","/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrModel"),c(Rq,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertModel"),c(Pq,"href","/docs/transformers/pr_17826/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(Bq,"href","/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTModel"),c(Iq,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraModel"),c(Nq,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertModel"),c(qq,"href","/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaModel"),c(jq,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetModel"),c(Dq,"href","/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTModel"),c(Gq,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelModel"),c(Oq,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelBaseModel"),c(Vq,"href","/docs/transformers/pr_17826/en/model_doc/glpn#transformers.GLPNModel"),c(Xq,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2Model"),c(zq,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Qq,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Wq,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJModel"),c(Hq,"href","/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertModel"),c(Uq,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertModel"),c(Jq,"href","/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Yq,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Kq,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Zq,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(ej,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDModel"),c(oj,"href","/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitModel"),c(rj,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerModel"),c(tj,"href","/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5Model"),c(aj,"href","/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeModel"),c(nj,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertModel"),c(sj,"href","/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100Model"),c(lj,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianModel"),c(ij,"href","/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerModel"),c(dj,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartModel"),c(cj,"href","/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTModel"),c(fj,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(mj,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertModel"),c(gj,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetModel"),c(hj,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5Model"),c(pj,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaModel"),c(_j,"href","/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerModel"),c(uj,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(bj,"href","/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTModel"),c(vj,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusModel"),c(Fj,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverModel"),c(Tj,"href","/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartModel"),c(Mj,"href","/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerModel"),c(Ej,"href","/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Cj,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertModel"),c(wj,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerModel"),c(Aj,"href","/docs/transformers/pr_17826/en/model_doc/regnet#transformers.RegNetModel"),c(Lj,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertModel"),c(yj,"href","/docs/transformers/pr_17826/en/model_doc/resnet#transformers.ResNetModel"),c(xj,"href","/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertModel"),c($j,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaModel"),c(kj,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerModel"),c(Sj,"href","/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerModel"),c(Rj,"href","/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWModel"),c(Pj,"href","/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDModel"),c(Bj,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Ij,"href","/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterModel"),c(Nj,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(qj,"href","/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinModel"),c(jj,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5Model"),c(Dj,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasModel"),c(Gj,"href","/docs/transformers/pr_17826/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(Oj,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(Vj,"href","/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Xj,"href","/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(zj,"href","/docs/transformers/pr_17826/en/model_doc/van#transformers.VanModel"),c(Qj,"href","/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltModel"),c(Wj,"href","/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Hj,"href","/docs/transformers/pr_17826/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Uj,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTModel"),c(Jj,"href","/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Yj,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Kj,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Zj,"href","/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMModel"),c(eD,"href","/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMModel"),c(oD,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMModel"),c(rD,"href","/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(tD,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(aD,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(nD,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetModel"),c(sD,"href","/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosModel"),c(lD,"href","/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ru,"id","transformers.AutoModelForPreTraining"),c(Ru,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ru,"href","#transformers.AutoModelForPreTraining"),c(qi,"class","relative group"),c(iD,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dD,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cD,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fD,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForPreTraining"),c(mD,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(gD,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForPreTraining"),c(hD,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(pD,"href","/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForCausalLM"),c(_D,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(uD,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(bD,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(vD,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(FD,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(TD,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(MD,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForPreTraining"),c(ED,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(CD,"href","/docs/transformers/pr_17826/en/model_doc/flava#transformers.FlavaForPreTraining"),c(wD,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForPreTraining"),c(AD,"href","/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(LD,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(yD,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(xD,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForMaskedLM"),c($D,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(kD,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(SD,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(RD,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(PD,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(BD,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(ID,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(ND,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(qD,"href","/docs/transformers/pr_17826/en/model_doc/retribert#transformers.RetriBertModel"),c(jD,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(DD,"href","/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(GD,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(OD,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(VD,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(XD,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(zD,"href","/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(QD,"href","/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(WD,"href","/docs/transformers/pr_17826/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(HD,"href","/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(UD,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(JD,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(YD,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(KD,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(ZD,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(eG,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L2,"id","transformers.AutoModelForCausalLM"),c(L2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L2,"href","#transformers.AutoModelForCausalLM"),c(Gi,"class","relative group"),c(oG,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rG,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tG,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aG,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForCausalLM"),c(nG,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertLMHeadModel"),c(sG,"href","/docs/transformers/pr_17826/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(lG,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(iG,"href","/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(dG,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(cG,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(fG,"href","/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForCausalLM"),c(mG,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(gG,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(hG,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(pG,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForCausalLM"),c(_G,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(uG,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(bG,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(vG,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(FG,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianForCausalLM"),c(TG,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForCausalLM"),c(MG,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(EG,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(CG,"href","/docs/transformers/pr_17826/en/model_doc/opt#transformers.OPTForCausalLM"),c(wG,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(AG,"href","/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(LG,"href","/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(yG,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(xG,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c($G,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(kG,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(SG,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(RG,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(PG,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(BG,"href","/docs/transformers/pr_17826/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(IG,"href","/docs/transformers/pr_17826/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(NG,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(qG,"href","/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(jG,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(DG,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(GG,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p1,"id","transformers.AutoModelForMaskedLM"),c(p1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p1,"href","#transformers.AutoModelForMaskedLM"),c(Xi,"class","relative group"),c(OG,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VG,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XG,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zG,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(QG,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(WG,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForMaskedLM"),c(HG,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(UG,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(JG,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(YG,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(KG,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(ZG,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(eO,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(oO,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(rO,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(tO,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(aO,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(nO,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(sO,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(lO,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(iO,"href","/docs/transformers/pr_17826/en/model_doc/luke#transformers.LukeForMaskedLM"),c(dO,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(cO,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(fO,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(mO,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(gO,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(hO,"href","/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(pO,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(_O,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(uO,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(bO,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(vO,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(FO,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(TO,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(MO,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(EO,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(CO,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(wO,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(AO,"href","/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rb,"id","transformers.AutoModelForSeq2SeqLM"),c(rb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rb,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wi,"class","relative group"),c(LO,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yO,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xO,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($O,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(kO,"href","/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(RO,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(PO,"href","/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(BO,"href","/docs/transformers/pr_17826/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(IO,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(NO,"href","/docs/transformers/pr_17826/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(qO,"href","/docs/transformers/pr_17826/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(jO,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.MarianMTModel"),c(DO,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(GO,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(OO,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(VO,"href","/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(XO,"href","/docs/transformers/pr_17826/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(zO,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(QO,"href","/docs/transformers/pr_17826/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eb,"id","transformers.AutoModelForSequenceClassification"),c(Eb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Eb,"href","#transformers.AutoModelForSequenceClassification"),c(Ji,"class","relative group"),c(WO,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HO,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UO,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JO,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(cV,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(fV,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(mV,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(gV,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(hV,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(pV,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(_V,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(uV,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(bV,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c($V,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17826/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(BV,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(NV,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(GV,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(OV,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(VV,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(XV,"href","/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mv,"id","transformers.AutoModelForMultipleChoice"),c(Mv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mv,"href","#transformers.AutoModelForMultipleChoice"),c(Zi,"class","relative group"),c(zV,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QV,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WV,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HV,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(UV,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForMultipleChoice"),c(JV,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(YV,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(KV,"href","/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(ZV,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(eX,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(oX,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(rX,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(tX,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(aX,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(nX,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(sX,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(lX,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(iX,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(dX,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(cX,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(fX,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(mX,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(gX,"href","/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(hX,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(pX,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(_X,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(uX,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(bX,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(vX,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(FX,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(TX,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(MX,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(EX,"href","/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rF,"id","transformers.AutoModelForNextSentencePrediction"),c(rF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rF,"href","#transformers.AutoModelForNextSentencePrediction"),c(rd,"class","relative group"),c(CX,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wX,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AX,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LX,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(yX,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(xX,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c($X,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(kX,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(SX,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mF,"id","transformers.AutoModelForTokenClassification"),c(mF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mF,"href","#transformers.AutoModelForTokenClassification"),c(nd,"class","relative group"),c(RX,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PX,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BX,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IX,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(NX,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForTokenClassification"),c(qX,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(jX,"href","/docs/transformers/pr_17826/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(DX,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(GX,"href","/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForTokenClassification"),c(OX,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(VX,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(XX,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(zX,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(QX,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(WX,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(HX,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(UX,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(JX,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(YX,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(KX,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(ZX,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(ez,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(oz,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(rz,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(tz,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(az,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(nz,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(sz,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(lz,"href","/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(iz,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(dz,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(cz,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(fz,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(mz,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(gz,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(hz,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(pz,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(_z,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(uz,"href","/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KF,"id","transformers.AutoModelForQuestionAnswering"),c(KF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KF,"href","#transformers.AutoModelForQuestionAnswering"),c(id,"class","relative group"),c(bz,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vz,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(Mz,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(Ez,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(wz,"href","/docs/transformers/pr_17826/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Az,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Lz,"href","/docs/transformers/pr_17826/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(yz,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(xz,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c($z,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(kz,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(Sz,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(Rz,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(Pz,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(Bz,"href","/docs/transformers/pr_17826/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(Iz,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Nz,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(qz,"href","/docs/transformers/pr_17826/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(jz,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Dz,"href","/docs/transformers/pr_17826/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(Gz,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(Oz,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(Vz,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(Xz,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17826/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(Qz,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(Hz,"href","/docs/transformers/pr_17826/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(Uz,"href","/docs/transformers/pr_17826/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(Jz,"href","/docs/transformers/pr_17826/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Yz,"href","/docs/transformers/pr_17826/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(Kz,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(Zz,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(eQ,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(oQ,"href","/docs/transformers/pr_17826/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(rQ,"href","/docs/transformers/pr_17826/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(tQ,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(aQ,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(nQ,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(sQ,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(lQ,"href","/docs/transformers/pr_17826/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V6,"id","transformers.AutoModelForTableQuestionAnswering"),c(V6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V6,"href","#transformers.AutoModelForTableQuestionAnswering"),c(fd,"class","relative group"),c(iQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H6,"id","transformers.AutoModelForImageClassification"),c(H6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H6,"href","#transformers.AutoModelForImageClassification"),c(hd,"class","relative group"),c(mQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pQ,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitForImageClassification"),c(_Q,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(uQ,"href","/docs/transformers/pr_17826/en/model_doc/cvt#transformers.CvtForImageClassification"),c(bQ,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(vQ,"href","/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTForImageClassification"),c(FQ,"href","/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(TQ,"href","/docs/transformers/pr_17826/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(MQ,"href","/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitForImageClassification"),c(EQ,"href","/docs/transformers/pr_17826/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(CQ,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(wQ,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(AQ,"href","/docs/transformers/pr_17826/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(LQ,"href","/docs/transformers/pr_17826/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(yQ,"href","/docs/transformers/pr_17826/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(xQ,"href","/docs/transformers/pr_17826/en/model_doc/resnet#transformers.ResNetForImageClassification"),c($Q,"href","/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(kQ,"href","/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinForImageClassification"),c(SQ,"href","/docs/transformers/pr_17826/en/model_doc/van#transformers.VanForImageClassification"),c(RQ,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cT,"id","transformers.AutoModelForVision2Seq"),c(cT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cT,"href","#transformers.AutoModelForVision2Seq"),c(ud,"class","relative group"),c(PQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NQ,"href","/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pT,"id","transformers.AutoModelForVisualQuestionAnswering"),c(pT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pT,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Fd,"class","relative group"),c(qQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GQ,"href","/docs/transformers/pr_17826/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FT,"id","transformers.AutoModelForAudioClassification"),c(FT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FT,"href","#transformers.AutoModelForAudioClassification"),c(Ed,"class","relative group"),c(OQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XQ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zQ,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(QQ,"href","/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(WQ,"href","/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(HQ,"href","/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(UQ,"href","/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(JQ,"href","/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(YQ,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(KQ,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(ZQ,"href","/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RT,"id","transformers.AutoModelForAudioFrameClassification"),c(RT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RT,"href","#transformers.AutoModelForAudioFrameClassification"),c(Ad,"class","relative group"),c(eW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tW,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(aW,"href","/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(nW,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(sW,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(lW,"href","/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OT,"id","transformers.AutoModelForCTC"),c(OT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OT,"href","#transformers.AutoModelForCTC"),c(xd,"class","relative group"),c(iW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fW,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(mW,"href","/docs/transformers/pr_17826/en/model_doc/hubert#transformers.HubertForCTC"),c(gW,"href","/docs/transformers/pr_17826/en/model_doc/mctct#transformers.MCTCTForCTC"),c(hW,"href","/docs/transformers/pr_17826/en/model_doc/sew#transformers.SEWForCTC"),c(pW,"href","/docs/transformers/pr_17826/en/model_doc/sew-d#transformers.SEWDForCTC"),c(_W,"href","/docs/transformers/pr_17826/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(uW,"href","/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(bW,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(vW,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(FW,"href","/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r7,"id","transformers.AutoModelForSpeechSeq2Seq"),c(r7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r7,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Sd,"class","relative group"),c(TW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CW,"href","/docs/transformers/pr_17826/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(wW,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i7,"id","transformers.AutoModelForAudioXVector"),c(i7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i7,"href","#transformers.AutoModelForAudioXVector"),c(Bd,"class","relative group"),c(AW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xW,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c($W,"href","/docs/transformers/pr_17826/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(kW,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(SW,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(RW,"href","/docs/transformers/pr_17826/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u7,"id","transformers.AutoModelForMaskedImageModeling"),c(u7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u7,"href","#transformers.AutoModelForMaskedImageModeling"),c(qd,"class","relative group"),c(PW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NW,"href","/docs/transformers/pr_17826/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(qW,"href","/docs/transformers/pr_17826/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(jW,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C7,"id","transformers.AutoModelForObjectDetection"),c(C7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C7,"href","#transformers.AutoModelForObjectDetection"),c(Od,"class","relative group"),c(DW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VW,"href","/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrForObjectDetection"),c(XW,"href","/docs/transformers/pr_17826/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($7,"id","transformers.AutoModelForImageSegmentation"),c($7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($7,"href","#transformers.AutoModelForImageSegmentation"),c(zd,"class","relative group"),c(zW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HW,"href","/docs/transformers/pr_17826/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B7,"id","transformers.AutoModelForSemanticSegmentation"),c(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B7,"href","#transformers.AutoModelForSemanticSegmentation"),c(Hd,"class","relative group"),c(UW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YW,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KW,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(ZW,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(eH,"href","/docs/transformers/pr_17826/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(oH,"href","/docs/transformers/pr_17826/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V7,"id","transformers.AutoModelForInstanceSegmentation"),c(V7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V7,"href","#transformers.AutoModelForInstanceSegmentation"),c(Yd,"class","relative group"),c(rH,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/pr_17826/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H7,"id","transformers.TFAutoModel"),c(H7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H7,"href","#transformers.TFAutoModel"),c(ec,"class","relative group"),c(sH,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lH,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iH,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dH,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertModel"),c(cH,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.TFBartModel"),c(fH,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertModel"),c(mH,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(gH,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(hH,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertModel"),c(pH,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.TFCLIPModel"),c(_H,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertModel"),c(uH,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.TFConvNextModel"),c(bH,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLModel"),c(vH,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(FH,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaModel"),c(TH,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(MH,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(EH,"href","/docs/transformers/pr_17826/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(CH,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraModel"),c(wH,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(AH,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelModel"),c(LH,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(yH,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2Model"),c(xH,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJModel"),c($H,"href","/docs/transformers/pr_17826/en/model_doc/hubert#transformers.TFHubertModel"),c(kH,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(SH,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.TFLEDModel"),c(RH,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerModel"),c(PH,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.TFLxmertModel"),c(BH,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.TFMarianModel"),c(IH,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.TFMBartModel"),c(NH,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(qH,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetModel"),c(jH,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.TFMT5Model"),c(DH,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(GH,"href","/docs/transformers/pr_17826/en/model_doc/opt#transformers.TFOPTModel"),c(OH,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.TFPegasusModel"),c(VH,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertModel"),c(XH,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaModel"),c(zH,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerModel"),c(QH,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(WH,"href","/docs/transformers/pr_17826/en/model_doc/swin#transformers.TFSwinModel"),c(HH,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.TFT5Model"),c(UH,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasModel"),c(JH,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(YH,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.TFViTModel"),c(KH,"href","/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(ZH,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(eU,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMModel"),c(oU,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(rU,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V8,"id","transformers.TFAutoModelForPreTraining"),c(V8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V8,"href","#transformers.TFAutoModelForPreTraining"),c(tc,"class","relative group"),c(tU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sU,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(lU,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(iU,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForPreTraining"),c(dU,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(cU,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(fU,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(mU,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(gU,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(hU,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(pU,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(_U,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(uU,"href","/docs/transformers/pr_17826/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(bU,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(vU,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(FU,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(TU,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(MU,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(EU,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(CU,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(wU,"href","/docs/transformers/pr_17826/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(AU,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(LU,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(yU,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pM,"id","transformers.TFAutoModelForCausalLM"),c(pM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pM,"href","#transformers.TFAutoModelForCausalLM"),c(sc,"class","relative group"),c(xU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($U,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SU,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(RU,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(PU,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(BU,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(IU,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(NU,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(qU,"href","/docs/transformers/pr_17826/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(jU,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(DU,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(GU,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(OU,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(VU,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(XU,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kM,"id","transformers.TFAutoModelForImageClassification"),c(kM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kM,"href","#transformers.TFAutoModelForImageClassification"),c(dc,"class","relative group"),c(zU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HU,"href","/docs/transformers/pr_17826/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(UU,"href","/docs/transformers/pr_17826/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(JU,"href","/docs/transformers/pr_17826/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(YU,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.TFViTForImageClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qM,"id","transformers.TFAutoModelForMaskedLM"),c(qM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qM,"href","#transformers.TFAutoModelForMaskedLM"),c(mc,"class","relative group"),c(KU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZU,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eJ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oJ,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(rJ,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(tJ,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(aJ,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(nJ,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(sJ,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(lJ,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(iJ,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(dJ,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(cJ,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(fJ,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(mJ,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(gJ,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(hJ,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(pJ,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(_J,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(uJ,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(bJ,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(vJ,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(FJ,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lE,"id","transformers.TFAutoModelForSeq2SeqLM"),c(lE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lE,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(pc,"class","relative group"),c(TJ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MJ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EJ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CJ,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(wJ,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(AJ,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(LJ,"href","/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(yJ,"href","/docs/transformers/pr_17826/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(xJ,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.TFMarianMTModel"),c($J,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(kJ,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(SJ,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(RJ,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FE,"id","transformers.TFAutoModelForSequenceClassification"),c(FE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FE,"href","#transformers.TFAutoModelForSequenceClassification"),c(bc,"class","relative group"),c(PJ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BJ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IJ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NJ,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(qJ,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(jJ,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(DJ,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(GJ,"href","/docs/transformers/pr_17826/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(OJ,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(VJ,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(XJ,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(zJ,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(QJ,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(WJ,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(HJ,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(UJ,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(JJ,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(YJ,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(KJ,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(ZJ,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(eY,"href","/docs/transformers/pr_17826/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(oY,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(rY,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(tY,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(aY,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(nY,"href","/docs/transformers/pr_17826/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(sY,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(lY,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(iY,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UE,"id","transformers.TFAutoModelForMultipleChoice"),c(UE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UE,"href","#transformers.TFAutoModelForMultipleChoice"),c(Tc,"class","relative group"),c(dY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mY,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(gY,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(hY,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(pY,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(_Y,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(uY,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(bY,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(vY,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(FY,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(TY,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(MY,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(EY,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(CY,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(wY,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(AY,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(LY,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(yY,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p4,"id","transformers.TFAutoModelForNextSentencePrediction"),c(p4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p4,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Cc,"class","relative group"),c(xY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($Y,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SY,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(RY,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F4,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(F4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F4,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Lc,"class","relative group"),c(PY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_17826/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C4,"id","transformers.TFAutoModelForTokenClassification"),c(C4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C4,"href","#transformers.TFAutoModelForTokenClassification"),c($c,"class","relative group"),c(qY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DY,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GY,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(OY,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(VY,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(XY,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(zY,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(QY,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(WY,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(HY,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(UY,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(JY,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(YY,"href","/docs/transformers/pr_17826/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(KY,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(ZY,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(eK,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(oK,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(rK,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(tK,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(aK,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(nK,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(sK,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W4,"id","transformers.TFAutoModelForQuestionAnswering"),c(W4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W4,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Rc,"class","relative group"),c(lK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cK,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(fK,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(mK,"href","/docs/transformers/pr_17826/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(gK,"href","/docs/transformers/pr_17826/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(hK,"href","/docs/transformers/pr_17826/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(pK,"href","/docs/transformers/pr_17826/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(_K,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(uK,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(bK,"href","/docs/transformers/pr_17826/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(vK,"href","/docs/transformers/pr_17826/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(FK,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(TK,"href","/docs/transformers/pr_17826/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(MK,"href","/docs/transformers/pr_17826/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(EK,"href","/docs/transformers/pr_17826/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(CK,"href","/docs/transformers/pr_17826/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(wK,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(AK,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(LK,"href","/docs/transformers/pr_17826/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(yK,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(xK,"href","/docs/transformers/pr_17826/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_C,"id","transformers.TFAutoModelForVision2Seq"),c(_C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_C,"href","#transformers.TFAutoModelForVision2Seq"),c(Ic,"class","relative group"),c($K,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FC,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(FC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FC,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c(PK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17826/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CC,"id","transformers.FlaxAutoModel"),c(CC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CC,"href","#transformers.FlaxAutoModel"),c(Oc,"class","relative group"),c(qK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DK,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GK,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertModel"),c(OK,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartModel"),c(VK,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.FlaxBeitModel"),c(XK,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertModel"),c(zK,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(QK,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(WK,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(HK,"href","/docs/transformers/pr_17826/en/model_doc/clip#transformers.FlaxCLIPModel"),c(UK,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(JK,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraModel"),c(YK,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(KK,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(ZK,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(eZ,"href","/docs/transformers/pr_17826/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(oZ,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.FlaxMarianModel"),c(rZ,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartModel"),c(tZ,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.FlaxMT5Model"),c(aZ,"href","/docs/transformers/pr_17826/en/model_doc/opt#transformers.FlaxOPTModel"),c(nZ,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(sZ,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(lZ,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(iZ,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.FlaxT5Model"),c(dZ,"href","/docs/transformers/pr_17826/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(cZ,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.FlaxViTModel"),c(fZ,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(mZ,"href","/docs/transformers/pr_17826/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(gZ,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e5,"id","transformers.FlaxAutoModelForCausalLM"),c(e5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e5,"href","#transformers.FlaxAutoModelForCausalLM"),c(zc,"class","relative group"),c(hZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_Z,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uZ,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(bZ,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(vZ,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(FZ,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(TZ,"href","/docs/transformers/pr_17826/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(MZ,"href","/docs/transformers/pr_17826/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(EZ,"href","/docs/transformers/pr_17826/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(CZ,"href","/docs/transformers/pr_17826/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(wZ,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(AZ,"href","/docs/transformers/pr_17826/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g5,"id","transformers.FlaxAutoModelForPreTraining"),c(g5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g5,"href","#transformers.FlaxAutoModelForPreTraining"),c(Hc,"class","relative group"),c(LZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($Z,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(kZ,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(SZ,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(RZ,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(PZ,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(BZ,"href","/docs/transformers/pr_17826/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(IZ,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(NZ,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(qZ,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(jZ,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(DZ,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(GZ,"href","/docs/transformers/pr_17826/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(OZ,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x5,"id","transformers.FlaxAutoModelForMaskedLM"),c(x5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x5,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Yc,"class","relative group"),c(VZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zZ,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QZ,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(WZ,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(HZ,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(UZ,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(JZ,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(YZ,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(KZ,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(ZZ,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(eee,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(oee,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(O5,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(O5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O5,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(ef,"class","relative group"),c(ree,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nee,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(see,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(lee,"href","/docs/transformers/pr_17826/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(iee,"href","/docs/transformers/pr_17826/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(dee,"href","/docs/transformers/pr_17826/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(cee,"href","/docs/transformers/pr_17826/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(fee,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(mee,"href","/docs/transformers/pr_17826/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(gee,"href","/docs/transformers/pr_17826/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(hee,"href","/docs/transformers/pr_17826/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o3,"id","transformers.FlaxAutoModelForSequenceClassification"),c(o3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o3,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(tf,"class","relative group"),c(pee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_ee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bee,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(vee,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Fee,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(Tee,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Mee,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Eee,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Cee,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(wee,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Aee,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Lee,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h3,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(h3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h3,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(sf,"class","relative group"),c(yee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($ee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kee,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(See,"href","/docs/transformers/pr_17826/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(Ree,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Pee,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Bee,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Iee,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Nee,"href","/docs/transformers/pr_17826/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(qee,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(jee,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Dee,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L3,"id","transformers.FlaxAutoModelForTokenClassification"),c(L3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L3,"href","#transformers.FlaxAutoModelForTokenClassification"),c(cf,"class","relative group"),c(Gee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Oee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xee,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(zee,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Qee,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Wee,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Hee,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Uee,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Jee,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Yee,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q3,"id","transformers.FlaxAutoModelForMultipleChoice"),c(q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q3,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(Kee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zee,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eoe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ooe,"href","/docs/transformers/pr_17826/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(roe,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(toe,"href","/docs/transformers/pr_17826/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(aoe,"href","/docs/transformers/pr_17826/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(noe,"href","/docs/transformers/pr_17826/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(soe,"href","/docs/transformers/pr_17826/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(loe,"href","/docs/transformers/pr_17826/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(ioe,"href","/docs/transformers/pr_17826/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U3,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(U3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U3,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(_f,"class","relative group"),c(doe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(foe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(moe,"href","/docs/transformers/pr_17826/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z3,"id","transformers.FlaxAutoModelForImageClassification"),c(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z3,"href","#transformers.FlaxAutoModelForImageClassification"),c(vf,"class","relative group"),c(goe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hoe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(poe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_oe,"href","/docs/transformers/pr_17826/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(uoe,"href","/docs/transformers/pr_17826/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a0,"id","transformers.FlaxAutoModelForVision2Seq"),c(a0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a0,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Mf,"class","relative group"),c(boe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(voe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Foe,"href","/docs/transformers/pr_17826/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Toe,"href","/docs/transformers/pr_17826/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,Ti),b(f,yf,u),b(f,at,u),e(at,Mi),e(at,Ei),e(Ei,yA),e(at,xf),b(f,Oe,u),b(f,Qe,u),e(Qe,Ci),e(Qe,Rn),e(Rn,xA),e(Qe,Pn),e(Qe,Bn),e(Bn,$A),e(Qe,wi),e(Qe,In),e(In,kA),e(Qe,Ai),b(f,$f,u),M(xa,f,u),b(f,We,u),b(f,Ae,u),e(Ae,nS),e(Ae,Li),e(Li,sS),e(Ae,lS),b(f,Co,u),b(f,$a,u),e($a,iS),e($a,kf),e(kf,dS),e($a,mQe),b(f,YGe,u),b(f,yi,u),e(yi,Sf),e(Sf,_te),M(SA,_te,null),e(yi,gQe),e(yi,ute),e(ute,hQe),b(f,KGe,u),b(f,Nn,u),e(Nn,pQe),e(Nn,bte),e(bte,_Qe),e(Nn,uQe),e(Nn,vte),e(vte,bQe),e(Nn,vQe),b(f,ZGe,u),M(RA,f,u),b(f,eOe,u),b(f,cS,u),e(cS,FQe),b(f,oOe,u),M(Rf,f,u),b(f,rOe,u),b(f,xi,u),e(xi,Pf),e(Pf,Fte),M(PA,Fte,null),e(xi,TQe),e(xi,Tte),e(Tte,MQe),b(f,tOe,u),b(f,wo,u),M(BA,wo,null),e(wo,EQe),e(wo,IA),e(IA,CQe),e(IA,fS),e(fS,wQe),e(IA,AQe),e(wo,LQe),e(wo,NA),e(NA,yQe),e(NA,Mte),e(Mte,xQe),e(NA,$Qe),e(wo,kQe),e(wo,Ar),M(qA,Ar,null),e(Ar,SQe),e(Ar,Ete),e(Ete,RQe),e(Ar,PQe),e(Ar,$i),e($i,BQe),e($i,Cte),e(Cte,IQe),e($i,NQe),e($i,wte),e(wte,qQe),e($i,jQe),e(Ar,DQe),e(Ar,A),e(A,Bf),e(Bf,Ate),e(Ate,GQe),e(Bf,OQe),e(Bf,mS),e(mS,VQe),e(Bf,XQe),e(A,zQe),e(A,If),e(If,Lte),e(Lte,QQe),e(If,WQe),e(If,gS),e(gS,HQe),e(If,UQe),e(A,JQe),e(A,Nf),e(Nf,yte),e(yte,YQe),e(Nf,KQe),e(Nf,hS),e(hS,ZQe),e(Nf,eWe),e(A,oWe),e(A,qf),e(qf,xte),e(xte,rWe),e(qf,tWe),e(qf,pS),e(pS,aWe),e(qf,nWe),e(A,sWe),e(A,jf),e(jf,$te),e($te,lWe),e(jf,iWe),e(jf,_S),e(_S,dWe),e(jf,cWe),e(A,fWe),e(A,Df),e(Df,kte),e(kte,mWe),e(Df,gWe),e(Df,uS),e(uS,hWe),e(Df,pWe),e(A,_We),e(A,Gf),e(Gf,Ste),e(Ste,uWe),e(Gf,bWe),e(Gf,bS),e(bS,vWe),e(Gf,FWe),e(A,TWe),e(A,Of),e(Of,Rte),e(Rte,MWe),e(Of,EWe),e(Of,vS),e(vS,CWe),e(Of,wWe),e(A,AWe),e(A,Vf),e(Vf,Pte),e(Pte,LWe),e(Vf,yWe),e(Vf,FS),e(FS,xWe),e(Vf,$We),e(A,kWe),e(A,Xf),e(Xf,Bte),e(Bte,SWe),e(Xf,RWe),e(Xf,TS),e(TS,PWe),e(Xf,BWe),e(A,IWe),e(A,zf),e(zf,Ite),e(Ite,NWe),e(zf,qWe),e(zf,MS),e(MS,jWe),e(zf,DWe),e(A,GWe),e(A,Qf),e(Qf,Nte),e(Nte,OWe),e(Qf,VWe),e(Qf,ES),e(ES,XWe),e(Qf,zWe),e(A,QWe),e(A,Wf),e(Wf,qte),e(qte,WWe),e(Wf,HWe),e(Wf,CS),e(CS,UWe),e(Wf,JWe),e(A,YWe),e(A,Hf),e(Hf,jte),e(jte,KWe),e(Hf,ZWe),e(Hf,wS),e(wS,eHe),e(Hf,oHe),e(A,rHe),e(A,Uf),e(Uf,Dte),e(Dte,tHe),e(Uf,aHe),e(Uf,AS),e(AS,nHe),e(Uf,sHe),e(A,lHe),e(A,Jf),e(Jf,Gte),e(Gte,iHe),e(Jf,dHe),e(Jf,LS),e(LS,cHe),e(Jf,fHe),e(A,mHe),e(A,Yf),e(Yf,Ote),e(Ote,gHe),e(Yf,hHe),e(Yf,yS),e(yS,pHe),e(Yf,_He),e(A,uHe),e(A,Kf),e(Kf,Vte),e(Vte,bHe),e(Kf,vHe),e(Kf,xS),e(xS,FHe),e(Kf,THe),e(A,MHe),e(A,Zf),e(Zf,Xte),e(Xte,EHe),e(Zf,CHe),e(Zf,$S),e($S,wHe),e(Zf,AHe),e(A,LHe),e(A,em),e(em,zte),e(zte,yHe),e(em,xHe),e(em,kS),e(kS,$He),e(em,kHe),e(A,SHe),e(A,om),e(om,Qte),e(Qte,RHe),e(om,PHe),e(om,SS),e(SS,BHe),e(om,IHe),e(A,NHe),e(A,rm),e(rm,Wte),e(Wte,qHe),e(rm,jHe),e(rm,RS),e(RS,DHe),e(rm,GHe),e(A,OHe),e(A,tm),e(tm,Hte),e(Hte,VHe),e(tm,XHe),e(tm,PS),e(PS,zHe),e(tm,QHe),e(A,WHe),e(A,am),e(am,Ute),e(Ute,HHe),e(am,UHe),e(am,BS),e(BS,JHe),e(am,YHe),e(A,KHe),e(A,nm),e(nm,Jte),e(Jte,ZHe),e(nm,eUe),e(nm,IS),e(IS,oUe),e(nm,rUe),e(A,tUe),e(A,sm),e(sm,Yte),e(Yte,aUe),e(sm,nUe),e(sm,NS),e(NS,sUe),e(sm,lUe),e(A,iUe),e(A,lm),e(lm,Kte),e(Kte,dUe),e(lm,cUe),e(lm,qS),e(qS,fUe),e(lm,mUe),e(A,gUe),e(A,im),e(im,Zte),e(Zte,hUe),e(im,pUe),e(im,jS),e(jS,_Ue),e(im,uUe),e(A,bUe),e(A,dm),e(dm,eae),e(eae,vUe),e(dm,FUe),e(dm,DS),e(DS,TUe),e(dm,MUe),e(A,EUe),e(A,cm),e(cm,oae),e(oae,CUe),e(cm,wUe),e(cm,GS),e(GS,AUe),e(cm,LUe),e(A,yUe),e(A,fm),e(fm,rae),e(rae,xUe),e(fm,$Ue),e(fm,OS),e(OS,kUe),e(fm,SUe),e(A,RUe),e(A,mm),e(mm,tae),e(tae,PUe),e(mm,BUe),e(mm,VS),e(VS,IUe),e(mm,NUe),e(A,qUe),e(A,gm),e(gm,aae),e(aae,jUe),e(gm,DUe),e(gm,XS),e(XS,GUe),e(gm,OUe),e(A,VUe),e(A,hm),e(hm,nae),e(nae,XUe),e(hm,zUe),e(hm,zS),e(zS,QUe),e(hm,WUe),e(A,HUe),e(A,pm),e(pm,sae),e(sae,UUe),e(pm,JUe),e(pm,QS),e(QS,YUe),e(pm,KUe),e(A,ZUe),e(A,_m),e(_m,lae),e(lae,eJe),e(_m,oJe),e(_m,WS),e(WS,rJe),e(_m,tJe),e(A,aJe),e(A,um),e(um,iae),e(iae,nJe),e(um,sJe),e(um,HS),e(HS,lJe),e(um,iJe),e(A,dJe),e(A,bm),e(bm,dae),e(dae,cJe),e(bm,fJe),e(bm,US),e(US,mJe),e(bm,gJe),e(A,hJe),e(A,vm),e(vm,cae),e(cae,pJe),e(vm,_Je),e(vm,JS),e(JS,uJe),e(vm,bJe),e(A,vJe),e(A,Fm),e(Fm,fae),e(fae,FJe),e(Fm,TJe),e(Fm,YS),e(YS,MJe),e(Fm,EJe),e(A,CJe),e(A,Tm),e(Tm,mae),e(mae,wJe),e(Tm,AJe),e(Tm,KS),e(KS,LJe),e(Tm,yJe),e(A,xJe),e(A,Mm),e(Mm,gae),e(gae,$Je),e(Mm,kJe),e(Mm,ZS),e(ZS,SJe),e(Mm,RJe),e(A,PJe),e(A,Em),e(Em,hae),e(hae,BJe),e(Em,IJe),e(Em,eR),e(eR,NJe),e(Em,qJe),e(A,jJe),e(A,Cm),e(Cm,pae),e(pae,DJe),e(Cm,GJe),e(Cm,oR),e(oR,OJe),e(Cm,VJe),e(A,XJe),e(A,wm),e(wm,_ae),e(_ae,zJe),e(wm,QJe),e(wm,rR),e(rR,WJe),e(wm,HJe),e(A,UJe),e(A,Am),e(Am,uae),e(uae,JJe),e(Am,YJe),e(Am,tR),e(tR,KJe),e(Am,ZJe),e(A,eYe),e(A,Lm),e(Lm,bae),e(bae,oYe),e(Lm,rYe),e(Lm,aR),e(aR,tYe),e(Lm,aYe),e(A,nYe),e(A,ym),e(ym,vae),e(vae,sYe),e(ym,lYe),e(ym,nR),e(nR,iYe),e(ym,dYe),e(A,cYe),e(A,xm),e(xm,Fae),e(Fae,fYe),e(xm,mYe),e(xm,sR),e(sR,gYe),e(xm,hYe),e(A,pYe),e(A,$m),e($m,Tae),e(Tae,_Ye),e($m,uYe),e($m,lR),e(lR,bYe),e($m,vYe),e(A,FYe),e(A,km),e(km,Mae),e(Mae,TYe),e(km,MYe),e(km,iR),e(iR,EYe),e(km,CYe),e(A,wYe),e(A,Sm),e(Sm,Eae),e(Eae,AYe),e(Sm,LYe),e(Sm,dR),e(dR,yYe),e(Sm,xYe),e(A,$Ye),e(A,Rm),e(Rm,Cae),e(Cae,kYe),e(Rm,SYe),e(Rm,cR),e(cR,RYe),e(Rm,PYe),e(A,BYe),e(A,Pm),e(Pm,wae),e(wae,IYe),e(Pm,NYe),e(Pm,fR),e(fR,qYe),e(Pm,jYe),e(A,DYe),e(A,Bm),e(Bm,Aae),e(Aae,GYe),e(Bm,OYe),e(Bm,mR),e(mR,VYe),e(Bm,XYe),e(A,zYe),e(A,Im),e(Im,Lae),e(Lae,QYe),e(Im,WYe),e(Im,gR),e(gR,HYe),e(Im,UYe),e(A,JYe),e(A,Nm),e(Nm,yae),e(yae,YYe),e(Nm,KYe),e(Nm,hR),e(hR,ZYe),e(Nm,eKe),e(A,oKe),e(A,qm),e(qm,xae),e(xae,rKe),e(qm,tKe),e(qm,pR),e(pR,aKe),e(qm,nKe),e(A,sKe),e(A,jm),e(jm,$ae),e($ae,lKe),e(jm,iKe),e(jm,_R),e(_R,dKe),e(jm,cKe),e(A,fKe),e(A,Dm),e(Dm,kae),e(kae,mKe),e(Dm,gKe),e(Dm,uR),e(uR,hKe),e(Dm,pKe),e(A,_Ke),e(A,Gm),e(Gm,Sae),e(Sae,uKe),e(Gm,bKe),e(Gm,bR),e(bR,vKe),e(Gm,FKe),e(A,TKe),e(A,Om),e(Om,Rae),e(Rae,MKe),e(Om,EKe),e(Om,vR),e(vR,CKe),e(Om,wKe),e(A,AKe),e(A,Vm),e(Vm,Pae),e(Pae,LKe),e(Vm,yKe),e(Vm,FR),e(FR,xKe),e(Vm,$Ke),e(A,kKe),e(A,Xm),e(Xm,Bae),e(Bae,SKe),e(Xm,RKe),e(Xm,TR),e(TR,PKe),e(Xm,BKe),e(A,IKe),e(A,zm),e(zm,Iae),e(Iae,NKe),e(zm,qKe),e(zm,MR),e(MR,jKe),e(zm,DKe),e(A,GKe),e(A,Qm),e(Qm,Nae),e(Nae,OKe),e(Qm,VKe),e(Qm,ER),e(ER,XKe),e(Qm,zKe),e(A,QKe),e(A,Wm),e(Wm,qae),e(qae,WKe),e(Wm,HKe),e(Wm,CR),e(CR,UKe),e(Wm,JKe),e(A,YKe),e(A,Hm),e(Hm,jae),e(jae,KKe),e(Hm,ZKe),e(Hm,wR),e(wR,eZe),e(Hm,oZe),e(A,rZe),e(A,Um),e(Um,Dae),e(Dae,tZe),e(Um,aZe),e(Um,AR),e(AR,nZe),e(Um,sZe),e(A,lZe),e(A,Jm),e(Jm,Gae),e(Gae,iZe),e(Jm,dZe),e(Jm,LR),e(LR,cZe),e(Jm,fZe),e(A,mZe),e(A,Ym),e(Ym,Oae),e(Oae,gZe),e(Ym,hZe),e(Ym,yR),e(yR,pZe),e(Ym,_Ze),e(A,uZe),e(A,Km),e(Km,Vae),e(Vae,bZe),e(Km,vZe),e(Km,xR),e(xR,FZe),e(Km,TZe),e(A,MZe),e(A,Zm),e(Zm,Xae),e(Xae,EZe),e(Zm,CZe),e(Zm,$R),e($R,wZe),e(Zm,AZe),e(A,LZe),e(A,eg),e(eg,zae),e(zae,yZe),e(eg,xZe),e(eg,kR),e(kR,$Ze),e(eg,kZe),e(A,SZe),e(A,og),e(og,Qae),e(Qae,RZe),e(og,PZe),e(og,SR),e(SR,BZe),e(og,IZe),e(A,NZe),e(A,rg),e(rg,Wae),e(Wae,qZe),e(rg,jZe),e(rg,RR),e(RR,DZe),e(rg,GZe),e(A,OZe),e(A,tg),e(tg,Hae),e(Hae,VZe),e(tg,XZe),e(tg,PR),e(PR,zZe),e(tg,QZe),e(A,WZe),e(A,ag),e(ag,Uae),e(Uae,HZe),e(ag,UZe),e(ag,BR),e(BR,JZe),e(ag,YZe),e(A,KZe),e(A,ng),e(ng,Jae),e(Jae,ZZe),e(ng,eeo),e(ng,IR),e(IR,oeo),e(ng,reo),e(A,teo),e(A,sg),e(sg,Yae),e(Yae,aeo),e(sg,neo),e(sg,NR),e(NR,seo),e(sg,leo),e(A,ieo),e(A,lg),e(lg,Kae),e(Kae,deo),e(lg,ceo),e(lg,qR),e(qR,feo),e(lg,meo),e(A,geo),e(A,ig),e(ig,Zae),e(Zae,heo),e(ig,peo),e(ig,jR),e(jR,_eo),e(ig,ueo),e(A,beo),e(A,dg),e(dg,ene),e(ene,veo),e(dg,Feo),e(dg,DR),e(DR,Teo),e(dg,Meo),e(A,Eeo),e(A,cg),e(cg,one),e(one,Ceo),e(cg,weo),e(cg,GR),e(GR,Aeo),e(cg,Leo),e(A,yeo),e(A,fg),e(fg,rne),e(rne,xeo),e(fg,$eo),e(fg,OR),e(OR,keo),e(fg,Seo),e(A,Reo),e(A,mg),e(mg,tne),e(tne,Peo),e(mg,Beo),e(mg,VR),e(VR,Ieo),e(mg,Neo),e(A,qeo),e(A,gg),e(gg,ane),e(ane,jeo),e(gg,Deo),e(gg,XR),e(XR,Geo),e(gg,Oeo),e(A,Veo),e(A,hg),e(hg,nne),e(nne,Xeo),e(hg,zeo),e(hg,zR),e(zR,Qeo),e(hg,Weo),e(A,Heo),e(A,pg),e(pg,sne),e(sne,Ueo),e(pg,Jeo),e(pg,QR),e(QR,Yeo),e(pg,Keo),e(A,Zeo),e(A,_g),e(_g,lne),e(lne,eoo),e(_g,ooo),e(_g,WR),e(WR,roo),e(_g,too),e(A,aoo),e(A,ug),e(ug,ine),e(ine,noo),e(ug,soo),e(ug,HR),e(HR,loo),e(ug,ioo),e(A,doo),e(A,bg),e(bg,dne),e(dne,coo),e(bg,foo),e(bg,UR),e(UR,moo),e(bg,goo),e(A,hoo),e(A,vg),e(vg,cne),e(cne,poo),e(vg,_oo),e(vg,JR),e(JR,uoo),e(vg,boo),e(A,voo),e(A,Fg),e(Fg,fne),e(fne,Foo),e(Fg,Too),e(Fg,YR),e(YR,Moo),e(Fg,Eoo),e(A,Coo),e(A,Tg),e(Tg,mne),e(mne,woo),e(Tg,Aoo),e(Tg,KR),e(KR,Loo),e(Tg,yoo),e(A,xoo),e(A,Mg),e(Mg,gne),e(gne,$oo),e(Mg,koo),e(Mg,ZR),e(ZR,Soo),e(Mg,Roo),e(A,Poo),e(A,Eg),e(Eg,hne),e(hne,Boo),e(Eg,Ioo),e(Eg,eP),e(eP,Noo),e(Eg,qoo),e(A,joo),e(A,Cg),e(Cg,pne),e(pne,Doo),e(Cg,Goo),e(Cg,oP),e(oP,Ooo),e(Cg,Voo),e(A,Xoo),e(A,wg),e(wg,_ne),e(_ne,zoo),e(wg,Qoo),e(wg,rP),e(rP,Woo),e(wg,Hoo),e(A,Uoo),e(A,Ag),e(Ag,une),e(une,Joo),e(Ag,Yoo),e(Ag,tP),e(tP,Koo),e(Ag,Zoo),e(A,ero),e(A,Lg),e(Lg,bne),e(bne,oro),e(Lg,rro),e(Lg,aP),e(aP,tro),e(Lg,aro),e(A,nro),e(A,yg),e(yg,vne),e(vne,sro),e(yg,lro),e(yg,nP),e(nP,iro),e(yg,dro),e(A,cro),e(A,xg),e(xg,Fne),e(Fne,fro),e(xg,mro),e(xg,sP),e(sP,gro),e(xg,hro),e(A,pro),e(A,$g),e($g,Tne),e(Tne,_ro),e($g,uro),e($g,lP),e(lP,bro),e($g,vro),e(A,Fro),e(A,kg),e(kg,Mne),e(Mne,Tro),e(kg,Mro),e(kg,iP),e(iP,Ero),e(kg,Cro),e(A,wro),e(A,Sg),e(Sg,Ene),e(Ene,Aro),e(Sg,Lro),e(Sg,dP),e(dP,yro),e(Sg,xro),e(A,$ro),e(A,Rg),e(Rg,Cne),e(Cne,kro),e(Rg,Sro),e(Rg,cP),e(cP,Rro),e(Rg,Pro),e(A,Bro),e(A,Pg),e(Pg,wne),e(wne,Iro),e(Pg,Nro),e(Pg,fP),e(fP,qro),e(Pg,jro),e(A,Dro),e(A,Bg),e(Bg,Ane),e(Ane,Gro),e(Bg,Oro),e(Bg,mP),e(mP,Vro),e(Bg,Xro),e(A,zro),e(A,Ig),e(Ig,Lne),e(Lne,Qro),e(Ig,Wro),e(Ig,gP),e(gP,Hro),e(Ig,Uro),e(A,Jro),e(A,Ng),e(Ng,yne),e(yne,Yro),e(Ng,Kro),e(Ng,hP),e(hP,Zro),e(Ng,eto),e(A,oto),e(A,qg),e(qg,xne),e(xne,rto),e(qg,tto),e(qg,pP),e(pP,ato),e(qg,nto),e(A,sto),e(A,jg),e(jg,$ne),e($ne,lto),e(jg,ito),e(jg,_P),e(_P,dto),e(jg,cto),e(A,fto),e(A,Dg),e(Dg,kne),e(kne,mto),e(Dg,gto),e(Dg,uP),e(uP,hto),e(Dg,pto),e(A,_to),e(A,Gg),e(Gg,Sne),e(Sne,uto),e(Gg,bto),e(Gg,bP),e(bP,vto),e(Gg,Fto),e(Ar,Tto),M(Og,Ar,null),e(wo,Mto),e(wo,Vg),M(jA,Vg,null),e(Vg,Eto),e(Vg,Rne),e(Rne,Cto),b(f,aOe,u),b(f,ki,u),e(ki,Xg),e(Xg,Pne),M(DA,Pne,null),e(ki,wto),e(ki,Bne),e(Bne,Ato),b(f,nOe,u),b(f,Ao,u),M(GA,Ao,null),e(Ao,Lto),e(Ao,OA),e(OA,yto),e(OA,vP),e(vP,xto),e(OA,$to),e(Ao,kto),e(Ao,VA),e(VA,Sto),e(VA,Ine),e(Ine,Rto),e(VA,Pto),e(Ao,Bto),e(Ao,Lr),M(XA,Lr,null),e(Lr,Ito),e(Lr,Nne),e(Nne,Nto),e(Lr,qto),e(Lr,ka),e(ka,jto),e(ka,qne),e(qne,Dto),e(ka,Gto),e(ka,jne),e(jne,Oto),e(ka,Vto),e(ka,Dne),e(Dne,Xto),e(ka,zto),e(Lr,Qto),e(Lr,k),e(k,qn),e(qn,Gne),e(Gne,Wto),e(qn,Hto),e(qn,FP),e(FP,Uto),e(qn,Jto),e(qn,TP),e(TP,Yto),e(qn,Kto),e(k,Zto),e(k,jn),e(jn,One),e(One,eao),e(jn,oao),e(jn,MP),e(MP,rao),e(jn,tao),e(jn,EP),e(EP,aao),e(jn,nao),e(k,sao),e(k,Dn),e(Dn,Vne),e(Vne,lao),e(Dn,iao),e(Dn,CP),e(CP,dao),e(Dn,cao),e(Dn,wP),e(wP,fao),e(Dn,mao),e(k,gao),e(k,zg),e(zg,Xne),e(Xne,hao),e(zg,pao),e(zg,AP),e(AP,_ao),e(zg,uao),e(k,bao),e(k,Gn),e(Gn,zne),e(zne,vao),e(Gn,Fao),e(Gn,LP),e(LP,Tao),e(Gn,Mao),e(Gn,yP),e(yP,Eao),e(Gn,Cao),e(k,wao),e(k,Qg),e(Qg,Qne),e(Qne,Aao),e(Qg,Lao),e(Qg,xP),e(xP,yao),e(Qg,xao),e(k,$ao),e(k,Wg),e(Wg,Wne),e(Wne,kao),e(Wg,Sao),e(Wg,$P),e($P,Rao),e(Wg,Pao),e(k,Bao),e(k,Hg),e(Hg,Hne),e(Hne,Iao),e(Hg,Nao),e(Hg,kP),e(kP,qao),e(Hg,jao),e(k,Dao),e(k,On),e(On,Une),e(Une,Gao),e(On,Oao),e(On,SP),e(SP,Vao),e(On,Xao),e(On,RP),e(RP,zao),e(On,Qao),e(k,Wao),e(k,Vn),e(Vn,Jne),e(Jne,Hao),e(Vn,Uao),e(Vn,PP),e(PP,Jao),e(Vn,Yao),e(Vn,BP),e(BP,Kao),e(Vn,Zao),e(k,eno),e(k,Xn),e(Xn,Yne),e(Yne,ono),e(Xn,rno),e(Xn,IP),e(IP,tno),e(Xn,ano),e(Xn,NP),e(NP,nno),e(Xn,sno),e(k,lno),e(k,Ug),e(Ug,Kne),e(Kne,ino),e(Ug,dno),e(Ug,qP),e(qP,cno),e(Ug,fno),e(k,mno),e(k,Jg),e(Jg,Zne),e(Zne,gno),e(Jg,hno),e(Jg,jP),e(jP,pno),e(Jg,_no),e(k,uno),e(k,Yg),e(Yg,ese),e(ese,bno),e(Yg,vno),e(Yg,DP),e(DP,Fno),e(Yg,Tno),e(k,Mno),e(k,zn),e(zn,ose),e(ose,Eno),e(zn,Cno),e(zn,GP),e(GP,wno),e(zn,Ano),e(zn,OP),e(OP,Lno),e(zn,yno),e(k,xno),e(k,Kg),e(Kg,rse),e(rse,$no),e(Kg,kno),e(Kg,VP),e(VP,Sno),e(Kg,Rno),e(k,Pno),e(k,Qn),e(Qn,tse),e(tse,Bno),e(Qn,Ino),e(Qn,XP),e(XP,Nno),e(Qn,qno),e(Qn,zP),e(zP,jno),e(Qn,Dno),e(k,Gno),e(k,Wn),e(Wn,ase),e(ase,Ono),e(Wn,Vno),e(Wn,QP),e(QP,Xno),e(Wn,zno),e(Wn,WP),e(WP,Qno),e(Wn,Wno),e(k,Hno),e(k,Hn),e(Hn,nse),e(nse,Uno),e(Hn,Jno),e(Hn,HP),e(HP,Yno),e(Hn,Kno),e(Hn,UP),e(UP,Zno),e(Hn,eso),e(k,oso),e(k,Zg),e(Zg,sse),e(sse,rso),e(Zg,tso),e(Zg,JP),e(JP,aso),e(Zg,nso),e(k,sso),e(k,Un),e(Un,lse),e(lse,lso),e(Un,iso),e(Un,YP),e(YP,dso),e(Un,cso),e(Un,KP),e(KP,fso),e(Un,mso),e(k,gso),e(k,Jn),e(Jn,ise),e(ise,hso),e(Jn,pso),e(Jn,ZP),e(ZP,_so),e(Jn,uso),e(Jn,eB),e(eB,bso),e(Jn,vso),e(k,Fso),e(k,Yn),e(Yn,dse),e(dse,Tso),e(Yn,Mso),e(Yn,oB),e(oB,Eso),e(Yn,Cso),e(Yn,rB),e(rB,wso),e(Yn,Aso),e(k,Lso),e(k,Kn),e(Kn,cse),e(cse,yso),e(Kn,xso),e(Kn,tB),e(tB,$so),e(Kn,kso),e(Kn,aB),e(aB,Sso),e(Kn,Rso),e(k,Pso),e(k,Zn),e(Zn,fse),e(fse,Bso),e(Zn,Iso),e(Zn,nB),e(nB,Nso),e(Zn,qso),e(Zn,sB),e(sB,jso),e(Zn,Dso),e(k,Gso),e(k,es),e(es,mse),e(mse,Oso),e(es,Vso),e(es,lB),e(lB,Xso),e(es,zso),e(es,iB),e(iB,Qso),e(es,Wso),e(k,Hso),e(k,eh),e(eh,gse),e(gse,Uso),e(eh,Jso),e(eh,dB),e(dB,Yso),e(eh,Kso),e(k,Zso),e(k,os),e(os,hse),e(hse,elo),e(os,olo),e(os,cB),e(cB,rlo),e(os,tlo),e(os,fB),e(fB,alo),e(os,nlo),e(k,slo),e(k,oh),e(oh,pse),e(pse,llo),e(oh,ilo),e(oh,mB),e(mB,dlo),e(oh,clo),e(k,flo),e(k,rs),e(rs,_se),e(_se,mlo),e(rs,glo),e(rs,gB),e(gB,hlo),e(rs,plo),e(rs,hB),e(hB,_lo),e(rs,ulo),e(k,blo),e(k,ts),e(ts,use),e(use,vlo),e(ts,Flo),e(ts,pB),e(pB,Tlo),e(ts,Mlo),e(ts,_B),e(_B,Elo),e(ts,Clo),e(k,wlo),e(k,as),e(as,bse),e(bse,Alo),e(as,Llo),e(as,uB),e(uB,ylo),e(as,xlo),e(as,bB),e(bB,$lo),e(as,klo),e(k,Slo),e(k,rh),e(rh,vse),e(vse,Rlo),e(rh,Plo),e(rh,vB),e(vB,Blo),e(rh,Ilo),e(k,Nlo),e(k,ns),e(ns,Fse),e(Fse,qlo),e(ns,jlo),e(ns,FB),e(FB,Dlo),e(ns,Glo),e(ns,TB),e(TB,Olo),e(ns,Vlo),e(k,Xlo),e(k,ss),e(ss,Tse),e(Tse,zlo),e(ss,Qlo),e(ss,MB),e(MB,Wlo),e(ss,Hlo),e(ss,EB),e(EB,Ulo),e(ss,Jlo),e(k,Ylo),e(k,th),e(th,Mse),e(Mse,Klo),e(th,Zlo),e(th,CB),e(CB,eio),e(th,oio),e(k,rio),e(k,ls),e(ls,Ese),e(Ese,tio),e(ls,aio),e(ls,wB),e(wB,nio),e(ls,sio),e(ls,AB),e(AB,lio),e(ls,iio),e(k,dio),e(k,ah),e(ah,Cse),e(Cse,cio),e(ah,fio),e(ah,wse),e(wse,mio),e(ah,gio),e(k,hio),e(k,is),e(is,Ase),e(Ase,pio),e(is,_io),e(is,LB),e(LB,uio),e(is,bio),e(is,yB),e(yB,vio),e(is,Fio),e(k,Tio),e(k,ds),e(ds,Lse),e(Lse,Mio),e(ds,Eio),e(ds,xB),e(xB,Cio),e(ds,wio),e(ds,$B),e($B,Aio),e(ds,Lio),e(k,yio),e(k,cs),e(cs,yse),e(yse,xio),e(cs,$io),e(cs,kB),e(kB,kio),e(cs,Sio),e(cs,SB),e(SB,Rio),e(cs,Pio),e(k,Bio),e(k,fs),e(fs,xse),e(xse,Iio),e(fs,Nio),e(fs,RB),e(RB,qio),e(fs,jio),e(fs,PB),e(PB,Dio),e(fs,Gio),e(k,Oio),e(k,ms),e(ms,$se),e($se,Vio),e(ms,Xio),e(ms,BB),e(BB,zio),e(ms,Qio),e(ms,IB),e(IB,Wio),e(ms,Hio),e(k,Uio),e(k,gs),e(gs,kse),e(kse,Jio),e(gs,Yio),e(gs,NB),e(NB,Kio),e(gs,Zio),e(gs,qB),e(qB,edo),e(gs,odo),e(k,rdo),e(k,hs),e(hs,Sse),e(Sse,tdo),e(hs,ado),e(hs,jB),e(jB,ndo),e(hs,sdo),e(hs,DB),e(DB,ldo),e(hs,ido),e(k,ddo),e(k,nh),e(nh,Rse),e(Rse,cdo),e(nh,fdo),e(nh,GB),e(GB,mdo),e(nh,gdo),e(k,hdo),e(k,ps),e(ps,Pse),e(Pse,pdo),e(ps,_do),e(ps,OB),e(OB,udo),e(ps,bdo),e(ps,VB),e(VB,vdo),e(ps,Fdo),e(k,Tdo),e(k,sh),e(sh,Bse),e(Bse,Mdo),e(sh,Edo),e(sh,XB),e(XB,Cdo),e(sh,wdo),e(k,Ado),e(k,lh),e(lh,Ise),e(Ise,Ldo),e(lh,ydo),e(lh,zB),e(zB,xdo),e(lh,$do),e(k,kdo),e(k,_s),e(_s,Nse),e(Nse,Sdo),e(_s,Rdo),e(_s,QB),e(QB,Pdo),e(_s,Bdo),e(_s,WB),e(WB,Ido),e(_s,Ndo),e(k,qdo),e(k,us),e(us,qse),e(qse,jdo),e(us,Ddo),e(us,HB),e(HB,Gdo),e(us,Odo),e(us,UB),e(UB,Vdo),e(us,Xdo),e(k,zdo),e(k,bs),e(bs,jse),e(jse,Qdo),e(bs,Wdo),e(bs,JB),e(JB,Hdo),e(bs,Udo),e(bs,YB),e(YB,Jdo),e(bs,Ydo),e(k,Kdo),e(k,ih),e(ih,Dse),e(Dse,Zdo),e(ih,eco),e(ih,KB),e(KB,oco),e(ih,rco),e(k,tco),e(k,vs),e(vs,Gse),e(Gse,aco),e(vs,nco),e(vs,ZB),e(ZB,sco),e(vs,lco),e(vs,eI),e(eI,ico),e(vs,dco),e(k,cco),e(k,Fs),e(Fs,Ose),e(Ose,fco),e(Fs,mco),e(Fs,oI),e(oI,gco),e(Fs,hco),e(Fs,rI),e(rI,pco),e(Fs,_co),e(k,uco),e(k,Ts),e(Ts,Vse),e(Vse,bco),e(Ts,vco),e(Ts,tI),e(tI,Fco),e(Ts,Tco),e(Ts,aI),e(aI,Mco),e(Ts,Eco),e(k,Cco),e(k,Ms),e(Ms,Xse),e(Xse,wco),e(Ms,Aco),e(Ms,nI),e(nI,Lco),e(Ms,yco),e(Ms,sI),e(sI,xco),e(Ms,$co),e(k,kco),e(k,Es),e(Es,zse),e(zse,Sco),e(Es,Rco),e(Es,lI),e(lI,Pco),e(Es,Bco),e(Es,iI),e(iI,Ico),e(Es,Nco),e(k,qco),e(k,Cs),e(Cs,Qse),e(Qse,jco),e(Cs,Dco),e(Cs,dI),e(dI,Gco),e(Cs,Oco),e(Cs,cI),e(cI,Vco),e(Cs,Xco),e(k,zco),e(k,dh),e(dh,Wse),e(Wse,Qco),e(dh,Wco),e(dh,fI),e(fI,Hco),e(dh,Uco),e(k,Jco),e(k,ws),e(ws,Hse),e(Hse,Yco),e(ws,Kco),e(ws,mI),e(mI,Zco),e(ws,efo),e(ws,gI),e(gI,ofo),e(ws,rfo),e(k,tfo),e(k,ch),e(ch,Use),e(Use,afo),e(ch,nfo),e(ch,hI),e(hI,sfo),e(ch,lfo),e(k,ifo),e(k,fh),e(fh,Jse),e(Jse,dfo),e(fh,cfo),e(fh,pI),e(pI,ffo),e(fh,mfo),e(k,gfo),e(k,mh),e(mh,Yse),e(Yse,hfo),e(mh,pfo),e(mh,_I),e(_I,_fo),e(mh,ufo),e(k,bfo),e(k,gh),e(gh,Kse),e(Kse,vfo),e(gh,Ffo),e(gh,uI),e(uI,Tfo),e(gh,Mfo),e(k,Efo),e(k,As),e(As,Zse),e(Zse,Cfo),e(As,wfo),e(As,bI),e(bI,Afo),e(As,Lfo),e(As,vI),e(vI,yfo),e(As,xfo),e(k,$fo),e(k,hh),e(hh,ele),e(ele,kfo),e(hh,Sfo),e(hh,FI),e(FI,Rfo),e(hh,Pfo),e(k,Bfo),e(k,Ls),e(Ls,ole),e(ole,Ifo),e(Ls,Nfo),e(Ls,TI),e(TI,qfo),e(Ls,jfo),e(Ls,MI),e(MI,Dfo),e(Ls,Gfo),e(k,Ofo),e(k,ys),e(ys,rle),e(rle,Vfo),e(ys,Xfo),e(ys,EI),e(EI,zfo),e(ys,Qfo),e(ys,CI),e(CI,Wfo),e(ys,Hfo),e(k,Ufo),e(k,xs),e(xs,tle),e(tle,Jfo),e(xs,Yfo),e(xs,wI),e(wI,Kfo),e(xs,Zfo),e(xs,AI),e(AI,emo),e(xs,omo),e(k,rmo),e(k,$s),e($s,ale),e(ale,tmo),e($s,amo),e($s,LI),e(LI,nmo),e($s,smo),e($s,yI),e(yI,lmo),e($s,imo),e(k,dmo),e(k,ks),e(ks,nle),e(nle,cmo),e(ks,fmo),e(ks,xI),e(xI,mmo),e(ks,gmo),e(ks,$I),e($I,hmo),e(ks,pmo),e(k,_mo),e(k,Ss),e(Ss,sle),e(sle,umo),e(Ss,bmo),e(Ss,kI),e(kI,vmo),e(Ss,Fmo),e(Ss,SI),e(SI,Tmo),e(Ss,Mmo),e(k,Emo),e(k,ph),e(ph,lle),e(lle,Cmo),e(ph,wmo),e(ph,RI),e(RI,Amo),e(ph,Lmo),e(k,ymo),e(k,_h),e(_h,ile),e(ile,xmo),e(_h,$mo),e(_h,PI),e(PI,kmo),e(_h,Smo),e(k,Rmo),e(k,Rs),e(Rs,dle),e(dle,Pmo),e(Rs,Bmo),e(Rs,BI),e(BI,Imo),e(Rs,Nmo),e(Rs,II),e(II,qmo),e(Rs,jmo),e(k,Dmo),e(k,Ps),e(Ps,cle),e(cle,Gmo),e(Ps,Omo),e(Ps,NI),e(NI,Vmo),e(Ps,Xmo),e(Ps,qI),e(qI,zmo),e(Ps,Qmo),e(k,Wmo),e(k,Bs),e(Bs,fle),e(fle,Hmo),e(Bs,Umo),e(Bs,jI),e(jI,Jmo),e(Bs,Ymo),e(Bs,DI),e(DI,Kmo),e(Bs,Zmo),e(k,ego),e(k,uh),e(uh,mle),e(mle,ogo),e(uh,rgo),e(uh,GI),e(GI,tgo),e(uh,ago),e(k,ngo),e(k,bh),e(bh,gle),e(gle,sgo),e(bh,lgo),e(bh,OI),e(OI,igo),e(bh,dgo),e(k,cgo),e(k,vh),e(vh,hle),e(hle,fgo),e(vh,mgo),e(vh,VI),e(VI,ggo),e(vh,hgo),e(k,pgo),e(k,Is),e(Is,ple),e(ple,_go),e(Is,ugo),e(Is,XI),e(XI,bgo),e(Is,vgo),e(Is,zI),e(zI,Fgo),e(Is,Tgo),e(k,Mgo),e(k,Ns),e(Ns,_le),e(_le,Ego),e(Ns,Cgo),e(Ns,QI),e(QI,wgo),e(Ns,Ago),e(Ns,WI),e(WI,Lgo),e(Ns,ygo),e(k,xgo),e(k,Fh),e(Fh,ule),e(ule,$go),e(Fh,kgo),e(Fh,HI),e(HI,Sgo),e(Fh,Rgo),e(k,Pgo),e(k,Th),e(Th,ble),e(ble,Bgo),e(Th,Igo),e(Th,UI),e(UI,Ngo),e(Th,qgo),e(k,jgo),e(k,Mh),e(Mh,vle),e(vle,Dgo),e(Mh,Ggo),e(Mh,JI),e(JI,Ogo),e(Mh,Vgo),e(k,Xgo),e(k,qs),e(qs,Fle),e(Fle,zgo),e(qs,Qgo),e(qs,YI),e(YI,Wgo),e(qs,Hgo),e(qs,KI),e(KI,Ugo),e(qs,Jgo),e(k,Ygo),e(k,Eh),e(Eh,Tle),e(Tle,Kgo),e(Eh,Zgo),e(Eh,ZI),e(ZI,eho),e(Eh,oho),e(k,rho),e(k,Ch),e(Ch,Mle),e(Mle,tho),e(Ch,aho),e(Ch,eN),e(eN,nho),e(Ch,sho),e(k,lho),e(k,js),e(js,Ele),e(Ele,iho),e(js,dho),e(js,oN),e(oN,cho),e(js,fho),e(js,rN),e(rN,mho),e(js,gho),e(k,hho),e(k,Ds),e(Ds,Cle),e(Cle,pho),e(Ds,_ho),e(Ds,tN),e(tN,uho),e(Ds,bho),e(Ds,aN),e(aN,vho),e(Ds,Fho),e(k,Tho),e(k,Gs),e(Gs,wle),e(wle,Mho),e(Gs,Eho),e(Gs,nN),e(nN,Cho),e(Gs,who),e(Gs,sN),e(sN,Aho),e(Gs,Lho),e(k,yho),e(k,Os),e(Os,Ale),e(Ale,xho),e(Os,$ho),e(Os,lN),e(lN,kho),e(Os,Sho),e(Os,iN),e(iN,Rho),e(Os,Pho),e(Lr,Bho),M(wh,Lr,null),e(Ao,Iho),e(Ao,Ah),M(zA,Ah,null),e(Ah,Nho),e(Ah,Lle),e(Lle,qho),b(f,sOe,u),b(f,Si,u),e(Si,Lh),e(Lh,yle),M(QA,yle,null),e(Si,jho),e(Si,xle),e(xle,Dho),b(f,lOe,u),b(f,Lo,u),M(WA,Lo,null),e(Lo,Gho),e(Lo,HA),e(HA,Oho),e(HA,dN),e(dN,Vho),e(HA,Xho),e(Lo,zho),e(Lo,UA),e(UA,Qho),e(UA,$le),e($le,Who),e(UA,Hho),e(Lo,Uho),e(Lo,He),M(JA,He,null),e(He,Jho),e(He,kle),e(kle,Yho),e(He,Kho),e(He,Sa),e(Sa,Zho),e(Sa,Sle),e(Sle,epo),e(Sa,opo),e(Sa,Rle),e(Rle,rpo),e(Sa,tpo),e(Sa,Ple),e(Ple,apo),e(Sa,npo),e(He,spo),e(He,Y),e(Y,yh),e(yh,Ble),e(Ble,lpo),e(yh,ipo),e(yh,cN),e(cN,dpo),e(yh,cpo),e(Y,fpo),e(Y,xh),e(xh,Ile),e(Ile,mpo),e(xh,gpo),e(xh,fN),e(fN,hpo),e(xh,ppo),e(Y,_po),e(Y,$h),e($h,Nle),e(Nle,upo),e($h,bpo),e($h,mN),e(mN,vpo),e($h,Fpo),e(Y,Tpo),e(Y,kh),e(kh,qle),e(qle,Mpo),e(kh,Epo),e(kh,gN),e(gN,Cpo),e(kh,wpo),e(Y,Apo),e(Y,Sh),e(Sh,jle),e(jle,Lpo),e(Sh,ypo),e(Sh,hN),e(hN,xpo),e(Sh,$po),e(Y,kpo),e(Y,Rh),e(Rh,Dle),e(Dle,Spo),e(Rh,Rpo),e(Rh,pN),e(pN,Ppo),e(Rh,Bpo),e(Y,Ipo),e(Y,Ph),e(Ph,Gle),e(Gle,Npo),e(Ph,qpo),e(Ph,_N),e(_N,jpo),e(Ph,Dpo),e(Y,Gpo),e(Y,Bh),e(Bh,Ole),e(Ole,Opo),e(Bh,Vpo),e(Bh,uN),e(uN,Xpo),e(Bh,zpo),e(Y,Qpo),e(Y,Ih),e(Ih,Vle),e(Vle,Wpo),e(Ih,Hpo),e(Ih,bN),e(bN,Upo),e(Ih,Jpo),e(Y,Ypo),e(Y,Nh),e(Nh,Xle),e(Xle,Kpo),e(Nh,Zpo),e(Nh,vN),e(vN,e_o),e(Nh,o_o),e(Y,r_o),e(Y,qh),e(qh,zle),e(zle,t_o),e(qh,a_o),e(qh,FN),e(FN,n_o),e(qh,s_o),e(Y,l_o),e(Y,jh),e(jh,Qle),e(Qle,i_o),e(jh,d_o),e(jh,TN),e(TN,c_o),e(jh,f_o),e(Y,m_o),e(Y,Dh),e(Dh,Wle),e(Wle,g_o),e(Dh,h_o),e(Dh,MN),e(MN,p_o),e(Dh,__o),e(Y,u_o),e(Y,Gh),e(Gh,Hle),e(Hle,b_o),e(Gh,v_o),e(Gh,EN),e(EN,F_o),e(Gh,T_o),e(Y,M_o),e(Y,Oh),e(Oh,Ule),e(Ule,E_o),e(Oh,C_o),e(Oh,CN),e(CN,w_o),e(Oh,A_o),e(Y,L_o),e(Y,Vh),e(Vh,Jle),e(Jle,y_o),e(Vh,x_o),e(Vh,wN),e(wN,$_o),e(Vh,k_o),e(Y,S_o),e(Y,Xh),e(Xh,Yle),e(Yle,R_o),e(Xh,P_o),e(Xh,AN),e(AN,B_o),e(Xh,I_o),e(Y,N_o),e(Y,zh),e(zh,Kle),e(Kle,q_o),e(zh,j_o),e(zh,LN),e(LN,D_o),e(zh,G_o),e(Y,O_o),e(Y,Qh),e(Qh,Zle),e(Zle,V_o),e(Qh,X_o),e(Qh,yN),e(yN,z_o),e(Qh,Q_o),e(Y,W_o),e(Y,Wh),e(Wh,eie),e(eie,H_o),e(Wh,U_o),e(Wh,xN),e(xN,J_o),e(Wh,Y_o),e(Y,K_o),e(Y,Hh),e(Hh,oie),e(oie,Z_o),e(Hh,euo),e(Hh,$N),e($N,ouo),e(Hh,ruo),e(Y,tuo),e(Y,Uh),e(Uh,rie),e(rie,auo),e(Uh,nuo),e(Uh,kN),e(kN,suo),e(Uh,luo),e(Y,iuo),e(Y,Jh),e(Jh,tie),e(tie,duo),e(Jh,cuo),e(Jh,SN),e(SN,fuo),e(Jh,muo),e(Y,guo),e(Y,Yh),e(Yh,aie),e(aie,huo),e(Yh,puo),e(Yh,RN),e(RN,_uo),e(Yh,uuo),e(Y,buo),e(Y,Kh),e(Kh,nie),e(nie,vuo),e(Kh,Fuo),e(Kh,PN),e(PN,Tuo),e(Kh,Muo),e(Y,Euo),e(Y,Zh),e(Zh,sie),e(sie,Cuo),e(Zh,wuo),e(Zh,BN),e(BN,Auo),e(Zh,Luo),e(Y,yuo),e(Y,ep),e(ep,lie),e(lie,xuo),e(ep,$uo),e(ep,IN),e(IN,kuo),e(ep,Suo),e(Y,Ruo),e(Y,op),e(op,iie),e(iie,Puo),e(op,Buo),e(op,NN),e(NN,Iuo),e(op,Nuo),e(Y,quo),e(Y,rp),e(rp,die),e(die,juo),e(rp,Duo),e(rp,qN),e(qN,Guo),e(rp,Ouo),e(Y,Vuo),e(Y,tp),e(tp,cie),e(cie,Xuo),e(tp,zuo),e(tp,jN),e(jN,Quo),e(tp,Wuo),e(Y,Huo),e(Y,ap),e(ap,fie),e(fie,Uuo),e(ap,Juo),e(ap,DN),e(DN,Yuo),e(ap,Kuo),e(Y,Zuo),e(Y,np),e(np,mie),e(mie,e2o),e(np,o2o),e(np,GN),e(GN,r2o),e(np,t2o),e(He,a2o),M(sp,He,null),e(He,n2o),M(lp,He,null),e(Lo,s2o),e(Lo,ip),M(YA,ip,null),e(ip,l2o),e(ip,gie),e(gie,i2o),b(f,iOe,u),b(f,Ri,u),e(Ri,dp),e(dp,hie),M(KA,hie,null),e(Ri,d2o),e(Ri,pie),e(pie,c2o),b(f,dOe,u),b(f,yo,u),M(ZA,yo,null),e(yo,f2o),e(yo,eL),e(eL,m2o),e(eL,ON),e(ON,g2o),e(eL,h2o),e(yo,p2o),e(yo,oL),e(oL,_2o),e(oL,_ie),e(_ie,u2o),e(oL,b2o),e(yo,v2o),e(yo,Ue),M(rL,Ue,null),e(Ue,F2o),e(Ue,uie),e(uie,T2o),e(Ue,M2o),e(Ue,Pi),e(Pi,E2o),e(Pi,bie),e(bie,C2o),e(Pi,w2o),e(Pi,vie),e(vie,A2o),e(Pi,L2o),e(Ue,y2o),e(Ue,he),e(he,cp),e(cp,Fie),e(Fie,x2o),e(cp,$2o),e(cp,VN),e(VN,k2o),e(cp,S2o),e(he,R2o),e(he,fp),e(fp,Tie),e(Tie,P2o),e(fp,B2o),e(fp,Mie),e(Mie,I2o),e(fp,N2o),e(he,q2o),e(he,mp),e(mp,Eie),e(Eie,j2o),e(mp,D2o),e(mp,XN),e(XN,G2o),e(mp,O2o),e(he,V2o),e(he,gp),e(gp,Cie),e(Cie,X2o),e(gp,z2o),e(gp,zN),e(zN,Q2o),e(gp,W2o),e(he,H2o),e(he,hp),e(hp,wie),e(wie,U2o),e(hp,J2o),e(hp,QN),e(QN,Y2o),e(hp,K2o),e(he,Z2o),e(he,pp),e(pp,Aie),e(Aie,e1o),e(pp,o1o),e(pp,WN),e(WN,r1o),e(pp,t1o),e(he,a1o),e(he,_p),e(_p,Lie),e(Lie,n1o),e(_p,s1o),e(_p,HN),e(HN,l1o),e(_p,i1o),e(he,d1o),e(he,up),e(up,yie),e(yie,c1o),e(up,f1o),e(up,UN),e(UN,m1o),e(up,g1o),e(he,h1o),e(he,bp),e(bp,xie),e(xie,p1o),e(bp,_1o),e(bp,JN),e(JN,u1o),e(bp,b1o),e(he,v1o),e(he,vp),e(vp,$ie),e($ie,F1o),e(vp,T1o),e(vp,YN),e(YN,M1o),e(vp,E1o),e(he,C1o),e(he,Fp),e(Fp,kie),e(kie,w1o),e(Fp,A1o),e(Fp,KN),e(KN,L1o),e(Fp,y1o),e(he,x1o),e(he,Tp),e(Tp,Sie),e(Sie,$1o),e(Tp,k1o),e(Tp,ZN),e(ZN,S1o),e(Tp,R1o),e(he,P1o),e(he,Mp),e(Mp,Rie),e(Rie,B1o),e(Mp,I1o),e(Mp,eq),e(eq,N1o),e(Mp,q1o),e(he,j1o),e(he,Ep),e(Ep,Pie),e(Pie,D1o),e(Ep,G1o),e(Ep,oq),e(oq,O1o),e(Ep,V1o),e(he,X1o),e(he,Cp),e(Cp,Bie),e(Bie,z1o),e(Cp,Q1o),e(Cp,rq),e(rq,W1o),e(Cp,H1o),e(he,U1o),e(he,wp),e(wp,Iie),e(Iie,J1o),e(wp,Y1o),e(wp,tq),e(tq,K1o),e(wp,Z1o),e(he,ebo),e(he,Ap),e(Ap,Nie),e(Nie,obo),e(Ap,rbo),e(Ap,aq),e(aq,tbo),e(Ap,abo),e(Ue,nbo),M(Lp,Ue,null),e(Ue,sbo),M(yp,Ue,null),e(yo,lbo),e(yo,xp),M(tL,xp,null),e(xp,ibo),e(xp,qie),e(qie,dbo),b(f,cOe,u),b(f,Bi,u),e(Bi,$p),e($p,jie),M(aL,jie,null),e(Bi,cbo),e(Bi,Die),e(Die,fbo),b(f,fOe,u),b(f,xo,u),M(nL,xo,null),e(xo,mbo),e(xo,Ii),e(Ii,gbo),e(Ii,nq),e(nq,hbo),e(Ii,pbo),e(Ii,sq),e(sq,_bo),e(Ii,ubo),e(xo,bbo),e(xo,sL),e(sL,vbo),e(sL,Gie),e(Gie,Fbo),e(sL,Tbo),e(xo,Mbo),e(xo,nt),M(lL,nt,null),e(nt,Ebo),e(nt,Oie),e(Oie,Cbo),e(nt,wbo),e(nt,Ni),e(Ni,Abo),e(Ni,Vie),e(Vie,Lbo),e(Ni,ybo),e(Ni,lq),e(lq,xbo),e(Ni,$bo),e(nt,kbo),M(kp,nt,null),e(xo,Sbo),e(xo,Je),M(iL,Je,null),e(Je,Rbo),e(Je,Xie),e(Xie,Pbo),e(Je,Bbo),e(Je,Ra),e(Ra,Ibo),e(Ra,zie),e(zie,Nbo),e(Ra,qbo),e(Ra,Qie),e(Qie,jbo),e(Ra,Dbo),e(Ra,Wie),e(Wie,Gbo),e(Ra,Obo),e(Je,Vbo),e(Je,y),e(y,Sp),e(Sp,Hie),e(Hie,Xbo),e(Sp,zbo),e(Sp,iq),e(iq,Qbo),e(Sp,Wbo),e(y,Hbo),e(y,Rp),e(Rp,Uie),e(Uie,Ubo),e(Rp,Jbo),e(Rp,dq),e(dq,Ybo),e(Rp,Kbo),e(y,Zbo),e(y,Pp),e(Pp,Jie),e(Jie,evo),e(Pp,ovo),e(Pp,cq),e(cq,rvo),e(Pp,tvo),e(y,avo),e(y,Bp),e(Bp,Yie),e(Yie,nvo),e(Bp,svo),e(Bp,fq),e(fq,lvo),e(Bp,ivo),e(y,dvo),e(y,Ip),e(Ip,Kie),e(Kie,cvo),e(Ip,fvo),e(Ip,mq),e(mq,mvo),e(Ip,gvo),e(y,hvo),e(y,Np),e(Np,Zie),e(Zie,pvo),e(Np,_vo),e(Np,gq),e(gq,uvo),e(Np,bvo),e(y,vvo),e(y,qp),e(qp,ede),e(ede,Fvo),e(qp,Tvo),e(qp,hq),e(hq,Mvo),e(qp,Evo),e(y,Cvo),e(y,jp),e(jp,ode),e(ode,wvo),e(jp,Avo),e(jp,pq),e(pq,Lvo),e(jp,yvo),e(y,xvo),e(y,Dp),e(Dp,rde),e(rde,$vo),e(Dp,kvo),e(Dp,_q),e(_q,Svo),e(Dp,Rvo),e(y,Pvo),e(y,Gp),e(Gp,tde),e(tde,Bvo),e(Gp,Ivo),e(Gp,uq),e(uq,Nvo),e(Gp,qvo),e(y,jvo),e(y,Op),e(Op,ade),e(ade,Dvo),e(Op,Gvo),e(Op,bq),e(bq,Ovo),e(Op,Vvo),e(y,Xvo),e(y,Vp),e(Vp,nde),e(nde,zvo),e(Vp,Qvo),e(Vp,vq),e(vq,Wvo),e(Vp,Hvo),e(y,Uvo),e(y,Xp),e(Xp,sde),e(sde,Jvo),e(Xp,Yvo),e(Xp,Fq),e(Fq,Kvo),e(Xp,Zvo),e(y,eFo),e(y,zp),e(zp,lde),e(lde,oFo),e(zp,rFo),e(zp,Tq),e(Tq,tFo),e(zp,aFo),e(y,nFo),e(y,Qp),e(Qp,ide),e(ide,sFo),e(Qp,lFo),e(Qp,Mq),e(Mq,iFo),e(Qp,dFo),e(y,cFo),e(y,Wp),e(Wp,dde),e(dde,fFo),e(Wp,mFo),e(Wp,Eq),e(Eq,gFo),e(Wp,hFo),e(y,pFo),e(y,Hp),e(Hp,cde),e(cde,_Fo),e(Hp,uFo),e(Hp,Cq),e(Cq,bFo),e(Hp,vFo),e(y,FFo),e(y,Up),e(Up,fde),e(fde,TFo),e(Up,MFo),e(Up,wq),e(wq,EFo),e(Up,CFo),e(y,wFo),e(y,Jp),e(Jp,mde),e(mde,AFo),e(Jp,LFo),e(Jp,Aq),e(Aq,yFo),e(Jp,xFo),e(y,$Fo),e(y,Yp),e(Yp,gde),e(gde,kFo),e(Yp,SFo),e(Yp,Lq),e(Lq,RFo),e(Yp,PFo),e(y,BFo),e(y,Kp),e(Kp,hde),e(hde,IFo),e(Kp,NFo),e(Kp,yq),e(yq,qFo),e(Kp,jFo),e(y,DFo),e(y,Zp),e(Zp,pde),e(pde,GFo),e(Zp,OFo),e(Zp,xq),e(xq,VFo),e(Zp,XFo),e(y,zFo),e(y,e_),e(e_,_de),e(_de,QFo),e(e_,WFo),e(e_,$q),e($q,HFo),e(e_,UFo),e(y,JFo),e(y,o_),e(o_,ude),e(ude,YFo),e(o_,KFo),e(o_,kq),e(kq,ZFo),e(o_,e6o),e(y,o6o),e(y,r_),e(r_,bde),e(bde,r6o),e(r_,t6o),e(r_,Sq),e(Sq,a6o),e(r_,n6o),e(y,s6o),e(y,t_),e(t_,vde),e(vde,l6o),e(t_,i6o),e(t_,Rq),e(Rq,d6o),e(t_,c6o),e(y,f6o),e(y,a_),e(a_,Fde),e(Fde,m6o),e(a_,g6o),e(a_,Pq),e(Pq,h6o),e(a_,p6o),e(y,_6o),e(y,n_),e(n_,Tde),e(Tde,u6o),e(n_,b6o),e(n_,Bq),e(Bq,v6o),e(n_,F6o),e(y,T6o),e(y,s_),e(s_,Mde),e(Mde,M6o),e(s_,E6o),e(s_,Iq),e(Iq,C6o),e(s_,w6o),e(y,A6o),e(y,l_),e(l_,Ede),e(Ede,L6o),e(l_,y6o),e(l_,Nq),e(Nq,x6o),e(l_,$6o),e(y,k6o),e(y,i_),e(i_,Cde),e(Cde,S6o),e(i_,R6o),e(i_,qq),e(qq,P6o),e(i_,B6o),e(y,I6o),e(y,d_),e(d_,wde),e(wde,N6o),e(d_,q6o),e(d_,jq),e(jq,j6o),e(d_,D6o),e(y,G6o),e(y,c_),e(c_,Ade),e(Ade,O6o),e(c_,V6o),e(c_,Dq),e(Dq,X6o),e(c_,z6o),e(y,Q6o),e(y,Vs),e(Vs,Lde),e(Lde,W6o),e(Vs,H6o),e(Vs,Gq),e(Gq,U6o),e(Vs,J6o),e(Vs,Oq),e(Oq,Y6o),e(Vs,K6o),e(y,Z6o),e(y,f_),e(f_,yde),e(yde,eTo),e(f_,oTo),e(f_,Vq),e(Vq,rTo),e(f_,tTo),e(y,aTo),e(y,m_),e(m_,xde),e(xde,nTo),e(m_,sTo),e(m_,Xq),e(Xq,lTo),e(m_,iTo),e(y,dTo),e(y,g_),e(g_,$de),e($de,cTo),e(g_,fTo),e(g_,zq),e(zq,mTo),e(g_,gTo),e(y,hTo),e(y,h_),e(h_,kde),e(kde,pTo),e(h_,_To),e(h_,Qq),e(Qq,uTo),e(h_,bTo),e(y,vTo),e(y,p_),e(p_,Sde),e(Sde,FTo),e(p_,TTo),e(p_,Wq),e(Wq,MTo),e(p_,ETo),e(y,CTo),e(y,__),e(__,Rde),e(Rde,wTo),e(__,ATo),e(__,Hq),e(Hq,LTo),e(__,yTo),e(y,xTo),e(y,u_),e(u_,Pde),e(Pde,$To),e(u_,kTo),e(u_,Uq),e(Uq,STo),e(u_,RTo),e(y,PTo),e(y,b_),e(b_,Bde),e(Bde,BTo),e(b_,ITo),e(b_,Jq),e(Jq,NTo),e(b_,qTo),e(y,jTo),e(y,v_),e(v_,Ide),e(Ide,DTo),e(v_,GTo),e(v_,Nde),e(Nde,OTo),e(v_,VTo),e(y,XTo),e(y,F_),e(F_,qde),e(qde,zTo),e(F_,QTo),e(F_,Yq),e(Yq,WTo),e(F_,HTo),e(y,UTo),e(y,T_),e(T_,jde),e(jde,JTo),e(T_,YTo),e(T_,Kq),e(Kq,KTo),e(T_,ZTo),e(y,e7o),e(y,M_),e(M_,Dde),e(Dde,o7o),e(M_,r7o),e(M_,Zq),e(Zq,t7o),e(M_,a7o),e(y,n7o),e(y,E_),e(E_,Gde),e(Gde,s7o),e(E_,l7o),e(E_,ej),e(ej,i7o),e(E_,d7o),e(y,c7o),e(y,C_),e(C_,Ode),e(Ode,f7o),e(C_,m7o),e(C_,oj),e(oj,g7o),e(C_,h7o),e(y,p7o),e(y,w_),e(w_,Vde),e(Vde,_7o),e(w_,u7o),e(w_,rj),e(rj,b7o),e(w_,v7o),e(y,F7o),e(y,A_),e(A_,Xde),e(Xde,T7o),e(A_,M7o),e(A_,tj),e(tj,E7o),e(A_,C7o),e(y,w7o),e(y,L_),e(L_,zde),e(zde,A7o),e(L_,L7o),e(L_,aj),e(aj,y7o),e(L_,x7o),e(y,$7o),e(y,y_),e(y_,Qde),e(Qde,k7o),e(y_,S7o),e(y_,nj),e(nj,R7o),e(y_,P7o),e(y,B7o),e(y,x_),e(x_,Wde),e(Wde,I7o),e(x_,N7o),e(x_,sj),e(sj,q7o),e(x_,j7o),e(y,D7o),e(y,$_),e($_,Hde),e(Hde,G7o),e($_,O7o),e($_,lj),e(lj,V7o),e($_,X7o),e(y,z7o),e(y,k_),e(k_,Ude),e(Ude,Q7o),e(k_,W7o),e(k_,ij),e(ij,H7o),e(k_,U7o),e(y,J7o),e(y,S_),e(S_,Jde),e(Jde,Y7o),e(S_,K7o),e(S_,dj),e(dj,Z7o),e(S_,e8o),e(y,o8o),e(y,R_),e(R_,Yde),e(Yde,r8o),e(R_,t8o),e(R_,cj),e(cj,a8o),e(R_,n8o),e(y,s8o),e(y,P_),e(P_,Kde),e(Kde,l8o),e(P_,i8o),e(P_,fj),e(fj,d8o),e(P_,c8o),e(y,f8o),e(y,B_),e(B_,Zde),e(Zde,m8o),e(B_,g8o),e(B_,mj),e(mj,h8o),e(B_,p8o),e(y,_8o),e(y,I_),e(I_,ece),e(ece,u8o),e(I_,b8o),e(I_,gj),e(gj,v8o),e(I_,F8o),e(y,T8o),e(y,N_),e(N_,oce),e(oce,M8o),e(N_,E8o),e(N_,hj),e(hj,C8o),e(N_,w8o),e(y,A8o),e(y,q_),e(q_,rce),e(rce,L8o),e(q_,y8o),e(q_,pj),e(pj,x8o),e(q_,$8o),e(y,k8o),e(y,j_),e(j_,tce),e(tce,S8o),e(j_,R8o),e(j_,_j),e(_j,P8o),e(j_,B8o),e(y,I8o),e(y,D_),e(D_,ace),e(ace,N8o),e(D_,q8o),e(D_,uj),e(uj,j8o),e(D_,D8o),e(y,G8o),e(y,G_),e(G_,nce),e(nce,O8o),e(G_,V8o),e(G_,bj),e(bj,X8o),e(G_,z8o),e(y,Q8o),e(y,O_),e(O_,sce),e(sce,W8o),e(O_,H8o),e(O_,vj),e(vj,U8o),e(O_,J8o),e(y,Y8o),e(y,V_),e(V_,lce),e(lce,K8o),e(V_,Z8o),e(V_,Fj),e(Fj,eMo),e(V_,oMo),e(y,rMo),e(y,X_),e(X_,ice),e(ice,tMo),e(X_,aMo),e(X_,Tj),e(Tj,nMo),e(X_,sMo),e(y,lMo),e(y,z_),e(z_,dce),e(dce,iMo),e(z_,dMo),e(z_,Mj),e(Mj,cMo),e(z_,fMo),e(y,mMo),e(y,Q_),e(Q_,cce),e(cce,gMo),e(Q_,hMo),e(Q_,Ej),e(Ej,pMo),e(Q_,_Mo),e(y,uMo),e(y,W_),e(W_,fce),e(fce,bMo),e(W_,vMo),e(W_,Cj),e(Cj,FMo),e(W_,TMo),e(y,MMo),e(y,H_),e(H_,mce),e(mce,EMo),e(H_,CMo),e(H_,wj),e(wj,wMo),e(H_,AMo),e(y,LMo),e(y,U_),e(U_,gce),e(gce,yMo),e(U_,xMo),e(U_,Aj),e(Aj,$Mo),e(U_,kMo),e(y,SMo),e(y,J_),e(J_,hce),e(hce,RMo),e(J_,PMo),e(J_,Lj),e(Lj,BMo),e(J_,IMo),e(y,NMo),e(y,Y_),e(Y_,pce),e(pce,qMo),e(Y_,jMo),e(Y_,yj),e(yj,DMo),e(Y_,GMo),e(y,OMo),e(y,K_),e(K_,_ce),e(_ce,VMo),e(K_,XMo),e(K_,xj),e(xj,zMo),e(K_,QMo),e(y,WMo),e(y,Z_),e(Z_,uce),e(uce,HMo),e(Z_,UMo),e(Z_,$j),e($j,JMo),e(Z_,YMo),e(y,KMo),e(y,eu),e(eu,bce),e(bce,ZMo),e(eu,eEo),e(eu,kj),e(kj,oEo),e(eu,rEo),e(y,tEo),e(y,ou),e(ou,vce),e(vce,aEo),e(ou,nEo),e(ou,Sj),e(Sj,sEo),e(ou,lEo),e(y,iEo),e(y,ru),e(ru,Fce),e(Fce,dEo),e(ru,cEo),e(ru,Rj),e(Rj,fEo),e(ru,mEo),e(y,gEo),e(y,tu),e(tu,Tce),e(Tce,hEo),e(tu,pEo),e(tu,Pj),e(Pj,_Eo),e(tu,uEo),e(y,bEo),e(y,au),e(au,Mce),e(Mce,vEo),e(au,FEo),e(au,Bj),e(Bj,TEo),e(au,MEo),e(y,EEo),e(y,nu),e(nu,Ece),e(Ece,CEo),e(nu,wEo),e(nu,Ij),e(Ij,AEo),e(nu,LEo),e(y,yEo),e(y,su),e(su,Cce),e(Cce,xEo),e(su,$Eo),e(su,Nj),e(Nj,kEo),e(su,SEo),e(y,REo),e(y,lu),e(lu,wce),e(wce,PEo),e(lu,BEo),e(lu,qj),e(qj,IEo),e(lu,NEo),e(y,qEo),e(y,iu),e(iu,Ace),e(Ace,jEo),e(iu,DEo),e(iu,jj),e(jj,GEo),e(iu,OEo),e(y,VEo),e(y,du),e(du,Lce),e(Lce,XEo),e(du,zEo),e(du,Dj),e(Dj,QEo),e(du,WEo),e(y,HEo),e(y,cu),e(cu,yce),e(yce,UEo),e(cu,JEo),e(cu,Gj),e(Gj,YEo),e(cu,KEo),e(y,ZEo),e(y,fu),e(fu,xce),e(xce,e4o),e(fu,o4o),e(fu,Oj),e(Oj,r4o),e(fu,t4o),e(y,a4o),e(y,mu),e(mu,$ce),e($ce,n4o),e(mu,s4o),e(mu,Vj),e(Vj,l4o),e(mu,i4o),e(y,d4o),e(y,gu),e(gu,kce),e(kce,c4o),e(gu,f4o),e(gu,Xj),e(Xj,m4o),e(gu,g4o),e(y,h4o),e(y,hu),e(hu,Sce),e(Sce,p4o),e(hu,_4o),e(hu,zj),e(zj,u4o),e(hu,b4o),e(y,v4o),e(y,pu),e(pu,Rce),e(Rce,F4o),e(pu,T4o),e(pu,Qj),e(Qj,M4o),e(pu,E4o),e(y,C4o),e(y,_u),e(_u,Pce),e(Pce,w4o),e(_u,A4o),e(_u,Wj),e(Wj,L4o),e(_u,y4o),e(y,x4o),e(y,uu),e(uu,Bce),e(Bce,$4o),e(uu,k4o),e(uu,Hj),e(Hj,S4o),e(uu,R4o),e(y,P4o),e(y,bu),e(bu,Ice),e(Ice,B4o),e(bu,I4o),e(bu,Uj),e(Uj,N4o),e(bu,q4o),e(y,j4o),e(y,vu),e(vu,Nce),e(Nce,D4o),e(vu,G4o),e(vu,Jj),e(Jj,O4o),e(vu,V4o),e(y,X4o),e(y,Fu),e(Fu,qce),e(qce,z4o),e(Fu,Q4o),e(Fu,Yj),e(Yj,W4o),e(Fu,H4o),e(y,U4o),e(y,Tu),e(Tu,jce),e(jce,J4o),e(Tu,Y4o),e(Tu,Kj),e(Kj,K4o),e(Tu,Z4o),e(y,eCo),e(y,Mu),e(Mu,Dce),e(Dce,oCo),e(Mu,rCo),e(Mu,Zj),e(Zj,tCo),e(Mu,aCo),e(y,nCo),e(y,Eu),e(Eu,Gce),e(Gce,sCo),e(Eu,lCo),e(Eu,eD),e(eD,iCo),e(Eu,dCo),e(y,cCo),e(y,Cu),e(Cu,Oce),e(Oce,fCo),e(Cu,mCo),e(Cu,oD),e(oD,gCo),e(Cu,hCo),e(y,pCo),e(y,wu),e(wu,Vce),e(Vce,_Co),e(wu,uCo),e(wu,rD),e(rD,bCo),e(wu,vCo),e(y,FCo),e(y,Au),e(Au,Xce),e(Xce,TCo),e(Au,MCo),e(Au,tD),e(tD,ECo),e(Au,CCo),e(y,wCo),e(y,Lu),e(Lu,zce),e(zce,ACo),e(Lu,LCo),e(Lu,aD),e(aD,yCo),e(Lu,xCo),e(y,$Co),e(y,yu),e(yu,Qce),e(Qce,kCo),e(yu,SCo),e(yu,nD),e(nD,RCo),e(yu,PCo),e(y,BCo),e(y,xu),e(xu,Wce),e(Wce,ICo),e(xu,NCo),e(xu,sD),e(sD,qCo),e(xu,jCo),e(y,DCo),e(y,$u),e($u,Hce),e(Hce,GCo),e($u,OCo),e($u,lD),e(lD,VCo),e($u,XCo),e(Je,zCo),e(Je,ku),e(ku,QCo),e(ku,Uce),e(Uce,WCo),e(ku,HCo),e(ku,Jce),e(Jce,UCo),e(Je,JCo),M(Su,Je,null),b(f,mOe,u),b(f,qi,u),e(qi,Ru),e(Ru,Yce),M(dL,Yce,null),e(qi,YCo),e(qi,Kce),e(Kce,KCo),b(f,gOe,u),b(f,$o,u),M(cL,$o,null),e($o,ZCo),e($o,ji),e(ji,e5o),e(ji,iD),e(iD,o5o),e(ji,r5o),e(ji,dD),e(dD,t5o),e(ji,a5o),e($o,n5o),e($o,fL),e(fL,s5o),e(fL,Zce),e(Zce,l5o),e(fL,i5o),e($o,d5o),e($o,st),M(mL,st,null),e(st,c5o),e(st,efe),e(efe,f5o),e(st,m5o),e(st,Di),e(Di,g5o),e(Di,ofe),e(ofe,h5o),e(Di,p5o),e(Di,cD),e(cD,_5o),e(Di,u5o),e(st,b5o),M(Pu,st,null),e($o,v5o),e($o,Ye),M(gL,Ye,null),e(Ye,F5o),e(Ye,rfe),e(rfe,T5o),e(Ye,M5o),e(Ye,Pa),e(Pa,E5o),e(Pa,tfe),e(tfe,C5o),e(Pa,w5o),e(Pa,afe),e(afe,A5o),e(Pa,L5o),e(Pa,nfe),e(nfe,y5o),e(Pa,x5o),e(Ye,$5o),e(Ye,G),e(G,Bu),e(Bu,sfe),e(sfe,k5o),e(Bu,S5o),e(Bu,fD),e(fD,R5o),e(Bu,P5o),e(G,B5o),e(G,Iu),e(Iu,lfe),e(lfe,I5o),e(Iu,N5o),e(Iu,mD),e(mD,q5o),e(Iu,j5o),e(G,D5o),e(G,Nu),e(Nu,ife),e(ife,G5o),e(Nu,O5o),e(Nu,gD),e(gD,V5o),e(Nu,X5o),e(G,z5o),e(G,qu),e(qu,dfe),e(dfe,Q5o),e(qu,W5o),e(qu,hD),e(hD,H5o),e(qu,U5o),e(G,J5o),e(G,ju),e(ju,cfe),e(cfe,Y5o),e(ju,K5o),e(ju,pD),e(pD,Z5o),e(ju,e3o),e(G,o3o),e(G,Du),e(Du,ffe),e(ffe,r3o),e(Du,t3o),e(Du,_D),e(_D,a3o),e(Du,n3o),e(G,s3o),e(G,Gu),e(Gu,mfe),e(mfe,l3o),e(Gu,i3o),e(Gu,uD),e(uD,d3o),e(Gu,c3o),e(G,f3o),e(G,Ou),e(Ou,gfe),e(gfe,m3o),e(Ou,g3o),e(Ou,bD),e(bD,h3o),e(Ou,p3o),e(G,_3o),e(G,Vu),e(Vu,hfe),e(hfe,u3o),e(Vu,b3o),e(Vu,vD),e(vD,v3o),e(Vu,F3o),e(G,T3o),e(G,Xu),e(Xu,pfe),e(pfe,M3o),e(Xu,E3o),e(Xu,FD),e(FD,C3o),e(Xu,w3o),e(G,A3o),e(G,zu),e(zu,_fe),e(_fe,L3o),e(zu,y3o),e(zu,TD),e(TD,x3o),e(zu,$3o),e(G,k3o),e(G,Qu),e(Qu,ufe),e(ufe,S3o),e(Qu,R3o),e(Qu,MD),e(MD,P3o),e(Qu,B3o),e(G,I3o),e(G,Wu),e(Wu,bfe),e(bfe,N3o),e(Wu,q3o),e(Wu,ED),e(ED,j3o),e(Wu,D3o),e(G,G3o),e(G,Hu),e(Hu,vfe),e(vfe,O3o),e(Hu,V3o),e(Hu,CD),e(CD,X3o),e(Hu,z3o),e(G,Q3o),e(G,Uu),e(Uu,Ffe),e(Ffe,W3o),e(Uu,H3o),e(Uu,wD),e(wD,U3o),e(Uu,J3o),e(G,Y3o),e(G,Ju),e(Ju,Tfe),e(Tfe,K3o),e(Ju,Z3o),e(Ju,AD),e(AD,e0o),e(Ju,o0o),e(G,r0o),e(G,Yu),e(Yu,Mfe),e(Mfe,t0o),e(Yu,a0o),e(Yu,LD),e(LD,n0o),e(Yu,s0o),e(G,l0o),e(G,Ku),e(Ku,Efe),e(Efe,i0o),e(Ku,d0o),e(Ku,yD),e(yD,c0o),e(Ku,f0o),e(G,m0o),e(G,Zu),e(Zu,Cfe),e(Cfe,g0o),e(Zu,h0o),e(Zu,xD),e(xD,p0o),e(Zu,_0o),e(G,u0o),e(G,e2),e(e2,wfe),e(wfe,b0o),e(e2,v0o),e(e2,$D),e($D,F0o),e(e2,T0o),e(G,M0o),e(G,o2),e(o2,Afe),e(Afe,E0o),e(o2,C0o),e(o2,kD),e(kD,w0o),e(o2,A0o),e(G,L0o),e(G,r2),e(r2,Lfe),e(Lfe,y0o),e(r2,x0o),e(r2,SD),e(SD,$0o),e(r2,k0o),e(G,S0o),e(G,t2),e(t2,yfe),e(yfe,R0o),e(t2,P0o),e(t2,RD),e(RD,B0o),e(t2,I0o),e(G,N0o),e(G,a2),e(a2,xfe),e(xfe,q0o),e(a2,j0o),e(a2,PD),e(PD,D0o),e(a2,G0o),e(G,O0o),e(G,n2),e(n2,$fe),e($fe,V0o),e(n2,X0o),e(n2,BD),e(BD,z0o),e(n2,Q0o),e(G,W0o),e(G,s2),e(s2,kfe),e(kfe,H0o),e(s2,U0o),e(s2,ID),e(ID,J0o),e(s2,Y0o),e(G,K0o),e(G,l2),e(l2,Sfe),e(Sfe,Z0o),e(l2,ewo),e(l2,ND),e(ND,owo),e(l2,rwo),e(G,two),e(G,i2),e(i2,Rfe),e(Rfe,awo),e(i2,nwo),e(i2,qD),e(qD,swo),e(i2,lwo),e(G,iwo),e(G,d2),e(d2,Pfe),e(Pfe,dwo),e(d2,cwo),e(d2,jD),e(jD,fwo),e(d2,mwo),e(G,gwo),e(G,c2),e(c2,Bfe),e(Bfe,hwo),e(c2,pwo),e(c2,DD),e(DD,_wo),e(c2,uwo),e(G,bwo),e(G,f2),e(f2,Ife),e(Ife,vwo),e(f2,Fwo),e(f2,GD),e(GD,Two),e(f2,Mwo),e(G,Ewo),e(G,m2),e(m2,Nfe),e(Nfe,Cwo),e(m2,wwo),e(m2,OD),e(OD,Awo),e(m2,Lwo),e(G,ywo),e(G,g2),e(g2,qfe),e(qfe,xwo),e(g2,$wo),e(g2,VD),e(VD,kwo),e(g2,Swo),e(G,Rwo),e(G,h2),e(h2,jfe),e(jfe,Pwo),e(h2,Bwo),e(h2,XD),e(XD,Iwo),e(h2,Nwo),e(G,qwo),e(G,p2),e(p2,Dfe),e(Dfe,jwo),e(p2,Dwo),e(p2,zD),e(zD,Gwo),e(p2,Owo),e(G,Vwo),e(G,_2),e(_2,Gfe),e(Gfe,Xwo),e(_2,zwo),e(_2,QD),e(QD,Qwo),e(_2,Wwo),e(G,Hwo),e(G,u2),e(u2,Ofe),e(Ofe,Uwo),e(u2,Jwo),e(u2,WD),e(WD,Ywo),e(u2,Kwo),e(G,Zwo),e(G,b2),e(b2,Vfe),e(Vfe,eAo),e(b2,oAo),e(b2,HD),e(HD,rAo),e(b2,tAo),e(G,aAo),e(G,v2),e(v2,Xfe),e(Xfe,nAo),e(v2,sAo),e(v2,UD),e(UD,lAo),e(v2,iAo),e(G,dAo),e(G,F2),e(F2,zfe),e(zfe,cAo),e(F2,fAo),e(F2,JD),e(JD,mAo),e(F2,gAo),e(G,hAo),e(G,T2),e(T2,Qfe),e(Qfe,pAo),e(T2,_Ao),e(T2,YD),e(YD,uAo),e(T2,bAo),e(G,vAo),e(G,M2),e(M2,Wfe),e(Wfe,FAo),e(M2,TAo),e(M2,KD),e(KD,MAo),e(M2,EAo),e(G,CAo),e(G,E2),e(E2,Hfe),e(Hfe,wAo),e(E2,AAo),e(E2,ZD),e(ZD,LAo),e(E2,yAo),e(G,xAo),e(G,C2),e(C2,Ufe),e(Ufe,$Ao),e(C2,kAo),e(C2,eG),e(eG,SAo),e(C2,RAo),e(Ye,PAo),e(Ye,w2),e(w2,BAo),e(w2,Jfe),e(Jfe,IAo),e(w2,NAo),e(w2,Yfe),e(Yfe,qAo),e(Ye,jAo),M(A2,Ye,null),b(f,hOe,u),b(f,Gi,u),e(Gi,L2),e(L2,Kfe),M(hL,Kfe,null),e(Gi,DAo),e(Gi,Zfe),e(Zfe,GAo),b(f,pOe,u),b(f,ko,u),M(pL,ko,null),e(ko,OAo),e(ko,Oi),e(Oi,VAo),e(Oi,oG),e(oG,XAo),e(Oi,zAo),e(Oi,rG),e(rG,QAo),e(Oi,WAo),e(ko,HAo),e(ko,_L),e(_L,UAo),e(_L,eme),e(eme,JAo),e(_L,YAo),e(ko,KAo),e(ko,lt),M(uL,lt,null),e(lt,ZAo),e(lt,ome),e(ome,eLo),e(lt,oLo),e(lt,Vi),e(Vi,rLo),e(Vi,rme),e(rme,tLo),e(Vi,aLo),e(Vi,tG),e(tG,nLo),e(Vi,sLo),e(lt,lLo),M(y2,lt,null),e(ko,iLo),e(ko,Ke),M(bL,Ke,null),e(Ke,dLo),e(Ke,tme),e(tme,cLo),e(Ke,fLo),e(Ke,Ba),e(Ba,mLo),e(Ba,ame),e(ame,gLo),e(Ba,hLo),e(Ba,nme),e(nme,pLo),e(Ba,_Lo),e(Ba,sme),e(sme,uLo),e(Ba,bLo),e(Ke,vLo),e(Ke,z),e(z,x2),e(x2,lme),e(lme,FLo),e(x2,TLo),e(x2,aG),e(aG,MLo),e(x2,ELo),e(z,CLo),e(z,$2),e($2,ime),e(ime,wLo),e($2,ALo),e($2,nG),e(nG,LLo),e($2,yLo),e(z,xLo),e(z,k2),e(k2,dme),e(dme,$Lo),e(k2,kLo),e(k2,sG),e(sG,SLo),e(k2,RLo),e(z,PLo),e(z,S2),e(S2,cme),e(cme,BLo),e(S2,ILo),e(S2,lG),e(lG,NLo),e(S2,qLo),e(z,jLo),e(z,R2),e(R2,fme),e(fme,DLo),e(R2,GLo),e(R2,iG),e(iG,OLo),e(R2,VLo),e(z,XLo),e(z,P2),e(P2,mme),e(mme,zLo),e(P2,QLo),e(P2,dG),e(dG,WLo),e(P2,HLo),e(z,ULo),e(z,B2),e(B2,gme),e(gme,JLo),e(B2,YLo),e(B2,cG),e(cG,KLo),e(B2,ZLo),e(z,eyo),e(z,I2),e(I2,hme),e(hme,oyo),e(I2,ryo),e(I2,fG),e(fG,tyo),e(I2,ayo),e(z,nyo),e(z,N2),e(N2,pme),e(pme,syo),e(N2,lyo),e(N2,mG),e(mG,iyo),e(N2,dyo),e(z,cyo),e(z,q2),e(q2,_me),e(_me,fyo),e(q2,myo),e(q2,gG),e(gG,gyo),e(q2,hyo),e(z,pyo),e(z,j2),e(j2,ume),e(ume,_yo),e(j2,uyo),e(j2,hG),e(hG,byo),e(j2,vyo),e(z,Fyo),e(z,D2),e(D2,bme),e(bme,Tyo),e(D2,Myo),e(D2,pG),e(pG,Eyo),e(D2,Cyo),e(z,wyo),e(z,G2),e(G2,vme),e(vme,Ayo),e(G2,Lyo),e(G2,_G),e(_G,yyo),e(G2,xyo),e(z,$yo),e(z,O2),e(O2,Fme),e(Fme,kyo),e(O2,Syo),e(O2,uG),e(uG,Ryo),e(O2,Pyo),e(z,Byo),e(z,V2),e(V2,Tme),e(Tme,Iyo),e(V2,Nyo),e(V2,bG),e(bG,qyo),e(V2,jyo),e(z,Dyo),e(z,X2),e(X2,Mme),e(Mme,Gyo),e(X2,Oyo),e(X2,vG),e(vG,Vyo),e(X2,Xyo),e(z,zyo),e(z,z2),e(z2,Eme),e(Eme,Qyo),e(z2,Wyo),e(z2,FG),e(FG,Hyo),e(z2,Uyo),e(z,Jyo),e(z,Q2),e(Q2,Cme),e(Cme,Yyo),e(Q2,Kyo),e(Q2,TG),e(TG,Zyo),e(Q2,e9o),e(z,o9o),e(z,W2),e(W2,wme),e(wme,r9o),e(W2,t9o),e(W2,MG),e(MG,a9o),e(W2,n9o),e(z,s9o),e(z,H2),e(H2,Ame),e(Ame,l9o),e(H2,i9o),e(H2,EG),e(EG,d9o),e(H2,c9o),e(z,f9o),e(z,U2),e(U2,Lme),e(Lme,m9o),e(U2,g9o),e(U2,CG),e(CG,h9o),e(U2,p9o),e(z,_9o),e(z,J2),e(J2,yme),e(yme,u9o),e(J2,b9o),e(J2,wG),e(wG,v9o),e(J2,F9o),e(z,T9o),e(z,Y2),e(Y2,xme),e(xme,M9o),e(Y2,E9o),e(Y2,AG),e(AG,C9o),e(Y2,w9o),e(z,A9o),e(z,K2),e(K2,$me),e($me,L9o),e(K2,y9o),e(K2,LG),e(LG,x9o),e(K2,$9o),e(z,k9o),e(z,Z2),e(Z2,kme),e(kme,S9o),e(Z2,R9o),e(Z2,yG),e(yG,P9o),e(Z2,B9o),e(z,I9o),e(z,e1),e(e1,Sme),e(Sme,N9o),e(e1,q9o),e(e1,xG),e(xG,j9o),e(e1,D9o),e(z,G9o),e(z,o1),e(o1,Rme),e(Rme,O9o),e(o1,V9o),e(o1,$G),e($G,X9o),e(o1,z9o),e(z,Q9o),e(z,r1),e(r1,Pme),e(Pme,W9o),e(r1,H9o),e(r1,kG),e(kG,U9o),e(r1,J9o),e(z,Y9o),e(z,t1),e(t1,Bme),e(Bme,K9o),e(t1,Z9o),e(t1,SG),e(SG,exo),e(t1,oxo),e(z,rxo),e(z,a1),e(a1,Ime),e(Ime,txo),e(a1,axo),e(a1,RG),e(RG,nxo),e(a1,sxo),e(z,lxo),e(z,n1),e(n1,Nme),e(Nme,ixo),e(n1,dxo),e(n1,PG),e(PG,cxo),e(n1,fxo),e(z,mxo),e(z,s1),e(s1,qme),e(qme,gxo),e(s1,hxo),e(s1,BG),e(BG,pxo),e(s1,_xo),e(z,uxo),e(z,l1),e(l1,jme),e(jme,bxo),e(l1,vxo),e(l1,IG),e(IG,Fxo),e(l1,Txo),e(z,Mxo),e(z,i1),e(i1,Dme),e(Dme,Exo),e(i1,Cxo),e(i1,NG),e(NG,wxo),e(i1,Axo),e(z,Lxo),e(z,d1),e(d1,Gme),e(Gme,yxo),e(d1,xxo),e(d1,qG),e(qG,$xo),e(d1,kxo),e(z,Sxo),e(z,c1),e(c1,Ome),e(Ome,Rxo),e(c1,Pxo),e(c1,jG),e(jG,Bxo),e(c1,Ixo),e(z,Nxo),e(z,f1),e(f1,Vme),e(Vme,qxo),e(f1,jxo),e(f1,DG),e(DG,Dxo),e(f1,Gxo),e(z,Oxo),e(z,m1),e(m1,Xme),e(Xme,Vxo),e(m1,Xxo),e(m1,GG),e(GG,zxo),e(m1,Qxo),e(Ke,Wxo),e(Ke,g1),e(g1,Hxo),e(g1,zme),e(zme,Uxo),e(g1,Jxo),e(g1,Qme),e(Qme,Yxo),e(Ke,Kxo),M(h1,Ke,null),b(f,_Oe,u),b(f,Xi,u),e(Xi,p1),e(p1,Wme),M(vL,Wme,null),e(Xi,Zxo),e(Xi,Hme),e(Hme,e$o),b(f,uOe,u),b(f,So,u),M(FL,So,null),e(So,o$o),e(So,zi),e(zi,r$o),e(zi,OG),e(OG,t$o),e(zi,a$o),e(zi,VG),e(VG,n$o),e(zi,s$o),e(So,l$o),e(So,TL),e(TL,i$o),e(TL,Ume),e(Ume,d$o),e(TL,c$o),e(So,f$o),e(So,it),M(ML,it,null),e(it,m$o),e(it,Jme),e(Jme,g$o),e(it,h$o),e(it,Qi),e(Qi,p$o),e(Qi,Yme),e(Yme,_$o),e(Qi,u$o),e(Qi,XG),e(XG,b$o),e(Qi,v$o),e(it,F$o),M(_1,it,null),e(So,T$o),e(So,Ze),M(EL,Ze,null),e(Ze,M$o),e(Ze,Kme),e(Kme,E$o),e(Ze,C$o),e(Ze,Ia),e(Ia,w$o),e(Ia,Zme),e(Zme,A$o),e(Ia,L$o),e(Ia,ege),e(ege,y$o),e(Ia,x$o),e(Ia,oge),e(oge,$$o),e(Ia,k$o),e(Ze,S$o),e(Ze,Q),e(Q,u1),e(u1,rge),e(rge,R$o),e(u1,P$o),e(u1,zG),e(zG,B$o),e(u1,I$o),e(Q,N$o),e(Q,b1),e(b1,tge),e(tge,q$o),e(b1,j$o),e(b1,QG),e(QG,D$o),e(b1,G$o),e(Q,O$o),e(Q,v1),e(v1,age),e(age,V$o),e(v1,X$o),e(v1,WG),e(WG,z$o),e(v1,Q$o),e(Q,W$o),e(Q,F1),e(F1,nge),e(nge,H$o),e(F1,U$o),e(F1,HG),e(HG,J$o),e(F1,Y$o),e(Q,K$o),e(Q,T1),e(T1,sge),e(sge,Z$o),e(T1,eko),e(T1,UG),e(UG,oko),e(T1,rko),e(Q,tko),e(Q,M1),e(M1,lge),e(lge,ako),e(M1,nko),e(M1,JG),e(JG,sko),e(M1,lko),e(Q,iko),e(Q,E1),e(E1,ige),e(ige,dko),e(E1,cko),e(E1,YG),e(YG,fko),e(E1,mko),e(Q,gko),e(Q,C1),e(C1,dge),e(dge,hko),e(C1,pko),e(C1,KG),e(KG,_ko),e(C1,uko),e(Q,bko),e(Q,w1),e(w1,cge),e(cge,vko),e(w1,Fko),e(w1,ZG),e(ZG,Tko),e(w1,Mko),e(Q,Eko),e(Q,A1),e(A1,fge),e(fge,Cko),e(A1,wko),e(A1,eO),e(eO,Ako),e(A1,Lko),e(Q,yko),e(Q,L1),e(L1,mge),e(mge,xko),e(L1,$ko),e(L1,oO),e(oO,kko),e(L1,Sko),e(Q,Rko),e(Q,y1),e(y1,gge),e(gge,Pko),e(y1,Bko),e(y1,rO),e(rO,Iko),e(y1,Nko),e(Q,qko),e(Q,x1),e(x1,hge),e(hge,jko),e(x1,Dko),e(x1,tO),e(tO,Gko),e(x1,Oko),e(Q,Vko),e(Q,$1),e($1,pge),e(pge,Xko),e($1,zko),e($1,aO),e(aO,Qko),e($1,Wko),e(Q,Hko),e(Q,k1),e(k1,_ge),e(_ge,Uko),e(k1,Jko),e(k1,nO),e(nO,Yko),e(k1,Kko),e(Q,Zko),e(Q,S1),e(S1,uge),e(uge,eSo),e(S1,oSo),e(S1,sO),e(sO,rSo),e(S1,tSo),e(Q,aSo),e(Q,R1),e(R1,bge),e(bge,nSo),e(R1,sSo),e(R1,lO),e(lO,lSo),e(R1,iSo),e(Q,dSo),e(Q,P1),e(P1,vge),e(vge,cSo),e(P1,fSo),e(P1,iO),e(iO,mSo),e(P1,gSo),e(Q,hSo),e(Q,B1),e(B1,Fge),e(Fge,pSo),e(B1,_So),e(B1,dO),e(dO,uSo),e(B1,bSo),e(Q,vSo),e(Q,I1),e(I1,Tge),e(Tge,FSo),e(I1,TSo),e(I1,cO),e(cO,MSo),e(I1,ESo),e(Q,CSo),e(Q,N1),e(N1,Mge),e(Mge,wSo),e(N1,ASo),e(N1,fO),e(fO,LSo),e(N1,ySo),e(Q,xSo),e(Q,q1),e(q1,Ege),e(Ege,$So),e(q1,kSo),e(q1,mO),e(mO,SSo),e(q1,RSo),e(Q,PSo),e(Q,j1),e(j1,Cge),e(Cge,BSo),e(j1,ISo),e(j1,gO),e(gO,NSo),e(j1,qSo),e(Q,jSo),e(Q,D1),e(D1,wge),e(wge,DSo),e(D1,GSo),e(D1,hO),e(hO,OSo),e(D1,VSo),e(Q,XSo),e(Q,G1),e(G1,Age),e(Age,zSo),e(G1,QSo),e(G1,pO),e(pO,WSo),e(G1,HSo),e(Q,USo),e(Q,O1),e(O1,Lge),e(Lge,JSo),e(O1,YSo),e(O1,_O),e(_O,KSo),e(O1,ZSo),e(Q,eRo),e(Q,V1),e(V1,yge),e(yge,oRo),e(V1,rRo),e(V1,uO),e(uO,tRo),e(V1,aRo),e(Q,nRo),e(Q,X1),e(X1,xge),e(xge,sRo),e(X1,lRo),e(X1,bO),e(bO,iRo),e(X1,dRo),e(Q,cRo),e(Q,z1),e(z1,$ge),e($ge,fRo),e(z1,mRo),e(z1,vO),e(vO,gRo),e(z1,hRo),e(Q,pRo),e(Q,Q1),e(Q1,kge),e(kge,_Ro),e(Q1,uRo),e(Q1,FO),e(FO,bRo),e(Q1,vRo),e(Q,FRo),e(Q,W1),e(W1,Sge),e(Sge,TRo),e(W1,MRo),e(W1,TO),e(TO,ERo),e(W1,CRo),e(Q,wRo),e(Q,H1),e(H1,Rge),e(Rge,ARo),e(H1,LRo),e(H1,MO),e(MO,yRo),e(H1,xRo),e(Q,$Ro),e(Q,U1),e(U1,Pge),e(Pge,kRo),e(U1,SRo),e(U1,Bge),e(Bge,RRo),e(U1,PRo),e(Q,BRo),e(Q,J1),e(J1,Ige),e(Ige,IRo),e(J1,NRo),e(J1,EO),e(EO,qRo),e(J1,jRo),e(Q,DRo),e(Q,Y1),e(Y1,Nge),e(Nge,GRo),e(Y1,ORo),e(Y1,CO),e(CO,VRo),e(Y1,XRo),e(Q,zRo),e(Q,K1),e(K1,qge),e(qge,QRo),e(K1,WRo),e(K1,wO),e(wO,HRo),e(K1,URo),e(Q,JRo),e(Q,Z1),e(Z1,jge),e(jge,YRo),e(Z1,KRo),e(Z1,AO),e(AO,ZRo),e(Z1,ePo),e(Ze,oPo),e(Ze,eb),e(eb,rPo),e(eb,Dge),e(Dge,tPo),e(eb,aPo),e(eb,Gge),e(Gge,nPo),e(Ze,sPo),M(ob,Ze,null),b(f,bOe,u),b(f,Wi,u),e(Wi,rb),e(rb,Oge),M(CL,Oge,null),e(Wi,lPo),e(Wi,Vge),e(Vge,iPo),b(f,vOe,u),b(f,Ro,u),M(wL,Ro,null),e(Ro,dPo),e(Ro,Hi),e(Hi,cPo),e(Hi,LO),e(LO,fPo),e(Hi,mPo),e(Hi,yO),e(yO,gPo),e(Hi,hPo),e(Ro,pPo),e(Ro,AL),e(AL,_Po),e(AL,Xge),e(Xge,uPo),e(AL,bPo),e(Ro,vPo),e(Ro,dt),M(LL,dt,null),e(dt,FPo),e(dt,zge),e(zge,TPo),e(dt,MPo),e(dt,Ui),e(Ui,EPo),e(Ui,Qge),e(Qge,CPo),e(Ui,wPo),e(Ui,xO),e(xO,APo),e(Ui,LPo),e(dt,yPo),M(tb,dt,null),e(Ro,xPo),e(Ro,eo),M(yL,eo,null),e(eo,$Po),e(eo,Wge),e(Wge,kPo),e(eo,SPo),e(eo,Na),e(Na,RPo),e(Na,Hge),e(Hge,PPo),e(Na,BPo),e(Na,Uge),e(Uge,IPo),e(Na,NPo),e(Na,Jge),e(Jge,qPo),e(Na,jPo),e(eo,DPo),e(eo,pe),e(pe,ab),e(ab,Yge),e(Yge,GPo),e(ab,OPo),e(ab,$O),e($O,VPo),e(ab,XPo),e(pe,zPo),e(pe,nb),e(nb,Kge),e(Kge,QPo),e(nb,WPo),e(nb,kO),e(kO,HPo),e(nb,UPo),e(pe,JPo),e(pe,sb),e(sb,Zge),e(Zge,YPo),e(sb,KPo),e(sb,SO),e(SO,ZPo),e(sb,eBo),e(pe,oBo),e(pe,lb),e(lb,ehe),e(ehe,rBo),e(lb,tBo),e(lb,RO),e(RO,aBo),e(lb,nBo),e(pe,sBo),e(pe,ib),e(ib,ohe),e(ohe,lBo),e(ib,iBo),e(ib,PO),e(PO,dBo),e(ib,cBo),e(pe,fBo),e(pe,db),e(db,rhe),e(rhe,mBo),e(db,gBo),e(db,BO),e(BO,hBo),e(db,pBo),e(pe,_Bo),e(pe,cb),e(cb,the),e(the,uBo),e(cb,bBo),e(cb,IO),e(IO,vBo),e(cb,FBo),e(pe,TBo),e(pe,fb),e(fb,ahe),e(ahe,MBo),e(fb,EBo),e(fb,NO),e(NO,CBo),e(fb,wBo),e(pe,ABo),e(pe,mb),e(mb,nhe),e(nhe,LBo),e(mb,yBo),e(mb,qO),e(qO,xBo),e(mb,$Bo),e(pe,kBo),e(pe,gb),e(gb,she),e(she,SBo),e(gb,RBo),e(gb,jO),e(jO,PBo),e(gb,BBo),e(pe,IBo),e(pe,hb),e(hb,lhe),e(lhe,NBo),e(hb,qBo),e(hb,DO),e(DO,jBo),e(hb,DBo),e(pe,GBo),e(pe,pb),e(pb,ihe),e(ihe,OBo),e(pb,VBo),e(pb,GO),e(GO,XBo),e(pb,zBo),e(pe,QBo),e(pe,_b),e(_b,dhe),e(dhe,WBo),e(_b,HBo),e(_b,OO),e(OO,UBo),e(_b,JBo),e(pe,YBo),e(pe,ub),e(ub,che),e(che,KBo),e(ub,ZBo),e(ub,VO),e(VO,eIo),e(ub,oIo),e(pe,rIo),e(pe,bb),e(bb,fhe),e(fhe,tIo),e(bb,aIo),e(bb,XO),e(XO,nIo),e(bb,sIo),e(pe,lIo),e(pe,vb),e(vb,mhe),e(mhe,iIo),e(vb,dIo),e(vb,zO),e(zO,cIo),e(vb,fIo),e(pe,mIo),e(pe,Fb),e(Fb,ghe),e(ghe,gIo),e(Fb,hIo),e(Fb,QO),e(QO,pIo),e(Fb,_Io),e(eo,uIo),e(eo,Tb),e(Tb,bIo),e(Tb,hhe),e(hhe,vIo),e(Tb,FIo),e(Tb,phe),e(phe,TIo),e(eo,MIo),M(Mb,eo,null),b(f,FOe,u),b(f,Ji,u),e(Ji,Eb),e(Eb,_he),M(xL,_he,null),e(Ji,EIo),e(Ji,uhe),e(uhe,CIo),b(f,TOe,u),b(f,Po,u),M($L,Po,null),e(Po,wIo),e(Po,Yi),e(Yi,AIo),e(Yi,WO),e(WO,LIo),e(Yi,yIo),e(Yi,HO),e(HO,xIo),e(Yi,$Io),e(Po,kIo),e(Po,kL),e(kL,SIo),e(kL,bhe),e(bhe,RIo),e(kL,PIo),e(Po,BIo),e(Po,ct),M(SL,ct,null),e(ct,IIo),e(ct,vhe),e(vhe,NIo),e(ct,qIo),e(ct,Ki),e(Ki,jIo),e(Ki,Fhe),e(Fhe,DIo),e(Ki,GIo),e(Ki,UO),e(UO,OIo),e(Ki,VIo),e(ct,XIo),M(Cb,ct,null),e(Po,zIo),e(Po,oo),M(RL,oo,null),e(oo,QIo),e(oo,The),e(The,WIo),e(oo,HIo),e(oo,qa),e(qa,UIo),e(qa,Mhe),e(Mhe,JIo),e(qa,YIo),e(qa,Ehe),e(Ehe,KIo),e(qa,ZIo),e(qa,Che),e(Che,eNo),e(qa,oNo),e(oo,rNo),e(oo,N),e(N,wb),e(wb,whe),e(whe,tNo),e(wb,aNo),e(wb,JO),e(JO,nNo),e(wb,sNo),e(N,lNo),e(N,Ab),e(Ab,Ahe),e(Ahe,iNo),e(Ab,dNo),e(Ab,YO),e(YO,cNo),e(Ab,fNo),e(N,mNo),e(N,Lb),e(Lb,Lhe),e(Lhe,gNo),e(Lb,hNo),e(Lb,KO),e(KO,pNo),e(Lb,_No),e(N,uNo),e(N,yb),e(yb,yhe),e(yhe,bNo),e(yb,vNo),e(yb,ZO),e(ZO,FNo),e(yb,TNo),e(N,MNo),e(N,xb),e(xb,xhe),e(xhe,ENo),e(xb,CNo),e(xb,eV),e(eV,wNo),e(xb,ANo),e(N,LNo),e(N,$b),e($b,$he),e($he,yNo),e($b,xNo),e($b,oV),e(oV,$No),e($b,kNo),e(N,SNo),e(N,kb),e(kb,khe),e(khe,RNo),e(kb,PNo),e(kb,rV),e(rV,BNo),e(kb,INo),e(N,NNo),e(N,Sb),e(Sb,She),e(She,qNo),e(Sb,jNo),e(Sb,tV),e(tV,DNo),e(Sb,GNo),e(N,ONo),e(N,Rb),e(Rb,Rhe),e(Rhe,VNo),e(Rb,XNo),e(Rb,aV),e(aV,zNo),e(Rb,QNo),e(N,WNo),e(N,Pb),e(Pb,Phe),e(Phe,HNo),e(Pb,UNo),e(Pb,nV),e(nV,JNo),e(Pb,YNo),e(N,KNo),e(N,Bb),e(Bb,Bhe),e(Bhe,ZNo),e(Bb,eqo),e(Bb,sV),e(sV,oqo),e(Bb,rqo),e(N,tqo),e(N,Ib),e(Ib,Ihe),e(Ihe,aqo),e(Ib,nqo),e(Ib,lV),e(lV,sqo),e(Ib,lqo),e(N,iqo),e(N,Nb),e(Nb,Nhe),e(Nhe,dqo),e(Nb,cqo),e(Nb,iV),e(iV,fqo),e(Nb,mqo),e(N,gqo),e(N,qb),e(qb,qhe),e(qhe,hqo),e(qb,pqo),e(qb,dV),e(dV,_qo),e(qb,uqo),e(N,bqo),e(N,jb),e(jb,jhe),e(jhe,vqo),e(jb,Fqo),e(jb,cV),e(cV,Tqo),e(jb,Mqo),e(N,Eqo),e(N,Db),e(Db,Dhe),e(Dhe,Cqo),e(Db,wqo),e(Db,fV),e(fV,Aqo),e(Db,Lqo),e(N,yqo),e(N,Gb),e(Gb,Ghe),e(Ghe,xqo),e(Gb,$qo),e(Gb,mV),e(mV,kqo),e(Gb,Sqo),e(N,Rqo),e(N,Ob),e(Ob,Ohe),e(Ohe,Pqo),e(Ob,Bqo),e(Ob,gV),e(gV,Iqo),e(Ob,Nqo),e(N,qqo),e(N,Vb),e(Vb,Vhe),e(Vhe,jqo),e(Vb,Dqo),e(Vb,hV),e(hV,Gqo),e(Vb,Oqo),e(N,Vqo),e(N,Xb),e(Xb,Xhe),e(Xhe,Xqo),e(Xb,zqo),e(Xb,pV),e(pV,Qqo),e(Xb,Wqo),e(N,Hqo),e(N,zb),e(zb,zhe),e(zhe,Uqo),e(zb,Jqo),e(zb,_V),e(_V,Yqo),e(zb,Kqo),e(N,Zqo),e(N,Qb),e(Qb,Qhe),e(Qhe,ejo),e(Qb,ojo),e(Qb,uV),e(uV,rjo),e(Qb,tjo),e(N,ajo),e(N,Wb),e(Wb,Whe),e(Whe,njo),e(Wb,sjo),e(Wb,bV),e(bV,ljo),e(Wb,ijo),e(N,djo),e(N,Hb),e(Hb,Hhe),e(Hhe,cjo),e(Hb,fjo),e(Hb,vV),e(vV,mjo),e(Hb,gjo),e(N,hjo),e(N,Ub),e(Ub,Uhe),e(Uhe,pjo),e(Ub,_jo),e(Ub,FV),e(FV,ujo),e(Ub,bjo),e(N,vjo),e(N,Jb),e(Jb,Jhe),e(Jhe,Fjo),e(Jb,Tjo),e(Jb,TV),e(TV,Mjo),e(Jb,Ejo),e(N,Cjo),e(N,Yb),e(Yb,Yhe),e(Yhe,wjo),e(Yb,Ajo),e(Yb,MV),e(MV,Ljo),e(Yb,yjo),e(N,xjo),e(N,Kb),e(Kb,Khe),e(Khe,$jo),e(Kb,kjo),e(Kb,EV),e(EV,Sjo),e(Kb,Rjo),e(N,Pjo),e(N,Zb),e(Zb,Zhe),e(Zhe,Bjo),e(Zb,Ijo),e(Zb,CV),e(CV,Njo),e(Zb,qjo),e(N,jjo),e(N,ev),e(ev,epe),e(epe,Djo),e(ev,Gjo),e(ev,wV),e(wV,Ojo),e(ev,Vjo),e(N,Xjo),e(N,ov),e(ov,ope),e(ope,zjo),e(ov,Qjo),e(ov,AV),e(AV,Wjo),e(ov,Hjo),e(N,Ujo),e(N,rv),e(rv,rpe),e(rpe,Jjo),e(rv,Yjo),e(rv,LV),e(LV,Kjo),e(rv,Zjo),e(N,eDo),e(N,tv),e(tv,tpe),e(tpe,oDo),e(tv,rDo),e(tv,yV),e(yV,tDo),e(tv,aDo),e(N,nDo),e(N,av),e(av,ape),e(ape,sDo),e(av,lDo),e(av,xV),e(xV,iDo),e(av,dDo),e(N,cDo),e(N,nv),e(nv,npe),e(npe,fDo),e(nv,mDo),e(nv,$V),e($V,gDo),e(nv,hDo),e(N,pDo),e(N,sv),e(sv,spe),e(spe,_Do),e(sv,uDo),e(sv,kV),e(kV,bDo),e(sv,vDo),e(N,FDo),e(N,lv),e(lv,lpe),e(lpe,TDo),e(lv,MDo),e(lv,SV),e(SV,EDo),e(lv,CDo),e(N,wDo),e(N,iv),e(iv,ipe),e(ipe,ADo),e(iv,LDo),e(iv,RV),e(RV,yDo),e(iv,xDo),e(N,$Do),e(N,dv),e(dv,dpe),e(dpe,kDo),e(dv,SDo),e(dv,PV),e(PV,RDo),e(dv,PDo),e(N,BDo),e(N,cv),e(cv,cpe),e(cpe,IDo),e(cv,NDo),e(cv,BV),e(BV,qDo),e(cv,jDo),e(N,DDo),e(N,fv),e(fv,fpe),e(fpe,GDo),e(fv,ODo),e(fv,IV),e(IV,VDo),e(fv,XDo),e(N,zDo),e(N,mv),e(mv,mpe),e(mpe,QDo),e(mv,WDo),e(mv,NV),e(NV,HDo),e(mv,UDo),e(N,JDo),e(N,gv),e(gv,gpe),e(gpe,YDo),e(gv,KDo),e(gv,qV),e(qV,ZDo),e(gv,eGo),e(N,oGo),e(N,hv),e(hv,hpe),e(hpe,rGo),e(hv,tGo),e(hv,jV),e(jV,aGo),e(hv,nGo),e(N,sGo),e(N,pv),e(pv,ppe),e(ppe,lGo),e(pv,iGo),e(pv,DV),e(DV,dGo),e(pv,cGo),e(N,fGo),e(N,_v),e(_v,_pe),e(_pe,mGo),e(_v,gGo),e(_v,GV),e(GV,hGo),e(_v,pGo),e(N,_Go),e(N,uv),e(uv,upe),e(upe,uGo),e(uv,bGo),e(uv,OV),e(OV,vGo),e(uv,FGo),e(N,TGo),e(N,bv),e(bv,bpe),e(bpe,MGo),e(bv,EGo),e(bv,VV),e(VV,CGo),e(bv,wGo),e(N,AGo),e(N,vv),e(vv,vpe),e(vpe,LGo),e(vv,yGo),e(vv,XV),e(XV,xGo),e(vv,$Go),e(oo,kGo),e(oo,Fv),e(Fv,SGo),e(Fv,Fpe),e(Fpe,RGo),e(Fv,PGo),e(Fv,Tpe),e(Tpe,BGo),e(oo,IGo),M(Tv,oo,null),b(f,MOe,u),b(f,Zi,u),e(Zi,Mv),e(Mv,Mpe),M(PL,Mpe,null),e(Zi,NGo),e(Zi,Epe),e(Epe,qGo),b(f,EOe,u),b(f,Bo,u),M(BL,Bo,null),e(Bo,jGo),e(Bo,ed),e(ed,DGo),e(ed,zV),e(zV,GGo),e(ed,OGo),e(ed,QV),e(QV,VGo),e(ed,XGo),e(Bo,zGo),e(Bo,IL),e(IL,QGo),e(IL,Cpe),e(Cpe,WGo),e(IL,HGo),e(Bo,UGo),e(Bo,ft),M(NL,ft,null),e(ft,JGo),e(ft,wpe),e(wpe,YGo),e(ft,KGo),e(ft,od),e(od,ZGo),e(od,Ape),e(Ape,eOo),e(od,oOo),e(od,WV),e(WV,rOo),e(od,tOo),e(ft,aOo),M(Ev,ft,null),e(Bo,nOo),e(Bo,ro),M(qL,ro,null),e(ro,sOo),e(ro,Lpe),e(Lpe,lOo),e(ro,iOo),e(ro,ja),e(ja,dOo),e(ja,ype),e(ype,cOo),e(ja,fOo),e(ja,xpe),e(xpe,mOo),e(ja,gOo),e(ja,$pe),e($pe,hOo),e(ja,pOo),e(ro,_Oo),e(ro,Z),e(Z,Cv),e(Cv,kpe),e(kpe,uOo),e(Cv,bOo),e(Cv,HV),e(HV,vOo),e(Cv,FOo),e(Z,TOo),e(Z,wv),e(wv,Spe),e(Spe,MOo),e(wv,EOo),e(wv,UV),e(UV,COo),e(wv,wOo),e(Z,AOo),e(Z,Av),e(Av,Rpe),e(Rpe,LOo),e(Av,yOo),e(Av,JV),e(JV,xOo),e(Av,$Oo),e(Z,kOo),e(Z,Lv),e(Lv,Ppe),e(Ppe,SOo),e(Lv,ROo),e(Lv,YV),e(YV,POo),e(Lv,BOo),e(Z,IOo),e(Z,yv),e(yv,Bpe),e(Bpe,NOo),e(yv,qOo),e(yv,KV),e(KV,jOo),e(yv,DOo),e(Z,GOo),e(Z,xv),e(xv,Ipe),e(Ipe,OOo),e(xv,VOo),e(xv,ZV),e(ZV,XOo),e(xv,zOo),e(Z,QOo),e(Z,$v),e($v,Npe),e(Npe,WOo),e($v,HOo),e($v,eX),e(eX,UOo),e($v,JOo),e(Z,YOo),e(Z,kv),e(kv,qpe),e(qpe,KOo),e(kv,ZOo),e(kv,oX),e(oX,eVo),e(kv,oVo),e(Z,rVo),e(Z,Sv),e(Sv,jpe),e(jpe,tVo),e(Sv,aVo),e(Sv,rX),e(rX,nVo),e(Sv,sVo),e(Z,lVo),e(Z,Rv),e(Rv,Dpe),e(Dpe,iVo),e(Rv,dVo),e(Rv,tX),e(tX,cVo),e(Rv,fVo),e(Z,mVo),e(Z,Pv),e(Pv,Gpe),e(Gpe,gVo),e(Pv,hVo),e(Pv,aX),e(aX,pVo),e(Pv,_Vo),e(Z,uVo),e(Z,Bv),e(Bv,Ope),e(Ope,bVo),e(Bv,vVo),e(Bv,nX),e(nX,FVo),e(Bv,TVo),e(Z,MVo),e(Z,Iv),e(Iv,Vpe),e(Vpe,EVo),e(Iv,CVo),e(Iv,sX),e(sX,wVo),e(Iv,AVo),e(Z,LVo),e(Z,Nv),e(Nv,Xpe),e(Xpe,yVo),e(Nv,xVo),e(Nv,lX),e(lX,$Vo),e(Nv,kVo),e(Z,SVo),e(Z,qv),e(qv,zpe),e(zpe,RVo),e(qv,PVo),e(qv,iX),e(iX,BVo),e(qv,IVo),e(Z,NVo),e(Z,jv),e(jv,Qpe),e(Qpe,qVo),e(jv,jVo),e(jv,dX),e(dX,DVo),e(jv,GVo),e(Z,OVo),e(Z,Dv),e(Dv,Wpe),e(Wpe,VVo),e(Dv,XVo),e(Dv,cX),e(cX,zVo),e(Dv,QVo),e(Z,WVo),e(Z,Gv),e(Gv,Hpe),e(Hpe,HVo),e(Gv,UVo),e(Gv,fX),e(fX,JVo),e(Gv,YVo),e(Z,KVo),e(Z,Ov),e(Ov,Upe),e(Upe,ZVo),e(Ov,eXo),e(Ov,mX),e(mX,oXo),e(Ov,rXo),e(Z,tXo),e(Z,Vv),e(Vv,Jpe),e(Jpe,aXo),e(Vv,nXo),e(Vv,gX),e(gX,sXo),e(Vv,lXo),e(Z,iXo),e(Z,Xv),e(Xv,Ype),e(Ype,dXo),e(Xv,cXo),e(Xv,hX),e(hX,fXo),e(Xv,mXo),e(Z,gXo),e(Z,zv),e(zv,Kpe),e(Kpe,hXo),e(zv,pXo),e(zv,pX),e(pX,_Xo),e(zv,uXo),e(Z,bXo),e(Z,Qv),e(Qv,Zpe),e(Zpe,vXo),e(Qv,FXo),e(Qv,_X),e(_X,TXo),e(Qv,MXo),e(Z,EXo),e(Z,Wv),e(Wv,e_e),e(e_e,CXo),e(Wv,wXo),e(Wv,uX),e(uX,AXo),e(Wv,LXo),e(Z,yXo),e(Z,Hv),e(Hv,o_e),e(o_e,xXo),e(Hv,$Xo),e(Hv,bX),e(bX,kXo),e(Hv,SXo),e(Z,RXo),e(Z,Uv),e(Uv,r_e),e(r_e,PXo),e(Uv,BXo),e(Uv,vX),e(vX,IXo),e(Uv,NXo),e(Z,qXo),e(Z,Jv),e(Jv,t_e),e(t_e,jXo),e(Jv,DXo),e(Jv,FX),e(FX,GXo),e(Jv,OXo),e(Z,VXo),e(Z,Yv),e(Yv,a_e),e(a_e,XXo),e(Yv,zXo),e(Yv,TX),e(TX,QXo),e(Yv,WXo),e(Z,HXo),e(Z,Kv),e(Kv,n_e),e(n_e,UXo),e(Kv,JXo),e(Kv,MX),e(MX,YXo),e(Kv,KXo),e(Z,ZXo),e(Z,Zv),e(Zv,s_e),e(s_e,ezo),e(Zv,ozo),e(Zv,EX),e(EX,rzo),e(Zv,tzo),e(ro,azo),e(ro,eF),e(eF,nzo),e(eF,l_e),e(l_e,szo),e(eF,lzo),e(eF,i_e),e(i_e,izo),e(ro,dzo),M(oF,ro,null),b(f,COe,u),b(f,rd,u),e(rd,rF),e(rF,d_e),M(jL,d_e,null),e(rd,czo),e(rd,c_e),e(c_e,fzo),b(f,wOe,u),b(f,Io,u),M(DL,Io,null),e(Io,mzo),e(Io,td),e(td,gzo),e(td,CX),e(CX,hzo),e(td,pzo),e(td,wX),e(wX,_zo),e(td,uzo),e(Io,bzo),e(Io,GL),e(GL,vzo),e(GL,f_e),e(f_e,Fzo),e(GL,Tzo),e(Io,Mzo),e(Io,mt),M(OL,mt,null),e(mt,Ezo),e(mt,m_e),e(m_e,Czo),e(mt,wzo),e(mt,ad),e(ad,Azo),e(ad,g_e),e(g_e,Lzo),e(ad,yzo),e(ad,AX),e(AX,xzo),e(ad,$zo),e(mt,kzo),M(tF,mt,null),e(Io,Szo),e(Io,to),M(VL,to,null),e(to,Rzo),e(to,h_e),e(h_e,Pzo),e(to,Bzo),e(to,Da),e(Da,Izo),e(Da,p_e),e(p_e,Nzo),e(Da,qzo),e(Da,__e),e(__e,jzo),e(Da,Dzo),e(Da,u_e),e(u_e,Gzo),e(Da,Ozo),e(to,Vzo),e(to,No),e(No,aF),e(aF,b_e),e(b_e,Xzo),e(aF,zzo),e(aF,LX),e(LX,Qzo),e(aF,Wzo),e(No,Hzo),e(No,nF),e(nF,v_e),e(v_e,Uzo),e(nF,Jzo),e(nF,yX),e(yX,Yzo),e(nF,Kzo),e(No,Zzo),e(No,sF),e(sF,F_e),e(F_e,eQo),e(sF,oQo),e(sF,xX),e(xX,rQo),e(sF,tQo),e(No,aQo),e(No,lF),e(lF,T_e),e(T_e,nQo),e(lF,sQo),e(lF,$X),e($X,lQo),e(lF,iQo),e(No,dQo),e(No,iF),e(iF,M_e),e(M_e,cQo),e(iF,fQo),e(iF,kX),e(kX,mQo),e(iF,gQo),e(No,hQo),e(No,dF),e(dF,E_e),e(E_e,pQo),e(dF,_Qo),e(dF,SX),e(SX,uQo),e(dF,bQo),e(to,vQo),e(to,cF),e(cF,FQo),e(cF,C_e),e(C_e,TQo),e(cF,MQo),e(cF,w_e),e(w_e,EQo),e(to,CQo),M(fF,to,null),b(f,AOe,u),b(f,nd,u),e(nd,mF),e(mF,A_e),M(XL,A_e,null),e(nd,wQo),e(nd,L_e),e(L_e,AQo),b(f,LOe,u),b(f,qo,u),M(zL,qo,null),e(qo,LQo),e(qo,sd),e(sd,yQo),e(sd,RX),e(RX,xQo),e(sd,$Qo),e(sd,PX),e(PX,kQo),e(sd,SQo),e(qo,RQo),e(qo,QL),e(QL,PQo),e(QL,y_e),e(y_e,BQo),e(QL,IQo),e(qo,NQo),e(qo,gt),M(WL,gt,null),e(gt,qQo),e(gt,x_e),e(x_e,jQo),e(gt,DQo),e(gt,ld),e(ld,GQo),e(ld,$_e),e($_e,OQo),e(ld,VQo),e(ld,BX),e(BX,XQo),e(ld,zQo),e(gt,QQo),M(gF,gt,null),e(qo,WQo),e(qo,ao),M(HL,ao,null),e(ao,HQo),e(ao,k_e),e(k_e,UQo),e(ao,JQo),e(ao,Ga),e(Ga,YQo),e(Ga,S_e),e(S_e,KQo),e(Ga,ZQo),e(Ga,R_e),e(R_e,eWo),e(Ga,oWo),e(Ga,P_e),e(P_e,rWo),e(Ga,tWo),e(ao,aWo),e(ao,H),e(H,hF),e(hF,B_e),e(B_e,nWo),e(hF,sWo),e(hF,IX),e(IX,lWo),e(hF,iWo),e(H,dWo),e(H,pF),e(pF,I_e),e(I_e,cWo),e(pF,fWo),e(pF,NX),e(NX,mWo),e(pF,gWo),e(H,hWo),e(H,_F),e(_F,N_e),e(N_e,pWo),e(_F,_Wo),e(_F,qX),e(qX,uWo),e(_F,bWo),e(H,vWo),e(H,uF),e(uF,q_e),e(q_e,FWo),e(uF,TWo),e(uF,jX),e(jX,MWo),e(uF,EWo),e(H,CWo),e(H,bF),e(bF,j_e),e(j_e,wWo),e(bF,AWo),e(bF,DX),e(DX,LWo),e(bF,yWo),e(H,xWo),e(H,vF),e(vF,D_e),e(D_e,$Wo),e(vF,kWo),e(vF,GX),e(GX,SWo),e(vF,RWo),e(H,PWo),e(H,FF),e(FF,G_e),e(G_e,BWo),e(FF,IWo),e(FF,OX),e(OX,NWo),e(FF,qWo),e(H,jWo),e(H,TF),e(TF,O_e),e(O_e,DWo),e(TF,GWo),e(TF,VX),e(VX,OWo),e(TF,VWo),e(H,XWo),e(H,MF),e(MF,V_e),e(V_e,zWo),e(MF,QWo),e(MF,XX),e(XX,WWo),e(MF,HWo),e(H,UWo),e(H,EF),e(EF,X_e),e(X_e,JWo),e(EF,YWo),e(EF,zX),e(zX,KWo),e(EF,ZWo),e(H,eHo),e(H,CF),e(CF,z_e),e(z_e,oHo),e(CF,rHo),e(CF,QX),e(QX,tHo),e(CF,aHo),e(H,nHo),e(H,wF),e(wF,Q_e),e(Q_e,sHo),e(wF,lHo),e(wF,WX),e(WX,iHo),e(wF,dHo),e(H,cHo),e(H,AF),e(AF,W_e),e(W_e,fHo),e(AF,mHo),e(AF,HX),e(HX,gHo),e(AF,hHo),e(H,pHo),e(H,LF),e(LF,H_e),e(H_e,_Ho),e(LF,uHo),e(LF,UX),e(UX,bHo),e(LF,vHo),e(H,FHo),e(H,yF),e(yF,U_e),e(U_e,THo),e(yF,MHo),e(yF,JX),e(JX,EHo),e(yF,CHo),e(H,wHo),e(H,xF),e(xF,J_e),e(J_e,AHo),e(xF,LHo),e(xF,YX),e(YX,yHo),e(xF,xHo),e(H,$Ho),e(H,$F),e($F,Y_e),e(Y_e,kHo),e($F,SHo),e($F,KX),e(KX,RHo),e($F,PHo),e(H,BHo),e(H,kF),e(kF,K_e),e(K_e,IHo),e(kF,NHo),e(kF,ZX),e(ZX,qHo),e(kF,jHo),e(H,DHo),e(H,SF),e(SF,Z_e),e(Z_e,GHo),e(SF,OHo),e(SF,ez),e(ez,VHo),e(SF,XHo),e(H,zHo),e(H,RF),e(RF,eue),e(eue,QHo),e(RF,WHo),e(RF,oz),e(oz,HHo),e(RF,UHo),e(H,JHo),e(H,PF),e(PF,oue),e(oue,YHo),e(PF,KHo),e(PF,rz),e(rz,ZHo),e(PF,eUo),e(H,oUo),e(H,BF),e(BF,rue),e(rue,rUo),e(BF,tUo),e(BF,tz),e(tz,aUo),e(BF,nUo),e(H,sUo),e(H,IF),e(IF,tue),e(tue,lUo),e(IF,iUo),e(IF,az),e(az,dUo),e(IF,cUo),e(H,fUo),e(H,NF),e(NF,aue),e(aue,mUo),e(NF,gUo),e(NF,nz),e(nz,hUo),e(NF,pUo),e(H,_Uo),e(H,qF),e(qF,nue),e(nue,uUo),e(qF,bUo),e(qF,sz),e(sz,vUo),e(qF,FUo),e(H,TUo),e(H,jF),e(jF,sue),e(sue,MUo),e(jF,EUo),e(jF,lz),e(lz,CUo),e(jF,wUo),e(H,AUo),e(H,DF),e(DF,lue),e(lue,LUo),e(DF,yUo),e(DF,iz),e(iz,xUo),e(DF,$Uo),e(H,kUo),e(H,GF),e(GF,iue),e(iue,SUo),e(GF,RUo),e(GF,dz),e(dz,PUo),e(GF,BUo),e(H,IUo),e(H,OF),e(OF,due),e(due,NUo),e(OF,qUo),e(OF,cz),e(cz,jUo),e(OF,DUo),e(H,GUo),e(H,VF),e(VF,cue),e(cue,OUo),e(VF,VUo),e(VF,fz),e(fz,XUo),e(VF,zUo),e(H,QUo),e(H,XF),e(XF,fue),e(fue,WUo),e(XF,HUo),e(XF,mz),e(mz,UUo),e(XF,JUo),e(H,YUo),e(H,zF),e(zF,mue),e(mue,KUo),e(zF,ZUo),e(zF,gz),e(gz,eJo),e(zF,oJo),e(H,rJo),e(H,QF),e(QF,gue),e(gue,tJo),e(QF,aJo),e(QF,hz),e(hz,nJo),e(QF,sJo),e(H,lJo),e(H,WF),e(WF,hue),e(hue,iJo),e(WF,dJo),e(WF,pz),e(pz,cJo),e(WF,fJo),e(H,mJo),e(H,HF),e(HF,pue),e(pue,gJo),e(HF,hJo),e(HF,_z),e(_z,pJo),e(HF,_Jo),e(H,uJo),e(H,UF),e(UF,_ue),e(_ue,bJo),e(UF,vJo),e(UF,uz),e(uz,FJo),e(UF,TJo),e(ao,MJo),e(ao,JF),e(JF,EJo),e(JF,uue),e(uue,CJo),e(JF,wJo),e(JF,bue),e(bue,AJo),e(ao,LJo),M(YF,ao,null),b(f,yOe,u),b(f,id,u),e(id,KF),e(KF,vue),M(UL,vue,null),e(id,yJo),e(id,Fue),e(Fue,xJo),b(f,xOe,u),b(f,jo,u),M(JL,jo,null),e(jo,$Jo),e(jo,dd),e(dd,kJo),e(dd,bz),e(bz,SJo),e(dd,RJo),e(dd,vz),e(vz,PJo),e(dd,BJo),e(jo,IJo),e(jo,YL),e(YL,NJo),e(YL,Tue),e(Tue,qJo),e(YL,jJo),e(jo,DJo),e(jo,ht),M(KL,ht,null),e(ht,GJo),e(ht,Mue),e(Mue,OJo),e(ht,VJo),e(ht,cd),e(cd,XJo),e(cd,Eue),e(Eue,zJo),e(cd,QJo),e(cd,Fz),e(Fz,WJo),e(cd,HJo),e(ht,UJo),M(ZF,ht,null),e(jo,JJo),e(jo,no),M(ZL,no,null),e(no,YJo),e(no,Cue),e(Cue,KJo),e(no,ZJo),e(no,Oa),e(Oa,eYo),e(Oa,wue),e(wue,oYo),e(Oa,rYo),e(Oa,Aue),e(Aue,tYo),e(Oa,aYo),e(Oa,Lue),e(Lue,nYo),e(Oa,sYo),e(no,lYo),e(no,V),e(V,e6),e(e6,yue),e(yue,iYo),e(e6,dYo),e(e6,Tz),e(Tz,cYo),e(e6,fYo),e(V,mYo),e(V,o6),e(o6,xue),e(xue,gYo),e(o6,hYo),e(o6,Mz),e(Mz,pYo),e(o6,_Yo),e(V,uYo),e(V,r6),e(r6,$ue),e($ue,bYo),e(r6,vYo),e(r6,Ez),e(Ez,FYo),e(r6,TYo),e(V,MYo),e(V,t6),e(t6,kue),e(kue,EYo),e(t6,CYo),e(t6,Cz),e(Cz,wYo),e(t6,AYo),e(V,LYo),e(V,a6),e(a6,Sue),e(Sue,yYo),e(a6,xYo),e(a6,wz),e(wz,$Yo),e(a6,kYo),e(V,SYo),e(V,n6),e(n6,Rue),e(Rue,RYo),e(n6,PYo),e(n6,Az),e(Az,BYo),e(n6,IYo),e(V,NYo),e(V,s6),e(s6,Pue),e(Pue,qYo),e(s6,jYo),e(s6,Lz),e(Lz,DYo),e(s6,GYo),e(V,OYo),e(V,l6),e(l6,Bue),e(Bue,VYo),e(l6,XYo),e(l6,yz),e(yz,zYo),e(l6,QYo),e(V,WYo),e(V,i6),e(i6,Iue),e(Iue,HYo),e(i6,UYo),e(i6,xz),e(xz,JYo),e(i6,YYo),e(V,KYo),e(V,d6),e(d6,Nue),e(Nue,ZYo),e(d6,eKo),e(d6,$z),e($z,oKo),e(d6,rKo),e(V,tKo),e(V,c6),e(c6,que),e(que,aKo),e(c6,nKo),e(c6,kz),e(kz,sKo),e(c6,lKo),e(V,iKo),e(V,f6),e(f6,jue),e(jue,dKo),e(f6,cKo),e(f6,Sz),e(Sz,fKo),e(f6,mKo),e(V,gKo),e(V,m6),e(m6,Due),e(Due,hKo),e(m6,pKo),e(m6,Rz),e(Rz,_Ko),e(m6,uKo),e(V,bKo),e(V,g6),e(g6,Gue),e(Gue,vKo),e(g6,FKo),e(g6,Pz),e(Pz,TKo),e(g6,MKo),e(V,EKo),e(V,h6),e(h6,Oue),e(Oue,CKo),e(h6,wKo),e(h6,Bz),e(Bz,AKo),e(h6,LKo),e(V,yKo),e(V,p6),e(p6,Vue),e(Vue,xKo),e(p6,$Ko),e(p6,Iz),e(Iz,kKo),e(p6,SKo),e(V,RKo),e(V,_6),e(_6,Xue),e(Xue,PKo),e(_6,BKo),e(_6,Nz),e(Nz,IKo),e(_6,NKo),e(V,qKo),e(V,u6),e(u6,zue),e(zue,jKo),e(u6,DKo),e(u6,qz),e(qz,GKo),e(u6,OKo),e(V,VKo),e(V,b6),e(b6,Que),e(Que,XKo),e(b6,zKo),e(b6,jz),e(jz,QKo),e(b6,WKo),e(V,HKo),e(V,v6),e(v6,Wue),e(Wue,UKo),e(v6,JKo),e(v6,Dz),e(Dz,YKo),e(v6,KKo),e(V,ZKo),e(V,F6),e(F6,Hue),e(Hue,eZo),e(F6,oZo),e(F6,Gz),e(Gz,rZo),e(F6,tZo),e(V,aZo),e(V,T6),e(T6,Uue),e(Uue,nZo),e(T6,sZo),e(T6,Oz),e(Oz,lZo),e(T6,iZo),e(V,dZo),e(V,M6),e(M6,Jue),e(Jue,cZo),e(M6,fZo),e(M6,Vz),e(Vz,mZo),e(M6,gZo),e(V,hZo),e(V,E6),e(E6,Yue),e(Yue,pZo),e(E6,_Zo),e(E6,Xz),e(Xz,uZo),e(E6,bZo),e(V,vZo),e(V,C6),e(C6,Kue),e(Kue,FZo),e(C6,TZo),e(C6,zz),e(zz,MZo),e(C6,EZo),e(V,CZo),e(V,w6),e(w6,Zue),e(Zue,wZo),e(w6,AZo),e(w6,Qz),e(Qz,LZo),e(w6,yZo),e(V,xZo),e(V,A6),e(A6,e2e),e(e2e,$Zo),e(A6,kZo),e(A6,Wz),e(Wz,SZo),e(A6,RZo),e(V,PZo),e(V,L6),e(L6,o2e),e(o2e,BZo),e(L6,IZo),e(L6,Hz),e(Hz,NZo),e(L6,qZo),e(V,jZo),e(V,y6),e(y6,r2e),e(r2e,DZo),e(y6,GZo),e(y6,Uz),e(Uz,OZo),e(y6,VZo),e(V,XZo),e(V,x6),e(x6,t2e),e(t2e,zZo),e(x6,QZo),e(x6,Jz),e(Jz,WZo),e(x6,HZo),e(V,UZo),e(V,$6),e($6,a2e),e(a2e,JZo),e($6,YZo),e($6,Yz),e(Yz,KZo),e($6,ZZo),e(V,eer),e(V,k6),e(k6,n2e),e(n2e,oer),e(k6,rer),e(k6,Kz),e(Kz,ter),e(k6,aer),e(V,ner),e(V,S6),e(S6,s2e),e(s2e,ser),e(S6,ler),e(S6,Zz),e(Zz,ier),e(S6,der),e(V,cer),e(V,R6),e(R6,l2e),e(l2e,fer),e(R6,mer),e(R6,eQ),e(eQ,ger),e(R6,her),e(V,per),e(V,P6),e(P6,i2e),e(i2e,_er),e(P6,uer),e(P6,oQ),e(oQ,ber),e(P6,ver),e(V,Fer),e(V,B6),e(B6,d2e),e(d2e,Ter),e(B6,Mer),e(B6,rQ),e(rQ,Eer),e(B6,Cer),e(V,wer),e(V,I6),e(I6,c2e),e(c2e,Aer),e(I6,Ler),e(I6,tQ),e(tQ,yer),e(I6,xer),e(V,$er),e(V,N6),e(N6,f2e),e(f2e,ker),e(N6,Ser),e(N6,aQ),e(aQ,Rer),e(N6,Per),e(V,Ber),e(V,q6),e(q6,m2e),e(m2e,Ier),e(q6,Ner),e(q6,nQ),e(nQ,qer),e(q6,jer),e(V,Der),e(V,j6),e(j6,g2e),e(g2e,Ger),e(j6,Oer),e(j6,sQ),e(sQ,Ver),e(j6,Xer),e(V,zer),e(V,D6),e(D6,h2e),e(h2e,Qer),e(D6,Wer),e(D6,lQ),e(lQ,Her),e(D6,Uer),e(no,Jer),e(no,G6),e(G6,Yer),e(G6,p2e),e(p2e,Ker),e(G6,Zer),e(G6,_2e),e(_2e,eor),e(no,oor),M(O6,no,null),b(f,$Oe,u),b(f,fd,u),e(fd,V6),e(V6,u2e),M(ey,u2e,null),e(fd,ror),e(fd,b2e),e(b2e,tor),b(f,kOe,u),b(f,Do,u),M(oy,Do,null),e(Do,aor),e(Do,md),e(md,nor),e(md,iQ),e(iQ,sor),e(md,lor),e(md,dQ),e(dQ,ior),e(md,dor),e(Do,cor),e(Do,ry),e(ry,mor),e(ry,v2e),e(v2e,gor),e(ry,hor),e(Do,por),e(Do,pt),M(ty,pt,null),e(pt,_or),e(pt,F2e),e(F2e,uor),e(pt,bor),e(pt,gd),e(gd,vor),e(gd,T2e),e(T2e,For),e(gd,Tor),e(gd,cQ),e(cQ,Mor),e(gd,Eor),e(pt,Cor),M(X6,pt,null),e(Do,wor),e(Do,so),M(ay,so,null),e(so,Aor),e(so,M2e),e(M2e,Lor),e(so,yor),e(so,Va),e(Va,xor),e(Va,E2e),e(E2e,$or),e(Va,kor),e(Va,C2e),e(C2e,Sor),e(Va,Ror),e(Va,w2e),e(w2e,Por),e(Va,Bor),e(so,Ior),e(so,A2e),e(A2e,z6),e(z6,L2e),e(L2e,Nor),e(z6,qor),e(z6,fQ),e(fQ,jor),e(z6,Dor),e(so,Gor),e(so,Q6),e(Q6,Oor),e(Q6,y2e),e(y2e,Vor),e(Q6,Xor),e(Q6,x2e),e(x2e,zor),e(so,Qor),M(W6,so,null),b(f,SOe,u),b(f,hd,u),e(hd,H6),e(H6,$2e),M(ny,$2e,null),e(hd,Wor),e(hd,k2e),e(k2e,Hor),b(f,ROe,u),b(f,Go,u),M(sy,Go,null),e(Go,Uor),e(Go,pd),e(pd,Jor),e(pd,mQ),e(mQ,Yor),e(pd,Kor),e(pd,gQ),e(gQ,Zor),e(pd,err),e(Go,orr),e(Go,ly),e(ly,rrr),e(ly,S2e),e(S2e,trr),e(ly,arr),e(Go,nrr),e(Go,_t),M(iy,_t,null),e(_t,srr),e(_t,R2e),e(R2e,lrr),e(_t,irr),e(_t,_d),e(_d,drr),e(_d,P2e),e(P2e,crr),e(_d,frr),e(_d,hQ),e(hQ,mrr),e(_d,grr),e(_t,hrr),M(U6,_t,null),e(Go,prr),e(Go,lo),M(dy,lo,null),e(lo,_rr),e(lo,B2e),e(B2e,urr),e(lo,brr),e(lo,Xa),e(Xa,vrr),e(Xa,I2e),e(I2e,Frr),e(Xa,Trr),e(Xa,N2e),e(N2e,Mrr),e(Xa,Err),e(Xa,q2e),e(q2e,Crr),e(Xa,wrr),e(lo,Arr),e(lo,Fe),e(Fe,J6),e(J6,j2e),e(j2e,Lrr),e(J6,yrr),e(J6,pQ),e(pQ,xrr),e(J6,$rr),e(Fe,krr),e(Fe,Y6),e(Y6,D2e),e(D2e,Srr),e(Y6,Rrr),e(Y6,_Q),e(_Q,Prr),e(Y6,Brr),e(Fe,Irr),e(Fe,K6),e(K6,G2e),e(G2e,Nrr),e(K6,qrr),e(K6,uQ),e(uQ,jrr),e(K6,Drr),e(Fe,Grr),e(Fe,Z6),e(Z6,O2e),e(O2e,Orr),e(Z6,Vrr),e(Z6,bQ),e(bQ,Xrr),e(Z6,zrr),e(Fe,Qrr),e(Fe,Xs),e(Xs,V2e),e(V2e,Wrr),e(Xs,Hrr),e(Xs,vQ),e(vQ,Urr),e(Xs,Jrr),e(Xs,FQ),e(FQ,Yrr),e(Xs,Krr),e(Fe,Zrr),e(Fe,eT),e(eT,X2e),e(X2e,etr),e(eT,otr),e(eT,TQ),e(TQ,rtr),e(eT,ttr),e(Fe,atr),e(Fe,zs),e(zs,z2e),e(z2e,ntr),e(zs,str),e(zs,MQ),e(MQ,ltr),e(zs,itr),e(zs,EQ),e(EQ,dtr),e(zs,ctr),e(Fe,ftr),e(Fe,ut),e(ut,Q2e),e(Q2e,mtr),e(ut,gtr),e(ut,CQ),e(CQ,htr),e(ut,ptr),e(ut,wQ),e(wQ,_tr),e(ut,utr),e(ut,AQ),e(AQ,btr),e(ut,vtr),e(Fe,Ftr),e(Fe,oT),e(oT,W2e),e(W2e,Ttr),e(oT,Mtr),e(oT,LQ),e(LQ,Etr),e(oT,Ctr),e(Fe,wtr),e(Fe,rT),e(rT,H2e),e(H2e,Atr),e(rT,Ltr),e(rT,yQ),e(yQ,ytr),e(rT,xtr),e(Fe,$tr),e(Fe,tT),e(tT,U2e),e(U2e,ktr),e(tT,Str),e(tT,xQ),e(xQ,Rtr),e(tT,Ptr),e(Fe,Btr),e(Fe,aT),e(aT,J2e),e(J2e,Itr),e(aT,Ntr),e(aT,$Q),e($Q,qtr),e(aT,jtr),e(Fe,Dtr),e(Fe,nT),e(nT,Y2e),e(Y2e,Gtr),e(nT,Otr),e(nT,kQ),e(kQ,Vtr),e(nT,Xtr),e(Fe,ztr),e(Fe,sT),e(sT,K2e),e(K2e,Qtr),e(sT,Wtr),e(sT,SQ),e(SQ,Htr),e(sT,Utr),e(Fe,Jtr),e(Fe,lT),e(lT,Z2e),e(Z2e,Ytr),e(lT,Ktr),e(lT,RQ),e(RQ,Ztr),e(lT,ear),e(lo,oar),e(lo,iT),e(iT,rar),e(iT,e1e),e(e1e,tar),e(iT,aar),e(iT,o1e),e(o1e,nar),e(lo,sar),M(dT,lo,null),b(f,POe,u),b(f,ud,u),e(ud,cT),e(cT,r1e),M(cy,r1e,null),e(ud,lar),e(ud,t1e),e(t1e,iar),b(f,BOe,u),b(f,Oo,u),M(fy,Oo,null),e(Oo,dar),e(Oo,bd),e(bd,car),e(bd,PQ),e(PQ,far),e(bd,mar),e(bd,BQ),e(BQ,gar),e(bd,har),e(Oo,par),e(Oo,my),e(my,_ar),e(my,a1e),e(a1e,uar),e(my,bar),e(Oo,Far),e(Oo,bt),M(gy,bt,null),e(bt,Tar),e(bt,n1e),e(n1e,Mar),e(bt,Ear),e(bt,vd),e(vd,Car),e(vd,s1e),e(s1e,war),e(vd,Aar),e(vd,IQ),e(IQ,Lar),e(vd,yar),e(bt,xar),M(fT,bt,null),e(Oo,$ar),e(Oo,io),M(hy,io,null),e(io,kar),e(io,l1e),e(l1e,Sar),e(io,Rar),e(io,za),e(za,Par),e(za,i1e),e(i1e,Bar),e(za,Iar),e(za,d1e),e(d1e,Nar),e(za,qar),e(za,c1e),e(c1e,jar),e(za,Dar),e(io,Gar),e(io,f1e),e(f1e,mT),e(mT,m1e),e(m1e,Oar),e(mT,Var),e(mT,NQ),e(NQ,Xar),e(mT,zar),e(io,Qar),e(io,gT),e(gT,War),e(gT,g1e),e(g1e,Har),e(gT,Uar),e(gT,h1e),e(h1e,Jar),e(io,Yar),M(hT,io,null),b(f,IOe,u),b(f,Fd,u),e(Fd,pT),e(pT,p1e),M(py,p1e,null),e(Fd,Kar),e(Fd,_1e),e(_1e,Zar),b(f,NOe,u),b(f,Vo,u),M(_y,Vo,null),e(Vo,enr),e(Vo,Td),e(Td,onr),e(Td,qQ),e(qQ,rnr),e(Td,tnr),e(Td,jQ),e(jQ,anr),e(Td,nnr),e(Vo,snr),e(Vo,uy),e(uy,lnr),e(uy,u1e),e(u1e,inr),e(uy,dnr),e(Vo,cnr),e(Vo,vt),M(by,vt,null),e(vt,fnr),e(vt,b1e),e(b1e,mnr),e(vt,gnr),e(vt,Md),e(Md,hnr),e(Md,v1e),e(v1e,pnr),e(Md,_nr),e(Md,DQ),e(DQ,unr),e(Md,bnr),e(vt,vnr),M(_T,vt,null),e(Vo,Fnr),e(Vo,co),M(vy,co,null),e(co,Tnr),e(co,F1e),e(F1e,Mnr),e(co,Enr),e(co,Qa),e(Qa,Cnr),e(Qa,T1e),e(T1e,wnr),e(Qa,Anr),e(Qa,M1e),e(M1e,Lnr),e(Qa,ynr),e(Qa,E1e),e(E1e,xnr),e(Qa,$nr),e(co,knr),e(co,C1e),e(C1e,uT),e(uT,w1e),e(w1e,Snr),e(uT,Rnr),e(uT,GQ),e(GQ,Pnr),e(uT,Bnr),e(co,Inr),e(co,bT),e(bT,Nnr),e(bT,A1e),e(A1e,qnr),e(bT,jnr),e(bT,L1e),e(L1e,Dnr),e(co,Gnr),M(vT,co,null),b(f,qOe,u),b(f,Ed,u),e(Ed,FT),e(FT,y1e),M(Fy,y1e,null),e(Ed,Onr),e(Ed,x1e),e(x1e,Vnr),b(f,jOe,u),b(f,Xo,u),M(Ty,Xo,null),e(Xo,Xnr),e(Xo,Cd),e(Cd,znr),e(Cd,OQ),e(OQ,Qnr),e(Cd,Wnr),e(Cd,VQ),e(VQ,Hnr),e(Cd,Unr),e(Xo,Jnr),e(Xo,My),e(My,Ynr),e(My,$1e),e($1e,Knr),e(My,Znr),e(Xo,esr),e(Xo,Ft),M(Ey,Ft,null),e(Ft,osr),e(Ft,k1e),e(k1e,rsr),e(Ft,tsr),e(Ft,wd),e(wd,asr),e(wd,S1e),e(S1e,nsr),e(wd,ssr),e(wd,XQ),e(XQ,lsr),e(wd,isr),e(Ft,dsr),M(TT,Ft,null),e(Xo,csr),e(Xo,fo),M(Cy,fo,null),e(fo,fsr),e(fo,R1e),e(R1e,msr),e(fo,gsr),e(fo,Wa),e(Wa,hsr),e(Wa,P1e),e(P1e,psr),e(Wa,_sr),e(Wa,B1e),e(B1e,usr),e(Wa,bsr),e(Wa,I1e),e(I1e,vsr),e(Wa,Fsr),e(fo,Tsr),e(fo,Pe),e(Pe,MT),e(MT,N1e),e(N1e,Msr),e(MT,Esr),e(MT,zQ),e(zQ,Csr),e(MT,wsr),e(Pe,Asr),e(Pe,ET),e(ET,q1e),e(q1e,Lsr),e(ET,ysr),e(ET,QQ),e(QQ,xsr),e(ET,$sr),e(Pe,ksr),e(Pe,CT),e(CT,j1e),e(j1e,Ssr),e(CT,Rsr),e(CT,WQ),e(WQ,Psr),e(CT,Bsr),e(Pe,Isr),e(Pe,wT),e(wT,D1e),e(D1e,Nsr),e(wT,qsr),e(wT,HQ),e(HQ,jsr),e(wT,Dsr),e(Pe,Gsr),e(Pe,AT),e(AT,G1e),e(G1e,Osr),e(AT,Vsr),e(AT,UQ),e(UQ,Xsr),e(AT,zsr),e(Pe,Qsr),e(Pe,LT),e(LT,O1e),e(O1e,Wsr),e(LT,Hsr),e(LT,JQ),e(JQ,Usr),e(LT,Jsr),e(Pe,Ysr),e(Pe,yT),e(yT,V1e),e(V1e,Ksr),e(yT,Zsr),e(yT,YQ),e(YQ,elr),e(yT,olr),e(Pe,rlr),e(Pe,xT),e(xT,X1e),e(X1e,tlr),e(xT,alr),e(xT,KQ),e(KQ,nlr),e(xT,slr),e(Pe,llr),e(Pe,$T),e($T,z1e),e(z1e,ilr),e($T,dlr),e($T,ZQ),e(ZQ,clr),e($T,flr),e(fo,mlr),e(fo,kT),e(kT,glr),e(kT,Q1e),e(Q1e,hlr),e(kT,plr),e(kT,W1e),e(W1e,_lr),e(fo,ulr),M(ST,fo,null),b(f,DOe,u),b(f,Ad,u),e(Ad,RT),e(RT,H1e),M(wy,H1e,null),e(Ad,blr),e(Ad,U1e),e(U1e,vlr),b(f,GOe,u),b(f,zo,u),M(Ay,zo,null),e(zo,Flr),e(zo,Ld),e(Ld,Tlr),e(Ld,eW),e(eW,Mlr),e(Ld,Elr),e(Ld,oW),e(oW,Clr),e(Ld,wlr),e(zo,Alr),e(zo,Ly),e(Ly,Llr),e(Ly,J1e),e(J1e,ylr),e(Ly,xlr),e(zo,$lr),e(zo,Tt),M(yy,Tt,null),e(Tt,klr),e(Tt,Y1e),e(Y1e,Slr),e(Tt,Rlr),e(Tt,yd),e(yd,Plr),e(yd,K1e),e(K1e,Blr),e(yd,Ilr),e(yd,rW),e(rW,Nlr),e(yd,qlr),e(Tt,jlr),M(PT,Tt,null),e(zo,Dlr),e(zo,mo),M(xy,mo,null),e(mo,Glr),e(mo,Z1e),e(Z1e,Olr),e(mo,Vlr),e(mo,Ha),e(Ha,Xlr),e(Ha,ebe),e(ebe,zlr),e(Ha,Qlr),e(Ha,obe),e(obe,Wlr),e(Ha,Hlr),e(Ha,rbe),e(rbe,Ulr),e(Ha,Jlr),e(mo,Ylr),e(mo,et),e(et,BT),e(BT,tbe),e(tbe,Klr),e(BT,Zlr),e(BT,tW),e(tW,eir),e(BT,oir),e(et,rir),e(et,IT),e(IT,abe),e(abe,tir),e(IT,air),e(IT,aW),e(aW,nir),e(IT,sir),e(et,lir),e(et,NT),e(NT,nbe),e(nbe,iir),e(NT,dir),e(NT,nW),e(nW,cir),e(NT,fir),e(et,mir),e(et,qT),e(qT,sbe),e(sbe,gir),e(qT,hir),e(qT,sW),e(sW,pir),e(qT,_ir),e(et,uir),e(et,jT),e(jT,lbe),e(lbe,bir),e(jT,vir),e(jT,lW),e(lW,Fir),e(jT,Tir),e(mo,Mir),e(mo,DT),e(DT,Eir),e(DT,ibe),e(ibe,Cir),e(DT,wir),e(DT,dbe),e(dbe,Air),e(mo,Lir),M(GT,mo,null),b(f,OOe,u),b(f,xd,u),e(xd,OT),e(OT,cbe),M($y,cbe,null),e(xd,yir),e(xd,fbe),e(fbe,xir),b(f,VOe,u),b(f,Qo,u),M(ky,Qo,null),e(Qo,$ir),e(Qo,$d),e($d,kir),e($d,iW),e(iW,Sir),e($d,Rir),e($d,dW),e(dW,Pir),e($d,Bir),e(Qo,Iir),e(Qo,Sy),e(Sy,Nir),e(Sy,mbe),e(mbe,qir),e(Sy,jir),e(Qo,Dir),e(Qo,Mt),M(Ry,Mt,null),e(Mt,Gir),e(Mt,gbe),e(gbe,Oir),e(Mt,Vir),e(Mt,kd),e(kd,Xir),e(kd,hbe),e(hbe,zir),e(kd,Qir),e(kd,cW),e(cW,Wir),e(kd,Hir),e(Mt,Uir),M(VT,Mt,null),e(Qo,Jir),e(Qo,go),M(Py,go,null),e(go,Yir),e(go,pbe),e(pbe,Kir),e(go,Zir),e(go,Ua),e(Ua,edr),e(Ua,_be),e(_be,odr),e(Ua,rdr),e(Ua,ube),e(ube,tdr),e(Ua,adr),e(Ua,bbe),e(bbe,ndr),e(Ua,sdr),e(go,ldr),e(go,Le),e(Le,XT),e(XT,vbe),e(vbe,idr),e(XT,ddr),e(XT,fW),e(fW,cdr),e(XT,fdr),e(Le,mdr),e(Le,zT),e(zT,Fbe),e(Fbe,gdr),e(zT,hdr),e(zT,mW),e(mW,pdr),e(zT,_dr),e(Le,udr),e(Le,QT),e(QT,Tbe),e(Tbe,bdr),e(QT,vdr),e(QT,gW),e(gW,Fdr),e(QT,Tdr),e(Le,Mdr),e(Le,WT),e(WT,Mbe),e(Mbe,Edr),e(WT,Cdr),e(WT,hW),e(hW,wdr),e(WT,Adr),e(Le,Ldr),e(Le,HT),e(HT,Ebe),e(Ebe,ydr),e(HT,xdr),e(HT,pW),e(pW,$dr),e(HT,kdr),e(Le,Sdr),e(Le,UT),e(UT,Cbe),e(Cbe,Rdr),e(UT,Pdr),e(UT,_W),e(_W,Bdr),e(UT,Idr),e(Le,Ndr),e(Le,JT),e(JT,wbe),e(wbe,qdr),e(JT,jdr),e(JT,uW),e(uW,Ddr),e(JT,Gdr),e(Le,Odr),e(Le,YT),e(YT,Abe),e(Abe,Vdr),e(YT,Xdr),e(YT,bW),e(bW,zdr),e(YT,Qdr),e(Le,Wdr),e(Le,KT),e(KT,Lbe),e(Lbe,Hdr),e(KT,Udr),e(KT,vW),e(vW,Jdr),e(KT,Ydr),e(Le,Kdr),e(Le,ZT),e(ZT,ybe),e(ybe,Zdr),e(ZT,ecr),e(ZT,FW),e(FW,ocr),e(ZT,rcr),e(go,tcr),e(go,e7),e(e7,acr),e(e7,xbe),e(xbe,ncr),e(e7,scr),e(e7,$be),e($be,lcr),e(go,icr),M(o7,go,null),b(f,XOe,u),b(f,Sd,u),e(Sd,r7),e(r7,kbe),M(By,kbe,null),e(Sd,dcr),e(Sd,Sbe),e(Sbe,ccr),b(f,zOe,u),b(f,Wo,u),M(Iy,Wo,null),e(Wo,fcr),e(Wo,Rd),e(Rd,mcr),e(Rd,TW),e(TW,gcr),e(Rd,hcr),e(Rd,MW),e(MW,pcr),e(Rd,_cr),e(Wo,ucr),e(Wo,Ny),e(Ny,bcr),e(Ny,Rbe),e(Rbe,vcr),e(Ny,Fcr),e(Wo,Tcr),e(Wo,Et),M(qy,Et,null),e(Et,Mcr),e(Et,Pbe),e(Pbe,Ecr),e(Et,Ccr),e(Et,Pd),e(Pd,wcr),e(Pd,Bbe),e(Bbe,Acr),e(Pd,Lcr),e(Pd,EW),e(EW,ycr),e(Pd,xcr),e(Et,$cr),M(t7,Et,null),e(Wo,kcr),e(Wo,ho),M(jy,ho,null),e(ho,Scr),e(ho,Ibe),e(Ibe,Rcr),e(ho,Pcr),e(ho,Ja),e(Ja,Bcr),e(Ja,Nbe),e(Nbe,Icr),e(Ja,Ncr),e(Ja,qbe),e(qbe,qcr),e(Ja,jcr),e(Ja,jbe),e(jbe,Dcr),e(Ja,Gcr),e(ho,Ocr),e(ho,Dy),e(Dy,a7),e(a7,Dbe),e(Dbe,Vcr),e(a7,Xcr),e(a7,CW),e(CW,zcr),e(a7,Qcr),e(Dy,Wcr),e(Dy,n7),e(n7,Gbe),e(Gbe,Hcr),e(n7,Ucr),e(n7,wW),e(wW,Jcr),e(n7,Ycr),e(ho,Kcr),e(ho,s7),e(s7,Zcr),e(s7,Obe),e(Obe,efr),e(s7,ofr),e(s7,Vbe),e(Vbe,rfr),e(ho,tfr),M(l7,ho,null),b(f,QOe,u),b(f,Bd,u),e(Bd,i7),e(i7,Xbe),M(Gy,Xbe,null),e(Bd,afr),e(Bd,zbe),e(zbe,nfr),b(f,WOe,u),b(f,Ho,u),M(Oy,Ho,null),e(Ho,sfr),e(Ho,Id),e(Id,lfr),e(Id,AW),e(AW,ifr),e(Id,dfr),e(Id,LW),e(LW,cfr),e(Id,ffr),e(Ho,mfr),e(Ho,Vy),e(Vy,gfr),e(Vy,Qbe),e(Qbe,hfr),e(Vy,pfr),e(Ho,_fr),e(Ho,Ct),M(Xy,Ct,null),e(Ct,ufr),e(Ct,Wbe),e(Wbe,bfr),e(Ct,vfr),e(Ct,Nd),e(Nd,Ffr),e(Nd,Hbe),e(Hbe,Tfr),e(Nd,Mfr),e(Nd,yW),e(yW,Efr),e(Nd,Cfr),e(Ct,wfr),M(d7,Ct,null),e(Ho,Afr),e(Ho,po),M(zy,po,null),e(po,Lfr),e(po,Ube),e(Ube,yfr),e(po,xfr),e(po,Ya),e(Ya,$fr),e(Ya,Jbe),e(Jbe,kfr),e(Ya,Sfr),e(Ya,Ybe),e(Ybe,Rfr),e(Ya,Pfr),e(Ya,Kbe),e(Kbe,Bfr),e(Ya,Ifr),e(po,Nfr),e(po,ot),e(ot,c7),e(c7,Zbe),e(Zbe,qfr),e(c7,jfr),e(c7,xW),e(xW,Dfr),e(c7,Gfr),e(ot,Ofr),e(ot,f7),e(f7,eve),e(eve,Vfr),e(f7,Xfr),e(f7,$W),e($W,zfr),e(f7,Qfr),e(ot,Wfr),e(ot,m7),e(m7,ove),e(ove,Hfr),e(m7,Ufr),e(m7,kW),e(kW,Jfr),e(m7,Yfr),e(ot,Kfr),e(ot,g7),e(g7,rve),e(rve,Zfr),e(g7,emr),e(g7,SW),e(SW,omr),e(g7,rmr),e(ot,tmr),e(ot,h7),e(h7,tve),e(tve,amr),e(h7,nmr),e(h7,RW),e(RW,smr),e(h7,lmr),e(po,imr),e(po,p7),e(p7,dmr),e(p7,ave),e(ave,cmr),e(p7,fmr),e(p7,nve),e(nve,mmr),e(po,gmr),M(_7,po,null),b(f,HOe,u),b(f,qd,u),e(qd,u7),e(u7,sve),M(Qy,sve,null),e(qd,hmr),e(qd,lve),e(lve,pmr),b(f,UOe,u),b(f,Uo,u),M(Wy,Uo,null),e(Uo,_mr),e(Uo,jd),e(jd,umr),e(jd,PW),e(PW,bmr),e(jd,vmr),e(jd,BW),e(BW,Fmr),e(jd,Tmr),e(Uo,Mmr),e(Uo,Hy),e(Hy,Emr),e(Hy,ive),e(ive,Cmr),e(Hy,wmr),e(Uo,Amr),e(Uo,wt),M(Uy,wt,null),e(wt,Lmr),e(wt,dve),e(dve,ymr),e(wt,xmr),e(wt,Dd),e(Dd,$mr),e(Dd,cve),e(cve,kmr),e(Dd,Smr),e(Dd,IW),e(IW,Rmr),e(Dd,Pmr),e(wt,Bmr),M(b7,wt,null),e(Uo,Imr),e(Uo,_o),M(Jy,_o,null),e(_o,Nmr),e(_o,fve),e(fve,qmr),e(_o,jmr),e(_o,Ka),e(Ka,Dmr),e(Ka,mve),e(mve,Gmr),e(Ka,Omr),e(Ka,gve),e(gve,Vmr),e(Ka,Xmr),e(Ka,hve),e(hve,zmr),e(Ka,Qmr),e(_o,Wmr),e(_o,Gd),e(Gd,v7),e(v7,pve),e(pve,Hmr),e(v7,Umr),e(v7,NW),e(NW,Jmr),e(v7,Ymr),e(Gd,Kmr),e(Gd,F7),e(F7,_ve),e(_ve,Zmr),e(F7,egr),e(F7,qW),e(qW,ogr),e(F7,rgr),e(Gd,tgr),e(Gd,T7),e(T7,uve),e(uve,agr),e(T7,ngr),e(T7,jW),e(jW,sgr),e(T7,lgr),e(_o,igr),e(_o,M7),e(M7,dgr),e(M7,bve),e(bve,cgr),e(M7,fgr),e(M7,vve),e(vve,mgr),e(_o,ggr),M(E7,_o,null),b(f,JOe,u),b(f,Od,u),e(Od,C7),e(C7,Fve),M(Yy,Fve,null),e(Od,hgr),e(Od,Tve),e(Tve,pgr),b(f,YOe,u),b(f,Jo,u),M(Ky,Jo,null),e(Jo,_gr),e(Jo,Vd),e(Vd,ugr),e(Vd,DW),e(DW,bgr),e(Vd,vgr),e(Vd,GW),e(GW,Fgr),e(Vd,Tgr),e(Jo,Mgr),e(Jo,Zy),e(Zy,Egr),e(Zy,Mve),e(Mve,Cgr),e(Zy,wgr),e(Jo,Agr),e(Jo,At),M(e9,At,null),e(At,Lgr),e(At,Eve),e(Eve,ygr),e(At,xgr),e(At,Xd),e(Xd,$gr),e(Xd,Cve),e(Cve,kgr),e(Xd,Sgr),e(Xd,OW),e(OW,Rgr),e(Xd,Pgr),e(At,Bgr),M(w7,At,null),e(Jo,Igr),e(Jo,uo),M(o9,uo,null),e(uo,Ngr),e(uo,wve),e(wve,qgr),e(uo,jgr),e(uo,Za),e(Za,Dgr),e(Za,Ave),e(Ave,Ggr),e(Za,Ogr),e(Za,Lve),e(Lve,Vgr),e(Za,Xgr),e(Za,yve),e(yve,zgr),e(Za,Qgr),e(uo,Wgr),e(uo,r9),e(r9,A7),e(A7,xve),e(xve,Hgr),e(A7,Ugr),e(A7,VW),e(VW,Jgr),e(A7,Ygr),e(r9,Kgr),e(r9,L7),e(L7,$ve),e($ve,Zgr),e(L7,ehr),e(L7,XW),e(XW,ohr),e(L7,rhr),e(uo,thr),e(uo,y7),e(y7,ahr),e(y7,kve),e(kve,nhr),e(y7,shr),e(y7,Sve),e(Sve,lhr),e(uo,ihr),M(x7,uo,null),b(f,KOe,u),b(f,zd,u),e(zd,$7),e($7,Rve),M(t9,Rve,null),e(zd,dhr),e(zd,Pve),e(Pve,chr),b(f,ZOe,u),b(f,Yo,u),M(a9,Yo,null),e(Yo,fhr),e(Yo,Qd),e(Qd,mhr),e(Qd,zW),e(zW,ghr),e(Qd,hhr),e(Qd,QW),e(QW,phr),e(Qd,_hr),e(Yo,uhr),e(Yo,n9),e(n9,bhr),e(n9,Bve),e(Bve,vhr),e(n9,Fhr),e(Yo,Thr),e(Yo,Lt),M(s9,Lt,null),e(Lt,Mhr),e(Lt,Ive),e(Ive,Ehr),e(Lt,Chr),e(Lt,Wd),e(Wd,whr),e(Wd,Nve),e(Nve,Ahr),e(Wd,Lhr),e(Wd,WW),e(WW,yhr),e(Wd,xhr),e(Lt,$hr),M(k7,Lt,null),e(Yo,khr),e(Yo,bo),M(l9,bo,null),e(bo,Shr),e(bo,qve),e(qve,Rhr),e(bo,Phr),e(bo,en),e(en,Bhr),e(en,jve),e(jve,Ihr),e(en,Nhr),e(en,Dve),e(Dve,qhr),e(en,jhr),e(en,Gve),e(Gve,Dhr),e(en,Ghr),e(bo,Ohr),e(bo,Ove),e(Ove,S7),e(S7,Vve),e(Vve,Vhr),e(S7,Xhr),e(S7,HW),e(HW,zhr),e(S7,Qhr),e(bo,Whr),e(bo,R7),e(R7,Hhr),e(R7,Xve),e(Xve,Uhr),e(R7,Jhr),e(R7,zve),e(zve,Yhr),e(bo,Khr),M(P7,bo,null),b(f,eVe,u),b(f,Hd,u),e(Hd,B7),e(B7,Qve),M(i9,Qve,null),e(Hd,Zhr),e(Hd,Wve),e(Wve,epr),b(f,oVe,u),b(f,Ko,u),M(d9,Ko,null),e(Ko,opr),e(Ko,Ud),e(Ud,rpr),e(Ud,UW),e(UW,tpr),e(Ud,apr),e(Ud,JW),e(JW,npr),e(Ud,spr),e(Ko,lpr),e(Ko,c9),e(c9,ipr),e(c9,Hve),e(Hve,dpr),e(c9,cpr),e(Ko,fpr),e(Ko,yt),M(f9,yt,null),e(yt,mpr),e(yt,Uve),e(Uve,gpr),e(yt,hpr),e(yt,Jd),e(Jd,ppr),e(Jd,Jve),e(Jve,_pr),e(Jd,upr),e(Jd,YW),e(YW,bpr),e(Jd,vpr),e(yt,Fpr),M(I7,yt,null),e(Ko,Tpr),e(Ko,vo),M(m9,vo,null),e(vo,Mpr),e(vo,Yve),e(Yve,Epr),e(vo,Cpr),e(vo,on),e(on,wpr),e(on,Kve),e(Kve,Apr),e(on,Lpr),e(on,Zve),e(Zve,ypr),e(on,xpr),e(on,eFe),e(eFe,$pr),e(on,kpr),e(vo,Spr),e(vo,rn),e(rn,N7),e(N7,oFe),e(oFe,Rpr),e(N7,Ppr),e(N7,KW),e(KW,Bpr),e(N7,Ipr),e(rn,Npr),e(rn,q7),e(q7,rFe),e(rFe,qpr),e(q7,jpr),e(q7,ZW),e(ZW,Dpr),e(q7,Gpr),e(rn,Opr),e(rn,j7),e(j7,tFe),e(tFe,Vpr),e(j7,Xpr),e(j7,eH),e(eH,zpr),e(j7,Qpr),e(rn,Wpr),e(rn,D7),e(D7,aFe),e(aFe,Hpr),e(D7,Upr),e(D7,oH),e(oH,Jpr),e(D7,Ypr),e(vo,Kpr),e(vo,G7),e(G7,Zpr),e(G7,nFe),e(nFe,e_r),e(G7,o_r),e(G7,sFe),e(sFe,r_r),e(vo,t_r),M(O7,vo,null),b(f,rVe,u),b(f,Yd,u),e(Yd,V7),e(V7,lFe),M(g9,lFe,null),e(Yd,a_r),e(Yd,iFe),e(iFe,n_r),b(f,tVe,u),b(f,Zo,u),M(h9,Zo,null),e(Zo,s_r),e(Zo,Kd),e(Kd,l_r),e(Kd,rH),e(rH,i_r),e(Kd,d_r),e(Kd,tH),e(tH,c_r),e(Kd,f_r),e(Zo,m_r),e(Zo,p9),e(p9,g_r),e(p9,dFe),e(dFe,h_r),e(p9,p_r),e(Zo,__r),e(Zo,xt),M(_9,xt,null),e(xt,u_r),e(xt,cFe),e(cFe,b_r),e(xt,v_r),e(xt,Zd),e(Zd,F_r),e(Zd,fFe),e(fFe,T_r),e(Zd,M_r),e(Zd,aH),e(aH,E_r),e(Zd,C_r),e(xt,w_r),M(X7,xt,null),e(Zo,A_r),e(Zo,Fo),M(u9,Fo,null),e(Fo,L_r),e(Fo,mFe),e(mFe,y_r),e(Fo,x_r),e(Fo,tn),e(tn,$_r),e(tn,gFe),e(gFe,k_r),e(tn,S_r),e(tn,hFe),e(hFe,R_r),e(tn,P_r),e(tn,pFe),e(pFe,B_r),e(tn,I_r),e(Fo,N_r),e(Fo,_Fe),e(_Fe,z7),e(z7,uFe),e(uFe,q_r),e(z7,j_r),e(z7,nH),e(nH,D_r),e(z7,G_r),e(Fo,O_r),e(Fo,Q7),e(Q7,V_r),e(Q7,bFe),e(bFe,X_r),e(Q7,z_r),e(Q7,vFe),e(vFe,Q_r),e(Fo,W_r),M(W7,Fo,null),b(f,aVe,u),b(f,ec,u),e(ec,H7),e(H7,FFe),M(b9,FFe,null),e(ec,H_r),e(ec,TFe),e(TFe,U_r),b(f,nVe,u),b(f,er,u),M(v9,er,null),e(er,J_r),e(er,oc),e(oc,Y_r),e(oc,sH),e(sH,K_r),e(oc,Z_r),e(oc,lH),e(lH,eur),e(oc,our),e(er,rur),e(er,F9),e(F9,tur),e(F9,MFe),e(MFe,aur),e(F9,nur),e(er,sur),e(er,$t),M(T9,$t,null),e($t,lur),e($t,EFe),e(EFe,iur),e($t,dur),e($t,rc),e(rc,cur),e(rc,CFe),e(CFe,fur),e(rc,mur),e(rc,iH),e(iH,gur),e(rc,hur),e($t,pur),M(U7,$t,null),e(er,_ur),e(er,yr),M(M9,yr,null),e(yr,uur),e(yr,wFe),e(wFe,bur),e(yr,vur),e(yr,an),e(an,Fur),e(an,AFe),e(AFe,Tur),e(an,Mur),e(an,LFe),e(LFe,Eur),e(an,Cur),e(an,yFe),e(yFe,wur),e(an,Aur),e(yr,Lur),e(yr,j),e(j,J7),e(J7,xFe),e(xFe,yur),e(J7,xur),e(J7,dH),e(dH,$ur),e(J7,kur),e(j,Sur),e(j,Y7),e(Y7,$Fe),e($Fe,Rur),e(Y7,Pur),e(Y7,cH),e(cH,Bur),e(Y7,Iur),e(j,Nur),e(j,K7),e(K7,kFe),e(kFe,qur),e(K7,jur),e(K7,fH),e(fH,Dur),e(K7,Gur),e(j,Our),e(j,Z7),e(Z7,SFe),e(SFe,Vur),e(Z7,Xur),e(Z7,mH),e(mH,zur),e(Z7,Qur),e(j,Wur),e(j,e8),e(e8,RFe),e(RFe,Hur),e(e8,Uur),e(e8,gH),e(gH,Jur),e(e8,Yur),e(j,Kur),e(j,o8),e(o8,PFe),e(PFe,Zur),e(o8,e2r),e(o8,hH),e(hH,o2r),e(o8,r2r),e(j,t2r),e(j,r8),e(r8,BFe),e(BFe,a2r),e(r8,n2r),e(r8,pH),e(pH,s2r),e(r8,l2r),e(j,i2r),e(j,t8),e(t8,IFe),e(IFe,d2r),e(t8,c2r),e(t8,_H),e(_H,f2r),e(t8,m2r),e(j,g2r),e(j,a8),e(a8,NFe),e(NFe,h2r),e(a8,p2r),e(a8,uH),e(uH,_2r),e(a8,u2r),e(j,b2r),e(j,n8),e(n8,qFe),e(qFe,v2r),e(n8,F2r),e(n8,bH),e(bH,T2r),e(n8,M2r),e(j,E2r),e(j,s8),e(s8,jFe),e(jFe,C2r),e(s8,w2r),e(s8,vH),e(vH,A2r),e(s8,L2r),e(j,y2r),e(j,l8),e(l8,DFe),e(DFe,x2r),e(l8,$2r),e(l8,FH),e(FH,k2r),e(l8,S2r),e(j,R2r),e(j,i8),e(i8,GFe),e(GFe,P2r),e(i8,B2r),e(i8,TH),e(TH,I2r),e(i8,N2r),e(j,q2r),e(j,d8),e(d8,OFe),e(OFe,j2r),e(d8,D2r),e(d8,MH),e(MH,G2r),e(d8,O2r),e(j,V2r),e(j,c8),e(c8,VFe),e(VFe,X2r),e(c8,z2r),e(c8,EH),e(EH,Q2r),e(c8,W2r),e(j,H2r),e(j,f8),e(f8,XFe),e(XFe,U2r),e(f8,J2r),e(f8,CH),e(CH,Y2r),e(f8,K2r),e(j,Z2r),e(j,m8),e(m8,zFe),e(zFe,e1r),e(m8,o1r),e(m8,wH),e(wH,r1r),e(m8,t1r),e(j,a1r),e(j,Qs),e(Qs,QFe),e(QFe,n1r),e(Qs,s1r),e(Qs,AH),e(AH,l1r),e(Qs,i1r),e(Qs,LH),e(LH,d1r),e(Qs,c1r),e(j,f1r),e(j,g8),e(g8,WFe),e(WFe,m1r),e(g8,g1r),e(g8,yH),e(yH,h1r),e(g8,p1r),e(j,_1r),e(j,h8),e(h8,HFe),e(HFe,u1r),e(h8,b1r),e(h8,xH),e(xH,v1r),e(h8,F1r),e(j,T1r),e(j,p8),e(p8,UFe),e(UFe,M1r),e(p8,E1r),e(p8,$H),e($H,C1r),e(p8,w1r),e(j,A1r),e(j,_8),e(_8,JFe),e(JFe,L1r),e(_8,y1r),e(_8,kH),e(kH,x1r),e(_8,$1r),e(j,k1r),e(j,u8),e(u8,YFe),e(YFe,S1r),e(u8,R1r),e(u8,SH),e(SH,P1r),e(u8,B1r),e(j,I1r),e(j,b8),e(b8,KFe),e(KFe,N1r),e(b8,q1r),e(b8,RH),e(RH,j1r),e(b8,D1r),e(j,G1r),e(j,v8),e(v8,ZFe),e(ZFe,O1r),e(v8,V1r),e(v8,PH),e(PH,X1r),e(v8,z1r),e(j,Q1r),e(j,F8),e(F8,e6e),e(e6e,W1r),e(F8,H1r),e(F8,BH),e(BH,U1r),e(F8,J1r),e(j,Y1r),e(j,T8),e(T8,o6e),e(o6e,K1r),e(T8,Z1r),e(T8,IH),e(IH,ebr),e(T8,obr),e(j,rbr),e(j,M8),e(M8,r6e),e(r6e,tbr),e(M8,abr),e(M8,NH),e(NH,nbr),e(M8,sbr),e(j,lbr),e(j,E8),e(E8,t6e),e(t6e,ibr),e(E8,dbr),e(E8,qH),e(qH,cbr),e(E8,fbr),e(j,mbr),e(j,C8),e(C8,a6e),e(a6e,gbr),e(C8,hbr),e(C8,jH),e(jH,pbr),e(C8,_br),e(j,ubr),e(j,w8),e(w8,n6e),e(n6e,bbr),e(w8,vbr),e(w8,DH),e(DH,Fbr),e(w8,Tbr),e(j,Mbr),e(j,A8),e(A8,s6e),e(s6e,Ebr),e(A8,Cbr),e(A8,GH),e(GH,wbr),e(A8,Abr),e(j,Lbr),e(j,L8),e(L8,l6e),e(l6e,ybr),e(L8,xbr),e(L8,OH),e(OH,$br),e(L8,kbr),e(j,Sbr),e(j,y8),e(y8,i6e),e(i6e,Rbr),e(y8,Pbr),e(y8,VH),e(VH,Bbr),e(y8,Ibr),e(j,Nbr),e(j,x8),e(x8,d6e),e(d6e,qbr),e(x8,jbr),e(x8,XH),e(XH,Dbr),e(x8,Gbr),e(j,Obr),e(j,$8),e($8,c6e),e(c6e,Vbr),e($8,Xbr),e($8,zH),e(zH,zbr),e($8,Qbr),e(j,Wbr),e(j,k8),e(k8,f6e),e(f6e,Hbr),e(k8,Ubr),e(k8,QH),e(QH,Jbr),e(k8,Ybr),e(j,Kbr),e(j,S8),e(S8,m6e),e(m6e,Zbr),e(S8,evr),e(S8,WH),e(WH,ovr),e(S8,rvr),e(j,tvr),e(j,R8),e(R8,g6e),e(g6e,avr),e(R8,nvr),e(R8,HH),e(HH,svr),e(R8,lvr),e(j,ivr),e(j,P8),e(P8,h6e),e(h6e,dvr),e(P8,cvr),e(P8,UH),e(UH,fvr),e(P8,mvr),e(j,gvr),e(j,B8),e(B8,p6e),e(p6e,hvr),e(B8,pvr),e(B8,JH),e(JH,_vr),e(B8,uvr),e(j,bvr),e(j,I8),e(I8,_6e),e(_6e,vvr),e(I8,Fvr),e(I8,YH),e(YH,Tvr),e(I8,Mvr),e(j,Evr),e(j,N8),e(N8,u6e),e(u6e,Cvr),e(N8,wvr),e(N8,KH),e(KH,Avr),e(N8,Lvr),e(j,yvr),e(j,q8),e(q8,b6e),e(b6e,xvr),e(q8,$vr),e(q8,ZH),e(ZH,kvr),e(q8,Svr),e(j,Rvr),e(j,j8),e(j8,v6e),e(v6e,Pvr),e(j8,Bvr),e(j8,eU),e(eU,Ivr),e(j8,Nvr),e(j,qvr),e(j,D8),e(D8,F6e),e(F6e,jvr),e(D8,Dvr),e(D8,oU),e(oU,Gvr),e(D8,Ovr),e(j,Vvr),e(j,G8),e(G8,T6e),e(T6e,Xvr),e(G8,zvr),e(G8,rU),e(rU,Qvr),e(G8,Wvr),e(yr,Hvr),M(O8,yr,null),b(f,sVe,u),b(f,tc,u),e(tc,V8),e(V8,M6e),M(E9,M6e,null),e(tc,Uvr),e(tc,E6e),e(E6e,Jvr),b(f,lVe,u),b(f,or,u),M(C9,or,null),e(or,Yvr),e(or,ac),e(ac,Kvr),e(ac,tU),e(tU,Zvr),e(ac,eFr),e(ac,aU),e(aU,oFr),e(ac,rFr),e(or,tFr),e(or,w9),e(w9,aFr),e(w9,C6e),e(C6e,nFr),e(w9,sFr),e(or,lFr),e(or,kt),M(A9,kt,null),e(kt,iFr),e(kt,w6e),e(w6e,dFr),e(kt,cFr),e(kt,nc),e(nc,fFr),e(nc,A6e),e(A6e,mFr),e(nc,gFr),e(nc,nU),e(nU,hFr),e(nc,pFr),e(kt,_Fr),M(X8,kt,null),e(or,uFr),e(or,xr),M(L9,xr,null),e(xr,bFr),e(xr,L6e),e(L6e,vFr),e(xr,FFr),e(xr,nn),e(nn,TFr),e(nn,y6e),e(y6e,MFr),e(nn,EFr),e(nn,x6e),e(x6e,CFr),e(nn,wFr),e(nn,$6e),e($6e,AFr),e(nn,LFr),e(xr,yFr),e(xr,se),e(se,z8),e(z8,k6e),e(k6e,xFr),e(z8,$Fr),e(z8,sU),e(sU,kFr),e(z8,SFr),e(se,RFr),e(se,Q8),e(Q8,S6e),e(S6e,PFr),e(Q8,BFr),e(Q8,lU),e(lU,IFr),e(Q8,NFr),e(se,qFr),e(se,W8),e(W8,R6e),e(R6e,jFr),e(W8,DFr),e(W8,iU),e(iU,GFr),e(W8,OFr),e(se,VFr),e(se,H8),e(H8,P6e),e(P6e,XFr),e(H8,zFr),e(H8,dU),e(dU,QFr),e(H8,WFr),e(se,HFr),e(se,U8),e(U8,B6e),e(B6e,UFr),e(U8,JFr),e(U8,cU),e(cU,YFr),e(U8,KFr),e(se,ZFr),e(se,J8),e(J8,I6e),e(I6e,e6r),e(J8,o6r),e(J8,fU),e(fU,r6r),e(J8,t6r),e(se,a6r),e(se,Y8),e(Y8,N6e),e(N6e,n6r),e(Y8,s6r),e(Y8,mU),e(mU,l6r),e(Y8,i6r),e(se,d6r),e(se,K8),e(K8,q6e),e(q6e,c6r),e(K8,f6r),e(K8,gU),e(gU,m6r),e(K8,g6r),e(se,h6r),e(se,Z8),e(Z8,j6e),e(j6e,p6r),e(Z8,_6r),e(Z8,hU),e(hU,u6r),e(Z8,b6r),e(se,v6r),e(se,eM),e(eM,D6e),e(D6e,F6r),e(eM,T6r),e(eM,pU),e(pU,M6r),e(eM,E6r),e(se,C6r),e(se,oM),e(oM,G6e),e(G6e,w6r),e(oM,A6r),e(oM,_U),e(_U,L6r),e(oM,y6r),e(se,x6r),e(se,rM),e(rM,O6e),e(O6e,$6r),e(rM,k6r),e(rM,uU),e(uU,S6r),e(rM,R6r),e(se,P6r),e(se,tM),e(tM,V6e),e(V6e,B6r),e(tM,I6r),e(tM,bU),e(bU,N6r),e(tM,q6r),e(se,j6r),e(se,aM),e(aM,X6e),e(X6e,D6r),e(aM,G6r),e(aM,vU),e(vU,O6r),e(aM,V6r),e(se,X6r),e(se,nM),e(nM,z6e),e(z6e,z6r),e(nM,Q6r),e(nM,FU),e(FU,W6r),e(nM,H6r),e(se,U6r),e(se,sM),e(sM,Q6e),e(Q6e,J6r),e(sM,Y6r),e(sM,TU),e(TU,K6r),e(sM,Z6r),e(se,eTr),e(se,lM),e(lM,W6e),e(W6e,oTr),e(lM,rTr),e(lM,MU),e(MU,tTr),e(lM,aTr),e(se,nTr),e(se,iM),e(iM,H6e),e(H6e,sTr),e(iM,lTr),e(iM,EU),e(EU,iTr),e(iM,dTr),e(se,cTr),e(se,dM),e(dM,U6e),e(U6e,fTr),e(dM,mTr),e(dM,CU),e(CU,gTr),e(dM,hTr),e(se,pTr),e(se,cM),e(cM,J6e),e(J6e,_Tr),e(cM,uTr),e(cM,wU),e(wU,bTr),e(cM,vTr),e(se,FTr),e(se,fM),e(fM,Y6e),e(Y6e,TTr),e(fM,MTr),e(fM,AU),e(AU,ETr),e(fM,CTr),e(se,wTr),e(se,mM),e(mM,K6e),e(K6e,ATr),e(mM,LTr),e(mM,LU),e(LU,yTr),e(mM,xTr),e(se,$Tr),e(se,gM),e(gM,Z6e),e(Z6e,kTr),e(gM,STr),e(gM,yU),e(yU,RTr),e(gM,PTr),e(xr,BTr),M(hM,xr,null),b(f,iVe,u),b(f,sc,u),e(sc,pM),e(pM,eTe),M(y9,eTe,null),e(sc,ITr),e(sc,oTe),e(oTe,NTr),b(f,dVe,u),b(f,rr,u),M(x9,rr,null),e(rr,qTr),e(rr,lc),e(lc,jTr),e(lc,xU),e(xU,DTr),e(lc,GTr),e(lc,$U),e($U,OTr),e(lc,VTr),e(rr,XTr),e(rr,$9),e($9,zTr),e($9,rTe),e(rTe,QTr),e($9,WTr),e(rr,HTr),e(rr,St),M(k9,St,null),e(St,UTr),e(St,tTe),e(tTe,JTr),e(St,YTr),e(St,ic),e(ic,KTr),e(ic,aTe),e(aTe,ZTr),e(ic,e7r),e(ic,kU),e(kU,o7r),e(ic,r7r),e(St,t7r),M(_M,St,null),e(rr,a7r),e(rr,$r),M(S9,$r,null),e($r,n7r),e($r,nTe),e(nTe,s7r),e($r,l7r),e($r,sn),e(sn,i7r),e(sn,sTe),e(sTe,d7r),e(sn,c7r),e(sn,lTe),e(lTe,f7r),e(sn,m7r),e(sn,iTe),e(iTe,g7r),e(sn,h7r),e($r,p7r),e($r,Me),e(Me,uM),e(uM,dTe),e(dTe,_7r),e(uM,u7r),e(uM,SU),e(SU,b7r),e(uM,v7r),e(Me,F7r),e(Me,bM),e(bM,cTe),e(cTe,T7r),e(bM,M7r),e(bM,RU),e(RU,E7r),e(bM,C7r),e(Me,w7r),e(Me,vM),e(vM,fTe),e(fTe,A7r),e(vM,L7r),e(vM,PU),e(PU,y7r),e(vM,x7r),e(Me,$7r),e(Me,FM),e(FM,mTe),e(mTe,k7r),e(FM,S7r),e(FM,BU),e(BU,R7r),e(FM,P7r),e(Me,B7r),e(Me,TM),e(TM,gTe),e(gTe,I7r),e(TM,N7r),e(TM,IU),e(IU,q7r),e(TM,j7r),e(Me,D7r),e(Me,MM),e(MM,hTe),e(hTe,G7r),e(MM,O7r),e(MM,NU),e(NU,V7r),e(MM,X7r),e(Me,z7r),e(Me,EM),e(EM,pTe),e(pTe,Q7r),e(EM,W7r),e(EM,qU),e(qU,H7r),e(EM,U7r),e(Me,J7r),e(Me,CM),e(CM,_Te),e(_Te,Y7r),e(CM,K7r),e(CM,jU),e(jU,Z7r),e(CM,e8r),e(Me,o8r),e(Me,wM),e(wM,uTe),e(uTe,r8r),e(wM,t8r),e(wM,DU),e(DU,a8r),e(wM,n8r),e(Me,s8r),e(Me,AM),e(AM,bTe),e(bTe,l8r),e(AM,i8r),e(AM,GU),e(GU,d8r),e(AM,c8r),e(Me,f8r),e(Me,LM),e(LM,vTe),e(vTe,m8r),e(LM,g8r),e(LM,OU),e(OU,h8r),e(LM,p8r),e(Me,_8r),e(Me,yM),e(yM,FTe),e(FTe,u8r),e(yM,b8r),e(yM,VU),e(VU,v8r),e(yM,F8r),e(Me,T8r),e(Me,xM),e(xM,TTe),e(TTe,M8r),e(xM,E8r),e(xM,XU),e(XU,C8r),e(xM,w8r),e($r,A8r),M($M,$r,null),b(f,cVe,u),b(f,dc,u),e(dc,kM),e(kM,MTe),M(R9,MTe,null),e(dc,L8r),e(dc,ETe),e(ETe,y8r),b(f,fVe,u),b(f,tr,u),M(P9,tr,null),e(tr,x8r),e(tr,cc),e(cc,$8r),e(cc,zU),e(zU,k8r),e(cc,S8r),e(cc,QU),e(QU,R8r),e(cc,P8r),e(tr,B8r),e(tr,B9),e(B9,I8r),e(B9,CTe),e(CTe,N8r),e(B9,q8r),e(tr,j8r),e(tr,Rt),M(I9,Rt,null),e(Rt,D8r),e(Rt,wTe),e(wTe,G8r),e(Rt,O8r),e(Rt,fc),e(fc,V8r),e(fc,ATe),e(ATe,X8r),e(fc,z8r),e(fc,WU),e(WU,Q8r),e(fc,W8r),e(Rt,H8r),M(SM,Rt,null),e(tr,U8r),e(tr,kr),M(N9,kr,null),e(kr,J8r),e(kr,LTe),e(LTe,Y8r),e(kr,K8r),e(kr,ln),e(ln,Z8r),e(ln,yTe),e(yTe,eMr),e(ln,oMr),e(ln,xTe),e(xTe,rMr),e(ln,tMr),e(ln,$Te),e($Te,aMr),e(ln,nMr),e(kr,sMr),e(kr,dn),e(dn,RM),e(RM,kTe),e(kTe,lMr),e(RM,iMr),e(RM,HU),e(HU,dMr),e(RM,cMr),e(dn,fMr),e(dn,PM),e(PM,STe),e(STe,mMr),e(PM,gMr),e(PM,UU),e(UU,hMr),e(PM,pMr),e(dn,_Mr),e(dn,BM),e(BM,RTe),e(RTe,uMr),e(BM,bMr),e(BM,JU),e(JU,vMr),e(BM,FMr),e(dn,TMr),e(dn,IM),e(IM,PTe),e(PTe,MMr),e(IM,EMr),e(IM,YU),e(YU,CMr),e(IM,wMr),e(kr,AMr),M(NM,kr,null),b(f,mVe,u),b(f,mc,u),e(mc,qM),e(qM,BTe),M(q9,BTe,null),e(mc,LMr),e(mc,ITe),e(ITe,yMr),b(f,gVe,u),b(f,ar,u),M(j9,ar,null),e(ar,xMr),e(ar,gc),e(gc,$Mr),e(gc,KU),e(KU,kMr),e(gc,SMr),e(gc,ZU),e(ZU,RMr),e(gc,PMr),e(ar,BMr),e(ar,D9),e(D9,IMr),e(D9,NTe),e(NTe,NMr),e(D9,qMr),e(ar,jMr),e(ar,Pt),M(G9,Pt,null),e(Pt,DMr),e(Pt,qTe),e(qTe,GMr),e(Pt,OMr),e(Pt,hc),e(hc,VMr),e(hc,jTe),e(jTe,XMr),e(hc,zMr),e(hc,eJ),e(eJ,QMr),e(hc,WMr),e(Pt,HMr),M(jM,Pt,null),e(ar,UMr),e(ar,Sr),M(O9,Sr,null),e(Sr,JMr),e(Sr,DTe),e(DTe,YMr),e(Sr,KMr),e(Sr,cn),e(cn,ZMr),e(cn,GTe),e(GTe,eEr),e(cn,oEr),e(cn,OTe),e(OTe,rEr),e(cn,tEr),e(cn,VTe),e(VTe,aEr),e(cn,nEr),e(Sr,sEr),e(Sr,ie),e(ie,DM),e(DM,XTe),e(XTe,lEr),e(DM,iEr),e(DM,oJ),e(oJ,dEr),e(DM,cEr),e(ie,fEr),e(ie,GM),e(GM,zTe),e(zTe,mEr),e(GM,gEr),e(GM,rJ),e(rJ,hEr),e(GM,pEr),e(ie,_Er),e(ie,OM),e(OM,QTe),e(QTe,uEr),e(OM,bEr),e(OM,tJ),e(tJ,vEr),e(OM,FEr),e(ie,TEr),e(ie,VM),e(VM,WTe),e(WTe,MEr),e(VM,EEr),e(VM,aJ),e(aJ,CEr),e(VM,wEr),e(ie,AEr),e(ie,XM),e(XM,HTe),e(HTe,LEr),e(XM,yEr),e(XM,nJ),e(nJ,xEr),e(XM,$Er),e(ie,kEr),e(ie,zM),e(zM,UTe),e(UTe,SEr),e(zM,REr),e(zM,sJ),e(sJ,PEr),e(zM,BEr),e(ie,IEr),e(ie,QM),e(QM,JTe),e(JTe,NEr),e(QM,qEr),e(QM,lJ),e(lJ,jEr),e(QM,DEr),e(ie,GEr),e(ie,WM),e(WM,YTe),e(YTe,OEr),e(WM,VEr),e(WM,iJ),e(iJ,XEr),e(WM,zEr),e(ie,QEr),e(ie,HM),e(HM,KTe),e(KTe,WEr),e(HM,HEr),e(HM,dJ),e(dJ,UEr),e(HM,JEr),e(ie,YEr),e(ie,UM),e(UM,ZTe),e(ZTe,KEr),e(UM,ZEr),e(UM,cJ),e(cJ,e4r),e(UM,o4r),e(ie,r4r),e(ie,JM),e(JM,e7e),e(e7e,t4r),e(JM,a4r),e(JM,fJ),e(fJ,n4r),e(JM,s4r),e(ie,l4r),e(ie,YM),e(YM,o7e),e(o7e,i4r),e(YM,d4r),e(YM,mJ),e(mJ,c4r),e(YM,f4r),e(ie,m4r),e(ie,KM),e(KM,r7e),e(r7e,g4r),e(KM,h4r),e(KM,gJ),e(gJ,p4r),e(KM,_4r),e(ie,u4r),e(ie,ZM),e(ZM,t7e),e(t7e,b4r),e(ZM,v4r),e(ZM,hJ),e(hJ,F4r),e(ZM,T4r),e(ie,M4r),e(ie,eE),e(eE,a7e),e(a7e,E4r),e(eE,C4r),e(eE,pJ),e(pJ,w4r),e(eE,A4r),e(ie,L4r),e(ie,oE),e(oE,n7e),e(n7e,y4r),e(oE,x4r),e(oE,_J),e(_J,$4r),e(oE,k4r),e(ie,S4r),e(ie,rE),e(rE,s7e),e(s7e,R4r),e(rE,P4r),e(rE,uJ),e(uJ,B4r),e(rE,I4r),e(ie,N4r),e(ie,tE),e(tE,l7e),e(l7e,q4r),e(tE,j4r),e(tE,bJ),e(bJ,D4r),e(tE,G4r),e(ie,O4r),e(ie,aE),e(aE,i7e),e(i7e,V4r),e(aE,X4r),e(aE,vJ),e(vJ,z4r),e(aE,Q4r),e(ie,W4r),e(ie,nE),e(nE,d7e),e(d7e,H4r),e(nE,U4r),e(nE,FJ),e(FJ,J4r),e(nE,Y4r),e(Sr,K4r),M(sE,Sr,null),b(f,hVe,u),b(f,pc,u),e(pc,lE),e(lE,c7e),M(V9,c7e,null),e(pc,Z4r),e(pc,f7e),e(f7e,eCr),b(f,pVe,u),b(f,nr,u),M(X9,nr,null),e(nr,oCr),e(nr,_c),e(_c,rCr),e(_c,TJ),e(TJ,tCr),e(_c,aCr),e(_c,MJ),e(MJ,nCr),e(_c,sCr),e(nr,lCr),e(nr,z9),e(z9,iCr),e(z9,m7e),e(m7e,dCr),e(z9,cCr),e(nr,fCr),e(nr,Bt),M(Q9,Bt,null),e(Bt,mCr),e(Bt,g7e),e(g7e,gCr),e(Bt,hCr),e(Bt,uc),e(uc,pCr),e(uc,h7e),e(h7e,_Cr),e(uc,uCr),e(uc,EJ),e(EJ,bCr),e(uc,vCr),e(Bt,FCr),M(iE,Bt,null),e(nr,TCr),e(nr,Rr),M(W9,Rr,null),e(Rr,MCr),e(Rr,p7e),e(p7e,ECr),e(Rr,CCr),e(Rr,fn),e(fn,wCr),e(fn,_7e),e(_7e,ACr),e(fn,LCr),e(fn,u7e),e(u7e,yCr),e(fn,xCr),e(fn,b7e),e(b7e,$Cr),e(fn,kCr),e(Rr,SCr),e(Rr,ye),e(ye,dE),e(dE,v7e),e(v7e,RCr),e(dE,PCr),e(dE,CJ),e(CJ,BCr),e(dE,ICr),e(ye,NCr),e(ye,cE),e(cE,F7e),e(F7e,qCr),e(cE,jCr),e(cE,wJ),e(wJ,DCr),e(cE,GCr),e(ye,OCr),e(ye,fE),e(fE,T7e),e(T7e,VCr),e(fE,XCr),e(fE,AJ),e(AJ,zCr),e(fE,QCr),e(ye,WCr),e(ye,mE),e(mE,M7e),e(M7e,HCr),e(mE,UCr),e(mE,LJ),e(LJ,JCr),e(mE,YCr),e(ye,KCr),e(ye,gE),e(gE,E7e),e(E7e,ZCr),e(gE,e5r),e(gE,yJ),e(yJ,o5r),e(gE,r5r),e(ye,t5r),e(ye,hE),e(hE,C7e),e(C7e,a5r),e(hE,n5r),e(hE,xJ),e(xJ,s5r),e(hE,l5r),e(ye,i5r),e(ye,pE),e(pE,w7e),e(w7e,d5r),e(pE,c5r),e(pE,$J),e($J,f5r),e(pE,m5r),e(ye,g5r),e(ye,_E),e(_E,A7e),e(A7e,h5r),e(_E,p5r),e(_E,kJ),e(kJ,_5r),e(_E,u5r),e(ye,b5r),e(ye,uE),e(uE,L7e),e(L7e,v5r),e(uE,F5r),e(uE,SJ),e(SJ,T5r),e(uE,M5r),e(ye,E5r),e(ye,bE),e(bE,y7e),e(y7e,C5r),e(bE,w5r),e(bE,RJ),e(RJ,A5r),e(bE,L5r),e(Rr,y5r),M(vE,Rr,null),b(f,_Ve,u),b(f,bc,u),e(bc,FE),e(FE,x7e),M(H9,x7e,null),e(bc,x5r),e(bc,$7e),e($7e,$5r),b(f,uVe,u),b(f,sr,u),M(U9,sr,null),e(sr,k5r),e(sr,vc),e(vc,S5r),e(vc,PJ),e(PJ,R5r),e(vc,P5r),e(vc,BJ),e(BJ,B5r),e(vc,I5r),e(sr,N5r),e(sr,J9),e(J9,q5r),e(J9,k7e),e(k7e,j5r),e(J9,D5r),e(sr,G5r),e(sr,It),M(Y9,It,null),e(It,O5r),e(It,S7e),e(S7e,V5r),e(It,X5r),e(It,Fc),e(Fc,z5r),e(Fc,R7e),e(R7e,Q5r),e(Fc,W5r),e(Fc,IJ),e(IJ,H5r),e(Fc,U5r),e(It,J5r),M(TE,It,null),e(sr,Y5r),e(sr,Pr),M(K9,Pr,null),e(Pr,K5r),e(Pr,P7e),e(P7e,Z5r),e(Pr,e3r),e(Pr,mn),e(mn,o3r),e(mn,B7e),e(B7e,r3r),e(mn,t3r),e(mn,I7e),e(I7e,a3r),e(mn,n3r),e(mn,N7e),e(N7e,s3r),e(mn,l3r),e(Pr,i3r),e(Pr,te),e(te,ME),e(ME,q7e),e(q7e,d3r),e(ME,c3r),e(ME,NJ),e(NJ,f3r),e(ME,m3r),e(te,g3r),e(te,EE),e(EE,j7e),e(j7e,h3r),e(EE,p3r),e(EE,qJ),e(qJ,_3r),e(EE,u3r),e(te,b3r),e(te,CE),e(CE,D7e),e(D7e,v3r),e(CE,F3r),e(CE,jJ),e(jJ,T3r),e(CE,M3r),e(te,E3r),e(te,wE),e(wE,G7e),e(G7e,C3r),e(wE,w3r),e(wE,DJ),e(DJ,A3r),e(wE,L3r),e(te,y3r),e(te,AE),e(AE,O7e),e(O7e,x3r),e(AE,$3r),e(AE,GJ),e(GJ,k3r),e(AE,S3r),e(te,R3r),e(te,LE),e(LE,V7e),e(V7e,P3r),e(LE,B3r),e(LE,OJ),e(OJ,I3r),e(LE,N3r),e(te,q3r),e(te,yE),e(yE,X7e),e(X7e,j3r),e(yE,D3r),e(yE,VJ),e(VJ,G3r),e(yE,O3r),e(te,V3r),e(te,xE),e(xE,z7e),e(z7e,X3r),e(xE,z3r),e(xE,XJ),e(XJ,Q3r),e(xE,W3r),e(te,H3r),e(te,$E),e($E,Q7e),e(Q7e,U3r),e($E,J3r),e($E,zJ),e(zJ,Y3r),e($E,K3r),e(te,Z3r),e(te,kE),e(kE,W7e),e(W7e,e0r),e(kE,o0r),e(kE,QJ),e(QJ,r0r),e(kE,t0r),e(te,a0r),e(te,SE),e(SE,H7e),e(H7e,n0r),e(SE,s0r),e(SE,WJ),e(WJ,l0r),e(SE,i0r),e(te,d0r),e(te,RE),e(RE,U7e),e(U7e,c0r),e(RE,f0r),e(RE,HJ),e(HJ,m0r),e(RE,g0r),e(te,h0r),e(te,PE),e(PE,J7e),e(J7e,p0r),e(PE,_0r),e(PE,UJ),e(UJ,u0r),e(PE,b0r),e(te,v0r),e(te,BE),e(BE,Y7e),e(Y7e,F0r),e(BE,T0r),e(BE,JJ),e(JJ,M0r),e(BE,E0r),e(te,C0r),e(te,IE),e(IE,K7e),e(K7e,w0r),e(IE,A0r),e(IE,YJ),e(YJ,L0r),e(IE,y0r),e(te,x0r),e(te,NE),e(NE,Z7e),e(Z7e,$0r),e(NE,k0r),e(NE,KJ),e(KJ,S0r),e(NE,R0r),e(te,P0r),e(te,qE),e(qE,e8e),e(e8e,B0r),e(qE,I0r),e(qE,ZJ),e(ZJ,N0r),e(qE,q0r),e(te,j0r),e(te,jE),e(jE,o8e),e(o8e,D0r),e(jE,G0r),e(jE,eY),e(eY,O0r),e(jE,V0r),e(te,X0r),e(te,DE),e(DE,r8e),e(r8e,z0r),e(DE,Q0r),e(DE,oY),e(oY,W0r),e(DE,H0r),e(te,U0r),e(te,GE),e(GE,t8e),e(t8e,J0r),e(GE,Y0r),e(GE,rY),e(rY,K0r),e(GE,Z0r),e(te,ewr),e(te,OE),e(OE,a8e),e(a8e,owr),e(OE,rwr),e(OE,tY),e(tY,twr),e(OE,awr),e(te,nwr),e(te,VE),e(VE,n8e),e(n8e,swr),e(VE,lwr),e(VE,aY),e(aY,iwr),e(VE,dwr),e(te,cwr),e(te,XE),e(XE,s8e),e(s8e,fwr),e(XE,mwr),e(XE,nY),e(nY,gwr),e(XE,hwr),e(te,pwr),e(te,zE),e(zE,l8e),e(l8e,_wr),e(zE,uwr),e(zE,sY),e(sY,bwr),e(zE,vwr),e(te,Fwr),e(te,QE),e(QE,i8e),e(i8e,Twr),e(QE,Mwr),e(QE,lY),e(lY,Ewr),e(QE,Cwr),e(te,wwr),e(te,WE),e(WE,d8e),e(d8e,Awr),e(WE,Lwr),e(WE,iY),e(iY,ywr),e(WE,xwr),e(Pr,$wr),M(HE,Pr,null),b(f,bVe,u),b(f,Tc,u),e(Tc,UE),e(UE,c8e),M(Z9,c8e,null),e(Tc,kwr),e(Tc,f8e),e(f8e,Swr),b(f,vVe,u),b(f,lr,u),M(ex,lr,null),e(lr,Rwr),e(lr,Mc),e(Mc,Pwr),e(Mc,dY),e(dY,Bwr),e(Mc,Iwr),e(Mc,cY),e(cY,Nwr),e(Mc,qwr),e(lr,jwr),e(lr,ox),e(ox,Dwr),e(ox,m8e),e(m8e,Gwr),e(ox,Owr),e(lr,Vwr),e(lr,Nt),M(rx,Nt,null),e(Nt,Xwr),e(Nt,g8e),e(g8e,zwr),e(Nt,Qwr),e(Nt,Ec),e(Ec,Wwr),e(Ec,h8e),e(h8e,Hwr),e(Ec,Uwr),e(Ec,fY),e(fY,Jwr),e(Ec,Ywr),e(Nt,Kwr),M(JE,Nt,null),e(lr,Zwr),e(lr,Br),M(tx,Br,null),e(Br,eAr),e(Br,p8e),e(p8e,oAr),e(Br,rAr),e(Br,gn),e(gn,tAr),e(gn,_8e),e(_8e,aAr),e(gn,nAr),e(gn,u8e),e(u8e,sAr),e(gn,lAr),e(gn,b8e),e(b8e,iAr),e(gn,dAr),e(Br,cAr),e(Br,_e),e(_e,YE),e(YE,v8e),e(v8e,fAr),e(YE,mAr),e(YE,mY),e(mY,gAr),e(YE,hAr),e(_e,pAr),e(_e,KE),e(KE,F8e),e(F8e,_Ar),e(KE,uAr),e(KE,gY),e(gY,bAr),e(KE,vAr),e(_e,FAr),e(_e,ZE),e(ZE,T8e),e(T8e,TAr),e(ZE,MAr),e(ZE,hY),e(hY,EAr),e(ZE,CAr),e(_e,wAr),e(_e,e4),e(e4,M8e),e(M8e,AAr),e(e4,LAr),e(e4,pY),e(pY,yAr),e(e4,xAr),e(_e,$Ar),e(_e,o4),e(o4,E8e),e(E8e,kAr),e(o4,SAr),e(o4,_Y),e(_Y,RAr),e(o4,PAr),e(_e,BAr),e(_e,r4),e(r4,C8e),e(C8e,IAr),e(r4,NAr),e(r4,uY),e(uY,qAr),e(r4,jAr),e(_e,DAr),e(_e,t4),e(t4,w8e),e(w8e,GAr),e(t4,OAr),e(t4,bY),e(bY,VAr),e(t4,XAr),e(_e,zAr),e(_e,a4),e(a4,A8e),e(A8e,QAr),e(a4,WAr),e(a4,vY),e(vY,HAr),e(a4,UAr),e(_e,JAr),e(_e,n4),e(n4,L8e),e(L8e,YAr),e(n4,KAr),e(n4,FY),e(FY,ZAr),e(n4,eLr),e(_e,oLr),e(_e,s4),e(s4,y8e),e(y8e,rLr),e(s4,tLr),e(s4,TY),e(TY,aLr),e(s4,nLr),e(_e,sLr),e(_e,l4),e(l4,x8e),e(x8e,lLr),e(l4,iLr),e(l4,MY),e(MY,dLr),e(l4,cLr),e(_e,fLr),e(_e,i4),e(i4,$8e),e($8e,mLr),e(i4,gLr),e(i4,EY),e(EY,hLr),e(i4,pLr),e(_e,_Lr),e(_e,d4),e(d4,k8e),e(k8e,uLr),e(d4,bLr),e(d4,CY),e(CY,vLr),e(d4,FLr),e(_e,TLr),e(_e,c4),e(c4,S8e),e(S8e,MLr),e(c4,ELr),e(c4,wY),e(wY,CLr),e(c4,wLr),e(_e,ALr),e(_e,f4),e(f4,R8e),e(R8e,LLr),e(f4,yLr),e(f4,AY),e(AY,xLr),e(f4,$Lr),e(_e,kLr),e(_e,m4),e(m4,P8e),e(P8e,SLr),e(m4,RLr),e(m4,LY),e(LY,PLr),e(m4,BLr),e(_e,ILr),e(_e,g4),e(g4,B8e),e(B8e,NLr),e(g4,qLr),e(g4,yY),e(yY,jLr),e(g4,DLr),e(Br,GLr),M(h4,Br,null),b(f,FVe,u),b(f,Cc,u),e(Cc,p4),e(p4,I8e),M(ax,I8e,null),e(Cc,OLr),e(Cc,N8e),e(N8e,VLr),b(f,TVe,u),b(f,ir,u),M(nx,ir,null),e(ir,XLr),e(ir,wc),e(wc,zLr),e(wc,xY),e(xY,QLr),e(wc,WLr),e(wc,$Y),e($Y,HLr),e(wc,ULr),e(ir,JLr),e(ir,sx),e(sx,YLr),e(sx,q8e),e(q8e,KLr),e(sx,ZLr),e(ir,eyr),e(ir,qt),M(lx,qt,null),e(qt,oyr),e(qt,j8e),e(j8e,ryr),e(qt,tyr),e(qt,Ac),e(Ac,ayr),e(Ac,D8e),e(D8e,nyr),e(Ac,syr),e(Ac,kY),e(kY,lyr),e(Ac,iyr),e(qt,dyr),M(_4,qt,null),e(ir,cyr),e(ir,Ir),M(ix,Ir,null),e(Ir,fyr),e(Ir,G8e),e(G8e,myr),e(Ir,gyr),e(Ir,hn),e(hn,hyr),e(hn,O8e),e(O8e,pyr),e(hn,_yr),e(hn,V8e),e(V8e,uyr),e(hn,byr),e(hn,X8e),e(X8e,vyr),e(hn,Fyr),e(Ir,Tyr),e(Ir,dx),e(dx,u4),e(u4,z8e),e(z8e,Myr),e(u4,Eyr),e(u4,SY),e(SY,Cyr),e(u4,wyr),e(dx,Ayr),e(dx,b4),e(b4,Q8e),e(Q8e,Lyr),e(b4,yyr),e(b4,RY),e(RY,xyr),e(b4,$yr),e(Ir,kyr),M(v4,Ir,null),b(f,MVe,u),b(f,Lc,u),e(Lc,F4),e(F4,W8e),M(cx,W8e,null),e(Lc,Syr),e(Lc,H8e),e(H8e,Ryr),b(f,EVe,u),b(f,dr,u),M(fx,dr,null),e(dr,Pyr),e(dr,yc),e(yc,Byr),e(yc,PY),e(PY,Iyr),e(yc,Nyr),e(yc,BY),e(BY,qyr),e(yc,jyr),e(dr,Dyr),e(dr,mx),e(mx,Gyr),e(mx,U8e),e(U8e,Oyr),e(mx,Vyr),e(dr,Xyr),e(dr,jt),M(gx,jt,null),e(jt,zyr),e(jt,J8e),e(J8e,Qyr),e(jt,Wyr),e(jt,xc),e(xc,Hyr),e(xc,Y8e),e(Y8e,Uyr),e(xc,Jyr),e(xc,IY),e(IY,Yyr),e(xc,Kyr),e(jt,Zyr),M(T4,jt,null),e(dr,e9r),e(dr,Nr),M(hx,Nr,null),e(Nr,o9r),e(Nr,K8e),e(K8e,r9r),e(Nr,t9r),e(Nr,pn),e(pn,a9r),e(pn,Z8e),e(Z8e,n9r),e(pn,s9r),e(pn,eMe),e(eMe,l9r),e(pn,i9r),e(pn,oMe),e(oMe,d9r),e(pn,c9r),e(Nr,f9r),e(Nr,rMe),e(rMe,M4),e(M4,tMe),e(tMe,m9r),e(M4,g9r),e(M4,NY),e(NY,h9r),e(M4,p9r),e(Nr,_9r),M(E4,Nr,null),b(f,CVe,u),b(f,$c,u),e($c,C4),e(C4,aMe),M(px,aMe,null),e($c,u9r),e($c,nMe),e(nMe,b9r),b(f,wVe,u),b(f,cr,u),M(_x,cr,null),e(cr,v9r),e(cr,kc),e(kc,F9r),e(kc,qY),e(qY,T9r),e(kc,M9r),e(kc,jY),e(jY,E9r),e(kc,C9r),e(cr,w9r),e(cr,ux),e(ux,A9r),e(ux,sMe),e(sMe,L9r),e(ux,y9r),e(cr,x9r),e(cr,Dt),M(bx,Dt,null),e(Dt,$9r),e(Dt,lMe),e(lMe,k9r),e(Dt,S9r),e(Dt,Sc),e(Sc,R9r),e(Sc,iMe),e(iMe,P9r),e(Sc,B9r),e(Sc,DY),e(DY,I9r),e(Sc,N9r),e(Dt,q9r),M(w4,Dt,null),e(cr,j9r),e(cr,qr),M(vx,qr,null),e(qr,D9r),e(qr,dMe),e(dMe,G9r),e(qr,O9r),e(qr,_n),e(_n,V9r),e(_n,cMe),e(cMe,X9r),e(_n,z9r),e(_n,fMe),e(fMe,Q9r),e(_n,W9r),e(_n,mMe),e(mMe,H9r),e(_n,U9r),e(qr,J9r),e(qr,de),e(de,A4),e(A4,gMe),e(gMe,Y9r),e(A4,K9r),e(A4,GY),e(GY,Z9r),e(A4,exr),e(de,oxr),e(de,L4),e(L4,hMe),e(hMe,rxr),e(L4,txr),e(L4,OY),e(OY,axr),e(L4,nxr),e(de,sxr),e(de,y4),e(y4,pMe),e(pMe,lxr),e(y4,ixr),e(y4,VY),e(VY,dxr),e(y4,cxr),e(de,fxr),e(de,x4),e(x4,_Me),e(_Me,mxr),e(x4,gxr),e(x4,XY),e(XY,hxr),e(x4,pxr),e(de,_xr),e(de,$4),e($4,uMe),e(uMe,uxr),e($4,bxr),e($4,zY),e(zY,vxr),e($4,Fxr),e(de,Txr),e(de,k4),e(k4,bMe),e(bMe,Mxr),e(k4,Exr),e(k4,QY),e(QY,Cxr),e(k4,wxr),e(de,Axr),e(de,S4),e(S4,vMe),e(vMe,Lxr),e(S4,yxr),e(S4,WY),e(WY,xxr),e(S4,$xr),e(de,kxr),e(de,R4),e(R4,FMe),e(FMe,Sxr),e(R4,Rxr),e(R4,HY),e(HY,Pxr),e(R4,Bxr),e(de,Ixr),e(de,P4),e(P4,TMe),e(TMe,Nxr),e(P4,qxr),e(P4,UY),e(UY,jxr),e(P4,Dxr),e(de,Gxr),e(de,B4),e(B4,MMe),e(MMe,Oxr),e(B4,Vxr),e(B4,JY),e(JY,Xxr),e(B4,zxr),e(de,Qxr),e(de,I4),e(I4,EMe),e(EMe,Wxr),e(I4,Hxr),e(I4,YY),e(YY,Uxr),e(I4,Jxr),e(de,Yxr),e(de,N4),e(N4,CMe),e(CMe,Kxr),e(N4,Zxr),e(N4,KY),e(KY,e$r),e(N4,o$r),e(de,r$r),e(de,q4),e(q4,wMe),e(wMe,t$r),e(q4,a$r),e(q4,ZY),e(ZY,n$r),e(q4,s$r),e(de,l$r),e(de,j4),e(j4,AMe),e(AMe,i$r),e(j4,d$r),e(j4,eK),e(eK,c$r),e(j4,f$r),e(de,m$r),e(de,D4),e(D4,LMe),e(LMe,g$r),e(D4,h$r),e(D4,oK),e(oK,p$r),e(D4,_$r),e(de,u$r),e(de,G4),e(G4,yMe),e(yMe,b$r),e(G4,v$r),e(G4,rK),e(rK,F$r),e(G4,T$r),e(de,M$r),e(de,O4),e(O4,xMe),e(xMe,E$r),e(O4,C$r),e(O4,tK),e(tK,w$r),e(O4,A$r),e(de,L$r),e(de,V4),e(V4,$Me),e($Me,y$r),e(V4,x$r),e(V4,aK),e(aK,$$r),e(V4,k$r),e(de,S$r),e(de,X4),e(X4,kMe),e(kMe,R$r),e(X4,P$r),e(X4,nK),e(nK,B$r),e(X4,I$r),e(de,N$r),e(de,z4),e(z4,SMe),e(SMe,q$r),e(z4,j$r),e(z4,sK),e(sK,D$r),e(z4,G$r),e(qr,O$r),M(Q4,qr,null),b(f,AVe,u),b(f,Rc,u),e(Rc,W4),e(W4,RMe),M(Fx,RMe,null),e(Rc,V$r),e(Rc,PMe),e(PMe,X$r),b(f,LVe,u),b(f,fr,u),M(Tx,fr,null),e(fr,z$r),e(fr,Pc),e(Pc,Q$r),e(Pc,lK),e(lK,W$r),e(Pc,H$r),e(Pc,iK),e(iK,U$r),e(Pc,J$r),e(fr,Y$r),e(fr,Mx),e(Mx,K$r),e(Mx,BMe),e(BMe,Z$r),e(Mx,ekr),e(fr,okr),e(fr,Gt),M(Ex,Gt,null),e(Gt,rkr),e(Gt,IMe),e(IMe,tkr),e(Gt,akr),e(Gt,Bc),e(Bc,nkr),e(Bc,NMe),e(NMe,skr),e(Bc,lkr),e(Bc,dK),e(dK,ikr),e(Bc,dkr),e(Gt,ckr),M(H4,Gt,null),e(fr,fkr),e(fr,jr),M(Cx,jr,null),e(jr,mkr),e(jr,qMe),e(qMe,gkr),e(jr,hkr),e(jr,un),e(un,pkr),e(un,jMe),e(jMe,_kr),e(un,ukr),e(un,DMe),e(DMe,bkr),e(un,vkr),e(un,GMe),e(GMe,Fkr),e(un,Tkr),e(jr,Mkr),e(jr,ce),e(ce,U4),e(U4,OMe),e(OMe,Ekr),e(U4,Ckr),e(U4,cK),e(cK,wkr),e(U4,Akr),e(ce,Lkr),e(ce,J4),e(J4,VMe),e(VMe,ykr),e(J4,xkr),e(J4,fK),e(fK,$kr),e(J4,kkr),e(ce,Skr),e(ce,Y4),e(Y4,XMe),e(XMe,Rkr),e(Y4,Pkr),e(Y4,mK),e(mK,Bkr),e(Y4,Ikr),e(ce,Nkr),e(ce,K4),e(K4,zMe),e(zMe,qkr),e(K4,jkr),e(K4,gK),e(gK,Dkr),e(K4,Gkr),e(ce,Okr),e(ce,Z4),e(Z4,QMe),e(QMe,Vkr),e(Z4,Xkr),e(Z4,hK),e(hK,zkr),e(Z4,Qkr),e(ce,Wkr),e(ce,eC),e(eC,WMe),e(WMe,Hkr),e(eC,Ukr),e(eC,pK),e(pK,Jkr),e(eC,Ykr),e(ce,Kkr),e(ce,oC),e(oC,HMe),e(HMe,Zkr),e(oC,eSr),e(oC,_K),e(_K,oSr),e(oC,rSr),e(ce,tSr),e(ce,rC),e(rC,UMe),e(UMe,aSr),e(rC,nSr),e(rC,uK),e(uK,sSr),e(rC,lSr),e(ce,iSr),e(ce,tC),e(tC,JMe),e(JMe,dSr),e(tC,cSr),e(tC,bK),e(bK,fSr),e(tC,mSr),e(ce,gSr),e(ce,aC),e(aC,YMe),e(YMe,hSr),e(aC,pSr),e(aC,vK),e(vK,_Sr),e(aC,uSr),e(ce,bSr),e(ce,nC),e(nC,KMe),e(KMe,vSr),e(nC,FSr),e(nC,FK),e(FK,TSr),e(nC,MSr),e(ce,ESr),e(ce,sC),e(sC,ZMe),e(ZMe,CSr),e(sC,wSr),e(sC,TK),e(TK,ASr),e(sC,LSr),e(ce,ySr),e(ce,lC),e(lC,eEe),e(eEe,xSr),e(lC,$Sr),e(lC,MK),e(MK,kSr),e(lC,SSr),e(ce,RSr),e(ce,iC),e(iC,oEe),e(oEe,PSr),e(iC,BSr),e(iC,EK),e(EK,ISr),e(iC,NSr),e(ce,qSr),e(ce,dC),e(dC,rEe),e(rEe,jSr),e(dC,DSr),e(dC,CK),e(CK,GSr),e(dC,OSr),e(ce,VSr),e(ce,cC),e(cC,tEe),e(tEe,XSr),e(cC,zSr),e(cC,wK),e(wK,QSr),e(cC,WSr),e(ce,HSr),e(ce,fC),e(fC,aEe),e(aEe,USr),e(fC,JSr),e(fC,AK),e(AK,YSr),e(fC,KSr),e(ce,ZSr),e(ce,mC),e(mC,nEe),e(nEe,eRr),e(mC,oRr),e(mC,LK),e(LK,rRr),e(mC,tRr),e(ce,aRr),e(ce,gC),e(gC,sEe),e(sEe,nRr),e(gC,sRr),e(gC,yK),e(yK,lRr),e(gC,iRr),e(ce,dRr),e(ce,hC),e(hC,lEe),e(lEe,cRr),e(hC,fRr),e(hC,xK),e(xK,mRr),e(hC,gRr),e(jr,hRr),M(pC,jr,null),b(f,yVe,u),b(f,Ic,u),e(Ic,_C),e(_C,iEe),M(wx,iEe,null),e(Ic,pRr),e(Ic,dEe),e(dEe,_Rr),b(f,xVe,u),b(f,mr,u),M(Ax,mr,null),e(mr,uRr),e(mr,Nc),e(Nc,bRr),e(Nc,$K),e($K,vRr),e(Nc,FRr),e(Nc,kK),e(kK,TRr),e(Nc,MRr),e(mr,ERr),e(mr,Lx),e(Lx,CRr),e(Lx,cEe),e(cEe,wRr),e(Lx,ARr),e(mr,LRr),e(mr,Ot),M(yx,Ot,null),e(Ot,yRr),e(Ot,fEe),e(fEe,xRr),e(Ot,$Rr),e(Ot,qc),e(qc,kRr),e(qc,mEe),e(mEe,SRr),e(qc,RRr),e(qc,SK),e(SK,PRr),e(qc,BRr),e(Ot,IRr),M(uC,Ot,null),e(mr,NRr),e(mr,Dr),M(xx,Dr,null),e(Dr,qRr),e(Dr,gEe),e(gEe,jRr),e(Dr,DRr),e(Dr,bn),e(bn,GRr),e(bn,hEe),e(hEe,ORr),e(bn,VRr),e(bn,pEe),e(pEe,XRr),e(bn,zRr),e(bn,_Ee),e(_Ee,QRr),e(bn,WRr),e(Dr,HRr),e(Dr,uEe),e(uEe,bC),e(bC,bEe),e(bEe,URr),e(bC,JRr),e(bC,RK),e(RK,YRr),e(bC,KRr),e(Dr,ZRr),M(vC,Dr,null),b(f,$Ve,u),b(f,jc,u),e(jc,FC),e(FC,vEe),M($x,vEe,null),e(jc,ePr),e(jc,FEe),e(FEe,oPr),b(f,kVe,u),b(f,gr,u),M(kx,gr,null),e(gr,rPr),e(gr,Dc),e(Dc,tPr),e(Dc,PK),e(PK,aPr),e(Dc,nPr),e(Dc,BK),e(BK,sPr),e(Dc,lPr),e(gr,iPr),e(gr,Sx),e(Sx,dPr),e(Sx,TEe),e(TEe,cPr),e(Sx,fPr),e(gr,mPr),e(gr,Vt),M(Rx,Vt,null),e(Vt,gPr),e(Vt,MEe),e(MEe,hPr),e(Vt,pPr),e(Vt,Gc),e(Gc,_Pr),e(Gc,EEe),e(EEe,uPr),e(Gc,bPr),e(Gc,IK),e(IK,vPr),e(Gc,FPr),e(Vt,TPr),M(TC,Vt,null),e(gr,MPr),e(gr,Gr),M(Px,Gr,null),e(Gr,EPr),e(Gr,CEe),e(CEe,CPr),e(Gr,wPr),e(Gr,vn),e(vn,APr),e(vn,wEe),e(wEe,LPr),e(vn,yPr),e(vn,AEe),e(AEe,xPr),e(vn,$Pr),e(vn,LEe),e(LEe,kPr),e(vn,SPr),e(Gr,RPr),e(Gr,yEe),e(yEe,MC),e(MC,xEe),e(xEe,PPr),e(MC,BPr),e(MC,NK),e(NK,IPr),e(MC,NPr),e(Gr,qPr),M(EC,Gr,null),b(f,SVe,u),b(f,Oc,u),e(Oc,CC),e(CC,$Ee),M(Bx,$Ee,null),e(Oc,jPr),e(Oc,kEe),e(kEe,DPr),b(f,RVe,u),b(f,hr,u),M(Ix,hr,null),e(hr,GPr),e(hr,Vc),e(Vc,OPr),e(Vc,qK),e(qK,VPr),e(Vc,XPr),e(Vc,jK),e(jK,zPr),e(Vc,QPr),e(hr,WPr),e(hr,Nx),e(Nx,HPr),e(Nx,SEe),e(SEe,UPr),e(Nx,JPr),e(hr,YPr),e(hr,Xt),M(qx,Xt,null),e(Xt,KPr),e(Xt,REe),e(REe,ZPr),e(Xt,eBr),e(Xt,Xc),e(Xc,oBr),e(Xc,PEe),e(PEe,rBr),e(Xc,tBr),e(Xc,DK),e(DK,aBr),e(Xc,nBr),e(Xt,sBr),M(wC,Xt,null),e(hr,lBr),e(hr,Or),M(jx,Or,null),e(Or,iBr),e(Or,BEe),e(BEe,dBr),e(Or,cBr),e(Or,Fn),e(Fn,fBr),e(Fn,IEe),e(IEe,mBr),e(Fn,gBr),e(Fn,NEe),e(NEe,hBr),e(Fn,pBr),e(Fn,qEe),e(qEe,_Br),e(Fn,uBr),e(Or,bBr),e(Or,oe),e(oe,AC),e(AC,jEe),e(jEe,vBr),e(AC,FBr),e(AC,GK),e(GK,TBr),e(AC,MBr),e(oe,EBr),e(oe,LC),e(LC,DEe),e(DEe,CBr),e(LC,wBr),e(LC,OK),e(OK,ABr),e(LC,LBr),e(oe,yBr),e(oe,yC),e(yC,GEe),e(GEe,xBr),e(yC,$Br),e(yC,VK),e(VK,kBr),e(yC,SBr),e(oe,RBr),e(oe,xC),e(xC,OEe),e(OEe,PBr),e(xC,BBr),e(xC,XK),e(XK,IBr),e(xC,NBr),e(oe,qBr),e(oe,$C),e($C,VEe),e(VEe,jBr),e($C,DBr),e($C,zK),e(zK,GBr),e($C,OBr),e(oe,VBr),e(oe,kC),e(kC,XEe),e(XEe,XBr),e(kC,zBr),e(kC,QK),e(QK,QBr),e(kC,WBr),e(oe,HBr),e(oe,SC),e(SC,zEe),e(zEe,UBr),e(SC,JBr),e(SC,WK),e(WK,YBr),e(SC,KBr),e(oe,ZBr),e(oe,RC),e(RC,QEe),e(QEe,eIr),e(RC,oIr),e(RC,HK),e(HK,rIr),e(RC,tIr),e(oe,aIr),e(oe,PC),e(PC,WEe),e(WEe,nIr),e(PC,sIr),e(PC,UK),e(UK,lIr),e(PC,iIr),e(oe,dIr),e(oe,BC),e(BC,HEe),e(HEe,cIr),e(BC,fIr),e(BC,JK),e(JK,mIr),e(BC,gIr),e(oe,hIr),e(oe,IC),e(IC,UEe),e(UEe,pIr),e(IC,_Ir),e(IC,YK),e(YK,uIr),e(IC,bIr),e(oe,vIr),e(oe,NC),e(NC,JEe),e(JEe,FIr),e(NC,TIr),e(NC,KK),e(KK,MIr),e(NC,EIr),e(oe,CIr),e(oe,qC),e(qC,YEe),e(YEe,wIr),e(qC,AIr),e(qC,ZK),e(ZK,LIr),e(qC,yIr),e(oe,xIr),e(oe,jC),e(jC,KEe),e(KEe,$Ir),e(jC,kIr),e(jC,eZ),e(eZ,SIr),e(jC,RIr),e(oe,PIr),e(oe,DC),e(DC,ZEe),e(ZEe,BIr),e(DC,IIr),e(DC,oZ),e(oZ,NIr),e(DC,qIr),e(oe,jIr),e(oe,GC),e(GC,e4e),e(e4e,DIr),e(GC,GIr),e(GC,rZ),e(rZ,OIr),e(GC,VIr),e(oe,XIr),e(oe,OC),e(OC,o4e),e(o4e,zIr),e(OC,QIr),e(OC,tZ),e(tZ,WIr),e(OC,HIr),e(oe,UIr),e(oe,VC),e(VC,r4e),e(r4e,JIr),e(VC,YIr),e(VC,aZ),e(aZ,KIr),e(VC,ZIr),e(oe,eNr),e(oe,XC),e(XC,t4e),e(t4e,oNr),e(XC,rNr),e(XC,nZ),e(nZ,tNr),e(XC,aNr),e(oe,nNr),e(oe,zC),e(zC,a4e),e(a4e,sNr),e(zC,lNr),e(zC,sZ),e(sZ,iNr),e(zC,dNr),e(oe,cNr),e(oe,QC),e(QC,n4e),e(n4e,fNr),e(QC,mNr),e(QC,lZ),e(lZ,gNr),e(QC,hNr),e(oe,pNr),e(oe,WC),e(WC,s4e),e(s4e,_Nr),e(WC,uNr),e(WC,iZ),e(iZ,bNr),e(WC,vNr),e(oe,FNr),e(oe,HC),e(HC,l4e),e(l4e,TNr),e(HC,MNr),e(HC,dZ),e(dZ,ENr),e(HC,CNr),e(oe,wNr),e(oe,UC),e(UC,i4e),e(i4e,ANr),e(UC,LNr),e(UC,cZ),e(cZ,yNr),e(UC,xNr),e(oe,$Nr),e(oe,JC),e(JC,d4e),e(d4e,kNr),e(JC,SNr),e(JC,fZ),e(fZ,RNr),e(JC,PNr),e(oe,BNr),e(oe,YC),e(YC,c4e),e(c4e,INr),e(YC,NNr),e(YC,mZ),e(mZ,qNr),e(YC,jNr),e(oe,DNr),e(oe,KC),e(KC,f4e),e(f4e,GNr),e(KC,ONr),e(KC,gZ),e(gZ,VNr),e(KC,XNr),e(Or,zNr),M(ZC,Or,null),b(f,PVe,u),b(f,zc,u),e(zc,e5),e(e5,m4e),M(Dx,m4e,null),e(zc,QNr),e(zc,g4e),e(g4e,WNr),b(f,BVe,u),b(f,pr,u),M(Gx,pr,null),e(pr,HNr),e(pr,Qc),e(Qc,UNr),e(Qc,hZ),e(hZ,JNr),e(Qc,YNr),e(Qc,pZ),e(pZ,KNr),e(Qc,ZNr),e(pr,eqr),e(pr,Ox),e(Ox,oqr),e(Ox,h4e),e(h4e,rqr),e(Ox,tqr),e(pr,aqr),e(pr,zt),M(Vx,zt,null),e(zt,nqr),e(zt,p4e),e(p4e,sqr),e(zt,lqr),e(zt,Wc),e(Wc,iqr),e(Wc,_4e),e(_4e,dqr),e(Wc,cqr),e(Wc,_Z),e(_Z,fqr),e(Wc,mqr),e(zt,gqr),M(o5,zt,null),e(pr,hqr),e(pr,Vr),M(Xx,Vr,null),e(Vr,pqr),e(Vr,u4e),e(u4e,_qr),e(Vr,uqr),e(Vr,Tn),e(Tn,bqr),e(Tn,b4e),e(b4e,vqr),e(Tn,Fqr),e(Tn,v4e),e(v4e,Tqr),e(Tn,Mqr),e(Tn,F4e),e(F4e,Eqr),e(Tn,Cqr),e(Vr,wqr),e(Vr,xe),e(xe,r5),e(r5,T4e),e(T4e,Aqr),e(r5,Lqr),e(r5,uZ),e(uZ,yqr),e(r5,xqr),e(xe,$qr),e(xe,t5),e(t5,M4e),e(M4e,kqr),e(t5,Sqr),e(t5,bZ),e(bZ,Rqr),e(t5,Pqr),e(xe,Bqr),e(xe,a5),e(a5,E4e),e(E4e,Iqr),e(a5,Nqr),e(a5,vZ),e(vZ,qqr),e(a5,jqr),e(xe,Dqr),e(xe,n5),e(n5,C4e),e(C4e,Gqr),e(n5,Oqr),e(n5,FZ),e(FZ,Vqr),e(n5,Xqr),e(xe,zqr),e(xe,s5),e(s5,w4e),e(w4e,Qqr),e(s5,Wqr),e(s5,TZ),e(TZ,Hqr),e(s5,Uqr),e(xe,Jqr),e(xe,l5),e(l5,A4e),e(A4e,Yqr),e(l5,Kqr),e(l5,MZ),e(MZ,Zqr),e(l5,ejr),e(xe,ojr),e(xe,i5),e(i5,L4e),e(L4e,rjr),e(i5,tjr),e(i5,EZ),e(EZ,ajr),e(i5,njr),e(xe,sjr),e(xe,d5),e(d5,y4e),e(y4e,ljr),e(d5,ijr),e(d5,CZ),e(CZ,djr),e(d5,cjr),e(xe,fjr),e(xe,c5),e(c5,x4e),e(x4e,mjr),e(c5,gjr),e(c5,wZ),e(wZ,hjr),e(c5,pjr),e(xe,_jr),e(xe,f5),e(f5,$4e),e($4e,ujr),e(f5,bjr),e(f5,AZ),e(AZ,vjr),e(f5,Fjr),e(Vr,Tjr),M(m5,Vr,null),b(f,IVe,u),b(f,Hc,u),e(Hc,g5),e(g5,k4e),M(zx,k4e,null),e(Hc,Mjr),e(Hc,S4e),e(S4e,Ejr),b(f,NVe,u),b(f,_r,u),M(Qx,_r,null),e(_r,Cjr),e(_r,Uc),e(Uc,wjr),e(Uc,LZ),e(LZ,Ajr),e(Uc,Ljr),e(Uc,yZ),e(yZ,yjr),e(Uc,xjr),e(_r,$jr),e(_r,Wx),e(Wx,kjr),e(Wx,R4e),e(R4e,Sjr),e(Wx,Rjr),e(_r,Pjr),e(_r,Qt),M(Hx,Qt,null),e(Qt,Bjr),e(Qt,P4e),e(P4e,Ijr),e(Qt,Njr),e(Qt,Jc),e(Jc,qjr),e(Jc,B4e),e(B4e,jjr),e(Jc,Djr),e(Jc,xZ),e(xZ,Gjr),e(Jc,Ojr),e(Qt,Vjr),M(h5,Qt,null),e(_r,Xjr),e(_r,Xr),M(Ux,Xr,null),e(Xr,zjr),e(Xr,I4e),e(I4e,Qjr),e(Xr,Wjr),e(Xr,Mn),e(Mn,Hjr),e(Mn,N4e),e(N4e,Ujr),e(Mn,Jjr),e(Mn,q4e),e(q4e,Yjr),e(Mn,Kjr),e(Mn,j4e),e(j4e,Zjr),e(Mn,eDr),e(Xr,oDr),e(Xr,Ee),e(Ee,p5),e(p5,D4e),e(D4e,rDr),e(p5,tDr),e(p5,$Z),e($Z,aDr),e(p5,nDr),e(Ee,sDr),e(Ee,_5),e(_5,G4e),e(G4e,lDr),e(_5,iDr),e(_5,kZ),e(kZ,dDr),e(_5,cDr),e(Ee,fDr),e(Ee,u5),e(u5,O4e),e(O4e,mDr),e(u5,gDr),e(u5,SZ),e(SZ,hDr),e(u5,pDr),e(Ee,_Dr),e(Ee,b5),e(b5,V4e),e(V4e,uDr),e(b5,bDr),e(b5,RZ),e(RZ,vDr),e(b5,FDr),e(Ee,TDr),e(Ee,v5),e(v5,X4e),e(X4e,MDr),e(v5,EDr),e(v5,PZ),e(PZ,CDr),e(v5,wDr),e(Ee,ADr),e(Ee,F5),e(F5,z4e),e(z4e,LDr),e(F5,yDr),e(F5,BZ),e(BZ,xDr),e(F5,$Dr),e(Ee,kDr),e(Ee,T5),e(T5,Q4e),e(Q4e,SDr),e(T5,RDr),e(T5,IZ),e(IZ,PDr),e(T5,BDr),e(Ee,IDr),e(Ee,M5),e(M5,W4e),e(W4e,NDr),e(M5,qDr),e(M5,NZ),e(NZ,jDr),e(M5,DDr),e(Ee,GDr),e(Ee,E5),e(E5,H4e),e(H4e,ODr),e(E5,VDr),e(E5,qZ),e(qZ,XDr),e(E5,zDr),e(Ee,QDr),e(Ee,C5),e(C5,U4e),e(U4e,WDr),e(C5,HDr),e(C5,jZ),e(jZ,UDr),e(C5,JDr),e(Ee,YDr),e(Ee,w5),e(w5,J4e),e(J4e,KDr),e(w5,ZDr),e(w5,DZ),e(DZ,eGr),e(w5,oGr),e(Ee,rGr),e(Ee,A5),e(A5,Y4e),e(Y4e,tGr),e(A5,aGr),e(A5,GZ),e(GZ,nGr),e(A5,sGr),e(Ee,lGr),e(Ee,L5),e(L5,K4e),e(K4e,iGr),e(L5,dGr),e(L5,OZ),e(OZ,cGr),e(L5,fGr),e(Xr,mGr),M(y5,Xr,null),b(f,qVe,u),b(f,Yc,u),e(Yc,x5),e(x5,Z4e),M(Jx,Z4e,null),e(Yc,gGr),e(Yc,eCe),e(eCe,hGr),b(f,jVe,u),b(f,ur,u),M(Yx,ur,null),e(ur,pGr),e(ur,Kc),e(Kc,_Gr),e(Kc,VZ),e(VZ,uGr),e(Kc,bGr),e(Kc,XZ),e(XZ,vGr),e(Kc,FGr),e(ur,TGr),e(ur,Kx),e(Kx,MGr),e(Kx,oCe),e(oCe,EGr),e(Kx,CGr),e(ur,wGr),e(ur,Wt),M(Zx,Wt,null),e(Wt,AGr),e(Wt,rCe),e(rCe,LGr),e(Wt,yGr),e(Wt,Zc),e(Zc,xGr),e(Zc,tCe),e(tCe,$Gr),e(Zc,kGr),e(Zc,zZ),e(zZ,SGr),e(Zc,RGr),e(Wt,PGr),M($5,Wt,null),e(ur,BGr),e(ur,zr),M(e$,zr,null),e(zr,IGr),e(zr,aCe),e(aCe,NGr),e(zr,qGr),e(zr,En),e(En,jGr),e(En,nCe),e(nCe,DGr),e(En,GGr),e(En,sCe),e(sCe,OGr),e(En,VGr),e(En,lCe),e(lCe,XGr),e(En,zGr),e(zr,QGr),e(zr,$e),e($e,k5),e(k5,iCe),e(iCe,WGr),e(k5,HGr),e(k5,QZ),e(QZ,UGr),e(k5,JGr),e($e,YGr),e($e,S5),e(S5,dCe),e(dCe,KGr),e(S5,ZGr),e(S5,WZ),e(WZ,eOr),e(S5,oOr),e($e,rOr),e($e,R5),e(R5,cCe),e(cCe,tOr),e(R5,aOr),e(R5,HZ),e(HZ,nOr),e(R5,sOr),e($e,lOr),e($e,P5),e(P5,fCe),e(fCe,iOr),e(P5,dOr),e(P5,UZ),e(UZ,cOr),e(P5,fOr),e($e,mOr),e($e,B5),e(B5,mCe),e(mCe,gOr),e(B5,hOr),e(B5,JZ),e(JZ,pOr),e(B5,_Or),e($e,uOr),e($e,I5),e(I5,gCe),e(gCe,bOr),e(I5,vOr),e(I5,YZ),e(YZ,FOr),e(I5,TOr),e($e,MOr),e($e,N5),e(N5,hCe),e(hCe,EOr),e(N5,COr),e(N5,KZ),e(KZ,wOr),e(N5,AOr),e($e,LOr),e($e,q5),e(q5,pCe),e(pCe,yOr),e(q5,xOr),e(q5,ZZ),e(ZZ,$Or),e(q5,kOr),e($e,SOr),e($e,j5),e(j5,_Ce),e(_Ce,ROr),e(j5,POr),e(j5,eee),e(eee,BOr),e(j5,IOr),e($e,NOr),e($e,D5),e(D5,uCe),e(uCe,qOr),e(D5,jOr),e(D5,oee),e(oee,DOr),e(D5,GOr),e(zr,OOr),M(G5,zr,null),b(f,DVe,u),b(f,ef,u),e(ef,O5),e(O5,bCe),M(o$,bCe,null),e(ef,VOr),e(ef,vCe),e(vCe,XOr),b(f,GVe,u),b(f,br,u),M(r$,br,null),e(br,zOr),e(br,of),e(of,QOr),e(of,ree),e(ree,WOr),e(of,HOr),e(of,tee),e(tee,UOr),e(of,JOr),e(br,YOr),e(br,t$),e(t$,KOr),e(t$,FCe),e(FCe,ZOr),e(t$,eVr),e(br,oVr),e(br,Ht),M(a$,Ht,null),e(Ht,rVr),e(Ht,TCe),e(TCe,tVr),e(Ht,aVr),e(Ht,rf),e(rf,nVr),e(rf,MCe),e(MCe,sVr),e(rf,lVr),e(rf,aee),e(aee,iVr),e(rf,dVr),e(Ht,cVr),M(V5,Ht,null),e(br,fVr),e(br,Qr),M(n$,Qr,null),e(Qr,mVr),e(Qr,ECe),e(ECe,gVr),e(Qr,hVr),e(Qr,Cn),e(Cn,pVr),e(Cn,CCe),e(CCe,_Vr),e(Cn,uVr),e(Cn,wCe),e(wCe,bVr),e(Cn,vVr),e(Cn,ACe),e(ACe,FVr),e(Cn,TVr),e(Qr,MVr),e(Qr,ke),e(ke,X5),e(X5,LCe),e(LCe,EVr),e(X5,CVr),e(X5,nee),e(nee,wVr),e(X5,AVr),e(ke,LVr),e(ke,z5),e(z5,yCe),e(yCe,yVr),e(z5,xVr),e(z5,see),e(see,$Vr),e(z5,kVr),e(ke,SVr),e(ke,Q5),e(Q5,xCe),e(xCe,RVr),e(Q5,PVr),e(Q5,lee),e(lee,BVr),e(Q5,IVr),e(ke,NVr),e(ke,W5),e(W5,$Ce),e($Ce,qVr),e(W5,jVr),e(W5,iee),e(iee,DVr),e(W5,GVr),e(ke,OVr),e(ke,H5),e(H5,kCe),e(kCe,VVr),e(H5,XVr),e(H5,dee),e(dee,zVr),e(H5,QVr),e(ke,WVr),e(ke,U5),e(U5,SCe),e(SCe,HVr),e(U5,UVr),e(U5,cee),e(cee,JVr),e(U5,YVr),e(ke,KVr),e(ke,J5),e(J5,RCe),e(RCe,ZVr),e(J5,eXr),e(J5,fee),e(fee,oXr),e(J5,rXr),e(ke,tXr),e(ke,Y5),e(Y5,PCe),e(PCe,aXr),e(Y5,nXr),e(Y5,mee),e(mee,sXr),e(Y5,lXr),e(ke,iXr),e(ke,K5),e(K5,BCe),e(BCe,dXr),e(K5,cXr),e(K5,gee),e(gee,fXr),e(K5,mXr),e(ke,gXr),e(ke,Z5),e(Z5,ICe),e(ICe,hXr),e(Z5,pXr),e(Z5,hee),e(hee,_Xr),e(Z5,uXr),e(Qr,bXr),M(e3,Qr,null),b(f,OVe,u),b(f,tf,u),e(tf,o3),e(o3,NCe),M(s$,NCe,null),e(tf,vXr),e(tf,qCe),e(qCe,FXr),b(f,VVe,u),b(f,vr,u),M(l$,vr,null),e(vr,TXr),e(vr,af),e(af,MXr),e(af,pee),e(pee,EXr),e(af,CXr),e(af,_ee),e(_ee,wXr),e(af,AXr),e(vr,LXr),e(vr,i$),e(i$,yXr),e(i$,jCe),e(jCe,xXr),e(i$,$Xr),e(vr,kXr),e(vr,Ut),M(d$,Ut,null),e(Ut,SXr),e(Ut,DCe),e(DCe,RXr),e(Ut,PXr),e(Ut,nf),e(nf,BXr),e(nf,GCe),e(GCe,IXr),e(nf,NXr),e(nf,uee),e(uee,qXr),e(nf,jXr),e(Ut,DXr),M(r3,Ut,null),e(vr,GXr),e(vr,Wr),M(c$,Wr,null),e(Wr,OXr),e(Wr,OCe),e(OCe,VXr),e(Wr,XXr),e(Wr,wn),e(wn,zXr),e(wn,VCe),e(VCe,QXr),e(wn,WXr),e(wn,XCe),e(XCe,HXr),e(wn,UXr),e(wn,zCe),e(zCe,JXr),e(wn,YXr),e(Wr,KXr),e(Wr,Se),e(Se,t3),e(t3,QCe),e(QCe,ZXr),e(t3,ezr),e(t3,bee),e(bee,ozr),e(t3,rzr),e(Se,tzr),e(Se,a3),e(a3,WCe),e(WCe,azr),e(a3,nzr),e(a3,vee),e(vee,szr),e(a3,lzr),e(Se,izr),e(Se,n3),e(n3,HCe),e(HCe,dzr),e(n3,czr),e(n3,Fee),e(Fee,fzr),e(n3,mzr),e(Se,gzr),e(Se,s3),e(s3,UCe),e(UCe,hzr),e(s3,pzr),e(s3,Tee),e(Tee,_zr),e(s3,uzr),e(Se,bzr),e(Se,l3),e(l3,JCe),e(JCe,vzr),e(l3,Fzr),e(l3,Mee),e(Mee,Tzr),e(l3,Mzr),e(Se,Ezr),e(Se,i3),e(i3,YCe),e(YCe,Czr),e(i3,wzr),e(i3,Eee),e(Eee,Azr),e(i3,Lzr),e(Se,yzr),e(Se,d3),e(d3,KCe),e(KCe,xzr),e(d3,$zr),e(d3,Cee),e(Cee,kzr),e(d3,Szr),e(Se,Rzr),e(Se,c3),e(c3,ZCe),e(ZCe,Pzr),e(c3,Bzr),e(c3,wee),e(wee,Izr),e(c3,Nzr),e(Se,qzr),e(Se,f3),e(f3,e5e),e(e5e,jzr),e(f3,Dzr),e(f3,Aee),e(Aee,Gzr),e(f3,Ozr),e(Se,Vzr),e(Se,m3),e(m3,o5e),e(o5e,Xzr),e(m3,zzr),e(m3,Lee),e(Lee,Qzr),e(m3,Wzr),e(Wr,Hzr),M(g3,Wr,null),b(f,XVe,u),b(f,sf,u),e(sf,h3),e(h3,r5e),M(f$,r5e,null),e(sf,Uzr),e(sf,t5e),e(t5e,Jzr),b(f,zVe,u),b(f,Fr,u),M(m$,Fr,null),e(Fr,Yzr),e(Fr,lf),e(lf,Kzr),e(lf,yee),e(yee,Zzr),e(lf,eQr),e(lf,xee),e(xee,oQr),e(lf,rQr),e(Fr,tQr),e(Fr,g$),e(g$,aQr),e(g$,a5e),e(a5e,nQr),e(g$,sQr),e(Fr,lQr),e(Fr,Jt),M(h$,Jt,null),e(Jt,iQr),e(Jt,n5e),e(n5e,dQr),e(Jt,cQr),e(Jt,df),e(df,fQr),e(df,s5e),e(s5e,mQr),e(df,gQr),e(df,$ee),e($ee,hQr),e(df,pQr),e(Jt,_Qr),M(p3,Jt,null),e(Fr,uQr),e(Fr,Hr),M(p$,Hr,null),e(Hr,bQr),e(Hr,l5e),e(l5e,vQr),e(Hr,FQr),e(Hr,An),e(An,TQr),e(An,i5e),e(i5e,MQr),e(An,EQr),e(An,d5e),e(d5e,CQr),e(An,wQr),e(An,c5e),e(c5e,AQr),e(An,LQr),e(Hr,yQr),e(Hr,Re),e(Re,_3),e(_3,f5e),e(f5e,xQr),e(_3,$Qr),e(_3,kee),e(kee,kQr),e(_3,SQr),e(Re,RQr),e(Re,u3),e(u3,m5e),e(m5e,PQr),e(u3,BQr),e(u3,See),e(See,IQr),e(u3,NQr),e(Re,qQr),e(Re,b3),e(b3,g5e),e(g5e,jQr),e(b3,DQr),e(b3,Ree),e(Ree,GQr),e(b3,OQr),e(Re,VQr),e(Re,v3),e(v3,h5e),e(h5e,XQr),e(v3,zQr),e(v3,Pee),e(Pee,QQr),e(v3,WQr),e(Re,HQr),e(Re,F3),e(F3,p5e),e(p5e,UQr),e(F3,JQr),e(F3,Bee),e(Bee,YQr),e(F3,KQr),e(Re,ZQr),e(Re,T3),e(T3,_5e),e(_5e,eWr),e(T3,oWr),e(T3,Iee),e(Iee,rWr),e(T3,tWr),e(Re,aWr),e(Re,M3),e(M3,u5e),e(u5e,nWr),e(M3,sWr),e(M3,Nee),e(Nee,lWr),e(M3,iWr),e(Re,dWr),e(Re,E3),e(E3,b5e),e(b5e,cWr),e(E3,fWr),e(E3,qee),e(qee,mWr),e(E3,gWr),e(Re,hWr),e(Re,C3),e(C3,v5e),e(v5e,pWr),e(C3,_Wr),e(C3,jee),e(jee,uWr),e(C3,bWr),e(Re,vWr),e(Re,w3),e(w3,F5e),e(F5e,FWr),e(w3,TWr),e(w3,Dee),e(Dee,MWr),e(w3,EWr),e(Hr,CWr),M(A3,Hr,null),b(f,QVe,u),b(f,cf,u),e(cf,L3),e(L3,T5e),M(_$,T5e,null),e(cf,wWr),e(cf,M5e),e(M5e,AWr),b(f,WVe,u),b(f,Tr,u),M(u$,Tr,null),e(Tr,LWr),e(Tr,ff),e(ff,yWr),e(ff,Gee),e(Gee,xWr),e(ff,$Wr),e(ff,Oee),e(Oee,kWr),e(ff,SWr),e(Tr,RWr),e(Tr,b$),e(b$,PWr),e(b$,E5e),e(E5e,BWr),e(b$,IWr),e(Tr,NWr),e(Tr,Yt),M(v$,Yt,null),e(Yt,qWr),e(Yt,C5e),e(C5e,jWr),e(Yt,DWr),e(Yt,mf),e(mf,GWr),e(mf,w5e),e(w5e,OWr),e(mf,VWr),e(mf,Vee),e(Vee,XWr),e(mf,zWr),e(Yt,QWr),M(y3,Yt,null),e(Tr,WWr),e(Tr,Ur),M(F$,Ur,null),e(Ur,HWr),e(Ur,A5e),e(A5e,UWr),e(Ur,JWr),e(Ur,Ln),e(Ln,YWr),e(Ln,L5e),e(L5e,KWr),e(Ln,ZWr),e(Ln,y5e),e(y5e,eHr),e(Ln,oHr),e(Ln,x5e),e(x5e,rHr),e(Ln,tHr),e(Ur,aHr),e(Ur,Ve),e(Ve,x3),e(x3,$5e),e($5e,nHr),e(x3,sHr),e(x3,Xee),e(Xee,lHr),e(x3,iHr),e(Ve,dHr),e(Ve,$3),e($3,k5e),e(k5e,cHr),e($3,fHr),e($3,zee),e(zee,mHr),e($3,gHr),e(Ve,hHr),e(Ve,k3),e(k3,S5e),e(S5e,pHr),e(k3,_Hr),e(k3,Qee),e(Qee,uHr),e(k3,bHr),e(Ve,vHr),e(Ve,S3),e(S3,R5e),e(R5e,FHr),e(S3,THr),e(S3,Wee),e(Wee,MHr),e(S3,EHr),e(Ve,CHr),e(Ve,R3),e(R3,P5e),e(P5e,wHr),e(R3,AHr),e(R3,Hee),e(Hee,LHr),e(R3,yHr),e(Ve,xHr),e(Ve,P3),e(P3,B5e),e(B5e,$Hr),e(P3,kHr),e(P3,Uee),e(Uee,SHr),e(P3,RHr),e(Ve,PHr),e(Ve,B3),e(B3,I5e),e(I5e,BHr),e(B3,IHr),e(B3,Jee),e(Jee,NHr),e(B3,qHr),e(Ve,jHr),e(Ve,I3),e(I3,N5e),e(N5e,DHr),e(I3,GHr),e(I3,Yee),e(Yee,OHr),e(I3,VHr),e(Ur,XHr),M(N3,Ur,null),b(f,HVe,u),b(f,gf,u),e(gf,q3),e(q3,q5e),M(T$,q5e,null),e(gf,zHr),e(gf,j5e),e(j5e,QHr),b(f,UVe,u),b(f,Mr,u),M(M$,Mr,null),e(Mr,WHr),e(Mr,hf),e(hf,HHr),e(hf,Kee),e(Kee,UHr),e(hf,JHr),e(hf,Zee),e(Zee,YHr),e(hf,KHr),e(Mr,ZHr),e(Mr,E$),e(E$,eUr),e(E$,D5e),e(D5e,oUr),e(E$,rUr),e(Mr,tUr),e(Mr,Kt),M(C$,Kt,null),e(Kt,aUr),e(Kt,G5e),e(G5e,nUr),e(Kt,sUr),e(Kt,pf),e(pf,lUr),e(pf,O5e),e(O5e,iUr),e(pf,dUr),e(pf,eoe),e(eoe,cUr),e(pf,fUr),e(Kt,mUr),M(j3,Kt,null),e(Mr,gUr),e(Mr,Jr),M(w$,Jr,null),e(Jr,hUr),e(Jr,V5e),e(V5e,pUr),e(Jr,_Ur),e(Jr,yn),e(yn,uUr),e(yn,X5e),e(X5e,bUr),e(yn,vUr),e(yn,z5e),e(z5e,FUr),e(yn,TUr),e(yn,Q5e),e(Q5e,MUr),e(yn,EUr),e(Jr,CUr),e(Jr,Xe),e(Xe,D3),e(D3,W5e),e(W5e,wUr),e(D3,AUr),e(D3,ooe),e(ooe,LUr),e(D3,yUr),e(Xe,xUr),e(Xe,G3),e(G3,H5e),e(H5e,$Ur),e(G3,kUr),e(G3,roe),e(roe,SUr),e(G3,RUr),e(Xe,PUr),e(Xe,O3),e(O3,U5e),e(U5e,BUr),e(O3,IUr),e(O3,toe),e(toe,NUr),e(O3,qUr),e(Xe,jUr),e(Xe,V3),e(V3,J5e),e(J5e,DUr),e(V3,GUr),e(V3,aoe),e(aoe,OUr),e(V3,VUr),e(Xe,XUr),e(Xe,X3),e(X3,Y5e),e(Y5e,zUr),e(X3,QUr),e(X3,noe),e(noe,WUr),e(X3,HUr),e(Xe,UUr),e(Xe,z3),e(z3,K5e),e(K5e,JUr),e(z3,YUr),e(z3,soe),e(soe,KUr),e(z3,ZUr),e(Xe,eJr),e(Xe,Q3),e(Q3,Z5e),e(Z5e,oJr),e(Q3,rJr),e(Q3,loe),e(loe,tJr),e(Q3,aJr),e(Xe,nJr),e(Xe,W3),e(W3,e3e),e(e3e,sJr),e(W3,lJr),e(W3,ioe),e(ioe,iJr),e(W3,dJr),e(Jr,cJr),M(H3,Jr,null),b(f,JVe,u),b(f,_f,u),e(_f,U3),e(U3,o3e),M(A$,o3e,null),e(_f,fJr),e(_f,r3e),e(r3e,mJr),b(f,YVe,u),b(f,Er,u),M(L$,Er,null),e(Er,gJr),e(Er,uf),e(uf,hJr),e(uf,doe),e(doe,pJr),e(uf,_Jr),e(uf,coe),e(coe,uJr),e(uf,bJr),e(Er,vJr),e(Er,y$),e(y$,FJr),e(y$,t3e),e(t3e,TJr),e(y$,MJr),e(Er,EJr),e(Er,Zt),M(x$,Zt,null),e(Zt,CJr),e(Zt,a3e),e(a3e,wJr),e(Zt,AJr),e(Zt,bf),e(bf,LJr),e(bf,n3e),e(n3e,yJr),e(bf,xJr),e(bf,foe),e(foe,$Jr),e(bf,kJr),e(Zt,SJr),M(J3,Zt,null),e(Er,RJr),e(Er,Yr),M($$,Yr,null),e(Yr,PJr),e(Yr,s3e),e(s3e,BJr),e(Yr,IJr),e(Yr,xn),e(xn,NJr),e(xn,l3e),e(l3e,qJr),e(xn,jJr),e(xn,i3e),e(i3e,DJr),e(xn,GJr),e(xn,d3e),e(d3e,OJr),e(xn,VJr),e(Yr,XJr),e(Yr,c3e),e(c3e,Y3),e(Y3,f3e),e(f3e,zJr),e(Y3,QJr),e(Y3,moe),e(moe,WJr),e(Y3,HJr),e(Yr,UJr),M(K3,Yr,null),b(f,KVe,u),b(f,vf,u),e(vf,Z3),e(Z3,m3e),M(k$,m3e,null),e(vf,JJr),e(vf,g3e),e(g3e,YJr),b(f,ZVe,u),b(f,Cr,u),M(S$,Cr,null),e(Cr,KJr),e(Cr,Ff),e(Ff,ZJr),e(Ff,goe),e(goe,eYr),e(Ff,oYr),e(Ff,hoe),e(hoe,rYr),e(Ff,tYr),e(Cr,aYr),e(Cr,R$),e(R$,nYr),e(R$,h3e),e(h3e,sYr),e(R$,lYr),e(Cr,iYr),e(Cr,ea),M(P$,ea,null),e(ea,dYr),e(ea,p3e),e(p3e,cYr),e(ea,fYr),e(ea,Tf),e(Tf,mYr),e(Tf,_3e),e(_3e,gYr),e(Tf,hYr),e(Tf,poe),e(poe,pYr),e(Tf,_Yr),e(ea,uYr),M(e0,ea,null),e(Cr,bYr),e(Cr,Kr),M(B$,Kr,null),e(Kr,vYr),e(Kr,u3e),e(u3e,FYr),e(Kr,TYr),e(Kr,$n),e($n,MYr),e($n,b3e),e(b3e,EYr),e($n,CYr),e($n,v3e),e(v3e,wYr),e($n,AYr),e($n,F3e),e(F3e,LYr),e($n,yYr),e(Kr,xYr),e(Kr,I$),e(I$,o0),e(o0,T3e),e(T3e,$Yr),e(o0,kYr),e(o0,_oe),e(_oe,SYr),e(o0,RYr),e(I$,PYr),e(I$,r0),e(r0,M3e),e(M3e,BYr),e(r0,IYr),e(r0,uoe),e(uoe,NYr),e(r0,qYr),e(Kr,jYr),M(t0,Kr,null),b(f,eXe,u),b(f,Mf,u),e(Mf,a0),e(a0,E3e),M(N$,E3e,null),e(Mf,DYr),e(Mf,C3e),e(C3e,GYr),b(f,oXe,u),b(f,wr,u),M(q$,wr,null),e(wr,OYr),e(wr,Ef),e(Ef,VYr),e(Ef,boe),e(boe,XYr),e(Ef,zYr),e(Ef,voe),e(voe,QYr),e(Ef,WYr),e(wr,HYr),e(wr,j$),e(j$,UYr),e(j$,w3e),e(w3e,JYr),e(j$,YYr),e(wr,KYr),e(wr,oa),M(D$,oa,null),e(oa,ZYr),e(oa,A3e),e(A3e,eKr),e(oa,oKr),e(oa,Cf),e(Cf,rKr),e(Cf,L3e),e(L3e,tKr),e(Cf,aKr),e(Cf,Foe),e(Foe,nKr),e(Cf,sKr),e(oa,lKr),M(n0,oa,null),e(wr,iKr),e(wr,Zr),M(G$,Zr,null),e(Zr,dKr),e(Zr,y3e),e(y3e,cKr),e(Zr,fKr),e(Zr,kn),e(kn,mKr),e(kn,x3e),e(x3e,gKr),e(kn,hKr),e(kn,$3e),e($3e,pKr),e(kn,_Kr),e(kn,k3e),e(k3e,uKr),e(kn,bKr),e(Zr,vKr),e(Zr,S3e),e(S3e,s0),e(s0,R3e),e(R3e,FKr),e(s0,TKr),e(s0,Toe),e(Toe,MKr),e(s0,EKr),e(Zr,CKr),M(l0,Zr,null),rXe=!0},p(f,[u]){const O$={};u&2&&(O$.$$scope={dirty:u,ctx:f}),Rf.$set(O$);const P3e={};u&2&&(P3e.$$scope={dirty:u,ctx:f}),Og.$set(P3e);const B3e={};u&2&&(B3e.$$scope={dirty:u,ctx:f}),wh.$set(B3e);const I3e={};u&2&&(I3e.$$scope={dirty:u,ctx:f}),sp.$set(I3e);const V$={};u&2&&(V$.$$scope={dirty:u,ctx:f}),lp.$set(V$);const N3e={};u&2&&(N3e.$$scope={dirty:u,ctx:f}),Lp.$set(N3e);const Sn={};u&2&&(Sn.$$scope={dirty:u,ctx:f}),yp.$set(Sn);const q3e={};u&2&&(q3e.$$scope={dirty:u,ctx:f}),kp.$set(q3e);const j3e={};u&2&&(j3e.$$scope={dirty:u,ctx:f}),Su.$set(j3e);const D3e={};u&2&&(D3e.$$scope={dirty:u,ctx:f}),Pu.$set(D3e);const X$={};u&2&&(X$.$$scope={dirty:u,ctx:f}),A2.$set(X$);const G3e={};u&2&&(G3e.$$scope={dirty:u,ctx:f}),y2.$set(G3e);const z$={};u&2&&(z$.$$scope={dirty:u,ctx:f}),h1.$set(z$);const O3e={};u&2&&(O3e.$$scope={dirty:u,ctx:f}),_1.$set(O3e);const Q$={};u&2&&(Q$.$$scope={dirty:u,ctx:f}),ob.$set(Q$);const V3e={};u&2&&(V3e.$$scope={dirty:u,ctx:f}),tb.$set(V3e);const X3e={};u&2&&(X3e.$$scope={dirty:u,ctx:f}),Mb.$set(X3e);const z3e={};u&2&&(z3e.$$scope={dirty:u,ctx:f}),Cb.$set(z3e);const wf={};u&2&&(wf.$$scope={dirty:u,ctx:f}),Tv.$set(wf);const Q3e={};u&2&&(Q3e.$$scope={dirty:u,ctx:f}),Ev.$set(Q3e);const W3e={};u&2&&(W3e.$$scope={dirty:u,ctx:f}),oF.$set(W3e);const H3e={};u&2&&(H3e.$$scope={dirty:u,ctx:f}),tF.$set(H3e);const W$={};u&2&&(W$.$$scope={dirty:u,ctx:f}),fF.$set(W$);const U3e={};u&2&&(U3e.$$scope={dirty:u,ctx:f}),gF.$set(U3e);const J3e={};u&2&&(J3e.$$scope={dirty:u,ctx:f}),YF.$set(J3e);const Y3e={};u&2&&(Y3e.$$scope={dirty:u,ctx:f}),ZF.$set(Y3e);const rt={};u&2&&(rt.$$scope={dirty:u,ctx:f}),O6.$set(rt);const H$={};u&2&&(H$.$$scope={dirty:u,ctx:f}),X6.$set(H$);const K3e={};u&2&&(K3e.$$scope={dirty:u,ctx:f}),W6.$set(K3e);const U$={};u&2&&(U$.$$scope={dirty:u,ctx:f}),U6.$set(U$);const Z3e={};u&2&&(Z3e.$$scope={dirty:u,ctx:f}),dT.$set(Z3e);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),fT.$set(tt);const e0e={};u&2&&(e0e.$$scope={dirty:u,ctx:f}),hT.$set(e0e);const Af={};u&2&&(Af.$$scope={dirty:u,ctx:f}),_T.$set(Af);const o0e={};u&2&&(o0e.$$scope={dirty:u,ctx:f}),vT.$set(o0e);const r0e={};u&2&&(r0e.$$scope={dirty:u,ctx:f}),TT.$set(r0e);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),ST.$set(L);const i0={};u&2&&(i0.$$scope={dirty:u,ctx:f}),PT.$set(i0);const t0e={};u&2&&(t0e.$$scope={dirty:u,ctx:f}),GT.$set(t0e);const a0e={};u&2&&(a0e.$$scope={dirty:u,ctx:f}),VT.$set(a0e);const d0={};u&2&&(d0.$$scope={dirty:u,ctx:f}),o7.$set(d0);const n0e={};u&2&&(n0e.$$scope={dirty:u,ctx:f}),t7.$set(n0e);const s0e={};u&2&&(s0e.$$scope={dirty:u,ctx:f}),l7.$set(s0e);const c0={};u&2&&(c0.$$scope={dirty:u,ctx:f}),d7.$set(c0);const l0e={};u&2&&(l0e.$$scope={dirty:u,ctx:f}),_7.$set(l0e);const i0e={};u&2&&(i0e.$$scope={dirty:u,ctx:f}),b7.$set(i0e);const f0={};u&2&&(f0.$$scope={dirty:u,ctx:f}),E7.$set(f0);const d0e={};u&2&&(d0e.$$scope={dirty:u,ctx:f}),w7.$set(d0e);const c0e={};u&2&&(c0e.$$scope={dirty:u,ctx:f}),x7.$set(c0e);const m0={};u&2&&(m0.$$scope={dirty:u,ctx:f}),k7.$set(m0);const f0e={};u&2&&(f0e.$$scope={dirty:u,ctx:f}),P7.$set(f0e);const m0e={};u&2&&(m0e.$$scope={dirty:u,ctx:f}),I7.$set(m0e);const g0={};u&2&&(g0.$$scope={dirty:u,ctx:f}),O7.$set(g0);const g0e={};u&2&&(g0e.$$scope={dirty:u,ctx:f}),X7.$set(g0e);const h0e={};u&2&&(h0e.$$scope={dirty:u,ctx:f}),W7.$set(h0e);const h0={};u&2&&(h0.$$scope={dirty:u,ctx:f}),U7.$set(h0);const p0e={};u&2&&(p0e.$$scope={dirty:u,ctx:f}),O8.$set(p0e);const _0e={};u&2&&(_0e.$$scope={dirty:u,ctx:f}),X8.$set(_0e);const p0={};u&2&&(p0.$$scope={dirty:u,ctx:f}),hM.$set(p0);const u0e={};u&2&&(u0e.$$scope={dirty:u,ctx:f}),_M.$set(u0e);const b0e={};u&2&&(b0e.$$scope={dirty:u,ctx:f}),$M.$set(b0e);const _0={};u&2&&(_0.$$scope={dirty:u,ctx:f}),SM.$set(_0);const v0e={};u&2&&(v0e.$$scope={dirty:u,ctx:f}),NM.$set(v0e);const F0e={};u&2&&(F0e.$$scope={dirty:u,ctx:f}),jM.$set(F0e);const u0={};u&2&&(u0.$$scope={dirty:u,ctx:f}),sE.$set(u0);const T0e={};u&2&&(T0e.$$scope={dirty:u,ctx:f}),iE.$set(T0e);const M0e={};u&2&&(M0e.$$scope={dirty:u,ctx:f}),vE.$set(M0e);const b0={};u&2&&(b0.$$scope={dirty:u,ctx:f}),TE.$set(b0);const E0e={};u&2&&(E0e.$$scope={dirty:u,ctx:f}),HE.$set(E0e);const C0e={};u&2&&(C0e.$$scope={dirty:u,ctx:f}),JE.$set(C0e);const v0={};u&2&&(v0.$$scope={dirty:u,ctx:f}),h4.$set(v0);const w0e={};u&2&&(w0e.$$scope={dirty:u,ctx:f}),_4.$set(w0e);const A0e={};u&2&&(A0e.$$scope={dirty:u,ctx:f}),v4.$set(A0e);const F0={};u&2&&(F0.$$scope={dirty:u,ctx:f}),T4.$set(F0);const L0e={};u&2&&(L0e.$$scope={dirty:u,ctx:f}),E4.$set(L0e);const y0e={};u&2&&(y0e.$$scope={dirty:u,ctx:f}),w4.$set(y0e);const T0={};u&2&&(T0.$$scope={dirty:u,ctx:f}),Q4.$set(T0);const x0e={};u&2&&(x0e.$$scope={dirty:u,ctx:f}),H4.$set(x0e);const $0e={};u&2&&($0e.$$scope={dirty:u,ctx:f}),pC.$set($0e);const M0={};u&2&&(M0.$$scope={dirty:u,ctx:f}),uC.$set(M0);const k0e={};u&2&&(k0e.$$scope={dirty:u,ctx:f}),vC.$set(k0e);const S0e={};u&2&&(S0e.$$scope={dirty:u,ctx:f}),TC.$set(S0e);const E0={};u&2&&(E0.$$scope={dirty:u,ctx:f}),EC.$set(E0);const R0e={};u&2&&(R0e.$$scope={dirty:u,ctx:f}),wC.$set(R0e);const P0e={};u&2&&(P0e.$$scope={dirty:u,ctx:f}),ZC.$set(P0e);const C0={};u&2&&(C0.$$scope={dirty:u,ctx:f}),o5.$set(C0);const B0e={};u&2&&(B0e.$$scope={dirty:u,ctx:f}),m5.$set(B0e);const I0e={};u&2&&(I0e.$$scope={dirty:u,ctx:f}),h5.$set(I0e);const w0={};u&2&&(w0.$$scope={dirty:u,ctx:f}),y5.$set(w0);const N0e={};u&2&&(N0e.$$scope={dirty:u,ctx:f}),$5.$set(N0e);const q0e={};u&2&&(q0e.$$scope={dirty:u,ctx:f}),G5.$set(q0e);const A0={};u&2&&(A0.$$scope={dirty:u,ctx:f}),V5.$set(A0);const j0e={};u&2&&(j0e.$$scope={dirty:u,ctx:f}),e3.$set(j0e);const D0e={};u&2&&(D0e.$$scope={dirty:u,ctx:f}),r3.$set(D0e);const L0={};u&2&&(L0.$$scope={dirty:u,ctx:f}),g3.$set(L0);const G0e={};u&2&&(G0e.$$scope={dirty:u,ctx:f}),p3.$set(G0e);const O0e={};u&2&&(O0e.$$scope={dirty:u,ctx:f}),A3.$set(O0e);const y0={};u&2&&(y0.$$scope={dirty:u,ctx:f}),y3.$set(y0);const V0e={};u&2&&(V0e.$$scope={dirty:u,ctx:f}),N3.$set(V0e);const X0e={};u&2&&(X0e.$$scope={dirty:u,ctx:f}),j3.$set(X0e);const x0={};u&2&&(x0.$$scope={dirty:u,ctx:f}),H3.$set(x0);const z0e={};u&2&&(z0e.$$scope={dirty:u,ctx:f}),J3.$set(z0e);const Q0e={};u&2&&(Q0e.$$scope={dirty:u,ctx:f}),K3.$set(Q0e);const $0={};u&2&&($0.$$scope={dirty:u,ctx:f}),e0.$set($0);const W0e={};u&2&&(W0e.$$scope={dirty:u,ctx:f}),t0.$set(W0e);const H0e={};u&2&&(H0e.$$scope={dirty:u,ctx:f}),n0.$set(H0e);const k0={};u&2&&(k0.$$scope={dirty:u,ctx:f}),l0.$set(k0)},i(f){rXe||(E(d.$$.fragment,f),E(xa.$$.fragment,f),E(SA.$$.fragment,f),E(RA.$$.fragment,f),E(Rf.$$.fragment,f),E(PA.$$.fragment,f),E(BA.$$.fragment,f),E(qA.$$.fragment,f),E(Og.$$.fragment,f),E(jA.$$.fragment,f),E(DA.$$.fragment,f),E(GA.$$.fragment,f),E(XA.$$.fragment,f),E(wh.$$.fragment,f),E(zA.$$.fragment,f),E(QA.$$.fragment,f),E(WA.$$.fragment,f),E(JA.$$.fragment,f),E(sp.$$.fragment,f),E(lp.$$.fragment,f),E(YA.$$.fragment,f),E(KA.$$.fragment,f),E(ZA.$$.fragment,f),E(rL.$$.fragment,f),E(Lp.$$.fragment,f),E(yp.$$.fragment,f),E(tL.$$.fragment,f),E(aL.$$.fragment,f),E(nL.$$.fragment,f),E(lL.$$.fragment,f),E(kp.$$.fragment,f),E(iL.$$.fragment,f),E(Su.$$.fragment,f),E(dL.$$.fragment,f),E(cL.$$.fragment,f),E(mL.$$.fragment,f),E(Pu.$$.fragment,f),E(gL.$$.fragment,f),E(A2.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(uL.$$.fragment,f),E(y2.$$.fragment,f),E(bL.$$.fragment,f),E(h1.$$.fragment,f),E(vL.$$.fragment,f),E(FL.$$.fragment,f),E(ML.$$.fragment,f),E(_1.$$.fragment,f),E(EL.$$.fragment,f),E(ob.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(LL.$$.fragment,f),E(tb.$$.fragment,f),E(yL.$$.fragment,f),E(Mb.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(SL.$$.fragment,f),E(Cb.$$.fragment,f),E(RL.$$.fragment,f),E(Tv.$$.fragment,f),E(PL.$$.fragment,f),E(BL.$$.fragment,f),E(NL.$$.fragment,f),E(Ev.$$.fragment,f),E(qL.$$.fragment,f),E(oF.$$.fragment,f),E(jL.$$.fragment,f),E(DL.$$.fragment,f),E(OL.$$.fragment,f),E(tF.$$.fragment,f),E(VL.$$.fragment,f),E(fF.$$.fragment,f),E(XL.$$.fragment,f),E(zL.$$.fragment,f),E(WL.$$.fragment,f),E(gF.$$.fragment,f),E(HL.$$.fragment,f),E(YF.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(KL.$$.fragment,f),E(ZF.$$.fragment,f),E(ZL.$$.fragment,f),E(O6.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ty.$$.fragment,f),E(X6.$$.fragment,f),E(ay.$$.fragment,f),E(W6.$$.fragment,f),E(ny.$$.fragment,f),E(sy.$$.fragment,f),E(iy.$$.fragment,f),E(U6.$$.fragment,f),E(dy.$$.fragment,f),E(dT.$$.fragment,f),E(cy.$$.fragment,f),E(fy.$$.fragment,f),E(gy.$$.fragment,f),E(fT.$$.fragment,f),E(hy.$$.fragment,f),E(hT.$$.fragment,f),E(py.$$.fragment,f),E(_y.$$.fragment,f),E(by.$$.fragment,f),E(_T.$$.fragment,f),E(vy.$$.fragment,f),E(vT.$$.fragment,f),E(Fy.$$.fragment,f),E(Ty.$$.fragment,f),E(Ey.$$.fragment,f),E(TT.$$.fragment,f),E(Cy.$$.fragment,f),E(ST.$$.fragment,f),E(wy.$$.fragment,f),E(Ay.$$.fragment,f),E(yy.$$.fragment,f),E(PT.$$.fragment,f),E(xy.$$.fragment,f),E(GT.$$.fragment,f),E($y.$$.fragment,f),E(ky.$$.fragment,f),E(Ry.$$.fragment,f),E(VT.$$.fragment,f),E(Py.$$.fragment,f),E(o7.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(qy.$$.fragment,f),E(t7.$$.fragment,f),E(jy.$$.fragment,f),E(l7.$$.fragment,f),E(Gy.$$.fragment,f),E(Oy.$$.fragment,f),E(Xy.$$.fragment,f),E(d7.$$.fragment,f),E(zy.$$.fragment,f),E(_7.$$.fragment,f),E(Qy.$$.fragment,f),E(Wy.$$.fragment,f),E(Uy.$$.fragment,f),E(b7.$$.fragment,f),E(Jy.$$.fragment,f),E(E7.$$.fragment,f),E(Yy.$$.fragment,f),E(Ky.$$.fragment,f),E(e9.$$.fragment,f),E(w7.$$.fragment,f),E(o9.$$.fragment,f),E(x7.$$.fragment,f),E(t9.$$.fragment,f),E(a9.$$.fragment,f),E(s9.$$.fragment,f),E(k7.$$.fragment,f),E(l9.$$.fragment,f),E(P7.$$.fragment,f),E(i9.$$.fragment,f),E(d9.$$.fragment,f),E(f9.$$.fragment,f),E(I7.$$.fragment,f),E(m9.$$.fragment,f),E(O7.$$.fragment,f),E(g9.$$.fragment,f),E(h9.$$.fragment,f),E(_9.$$.fragment,f),E(X7.$$.fragment,f),E(u9.$$.fragment,f),E(W7.$$.fragment,f),E(b9.$$.fragment,f),E(v9.$$.fragment,f),E(T9.$$.fragment,f),E(U7.$$.fragment,f),E(M9.$$.fragment,f),E(O8.$$.fragment,f),E(E9.$$.fragment,f),E(C9.$$.fragment,f),E(A9.$$.fragment,f),E(X8.$$.fragment,f),E(L9.$$.fragment,f),E(hM.$$.fragment,f),E(y9.$$.fragment,f),E(x9.$$.fragment,f),E(k9.$$.fragment,f),E(_M.$$.fragment,f),E(S9.$$.fragment,f),E($M.$$.fragment,f),E(R9.$$.fragment,f),E(P9.$$.fragment,f),E(I9.$$.fragment,f),E(SM.$$.fragment,f),E(N9.$$.fragment,f),E(NM.$$.fragment,f),E(q9.$$.fragment,f),E(j9.$$.fragment,f),E(G9.$$.fragment,f),E(jM.$$.fragment,f),E(O9.$$.fragment,f),E(sE.$$.fragment,f),E(V9.$$.fragment,f),E(X9.$$.fragment,f),E(Q9.$$.fragment,f),E(iE.$$.fragment,f),E(W9.$$.fragment,f),E(vE.$$.fragment,f),E(H9.$$.fragment,f),E(U9.$$.fragment,f),E(Y9.$$.fragment,f),E(TE.$$.fragment,f),E(K9.$$.fragment,f),E(HE.$$.fragment,f),E(Z9.$$.fragment,f),E(ex.$$.fragment,f),E(rx.$$.fragment,f),E(JE.$$.fragment,f),E(tx.$$.fragment,f),E(h4.$$.fragment,f),E(ax.$$.fragment,f),E(nx.$$.fragment,f),E(lx.$$.fragment,f),E(_4.$$.fragment,f),E(ix.$$.fragment,f),E(v4.$$.fragment,f),E(cx.$$.fragment,f),E(fx.$$.fragment,f),E(gx.$$.fragment,f),E(T4.$$.fragment,f),E(hx.$$.fragment,f),E(E4.$$.fragment,f),E(px.$$.fragment,f),E(_x.$$.fragment,f),E(bx.$$.fragment,f),E(w4.$$.fragment,f),E(vx.$$.fragment,f),E(Q4.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(H4.$$.fragment,f),E(Cx.$$.fragment,f),E(pC.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(yx.$$.fragment,f),E(uC.$$.fragment,f),E(xx.$$.fragment,f),E(vC.$$.fragment,f),E($x.$$.fragment,f),E(kx.$$.fragment,f),E(Rx.$$.fragment,f),E(TC.$$.fragment,f),E(Px.$$.fragment,f),E(EC.$$.fragment,f),E(Bx.$$.fragment,f),E(Ix.$$.fragment,f),E(qx.$$.fragment,f),E(wC.$$.fragment,f),E(jx.$$.fragment,f),E(ZC.$$.fragment,f),E(Dx.$$.fragment,f),E(Gx.$$.fragment,f),E(Vx.$$.fragment,f),E(o5.$$.fragment,f),E(Xx.$$.fragment,f),E(m5.$$.fragment,f),E(zx.$$.fragment,f),E(Qx.$$.fragment,f),E(Hx.$$.fragment,f),E(h5.$$.fragment,f),E(Ux.$$.fragment,f),E(y5.$$.fragment,f),E(Jx.$$.fragment,f),E(Yx.$$.fragment,f),E(Zx.$$.fragment,f),E($5.$$.fragment,f),E(e$.$$.fragment,f),E(G5.$$.fragment,f),E(o$.$$.fragment,f),E(r$.$$.fragment,f),E(a$.$$.fragment,f),E(V5.$$.fragment,f),E(n$.$$.fragment,f),E(e3.$$.fragment,f),E(s$.$$.fragment,f),E(l$.$$.fragment,f),E(d$.$$.fragment,f),E(r3.$$.fragment,f),E(c$.$$.fragment,f),E(g3.$$.fragment,f),E(f$.$$.fragment,f),E(m$.$$.fragment,f),E(h$.$$.fragment,f),E(p3.$$.fragment,f),E(p$.$$.fragment,f),E(A3.$$.fragment,f),E(_$.$$.fragment,f),E(u$.$$.fragment,f),E(v$.$$.fragment,f),E(y3.$$.fragment,f),E(F$.$$.fragment,f),E(N3.$$.fragment,f),E(T$.$$.fragment,f),E(M$.$$.fragment,f),E(C$.$$.fragment,f),E(j3.$$.fragment,f),E(w$.$$.fragment,f),E(H3.$$.fragment,f),E(A$.$$.fragment,f),E(L$.$$.fragment,f),E(x$.$$.fragment,f),E(J3.$$.fragment,f),E($$.$$.fragment,f),E(K3.$$.fragment,f),E(k$.$$.fragment,f),E(S$.$$.fragment,f),E(P$.$$.fragment,f),E(e0.$$.fragment,f),E(B$.$$.fragment,f),E(t0.$$.fragment,f),E(N$.$$.fragment,f),E(q$.$$.fragment,f),E(D$.$$.fragment,f),E(n0.$$.fragment,f),E(G$.$$.fragment,f),E(l0.$$.fragment,f),rXe=!0)},o(f){C(d.$$.fragment,f),C(xa.$$.fragment,f),C(SA.$$.fragment,f),C(RA.$$.fragment,f),C(Rf.$$.fragment,f),C(PA.$$.fragment,f),C(BA.$$.fragment,f),C(qA.$$.fragment,f),C(Og.$$.fragment,f),C(jA.$$.fragment,f),C(DA.$$.fragment,f),C(GA.$$.fragment,f),C(XA.$$.fragment,f),C(wh.$$.fragment,f),C(zA.$$.fragment,f),C(QA.$$.fragment,f),C(WA.$$.fragment,f),C(JA.$$.fragment,f),C(sp.$$.fragment,f),C(lp.$$.fragment,f),C(YA.$$.fragment,f),C(KA.$$.fragment,f),C(ZA.$$.fragment,f),C(rL.$$.fragment,f),C(Lp.$$.fragment,f),C(yp.$$.fragment,f),C(tL.$$.fragment,f),C(aL.$$.fragment,f),C(nL.$$.fragment,f),C(lL.$$.fragment,f),C(kp.$$.fragment,f),C(iL.$$.fragment,f),C(Su.$$.fragment,f),C(dL.$$.fragment,f),C(cL.$$.fragment,f),C(mL.$$.fragment,f),C(Pu.$$.fragment,f),C(gL.$$.fragment,f),C(A2.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(uL.$$.fragment,f),C(y2.$$.fragment,f),C(bL.$$.fragment,f),C(h1.$$.fragment,f),C(vL.$$.fragment,f),C(FL.$$.fragment,f),C(ML.$$.fragment,f),C(_1.$$.fragment,f),C(EL.$$.fragment,f),C(ob.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(LL.$$.fragment,f),C(tb.$$.fragment,f),C(yL.$$.fragment,f),C(Mb.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(SL.$$.fragment,f),C(Cb.$$.fragment,f),C(RL.$$.fragment,f),C(Tv.$$.fragment,f),C(PL.$$.fragment,f),C(BL.$$.fragment,f),C(NL.$$.fragment,f),C(Ev.$$.fragment,f),C(qL.$$.fragment,f),C(oF.$$.fragment,f),C(jL.$$.fragment,f),C(DL.$$.fragment,f),C(OL.$$.fragment,f),C(tF.$$.fragment,f),C(VL.$$.fragment,f),C(fF.$$.fragment,f),C(XL.$$.fragment,f),C(zL.$$.fragment,f),C(WL.$$.fragment,f),C(gF.$$.fragment,f),C(HL.$$.fragment,f),C(YF.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(KL.$$.fragment,f),C(ZF.$$.fragment,f),C(ZL.$$.fragment,f),C(O6.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ty.$$.fragment,f),C(X6.$$.fragment,f),C(ay.$$.fragment,f),C(W6.$$.fragment,f),C(ny.$$.fragment,f),C(sy.$$.fragment,f),C(iy.$$.fragment,f),C(U6.$$.fragment,f),C(dy.$$.fragment,f),C(dT.$$.fragment,f),C(cy.$$.fragment,f),C(fy.$$.fragment,f),C(gy.$$.fragment,f),C(fT.$$.fragment,f),C(hy.$$.fragment,f),C(hT.$$.fragment,f),C(py.$$.fragment,f),C(_y.$$.fragment,f),C(by.$$.fragment,f),C(_T.$$.fragment,f),C(vy.$$.fragment,f),C(vT.$$.fragment,f),C(Fy.$$.fragment,f),C(Ty.$$.fragment,f),C(Ey.$$.fragment,f),C(TT.$$.fragment,f),C(Cy.$$.fragment,f),C(ST.$$.fragment,f),C(wy.$$.fragment,f),C(Ay.$$.fragment,f),C(yy.$$.fragment,f),C(PT.$$.fragment,f),C(xy.$$.fragment,f),C(GT.$$.fragment,f),C($y.$$.fragment,f),C(ky.$$.fragment,f),C(Ry.$$.fragment,f),C(VT.$$.fragment,f),C(Py.$$.fragment,f),C(o7.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(qy.$$.fragment,f),C(t7.$$.fragment,f),C(jy.$$.fragment,f),C(l7.$$.fragment,f),C(Gy.$$.fragment,f),C(Oy.$$.fragment,f),C(Xy.$$.fragment,f),C(d7.$$.fragment,f),C(zy.$$.fragment,f),C(_7.$$.fragment,f),C(Qy.$$.fragment,f),C(Wy.$$.fragment,f),C(Uy.$$.fragment,f),C(b7.$$.fragment,f),C(Jy.$$.fragment,f),C(E7.$$.fragment,f),C(Yy.$$.fragment,f),C(Ky.$$.fragment,f),C(e9.$$.fragment,f),C(w7.$$.fragment,f),C(o9.$$.fragment,f),C(x7.$$.fragment,f),C(t9.$$.fragment,f),C(a9.$$.fragment,f),C(s9.$$.fragment,f),C(k7.$$.fragment,f),C(l9.$$.fragment,f),C(P7.$$.fragment,f),C(i9.$$.fragment,f),C(d9.$$.fragment,f),C(f9.$$.fragment,f),C(I7.$$.fragment,f),C(m9.$$.fragment,f),C(O7.$$.fragment,f),C(g9.$$.fragment,f),C(h9.$$.fragment,f),C(_9.$$.fragment,f),C(X7.$$.fragment,f),C(u9.$$.fragment,f),C(W7.$$.fragment,f),C(b9.$$.fragment,f),C(v9.$$.fragment,f),C(T9.$$.fragment,f),C(U7.$$.fragment,f),C(M9.$$.fragment,f),C(O8.$$.fragment,f),C(E9.$$.fragment,f),C(C9.$$.fragment,f),C(A9.$$.fragment,f),C(X8.$$.fragment,f),C(L9.$$.fragment,f),C(hM.$$.fragment,f),C(y9.$$.fragment,f),C(x9.$$.fragment,f),C(k9.$$.fragment,f),C(_M.$$.fragment,f),C(S9.$$.fragment,f),C($M.$$.fragment,f),C(R9.$$.fragment,f),C(P9.$$.fragment,f),C(I9.$$.fragment,f),C(SM.$$.fragment,f),C(N9.$$.fragment,f),C(NM.$$.fragment,f),C(q9.$$.fragment,f),C(j9.$$.fragment,f),C(G9.$$.fragment,f),C(jM.$$.fragment,f),C(O9.$$.fragment,f),C(sE.$$.fragment,f),C(V9.$$.fragment,f),C(X9.$$.fragment,f),C(Q9.$$.fragment,f),C(iE.$$.fragment,f),C(W9.$$.fragment,f),C(vE.$$.fragment,f),C(H9.$$.fragment,f),C(U9.$$.fragment,f),C(Y9.$$.fragment,f),C(TE.$$.fragment,f),C(K9.$$.fragment,f),C(HE.$$.fragment,f),C(Z9.$$.fragment,f),C(ex.$$.fragment,f),C(rx.$$.fragment,f),C(JE.$$.fragment,f),C(tx.$$.fragment,f),C(h4.$$.fragment,f),C(ax.$$.fragment,f),C(nx.$$.fragment,f),C(lx.$$.fragment,f),C(_4.$$.fragment,f),C(ix.$$.fragment,f),C(v4.$$.fragment,f),C(cx.$$.fragment,f),C(fx.$$.fragment,f),C(gx.$$.fragment,f),C(T4.$$.fragment,f),C(hx.$$.fragment,f),C(E4.$$.fragment,f),C(px.$$.fragment,f),C(_x.$$.fragment,f),C(bx.$$.fragment,f),C(w4.$$.fragment,f),C(vx.$$.fragment,f),C(Q4.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(H4.$$.fragment,f),C(Cx.$$.fragment,f),C(pC.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(yx.$$.fragment,f),C(uC.$$.fragment,f),C(xx.$$.fragment,f),C(vC.$$.fragment,f),C($x.$$.fragment,f),C(kx.$$.fragment,f),C(Rx.$$.fragment,f),C(TC.$$.fragment,f),C(Px.$$.fragment,f),C(EC.$$.fragment,f),C(Bx.$$.fragment,f),C(Ix.$$.fragment,f),C(qx.$$.fragment,f),C(wC.$$.fragment,f),C(jx.$$.fragment,f),C(ZC.$$.fragment,f),C(Dx.$$.fragment,f),C(Gx.$$.fragment,f),C(Vx.$$.fragment,f),C(o5.$$.fragment,f),C(Xx.$$.fragment,f),C(m5.$$.fragment,f),C(zx.$$.fragment,f),C(Qx.$$.fragment,f),C(Hx.$$.fragment,f),C(h5.$$.fragment,f),C(Ux.$$.fragment,f),C(y5.$$.fragment,f),C(Jx.$$.fragment,f),C(Yx.$$.fragment,f),C(Zx.$$.fragment,f),C($5.$$.fragment,f),C(e$.$$.fragment,f),C(G5.$$.fragment,f),C(o$.$$.fragment,f),C(r$.$$.fragment,f),C(a$.$$.fragment,f),C(V5.$$.fragment,f),C(n$.$$.fragment,f),C(e3.$$.fragment,f),C(s$.$$.fragment,f),C(l$.$$.fragment,f),C(d$.$$.fragment,f),C(r3.$$.fragment,f),C(c$.$$.fragment,f),C(g3.$$.fragment,f),C(f$.$$.fragment,f),C(m$.$$.fragment,f),C(h$.$$.fragment,f),C(p3.$$.fragment,f),C(p$.$$.fragment,f),C(A3.$$.fragment,f),C(_$.$$.fragment,f),C(u$.$$.fragment,f),C(v$.$$.fragment,f),C(y3.$$.fragment,f),C(F$.$$.fragment,f),C(N3.$$.fragment,f),C(T$.$$.fragment,f),C(M$.$$.fragment,f),C(C$.$$.fragment,f),C(j3.$$.fragment,f),C(w$.$$.fragment,f),C(H3.$$.fragment,f),C(A$.$$.fragment,f),C(L$.$$.fragment,f),C(x$.$$.fragment,f),C(J3.$$.fragment,f),C($$.$$.fragment,f),C(K3.$$.fragment,f),C(k$.$$.fragment,f),C(S$.$$.fragment,f),C(P$.$$.fragment,f),C(e0.$$.fragment,f),C(B$.$$.fragment,f),C(t0.$$.fragment,f),C(N$.$$.fragment,f),C(q$.$$.fragment,f),C(D$.$$.fragment,f),C(n0.$$.fragment,f),C(G$.$$.fragment,f),C(l0.$$.fragment,f),rXe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(yf),f&&t(at),f&&t(Oe),f&&t(Qe),f&&t($f),w(xa,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t($a),f&&t(YGe),f&&t(yi),w(SA),f&&t(KGe),f&&t(Nn),f&&t(ZGe),w(RA,f),f&&t(eOe),f&&t(cS),f&&t(oOe),w(Rf,f),f&&t(rOe),f&&t(xi),w(PA),f&&t(tOe),f&&t(wo),w(BA),w(qA),w(Og),w(jA),f&&t(aOe),f&&t(ki),w(DA),f&&t(nOe),f&&t(Ao),w(GA),w(XA),w(wh),w(zA),f&&t(sOe),f&&t(Si),w(QA),f&&t(lOe),f&&t(Lo),w(WA),w(JA),w(sp),w(lp),w(YA),f&&t(iOe),f&&t(Ri),w(KA),f&&t(dOe),f&&t(yo),w(ZA),w(rL),w(Lp),w(yp),w(tL),f&&t(cOe),f&&t(Bi),w(aL),f&&t(fOe),f&&t(xo),w(nL),w(lL),w(kp),w(iL),w(Su),f&&t(mOe),f&&t(qi),w(dL),f&&t(gOe),f&&t($o),w(cL),w(mL),w(Pu),w(gL),w(A2),f&&t(hOe),f&&t(Gi),w(hL),f&&t(pOe),f&&t(ko),w(pL),w(uL),w(y2),w(bL),w(h1),f&&t(_Oe),f&&t(Xi),w(vL),f&&t(uOe),f&&t(So),w(FL),w(ML),w(_1),w(EL),w(ob),f&&t(bOe),f&&t(Wi),w(CL),f&&t(vOe),f&&t(Ro),w(wL),w(LL),w(tb),w(yL),w(Mb),f&&t(FOe),f&&t(Ji),w(xL),f&&t(TOe),f&&t(Po),w($L),w(SL),w(Cb),w(RL),w(Tv),f&&t(MOe),f&&t(Zi),w(PL),f&&t(EOe),f&&t(Bo),w(BL),w(NL),w(Ev),w(qL),w(oF),f&&t(COe),f&&t(rd),w(jL),f&&t(wOe),f&&t(Io),w(DL),w(OL),w(tF),w(VL),w(fF),f&&t(AOe),f&&t(nd),w(XL),f&&t(LOe),f&&t(qo),w(zL),w(WL),w(gF),w(HL),w(YF),f&&t(yOe),f&&t(id),w(UL),f&&t(xOe),f&&t(jo),w(JL),w(KL),w(ZF),w(ZL),w(O6),f&&t($Oe),f&&t(fd),w(ey),f&&t(kOe),f&&t(Do),w(oy),w(ty),w(X6),w(ay),w(W6),f&&t(SOe),f&&t(hd),w(ny),f&&t(ROe),f&&t(Go),w(sy),w(iy),w(U6),w(dy),w(dT),f&&t(POe),f&&t(ud),w(cy),f&&t(BOe),f&&t(Oo),w(fy),w(gy),w(fT),w(hy),w(hT),f&&t(IOe),f&&t(Fd),w(py),f&&t(NOe),f&&t(Vo),w(_y),w(by),w(_T),w(vy),w(vT),f&&t(qOe),f&&t(Ed),w(Fy),f&&t(jOe),f&&t(Xo),w(Ty),w(Ey),w(TT),w(Cy),w(ST),f&&t(DOe),f&&t(Ad),w(wy),f&&t(GOe),f&&t(zo),w(Ay),w(yy),w(PT),w(xy),w(GT),f&&t(OOe),f&&t(xd),w($y),f&&t(VOe),f&&t(Qo),w(ky),w(Ry),w(VT),w(Py),w(o7),f&&t(XOe),f&&t(Sd),w(By),f&&t(zOe),f&&t(Wo),w(Iy),w(qy),w(t7),w(jy),w(l7),f&&t(QOe),f&&t(Bd),w(Gy),f&&t(WOe),f&&t(Ho),w(Oy),w(Xy),w(d7),w(zy),w(_7),f&&t(HOe),f&&t(qd),w(Qy),f&&t(UOe),f&&t(Uo),w(Wy),w(Uy),w(b7),w(Jy),w(E7),f&&t(JOe),f&&t(Od),w(Yy),f&&t(YOe),f&&t(Jo),w(Ky),w(e9),w(w7),w(o9),w(x7),f&&t(KOe),f&&t(zd),w(t9),f&&t(ZOe),f&&t(Yo),w(a9),w(s9),w(k7),w(l9),w(P7),f&&t(eVe),f&&t(Hd),w(i9),f&&t(oVe),f&&t(Ko),w(d9),w(f9),w(I7),w(m9),w(O7),f&&t(rVe),f&&t(Yd),w(g9),f&&t(tVe),f&&t(Zo),w(h9),w(_9),w(X7),w(u9),w(W7),f&&t(aVe),f&&t(ec),w(b9),f&&t(nVe),f&&t(er),w(v9),w(T9),w(U7),w(M9),w(O8),f&&t(sVe),f&&t(tc),w(E9),f&&t(lVe),f&&t(or),w(C9),w(A9),w(X8),w(L9),w(hM),f&&t(iVe),f&&t(sc),w(y9),f&&t(dVe),f&&t(rr),w(x9),w(k9),w(_M),w(S9),w($M),f&&t(cVe),f&&t(dc),w(R9),f&&t(fVe),f&&t(tr),w(P9),w(I9),w(SM),w(N9),w(NM),f&&t(mVe),f&&t(mc),w(q9),f&&t(gVe),f&&t(ar),w(j9),w(G9),w(jM),w(O9),w(sE),f&&t(hVe),f&&t(pc),w(V9),f&&t(pVe),f&&t(nr),w(X9),w(Q9),w(iE),w(W9),w(vE),f&&t(_Ve),f&&t(bc),w(H9),f&&t(uVe),f&&t(sr),w(U9),w(Y9),w(TE),w(K9),w(HE),f&&t(bVe),f&&t(Tc),w(Z9),f&&t(vVe),f&&t(lr),w(ex),w(rx),w(JE),w(tx),w(h4),f&&t(FVe),f&&t(Cc),w(ax),f&&t(TVe),f&&t(ir),w(nx),w(lx),w(_4),w(ix),w(v4),f&&t(MVe),f&&t(Lc),w(cx),f&&t(EVe),f&&t(dr),w(fx),w(gx),w(T4),w(hx),w(E4),f&&t(CVe),f&&t($c),w(px),f&&t(wVe),f&&t(cr),w(_x),w(bx),w(w4),w(vx),w(Q4),f&&t(AVe),f&&t(Rc),w(Fx),f&&t(LVe),f&&t(fr),w(Tx),w(Ex),w(H4),w(Cx),w(pC),f&&t(yVe),f&&t(Ic),w(wx),f&&t(xVe),f&&t(mr),w(Ax),w(yx),w(uC),w(xx),w(vC),f&&t($Ve),f&&t(jc),w($x),f&&t(kVe),f&&t(gr),w(kx),w(Rx),w(TC),w(Px),w(EC),f&&t(SVe),f&&t(Oc),w(Bx),f&&t(RVe),f&&t(hr),w(Ix),w(qx),w(wC),w(jx),w(ZC),f&&t(PVe),f&&t(zc),w(Dx),f&&t(BVe),f&&t(pr),w(Gx),w(Vx),w(o5),w(Xx),w(m5),f&&t(IVe),f&&t(Hc),w(zx),f&&t(NVe),f&&t(_r),w(Qx),w(Hx),w(h5),w(Ux),w(y5),f&&t(qVe),f&&t(Yc),w(Jx),f&&t(jVe),f&&t(ur),w(Yx),w(Zx),w($5),w(e$),w(G5),f&&t(DVe),f&&t(ef),w(o$),f&&t(GVe),f&&t(br),w(r$),w(a$),w(V5),w(n$),w(e3),f&&t(OVe),f&&t(tf),w(s$),f&&t(VVe),f&&t(vr),w(l$),w(d$),w(r3),w(c$),w(g3),f&&t(XVe),f&&t(sf),w(f$),f&&t(zVe),f&&t(Fr),w(m$),w(h$),w(p3),w(p$),w(A3),f&&t(QVe),f&&t(cf),w(_$),f&&t(WVe),f&&t(Tr),w(u$),w(v$),w(y3),w(F$),w(N3),f&&t(HVe),f&&t(gf),w(T$),f&&t(UVe),f&&t(Mr),w(M$),w(C$),w(j3),w(w$),w(H3),f&&t(JVe),f&&t(_f),w(A$),f&&t(YVe),f&&t(Er),w(L$),w(x$),w(J3),w($$),w(K3),f&&t(KVe),f&&t(vf),w(k$),f&&t(ZVe),f&&t(Cr),w(S$),w(P$),w(e0),w(B$),w(t0),f&&t(eXe),f&&t(Mf),w(N$),f&&t(oXe),f&&t(wr),w(q$),w(D$),w(n0),w(G$),w(l0)}}}const tVt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function aVt(x){return rGt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class fVt extends KDt{constructor(g){super();ZDt(this,g,aVt,rVt,eGt,{})}}export{fVt as default,tVt as metadata};
