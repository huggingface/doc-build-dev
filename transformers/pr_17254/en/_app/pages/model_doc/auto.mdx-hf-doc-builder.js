import{S as nSt,i as sSt,s as lSt,e as a,k as l,w as F,t as o,M as iSt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as dSt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as dzr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as te}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function cSt(L){let g,v,p,m,_,d,h,Mo,gi,uf,rt,hi,pi,SA,bf,De,We,_i,yn,RA,Ln,xn,PA,ui,$n,BA,bi,vf,Ca;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),gi=a("code"),uf=o("model_type"),rt=o(" attribute is set to the same key you use when registering the config (here "),hi=a("code"),pi=o('"new-model"'),SA=o(")."),bf=l(),De=a("p"),We=o("Likewise, if your "),_i=a("code"),yn=o("NewModel"),RA=o(" is a subclass of "),Ln=a("a"),xn=o("PreTrainedModel"),PA=o(`, make sure its
`),ui=a("code"),$n=o("config_class"),BA=o(` attribute is set to the same class you use when registering the model (here
`),bi=a("code"),vf=o("NewModelConfig"),Ca=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var rk=s(p);m=r(rk,"NewModelConfig"),rk.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var vi=s(d);h=r(vi,"PretrainedConfig"),vi.forEach(t),Mo=r(Ae,`, make sure its
`),gi=n(Ae,"CODE",{});var tk=s(gi);uf=r(tk,"model_type"),tk.forEach(t),rt=r(Ae," attribute is set to the same key you use when registering the config (here "),hi=n(Ae,"CODE",{});var ak=s(hi);pi=r(ak,'"new-model"'),ak.forEach(t),SA=r(Ae,")."),Ae.forEach(t),bf=i(Qe),De=n(Qe,"P",{});var Eo=s(De);We=r(Eo,"Likewise, if your "),_i=n(Eo,"CODE",{});var wa=s(_i);yn=r(wa,"NewModel"),wa.forEach(t),RA=r(Eo," is a subclass of "),Ln=n(Eo,"A",{href:!0});var nk=s(Ln);xn=r(nk,"PreTrainedModel"),nk.forEach(t),PA=r(Eo,`, make sure its
`),ui=n(Eo,"CODE",{});var Ff=s(ui);$n=r(Ff,"config_class"),Ff.forEach(t),BA=r(Eo,` attribute is set to the same class you use when registering the model (here
`),bi=n(Eo,"CODE",{});var sk=s(bi);vf=r(sk,"NewModelConfig"),sk.forEach(t),Ca=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(Ln,"href","/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Mo),e(g,gi),e(gi,uf),e(g,rt),e(g,hi),e(hi,pi),e(g,SA),b(Qe,bf,Ae),b(Qe,De,Ae),e(De,We),e(De,_i),e(_i,yn),e(De,RA),e(De,Ln),e(Ln,xn),e(De,PA),e(De,ui),e(ui,$n),e(De,BA),e(De,bi),e(bi,vf),e(De,Ca)},d(Qe){Qe&&t(g),Qe&&t(bf),Qe&&t(De)}}}function fSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gSt(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function hSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pSt(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function _St(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ESt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ASt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ySt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $St(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ISt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function USt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Rt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ERt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ARt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Rt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ORt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function URt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ePt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oPt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rPt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tPt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aPt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nPt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sPt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lPt(L){let g,v,p,m,_,d,h,Mo,gi,uf,rt,hi,pi,SA,bf,De,We,_i,yn,RA,Ln,xn,PA,ui,$n,BA,bi,vf,Ca,Qe,Ae,rk,vi,tk,ak,Eo,wa,nk,Ff,sk,QOe,Iqe,Fi,Tf,Loe,IA,HOe,xoe,UOe,Nqe,kn,JOe,$oe,YOe,KOe,koe,ZOe,eVe,qqe,NA,jqe,lk,oVe,Dqe,Mf,Gqe,Ti,Ef,Soe,qA,rVe,Roe,tVe,Oqe,Co,jA,aVe,DA,nVe,ik,sVe,lVe,iVe,GA,dVe,Poe,cVe,fVe,mVe,Er,OA,gVe,Boe,hVe,pVe,Mi,_Ve,Ioe,uVe,bVe,Noe,vVe,FVe,TVe,A,Cf,qoe,MVe,EVe,dk,CVe,wVe,AVe,wf,joe,yVe,LVe,ck,xVe,$Ve,kVe,Af,Doe,SVe,RVe,fk,PVe,BVe,IVe,yf,Goe,NVe,qVe,mk,jVe,DVe,GVe,Lf,Ooe,OVe,VVe,gk,XVe,zVe,WVe,xf,Voe,QVe,HVe,hk,UVe,JVe,YVe,$f,Xoe,KVe,ZVe,pk,eXe,oXe,rXe,kf,zoe,tXe,aXe,_k,nXe,sXe,lXe,Sf,Woe,iXe,dXe,uk,cXe,fXe,mXe,Rf,Qoe,gXe,hXe,bk,pXe,_Xe,uXe,Pf,Hoe,bXe,vXe,vk,FXe,TXe,MXe,Bf,Uoe,EXe,CXe,Fk,wXe,AXe,yXe,If,Joe,LXe,xXe,Tk,$Xe,kXe,SXe,Nf,Yoe,RXe,PXe,Mk,BXe,IXe,NXe,qf,Koe,qXe,jXe,Ek,DXe,GXe,OXe,jf,Zoe,VXe,XXe,Ck,zXe,WXe,QXe,Df,ere,HXe,UXe,wk,JXe,YXe,KXe,Gf,ore,ZXe,eze,Ak,oze,rze,tze,Of,rre,aze,nze,yk,sze,lze,ize,Vf,tre,dze,cze,Lk,fze,mze,gze,Xf,are,hze,pze,xk,_ze,uze,bze,zf,nre,vze,Fze,$k,Tze,Mze,Eze,Wf,sre,Cze,wze,kk,Aze,yze,Lze,Qf,lre,xze,$ze,Sk,kze,Sze,Rze,Hf,ire,Pze,Bze,Rk,Ize,Nze,qze,Uf,dre,jze,Dze,Pk,Gze,Oze,Vze,Jf,cre,Xze,zze,Bk,Wze,Qze,Hze,Yf,fre,Uze,Jze,Ik,Yze,Kze,Zze,Kf,mre,eWe,oWe,Nk,rWe,tWe,aWe,Zf,gre,nWe,sWe,qk,lWe,iWe,dWe,em,hre,cWe,fWe,jk,mWe,gWe,hWe,om,pre,pWe,_We,Dk,uWe,bWe,vWe,rm,_re,FWe,TWe,Gk,MWe,EWe,CWe,tm,ure,wWe,AWe,Ok,yWe,LWe,xWe,am,bre,$We,kWe,Vk,SWe,RWe,PWe,nm,vre,BWe,IWe,Xk,NWe,qWe,jWe,sm,Fre,DWe,GWe,zk,OWe,VWe,XWe,lm,Tre,zWe,WWe,Wk,QWe,HWe,UWe,im,Mre,JWe,YWe,Qk,KWe,ZWe,eQe,dm,Ere,oQe,rQe,Hk,tQe,aQe,nQe,cm,Cre,sQe,lQe,Uk,iQe,dQe,cQe,fm,wre,fQe,mQe,Jk,gQe,hQe,pQe,mm,Are,_Qe,uQe,Yk,bQe,vQe,FQe,gm,yre,TQe,MQe,Kk,EQe,CQe,wQe,hm,Lre,AQe,yQe,Zk,LQe,xQe,$Qe,pm,xre,kQe,SQe,eS,RQe,PQe,BQe,_m,$re,IQe,NQe,oS,qQe,jQe,DQe,um,kre,GQe,OQe,rS,VQe,XQe,zQe,bm,Sre,WQe,QQe,tS,HQe,UQe,JQe,vm,Rre,YQe,KQe,aS,ZQe,eHe,oHe,Fm,Pre,rHe,tHe,nS,aHe,nHe,sHe,Tm,Bre,lHe,iHe,sS,dHe,cHe,fHe,Mm,Ire,mHe,gHe,lS,hHe,pHe,_He,Em,Nre,uHe,bHe,iS,vHe,FHe,THe,Cm,qre,MHe,EHe,dS,CHe,wHe,AHe,wm,jre,yHe,LHe,cS,xHe,$He,kHe,Am,Dre,SHe,RHe,fS,PHe,BHe,IHe,ym,Gre,NHe,qHe,mS,jHe,DHe,GHe,Lm,Ore,OHe,VHe,gS,XHe,zHe,WHe,xm,Vre,QHe,HHe,hS,UHe,JHe,YHe,$m,Xre,KHe,ZHe,pS,eUe,oUe,rUe,km,zre,tUe,aUe,_S,nUe,sUe,lUe,Sm,Wre,iUe,dUe,uS,cUe,fUe,mUe,Rm,Qre,gUe,hUe,bS,pUe,_Ue,uUe,Pm,Hre,bUe,vUe,vS,FUe,TUe,MUe,Bm,Ure,EUe,CUe,FS,wUe,AUe,yUe,Im,Jre,LUe,xUe,TS,$Ue,kUe,SUe,Nm,Yre,RUe,PUe,MS,BUe,IUe,NUe,qm,Kre,qUe,jUe,ES,DUe,GUe,OUe,jm,Zre,VUe,XUe,CS,zUe,WUe,QUe,Dm,ete,HUe,UUe,wS,JUe,YUe,KUe,Gm,ote,ZUe,eJe,AS,oJe,rJe,tJe,Om,rte,aJe,nJe,yS,sJe,lJe,iJe,Vm,tte,dJe,cJe,LS,fJe,mJe,gJe,Xm,ate,hJe,pJe,xS,_Je,uJe,bJe,zm,nte,vJe,FJe,$S,TJe,MJe,EJe,Wm,ste,CJe,wJe,kS,AJe,yJe,LJe,Qm,lte,xJe,$Je,SS,kJe,SJe,RJe,Hm,ite,PJe,BJe,RS,IJe,NJe,qJe,Um,dte,jJe,DJe,PS,GJe,OJe,VJe,Jm,cte,XJe,zJe,BS,WJe,QJe,HJe,Ym,fte,UJe,JJe,IS,YJe,KJe,ZJe,Km,mte,eYe,oYe,NS,rYe,tYe,aYe,Zm,gte,nYe,sYe,qS,lYe,iYe,dYe,eg,hte,cYe,fYe,jS,mYe,gYe,hYe,og,pte,pYe,_Ye,DS,uYe,bYe,vYe,rg,_te,FYe,TYe,GS,MYe,EYe,CYe,tg,ute,wYe,AYe,OS,yYe,LYe,xYe,ag,bte,$Ye,kYe,VS,SYe,RYe,PYe,ng,vte,BYe,IYe,XS,NYe,qYe,jYe,sg,Fte,DYe,GYe,zS,OYe,VYe,XYe,lg,Tte,zYe,WYe,WS,QYe,HYe,UYe,ig,Mte,JYe,YYe,QS,KYe,ZYe,eKe,dg,Ete,oKe,rKe,HS,tKe,aKe,nKe,cg,Cte,sKe,lKe,US,iKe,dKe,cKe,fg,wte,fKe,mKe,JS,gKe,hKe,pKe,mg,Ate,_Ke,uKe,YS,bKe,vKe,FKe,gg,yte,TKe,MKe,KS,EKe,CKe,wKe,hg,Lte,AKe,yKe,ZS,LKe,xKe,$Ke,pg,xte,kKe,SKe,eR,RKe,PKe,BKe,_g,$te,IKe,NKe,oR,qKe,jKe,DKe,ug,kte,GKe,OKe,rR,VKe,XKe,zKe,bg,Ste,WKe,QKe,tR,HKe,UKe,JKe,vg,Rte,YKe,KKe,aR,ZKe,eZe,oZe,Fg,Pte,rZe,tZe,nR,aZe,nZe,sZe,Tg,Bte,lZe,iZe,sR,dZe,cZe,fZe,Mg,Ite,mZe,gZe,lR,hZe,pZe,_Ze,Eg,Nte,uZe,bZe,iR,vZe,FZe,TZe,Cg,qte,MZe,EZe,dR,CZe,wZe,AZe,wg,jte,yZe,LZe,cR,xZe,$Ze,kZe,Ag,SZe,yg,VA,RZe,Dte,PZe,Vqe,Ei,Lg,Gte,XA,BZe,Ote,IZe,Xqe,wo,zA,NZe,WA,qZe,fR,jZe,DZe,GZe,QA,OZe,Vte,VZe,XZe,zZe,Cr,HA,WZe,Xte,QZe,HZe,Aa,UZe,zte,JZe,YZe,Wte,KZe,ZZe,Qte,eeo,oeo,reo,k,Sn,Hte,teo,aeo,mR,neo,seo,gR,leo,ieo,deo,Rn,Ute,ceo,feo,hR,meo,geo,pR,heo,peo,_eo,Pn,Jte,ueo,beo,_R,veo,Feo,uR,Teo,Meo,Eeo,Bn,Yte,Ceo,weo,bR,Aeo,yeo,vR,Leo,xeo,$eo,In,Kte,keo,Seo,FR,Reo,Peo,TR,Beo,Ieo,Neo,xg,Zte,qeo,jeo,MR,Deo,Geo,Oeo,$g,eae,Veo,Xeo,ER,zeo,Weo,Qeo,kg,oae,Heo,Ueo,CR,Jeo,Yeo,Keo,Nn,rae,Zeo,eoo,wR,ooo,roo,AR,too,aoo,noo,qn,tae,soo,loo,yR,ioo,doo,LR,coo,foo,moo,jn,aae,goo,hoo,xR,poo,_oo,$R,uoo,boo,voo,Sg,nae,Foo,Too,kR,Moo,Eoo,Coo,Rg,sae,woo,Aoo,SR,yoo,Loo,xoo,Dn,lae,$oo,koo,RR,Soo,Roo,PR,Poo,Boo,Ioo,Pg,iae,Noo,qoo,BR,joo,Doo,Goo,Gn,dae,Ooo,Voo,IR,Xoo,zoo,NR,Woo,Qoo,Hoo,On,cae,Uoo,Joo,qR,Yoo,Koo,jR,Zoo,ero,oro,Vn,fae,rro,tro,DR,aro,nro,GR,sro,lro,iro,Bg,mae,dro,cro,OR,fro,mro,gro,Xn,gae,hro,pro,VR,_ro,uro,XR,bro,vro,Fro,zn,hae,Tro,Mro,zR,Ero,Cro,WR,wro,Aro,yro,Wn,pae,Lro,xro,QR,$ro,kro,HR,Sro,Rro,Pro,Qn,_ae,Bro,Iro,UR,Nro,qro,JR,jro,Dro,Gro,Hn,uae,Oro,Vro,YR,Xro,zro,KR,Wro,Qro,Hro,Un,bae,Uro,Jro,ZR,Yro,Kro,eP,Zro,eto,oto,Ig,vae,rto,tto,oP,ato,nto,sto,Jn,Fae,lto,ito,rP,dto,cto,tP,fto,mto,gto,Ng,Tae,hto,pto,aP,_to,uto,bto,Yn,Mae,vto,Fto,nP,Tto,Mto,sP,Eto,Cto,wto,Kn,Eae,Ato,yto,lP,Lto,xto,iP,$to,kto,Sto,Zn,Cae,Rto,Pto,dP,Bto,Ito,cP,Nto,qto,jto,qg,wae,Dto,Gto,fP,Oto,Vto,Xto,es,Aae,zto,Wto,mP,Qto,Hto,gP,Uto,Jto,Yto,os,yae,Kto,Zto,hP,eao,oao,pP,rao,tao,aao,jg,Lae,nao,sao,_P,lao,iao,dao,rs,xae,cao,fao,uP,mao,gao,bP,hao,pao,_ao,ts,$ae,uao,bao,vP,vao,Fao,FP,Tao,Mao,Eao,as,kae,Cao,wao,TP,Aao,yao,MP,Lao,xao,$ao,ns,Sae,kao,Sao,EP,Rao,Pao,CP,Bao,Iao,Nao,ss,Rae,qao,jao,wP,Dao,Gao,AP,Oao,Vao,Xao,ls,Pae,zao,Wao,yP,Qao,Hao,LP,Uao,Jao,Yao,is,Bae,Kao,Zao,xP,eno,ono,$P,rno,tno,ano,Dg,Iae,nno,sno,kP,lno,ino,dno,ds,Nae,cno,fno,SP,mno,gno,RP,hno,pno,_no,Gg,qae,uno,bno,PP,vno,Fno,Tno,Og,jae,Mno,Eno,BP,Cno,wno,Ano,cs,Dae,yno,Lno,IP,xno,$no,NP,kno,Sno,Rno,fs,Gae,Pno,Bno,qP,Ino,Nno,jP,qno,jno,Dno,ms,Oae,Gno,Ono,DP,Vno,Xno,GP,zno,Wno,Qno,Vg,Vae,Hno,Uno,OP,Jno,Yno,Kno,gs,Xae,Zno,eso,VP,oso,rso,XP,tso,aso,nso,hs,zae,sso,lso,zP,iso,dso,WP,cso,fso,mso,ps,Wae,gso,hso,QP,pso,_so,HP,uso,bso,vso,_s,Qae,Fso,Tso,UP,Mso,Eso,JP,Cso,wso,Aso,us,Hae,yso,Lso,YP,xso,$so,KP,kso,Sso,Rso,Xg,Uae,Pso,Bso,ZP,Iso,Nso,qso,bs,Jae,jso,Dso,eB,Gso,Oso,oB,Vso,Xso,zso,zg,Yae,Wso,Qso,rB,Hso,Uso,Jso,Wg,Kae,Yso,Kso,tB,Zso,elo,olo,Qg,Zae,rlo,tlo,aB,alo,nlo,slo,Hg,ene,llo,ilo,nB,dlo,clo,flo,vs,one,mlo,glo,sB,hlo,plo,lB,_lo,ulo,blo,Ug,rne,vlo,Flo,iB,Tlo,Mlo,Elo,Fs,tne,Clo,wlo,dB,Alo,ylo,cB,Llo,xlo,$lo,Ts,ane,klo,Slo,fB,Rlo,Plo,mB,Blo,Ilo,Nlo,Ms,nne,qlo,jlo,gB,Dlo,Glo,hB,Olo,Vlo,Xlo,Es,sne,zlo,Wlo,pB,Qlo,Hlo,_B,Ulo,Jlo,Ylo,Cs,lne,Klo,Zlo,uB,eio,oio,bB,rio,tio,aio,ws,ine,nio,sio,vB,lio,iio,FB,dio,cio,fio,Jg,dne,mio,gio,TB,hio,pio,_io,Yg,cne,uio,bio,MB,vio,Fio,Tio,As,fne,Mio,Eio,EB,Cio,wio,CB,Aio,yio,Lio,ys,mne,xio,$io,wB,kio,Sio,AB,Rio,Pio,Bio,Ls,gne,Iio,Nio,yB,qio,jio,LB,Dio,Gio,Oio,Kg,hne,Vio,Xio,xB,zio,Wio,Qio,Zg,pne,Hio,Uio,$B,Jio,Yio,Kio,eh,_ne,Zio,edo,kB,odo,rdo,tdo,xs,une,ado,ndo,SB,sdo,ldo,RB,ido,ddo,cdo,oh,bne,fdo,mdo,PB,gdo,hdo,pdo,rh,vne,_do,udo,BB,bdo,vdo,Fdo,th,Fne,Tdo,Mdo,IB,Edo,Cdo,wdo,$s,Tne,Ado,ydo,NB,Ldo,xdo,qB,$do,kdo,Sdo,ah,Mne,Rdo,Pdo,jB,Bdo,Ido,Ndo,nh,Ene,qdo,jdo,DB,Ddo,Gdo,Odo,ks,Cne,Vdo,Xdo,GB,zdo,Wdo,OB,Qdo,Hdo,Udo,Ss,wne,Jdo,Ydo,VB,Kdo,Zdo,XB,eco,oco,rco,Rs,Ane,tco,aco,zB,nco,sco,WB,lco,ico,dco,Ps,yne,cco,fco,QB,mco,gco,HB,hco,pco,_co,sh,uco,lh,UA,bco,Lne,vco,zqe,Ci,ih,xne,JA,Fco,$ne,Tco,Wqe,Ao,YA,Mco,KA,Eco,UB,Cco,wco,Aco,ZA,yco,kne,Lco,xco,$co,He,ey,kco,Sne,Sco,Rco,ya,Pco,Rne,Bco,Ico,Pne,Nco,qco,Bne,jco,Dco,Gco,Y,dh,Ine,Oco,Vco,JB,Xco,zco,Wco,ch,Nne,Qco,Hco,YB,Uco,Jco,Yco,fh,qne,Kco,Zco,KB,efo,ofo,rfo,mh,jne,tfo,afo,ZB,nfo,sfo,lfo,gh,Dne,ifo,dfo,eI,cfo,ffo,mfo,hh,Gne,gfo,hfo,oI,pfo,_fo,ufo,ph,One,bfo,vfo,rI,Ffo,Tfo,Mfo,_h,Vne,Efo,Cfo,tI,wfo,Afo,yfo,uh,Xne,Lfo,xfo,aI,$fo,kfo,Sfo,bh,zne,Rfo,Pfo,nI,Bfo,Ifo,Nfo,vh,Wne,qfo,jfo,sI,Dfo,Gfo,Ofo,Fh,Qne,Vfo,Xfo,lI,zfo,Wfo,Qfo,Th,Hne,Hfo,Ufo,iI,Jfo,Yfo,Kfo,Mh,Une,Zfo,emo,dI,omo,rmo,tmo,Eh,Jne,amo,nmo,cI,smo,lmo,imo,Ch,Yne,dmo,cmo,fI,fmo,mmo,gmo,wh,Kne,hmo,pmo,mI,_mo,umo,bmo,Ah,Zne,vmo,Fmo,gI,Tmo,Mmo,Emo,yh,ese,Cmo,wmo,hI,Amo,ymo,Lmo,Lh,ose,xmo,$mo,pI,kmo,Smo,Rmo,xh,rse,Pmo,Bmo,_I,Imo,Nmo,qmo,$h,tse,jmo,Dmo,uI,Gmo,Omo,Vmo,kh,ase,Xmo,zmo,bI,Wmo,Qmo,Hmo,Sh,nse,Umo,Jmo,vI,Ymo,Kmo,Zmo,Rh,sse,ego,ogo,FI,rgo,tgo,ago,Ph,lse,ngo,sgo,TI,lgo,igo,dgo,Bh,ise,cgo,fgo,MI,mgo,ggo,hgo,Ih,dse,pgo,_go,EI,ugo,bgo,vgo,Nh,cse,Fgo,Tgo,CI,Mgo,Ego,Cgo,qh,fse,wgo,Ago,wI,ygo,Lgo,xgo,jh,$go,Dh,kgo,Gh,oy,Sgo,mse,Rgo,Qqe,wi,Oh,gse,ry,Pgo,hse,Bgo,Hqe,yo,ty,Igo,ay,Ngo,AI,qgo,jgo,Dgo,ny,Ggo,pse,Ogo,Vgo,Xgo,Ue,sy,zgo,_se,Wgo,Qgo,Ai,Hgo,use,Ugo,Jgo,bse,Ygo,Kgo,Zgo,he,Vh,vse,eho,oho,yI,rho,tho,aho,Xh,Fse,nho,sho,Tse,lho,iho,dho,zh,Mse,cho,fho,LI,mho,gho,hho,Wh,Ese,pho,_ho,xI,uho,bho,vho,Qh,Cse,Fho,Tho,$I,Mho,Eho,Cho,Hh,wse,who,Aho,kI,yho,Lho,xho,Uh,Ase,$ho,kho,SI,Sho,Rho,Pho,Jh,yse,Bho,Iho,RI,Nho,qho,jho,Yh,Lse,Dho,Gho,PI,Oho,Vho,Xho,Kh,xse,zho,Who,BI,Qho,Hho,Uho,Zh,$se,Jho,Yho,II,Kho,Zho,epo,ep,kse,opo,rpo,NI,tpo,apo,npo,op,Sse,spo,lpo,qI,ipo,dpo,cpo,rp,Rse,fpo,mpo,jI,gpo,hpo,ppo,tp,Pse,_po,upo,DI,bpo,vpo,Fpo,ap,Bse,Tpo,Mpo,GI,Epo,Cpo,wpo,np,Ise,Apo,ypo,OI,Lpo,xpo,$po,sp,kpo,lp,Spo,ip,ly,Rpo,Nse,Ppo,Uqe,yi,dp,qse,iy,Bpo,jse,Ipo,Jqe,Lo,dy,Npo,Li,qpo,VI,jpo,Dpo,XI,Gpo,Opo,Vpo,cy,Xpo,Dse,zpo,Wpo,Qpo,tt,fy,Hpo,Gse,Upo,Jpo,xi,Ypo,Ose,Kpo,Zpo,zI,e_o,o_o,r_o,cp,t_o,Je,my,a_o,Vse,n_o,s_o,La,l_o,Xse,i_o,d_o,zse,c_o,f_o,Wse,m_o,g_o,h_o,x,fp,Qse,p_o,__o,WI,u_o,b_o,v_o,mp,Hse,F_o,T_o,QI,M_o,E_o,C_o,gp,Use,w_o,A_o,HI,y_o,L_o,x_o,hp,Jse,$_o,k_o,UI,S_o,R_o,P_o,pp,Yse,B_o,I_o,JI,N_o,q_o,j_o,_p,Kse,D_o,G_o,YI,O_o,V_o,X_o,up,Zse,z_o,W_o,KI,Q_o,H_o,U_o,bp,ele,J_o,Y_o,ZI,K_o,Z_o,euo,vp,ole,ouo,ruo,eN,tuo,auo,nuo,Fp,rle,suo,luo,oN,iuo,duo,cuo,Tp,tle,fuo,muo,rN,guo,huo,puo,Mp,ale,_uo,uuo,tN,buo,vuo,Fuo,Ep,nle,Tuo,Muo,aN,Euo,Cuo,wuo,Cp,sle,Auo,yuo,nN,Luo,xuo,$uo,wp,lle,kuo,Suo,sN,Ruo,Puo,Buo,Ap,ile,Iuo,Nuo,lN,quo,juo,Duo,yp,dle,Guo,Ouo,iN,Vuo,Xuo,zuo,Lp,cle,Wuo,Quo,dN,Huo,Uuo,Juo,xp,fle,Yuo,Kuo,cN,Zuo,e2o,o2o,$p,mle,r2o,t2o,fN,a2o,n2o,s2o,kp,gle,l2o,i2o,mN,d2o,c2o,f2o,Sp,hle,m2o,g2o,gN,h2o,p2o,_2o,Rp,ple,u2o,b2o,hN,v2o,F2o,T2o,Pp,_le,M2o,E2o,pN,C2o,w2o,A2o,Bp,ule,y2o,L2o,_N,x2o,$2o,k2o,Ip,ble,S2o,R2o,uN,P2o,B2o,I2o,Np,vle,N2o,q2o,bN,j2o,D2o,G2o,qp,Fle,O2o,V2o,vN,X2o,z2o,W2o,jp,Tle,Q2o,H2o,FN,U2o,J2o,Y2o,Dp,Mle,K2o,Z2o,TN,e1o,o1o,r1o,Gp,Ele,t1o,a1o,MN,n1o,s1o,l1o,Op,Cle,i1o,d1o,EN,c1o,f1o,m1o,Bs,wle,g1o,h1o,CN,p1o,_1o,wN,u1o,b1o,v1o,Vp,Ale,F1o,T1o,AN,M1o,E1o,C1o,Xp,yle,w1o,A1o,yN,y1o,L1o,x1o,zp,Lle,$1o,k1o,LN,S1o,R1o,P1o,Wp,xle,B1o,I1o,xN,N1o,q1o,j1o,Qp,$le,D1o,G1o,$N,O1o,V1o,X1o,Hp,kle,z1o,W1o,kN,Q1o,H1o,U1o,Up,Sle,J1o,Y1o,SN,K1o,Z1o,ebo,Jp,Rle,obo,rbo,RN,tbo,abo,nbo,Yp,Ple,sbo,lbo,PN,ibo,dbo,cbo,Kp,Ble,fbo,mbo,BN,gbo,hbo,pbo,Zp,Ile,_bo,ubo,IN,bbo,vbo,Fbo,e_,Nle,Tbo,Mbo,NN,Ebo,Cbo,wbo,o_,qle,Abo,ybo,qN,Lbo,xbo,$bo,r_,jle,kbo,Sbo,jN,Rbo,Pbo,Bbo,t_,Dle,Ibo,Nbo,DN,qbo,jbo,Dbo,a_,Gle,Gbo,Obo,GN,Vbo,Xbo,zbo,n_,Ole,Wbo,Qbo,ON,Hbo,Ubo,Jbo,s_,Vle,Ybo,Kbo,VN,Zbo,e4o,o4o,l_,Xle,r4o,t4o,XN,a4o,n4o,s4o,i_,zle,l4o,i4o,zN,d4o,c4o,f4o,d_,Wle,m4o,g4o,WN,h4o,p4o,_4o,c_,Qle,u4o,b4o,QN,v4o,F4o,T4o,f_,Hle,M4o,E4o,HN,C4o,w4o,A4o,m_,Ule,y4o,L4o,UN,x4o,$4o,k4o,g_,Jle,S4o,R4o,JN,P4o,B4o,I4o,h_,Yle,N4o,q4o,YN,j4o,D4o,G4o,p_,Kle,O4o,V4o,KN,X4o,z4o,W4o,__,Zle,Q4o,H4o,ZN,U4o,J4o,Y4o,u_,eie,K4o,Z4o,eq,evo,ovo,rvo,b_,oie,tvo,avo,oq,nvo,svo,lvo,v_,rie,ivo,dvo,rq,cvo,fvo,mvo,F_,tie,gvo,hvo,tq,pvo,_vo,uvo,T_,aie,bvo,vvo,aq,Fvo,Tvo,Mvo,M_,nie,Evo,Cvo,nq,wvo,Avo,yvo,E_,sie,Lvo,xvo,sq,$vo,kvo,Svo,C_,lie,Rvo,Pvo,lq,Bvo,Ivo,Nvo,w_,iie,qvo,jvo,iq,Dvo,Gvo,Ovo,A_,die,Vvo,Xvo,dq,zvo,Wvo,Qvo,y_,cie,Hvo,Uvo,cq,Jvo,Yvo,Kvo,L_,fie,Zvo,e5o,fq,o5o,r5o,t5o,x_,mie,a5o,n5o,mq,s5o,l5o,i5o,$_,gie,d5o,c5o,gq,f5o,m5o,g5o,k_,hie,h5o,p5o,hq,_5o,u5o,b5o,S_,pie,v5o,F5o,pq,T5o,M5o,E5o,R_,_ie,C5o,w5o,_q,A5o,y5o,L5o,P_,uie,x5o,$5o,uq,k5o,S5o,R5o,B_,bie,P5o,B5o,bq,I5o,N5o,q5o,I_,vie,j5o,D5o,vq,G5o,O5o,V5o,N_,Fie,X5o,z5o,Fq,W5o,Q5o,H5o,q_,Tie,U5o,J5o,Tq,Y5o,K5o,Z5o,j_,Mie,eFo,oFo,Mq,rFo,tFo,aFo,D_,Eie,nFo,sFo,Eq,lFo,iFo,dFo,G_,Cie,cFo,fFo,Cq,mFo,gFo,hFo,O_,wie,pFo,_Fo,wq,uFo,bFo,vFo,V_,Aie,FFo,TFo,Aq,MFo,EFo,CFo,X_,yie,wFo,AFo,yq,yFo,LFo,xFo,z_,Lie,$Fo,kFo,Lq,SFo,RFo,PFo,W_,xie,BFo,IFo,xq,NFo,qFo,jFo,Q_,$ie,DFo,GFo,$q,OFo,VFo,XFo,H_,kie,zFo,WFo,kq,QFo,HFo,UFo,U_,Sie,JFo,YFo,Sq,KFo,ZFo,eTo,J_,Rie,oTo,rTo,Rq,tTo,aTo,nTo,Y_,Pie,sTo,lTo,Pq,iTo,dTo,cTo,K_,Bie,fTo,mTo,Bq,gTo,hTo,pTo,Z_,Iie,_To,uTo,Iq,bTo,vTo,FTo,eu,Nie,TTo,MTo,Nq,ETo,CTo,wTo,ou,qie,ATo,yTo,qq,LTo,xTo,$To,ru,jie,kTo,STo,jq,RTo,PTo,BTo,tu,Die,ITo,NTo,Dq,qTo,jTo,DTo,au,Gie,GTo,OTo,Gq,VTo,XTo,zTo,nu,WTo,Oie,QTo,HTo,Vie,UTo,JTo,su,Yqe,$i,lu,Xie,gy,YTo,zie,KTo,Kqe,xo,hy,ZTo,ki,e7o,Oq,o7o,r7o,Vq,t7o,a7o,n7o,py,s7o,Wie,l7o,i7o,d7o,at,_y,c7o,Qie,f7o,m7o,Si,g7o,Hie,h7o,p7o,Xq,_7o,u7o,b7o,iu,v7o,Ye,uy,F7o,Uie,T7o,M7o,xa,E7o,Jie,C7o,w7o,Yie,A7o,y7o,Kie,L7o,x7o,$7o,G,du,Zie,k7o,S7o,zq,R7o,P7o,B7o,cu,ede,I7o,N7o,Wq,q7o,j7o,D7o,fu,ode,G7o,O7o,Qq,V7o,X7o,z7o,mu,rde,W7o,Q7o,Hq,H7o,U7o,J7o,gu,tde,Y7o,K7o,Uq,Z7o,eMo,oMo,hu,ade,rMo,tMo,Jq,aMo,nMo,sMo,pu,nde,lMo,iMo,Yq,dMo,cMo,fMo,_u,sde,mMo,gMo,Kq,hMo,pMo,_Mo,uu,lde,uMo,bMo,Zq,vMo,FMo,TMo,bu,ide,MMo,EMo,ej,CMo,wMo,AMo,vu,dde,yMo,LMo,oj,xMo,$Mo,kMo,Fu,cde,SMo,RMo,rj,PMo,BMo,IMo,Tu,fde,NMo,qMo,tj,jMo,DMo,GMo,Mu,mde,OMo,VMo,aj,XMo,zMo,WMo,Eu,gde,QMo,HMo,nj,UMo,JMo,YMo,Cu,hde,KMo,ZMo,sj,eEo,oEo,rEo,wu,pde,tEo,aEo,lj,nEo,sEo,lEo,Au,_de,iEo,dEo,ij,cEo,fEo,mEo,yu,ude,gEo,hEo,dj,pEo,_Eo,uEo,Lu,bde,bEo,vEo,cj,FEo,TEo,MEo,xu,vde,EEo,CEo,fj,wEo,AEo,yEo,$u,Fde,LEo,xEo,mj,$Eo,kEo,SEo,ku,Tde,REo,PEo,gj,BEo,IEo,NEo,Su,Mde,qEo,jEo,hj,DEo,GEo,OEo,Ru,Ede,VEo,XEo,pj,zEo,WEo,QEo,Pu,Cde,HEo,UEo,_j,JEo,YEo,KEo,Bu,wde,ZEo,eCo,uj,oCo,rCo,tCo,Iu,Ade,aCo,nCo,bj,sCo,lCo,iCo,Nu,yde,dCo,cCo,vj,fCo,mCo,gCo,qu,Lde,hCo,pCo,Fj,_Co,uCo,bCo,ju,xde,vCo,FCo,Tj,TCo,MCo,ECo,Du,$de,CCo,wCo,Mj,ACo,yCo,LCo,Gu,kde,xCo,$Co,Ej,kCo,SCo,RCo,Ou,Sde,PCo,BCo,Cj,ICo,NCo,qCo,Vu,Rde,jCo,DCo,wj,GCo,OCo,VCo,Xu,Pde,XCo,zCo,Aj,WCo,QCo,HCo,zu,Bde,UCo,JCo,yj,YCo,KCo,ZCo,Wu,Ide,e3o,o3o,Lj,r3o,t3o,a3o,Qu,Nde,n3o,s3o,xj,l3o,i3o,d3o,Hu,qde,c3o,f3o,$j,m3o,g3o,h3o,Uu,jde,p3o,_3o,kj,u3o,b3o,v3o,Ju,Dde,F3o,T3o,Sj,M3o,E3o,C3o,Yu,w3o,Gde,A3o,y3o,Ode,L3o,x3o,Ku,Zqe,Ri,Zu,Vde,by,$3o,Xde,k3o,eje,$o,vy,S3o,Pi,R3o,Rj,P3o,B3o,Pj,I3o,N3o,q3o,Fy,j3o,zde,D3o,G3o,O3o,nt,Ty,V3o,Wde,X3o,z3o,Bi,W3o,Qde,Q3o,H3o,Bj,U3o,J3o,Y3o,e2,K3o,Ke,My,Z3o,Hde,e0o,o0o,$a,r0o,Ude,t0o,a0o,Jde,n0o,s0o,Yde,l0o,i0o,d0o,z,o2,Kde,c0o,f0o,Ij,m0o,g0o,h0o,r2,Zde,p0o,_0o,Nj,u0o,b0o,v0o,t2,ece,F0o,T0o,qj,M0o,E0o,C0o,a2,oce,w0o,A0o,jj,y0o,L0o,x0o,n2,rce,$0o,k0o,Dj,S0o,R0o,P0o,s2,tce,B0o,I0o,Gj,N0o,q0o,j0o,l2,ace,D0o,G0o,Oj,O0o,V0o,X0o,i2,nce,z0o,W0o,Vj,Q0o,H0o,U0o,d2,sce,J0o,Y0o,Xj,K0o,Z0o,ewo,c2,lce,owo,rwo,zj,two,awo,nwo,f2,ice,swo,lwo,Wj,iwo,dwo,cwo,m2,dce,fwo,mwo,Qj,gwo,hwo,pwo,g2,cce,_wo,uwo,Hj,bwo,vwo,Fwo,h2,fce,Two,Mwo,Uj,Ewo,Cwo,wwo,p2,mce,Awo,ywo,Jj,Lwo,xwo,$wo,_2,gce,kwo,Swo,Yj,Rwo,Pwo,Bwo,u2,hce,Iwo,Nwo,Kj,qwo,jwo,Dwo,b2,pce,Gwo,Owo,Zj,Vwo,Xwo,zwo,v2,_ce,Wwo,Qwo,eD,Hwo,Uwo,Jwo,F2,uce,Ywo,Kwo,oD,Zwo,e6o,o6o,T2,bce,r6o,t6o,rD,a6o,n6o,s6o,M2,vce,l6o,i6o,tD,d6o,c6o,f6o,E2,Fce,m6o,g6o,aD,h6o,p6o,_6o,C2,Tce,u6o,b6o,nD,v6o,F6o,T6o,w2,Mce,M6o,E6o,sD,C6o,w6o,A6o,A2,Ece,y6o,L6o,lD,x6o,$6o,k6o,y2,Cce,S6o,R6o,iD,P6o,B6o,I6o,L2,wce,N6o,q6o,dD,j6o,D6o,G6o,x2,Ace,O6o,V6o,cD,X6o,z6o,W6o,$2,yce,Q6o,H6o,fD,U6o,J6o,Y6o,k2,Lce,K6o,Z6o,mD,eAo,oAo,rAo,S2,xce,tAo,aAo,gD,nAo,sAo,lAo,R2,$ce,iAo,dAo,hD,cAo,fAo,mAo,P2,kce,gAo,hAo,pD,pAo,_Ao,uAo,B2,Sce,bAo,vAo,_D,FAo,TAo,MAo,I2,Rce,EAo,CAo,uD,wAo,AAo,yAo,N2,Pce,LAo,xAo,bD,$Ao,kAo,SAo,q2,RAo,Bce,PAo,BAo,Ice,IAo,NAo,j2,oje,Ii,D2,Nce,Ey,qAo,qce,jAo,rje,ko,Cy,DAo,Ni,GAo,vD,OAo,VAo,FD,XAo,zAo,WAo,wy,QAo,jce,HAo,UAo,JAo,st,Ay,YAo,Dce,KAo,ZAo,qi,eyo,Gce,oyo,ryo,TD,tyo,ayo,nyo,G2,syo,Ze,yy,lyo,Oce,iyo,dyo,ka,cyo,Vce,fyo,myo,Xce,gyo,hyo,zce,pyo,_yo,uyo,W,O2,Wce,byo,vyo,MD,Fyo,Tyo,Myo,V2,Qce,Eyo,Cyo,ED,wyo,Ayo,yyo,X2,Hce,Lyo,xyo,CD,$yo,kyo,Syo,z2,Uce,Ryo,Pyo,wD,Byo,Iyo,Nyo,W2,Jce,qyo,jyo,AD,Dyo,Gyo,Oyo,Q2,Yce,Vyo,Xyo,yD,zyo,Wyo,Qyo,H2,Kce,Hyo,Uyo,LD,Jyo,Yyo,Kyo,U2,Zce,Zyo,eLo,xD,oLo,rLo,tLo,J2,efe,aLo,nLo,$D,sLo,lLo,iLo,Y2,ofe,dLo,cLo,kD,fLo,mLo,gLo,K2,rfe,hLo,pLo,SD,_Lo,uLo,bLo,Z2,tfe,vLo,FLo,RD,TLo,MLo,ELo,e1,afe,CLo,wLo,PD,ALo,yLo,LLo,o1,nfe,xLo,$Lo,BD,kLo,SLo,RLo,r1,sfe,PLo,BLo,ID,ILo,NLo,qLo,t1,lfe,jLo,DLo,ND,GLo,OLo,VLo,a1,ife,XLo,zLo,qD,WLo,QLo,HLo,n1,dfe,ULo,JLo,jD,YLo,KLo,ZLo,s1,cfe,e8o,o8o,DD,r8o,t8o,a8o,l1,ffe,n8o,s8o,GD,l8o,i8o,d8o,i1,mfe,c8o,f8o,OD,m8o,g8o,h8o,d1,gfe,p8o,_8o,VD,u8o,b8o,v8o,c1,hfe,F8o,T8o,XD,M8o,E8o,C8o,f1,pfe,w8o,A8o,zD,y8o,L8o,x8o,m1,_fe,$8o,k8o,WD,S8o,R8o,P8o,g1,ufe,B8o,I8o,QD,N8o,q8o,j8o,h1,bfe,D8o,G8o,HD,O8o,V8o,X8o,p1,vfe,z8o,W8o,UD,Q8o,H8o,U8o,_1,Ffe,J8o,Y8o,JD,K8o,Z8o,e9o,u1,Tfe,o9o,r9o,YD,t9o,a9o,n9o,b1,Mfe,s9o,l9o,KD,i9o,d9o,c9o,v1,Efe,f9o,m9o,Cfe,g9o,h9o,p9o,F1,wfe,_9o,u9o,ZD,b9o,v9o,F9o,T1,Afe,T9o,M9o,eG,E9o,C9o,w9o,M1,yfe,A9o,y9o,oG,L9o,x9o,$9o,E1,Lfe,k9o,S9o,rG,R9o,P9o,B9o,C1,I9o,xfe,N9o,q9o,$fe,j9o,D9o,w1,tje,ji,A1,kfe,Ly,G9o,Sfe,O9o,aje,So,xy,V9o,Di,X9o,tG,z9o,W9o,aG,Q9o,H9o,U9o,$y,J9o,Rfe,Y9o,K9o,Z9o,lt,ky,exo,Pfe,oxo,rxo,Gi,txo,Bfe,axo,nxo,nG,sxo,lxo,ixo,y1,dxo,eo,Sy,cxo,Ife,fxo,mxo,Sa,gxo,Nfe,hxo,pxo,qfe,_xo,uxo,jfe,bxo,vxo,Fxo,_e,L1,Dfe,Txo,Mxo,sG,Exo,Cxo,wxo,x1,Gfe,Axo,yxo,lG,Lxo,xxo,$xo,$1,Ofe,kxo,Sxo,iG,Rxo,Pxo,Bxo,k1,Vfe,Ixo,Nxo,dG,qxo,jxo,Dxo,S1,Xfe,Gxo,Oxo,cG,Vxo,Xxo,zxo,R1,zfe,Wxo,Qxo,fG,Hxo,Uxo,Jxo,P1,Wfe,Yxo,Kxo,mG,Zxo,e$o,o$o,B1,Qfe,r$o,t$o,gG,a$o,n$o,s$o,I1,Hfe,l$o,i$o,hG,d$o,c$o,f$o,N1,Ufe,m$o,g$o,pG,h$o,p$o,_$o,q1,Jfe,u$o,b$o,_G,v$o,F$o,T$o,j1,Yfe,M$o,E$o,uG,C$o,w$o,A$o,D1,Kfe,y$o,L$o,bG,x$o,$$o,k$o,G1,Zfe,S$o,R$o,vG,P$o,B$o,I$o,O1,eme,N$o,q$o,FG,j$o,D$o,G$o,V1,ome,O$o,V$o,TG,X$o,z$o,W$o,X1,Q$o,rme,H$o,U$o,tme,J$o,Y$o,z1,nje,Oi,W1,ame,Ry,K$o,nme,Z$o,sje,Ro,Py,eko,Vi,oko,MG,rko,tko,EG,ako,nko,sko,By,lko,sme,iko,dko,cko,it,Iy,fko,lme,mko,gko,Xi,hko,ime,pko,_ko,CG,uko,bko,vko,Q1,Fko,oo,Ny,Tko,dme,Mko,Eko,Ra,Cko,cme,wko,Ako,fme,yko,Lko,mme,xko,$ko,kko,N,H1,gme,Sko,Rko,wG,Pko,Bko,Iko,U1,hme,Nko,qko,AG,jko,Dko,Gko,J1,pme,Oko,Vko,yG,Xko,zko,Wko,Y1,_me,Qko,Hko,LG,Uko,Jko,Yko,K1,ume,Kko,Zko,xG,eSo,oSo,rSo,Z1,bme,tSo,aSo,$G,nSo,sSo,lSo,eb,vme,iSo,dSo,kG,cSo,fSo,mSo,ob,Fme,gSo,hSo,SG,pSo,_So,uSo,rb,Tme,bSo,vSo,RG,FSo,TSo,MSo,tb,Mme,ESo,CSo,PG,wSo,ASo,ySo,ab,Eme,LSo,xSo,BG,$So,kSo,SSo,nb,Cme,RSo,PSo,IG,BSo,ISo,NSo,sb,wme,qSo,jSo,NG,DSo,GSo,OSo,lb,Ame,VSo,XSo,qG,zSo,WSo,QSo,ib,yme,HSo,USo,jG,JSo,YSo,KSo,db,Lme,ZSo,eRo,DG,oRo,rRo,tRo,cb,xme,aRo,nRo,GG,sRo,lRo,iRo,fb,$me,dRo,cRo,OG,fRo,mRo,gRo,mb,kme,hRo,pRo,VG,_Ro,uRo,bRo,gb,Sme,vRo,FRo,XG,TRo,MRo,ERo,hb,Rme,CRo,wRo,zG,ARo,yRo,LRo,pb,Pme,xRo,$Ro,WG,kRo,SRo,RRo,_b,Bme,PRo,BRo,QG,IRo,NRo,qRo,ub,Ime,jRo,DRo,HG,GRo,ORo,VRo,bb,Nme,XRo,zRo,UG,WRo,QRo,HRo,vb,qme,URo,JRo,JG,YRo,KRo,ZRo,Fb,jme,ePo,oPo,YG,rPo,tPo,aPo,Tb,Dme,nPo,sPo,KG,lPo,iPo,dPo,Mb,Gme,cPo,fPo,ZG,mPo,gPo,hPo,Eb,Ome,pPo,_Po,eO,uPo,bPo,vPo,Cb,Vme,FPo,TPo,oO,MPo,EPo,CPo,wb,Xme,wPo,APo,rO,yPo,LPo,xPo,Ab,zme,$Po,kPo,tO,SPo,RPo,PPo,yb,Wme,BPo,IPo,aO,NPo,qPo,jPo,Lb,Qme,DPo,GPo,nO,OPo,VPo,XPo,xb,Hme,zPo,WPo,sO,QPo,HPo,UPo,$b,Ume,JPo,YPo,lO,KPo,ZPo,eBo,kb,Jme,oBo,rBo,iO,tBo,aBo,nBo,Sb,Yme,sBo,lBo,dO,iBo,dBo,cBo,Rb,Kme,fBo,mBo,cO,gBo,hBo,pBo,Pb,Zme,_Bo,uBo,fO,bBo,vBo,FBo,Bb,ege,TBo,MBo,mO,EBo,CBo,wBo,Ib,oge,ABo,yBo,gO,LBo,xBo,$Bo,Nb,rge,kBo,SBo,hO,RBo,PBo,BBo,qb,tge,IBo,NBo,pO,qBo,jBo,DBo,jb,age,GBo,OBo,_O,VBo,XBo,zBo,Db,nge,WBo,QBo,uO,HBo,UBo,JBo,Gb,YBo,sge,KBo,ZBo,lge,eIo,oIo,Ob,lje,zi,Vb,ige,qy,rIo,dge,tIo,ije,Po,jy,aIo,Wi,nIo,bO,sIo,lIo,vO,iIo,dIo,cIo,Dy,fIo,cge,mIo,gIo,hIo,dt,Gy,pIo,fge,_Io,uIo,Qi,bIo,mge,vIo,FIo,FO,TIo,MIo,EIo,Xb,CIo,ro,Oy,wIo,gge,AIo,yIo,Pa,LIo,hge,xIo,$Io,pge,kIo,SIo,_ge,RIo,PIo,BIo,K,zb,uge,IIo,NIo,TO,qIo,jIo,DIo,Wb,bge,GIo,OIo,MO,VIo,XIo,zIo,Qb,vge,WIo,QIo,EO,HIo,UIo,JIo,Hb,Fge,YIo,KIo,CO,ZIo,eNo,oNo,Ub,Tge,rNo,tNo,wO,aNo,nNo,sNo,Jb,Mge,lNo,iNo,AO,dNo,cNo,fNo,Yb,Ege,mNo,gNo,yO,hNo,pNo,_No,Kb,Cge,uNo,bNo,LO,vNo,FNo,TNo,Zb,wge,MNo,ENo,xO,CNo,wNo,ANo,e4,Age,yNo,LNo,$O,xNo,$No,kNo,o4,yge,SNo,RNo,kO,PNo,BNo,INo,r4,Lge,NNo,qNo,SO,jNo,DNo,GNo,t4,xge,ONo,VNo,RO,XNo,zNo,WNo,a4,$ge,QNo,HNo,PO,UNo,JNo,YNo,n4,kge,KNo,ZNo,BO,eqo,oqo,rqo,s4,Sge,tqo,aqo,IO,nqo,sqo,lqo,l4,Rge,iqo,dqo,NO,cqo,fqo,mqo,i4,Pge,gqo,hqo,qO,pqo,_qo,uqo,d4,Bge,bqo,vqo,jO,Fqo,Tqo,Mqo,c4,Ige,Eqo,Cqo,DO,wqo,Aqo,yqo,f4,Nge,Lqo,xqo,GO,$qo,kqo,Sqo,m4,qge,Rqo,Pqo,OO,Bqo,Iqo,Nqo,g4,jge,qqo,jqo,VO,Dqo,Gqo,Oqo,h4,Dge,Vqo,Xqo,XO,zqo,Wqo,Qqo,p4,Gge,Hqo,Uqo,zO,Jqo,Yqo,Kqo,_4,Oge,Zqo,ejo,WO,ojo,rjo,tjo,u4,Vge,ajo,njo,QO,sjo,ljo,ijo,b4,Xge,djo,cjo,HO,fjo,mjo,gjo,v4,zge,hjo,pjo,UO,_jo,ujo,bjo,F4,vjo,Wge,Fjo,Tjo,Qge,Mjo,Ejo,T4,dje,Hi,M4,Hge,Vy,Cjo,Uge,wjo,cje,Bo,Xy,Ajo,Ui,yjo,JO,Ljo,xjo,YO,$jo,kjo,Sjo,zy,Rjo,Jge,Pjo,Bjo,Ijo,ct,Wy,Njo,Yge,qjo,jjo,Ji,Djo,Kge,Gjo,Ojo,KO,Vjo,Xjo,zjo,E4,Wjo,to,Qy,Qjo,Zge,Hjo,Ujo,Ba,Jjo,ehe,Yjo,Kjo,ohe,Zjo,eDo,rhe,oDo,rDo,tDo,Yr,C4,the,aDo,nDo,ZO,sDo,lDo,iDo,w4,ahe,dDo,cDo,eV,fDo,mDo,gDo,A4,nhe,hDo,pDo,oV,_Do,uDo,bDo,y4,she,vDo,FDo,rV,TDo,MDo,EDo,L4,lhe,CDo,wDo,tV,ADo,yDo,LDo,x4,xDo,ihe,$Do,kDo,dhe,SDo,RDo,$4,fje,Yi,k4,che,Hy,PDo,fhe,BDo,mje,Io,Uy,IDo,Ki,NDo,aV,qDo,jDo,nV,DDo,GDo,ODo,Jy,VDo,mhe,XDo,zDo,WDo,ft,Yy,QDo,ghe,HDo,UDo,Zi,JDo,hhe,YDo,KDo,sV,ZDo,eGo,oGo,S4,rGo,ao,Ky,tGo,phe,aGo,nGo,Ia,sGo,_he,lGo,iGo,uhe,dGo,cGo,bhe,fGo,mGo,gGo,U,R4,vhe,hGo,pGo,lV,_Go,uGo,bGo,P4,Fhe,vGo,FGo,iV,TGo,MGo,EGo,B4,The,CGo,wGo,dV,AGo,yGo,LGo,I4,Mhe,xGo,$Go,cV,kGo,SGo,RGo,N4,Ehe,PGo,BGo,fV,IGo,NGo,qGo,q4,Che,jGo,DGo,mV,GGo,OGo,VGo,j4,whe,XGo,zGo,gV,WGo,QGo,HGo,D4,Ahe,UGo,JGo,hV,YGo,KGo,ZGo,G4,yhe,eOo,oOo,pV,rOo,tOo,aOo,O4,Lhe,nOo,sOo,_V,lOo,iOo,dOo,V4,xhe,cOo,fOo,uV,mOo,gOo,hOo,X4,$he,pOo,_Oo,bV,uOo,bOo,vOo,z4,khe,FOo,TOo,vV,MOo,EOo,COo,W4,She,wOo,AOo,FV,yOo,LOo,xOo,Q4,Rhe,$Oo,kOo,TV,SOo,ROo,POo,H4,Phe,BOo,IOo,MV,NOo,qOo,jOo,U4,Bhe,DOo,GOo,EV,OOo,VOo,XOo,J4,Ihe,zOo,WOo,CV,QOo,HOo,UOo,Y4,Nhe,JOo,YOo,wV,KOo,ZOo,eVo,K4,qhe,oVo,rVo,AV,tVo,aVo,nVo,Z4,jhe,sVo,lVo,yV,iVo,dVo,cVo,ev,Dhe,fVo,mVo,LV,gVo,hVo,pVo,ov,Ghe,_Vo,uVo,xV,bVo,vVo,FVo,rv,Ohe,TVo,MVo,$V,EVo,CVo,wVo,tv,Vhe,AVo,yVo,kV,LVo,xVo,$Vo,av,Xhe,kVo,SVo,SV,RVo,PVo,BVo,nv,zhe,IVo,NVo,RV,qVo,jVo,DVo,sv,Whe,GVo,OVo,PV,VVo,XVo,zVo,lv,Qhe,WVo,QVo,BV,HVo,UVo,JVo,iv,Hhe,YVo,KVo,IV,ZVo,eXo,oXo,dv,Uhe,rXo,tXo,NV,aXo,nXo,sXo,cv,Jhe,lXo,iXo,qV,dXo,cXo,fXo,fv,Yhe,mXo,gXo,jV,hXo,pXo,_Xo,mv,Khe,uXo,bXo,DV,vXo,FXo,TXo,gv,MXo,Zhe,EXo,CXo,epe,wXo,AXo,hv,gje,ed,pv,ope,Zy,yXo,rpe,LXo,hje,No,eL,xXo,od,$Xo,GV,kXo,SXo,OV,RXo,PXo,BXo,oL,IXo,tpe,NXo,qXo,jXo,mt,rL,DXo,ape,GXo,OXo,rd,VXo,npe,XXo,zXo,VV,WXo,QXo,HXo,_v,UXo,no,tL,JXo,spe,YXo,KXo,Na,ZXo,lpe,ezo,ozo,ipe,rzo,tzo,dpe,azo,nzo,szo,V,uv,cpe,lzo,izo,XV,dzo,czo,fzo,bv,fpe,mzo,gzo,zV,hzo,pzo,_zo,vv,mpe,uzo,bzo,WV,vzo,Fzo,Tzo,Fv,gpe,Mzo,Ezo,QV,Czo,wzo,Azo,Tv,hpe,yzo,Lzo,HV,xzo,$zo,kzo,Mv,ppe,Szo,Rzo,UV,Pzo,Bzo,Izo,Ev,_pe,Nzo,qzo,JV,jzo,Dzo,Gzo,Cv,upe,Ozo,Vzo,YV,Xzo,zzo,Wzo,wv,bpe,Qzo,Hzo,KV,Uzo,Jzo,Yzo,Av,vpe,Kzo,Zzo,ZV,eWo,oWo,rWo,yv,Fpe,tWo,aWo,eX,nWo,sWo,lWo,Lv,Tpe,iWo,dWo,oX,cWo,fWo,mWo,xv,Mpe,gWo,hWo,rX,pWo,_Wo,uWo,$v,Epe,bWo,vWo,tX,FWo,TWo,MWo,kv,Cpe,EWo,CWo,aX,wWo,AWo,yWo,Sv,wpe,LWo,xWo,nX,$Wo,kWo,SWo,Rv,Ape,RWo,PWo,sX,BWo,IWo,NWo,Pv,ype,qWo,jWo,lX,DWo,GWo,OWo,Bv,Lpe,VWo,XWo,iX,zWo,WWo,QWo,Iv,xpe,HWo,UWo,dX,JWo,YWo,KWo,Nv,$pe,ZWo,eQo,cX,oQo,rQo,tQo,qv,kpe,aQo,nQo,fX,sQo,lQo,iQo,jv,Spe,dQo,cQo,mX,fQo,mQo,gQo,Dv,Rpe,hQo,pQo,gX,_Qo,uQo,bQo,Gv,Ppe,vQo,FQo,hX,TQo,MQo,EQo,Ov,Bpe,CQo,wQo,pX,AQo,yQo,LQo,Vv,Ipe,xQo,$Qo,_X,kQo,SQo,RQo,Xv,Npe,PQo,BQo,uX,IQo,NQo,qQo,zv,qpe,jQo,DQo,bX,GQo,OQo,VQo,Wv,jpe,XQo,zQo,vX,WQo,QQo,HQo,Qv,Dpe,UQo,JQo,FX,YQo,KQo,ZQo,Hv,Gpe,eHo,oHo,TX,rHo,tHo,aHo,Uv,Ope,nHo,sHo,MX,lHo,iHo,dHo,Jv,Vpe,cHo,fHo,EX,mHo,gHo,hHo,Yv,Xpe,pHo,_Ho,CX,uHo,bHo,vHo,Kv,zpe,FHo,THo,wX,MHo,EHo,CHo,Zv,Wpe,wHo,AHo,AX,yHo,LHo,xHo,e5,Qpe,$Ho,kHo,yX,SHo,RHo,PHo,o5,Hpe,BHo,IHo,LX,NHo,qHo,jHo,r5,Upe,DHo,GHo,xX,OHo,VHo,XHo,t5,zHo,Jpe,WHo,QHo,Ype,HHo,UHo,a5,pje,td,n5,Kpe,aL,JHo,Zpe,YHo,_je,qo,nL,KHo,ad,ZHo,$X,eUo,oUo,kX,rUo,tUo,aUo,sL,nUo,e_e,sUo,lUo,iUo,gt,lL,dUo,o_e,cUo,fUo,nd,mUo,r_e,gUo,hUo,SX,pUo,_Uo,uUo,s5,bUo,so,iL,vUo,t_e,FUo,TUo,qa,MUo,a_e,EUo,CUo,n_e,wUo,AUo,s_e,yUo,LUo,xUo,l_e,l5,i_e,$Uo,kUo,RX,SUo,RUo,PUo,i5,BUo,d_e,IUo,NUo,c_e,qUo,jUo,d5,uje,sd,c5,f_e,dL,DUo,m_e,GUo,bje,jo,cL,OUo,ld,VUo,PX,XUo,zUo,BX,WUo,QUo,HUo,fL,UUo,g_e,JUo,YUo,KUo,ht,mL,ZUo,h_e,eJo,oJo,id,rJo,p_e,tJo,aJo,IX,nJo,sJo,lJo,f5,iJo,lo,gL,dJo,__e,cJo,fJo,ja,mJo,u_e,gJo,hJo,b_e,pJo,_Jo,v_e,uJo,bJo,vJo,ve,m5,F_e,FJo,TJo,NX,MJo,EJo,CJo,g5,T_e,wJo,AJo,qX,yJo,LJo,xJo,h5,M_e,$Jo,kJo,jX,SJo,RJo,PJo,p5,E_e,BJo,IJo,DX,NJo,qJo,jJo,Is,C_e,DJo,GJo,GX,OJo,VJo,OX,XJo,zJo,WJo,_5,w_e,QJo,HJo,VX,UJo,JJo,YJo,Ns,A_e,KJo,ZJo,XX,eYo,oYo,zX,rYo,tYo,aYo,pt,y_e,nYo,sYo,WX,lYo,iYo,QX,dYo,cYo,HX,fYo,mYo,gYo,u5,L_e,hYo,pYo,UX,_Yo,uYo,bYo,b5,x_e,vYo,FYo,JX,TYo,MYo,EYo,v5,$_e,CYo,wYo,YX,AYo,yYo,LYo,F5,k_e,xYo,$Yo,KX,kYo,SYo,RYo,T5,S_e,PYo,BYo,ZX,IYo,NYo,qYo,M5,R_e,jYo,DYo,ez,GYo,OYo,VYo,E5,P_e,XYo,zYo,oz,WYo,QYo,HYo,C5,UYo,B_e,JYo,YYo,I_e,KYo,ZYo,w5,vje,dd,A5,N_e,hL,eKo,q_e,oKo,Fje,Do,pL,rKo,cd,tKo,rz,aKo,nKo,tz,sKo,lKo,iKo,_L,dKo,j_e,cKo,fKo,mKo,_t,uL,gKo,D_e,hKo,pKo,fd,_Ko,G_e,uKo,bKo,az,vKo,FKo,TKo,y5,MKo,io,bL,EKo,O_e,CKo,wKo,Da,AKo,V_e,yKo,LKo,X_e,xKo,$Ko,z_e,kKo,SKo,RKo,W_e,L5,Q_e,PKo,BKo,nz,IKo,NKo,qKo,x5,jKo,H_e,DKo,GKo,U_e,OKo,VKo,$5,Tje,md,k5,J_e,vL,XKo,Y_e,zKo,Mje,Go,FL,WKo,gd,QKo,sz,HKo,UKo,lz,JKo,YKo,KKo,TL,ZKo,K_e,eZo,oZo,rZo,ut,ML,tZo,Z_e,aZo,nZo,hd,sZo,eue,lZo,iZo,iz,dZo,cZo,fZo,S5,mZo,co,EL,gZo,oue,hZo,pZo,Ga,_Zo,rue,uZo,bZo,tue,vZo,FZo,aue,TZo,MZo,EZo,Se,R5,nue,CZo,wZo,dz,AZo,yZo,LZo,P5,sue,xZo,$Zo,cz,kZo,SZo,RZo,B5,lue,PZo,BZo,fz,IZo,NZo,qZo,I5,iue,jZo,DZo,mz,GZo,OZo,VZo,N5,due,XZo,zZo,gz,WZo,QZo,HZo,q5,cue,UZo,JZo,hz,YZo,KZo,ZZo,j5,fue,eer,oer,pz,rer,ter,aer,D5,mue,ner,ser,_z,ler,ier,der,G5,gue,cer,fer,uz,mer,ger,her,O5,per,hue,_er,uer,pue,ber,ver,V5,Eje,pd,X5,_ue,CL,Fer,uue,Ter,Cje,Oo,wL,Mer,_d,Eer,bz,Cer,wer,vz,Aer,yer,Ler,AL,xer,bue,$er,ker,Ser,bt,yL,Rer,vue,Per,Ber,ud,Ier,Fue,Ner,qer,Fz,jer,Der,Ger,z5,Oer,fo,LL,Ver,Tue,Xer,zer,Oa,Wer,Mue,Qer,Her,Eue,Uer,Jer,Cue,Yer,Ker,Zer,Kr,W5,wue,eor,oor,Tz,ror,tor,aor,Q5,Aue,nor,sor,Mz,lor,ior,dor,H5,yue,cor,mor,Ez,gor,hor,por,U5,Lue,_or,uor,Cz,bor,vor,For,J5,xue,Tor,Mor,wz,Eor,Cor,wor,Y5,Aor,$ue,yor,Lor,kue,xor,$or,K5,wje,bd,Z5,Sue,xL,kor,Rue,Sor,Aje,Vo,$L,Ror,vd,Por,Az,Bor,Ior,yz,Nor,qor,jor,kL,Dor,Pue,Gor,Oor,Vor,vt,SL,Xor,Bue,zor,Wor,Fd,Qor,Iue,Hor,Uor,Lz,Jor,Yor,Kor,eF,Zor,mo,RL,err,Nue,orr,rrr,Va,trr,que,arr,nrr,jue,srr,lrr,Due,irr,drr,crr,Re,oF,Gue,frr,mrr,xz,grr,hrr,prr,rF,Oue,_rr,urr,$z,brr,vrr,Frr,tF,Vue,Trr,Mrr,kz,Err,Crr,wrr,aF,Xue,Arr,yrr,Sz,Lrr,xrr,$rr,nF,zue,krr,Srr,Rz,Rrr,Prr,Brr,sF,Wue,Irr,Nrr,Pz,qrr,jrr,Drr,lF,Que,Grr,Orr,Bz,Vrr,Xrr,zrr,iF,Hue,Wrr,Qrr,Iz,Hrr,Urr,Jrr,dF,Uue,Yrr,Krr,Nz,Zrr,etr,otr,cF,rtr,Jue,ttr,atr,Yue,ntr,str,fF,yje,Td,mF,Kue,PL,ltr,Zue,itr,Lje,Xo,BL,dtr,Md,ctr,qz,ftr,mtr,jz,gtr,htr,ptr,IL,_tr,e2e,utr,btr,vtr,Ft,NL,Ftr,o2e,Ttr,Mtr,Ed,Etr,r2e,Ctr,wtr,Dz,Atr,ytr,Ltr,gF,xtr,go,qL,$tr,t2e,ktr,Str,Xa,Rtr,a2e,Ptr,Btr,n2e,Itr,Ntr,s2e,qtr,jtr,Dtr,jL,hF,l2e,Gtr,Otr,Gz,Vtr,Xtr,ztr,pF,i2e,Wtr,Qtr,Oz,Htr,Utr,Jtr,_F,Ytr,d2e,Ktr,Ztr,c2e,ear,oar,uF,xje,Cd,bF,f2e,DL,rar,m2e,tar,$je,zo,GL,aar,wd,nar,Vz,sar,lar,Xz,iar,dar,car,OL,far,g2e,mar,gar,har,Tt,VL,par,h2e,_ar,uar,Ad,bar,p2e,Far,Tar,zz,Mar,Ear,Car,vF,war,ho,XL,Aar,_2e,yar,Lar,za,xar,u2e,$ar,kar,b2e,Sar,Rar,v2e,Par,Bar,Iar,Zr,FF,F2e,Nar,qar,Wz,jar,Dar,Gar,TF,T2e,Oar,Var,Qz,Xar,zar,War,MF,M2e,Qar,Har,Hz,Uar,Jar,Yar,EF,E2e,Kar,Zar,Uz,enr,onr,rnr,CF,C2e,tnr,anr,Jz,nnr,snr,lnr,wF,inr,w2e,dnr,cnr,A2e,fnr,mnr,AF,kje,yd,yF,y2e,zL,gnr,L2e,hnr,Sje,Wo,WL,pnr,Ld,_nr,Yz,unr,bnr,Kz,vnr,Fnr,Tnr,QL,Mnr,x2e,Enr,Cnr,wnr,Mt,HL,Anr,$2e,ynr,Lnr,xd,xnr,k2e,$nr,knr,Zz,Snr,Rnr,Pnr,LF,Bnr,po,UL,Inr,S2e,Nnr,qnr,Wa,jnr,R2e,Dnr,Gnr,P2e,Onr,Vnr,B2e,Xnr,znr,Wnr,$d,xF,I2e,Qnr,Hnr,eW,Unr,Jnr,Ynr,$F,N2e,Knr,Znr,oW,esr,osr,rsr,kF,q2e,tsr,asr,rW,nsr,ssr,lsr,SF,isr,j2e,dsr,csr,D2e,fsr,msr,RF,Rje,kd,PF,G2e,JL,gsr,O2e,hsr,Pje,Qo,YL,psr,Sd,_sr,tW,usr,bsr,aW,vsr,Fsr,Tsr,KL,Msr,V2e,Esr,Csr,wsr,Et,ZL,Asr,X2e,ysr,Lsr,Rd,xsr,z2e,$sr,ksr,nW,Ssr,Rsr,Psr,BF,Bsr,_o,e8,Isr,W2e,Nsr,qsr,Qa,jsr,Q2e,Dsr,Gsr,H2e,Osr,Vsr,U2e,Xsr,zsr,Wsr,o8,IF,J2e,Qsr,Hsr,sW,Usr,Jsr,Ysr,NF,Y2e,Ksr,Zsr,lW,elr,olr,rlr,qF,tlr,K2e,alr,nlr,Z2e,slr,llr,jF,Bje,Pd,DF,e1e,r8,ilr,o1e,dlr,Ije,Ho,t8,clr,Bd,flr,iW,mlr,glr,dW,hlr,plr,_lr,a8,ulr,r1e,blr,vlr,Flr,Ct,n8,Tlr,t1e,Mlr,Elr,Id,Clr,a1e,wlr,Alr,cW,ylr,Llr,xlr,GF,$lr,uo,s8,klr,n1e,Slr,Rlr,Ha,Plr,s1e,Blr,Ilr,l1e,Nlr,qlr,i1e,jlr,Dlr,Glr,d1e,OF,c1e,Olr,Vlr,fW,Xlr,zlr,Wlr,VF,Qlr,f1e,Hlr,Ulr,m1e,Jlr,Ylr,XF,Nje,Nd,zF,g1e,l8,Klr,h1e,Zlr,qje,Uo,i8,eir,qd,oir,mW,rir,tir,gW,air,nir,sir,d8,lir,p1e,iir,dir,cir,wt,c8,fir,_1e,mir,gir,jd,hir,u1e,pir,_ir,hW,uir,bir,vir,WF,Fir,bo,f8,Tir,b1e,Mir,Eir,Ua,Cir,v1e,wir,Air,F1e,yir,Lir,T1e,xir,$ir,kir,Ja,QF,M1e,Sir,Rir,pW,Pir,Bir,Iir,HF,E1e,Nir,qir,_W,jir,Dir,Gir,UF,C1e,Oir,Vir,uW,Xir,zir,Wir,JF,w1e,Qir,Hir,bW,Uir,Jir,Yir,YF,Kir,A1e,Zir,edr,y1e,odr,rdr,KF,jje,Dd,ZF,L1e,m8,tdr,x1e,adr,Dje,Jo,g8,ndr,Gd,sdr,vW,ldr,idr,FW,ddr,cdr,fdr,h8,mdr,$1e,gdr,hdr,pdr,At,p8,_dr,k1e,udr,bdr,Od,vdr,S1e,Fdr,Tdr,TW,Mdr,Edr,Cdr,eT,wdr,vo,_8,Adr,R1e,ydr,Ldr,Ya,xdr,P1e,$dr,kdr,B1e,Sdr,Rdr,I1e,Pdr,Bdr,Idr,N1e,oT,q1e,Ndr,qdr,MW,jdr,Ddr,Gdr,rT,Odr,j1e,Vdr,Xdr,D1e,zdr,Wdr,tT,Gje,Vd,aT,G1e,u8,Qdr,O1e,Hdr,Oje,Yo,b8,Udr,Xd,Jdr,EW,Ydr,Kdr,CW,Zdr,ecr,ocr,v8,rcr,V1e,tcr,acr,ncr,yt,F8,scr,X1e,lcr,icr,zd,dcr,z1e,ccr,fcr,wW,mcr,gcr,hcr,nT,pcr,wr,T8,_cr,W1e,ucr,bcr,Ka,vcr,Q1e,Fcr,Tcr,H1e,Mcr,Ecr,U1e,Ccr,wcr,Acr,q,sT,J1e,ycr,Lcr,AW,xcr,$cr,kcr,lT,Y1e,Scr,Rcr,yW,Pcr,Bcr,Icr,iT,K1e,Ncr,qcr,LW,jcr,Dcr,Gcr,dT,Z1e,Ocr,Vcr,xW,Xcr,zcr,Wcr,cT,ebe,Qcr,Hcr,$W,Ucr,Jcr,Ycr,fT,obe,Kcr,Zcr,kW,efr,ofr,rfr,mT,rbe,tfr,afr,SW,nfr,sfr,lfr,gT,tbe,ifr,dfr,RW,cfr,ffr,mfr,hT,abe,gfr,hfr,PW,pfr,_fr,ufr,pT,nbe,bfr,vfr,BW,Ffr,Tfr,Mfr,_T,sbe,Efr,Cfr,IW,wfr,Afr,yfr,uT,lbe,Lfr,xfr,NW,$fr,kfr,Sfr,bT,ibe,Rfr,Pfr,qW,Bfr,Ifr,Nfr,vT,dbe,qfr,jfr,jW,Dfr,Gfr,Ofr,FT,cbe,Vfr,Xfr,DW,zfr,Wfr,Qfr,TT,fbe,Hfr,Ufr,GW,Jfr,Yfr,Kfr,MT,mbe,Zfr,emr,OW,omr,rmr,tmr,qs,gbe,amr,nmr,VW,smr,lmr,XW,imr,dmr,cmr,ET,hbe,fmr,mmr,zW,gmr,hmr,pmr,CT,pbe,_mr,umr,WW,bmr,vmr,Fmr,wT,_be,Tmr,Mmr,QW,Emr,Cmr,wmr,AT,ube,Amr,ymr,HW,Lmr,xmr,$mr,yT,bbe,kmr,Smr,UW,Rmr,Pmr,Bmr,LT,vbe,Imr,Nmr,JW,qmr,jmr,Dmr,xT,Fbe,Gmr,Omr,YW,Vmr,Xmr,zmr,$T,Tbe,Wmr,Qmr,KW,Hmr,Umr,Jmr,kT,Mbe,Ymr,Kmr,ZW,Zmr,egr,ogr,ST,Ebe,rgr,tgr,eQ,agr,ngr,sgr,RT,Cbe,lgr,igr,oQ,dgr,cgr,fgr,PT,wbe,mgr,ggr,rQ,hgr,pgr,_gr,BT,Abe,ugr,bgr,tQ,vgr,Fgr,Tgr,IT,ybe,Mgr,Egr,aQ,Cgr,wgr,Agr,NT,Lbe,ygr,Lgr,nQ,xgr,$gr,kgr,qT,xbe,Sgr,Rgr,sQ,Pgr,Bgr,Igr,jT,$be,Ngr,qgr,lQ,jgr,Dgr,Ggr,DT,kbe,Ogr,Vgr,iQ,Xgr,zgr,Wgr,GT,Sbe,Qgr,Hgr,dQ,Ugr,Jgr,Ygr,OT,Rbe,Kgr,Zgr,cQ,ehr,ohr,rhr,VT,Pbe,thr,ahr,fQ,nhr,shr,lhr,XT,Bbe,ihr,dhr,mQ,chr,fhr,mhr,zT,Ibe,ghr,hhr,gQ,phr,_hr,uhr,WT,Nbe,bhr,vhr,hQ,Fhr,Thr,Mhr,QT,qbe,Ehr,Chr,pQ,whr,Ahr,yhr,HT,jbe,Lhr,xhr,_Q,$hr,khr,Shr,UT,Dbe,Rhr,Phr,uQ,Bhr,Ihr,Nhr,JT,Gbe,qhr,jhr,bQ,Dhr,Ghr,Ohr,YT,Obe,Vhr,Xhr,vQ,zhr,Whr,Qhr,KT,Vje,Wd,ZT,Vbe,M8,Hhr,Xbe,Uhr,Xje,Ko,E8,Jhr,Qd,Yhr,FQ,Khr,Zhr,TQ,epr,opr,rpr,C8,tpr,zbe,apr,npr,spr,Lt,w8,lpr,Wbe,ipr,dpr,Hd,cpr,Qbe,fpr,mpr,MQ,gpr,hpr,ppr,e7,_pr,Ar,A8,upr,Hbe,bpr,vpr,Za,Fpr,Ube,Tpr,Mpr,Jbe,Epr,Cpr,Ybe,wpr,Apr,ypr,se,o7,Kbe,Lpr,xpr,EQ,$pr,kpr,Spr,r7,Zbe,Rpr,Ppr,CQ,Bpr,Ipr,Npr,t7,e4e,qpr,jpr,wQ,Dpr,Gpr,Opr,a7,o4e,Vpr,Xpr,AQ,zpr,Wpr,Qpr,n7,r4e,Hpr,Upr,yQ,Jpr,Ypr,Kpr,s7,t4e,Zpr,e_r,LQ,o_r,r_r,t_r,l7,a4e,a_r,n_r,xQ,s_r,l_r,i_r,i7,n4e,d_r,c_r,$Q,f_r,m_r,g_r,d7,s4e,h_r,p_r,kQ,__r,u_r,b_r,c7,l4e,v_r,F_r,SQ,T_r,M_r,E_r,f7,i4e,C_r,w_r,RQ,A_r,y_r,L_r,m7,d4e,x_r,$_r,PQ,k_r,S_r,R_r,g7,c4e,P_r,B_r,BQ,I_r,N_r,q_r,h7,f4e,j_r,D_r,IQ,G_r,O_r,V_r,p7,m4e,X_r,z_r,NQ,W_r,Q_r,H_r,_7,g4e,U_r,J_r,qQ,Y_r,K_r,Z_r,u7,h4e,eur,our,jQ,rur,tur,aur,b7,p4e,nur,sur,DQ,lur,iur,dur,v7,_4e,cur,fur,GQ,mur,gur,hur,F7,u4e,pur,_ur,OQ,uur,bur,vur,T7,b4e,Fur,Tur,VQ,Mur,Eur,Cur,M7,v4e,wur,Aur,XQ,yur,Lur,xur,E7,F4e,$ur,kur,zQ,Sur,Rur,Pur,C7,zje,Ud,w7,T4e,y8,Bur,M4e,Iur,Wje,Zo,L8,Nur,Jd,qur,WQ,jur,Dur,QQ,Gur,Our,Vur,x8,Xur,E4e,zur,Wur,Qur,xt,$8,Hur,C4e,Uur,Jur,Yd,Yur,w4e,Kur,Zur,HQ,e2r,o2r,r2r,A7,t2r,yr,k8,a2r,A4e,n2r,s2r,en,l2r,y4e,i2r,d2r,L4e,c2r,f2r,x4e,m2r,g2r,h2r,Me,y7,$4e,p2r,_2r,UQ,u2r,b2r,v2r,L7,k4e,F2r,T2r,JQ,M2r,E2r,C2r,x7,S4e,w2r,A2r,YQ,y2r,L2r,x2r,$7,R4e,$2r,k2r,KQ,S2r,R2r,P2r,k7,P4e,B2r,I2r,ZQ,N2r,q2r,j2r,S7,B4e,D2r,G2r,eH,O2r,V2r,X2r,R7,I4e,z2r,W2r,oH,Q2r,H2r,U2r,P7,N4e,J2r,Y2r,rH,K2r,Z2r,e1r,B7,q4e,o1r,r1r,tH,t1r,a1r,n1r,I7,j4e,s1r,l1r,aH,i1r,d1r,c1r,N7,D4e,f1r,m1r,nH,g1r,h1r,p1r,q7,G4e,_1r,u1r,sH,b1r,v1r,F1r,j7,O4e,T1r,M1r,lH,E1r,C1r,w1r,D7,Qje,Kd,G7,V4e,S8,A1r,X4e,y1r,Hje,er,R8,L1r,Zd,x1r,iH,$1r,k1r,dH,S1r,R1r,P1r,P8,B1r,z4e,I1r,N1r,q1r,$t,B8,j1r,W4e,D1r,G1r,ec,O1r,Q4e,V1r,X1r,cH,z1r,W1r,Q1r,O7,H1r,Lr,I8,U1r,H4e,J1r,Y1r,on,K1r,U4e,Z1r,ebr,J4e,obr,rbr,Y4e,tbr,abr,nbr,rn,V7,K4e,sbr,lbr,fH,ibr,dbr,cbr,X7,Z4e,fbr,mbr,mH,gbr,hbr,pbr,z7,eve,_br,ubr,gH,bbr,vbr,Fbr,W7,ove,Tbr,Mbr,hH,Ebr,Cbr,wbr,Q7,Uje,oc,H7,rve,N8,Abr,tve,ybr,Jje,or,q8,Lbr,rc,xbr,pH,$br,kbr,_H,Sbr,Rbr,Pbr,j8,Bbr,ave,Ibr,Nbr,qbr,kt,D8,jbr,nve,Dbr,Gbr,tc,Obr,sve,Vbr,Xbr,uH,zbr,Wbr,Qbr,U7,Hbr,xr,G8,Ubr,lve,Jbr,Ybr,tn,Kbr,ive,Zbr,e4r,dve,o4r,r4r,cve,t4r,a4r,n4r,ie,J7,fve,s4r,l4r,bH,i4r,d4r,c4r,Y7,mve,f4r,m4r,vH,g4r,h4r,p4r,K7,gve,_4r,u4r,FH,b4r,v4r,F4r,Z7,hve,T4r,M4r,TH,E4r,C4r,w4r,eM,pve,A4r,y4r,MH,L4r,x4r,$4r,oM,_ve,k4r,S4r,EH,R4r,P4r,B4r,rM,uve,I4r,N4r,CH,q4r,j4r,D4r,tM,bve,G4r,O4r,wH,V4r,X4r,z4r,aM,vve,W4r,Q4r,AH,H4r,U4r,J4r,nM,Fve,Y4r,K4r,yH,Z4r,evr,ovr,sM,Tve,rvr,tvr,LH,avr,nvr,svr,lM,Mve,lvr,ivr,xH,dvr,cvr,fvr,iM,Eve,mvr,gvr,$H,hvr,pvr,_vr,dM,Cve,uvr,bvr,kH,vvr,Fvr,Tvr,cM,wve,Mvr,Evr,SH,Cvr,wvr,Avr,fM,Ave,yvr,Lvr,RH,xvr,$vr,kvr,mM,yve,Svr,Rvr,PH,Pvr,Bvr,Ivr,gM,Lve,Nvr,qvr,BH,jvr,Dvr,Gvr,hM,xve,Ovr,Vvr,IH,Xvr,zvr,Wvr,pM,$ve,Qvr,Hvr,NH,Uvr,Jvr,Yvr,_M,Yje,ac,uM,kve,O8,Kvr,Sve,Zvr,Kje,rr,V8,e5r,nc,o5r,qH,r5r,t5r,jH,a5r,n5r,s5r,X8,l5r,Rve,i5r,d5r,c5r,St,z8,f5r,Pve,m5r,g5r,sc,h5r,Bve,p5r,_5r,DH,u5r,b5r,v5r,bM,F5r,$r,W8,T5r,Ive,M5r,E5r,an,C5r,Nve,w5r,A5r,qve,y5r,L5r,jve,x5r,$5r,k5r,ye,vM,Dve,S5r,R5r,GH,P5r,B5r,I5r,FM,Gve,N5r,q5r,OH,j5r,D5r,G5r,TM,Ove,O5r,V5r,VH,X5r,z5r,W5r,MM,Vve,Q5r,H5r,XH,U5r,J5r,Y5r,EM,Xve,K5r,Z5r,zH,eFr,oFr,rFr,CM,zve,tFr,aFr,WH,nFr,sFr,lFr,wM,Wve,iFr,dFr,QH,cFr,fFr,mFr,AM,Qve,gFr,hFr,HH,pFr,_Fr,uFr,yM,Hve,bFr,vFr,UH,FFr,TFr,MFr,LM,Uve,EFr,CFr,JH,wFr,AFr,yFr,xM,Zje,lc,$M,Jve,Q8,LFr,Yve,xFr,eDe,tr,H8,$Fr,ic,kFr,YH,SFr,RFr,KH,PFr,BFr,IFr,U8,NFr,Kve,qFr,jFr,DFr,Rt,J8,GFr,Zve,OFr,VFr,dc,XFr,e5e,zFr,WFr,ZH,QFr,HFr,UFr,kM,JFr,kr,Y8,YFr,o5e,KFr,ZFr,nn,eTr,r5e,oTr,rTr,t5e,tTr,aTr,a5e,nTr,sTr,lTr,oe,SM,n5e,iTr,dTr,eU,cTr,fTr,mTr,RM,s5e,gTr,hTr,oU,pTr,_Tr,uTr,PM,l5e,bTr,vTr,rU,FTr,TTr,MTr,BM,i5e,ETr,CTr,tU,wTr,ATr,yTr,IM,d5e,LTr,xTr,aU,$Tr,kTr,STr,NM,c5e,RTr,PTr,nU,BTr,ITr,NTr,qM,f5e,qTr,jTr,sU,DTr,GTr,OTr,jM,m5e,VTr,XTr,lU,zTr,WTr,QTr,DM,g5e,HTr,UTr,iU,JTr,YTr,KTr,GM,h5e,ZTr,e7r,dU,o7r,r7r,t7r,OM,p5e,a7r,n7r,cU,s7r,l7r,i7r,VM,_5e,d7r,c7r,fU,f7r,m7r,g7r,XM,u5e,h7r,p7r,mU,_7r,u7r,b7r,zM,b5e,v7r,F7r,gU,T7r,M7r,E7r,WM,v5e,C7r,w7r,hU,A7r,y7r,L7r,QM,F5e,x7r,$7r,pU,k7r,S7r,R7r,HM,T5e,P7r,B7r,_U,I7r,N7r,q7r,UM,M5e,j7r,D7r,uU,G7r,O7r,V7r,JM,E5e,X7r,z7r,bU,W7r,Q7r,H7r,YM,C5e,U7r,J7r,vU,Y7r,K7r,Z7r,KM,w5e,eMr,oMr,FU,rMr,tMr,aMr,ZM,A5e,nMr,sMr,TU,lMr,iMr,dMr,eE,y5e,cMr,fMr,MU,mMr,gMr,hMr,oE,L5e,pMr,_Mr,EU,uMr,bMr,vMr,rE,x5e,FMr,TMr,CU,MMr,EMr,CMr,tE,$5e,wMr,AMr,wU,yMr,LMr,xMr,aE,oDe,cc,nE,k5e,K8,$Mr,S5e,kMr,rDe,ar,Z8,SMr,fc,RMr,AU,PMr,BMr,yU,IMr,NMr,qMr,e9,jMr,R5e,DMr,GMr,OMr,Pt,o9,VMr,P5e,XMr,zMr,mc,WMr,B5e,QMr,HMr,LU,UMr,JMr,YMr,sE,KMr,Sr,r9,ZMr,I5e,eEr,oEr,sn,rEr,N5e,tEr,aEr,q5e,nEr,sEr,j5e,lEr,iEr,dEr,pe,lE,D5e,cEr,fEr,xU,mEr,gEr,hEr,iE,G5e,pEr,_Er,$U,uEr,bEr,vEr,dE,O5e,FEr,TEr,kU,MEr,EEr,CEr,cE,V5e,wEr,AEr,SU,yEr,LEr,xEr,fE,X5e,$Er,kEr,RU,SEr,REr,PEr,mE,z5e,BEr,IEr,PU,NEr,qEr,jEr,gE,W5e,DEr,GEr,BU,OEr,VEr,XEr,hE,Q5e,zEr,WEr,IU,QEr,HEr,UEr,pE,H5e,JEr,YEr,NU,KEr,ZEr,eCr,_E,U5e,oCr,rCr,qU,tCr,aCr,nCr,uE,J5e,sCr,lCr,jU,iCr,dCr,cCr,bE,Y5e,fCr,mCr,DU,gCr,hCr,pCr,vE,K5e,_Cr,uCr,GU,bCr,vCr,FCr,FE,Z5e,TCr,MCr,OU,ECr,CCr,wCr,TE,eFe,ACr,yCr,VU,LCr,xCr,$Cr,ME,oFe,kCr,SCr,XU,RCr,PCr,BCr,EE,rFe,ICr,NCr,zU,qCr,jCr,DCr,CE,tDe,gc,wE,tFe,t9,GCr,aFe,OCr,aDe,nr,a9,VCr,hc,XCr,WU,zCr,WCr,QU,QCr,HCr,UCr,n9,JCr,nFe,YCr,KCr,ZCr,Bt,s9,e3r,sFe,o3r,r3r,pc,t3r,lFe,a3r,n3r,HU,s3r,l3r,i3r,AE,d3r,Rr,l9,c3r,iFe,f3r,m3r,ln,g3r,dFe,h3r,p3r,cFe,_3r,u3r,fFe,b3r,v3r,F3r,i9,yE,mFe,T3r,M3r,UU,E3r,C3r,w3r,LE,gFe,A3r,y3r,JU,L3r,x3r,$3r,xE,nDe,_c,$E,hFe,d9,k3r,pFe,S3r,sDe,sr,c9,R3r,uc,P3r,YU,B3r,I3r,KU,N3r,q3r,j3r,f9,D3r,_Fe,G3r,O3r,V3r,It,m9,X3r,uFe,z3r,W3r,bc,Q3r,bFe,H3r,U3r,ZU,J3r,Y3r,K3r,kE,Z3r,Pr,g9,e0r,vFe,o0r,r0r,dn,t0r,FFe,a0r,n0r,TFe,s0r,l0r,MFe,i0r,d0r,c0r,EFe,SE,CFe,f0r,m0r,eJ,g0r,h0r,p0r,RE,lDe,vc,PE,wFe,h9,_0r,AFe,u0r,iDe,lr,p9,b0r,Fc,v0r,oJ,F0r,T0r,rJ,M0r,E0r,C0r,_9,w0r,yFe,A0r,y0r,L0r,Nt,u9,x0r,LFe,$0r,k0r,Tc,S0r,xFe,R0r,P0r,tJ,B0r,I0r,N0r,BE,q0r,Br,b9,j0r,$Fe,D0r,G0r,cn,O0r,kFe,V0r,X0r,SFe,z0r,W0r,RFe,Q0r,H0r,U0r,de,IE,PFe,J0r,Y0r,aJ,K0r,Z0r,ewr,NE,BFe,owr,rwr,nJ,twr,awr,nwr,qE,IFe,swr,lwr,sJ,iwr,dwr,cwr,jE,NFe,fwr,mwr,lJ,gwr,hwr,pwr,DE,qFe,_wr,uwr,iJ,bwr,vwr,Fwr,GE,jFe,Twr,Mwr,dJ,Ewr,Cwr,wwr,OE,DFe,Awr,ywr,cJ,Lwr,xwr,$wr,VE,GFe,kwr,Swr,fJ,Rwr,Pwr,Bwr,XE,OFe,Iwr,Nwr,mJ,qwr,jwr,Dwr,zE,VFe,Gwr,Owr,gJ,Vwr,Xwr,zwr,WE,XFe,Wwr,Qwr,hJ,Hwr,Uwr,Jwr,QE,zFe,Ywr,Kwr,pJ,Zwr,e6r,o6r,HE,WFe,r6r,t6r,_J,a6r,n6r,s6r,UE,QFe,l6r,i6r,uJ,d6r,c6r,f6r,JE,HFe,m6r,g6r,bJ,h6r,p6r,_6r,YE,UFe,u6r,b6r,vJ,v6r,F6r,T6r,KE,JFe,M6r,E6r,FJ,C6r,w6r,A6r,ZE,YFe,y6r,L6r,TJ,x6r,$6r,k6r,eC,KFe,S6r,R6r,MJ,P6r,B6r,I6r,oC,ZFe,N6r,q6r,EJ,j6r,D6r,G6r,rC,dDe,Mc,tC,eTe,v9,O6r,oTe,V6r,cDe,ir,F9,X6r,Ec,z6r,CJ,W6r,Q6r,wJ,H6r,U6r,J6r,T9,Y6r,rTe,K6r,Z6r,eAr,qt,M9,oAr,tTe,rAr,tAr,Cc,aAr,aTe,nAr,sAr,AJ,lAr,iAr,dAr,aC,cAr,Ir,E9,fAr,nTe,mAr,gAr,fn,hAr,sTe,pAr,_Ar,lTe,uAr,bAr,iTe,vAr,FAr,TAr,ce,nC,dTe,MAr,EAr,yJ,CAr,wAr,AAr,sC,cTe,yAr,LAr,LJ,xAr,$Ar,kAr,lC,fTe,SAr,RAr,xJ,PAr,BAr,IAr,iC,mTe,NAr,qAr,$J,jAr,DAr,GAr,dC,gTe,OAr,VAr,kJ,XAr,zAr,WAr,cC,hTe,QAr,HAr,SJ,UAr,JAr,YAr,fC,pTe,KAr,ZAr,RJ,eyr,oyr,ryr,mC,_Te,tyr,ayr,PJ,nyr,syr,lyr,gC,uTe,iyr,dyr,BJ,cyr,fyr,myr,hC,bTe,gyr,hyr,IJ,pyr,_yr,uyr,pC,vTe,byr,vyr,NJ,Fyr,Tyr,Myr,_C,FTe,Eyr,Cyr,qJ,wyr,Ayr,yyr,uC,TTe,Lyr,xyr,jJ,$yr,kyr,Syr,bC,MTe,Ryr,Pyr,DJ,Byr,Iyr,Nyr,vC,ETe,qyr,jyr,GJ,Dyr,Gyr,Oyr,FC,CTe,Vyr,Xyr,OJ,zyr,Wyr,Qyr,TC,wTe,Hyr,Uyr,VJ,Jyr,Yyr,Kyr,MC,ATe,Zyr,eLr,XJ,oLr,rLr,tLr,EC,yTe,aLr,nLr,zJ,sLr,lLr,iLr,CC,LTe,dLr,cLr,WJ,fLr,mLr,gLr,wC,fDe,wc,AC,xTe,C9,hLr,$Te,pLr,mDe,dr,w9,_Lr,Ac,uLr,QJ,bLr,vLr,HJ,FLr,TLr,MLr,A9,ELr,kTe,CLr,wLr,ALr,jt,y9,yLr,STe,LLr,xLr,yc,$Lr,RTe,kLr,SLr,UJ,RLr,PLr,BLr,yC,ILr,Nr,L9,NLr,PTe,qLr,jLr,mn,DLr,BTe,GLr,OLr,ITe,VLr,XLr,NTe,zLr,WLr,QLr,qTe,LC,jTe,HLr,ULr,JJ,JLr,YLr,KLr,xC,gDe,Lc,$C,DTe,x9,ZLr,GTe,e8r,hDe,cr,$9,o8r,xc,r8r,YJ,t8r,a8r,KJ,n8r,s8r,l8r,k9,i8r,OTe,d8r,c8r,f8r,Dt,S9,m8r,VTe,g8r,h8r,$c,p8r,XTe,_8r,u8r,ZJ,b8r,v8r,F8r,kC,T8r,qr,R9,M8r,zTe,E8r,C8r,gn,w8r,WTe,A8r,y8r,QTe,L8r,x8r,HTe,$8r,k8r,S8r,UTe,SC,JTe,R8r,P8r,eY,B8r,I8r,N8r,RC,pDe,kc,PC,YTe,P9,q8r,KTe,j8r,_De,fr,B9,D8r,Sc,G8r,oY,O8r,V8r,rY,X8r,z8r,W8r,I9,Q8r,ZTe,H8r,U8r,J8r,Gt,N9,Y8r,e7e,K8r,Z8r,Rc,e9r,o7e,o9r,r9r,tY,t9r,a9r,n9r,BC,s9r,jr,q9,l9r,r7e,i9r,d9r,hn,c9r,t7e,f9r,m9r,a7e,g9r,h9r,n7e,p9r,_9r,u9r,re,IC,s7e,b9r,v9r,aY,F9r,T9r,M9r,NC,l7e,E9r,C9r,nY,w9r,A9r,y9r,qC,i7e,L9r,x9r,sY,$9r,k9r,S9r,jC,d7e,R9r,P9r,lY,B9r,I9r,N9r,DC,c7e,q9r,j9r,iY,D9r,G9r,O9r,GC,f7e,V9r,X9r,dY,z9r,W9r,Q9r,OC,m7e,H9r,U9r,cY,J9r,Y9r,K9r,VC,g7e,Z9r,exr,fY,oxr,rxr,txr,XC,h7e,axr,nxr,mY,sxr,lxr,ixr,zC,p7e,dxr,cxr,gY,fxr,mxr,gxr,WC,_7e,hxr,pxr,hY,_xr,uxr,bxr,QC,u7e,vxr,Fxr,pY,Txr,Mxr,Exr,HC,b7e,Cxr,wxr,_Y,Axr,yxr,Lxr,UC,v7e,xxr,$xr,uY,kxr,Sxr,Rxr,JC,F7e,Pxr,Bxr,bY,Ixr,Nxr,qxr,YC,T7e,jxr,Dxr,vY,Gxr,Oxr,Vxr,KC,M7e,Xxr,zxr,FY,Wxr,Qxr,Hxr,ZC,E7e,Uxr,Jxr,TY,Yxr,Kxr,Zxr,e3,C7e,e$r,o$r,MY,r$r,t$r,a$r,o3,w7e,n$r,s$r,EY,l$r,i$r,d$r,r3,A7e,c$r,f$r,CY,m$r,g$r,h$r,t3,y7e,p$r,_$r,wY,u$r,b$r,v$r,a3,L7e,F$r,T$r,AY,M$r,E$r,C$r,n3,x7e,w$r,A$r,yY,y$r,L$r,x$r,s3,$7e,$$r,k$r,LY,S$r,R$r,P$r,l3,k7e,B$r,I$r,xY,N$r,q$r,j$r,i3,uDe,Pc,d3,S7e,j9,D$r,R7e,G$r,bDe,mr,D9,O$r,Bc,V$r,$Y,X$r,z$r,kY,W$r,Q$r,H$r,G9,U$r,P7e,J$r,Y$r,K$r,Ot,O9,Z$r,B7e,ekr,okr,Ic,rkr,I7e,tkr,akr,SY,nkr,skr,lkr,c3,ikr,Dr,V9,dkr,N7e,ckr,fkr,pn,mkr,q7e,gkr,hkr,j7e,pkr,_kr,D7e,ukr,bkr,vkr,Le,f3,G7e,Fkr,Tkr,RY,Mkr,Ekr,Ckr,m3,O7e,wkr,Akr,PY,ykr,Lkr,xkr,g3,V7e,$kr,kkr,BY,Skr,Rkr,Pkr,h3,X7e,Bkr,Ikr,IY,Nkr,qkr,jkr,p3,z7e,Dkr,Gkr,NY,Okr,Vkr,Xkr,_3,W7e,zkr,Wkr,qY,Qkr,Hkr,Ukr,u3,Q7e,Jkr,Ykr,jY,Kkr,Zkr,eSr,b3,H7e,oSr,rSr,DY,tSr,aSr,nSr,v3,U7e,sSr,lSr,GY,iSr,dSr,cSr,F3,J7e,fSr,mSr,OY,gSr,hSr,pSr,T3,vDe,Nc,M3,Y7e,X9,_Sr,K7e,uSr,FDe,gr,z9,bSr,qc,vSr,VY,FSr,TSr,XY,MSr,ESr,CSr,W9,wSr,Z7e,ASr,ySr,LSr,Vt,Q9,xSr,eMe,$Sr,kSr,jc,SSr,oMe,RSr,PSr,zY,BSr,ISr,NSr,E3,qSr,Gr,H9,jSr,rMe,DSr,GSr,_n,OSr,tMe,VSr,XSr,aMe,zSr,WSr,nMe,QSr,HSr,USr,Ee,C3,sMe,JSr,YSr,WY,KSr,ZSr,eRr,w3,lMe,oRr,rRr,QY,tRr,aRr,nRr,A3,iMe,sRr,lRr,HY,iRr,dRr,cRr,y3,dMe,fRr,mRr,UY,gRr,hRr,pRr,L3,cMe,_Rr,uRr,JY,bRr,vRr,FRr,x3,fMe,TRr,MRr,YY,ERr,CRr,wRr,$3,mMe,ARr,yRr,KY,LRr,xRr,$Rr,k3,gMe,kRr,SRr,ZY,RRr,PRr,BRr,S3,hMe,IRr,NRr,eK,qRr,jRr,DRr,R3,pMe,GRr,ORr,oK,VRr,XRr,zRr,P3,_Me,WRr,QRr,rK,HRr,URr,JRr,B3,uMe,YRr,KRr,tK,ZRr,ePr,oPr,I3,TDe,Dc,N3,bMe,U9,rPr,vMe,tPr,MDe,hr,J9,aPr,Gc,nPr,aK,sPr,lPr,nK,iPr,dPr,cPr,Y9,fPr,FMe,mPr,gPr,hPr,Xt,K9,pPr,TMe,_Pr,uPr,Oc,bPr,MMe,vPr,FPr,sK,TPr,MPr,EPr,q3,CPr,Or,Z9,wPr,EMe,APr,yPr,un,LPr,CMe,xPr,$Pr,wMe,kPr,SPr,AMe,RPr,PPr,BPr,xe,j3,yMe,IPr,NPr,lK,qPr,jPr,DPr,D3,LMe,GPr,OPr,iK,VPr,XPr,zPr,G3,xMe,WPr,QPr,dK,HPr,UPr,JPr,O3,$Me,YPr,KPr,cK,ZPr,eBr,oBr,V3,kMe,rBr,tBr,fK,aBr,nBr,sBr,X3,SMe,lBr,iBr,mK,dBr,cBr,fBr,z3,RMe,mBr,gBr,gK,hBr,pBr,_Br,W3,PMe,uBr,bBr,hK,vBr,FBr,TBr,Q3,BMe,MBr,EBr,pK,CBr,wBr,ABr,H3,IMe,yBr,LBr,_K,xBr,$Br,kBr,U3,EDe,Vc,J3,NMe,ex,SBr,qMe,RBr,CDe,pr,ox,PBr,Xc,BBr,uK,IBr,NBr,bK,qBr,jBr,DBr,rx,GBr,jMe,OBr,VBr,XBr,zt,tx,zBr,DMe,WBr,QBr,zc,HBr,GMe,UBr,JBr,vK,YBr,KBr,ZBr,Y3,eIr,Vr,ax,oIr,OMe,rIr,tIr,bn,aIr,VMe,nIr,sIr,XMe,lIr,iIr,zMe,dIr,cIr,fIr,Pe,K3,WMe,mIr,gIr,FK,hIr,pIr,_Ir,Z3,QMe,uIr,bIr,TK,vIr,FIr,TIr,e0,HMe,MIr,EIr,MK,CIr,wIr,AIr,o0,UMe,yIr,LIr,EK,xIr,$Ir,kIr,r0,JMe,SIr,RIr,CK,PIr,BIr,IIr,t0,YMe,NIr,qIr,wK,jIr,DIr,GIr,a0,KMe,OIr,VIr,AK,XIr,zIr,WIr,n0,ZMe,QIr,HIr,yK,UIr,JIr,YIr,s0,eEe,KIr,ZIr,LK,eNr,oNr,rNr,l0,wDe,Wc,i0,oEe,nx,tNr,rEe,aNr,ADe,_r,sx,nNr,Qc,sNr,xK,lNr,iNr,$K,dNr,cNr,fNr,lx,mNr,tEe,gNr,hNr,pNr,Wt,ix,_Nr,aEe,uNr,bNr,Hc,vNr,nEe,FNr,TNr,kK,MNr,ENr,CNr,d0,wNr,Xr,dx,ANr,sEe,yNr,LNr,vn,xNr,lEe,$Nr,kNr,iEe,SNr,RNr,dEe,PNr,BNr,INr,$e,c0,cEe,NNr,qNr,SK,jNr,DNr,GNr,f0,fEe,ONr,VNr,RK,XNr,zNr,WNr,m0,mEe,QNr,HNr,PK,UNr,JNr,YNr,g0,gEe,KNr,ZNr,BK,eqr,oqr,rqr,h0,hEe,tqr,aqr,IK,nqr,sqr,lqr,p0,pEe,iqr,dqr,NK,cqr,fqr,mqr,_0,_Ee,gqr,hqr,qK,pqr,_qr,uqr,u0,uEe,bqr,vqr,jK,Fqr,Tqr,Mqr,b0,bEe,Eqr,Cqr,DK,wqr,Aqr,yqr,v0,vEe,Lqr,xqr,GK,$qr,kqr,Sqr,F0,yDe,Uc,T0,FEe,cx,Rqr,TEe,Pqr,LDe,ur,fx,Bqr,Jc,Iqr,OK,Nqr,qqr,VK,jqr,Dqr,Gqr,mx,Oqr,MEe,Vqr,Xqr,zqr,Qt,gx,Wqr,EEe,Qqr,Hqr,Yc,Uqr,CEe,Jqr,Yqr,XK,Kqr,Zqr,ejr,M0,ojr,zr,hx,rjr,wEe,tjr,ajr,Fn,njr,AEe,sjr,ljr,yEe,ijr,djr,LEe,cjr,fjr,mjr,ke,E0,xEe,gjr,hjr,zK,pjr,_jr,ujr,C0,$Ee,bjr,vjr,WK,Fjr,Tjr,Mjr,w0,kEe,Ejr,Cjr,QK,wjr,Ajr,yjr,A0,SEe,Ljr,xjr,HK,$jr,kjr,Sjr,y0,REe,Rjr,Pjr,UK,Bjr,Ijr,Njr,L0,PEe,qjr,jjr,JK,Djr,Gjr,Ojr,x0,BEe,Vjr,Xjr,YK,zjr,Wjr,Qjr,$0,IEe,Hjr,Ujr,KK,Jjr,Yjr,Kjr,k0,NEe,Zjr,eDr,ZK,oDr,rDr,tDr,S0,qEe,aDr,nDr,eZ,sDr,lDr,iDr,R0,xDe,Kc,P0,jEe,px,dDr,DEe,cDr,$De,br,_x,fDr,Zc,mDr,oZ,gDr,hDr,rZ,pDr,_Dr,uDr,ux,bDr,GEe,vDr,FDr,TDr,Ht,bx,MDr,OEe,EDr,CDr,ef,wDr,VEe,ADr,yDr,tZ,LDr,xDr,$Dr,B0,kDr,Wr,vx,SDr,XEe,RDr,PDr,Tn,BDr,zEe,IDr,NDr,WEe,qDr,jDr,QEe,DDr,GDr,ODr,Ge,I0,HEe,VDr,XDr,aZ,zDr,WDr,QDr,N0,UEe,HDr,UDr,nZ,JDr,YDr,KDr,q0,JEe,ZDr,eGr,sZ,oGr,rGr,tGr,j0,YEe,aGr,nGr,lZ,sGr,lGr,iGr,D0,KEe,dGr,cGr,iZ,fGr,mGr,gGr,G0,ZEe,hGr,pGr,dZ,_Gr,uGr,bGr,O0,eCe,vGr,FGr,cZ,TGr,MGr,EGr,V0,oCe,CGr,wGr,fZ,AGr,yGr,LGr,X0,kDe,of,z0,rCe,Fx,xGr,tCe,$Gr,SDe,vr,Tx,kGr,rf,SGr,mZ,RGr,PGr,gZ,BGr,IGr,NGr,Mx,qGr,aCe,jGr,DGr,GGr,Ut,Ex,OGr,nCe,VGr,XGr,tf,zGr,sCe,WGr,QGr,hZ,HGr,UGr,JGr,W0,YGr,Qr,Cx,KGr,lCe,ZGr,eOr,Mn,oOr,iCe,rOr,tOr,dCe,aOr,nOr,cCe,sOr,lOr,iOr,Oe,Q0,fCe,dOr,cOr,pZ,fOr,mOr,gOr,H0,mCe,hOr,pOr,_Z,_Or,uOr,bOr,U0,gCe,vOr,FOr,uZ,TOr,MOr,EOr,J0,hCe,COr,wOr,bZ,AOr,yOr,LOr,Y0,pCe,xOr,$Or,vZ,kOr,SOr,ROr,K0,_Ce,POr,BOr,FZ,IOr,NOr,qOr,Z0,uCe,jOr,DOr,TZ,GOr,OOr,VOr,ew,bCe,XOr,zOr,MZ,WOr,QOr,HOr,ow,RDe,af,rw,vCe,wx,UOr,FCe,JOr,PDe,Fr,Ax,YOr,nf,KOr,EZ,ZOr,eVr,CZ,oVr,rVr,tVr,yx,aVr,TCe,nVr,sVr,lVr,Jt,Lx,iVr,MCe,dVr,cVr,sf,fVr,ECe,mVr,gVr,wZ,hVr,pVr,_Vr,tw,uVr,Hr,xx,bVr,CCe,vVr,FVr,En,TVr,wCe,MVr,EVr,ACe,CVr,wVr,yCe,AVr,yVr,LVr,LCe,aw,xCe,xVr,$Vr,AZ,kVr,SVr,RVr,nw,BDe,lf,sw,$Ce,$x,PVr,kCe,BVr,IDe,Tr,kx,IVr,df,NVr,yZ,qVr,jVr,LZ,DVr,GVr,OVr,Sx,VVr,SCe,XVr,zVr,WVr,Yt,Rx,QVr,RCe,HVr,UVr,cf,JVr,PCe,YVr,KVr,xZ,ZVr,eXr,oXr,lw,rXr,Ur,Px,tXr,BCe,aXr,nXr,Cn,sXr,ICe,lXr,iXr,NCe,dXr,cXr,qCe,fXr,mXr,gXr,Bx,iw,jCe,hXr,pXr,$Z,_Xr,uXr,bXr,dw,DCe,vXr,FXr,kZ,TXr,MXr,EXr,cw,NDe,ff,fw,GCe,Ix,CXr,OCe,wXr,qDe,Mr,Nx,AXr,mf,yXr,SZ,LXr,xXr,RZ,$Xr,kXr,SXr,qx,RXr,VCe,PXr,BXr,IXr,Kt,jx,NXr,XCe,qXr,jXr,gf,DXr,zCe,GXr,OXr,PZ,VXr,XXr,zXr,mw,WXr,Jr,Dx,QXr,WCe,HXr,UXr,wn,JXr,QCe,YXr,KXr,HCe,ZXr,ezr,UCe,ozr,rzr,tzr,JCe,gw,YCe,azr,nzr,BZ,szr,lzr,izr,hw,jDe;return d=new te({}),Ca=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),IA=new te({}),NA=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Mf=new dzr({props:{warning:!0,$$slots:{default:[cSt]},$$scope:{ctx:L}}}),qA=new te({}),jA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/configuration_auto.py#L587"}}),OA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/configuration_auto.py#L610"}}),Ag=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[fSt]},$$scope:{ctx:L}}}),VA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/configuration_auto.py#L733"}}),XA=new te({}),zA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/tokenization_auto.py#L396"}}),HA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17254/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/tokenization_auto.py#L410"}}),sh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[mSt]},$$scope:{ctx:L}}}),UA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/tokenization_auto.py#L609"}}),JA=new te({}),YA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/feature_extraction_auto.py#L191"}}),ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17254/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/feature_extraction_auto.py#L205"}}),jh=new dzr({props:{$$slots:{default:[gSt]},$$scope:{ctx:L}}}),Dh=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[hSt]},$$scope:{ctx:L}}}),oy=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/feature_extraction_auto.py#L332"}}),ry=new te({}),ty=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/processing_auto.py#L88"}}),sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/processing_auto.py#L102"}}),sp=new dzr({props:{$$slots:{default:[pSt]},$$scope:{ctx:L}}}),lp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[_St]},$$scope:{ctx:L}}}),ly=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/processing_auto.py#L255"}}),iy=new te({}),dy=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L739"}}),fy=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),cp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[uSt]},$$scope:{ctx:L}}}),my=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),su=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[bSt]},$$scope:{ctx:L}}}),gy=new te({}),hy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L746"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),iu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[vSt]},$$scope:{ctx:L}}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Ku=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[FSt]},$$scope:{ctx:L}}}),by=new te({}),vy=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L761"}}),Ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),e2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[TSt]},$$scope:{ctx:L}}}),My=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),j2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[MSt]},$$scope:{ctx:L}}}),Ey=new te({}),Cy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L768"}}),Ay=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),G2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[ESt]},$$scope:{ctx:L}}}),yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),w1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[CSt]},$$scope:{ctx:L}}}),Ly=new te({}),xy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L775"}}),ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),y1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[wSt]},$$scope:{ctx:L}}}),Sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),z1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[ASt]},$$scope:{ctx:L}}}),Ry=new te({}),Py=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L784"}}),Iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),Q1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[ySt]},$$scope:{ctx:L}}}),Ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Ob=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[LSt]},$$scope:{ctx:L}}}),qy=new te({}),jy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L818"}}),Gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),Xb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[xSt]},$$scope:{ctx:L}}}),Oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),T4=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[$St]},$$scope:{ctx:L}}}),Vy=new te({}),Xy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L825"}}),Wy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),E4=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[kSt]},$$scope:{ctx:L}}}),Qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),$4=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[SSt]},$$scope:{ctx:L}}}),Hy=new te({}),Uy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L811"}}),Yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),S4=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[RSt]},$$scope:{ctx:L}}}),Ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),hv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[PSt]},$$scope:{ctx:L}}}),Zy=new te({}),eL=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L793"}}),rL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),_v=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[BSt]},$$scope:{ctx:L}}}),tL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[ISt]},$$scope:{ctx:L}}}),aL=new te({}),nL=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L800"}}),lL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[NSt]},$$scope:{ctx:L}}}),iL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),d5=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[qSt]},$$scope:{ctx:L}}}),dL=new te({}),cL=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L834"}}),mL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),f5=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[jSt]},$$scope:{ctx:L}}}),gL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),w5=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[DSt]},$$scope:{ctx:L}}}),hL=new te({}),pL=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L873"}}),uL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),y5=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[GSt]},$$scope:{ctx:L}}}),bL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),$5=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[OSt]},$$scope:{ctx:L}}}),vL=new te({}),FL=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L880"}}),ML=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),S5=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[VSt]},$$scope:{ctx:L}}}),EL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),V5=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[XSt]},$$scope:{ctx:L}}}),CL=new te({}),wL=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L903"}}),yL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),z5=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[zSt]},$$scope:{ctx:L}}}),LL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),K5=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[WSt]},$$scope:{ctx:L}}}),xL=new te({}),$L=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L887"}}),SL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),eF=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[QSt]},$$scope:{ctx:L}}}),RL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),fF=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[HSt]},$$scope:{ctx:L}}}),PL=new te({}),BL=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L894"}}),NL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),gF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[USt]},$$scope:{ctx:L}}}),qL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),uF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[JSt]},$$scope:{ctx:L}}}),DL=new te({}),GL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L912"}}),VL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),vF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[YSt]},$$scope:{ctx:L}}}),XL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),AF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[KSt]},$$scope:{ctx:L}}}),zL=new te({}),WL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L919"}}),HL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),LF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[ZSt]},$$scope:{ctx:L}}}),UL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),RF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[eRt]},$$scope:{ctx:L}}}),JL=new te({}),YL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L866"}}),ZL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),BF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[oRt]},$$scope:{ctx:L}}}),e8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[rRt]},$$scope:{ctx:L}}}),r8=new te({}),t8=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L841"}}),n8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),GF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[tRt]},$$scope:{ctx:L}}}),s8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),XF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[aRt]},$$scope:{ctx:L}}}),l8=new te({}),i8=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L848"}}),c8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),WF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[nRt]},$$scope:{ctx:L}}}),f8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),KF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[sRt]},$$scope:{ctx:L}}}),m8=new te({}),g8=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L857"}}),p8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),eT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[lRt]},$$scope:{ctx:L}}}),_8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),tT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[iRt]},$$scope:{ctx:L}}}),u8=new te({}),b8=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L396"}}),F8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),nT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[dRt]},$$scope:{ctx:L}}}),T8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),KT=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[cRt]},$$scope:{ctx:L}}}),M8=new te({}),E8=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L403"}}),w8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),e7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[fRt]},$$scope:{ctx:L}}}),A8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),C7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[mRt]},$$scope:{ctx:L}}}),y8=new te({}),L8=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L418"}}),$8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),A7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[gRt]},$$scope:{ctx:L}}}),k8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),D7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[hRt]},$$scope:{ctx:L}}}),S8=new te({}),R8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L434"}}),B8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),O7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[pRt]},$$scope:{ctx:L}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Q7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[_Rt]},$$scope:{ctx:L}}}),N8=new te({}),q8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L450"}}),D8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),U7=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[uRt]},$$scope:{ctx:L}}}),G8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),_M=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[bRt]},$$scope:{ctx:L}}}),O8=new te({}),V8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L457"}}),z8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),bM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[vRt]},$$scope:{ctx:L}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),xM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[FRt]},$$scope:{ctx:L}}}),Q8=new te({}),H8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),J8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),kM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[TRt]},$$scope:{ctx:L}}}),Y8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),aE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[MRt]},$$scope:{ctx:L}}}),K8=new te({}),Z8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L502"}}),o9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),sE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[ERt]},$$scope:{ctx:L}}}),r9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),CE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[CRt]},$$scope:{ctx:L}}}),t9=new te({}),a9=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L509"}}),s9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),AE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[wRt]},$$scope:{ctx:L}}}),l9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),xE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ARt]},$$scope:{ctx:L}}}),d9=new te({}),c9=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),m9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),kE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[yRt]},$$scope:{ctx:L}}}),g9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),RE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[LRt]},$$scope:{ctx:L}}}),h9=new te({}),p9=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L493"}}),u9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),BE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[xRt]},$$scope:{ctx:L}}}),b9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),rC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[$Rt]},$$scope:{ctx:L}}}),v9=new te({}),F9=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L475"}}),M9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),aC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[kRt]},$$scope:{ctx:L}}}),E9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),wC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[SRt]},$$scope:{ctx:L}}}),C9=new te({}),w9=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L443"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),yC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[RRt]},$$scope:{ctx:L}}}),L9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),xC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[PRt]},$$scope:{ctx:L}}}),x9=new te({}),$9=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L518"}}),S9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),kC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[BRt]},$$scope:{ctx:L}}}),R9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),RC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[IRt]},$$scope:{ctx:L}}}),P9=new te({}),B9=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L243"}}),N9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),BC=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[NRt]},$$scope:{ctx:L}}}),q9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),i3=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[qRt]},$$scope:{ctx:L}}}),j9=new te({}),D9=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L257"}}),O9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),c3=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[jRt]},$$scope:{ctx:L}}}),V9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),T3=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[DRt]},$$scope:{ctx:L}}}),X9=new te({}),z9=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L250"}}),Q9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),E3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[GRt]},$$scope:{ctx:L}}}),H9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),I3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[ORt]},$$scope:{ctx:L}}}),U9=new te({}),J9=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),K9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),q3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[VRt]},$$scope:{ctx:L}}}),Z9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),U3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[XRt]},$$scope:{ctx:L}}}),ex=new te({}),ox=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L271"}}),tx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),Y3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[zRt]},$$scope:{ctx:L}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),l0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[WRt]},$$scope:{ctx:L}}}),nx=new te({}),sx=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L280"}}),ix=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),d0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[QRt]},$$scope:{ctx:L}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),F0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[HRt]},$$scope:{ctx:L}}}),cx=new te({}),fx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L289"}}),gx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),M0=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[URt]},$$scope:{ctx:L}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),R0=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JRt]},$$scope:{ctx:L}}}),px=new te({}),_x=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L296"}}),bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),B0=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[YRt]},$$scope:{ctx:L}}}),vx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),X0=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[KRt]},$$scope:{ctx:L}}}),Fx=new te({}),Tx=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L305"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),W0=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[ZRt]},$$scope:{ctx:L}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),ow=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[ePt]},$$scope:{ctx:L}}}),wx=new te({}),Ax=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L312"}}),Lx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),tw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[oPt]},$$scope:{ctx:L}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),nw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[rPt]},$$scope:{ctx:L}}}),$x=new te({}),kx=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L321"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),lw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[tPt]},$$scope:{ctx:L}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),cw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[aPt]},$$scope:{ctx:L}}}),Ix=new te({}),Nx=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L330"}}),jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),mw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[nPt]},$$scope:{ctx:L}}}),Dx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),hw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[sPt]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),gi=o("Auto Classes"),uf=l(),rt=a("p"),hi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),pi=a("code"),SA=o("from_pretrained()"),bf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),De=l(),We=a("p"),_i=o("Instantiating one of "),yn=a("a"),RA=o("AutoConfig"),Ln=o(", "),xn=a("a"),PA=o("AutoModel"),ui=o(`, and
`),$n=a("a"),BA=o("AutoTokenizer"),bi=o(" will directly create a class of the relevant architecture. For instance"),vf=l(),F(Ca.$$.fragment),Qe=l(),Ae=a("p"),rk=o("will create a model that is an instance of "),vi=a("a"),tk=o("BertModel"),ak=o("."),Eo=l(),wa=a("p"),nk=o("There is one class of "),Ff=a("code"),sk=o("AutoModel"),QOe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Iqe=l(),Fi=a("h2"),Tf=a("a"),Loe=a("span"),F(IA.$$.fragment),HOe=l(),xoe=a("span"),UOe=o("Extending the Auto Classes"),Nqe=l(),kn=a("p"),JOe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),$oe=a("code"),YOe=o("NewModel"),KOe=o(", make sure you have a "),koe=a("code"),ZOe=o("NewModelConfig"),eVe=o(` then you can add those to the auto
classes like this:`),qqe=l(),F(NA.$$.fragment),jqe=l(),lk=a("p"),oVe=o("You will then be able to use the auto classes like you would usually do!"),Dqe=l(),F(Mf.$$.fragment),Gqe=l(),Ti=a("h2"),Ef=a("a"),Soe=a("span"),F(qA.$$.fragment),rVe=l(),Roe=a("span"),tVe=o("AutoConfig"),Oqe=l(),Co=a("div"),F(jA.$$.fragment),aVe=l(),DA=a("p"),nVe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),ik=a("a"),sVe=o("from_pretrained()"),lVe=o(" class method."),iVe=l(),GA=a("p"),dVe=o("This class cannot be instantiated directly using "),Poe=a("code"),cVe=o("__init__()"),fVe=o(" (throws an error)."),mVe=l(),Er=a("div"),F(OA.$$.fragment),gVe=l(),Boe=a("p"),hVe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),pVe=l(),Mi=a("p"),_Ve=o("The configuration class to instantiate is selected based on the "),Ioe=a("code"),uVe=o("model_type"),bVe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Noe=a("code"),vVe=o("pretrained_model_name_or_path"),FVe=o(":"),TVe=l(),A=a("ul"),Cf=a("li"),qoe=a("strong"),MVe=o("albert"),EVe=o(" \u2014 "),dk=a("a"),CVe=o("AlbertConfig"),wVe=o(" (ALBERT model)"),AVe=l(),wf=a("li"),joe=a("strong"),yVe=o("bart"),LVe=o(" \u2014 "),ck=a("a"),xVe=o("BartConfig"),$Ve=o(" (BART model)"),kVe=l(),Af=a("li"),Doe=a("strong"),SVe=o("beit"),RVe=o(" \u2014 "),fk=a("a"),PVe=o("BeitConfig"),BVe=o(" (BEiT model)"),IVe=l(),yf=a("li"),Goe=a("strong"),NVe=o("bert"),qVe=o(" \u2014 "),mk=a("a"),jVe=o("BertConfig"),DVe=o(" (BERT model)"),GVe=l(),Lf=a("li"),Ooe=a("strong"),OVe=o("bert-generation"),VVe=o(" \u2014 "),gk=a("a"),XVe=o("BertGenerationConfig"),zVe=o(" (Bert Generation model)"),WVe=l(),xf=a("li"),Voe=a("strong"),QVe=o("big_bird"),HVe=o(" \u2014 "),hk=a("a"),UVe=o("BigBirdConfig"),JVe=o(" (BigBird model)"),YVe=l(),$f=a("li"),Xoe=a("strong"),KVe=o("bigbird_pegasus"),ZVe=o(" \u2014 "),pk=a("a"),eXe=o("BigBirdPegasusConfig"),oXe=o(" (BigBirdPegasus model)"),rXe=l(),kf=a("li"),zoe=a("strong"),tXe=o("blenderbot"),aXe=o(" \u2014 "),_k=a("a"),nXe=o("BlenderbotConfig"),sXe=o(" (Blenderbot model)"),lXe=l(),Sf=a("li"),Woe=a("strong"),iXe=o("blenderbot-small"),dXe=o(" \u2014 "),uk=a("a"),cXe=o("BlenderbotSmallConfig"),fXe=o(" (BlenderbotSmall model)"),mXe=l(),Rf=a("li"),Qoe=a("strong"),gXe=o("camembert"),hXe=o(" \u2014 "),bk=a("a"),pXe=o("CamembertConfig"),_Xe=o(" (CamemBERT model)"),uXe=l(),Pf=a("li"),Hoe=a("strong"),bXe=o("canine"),vXe=o(" \u2014 "),vk=a("a"),FXe=o("CanineConfig"),TXe=o(" (Canine model)"),MXe=l(),Bf=a("li"),Uoe=a("strong"),EXe=o("clip"),CXe=o(" \u2014 "),Fk=a("a"),wXe=o("CLIPConfig"),AXe=o(" (CLIP model)"),yXe=l(),If=a("li"),Joe=a("strong"),LXe=o("convbert"),xXe=o(" \u2014 "),Tk=a("a"),$Xe=o("ConvBertConfig"),kXe=o(" (ConvBERT model)"),SXe=l(),Nf=a("li"),Yoe=a("strong"),RXe=o("convnext"),PXe=o(" \u2014 "),Mk=a("a"),BXe=o("ConvNextConfig"),IXe=o(" (ConvNext model)"),NXe=l(),qf=a("li"),Koe=a("strong"),qXe=o("ctrl"),jXe=o(" \u2014 "),Ek=a("a"),DXe=o("CTRLConfig"),GXe=o(" (CTRL model)"),OXe=l(),jf=a("li"),Zoe=a("strong"),VXe=o("cvt"),XXe=o(" \u2014 "),Ck=a("a"),zXe=o("CvtConfig"),WXe=o(" (CvT model)"),QXe=l(),Df=a("li"),ere=a("strong"),HXe=o("data2vec-audio"),UXe=o(" \u2014 "),wk=a("a"),JXe=o("Data2VecAudioConfig"),YXe=o(" (Data2VecAudio model)"),KXe=l(),Gf=a("li"),ore=a("strong"),ZXe=o("data2vec-text"),eze=o(" \u2014 "),Ak=a("a"),oze=o("Data2VecTextConfig"),rze=o(" (Data2VecText model)"),tze=l(),Of=a("li"),rre=a("strong"),aze=o("data2vec-vision"),nze=o(" \u2014 "),yk=a("a"),sze=o("Data2VecVisionConfig"),lze=o(" (Data2VecVision model)"),ize=l(),Vf=a("li"),tre=a("strong"),dze=o("deberta"),cze=o(" \u2014 "),Lk=a("a"),fze=o("DebertaConfig"),mze=o(" (DeBERTa model)"),gze=l(),Xf=a("li"),are=a("strong"),hze=o("deberta-v2"),pze=o(" \u2014 "),xk=a("a"),_ze=o("DebertaV2Config"),uze=o(" (DeBERTa-v2 model)"),bze=l(),zf=a("li"),nre=a("strong"),vze=o("decision_transformer"),Fze=o(" \u2014 "),$k=a("a"),Tze=o("DecisionTransformerConfig"),Mze=o(" (Decision Transformer model)"),Eze=l(),Wf=a("li"),sre=a("strong"),Cze=o("deit"),wze=o(" \u2014 "),kk=a("a"),Aze=o("DeiTConfig"),yze=o(" (DeiT model)"),Lze=l(),Qf=a("li"),lre=a("strong"),xze=o("detr"),$ze=o(" \u2014 "),Sk=a("a"),kze=o("DetrConfig"),Sze=o(" (DETR model)"),Rze=l(),Hf=a("li"),ire=a("strong"),Pze=o("distilbert"),Bze=o(" \u2014 "),Rk=a("a"),Ize=o("DistilBertConfig"),Nze=o(" (DistilBERT model)"),qze=l(),Uf=a("li"),dre=a("strong"),jze=o("dpr"),Dze=o(" \u2014 "),Pk=a("a"),Gze=o("DPRConfig"),Oze=o(" (DPR model)"),Vze=l(),Jf=a("li"),cre=a("strong"),Xze=o("dpt"),zze=o(" \u2014 "),Bk=a("a"),Wze=o("DPTConfig"),Qze=o(" (DPT model)"),Hze=l(),Yf=a("li"),fre=a("strong"),Uze=o("electra"),Jze=o(" \u2014 "),Ik=a("a"),Yze=o("ElectraConfig"),Kze=o(" (ELECTRA model)"),Zze=l(),Kf=a("li"),mre=a("strong"),eWe=o("encoder-decoder"),oWe=o(" \u2014 "),Nk=a("a"),rWe=o("EncoderDecoderConfig"),tWe=o(" (Encoder decoder model)"),aWe=l(),Zf=a("li"),gre=a("strong"),nWe=o("flaubert"),sWe=o(" \u2014 "),qk=a("a"),lWe=o("FlaubertConfig"),iWe=o(" (FlauBERT model)"),dWe=l(),em=a("li"),hre=a("strong"),cWe=o("flava"),fWe=o(" \u2014 "),jk=a("a"),mWe=o("FlavaConfig"),gWe=o(" (Flava model)"),hWe=l(),om=a("li"),pre=a("strong"),pWe=o("fnet"),_We=o(" \u2014 "),Dk=a("a"),uWe=o("FNetConfig"),bWe=o(" (FNet model)"),vWe=l(),rm=a("li"),_re=a("strong"),FWe=o("fsmt"),TWe=o(" \u2014 "),Gk=a("a"),MWe=o("FSMTConfig"),EWe=o(" (FairSeq Machine-Translation model)"),CWe=l(),tm=a("li"),ure=a("strong"),wWe=o("funnel"),AWe=o(" \u2014 "),Ok=a("a"),yWe=o("FunnelConfig"),LWe=o(" (Funnel Transformer model)"),xWe=l(),am=a("li"),bre=a("strong"),$We=o("glpn"),kWe=o(" \u2014 "),Vk=a("a"),SWe=o("GLPNConfig"),RWe=o(" (GLPN model)"),PWe=l(),nm=a("li"),vre=a("strong"),BWe=o("gpt2"),IWe=o(" \u2014 "),Xk=a("a"),NWe=o("GPT2Config"),qWe=o(" (OpenAI GPT-2 model)"),jWe=l(),sm=a("li"),Fre=a("strong"),DWe=o("gpt_neo"),GWe=o(" \u2014 "),zk=a("a"),OWe=o("GPTNeoConfig"),VWe=o(" (GPT Neo model)"),XWe=l(),lm=a("li"),Tre=a("strong"),zWe=o("gpt_neox"),WWe=o(" \u2014 "),Wk=a("a"),QWe=o("GPTNeoXConfig"),HWe=o(" (GPT NeoX model)"),UWe=l(),im=a("li"),Mre=a("strong"),JWe=o("gptj"),YWe=o(" \u2014 "),Qk=a("a"),KWe=o("GPTJConfig"),ZWe=o(" (GPT-J model)"),eQe=l(),dm=a("li"),Ere=a("strong"),oQe=o("hubert"),rQe=o(" \u2014 "),Hk=a("a"),tQe=o("HubertConfig"),aQe=o(" (Hubert model)"),nQe=l(),cm=a("li"),Cre=a("strong"),sQe=o("ibert"),lQe=o(" \u2014 "),Uk=a("a"),iQe=o("IBertConfig"),dQe=o(" (I-BERT model)"),cQe=l(),fm=a("li"),wre=a("strong"),fQe=o("imagegpt"),mQe=o(" \u2014 "),Jk=a("a"),gQe=o("ImageGPTConfig"),hQe=o(" (ImageGPT model)"),pQe=l(),mm=a("li"),Are=a("strong"),_Qe=o("layoutlm"),uQe=o(" \u2014 "),Yk=a("a"),bQe=o("LayoutLMConfig"),vQe=o(" (LayoutLM model)"),FQe=l(),gm=a("li"),yre=a("strong"),TQe=o("layoutlmv2"),MQe=o(" \u2014 "),Kk=a("a"),EQe=o("LayoutLMv2Config"),CQe=o(" (LayoutLMv2 model)"),wQe=l(),hm=a("li"),Lre=a("strong"),AQe=o("layoutlmv3"),yQe=o(" \u2014 "),Zk=a("a"),LQe=o("LayoutLMv3Config"),xQe=o(" (LayoutLMv3 model)"),$Qe=l(),pm=a("li"),xre=a("strong"),kQe=o("led"),SQe=o(" \u2014 "),eS=a("a"),RQe=o("LEDConfig"),PQe=o(" (LED model)"),BQe=l(),_m=a("li"),$re=a("strong"),IQe=o("levit"),NQe=o(" \u2014 "),oS=a("a"),qQe=o("LevitConfig"),jQe=o(" (LeViT model)"),DQe=l(),um=a("li"),kre=a("strong"),GQe=o("longformer"),OQe=o(" \u2014 "),rS=a("a"),VQe=o("LongformerConfig"),XQe=o(" (Longformer model)"),zQe=l(),bm=a("li"),Sre=a("strong"),WQe=o("luke"),QQe=o(" \u2014 "),tS=a("a"),HQe=o("LukeConfig"),UQe=o(" (LUKE model)"),JQe=l(),vm=a("li"),Rre=a("strong"),YQe=o("lxmert"),KQe=o(" \u2014 "),aS=a("a"),ZQe=o("LxmertConfig"),eHe=o(" (LXMERT model)"),oHe=l(),Fm=a("li"),Pre=a("strong"),rHe=o("m2m_100"),tHe=o(" \u2014 "),nS=a("a"),aHe=o("M2M100Config"),nHe=o(" (M2M100 model)"),sHe=l(),Tm=a("li"),Bre=a("strong"),lHe=o("marian"),iHe=o(" \u2014 "),sS=a("a"),dHe=o("MarianConfig"),cHe=o(" (Marian model)"),fHe=l(),Mm=a("li"),Ire=a("strong"),mHe=o("maskformer"),gHe=o(" \u2014 "),lS=a("a"),hHe=o("MaskFormerConfig"),pHe=o(" (MaskFormer model)"),_He=l(),Em=a("li"),Nre=a("strong"),uHe=o("mbart"),bHe=o(" \u2014 "),iS=a("a"),vHe=o("MBartConfig"),FHe=o(" (mBART model)"),THe=l(),Cm=a("li"),qre=a("strong"),MHe=o("megatron-bert"),EHe=o(" \u2014 "),dS=a("a"),CHe=o("MegatronBertConfig"),wHe=o(" (MegatronBert model)"),AHe=l(),wm=a("li"),jre=a("strong"),yHe=o("mobilebert"),LHe=o(" \u2014 "),cS=a("a"),xHe=o("MobileBertConfig"),$He=o(" (MobileBERT model)"),kHe=l(),Am=a("li"),Dre=a("strong"),SHe=o("mpnet"),RHe=o(" \u2014 "),fS=a("a"),PHe=o("MPNetConfig"),BHe=o(" (MPNet model)"),IHe=l(),ym=a("li"),Gre=a("strong"),NHe=o("mt5"),qHe=o(" \u2014 "),mS=a("a"),jHe=o("MT5Config"),DHe=o(" (mT5 model)"),GHe=l(),Lm=a("li"),Ore=a("strong"),OHe=o("nystromformer"),VHe=o(" \u2014 "),gS=a("a"),XHe=o("NystromformerConfig"),zHe=o(" (Nystromformer model)"),WHe=l(),xm=a("li"),Vre=a("strong"),QHe=o("openai-gpt"),HHe=o(" \u2014 "),hS=a("a"),UHe=o("OpenAIGPTConfig"),JHe=o(" (OpenAI GPT model)"),YHe=l(),$m=a("li"),Xre=a("strong"),KHe=o("opt"),ZHe=o(" \u2014 "),pS=a("a"),eUe=o("OPTConfig"),oUe=o(" (OPT model)"),rUe=l(),km=a("li"),zre=a("strong"),tUe=o("pegasus"),aUe=o(" \u2014 "),_S=a("a"),nUe=o("PegasusConfig"),sUe=o(" (Pegasus model)"),lUe=l(),Sm=a("li"),Wre=a("strong"),iUe=o("perceiver"),dUe=o(" \u2014 "),uS=a("a"),cUe=o("PerceiverConfig"),fUe=o(" (Perceiver model)"),mUe=l(),Rm=a("li"),Qre=a("strong"),gUe=o("plbart"),hUe=o(" \u2014 "),bS=a("a"),pUe=o("PLBartConfig"),_Ue=o(" (PLBart model)"),uUe=l(),Pm=a("li"),Hre=a("strong"),bUe=o("poolformer"),vUe=o(" \u2014 "),vS=a("a"),FUe=o("PoolFormerConfig"),TUe=o(" (PoolFormer model)"),MUe=l(),Bm=a("li"),Ure=a("strong"),EUe=o("prophetnet"),CUe=o(" \u2014 "),FS=a("a"),wUe=o("ProphetNetConfig"),AUe=o(" (ProphetNet model)"),yUe=l(),Im=a("li"),Jre=a("strong"),LUe=o("qdqbert"),xUe=o(" \u2014 "),TS=a("a"),$Ue=o("QDQBertConfig"),kUe=o(" (QDQBert model)"),SUe=l(),Nm=a("li"),Yre=a("strong"),RUe=o("rag"),PUe=o(" \u2014 "),MS=a("a"),BUe=o("RagConfig"),IUe=o(" (RAG model)"),NUe=l(),qm=a("li"),Kre=a("strong"),qUe=o("realm"),jUe=o(" \u2014 "),ES=a("a"),DUe=o("RealmConfig"),GUe=o(" (Realm model)"),OUe=l(),jm=a("li"),Zre=a("strong"),VUe=o("reformer"),XUe=o(" \u2014 "),CS=a("a"),zUe=o("ReformerConfig"),WUe=o(" (Reformer model)"),QUe=l(),Dm=a("li"),ete=a("strong"),HUe=o("regnet"),UUe=o(" \u2014 "),wS=a("a"),JUe=o("RegNetConfig"),YUe=o(" (RegNet model)"),KUe=l(),Gm=a("li"),ote=a("strong"),ZUe=o("rembert"),eJe=o(" \u2014 "),AS=a("a"),oJe=o("RemBertConfig"),rJe=o(" (RemBERT model)"),tJe=l(),Om=a("li"),rte=a("strong"),aJe=o("resnet"),nJe=o(" \u2014 "),yS=a("a"),sJe=o("ResNetConfig"),lJe=o(" (ResNet model)"),iJe=l(),Vm=a("li"),tte=a("strong"),dJe=o("retribert"),cJe=o(" \u2014 "),LS=a("a"),fJe=o("RetriBertConfig"),mJe=o(" (RetriBERT model)"),gJe=l(),Xm=a("li"),ate=a("strong"),hJe=o("roberta"),pJe=o(" \u2014 "),xS=a("a"),_Je=o("RobertaConfig"),uJe=o(" (RoBERTa model)"),bJe=l(),zm=a("li"),nte=a("strong"),vJe=o("roformer"),FJe=o(" \u2014 "),$S=a("a"),TJe=o("RoFormerConfig"),MJe=o(" (RoFormer model)"),EJe=l(),Wm=a("li"),ste=a("strong"),CJe=o("segformer"),wJe=o(" \u2014 "),kS=a("a"),AJe=o("SegformerConfig"),yJe=o(" (SegFormer model)"),LJe=l(),Qm=a("li"),lte=a("strong"),xJe=o("sew"),$Je=o(" \u2014 "),SS=a("a"),kJe=o("SEWConfig"),SJe=o(" (SEW model)"),RJe=l(),Hm=a("li"),ite=a("strong"),PJe=o("sew-d"),BJe=o(" \u2014 "),RS=a("a"),IJe=o("SEWDConfig"),NJe=o(" (SEW-D model)"),qJe=l(),Um=a("li"),dte=a("strong"),jJe=o("speech-encoder-decoder"),DJe=o(" \u2014 "),PS=a("a"),GJe=o("SpeechEncoderDecoderConfig"),OJe=o(" (Speech Encoder decoder model)"),VJe=l(),Jm=a("li"),cte=a("strong"),XJe=o("speech_to_text"),zJe=o(" \u2014 "),BS=a("a"),WJe=o("Speech2TextConfig"),QJe=o(" (Speech2Text model)"),HJe=l(),Ym=a("li"),fte=a("strong"),UJe=o("speech_to_text_2"),JJe=o(" \u2014 "),IS=a("a"),YJe=o("Speech2Text2Config"),KJe=o(" (Speech2Text2 model)"),ZJe=l(),Km=a("li"),mte=a("strong"),eYe=o("splinter"),oYe=o(" \u2014 "),NS=a("a"),rYe=o("SplinterConfig"),tYe=o(" (Splinter model)"),aYe=l(),Zm=a("li"),gte=a("strong"),nYe=o("squeezebert"),sYe=o(" \u2014 "),qS=a("a"),lYe=o("SqueezeBertConfig"),iYe=o(" (SqueezeBERT model)"),dYe=l(),eg=a("li"),hte=a("strong"),cYe=o("swin"),fYe=o(" \u2014 "),jS=a("a"),mYe=o("SwinConfig"),gYe=o(" (Swin model)"),hYe=l(),og=a("li"),pte=a("strong"),pYe=o("t5"),_Ye=o(" \u2014 "),DS=a("a"),uYe=o("T5Config"),bYe=o(" (T5 model)"),vYe=l(),rg=a("li"),_te=a("strong"),FYe=o("tapas"),TYe=o(" \u2014 "),GS=a("a"),MYe=o("TapasConfig"),EYe=o(" (TAPAS model)"),CYe=l(),tg=a("li"),ute=a("strong"),wYe=o("trajectory_transformer"),AYe=o(" \u2014 "),OS=a("a"),yYe=o("TrajectoryTransformerConfig"),LYe=o(" (Trajectory Transformer model)"),xYe=l(),ag=a("li"),bte=a("strong"),$Ye=o("transfo-xl"),kYe=o(" \u2014 "),VS=a("a"),SYe=o("TransfoXLConfig"),RYe=o(" (Transformer-XL model)"),PYe=l(),ng=a("li"),vte=a("strong"),BYe=o("trocr"),IYe=o(" \u2014 "),XS=a("a"),NYe=o("TrOCRConfig"),qYe=o(" (TrOCR model)"),jYe=l(),sg=a("li"),Fte=a("strong"),DYe=o("unispeech"),GYe=o(" \u2014 "),zS=a("a"),OYe=o("UniSpeechConfig"),VYe=o(" (UniSpeech model)"),XYe=l(),lg=a("li"),Tte=a("strong"),zYe=o("unispeech-sat"),WYe=o(" \u2014 "),WS=a("a"),QYe=o("UniSpeechSatConfig"),HYe=o(" (UniSpeechSat model)"),UYe=l(),ig=a("li"),Mte=a("strong"),JYe=o("van"),YYe=o(" \u2014 "),QS=a("a"),KYe=o("VanConfig"),ZYe=o(" (VAN model)"),eKe=l(),dg=a("li"),Ete=a("strong"),oKe=o("vilt"),rKe=o(" \u2014 "),HS=a("a"),tKe=o("ViltConfig"),aKe=o(" (ViLT model)"),nKe=l(),cg=a("li"),Cte=a("strong"),sKe=o("vision-encoder-decoder"),lKe=o(" \u2014 "),US=a("a"),iKe=o("VisionEncoderDecoderConfig"),dKe=o(" (Vision Encoder decoder model)"),cKe=l(),fg=a("li"),wte=a("strong"),fKe=o("vision-text-dual-encoder"),mKe=o(" \u2014 "),JS=a("a"),gKe=o("VisionTextDualEncoderConfig"),hKe=o(" (VisionTextDualEncoder model)"),pKe=l(),mg=a("li"),Ate=a("strong"),_Ke=o("visual_bert"),uKe=o(" \u2014 "),YS=a("a"),bKe=o("VisualBertConfig"),vKe=o(" (VisualBert model)"),FKe=l(),gg=a("li"),yte=a("strong"),TKe=o("vit"),MKe=o(" \u2014 "),KS=a("a"),EKe=o("ViTConfig"),CKe=o(" (ViT model)"),wKe=l(),hg=a("li"),Lte=a("strong"),AKe=o("vit_mae"),yKe=o(" \u2014 "),ZS=a("a"),LKe=o("ViTMAEConfig"),xKe=o(" (ViTMAE model)"),$Ke=l(),pg=a("li"),xte=a("strong"),kKe=o("wav2vec2"),SKe=o(" \u2014 "),eR=a("a"),RKe=o("Wav2Vec2Config"),PKe=o(" (Wav2Vec2 model)"),BKe=l(),_g=a("li"),$te=a("strong"),IKe=o("wav2vec2-conformer"),NKe=o(" \u2014 "),oR=a("a"),qKe=o("Wav2Vec2ConformerConfig"),jKe=o(" (Wav2Vec2-Conformer model)"),DKe=l(),ug=a("li"),kte=a("strong"),GKe=o("wavlm"),OKe=o(" \u2014 "),rR=a("a"),VKe=o("WavLMConfig"),XKe=o(" (WavLM model)"),zKe=l(),bg=a("li"),Ste=a("strong"),WKe=o("xglm"),QKe=o(" \u2014 "),tR=a("a"),HKe=o("XGLMConfig"),UKe=o(" (XGLM model)"),JKe=l(),vg=a("li"),Rte=a("strong"),YKe=o("xlm"),KKe=o(" \u2014 "),aR=a("a"),ZKe=o("XLMConfig"),eZe=o(" (XLM model)"),oZe=l(),Fg=a("li"),Pte=a("strong"),rZe=o("xlm-prophetnet"),tZe=o(" \u2014 "),nR=a("a"),aZe=o("XLMProphetNetConfig"),nZe=o(" (XLMProphetNet model)"),sZe=l(),Tg=a("li"),Bte=a("strong"),lZe=o("xlm-roberta"),iZe=o(" \u2014 "),sR=a("a"),dZe=o("XLMRobertaConfig"),cZe=o(" (XLM-RoBERTa model)"),fZe=l(),Mg=a("li"),Ite=a("strong"),mZe=o("xlm-roberta-xl"),gZe=o(" \u2014 "),lR=a("a"),hZe=o("XLMRobertaXLConfig"),pZe=o(" (XLM-RoBERTa-XL model)"),_Ze=l(),Eg=a("li"),Nte=a("strong"),uZe=o("xlnet"),bZe=o(" \u2014 "),iR=a("a"),vZe=o("XLNetConfig"),FZe=o(" (XLNet model)"),TZe=l(),Cg=a("li"),qte=a("strong"),MZe=o("yolos"),EZe=o(" \u2014 "),dR=a("a"),CZe=o("YolosConfig"),wZe=o(" (YOLOS model)"),AZe=l(),wg=a("li"),jte=a("strong"),yZe=o("yoso"),LZe=o(" \u2014 "),cR=a("a"),xZe=o("YosoConfig"),$Ze=o(" (YOSO model)"),kZe=l(),F(Ag.$$.fragment),SZe=l(),yg=a("div"),F(VA.$$.fragment),RZe=l(),Dte=a("p"),PZe=o("Register a new configuration for this class."),Vqe=l(),Ei=a("h2"),Lg=a("a"),Gte=a("span"),F(XA.$$.fragment),BZe=l(),Ote=a("span"),IZe=o("AutoTokenizer"),Xqe=l(),wo=a("div"),F(zA.$$.fragment),NZe=l(),WA=a("p"),qZe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),fR=a("a"),jZe=o("AutoTokenizer.from_pretrained()"),DZe=o(" class method."),GZe=l(),QA=a("p"),OZe=o("This class cannot be instantiated directly using "),Vte=a("code"),VZe=o("__init__()"),XZe=o(" (throws an error)."),zZe=l(),Cr=a("div"),F(HA.$$.fragment),WZe=l(),Xte=a("p"),QZe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),HZe=l(),Aa=a("p"),UZe=o("The tokenizer class to instantiate is selected based on the "),zte=a("code"),JZe=o("model_type"),YZe=o(` property of the config object (either
passed as an argument or loaded from `),Wte=a("code"),KZe=o("pretrained_model_name_or_path"),ZZe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qte=a("code"),eeo=o("pretrained_model_name_or_path"),oeo=o(":"),reo=l(),k=a("ul"),Sn=a("li"),Hte=a("strong"),teo=o("albert"),aeo=o(" \u2014 "),mR=a("a"),neo=o("AlbertTokenizer"),seo=o(" or "),gR=a("a"),leo=o("AlbertTokenizerFast"),ieo=o(" (ALBERT model)"),deo=l(),Rn=a("li"),Ute=a("strong"),ceo=o("bart"),feo=o(" \u2014 "),hR=a("a"),meo=o("BartTokenizer"),geo=o(" or "),pR=a("a"),heo=o("BartTokenizerFast"),peo=o(" (BART model)"),_eo=l(),Pn=a("li"),Jte=a("strong"),ueo=o("barthez"),beo=o(" \u2014 "),_R=a("a"),veo=o("BarthezTokenizer"),Feo=o(" or "),uR=a("a"),Teo=o("BarthezTokenizerFast"),Meo=o(" (BARThez model)"),Eeo=l(),Bn=a("li"),Yte=a("strong"),Ceo=o("bartpho"),weo=o(" \u2014 "),bR=a("a"),Aeo=o("BartphoTokenizer"),yeo=o(" or "),vR=a("a"),Leo=o("BartphoTokenizerFast"),xeo=o(" (BARTpho model)"),$eo=l(),In=a("li"),Kte=a("strong"),keo=o("bert"),Seo=o(" \u2014 "),FR=a("a"),Reo=o("BertTokenizer"),Peo=o(" or "),TR=a("a"),Beo=o("BertTokenizerFast"),Ieo=o(" (BERT model)"),Neo=l(),xg=a("li"),Zte=a("strong"),qeo=o("bert-generation"),jeo=o(" \u2014 "),MR=a("a"),Deo=o("BertGenerationTokenizer"),Geo=o(" (Bert Generation model)"),Oeo=l(),$g=a("li"),eae=a("strong"),Veo=o("bert-japanese"),Xeo=o(" \u2014 "),ER=a("a"),zeo=o("BertJapaneseTokenizer"),Weo=o(" (BertJapanese model)"),Qeo=l(),kg=a("li"),oae=a("strong"),Heo=o("bertweet"),Ueo=o(" \u2014 "),CR=a("a"),Jeo=o("BertweetTokenizer"),Yeo=o(" (Bertweet model)"),Keo=l(),Nn=a("li"),rae=a("strong"),Zeo=o("big_bird"),eoo=o(" \u2014 "),wR=a("a"),ooo=o("BigBirdTokenizer"),roo=o(" or "),AR=a("a"),too=o("BigBirdTokenizerFast"),aoo=o(" (BigBird model)"),noo=l(),qn=a("li"),tae=a("strong"),soo=o("bigbird_pegasus"),loo=o(" \u2014 "),yR=a("a"),ioo=o("PegasusTokenizer"),doo=o(" or "),LR=a("a"),coo=o("PegasusTokenizerFast"),foo=o(" (BigBirdPegasus model)"),moo=l(),jn=a("li"),aae=a("strong"),goo=o("blenderbot"),hoo=o(" \u2014 "),xR=a("a"),poo=o("BlenderbotTokenizer"),_oo=o(" or "),$R=a("a"),uoo=o("BlenderbotTokenizerFast"),boo=o(" (Blenderbot model)"),voo=l(),Sg=a("li"),nae=a("strong"),Foo=o("blenderbot-small"),Too=o(" \u2014 "),kR=a("a"),Moo=o("BlenderbotSmallTokenizer"),Eoo=o(" (BlenderbotSmall model)"),Coo=l(),Rg=a("li"),sae=a("strong"),woo=o("byt5"),Aoo=o(" \u2014 "),SR=a("a"),yoo=o("ByT5Tokenizer"),Loo=o(" (ByT5 model)"),xoo=l(),Dn=a("li"),lae=a("strong"),$oo=o("camembert"),koo=o(" \u2014 "),RR=a("a"),Soo=o("CamembertTokenizer"),Roo=o(" or "),PR=a("a"),Poo=o("CamembertTokenizerFast"),Boo=o(" (CamemBERT model)"),Ioo=l(),Pg=a("li"),iae=a("strong"),Noo=o("canine"),qoo=o(" \u2014 "),BR=a("a"),joo=o("CanineTokenizer"),Doo=o(" (Canine model)"),Goo=l(),Gn=a("li"),dae=a("strong"),Ooo=o("clip"),Voo=o(" \u2014 "),IR=a("a"),Xoo=o("CLIPTokenizer"),zoo=o(" or "),NR=a("a"),Woo=o("CLIPTokenizerFast"),Qoo=o(" (CLIP model)"),Hoo=l(),On=a("li"),cae=a("strong"),Uoo=o("convbert"),Joo=o(" \u2014 "),qR=a("a"),Yoo=o("ConvBertTokenizer"),Koo=o(" or "),jR=a("a"),Zoo=o("ConvBertTokenizerFast"),ero=o(" (ConvBERT model)"),oro=l(),Vn=a("li"),fae=a("strong"),rro=o("cpm"),tro=o(" \u2014 "),DR=a("a"),aro=o("CpmTokenizer"),nro=o(" or "),GR=a("a"),sro=o("CpmTokenizerFast"),lro=o(" (CPM model)"),iro=l(),Bg=a("li"),mae=a("strong"),dro=o("ctrl"),cro=o(" \u2014 "),OR=a("a"),fro=o("CTRLTokenizer"),mro=o(" (CTRL model)"),gro=l(),Xn=a("li"),gae=a("strong"),hro=o("data2vec-text"),pro=o(" \u2014 "),VR=a("a"),_ro=o("RobertaTokenizer"),uro=o(" or "),XR=a("a"),bro=o("RobertaTokenizerFast"),vro=o(" (Data2VecText model)"),Fro=l(),zn=a("li"),hae=a("strong"),Tro=o("deberta"),Mro=o(" \u2014 "),zR=a("a"),Ero=o("DebertaTokenizer"),Cro=o(" or "),WR=a("a"),wro=o("DebertaTokenizerFast"),Aro=o(" (DeBERTa model)"),yro=l(),Wn=a("li"),pae=a("strong"),Lro=o("deberta-v2"),xro=o(" \u2014 "),QR=a("a"),$ro=o("DebertaV2Tokenizer"),kro=o(" or "),HR=a("a"),Sro=o("DebertaV2TokenizerFast"),Rro=o(" (DeBERTa-v2 model)"),Pro=l(),Qn=a("li"),_ae=a("strong"),Bro=o("distilbert"),Iro=o(" \u2014 "),UR=a("a"),Nro=o("DistilBertTokenizer"),qro=o(" or "),JR=a("a"),jro=o("DistilBertTokenizerFast"),Dro=o(" (DistilBERT model)"),Gro=l(),Hn=a("li"),uae=a("strong"),Oro=o("dpr"),Vro=o(" \u2014 "),YR=a("a"),Xro=o("DPRQuestionEncoderTokenizer"),zro=o(" or "),KR=a("a"),Wro=o("DPRQuestionEncoderTokenizerFast"),Qro=o(" (DPR model)"),Hro=l(),Un=a("li"),bae=a("strong"),Uro=o("electra"),Jro=o(" \u2014 "),ZR=a("a"),Yro=o("ElectraTokenizer"),Kro=o(" or "),eP=a("a"),Zro=o("ElectraTokenizerFast"),eto=o(" (ELECTRA model)"),oto=l(),Ig=a("li"),vae=a("strong"),rto=o("flaubert"),tto=o(" \u2014 "),oP=a("a"),ato=o("FlaubertTokenizer"),nto=o(" (FlauBERT model)"),sto=l(),Jn=a("li"),Fae=a("strong"),lto=o("fnet"),ito=o(" \u2014 "),rP=a("a"),dto=o("FNetTokenizer"),cto=o(" or "),tP=a("a"),fto=o("FNetTokenizerFast"),mto=o(" (FNet model)"),gto=l(),Ng=a("li"),Tae=a("strong"),hto=o("fsmt"),pto=o(" \u2014 "),aP=a("a"),_to=o("FSMTTokenizer"),uto=o(" (FairSeq Machine-Translation model)"),bto=l(),Yn=a("li"),Mae=a("strong"),vto=o("funnel"),Fto=o(" \u2014 "),nP=a("a"),Tto=o("FunnelTokenizer"),Mto=o(" or "),sP=a("a"),Eto=o("FunnelTokenizerFast"),Cto=o(" (Funnel Transformer model)"),wto=l(),Kn=a("li"),Eae=a("strong"),Ato=o("gpt2"),yto=o(" \u2014 "),lP=a("a"),Lto=o("GPT2Tokenizer"),xto=o(" or "),iP=a("a"),$to=o("GPT2TokenizerFast"),kto=o(" (OpenAI GPT-2 model)"),Sto=l(),Zn=a("li"),Cae=a("strong"),Rto=o("gpt_neo"),Pto=o(" \u2014 "),dP=a("a"),Bto=o("GPT2Tokenizer"),Ito=o(" or "),cP=a("a"),Nto=o("GPT2TokenizerFast"),qto=o(" (GPT Neo model)"),jto=l(),qg=a("li"),wae=a("strong"),Dto=o("gpt_neox"),Gto=o(" \u2014 "),fP=a("a"),Oto=o("GPTNeoXTokenizerFast"),Vto=o(" (GPT NeoX model)"),Xto=l(),es=a("li"),Aae=a("strong"),zto=o("gptj"),Wto=o(" \u2014 "),mP=a("a"),Qto=o("GPT2Tokenizer"),Hto=o(" or "),gP=a("a"),Uto=o("GPT2TokenizerFast"),Jto=o(" (GPT-J model)"),Yto=l(),os=a("li"),yae=a("strong"),Kto=o("herbert"),Zto=o(" \u2014 "),hP=a("a"),eao=o("HerbertTokenizer"),oao=o(" or "),pP=a("a"),rao=o("HerbertTokenizerFast"),tao=o(" (HerBERT model)"),aao=l(),jg=a("li"),Lae=a("strong"),nao=o("hubert"),sao=o(" \u2014 "),_P=a("a"),lao=o("Wav2Vec2CTCTokenizer"),iao=o(" (Hubert model)"),dao=l(),rs=a("li"),xae=a("strong"),cao=o("ibert"),fao=o(" \u2014 "),uP=a("a"),mao=o("RobertaTokenizer"),gao=o(" or "),bP=a("a"),hao=o("RobertaTokenizerFast"),pao=o(" (I-BERT model)"),_ao=l(),ts=a("li"),$ae=a("strong"),uao=o("layoutlm"),bao=o(" \u2014 "),vP=a("a"),vao=o("LayoutLMTokenizer"),Fao=o(" or "),FP=a("a"),Tao=o("LayoutLMTokenizerFast"),Mao=o(" (LayoutLM model)"),Eao=l(),as=a("li"),kae=a("strong"),Cao=o("layoutlmv2"),wao=o(" \u2014 "),TP=a("a"),Aao=o("LayoutLMv2Tokenizer"),yao=o(" or "),MP=a("a"),Lao=o("LayoutLMv2TokenizerFast"),xao=o(" (LayoutLMv2 model)"),$ao=l(),ns=a("li"),Sae=a("strong"),kao=o("layoutlmv3"),Sao=o(" \u2014 "),EP=a("a"),Rao=o("LayoutLMv3Tokenizer"),Pao=o(" or "),CP=a("a"),Bao=o("LayoutLMv3TokenizerFast"),Iao=o(" (LayoutLMv3 model)"),Nao=l(),ss=a("li"),Rae=a("strong"),qao=o("layoutxlm"),jao=o(" \u2014 "),wP=a("a"),Dao=o("LayoutXLMTokenizer"),Gao=o(" or "),AP=a("a"),Oao=o("LayoutXLMTokenizerFast"),Vao=o(" (LayoutXLM model)"),Xao=l(),ls=a("li"),Pae=a("strong"),zao=o("led"),Wao=o(" \u2014 "),yP=a("a"),Qao=o("LEDTokenizer"),Hao=o(" or "),LP=a("a"),Uao=o("LEDTokenizerFast"),Jao=o(" (LED model)"),Yao=l(),is=a("li"),Bae=a("strong"),Kao=o("longformer"),Zao=o(" \u2014 "),xP=a("a"),eno=o("LongformerTokenizer"),ono=o(" or "),$P=a("a"),rno=o("LongformerTokenizerFast"),tno=o(" (Longformer model)"),ano=l(),Dg=a("li"),Iae=a("strong"),nno=o("luke"),sno=o(" \u2014 "),kP=a("a"),lno=o("LukeTokenizer"),ino=o(" (LUKE model)"),dno=l(),ds=a("li"),Nae=a("strong"),cno=o("lxmert"),fno=o(" \u2014 "),SP=a("a"),mno=o("LxmertTokenizer"),gno=o(" or "),RP=a("a"),hno=o("LxmertTokenizerFast"),pno=o(" (LXMERT model)"),_no=l(),Gg=a("li"),qae=a("strong"),uno=o("m2m_100"),bno=o(" \u2014 "),PP=a("a"),vno=o("M2M100Tokenizer"),Fno=o(" (M2M100 model)"),Tno=l(),Og=a("li"),jae=a("strong"),Mno=o("marian"),Eno=o(" \u2014 "),BP=a("a"),Cno=o("MarianTokenizer"),wno=o(" (Marian model)"),Ano=l(),cs=a("li"),Dae=a("strong"),yno=o("mbart"),Lno=o(" \u2014 "),IP=a("a"),xno=o("MBartTokenizer"),$no=o(" or "),NP=a("a"),kno=o("MBartTokenizerFast"),Sno=o(" (mBART model)"),Rno=l(),fs=a("li"),Gae=a("strong"),Pno=o("mbart50"),Bno=o(" \u2014 "),qP=a("a"),Ino=o("MBart50Tokenizer"),Nno=o(" or "),jP=a("a"),qno=o("MBart50TokenizerFast"),jno=o(" (mBART-50 model)"),Dno=l(),ms=a("li"),Oae=a("strong"),Gno=o("megatron-bert"),Ono=o(" \u2014 "),DP=a("a"),Vno=o("BertTokenizer"),Xno=o(" or "),GP=a("a"),zno=o("BertTokenizerFast"),Wno=o(" (MegatronBert model)"),Qno=l(),Vg=a("li"),Vae=a("strong"),Hno=o("mluke"),Uno=o(" \u2014 "),OP=a("a"),Jno=o("MLukeTokenizer"),Yno=o(" (mLUKE model)"),Kno=l(),gs=a("li"),Xae=a("strong"),Zno=o("mobilebert"),eso=o(" \u2014 "),VP=a("a"),oso=o("MobileBertTokenizer"),rso=o(" or "),XP=a("a"),tso=o("MobileBertTokenizerFast"),aso=o(" (MobileBERT model)"),nso=l(),hs=a("li"),zae=a("strong"),sso=o("mpnet"),lso=o(" \u2014 "),zP=a("a"),iso=o("MPNetTokenizer"),dso=o(" or "),WP=a("a"),cso=o("MPNetTokenizerFast"),fso=o(" (MPNet model)"),mso=l(),ps=a("li"),Wae=a("strong"),gso=o("mt5"),hso=o(" \u2014 "),QP=a("a"),pso=o("MT5Tokenizer"),_so=o(" or "),HP=a("a"),uso=o("MT5TokenizerFast"),bso=o(" (mT5 model)"),vso=l(),_s=a("li"),Qae=a("strong"),Fso=o("nystromformer"),Tso=o(" \u2014 "),UP=a("a"),Mso=o("AlbertTokenizer"),Eso=o(" or "),JP=a("a"),Cso=o("AlbertTokenizerFast"),wso=o(" (Nystromformer model)"),Aso=l(),us=a("li"),Hae=a("strong"),yso=o("openai-gpt"),Lso=o(" \u2014 "),YP=a("a"),xso=o("OpenAIGPTTokenizer"),$so=o(" or "),KP=a("a"),kso=o("OpenAIGPTTokenizerFast"),Sso=o(" (OpenAI GPT model)"),Rso=l(),Xg=a("li"),Uae=a("strong"),Pso=o("opt"),Bso=o(" \u2014 "),ZP=a("a"),Iso=o("GPT2Tokenizer"),Nso=o(" (OPT model)"),qso=l(),bs=a("li"),Jae=a("strong"),jso=o("pegasus"),Dso=o(" \u2014 "),eB=a("a"),Gso=o("PegasusTokenizer"),Oso=o(" or "),oB=a("a"),Vso=o("PegasusTokenizerFast"),Xso=o(" (Pegasus model)"),zso=l(),zg=a("li"),Yae=a("strong"),Wso=o("perceiver"),Qso=o(" \u2014 "),rB=a("a"),Hso=o("PerceiverTokenizer"),Uso=o(" (Perceiver model)"),Jso=l(),Wg=a("li"),Kae=a("strong"),Yso=o("phobert"),Kso=o(" \u2014 "),tB=a("a"),Zso=o("PhobertTokenizer"),elo=o(" (PhoBERT model)"),olo=l(),Qg=a("li"),Zae=a("strong"),rlo=o("plbart"),tlo=o(" \u2014 "),aB=a("a"),alo=o("PLBartTokenizer"),nlo=o(" (PLBart model)"),slo=l(),Hg=a("li"),ene=a("strong"),llo=o("prophetnet"),ilo=o(" \u2014 "),nB=a("a"),dlo=o("ProphetNetTokenizer"),clo=o(" (ProphetNet model)"),flo=l(),vs=a("li"),one=a("strong"),mlo=o("qdqbert"),glo=o(" \u2014 "),sB=a("a"),hlo=o("BertTokenizer"),plo=o(" or "),lB=a("a"),_lo=o("BertTokenizerFast"),ulo=o(" (QDQBert model)"),blo=l(),Ug=a("li"),rne=a("strong"),vlo=o("rag"),Flo=o(" \u2014 "),iB=a("a"),Tlo=o("RagTokenizer"),Mlo=o(" (RAG model)"),Elo=l(),Fs=a("li"),tne=a("strong"),Clo=o("realm"),wlo=o(" \u2014 "),dB=a("a"),Alo=o("RealmTokenizer"),ylo=o(" or "),cB=a("a"),Llo=o("RealmTokenizerFast"),xlo=o(" (Realm model)"),$lo=l(),Ts=a("li"),ane=a("strong"),klo=o("reformer"),Slo=o(" \u2014 "),fB=a("a"),Rlo=o("ReformerTokenizer"),Plo=o(" or "),mB=a("a"),Blo=o("ReformerTokenizerFast"),Ilo=o(" (Reformer model)"),Nlo=l(),Ms=a("li"),nne=a("strong"),qlo=o("rembert"),jlo=o(" \u2014 "),gB=a("a"),Dlo=o("RemBertTokenizer"),Glo=o(" or "),hB=a("a"),Olo=o("RemBertTokenizerFast"),Vlo=o(" (RemBERT model)"),Xlo=l(),Es=a("li"),sne=a("strong"),zlo=o("retribert"),Wlo=o(" \u2014 "),pB=a("a"),Qlo=o("RetriBertTokenizer"),Hlo=o(" or "),_B=a("a"),Ulo=o("RetriBertTokenizerFast"),Jlo=o(" (RetriBERT model)"),Ylo=l(),Cs=a("li"),lne=a("strong"),Klo=o("roberta"),Zlo=o(" \u2014 "),uB=a("a"),eio=o("RobertaTokenizer"),oio=o(" or "),bB=a("a"),rio=o("RobertaTokenizerFast"),tio=o(" (RoBERTa model)"),aio=l(),ws=a("li"),ine=a("strong"),nio=o("roformer"),sio=o(" \u2014 "),vB=a("a"),lio=o("RoFormerTokenizer"),iio=o(" or "),FB=a("a"),dio=o("RoFormerTokenizerFast"),cio=o(" (RoFormer model)"),fio=l(),Jg=a("li"),dne=a("strong"),mio=o("speech_to_text"),gio=o(" \u2014 "),TB=a("a"),hio=o("Speech2TextTokenizer"),pio=o(" (Speech2Text model)"),_io=l(),Yg=a("li"),cne=a("strong"),uio=o("speech_to_text_2"),bio=o(" \u2014 "),MB=a("a"),vio=o("Speech2Text2Tokenizer"),Fio=o(" (Speech2Text2 model)"),Tio=l(),As=a("li"),fne=a("strong"),Mio=o("splinter"),Eio=o(" \u2014 "),EB=a("a"),Cio=o("SplinterTokenizer"),wio=o(" or "),CB=a("a"),Aio=o("SplinterTokenizerFast"),yio=o(" (Splinter model)"),Lio=l(),ys=a("li"),mne=a("strong"),xio=o("squeezebert"),$io=o(" \u2014 "),wB=a("a"),kio=o("SqueezeBertTokenizer"),Sio=o(" or "),AB=a("a"),Rio=o("SqueezeBertTokenizerFast"),Pio=o(" (SqueezeBERT model)"),Bio=l(),Ls=a("li"),gne=a("strong"),Iio=o("t5"),Nio=o(" \u2014 "),yB=a("a"),qio=o("T5Tokenizer"),jio=o(" or "),LB=a("a"),Dio=o("T5TokenizerFast"),Gio=o(" (T5 model)"),Oio=l(),Kg=a("li"),hne=a("strong"),Vio=o("tapas"),Xio=o(" \u2014 "),xB=a("a"),zio=o("TapasTokenizer"),Wio=o(" (TAPAS model)"),Qio=l(),Zg=a("li"),pne=a("strong"),Hio=o("tapex"),Uio=o(" \u2014 "),$B=a("a"),Jio=o("TapexTokenizer"),Yio=o(" (TAPEX model)"),Kio=l(),eh=a("li"),_ne=a("strong"),Zio=o("transfo-xl"),edo=o(" \u2014 "),kB=a("a"),odo=o("TransfoXLTokenizer"),rdo=o(" (Transformer-XL model)"),tdo=l(),xs=a("li"),une=a("strong"),ado=o("visual_bert"),ndo=o(" \u2014 "),SB=a("a"),sdo=o("BertTokenizer"),ldo=o(" or "),RB=a("a"),ido=o("BertTokenizerFast"),ddo=o(" (VisualBert model)"),cdo=l(),oh=a("li"),bne=a("strong"),fdo=o("wav2vec2"),mdo=o(" \u2014 "),PB=a("a"),gdo=o("Wav2Vec2CTCTokenizer"),hdo=o(" (Wav2Vec2 model)"),pdo=l(),rh=a("li"),vne=a("strong"),_do=o("wav2vec2-conformer"),udo=o(" \u2014 "),BB=a("a"),bdo=o("Wav2Vec2CTCTokenizer"),vdo=o(" (Wav2Vec2-Conformer model)"),Fdo=l(),th=a("li"),Fne=a("strong"),Tdo=o("wav2vec2_phoneme"),Mdo=o(" \u2014 "),IB=a("a"),Edo=o("Wav2Vec2PhonemeCTCTokenizer"),Cdo=o(" (Wav2Vec2Phoneme model)"),wdo=l(),$s=a("li"),Tne=a("strong"),Ado=o("xglm"),ydo=o(" \u2014 "),NB=a("a"),Ldo=o("XGLMTokenizer"),xdo=o(" or "),qB=a("a"),$do=o("XGLMTokenizerFast"),kdo=o(" (XGLM model)"),Sdo=l(),ah=a("li"),Mne=a("strong"),Rdo=o("xlm"),Pdo=o(" \u2014 "),jB=a("a"),Bdo=o("XLMTokenizer"),Ido=o(" (XLM model)"),Ndo=l(),nh=a("li"),Ene=a("strong"),qdo=o("xlm-prophetnet"),jdo=o(" \u2014 "),DB=a("a"),Ddo=o("XLMProphetNetTokenizer"),Gdo=o(" (XLMProphetNet model)"),Odo=l(),ks=a("li"),Cne=a("strong"),Vdo=o("xlm-roberta"),Xdo=o(" \u2014 "),GB=a("a"),zdo=o("XLMRobertaTokenizer"),Wdo=o(" or "),OB=a("a"),Qdo=o("XLMRobertaTokenizerFast"),Hdo=o(" (XLM-RoBERTa model)"),Udo=l(),Ss=a("li"),wne=a("strong"),Jdo=o("xlm-roberta-xl"),Ydo=o(" \u2014 "),VB=a("a"),Kdo=o("RobertaTokenizer"),Zdo=o(" or "),XB=a("a"),eco=o("RobertaTokenizerFast"),oco=o(" (XLM-RoBERTa-XL model)"),rco=l(),Rs=a("li"),Ane=a("strong"),tco=o("xlnet"),aco=o(" \u2014 "),zB=a("a"),nco=o("XLNetTokenizer"),sco=o(" or "),WB=a("a"),lco=o("XLNetTokenizerFast"),ico=o(" (XLNet model)"),dco=l(),Ps=a("li"),yne=a("strong"),cco=o("yoso"),fco=o(" \u2014 "),QB=a("a"),mco=o("AlbertTokenizer"),gco=o(" or "),HB=a("a"),hco=o("AlbertTokenizerFast"),pco=o(" (YOSO model)"),_co=l(),F(sh.$$.fragment),uco=l(),lh=a("div"),F(UA.$$.fragment),bco=l(),Lne=a("p"),vco=o("Register a new tokenizer in this mapping."),zqe=l(),Ci=a("h2"),ih=a("a"),xne=a("span"),F(JA.$$.fragment),Fco=l(),$ne=a("span"),Tco=o("AutoFeatureExtractor"),Wqe=l(),Ao=a("div"),F(YA.$$.fragment),Mco=l(),KA=a("p"),Eco=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),UB=a("a"),Cco=o("AutoFeatureExtractor.from_pretrained()"),wco=o(" class method."),Aco=l(),ZA=a("p"),yco=o("This class cannot be instantiated directly using "),kne=a("code"),Lco=o("__init__()"),xco=o(" (throws an error)."),$co=l(),He=a("div"),F(ey.$$.fragment),kco=l(),Sne=a("p"),Sco=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Rco=l(),ya=a("p"),Pco=o("The feature extractor class to instantiate is selected based on the "),Rne=a("code"),Bco=o("model_type"),Ico=o(` property of the config object
(either passed as an argument or loaded from `),Pne=a("code"),Nco=o("pretrained_model_name_or_path"),qco=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Bne=a("code"),jco=o("pretrained_model_name_or_path"),Dco=o(":"),Gco=l(),Y=a("ul"),dh=a("li"),Ine=a("strong"),Oco=o("beit"),Vco=o(" \u2014 "),JB=a("a"),Xco=o("BeitFeatureExtractor"),zco=o(" (BEiT model)"),Wco=l(),ch=a("li"),Nne=a("strong"),Qco=o("clip"),Hco=o(" \u2014 "),YB=a("a"),Uco=o("CLIPFeatureExtractor"),Jco=o(" (CLIP model)"),Yco=l(),fh=a("li"),qne=a("strong"),Kco=o("convnext"),Zco=o(" \u2014 "),KB=a("a"),efo=o("ConvNextFeatureExtractor"),ofo=o(" (ConvNext model)"),rfo=l(),mh=a("li"),jne=a("strong"),tfo=o("cvt"),afo=o(" \u2014 "),ZB=a("a"),nfo=o("ConvNextFeatureExtractor"),sfo=o(" (CvT model)"),lfo=l(),gh=a("li"),Dne=a("strong"),ifo=o("data2vec-audio"),dfo=o(" \u2014 "),eI=a("a"),cfo=o("Wav2Vec2FeatureExtractor"),ffo=o(" (Data2VecAudio model)"),mfo=l(),hh=a("li"),Gne=a("strong"),gfo=o("data2vec-vision"),hfo=o(" \u2014 "),oI=a("a"),pfo=o("BeitFeatureExtractor"),_fo=o(" (Data2VecVision model)"),ufo=l(),ph=a("li"),One=a("strong"),bfo=o("deit"),vfo=o(" \u2014 "),rI=a("a"),Ffo=o("DeiTFeatureExtractor"),Tfo=o(" (DeiT model)"),Mfo=l(),_h=a("li"),Vne=a("strong"),Efo=o("detr"),Cfo=o(" \u2014 "),tI=a("a"),wfo=o("DetrFeatureExtractor"),Afo=o(" (DETR model)"),yfo=l(),uh=a("li"),Xne=a("strong"),Lfo=o("dpt"),xfo=o(" \u2014 "),aI=a("a"),$fo=o("DPTFeatureExtractor"),kfo=o(" (DPT model)"),Sfo=l(),bh=a("li"),zne=a("strong"),Rfo=o("flava"),Pfo=o(" \u2014 "),nI=a("a"),Bfo=o("FlavaFeatureExtractor"),Ifo=o(" (Flava model)"),Nfo=l(),vh=a("li"),Wne=a("strong"),qfo=o("glpn"),jfo=o(" \u2014 "),sI=a("a"),Dfo=o("GLPNFeatureExtractor"),Gfo=o(" (GLPN model)"),Ofo=l(),Fh=a("li"),Qne=a("strong"),Vfo=o("hubert"),Xfo=o(" \u2014 "),lI=a("a"),zfo=o("Wav2Vec2FeatureExtractor"),Wfo=o(" (Hubert model)"),Qfo=l(),Th=a("li"),Hne=a("strong"),Hfo=o("imagegpt"),Ufo=o(" \u2014 "),iI=a("a"),Jfo=o("ImageGPTFeatureExtractor"),Yfo=o(" (ImageGPT model)"),Kfo=l(),Mh=a("li"),Une=a("strong"),Zfo=o("layoutlmv2"),emo=o(" \u2014 "),dI=a("a"),omo=o("LayoutLMv2FeatureExtractor"),rmo=o(" (LayoutLMv2 model)"),tmo=l(),Eh=a("li"),Jne=a("strong"),amo=o("layoutlmv3"),nmo=o(" \u2014 "),cI=a("a"),smo=o("LayoutLMv3FeatureExtractor"),lmo=o(" (LayoutLMv3 model)"),imo=l(),Ch=a("li"),Yne=a("strong"),dmo=o("levit"),cmo=o(" \u2014 "),fI=a("a"),fmo=o("LevitFeatureExtractor"),mmo=o(" (LeViT model)"),gmo=l(),wh=a("li"),Kne=a("strong"),hmo=o("maskformer"),pmo=o(" \u2014 "),mI=a("a"),_mo=o("MaskFormerFeatureExtractor"),umo=o(" (MaskFormer model)"),bmo=l(),Ah=a("li"),Zne=a("strong"),vmo=o("perceiver"),Fmo=o(" \u2014 "),gI=a("a"),Tmo=o("PerceiverFeatureExtractor"),Mmo=o(" (Perceiver model)"),Emo=l(),yh=a("li"),ese=a("strong"),Cmo=o("poolformer"),wmo=o(" \u2014 "),hI=a("a"),Amo=o("PoolFormerFeatureExtractor"),ymo=o(" (PoolFormer model)"),Lmo=l(),Lh=a("li"),ose=a("strong"),xmo=o("regnet"),$mo=o(" \u2014 "),pI=a("a"),kmo=o("ConvNextFeatureExtractor"),Smo=o(" (RegNet model)"),Rmo=l(),xh=a("li"),rse=a("strong"),Pmo=o("resnet"),Bmo=o(" \u2014 "),_I=a("a"),Imo=o("ConvNextFeatureExtractor"),Nmo=o(" (ResNet model)"),qmo=l(),$h=a("li"),tse=a("strong"),jmo=o("segformer"),Dmo=o(" \u2014 "),uI=a("a"),Gmo=o("SegformerFeatureExtractor"),Omo=o(" (SegFormer model)"),Vmo=l(),kh=a("li"),ase=a("strong"),Xmo=o("speech_to_text"),zmo=o(" \u2014 "),bI=a("a"),Wmo=o("Speech2TextFeatureExtractor"),Qmo=o(" (Speech2Text model)"),Hmo=l(),Sh=a("li"),nse=a("strong"),Umo=o("swin"),Jmo=o(" \u2014 "),vI=a("a"),Ymo=o("ViTFeatureExtractor"),Kmo=o(" (Swin model)"),Zmo=l(),Rh=a("li"),sse=a("strong"),ego=o("van"),ogo=o(" \u2014 "),FI=a("a"),rgo=o("ConvNextFeatureExtractor"),tgo=o(" (VAN model)"),ago=l(),Ph=a("li"),lse=a("strong"),ngo=o("vit"),sgo=o(" \u2014 "),TI=a("a"),lgo=o("ViTFeatureExtractor"),igo=o(" (ViT model)"),dgo=l(),Bh=a("li"),ise=a("strong"),cgo=o("vit_mae"),fgo=o(" \u2014 "),MI=a("a"),mgo=o("ViTFeatureExtractor"),ggo=o(" (ViTMAE model)"),hgo=l(),Ih=a("li"),dse=a("strong"),pgo=o("wav2vec2"),_go=o(" \u2014 "),EI=a("a"),ugo=o("Wav2Vec2FeatureExtractor"),bgo=o(" (Wav2Vec2 model)"),vgo=l(),Nh=a("li"),cse=a("strong"),Fgo=o("wav2vec2-conformer"),Tgo=o(" \u2014 "),CI=a("a"),Mgo=o("Wav2Vec2FeatureExtractor"),Ego=o(" (Wav2Vec2-Conformer model)"),Cgo=l(),qh=a("li"),fse=a("strong"),wgo=o("yolos"),Ago=o(" \u2014 "),wI=a("a"),ygo=o("YolosFeatureExtractor"),Lgo=o(" (YOLOS model)"),xgo=l(),F(jh.$$.fragment),$go=l(),F(Dh.$$.fragment),kgo=l(),Gh=a("div"),F(oy.$$.fragment),Sgo=l(),mse=a("p"),Rgo=o("Register a new feature extractor for this class."),Qqe=l(),wi=a("h2"),Oh=a("a"),gse=a("span"),F(ry.$$.fragment),Pgo=l(),hse=a("span"),Bgo=o("AutoProcessor"),Hqe=l(),yo=a("div"),F(ty.$$.fragment),Igo=l(),ay=a("p"),Ngo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),AI=a("a"),qgo=o("AutoProcessor.from_pretrained()"),jgo=o(" class method."),Dgo=l(),ny=a("p"),Ggo=o("This class cannot be instantiated directly using "),pse=a("code"),Ogo=o("__init__()"),Vgo=o(" (throws an error)."),Xgo=l(),Ue=a("div"),F(sy.$$.fragment),zgo=l(),_se=a("p"),Wgo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Qgo=l(),Ai=a("p"),Hgo=o("The processor class to instantiate is selected based on the "),use=a("code"),Ugo=o("model_type"),Jgo=o(` property of the config object (either
passed as an argument or loaded from `),bse=a("code"),Ygo=o("pretrained_model_name_or_path"),Kgo=o(" if possible):"),Zgo=l(),he=a("ul"),Vh=a("li"),vse=a("strong"),eho=o("clip"),oho=o(" \u2014 "),yI=a("a"),rho=o("CLIPProcessor"),tho=o(" (CLIP model)"),aho=l(),Xh=a("li"),Fse=a("strong"),nho=o("flava"),sho=o(" \u2014 "),Tse=a("code"),lho=o("FLAVAProcessor"),iho=o(" (Flava model)"),dho=l(),zh=a("li"),Mse=a("strong"),cho=o("layoutlmv2"),fho=o(" \u2014 "),LI=a("a"),mho=o("LayoutLMv2Processor"),gho=o(" (LayoutLMv2 model)"),hho=l(),Wh=a("li"),Ese=a("strong"),pho=o("layoutlmv3"),_ho=o(" \u2014 "),xI=a("a"),uho=o("LayoutLMv3Processor"),bho=o(" (LayoutLMv3 model)"),vho=l(),Qh=a("li"),Cse=a("strong"),Fho=o("layoutxlm"),Tho=o(" \u2014 "),$I=a("a"),Mho=o("LayoutXLMProcessor"),Eho=o(" (LayoutXLM model)"),Cho=l(),Hh=a("li"),wse=a("strong"),who=o("sew"),Aho=o(" \u2014 "),kI=a("a"),yho=o("Wav2Vec2Processor"),Lho=o(" (SEW model)"),xho=l(),Uh=a("li"),Ase=a("strong"),$ho=o("sew-d"),kho=o(" \u2014 "),SI=a("a"),Sho=o("Wav2Vec2Processor"),Rho=o(" (SEW-D model)"),Pho=l(),Jh=a("li"),yse=a("strong"),Bho=o("speech_to_text"),Iho=o(" \u2014 "),RI=a("a"),Nho=o("Speech2TextProcessor"),qho=o(" (Speech2Text model)"),jho=l(),Yh=a("li"),Lse=a("strong"),Dho=o("speech_to_text_2"),Gho=o(" \u2014 "),PI=a("a"),Oho=o("Speech2Text2Processor"),Vho=o(" (Speech2Text2 model)"),Xho=l(),Kh=a("li"),xse=a("strong"),zho=o("trocr"),Who=o(" \u2014 "),BI=a("a"),Qho=o("TrOCRProcessor"),Hho=o(" (TrOCR model)"),Uho=l(),Zh=a("li"),$se=a("strong"),Jho=o("unispeech"),Yho=o(" \u2014 "),II=a("a"),Kho=o("Wav2Vec2Processor"),Zho=o(" (UniSpeech model)"),epo=l(),ep=a("li"),kse=a("strong"),opo=o("unispeech-sat"),rpo=o(" \u2014 "),NI=a("a"),tpo=o("Wav2Vec2Processor"),apo=o(" (UniSpeechSat model)"),npo=l(),op=a("li"),Sse=a("strong"),spo=o("vilt"),lpo=o(" \u2014 "),qI=a("a"),ipo=o("ViltProcessor"),dpo=o(" (ViLT model)"),cpo=l(),rp=a("li"),Rse=a("strong"),fpo=o("vision-text-dual-encoder"),mpo=o(" \u2014 "),jI=a("a"),gpo=o("VisionTextDualEncoderProcessor"),hpo=o(" (VisionTextDualEncoder model)"),ppo=l(),tp=a("li"),Pse=a("strong"),_po=o("wav2vec2"),upo=o(" \u2014 "),DI=a("a"),bpo=o("Wav2Vec2Processor"),vpo=o(" (Wav2Vec2 model)"),Fpo=l(),ap=a("li"),Bse=a("strong"),Tpo=o("wav2vec2-conformer"),Mpo=o(" \u2014 "),GI=a("a"),Epo=o("Wav2Vec2Processor"),Cpo=o(" (Wav2Vec2-Conformer model)"),wpo=l(),np=a("li"),Ise=a("strong"),Apo=o("wavlm"),ypo=o(" \u2014 "),OI=a("a"),Lpo=o("Wav2Vec2Processor"),xpo=o(" (WavLM model)"),$po=l(),F(sp.$$.fragment),kpo=l(),F(lp.$$.fragment),Spo=l(),ip=a("div"),F(ly.$$.fragment),Rpo=l(),Nse=a("p"),Ppo=o("Register a new processor for this class."),Uqe=l(),yi=a("h2"),dp=a("a"),qse=a("span"),F(iy.$$.fragment),Bpo=l(),jse=a("span"),Ipo=o("AutoModel"),Jqe=l(),Lo=a("div"),F(dy.$$.fragment),Npo=l(),Li=a("p"),qpo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),VI=a("a"),jpo=o("from_pretrained()"),Dpo=o(" class method or the "),XI=a("a"),Gpo=o("from_config()"),Opo=o(` class
method.`),Vpo=l(),cy=a("p"),Xpo=o("This class cannot be instantiated directly using "),Dse=a("code"),zpo=o("__init__()"),Wpo=o(" (throws an error)."),Qpo=l(),tt=a("div"),F(fy.$$.fragment),Hpo=l(),Gse=a("p"),Upo=o("Instantiates one of the base model classes of the library from a configuration."),Jpo=l(),xi=a("p"),Ypo=o(`Note:
Loading a model from its configuration file does `),Ose=a("strong"),Kpo=o("not"),Zpo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zI=a("a"),e_o=o("from_pretrained()"),o_o=o(" to load the model weights."),r_o=l(),F(cp.$$.fragment),t_o=l(),Je=a("div"),F(my.$$.fragment),a_o=l(),Vse=a("p"),n_o=o("Instantiate one of the base model classes of the library from a pretrained model."),s_o=l(),La=a("p"),l_o=o("The model class to instantiate is selected based on the "),Xse=a("code"),i_o=o("model_type"),d_o=o(` property of the config object (either
passed as an argument or loaded from `),zse=a("code"),c_o=o("pretrained_model_name_or_path"),f_o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wse=a("code"),m_o=o("pretrained_model_name_or_path"),g_o=o(":"),h_o=l(),x=a("ul"),fp=a("li"),Qse=a("strong"),p_o=o("albert"),__o=o(" \u2014 "),WI=a("a"),u_o=o("AlbertModel"),b_o=o(" (ALBERT model)"),v_o=l(),mp=a("li"),Hse=a("strong"),F_o=o("bart"),T_o=o(" \u2014 "),QI=a("a"),M_o=o("BartModel"),E_o=o(" (BART model)"),C_o=l(),gp=a("li"),Use=a("strong"),w_o=o("beit"),A_o=o(" \u2014 "),HI=a("a"),y_o=o("BeitModel"),L_o=o(" (BEiT model)"),x_o=l(),hp=a("li"),Jse=a("strong"),$_o=o("bert"),k_o=o(" \u2014 "),UI=a("a"),S_o=o("BertModel"),R_o=o(" (BERT model)"),P_o=l(),pp=a("li"),Yse=a("strong"),B_o=o("bert-generation"),I_o=o(" \u2014 "),JI=a("a"),N_o=o("BertGenerationEncoder"),q_o=o(" (Bert Generation model)"),j_o=l(),_p=a("li"),Kse=a("strong"),D_o=o("big_bird"),G_o=o(" \u2014 "),YI=a("a"),O_o=o("BigBirdModel"),V_o=o(" (BigBird model)"),X_o=l(),up=a("li"),Zse=a("strong"),z_o=o("bigbird_pegasus"),W_o=o(" \u2014 "),KI=a("a"),Q_o=o("BigBirdPegasusModel"),H_o=o(" (BigBirdPegasus model)"),U_o=l(),bp=a("li"),ele=a("strong"),J_o=o("blenderbot"),Y_o=o(" \u2014 "),ZI=a("a"),K_o=o("BlenderbotModel"),Z_o=o(" (Blenderbot model)"),euo=l(),vp=a("li"),ole=a("strong"),ouo=o("blenderbot-small"),ruo=o(" \u2014 "),eN=a("a"),tuo=o("BlenderbotSmallModel"),auo=o(" (BlenderbotSmall model)"),nuo=l(),Fp=a("li"),rle=a("strong"),suo=o("camembert"),luo=o(" \u2014 "),oN=a("a"),iuo=o("CamembertModel"),duo=o(" (CamemBERT model)"),cuo=l(),Tp=a("li"),tle=a("strong"),fuo=o("canine"),muo=o(" \u2014 "),rN=a("a"),guo=o("CanineModel"),huo=o(" (Canine model)"),puo=l(),Mp=a("li"),ale=a("strong"),_uo=o("clip"),uuo=o(" \u2014 "),tN=a("a"),buo=o("CLIPModel"),vuo=o(" (CLIP model)"),Fuo=l(),Ep=a("li"),nle=a("strong"),Tuo=o("convbert"),Muo=o(" \u2014 "),aN=a("a"),Euo=o("ConvBertModel"),Cuo=o(" (ConvBERT model)"),wuo=l(),Cp=a("li"),sle=a("strong"),Auo=o("convnext"),yuo=o(" \u2014 "),nN=a("a"),Luo=o("ConvNextModel"),xuo=o(" (ConvNext model)"),$uo=l(),wp=a("li"),lle=a("strong"),kuo=o("ctrl"),Suo=o(" \u2014 "),sN=a("a"),Ruo=o("CTRLModel"),Puo=o(" (CTRL model)"),Buo=l(),Ap=a("li"),ile=a("strong"),Iuo=o("cvt"),Nuo=o(" \u2014 "),lN=a("a"),quo=o("CvtModel"),juo=o(" (CvT model)"),Duo=l(),yp=a("li"),dle=a("strong"),Guo=o("data2vec-audio"),Ouo=o(" \u2014 "),iN=a("a"),Vuo=o("Data2VecAudioModel"),Xuo=o(" (Data2VecAudio model)"),zuo=l(),Lp=a("li"),cle=a("strong"),Wuo=o("data2vec-text"),Quo=o(" \u2014 "),dN=a("a"),Huo=o("Data2VecTextModel"),Uuo=o(" (Data2VecText model)"),Juo=l(),xp=a("li"),fle=a("strong"),Yuo=o("data2vec-vision"),Kuo=o(" \u2014 "),cN=a("a"),Zuo=o("Data2VecVisionModel"),e2o=o(" (Data2VecVision model)"),o2o=l(),$p=a("li"),mle=a("strong"),r2o=o("deberta"),t2o=o(" \u2014 "),fN=a("a"),a2o=o("DebertaModel"),n2o=o(" (DeBERTa model)"),s2o=l(),kp=a("li"),gle=a("strong"),l2o=o("deberta-v2"),i2o=o(" \u2014 "),mN=a("a"),d2o=o("DebertaV2Model"),c2o=o(" (DeBERTa-v2 model)"),f2o=l(),Sp=a("li"),hle=a("strong"),m2o=o("decision_transformer"),g2o=o(" \u2014 "),gN=a("a"),h2o=o("DecisionTransformerModel"),p2o=o(" (Decision Transformer model)"),_2o=l(),Rp=a("li"),ple=a("strong"),u2o=o("deit"),b2o=o(" \u2014 "),hN=a("a"),v2o=o("DeiTModel"),F2o=o(" (DeiT model)"),T2o=l(),Pp=a("li"),_le=a("strong"),M2o=o("detr"),E2o=o(" \u2014 "),pN=a("a"),C2o=o("DetrModel"),w2o=o(" (DETR model)"),A2o=l(),Bp=a("li"),ule=a("strong"),y2o=o("distilbert"),L2o=o(" \u2014 "),_N=a("a"),x2o=o("DistilBertModel"),$2o=o(" (DistilBERT model)"),k2o=l(),Ip=a("li"),ble=a("strong"),S2o=o("dpr"),R2o=o(" \u2014 "),uN=a("a"),P2o=o("DPRQuestionEncoder"),B2o=o(" (DPR model)"),I2o=l(),Np=a("li"),vle=a("strong"),N2o=o("dpt"),q2o=o(" \u2014 "),bN=a("a"),j2o=o("DPTModel"),D2o=o(" (DPT model)"),G2o=l(),qp=a("li"),Fle=a("strong"),O2o=o("electra"),V2o=o(" \u2014 "),vN=a("a"),X2o=o("ElectraModel"),z2o=o(" (ELECTRA model)"),W2o=l(),jp=a("li"),Tle=a("strong"),Q2o=o("flaubert"),H2o=o(" \u2014 "),FN=a("a"),U2o=o("FlaubertModel"),J2o=o(" (FlauBERT model)"),Y2o=l(),Dp=a("li"),Mle=a("strong"),K2o=o("flava"),Z2o=o(" \u2014 "),TN=a("a"),e1o=o("FlavaModel"),o1o=o(" (Flava model)"),r1o=l(),Gp=a("li"),Ele=a("strong"),t1o=o("fnet"),a1o=o(" \u2014 "),MN=a("a"),n1o=o("FNetModel"),s1o=o(" (FNet model)"),l1o=l(),Op=a("li"),Cle=a("strong"),i1o=o("fsmt"),d1o=o(" \u2014 "),EN=a("a"),c1o=o("FSMTModel"),f1o=o(" (FairSeq Machine-Translation model)"),m1o=l(),Bs=a("li"),wle=a("strong"),g1o=o("funnel"),h1o=o(" \u2014 "),CN=a("a"),p1o=o("FunnelModel"),_1o=o(" or "),wN=a("a"),u1o=o("FunnelBaseModel"),b1o=o(" (Funnel Transformer model)"),v1o=l(),Vp=a("li"),Ale=a("strong"),F1o=o("glpn"),T1o=o(" \u2014 "),AN=a("a"),M1o=o("GLPNModel"),E1o=o(" (GLPN model)"),C1o=l(),Xp=a("li"),yle=a("strong"),w1o=o("gpt2"),A1o=o(" \u2014 "),yN=a("a"),y1o=o("GPT2Model"),L1o=o(" (OpenAI GPT-2 model)"),x1o=l(),zp=a("li"),Lle=a("strong"),$1o=o("gpt_neo"),k1o=o(" \u2014 "),LN=a("a"),S1o=o("GPTNeoModel"),R1o=o(" (GPT Neo model)"),P1o=l(),Wp=a("li"),xle=a("strong"),B1o=o("gpt_neox"),I1o=o(" \u2014 "),xN=a("a"),N1o=o("GPTNeoXModel"),q1o=o(" (GPT NeoX model)"),j1o=l(),Qp=a("li"),$le=a("strong"),D1o=o("gptj"),G1o=o(" \u2014 "),$N=a("a"),O1o=o("GPTJModel"),V1o=o(" (GPT-J model)"),X1o=l(),Hp=a("li"),kle=a("strong"),z1o=o("hubert"),W1o=o(" \u2014 "),kN=a("a"),Q1o=o("HubertModel"),H1o=o(" (Hubert model)"),U1o=l(),Up=a("li"),Sle=a("strong"),J1o=o("ibert"),Y1o=o(" \u2014 "),SN=a("a"),K1o=o("IBertModel"),Z1o=o(" (I-BERT model)"),ebo=l(),Jp=a("li"),Rle=a("strong"),obo=o("imagegpt"),rbo=o(" \u2014 "),RN=a("a"),tbo=o("ImageGPTModel"),abo=o(" (ImageGPT model)"),nbo=l(),Yp=a("li"),Ple=a("strong"),sbo=o("layoutlm"),lbo=o(" \u2014 "),PN=a("a"),ibo=o("LayoutLMModel"),dbo=o(" (LayoutLM model)"),cbo=l(),Kp=a("li"),Ble=a("strong"),fbo=o("layoutlmv2"),mbo=o(" \u2014 "),BN=a("a"),gbo=o("LayoutLMv2Model"),hbo=o(" (LayoutLMv2 model)"),pbo=l(),Zp=a("li"),Ile=a("strong"),_bo=o("layoutlmv3"),ubo=o(" \u2014 "),IN=a("a"),bbo=o("LayoutLMv3Model"),vbo=o(" (LayoutLMv3 model)"),Fbo=l(),e_=a("li"),Nle=a("strong"),Tbo=o("led"),Mbo=o(" \u2014 "),NN=a("a"),Ebo=o("LEDModel"),Cbo=o(" (LED model)"),wbo=l(),o_=a("li"),qle=a("strong"),Abo=o("levit"),ybo=o(" \u2014 "),qN=a("a"),Lbo=o("LevitModel"),xbo=o(" (LeViT model)"),$bo=l(),r_=a("li"),jle=a("strong"),kbo=o("longformer"),Sbo=o(" \u2014 "),jN=a("a"),Rbo=o("LongformerModel"),Pbo=o(" (Longformer model)"),Bbo=l(),t_=a("li"),Dle=a("strong"),Ibo=o("luke"),Nbo=o(" \u2014 "),DN=a("a"),qbo=o("LukeModel"),jbo=o(" (LUKE model)"),Dbo=l(),a_=a("li"),Gle=a("strong"),Gbo=o("lxmert"),Obo=o(" \u2014 "),GN=a("a"),Vbo=o("LxmertModel"),Xbo=o(" (LXMERT model)"),zbo=l(),n_=a("li"),Ole=a("strong"),Wbo=o("m2m_100"),Qbo=o(" \u2014 "),ON=a("a"),Hbo=o("M2M100Model"),Ubo=o(" (M2M100 model)"),Jbo=l(),s_=a("li"),Vle=a("strong"),Ybo=o("marian"),Kbo=o(" \u2014 "),VN=a("a"),Zbo=o("MarianModel"),e4o=o(" (Marian model)"),o4o=l(),l_=a("li"),Xle=a("strong"),r4o=o("maskformer"),t4o=o(" \u2014 "),XN=a("a"),a4o=o("MaskFormerModel"),n4o=o(" (MaskFormer model)"),s4o=l(),i_=a("li"),zle=a("strong"),l4o=o("mbart"),i4o=o(" \u2014 "),zN=a("a"),d4o=o("MBartModel"),c4o=o(" (mBART model)"),f4o=l(),d_=a("li"),Wle=a("strong"),m4o=o("megatron-bert"),g4o=o(" \u2014 "),WN=a("a"),h4o=o("MegatronBertModel"),p4o=o(" (MegatronBert model)"),_4o=l(),c_=a("li"),Qle=a("strong"),u4o=o("mobilebert"),b4o=o(" \u2014 "),QN=a("a"),v4o=o("MobileBertModel"),F4o=o(" (MobileBERT model)"),T4o=l(),f_=a("li"),Hle=a("strong"),M4o=o("mpnet"),E4o=o(" \u2014 "),HN=a("a"),C4o=o("MPNetModel"),w4o=o(" (MPNet model)"),A4o=l(),m_=a("li"),Ule=a("strong"),y4o=o("mt5"),L4o=o(" \u2014 "),UN=a("a"),x4o=o("MT5Model"),$4o=o(" (mT5 model)"),k4o=l(),g_=a("li"),Jle=a("strong"),S4o=o("nystromformer"),R4o=o(" \u2014 "),JN=a("a"),P4o=o("NystromformerModel"),B4o=o(" (Nystromformer model)"),I4o=l(),h_=a("li"),Yle=a("strong"),N4o=o("openai-gpt"),q4o=o(" \u2014 "),YN=a("a"),j4o=o("OpenAIGPTModel"),D4o=o(" (OpenAI GPT model)"),G4o=l(),p_=a("li"),Kle=a("strong"),O4o=o("opt"),V4o=o(" \u2014 "),KN=a("a"),X4o=o("OPTModel"),z4o=o(" (OPT model)"),W4o=l(),__=a("li"),Zle=a("strong"),Q4o=o("pegasus"),H4o=o(" \u2014 "),ZN=a("a"),U4o=o("PegasusModel"),J4o=o(" (Pegasus model)"),Y4o=l(),u_=a("li"),eie=a("strong"),K4o=o("perceiver"),Z4o=o(" \u2014 "),eq=a("a"),evo=o("PerceiverModel"),ovo=o(" (Perceiver model)"),rvo=l(),b_=a("li"),oie=a("strong"),tvo=o("plbart"),avo=o(" \u2014 "),oq=a("a"),nvo=o("PLBartModel"),svo=o(" (PLBart model)"),lvo=l(),v_=a("li"),rie=a("strong"),ivo=o("poolformer"),dvo=o(" \u2014 "),rq=a("a"),cvo=o("PoolFormerModel"),fvo=o(" (PoolFormer model)"),mvo=l(),F_=a("li"),tie=a("strong"),gvo=o("prophetnet"),hvo=o(" \u2014 "),tq=a("a"),pvo=o("ProphetNetModel"),_vo=o(" (ProphetNet model)"),uvo=l(),T_=a("li"),aie=a("strong"),bvo=o("qdqbert"),vvo=o(" \u2014 "),aq=a("a"),Fvo=o("QDQBertModel"),Tvo=o(" (QDQBert model)"),Mvo=l(),M_=a("li"),nie=a("strong"),Evo=o("reformer"),Cvo=o(" \u2014 "),nq=a("a"),wvo=o("ReformerModel"),Avo=o(" (Reformer model)"),yvo=l(),E_=a("li"),sie=a("strong"),Lvo=o("regnet"),xvo=o(" \u2014 "),sq=a("a"),$vo=o("RegNetModel"),kvo=o(" (RegNet model)"),Svo=l(),C_=a("li"),lie=a("strong"),Rvo=o("rembert"),Pvo=o(" \u2014 "),lq=a("a"),Bvo=o("RemBertModel"),Ivo=o(" (RemBERT model)"),Nvo=l(),w_=a("li"),iie=a("strong"),qvo=o("resnet"),jvo=o(" \u2014 "),iq=a("a"),Dvo=o("ResNetModel"),Gvo=o(" (ResNet model)"),Ovo=l(),A_=a("li"),die=a("strong"),Vvo=o("retribert"),Xvo=o(" \u2014 "),dq=a("a"),zvo=o("RetriBertModel"),Wvo=o(" (RetriBERT model)"),Qvo=l(),y_=a("li"),cie=a("strong"),Hvo=o("roberta"),Uvo=o(" \u2014 "),cq=a("a"),Jvo=o("RobertaModel"),Yvo=o(" (RoBERTa model)"),Kvo=l(),L_=a("li"),fie=a("strong"),Zvo=o("roformer"),e5o=o(" \u2014 "),fq=a("a"),o5o=o("RoFormerModel"),r5o=o(" (RoFormer model)"),t5o=l(),x_=a("li"),mie=a("strong"),a5o=o("segformer"),n5o=o(" \u2014 "),mq=a("a"),s5o=o("SegformerModel"),l5o=o(" (SegFormer model)"),i5o=l(),$_=a("li"),gie=a("strong"),d5o=o("sew"),c5o=o(" \u2014 "),gq=a("a"),f5o=o("SEWModel"),m5o=o(" (SEW model)"),g5o=l(),k_=a("li"),hie=a("strong"),h5o=o("sew-d"),p5o=o(" \u2014 "),hq=a("a"),_5o=o("SEWDModel"),u5o=o(" (SEW-D model)"),b5o=l(),S_=a("li"),pie=a("strong"),v5o=o("speech_to_text"),F5o=o(" \u2014 "),pq=a("a"),T5o=o("Speech2TextModel"),M5o=o(" (Speech2Text model)"),E5o=l(),R_=a("li"),_ie=a("strong"),C5o=o("splinter"),w5o=o(" \u2014 "),_q=a("a"),A5o=o("SplinterModel"),y5o=o(" (Splinter model)"),L5o=l(),P_=a("li"),uie=a("strong"),x5o=o("squeezebert"),$5o=o(" \u2014 "),uq=a("a"),k5o=o("SqueezeBertModel"),S5o=o(" (SqueezeBERT model)"),R5o=l(),B_=a("li"),bie=a("strong"),P5o=o("swin"),B5o=o(" \u2014 "),bq=a("a"),I5o=o("SwinModel"),N5o=o(" (Swin model)"),q5o=l(),I_=a("li"),vie=a("strong"),j5o=o("t5"),D5o=o(" \u2014 "),vq=a("a"),G5o=o("T5Model"),O5o=o(" (T5 model)"),V5o=l(),N_=a("li"),Fie=a("strong"),X5o=o("tapas"),z5o=o(" \u2014 "),Fq=a("a"),W5o=o("TapasModel"),Q5o=o(" (TAPAS model)"),H5o=l(),q_=a("li"),Tie=a("strong"),U5o=o("trajectory_transformer"),J5o=o(" \u2014 "),Tq=a("a"),Y5o=o("TrajectoryTransformerModel"),K5o=o(" (Trajectory Transformer model)"),Z5o=l(),j_=a("li"),Mie=a("strong"),eFo=o("transfo-xl"),oFo=o(" \u2014 "),Mq=a("a"),rFo=o("TransfoXLModel"),tFo=o(" (Transformer-XL model)"),aFo=l(),D_=a("li"),Eie=a("strong"),nFo=o("unispeech"),sFo=o(" \u2014 "),Eq=a("a"),lFo=o("UniSpeechModel"),iFo=o(" (UniSpeech model)"),dFo=l(),G_=a("li"),Cie=a("strong"),cFo=o("unispeech-sat"),fFo=o(" \u2014 "),Cq=a("a"),mFo=o("UniSpeechSatModel"),gFo=o(" (UniSpeechSat model)"),hFo=l(),O_=a("li"),wie=a("strong"),pFo=o("van"),_Fo=o(" \u2014 "),wq=a("a"),uFo=o("VanModel"),bFo=o(" (VAN model)"),vFo=l(),V_=a("li"),Aie=a("strong"),FFo=o("vilt"),TFo=o(" \u2014 "),Aq=a("a"),MFo=o("ViltModel"),EFo=o(" (ViLT model)"),CFo=l(),X_=a("li"),yie=a("strong"),wFo=o("vision-text-dual-encoder"),AFo=o(" \u2014 "),yq=a("a"),yFo=o("VisionTextDualEncoderModel"),LFo=o(" (VisionTextDualEncoder model)"),xFo=l(),z_=a("li"),Lie=a("strong"),$Fo=o("visual_bert"),kFo=o(" \u2014 "),Lq=a("a"),SFo=o("VisualBertModel"),RFo=o(" (VisualBert model)"),PFo=l(),W_=a("li"),xie=a("strong"),BFo=o("vit"),IFo=o(" \u2014 "),xq=a("a"),NFo=o("ViTModel"),qFo=o(" (ViT model)"),jFo=l(),Q_=a("li"),$ie=a("strong"),DFo=o("vit_mae"),GFo=o(" \u2014 "),$q=a("a"),OFo=o("ViTMAEModel"),VFo=o(" (ViTMAE model)"),XFo=l(),H_=a("li"),kie=a("strong"),zFo=o("wav2vec2"),WFo=o(" \u2014 "),kq=a("a"),QFo=o("Wav2Vec2Model"),HFo=o(" (Wav2Vec2 model)"),UFo=l(),U_=a("li"),Sie=a("strong"),JFo=o("wav2vec2-conformer"),YFo=o(" \u2014 "),Sq=a("a"),KFo=o("Wav2Vec2ConformerModel"),ZFo=o(" (Wav2Vec2-Conformer model)"),eTo=l(),J_=a("li"),Rie=a("strong"),oTo=o("wavlm"),rTo=o(" \u2014 "),Rq=a("a"),tTo=o("WavLMModel"),aTo=o(" (WavLM model)"),nTo=l(),Y_=a("li"),Pie=a("strong"),sTo=o("xglm"),lTo=o(" \u2014 "),Pq=a("a"),iTo=o("XGLMModel"),dTo=o(" (XGLM model)"),cTo=l(),K_=a("li"),Bie=a("strong"),fTo=o("xlm"),mTo=o(" \u2014 "),Bq=a("a"),gTo=o("XLMModel"),hTo=o(" (XLM model)"),pTo=l(),Z_=a("li"),Iie=a("strong"),_To=o("xlm-prophetnet"),uTo=o(" \u2014 "),Iq=a("a"),bTo=o("XLMProphetNetModel"),vTo=o(" (XLMProphetNet model)"),FTo=l(),eu=a("li"),Nie=a("strong"),TTo=o("xlm-roberta"),MTo=o(" \u2014 "),Nq=a("a"),ETo=o("XLMRobertaModel"),CTo=o(" (XLM-RoBERTa model)"),wTo=l(),ou=a("li"),qie=a("strong"),ATo=o("xlm-roberta-xl"),yTo=o(" \u2014 "),qq=a("a"),LTo=o("XLMRobertaXLModel"),xTo=o(" (XLM-RoBERTa-XL model)"),$To=l(),ru=a("li"),jie=a("strong"),kTo=o("xlnet"),STo=o(" \u2014 "),jq=a("a"),RTo=o("XLNetModel"),PTo=o(" (XLNet model)"),BTo=l(),tu=a("li"),Die=a("strong"),ITo=o("yolos"),NTo=o(" \u2014 "),Dq=a("a"),qTo=o("YolosModel"),jTo=o(" (YOLOS model)"),DTo=l(),au=a("li"),Gie=a("strong"),GTo=o("yoso"),OTo=o(" \u2014 "),Gq=a("a"),VTo=o("YosoModel"),XTo=o(" (YOSO model)"),zTo=l(),nu=a("p"),WTo=o("The model is set in evaluation mode by default using "),Oie=a("code"),QTo=o("model.eval()"),HTo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vie=a("code"),UTo=o("model.train()"),JTo=l(),F(su.$$.fragment),Yqe=l(),$i=a("h2"),lu=a("a"),Xie=a("span"),F(gy.$$.fragment),YTo=l(),zie=a("span"),KTo=o("AutoModelForPreTraining"),Kqe=l(),xo=a("div"),F(hy.$$.fragment),ZTo=l(),ki=a("p"),e7o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Oq=a("a"),o7o=o("from_pretrained()"),r7o=o(" class method or the "),Vq=a("a"),t7o=o("from_config()"),a7o=o(` class
method.`),n7o=l(),py=a("p"),s7o=o("This class cannot be instantiated directly using "),Wie=a("code"),l7o=o("__init__()"),i7o=o(" (throws an error)."),d7o=l(),at=a("div"),F(_y.$$.fragment),c7o=l(),Qie=a("p"),f7o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),m7o=l(),Si=a("p"),g7o=o(`Note:
Loading a model from its configuration file does `),Hie=a("strong"),h7o=o("not"),p7o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xq=a("a"),_7o=o("from_pretrained()"),u7o=o(" to load the model weights."),b7o=l(),F(iu.$$.fragment),v7o=l(),Ye=a("div"),F(uy.$$.fragment),F7o=l(),Uie=a("p"),T7o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),M7o=l(),xa=a("p"),E7o=o("The model class to instantiate is selected based on the "),Jie=a("code"),C7o=o("model_type"),w7o=o(` property of the config object (either
passed as an argument or loaded from `),Yie=a("code"),A7o=o("pretrained_model_name_or_path"),y7o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kie=a("code"),L7o=o("pretrained_model_name_or_path"),x7o=o(":"),$7o=l(),G=a("ul"),du=a("li"),Zie=a("strong"),k7o=o("albert"),S7o=o(" \u2014 "),zq=a("a"),R7o=o("AlbertForPreTraining"),P7o=o(" (ALBERT model)"),B7o=l(),cu=a("li"),ede=a("strong"),I7o=o("bart"),N7o=o(" \u2014 "),Wq=a("a"),q7o=o("BartForConditionalGeneration"),j7o=o(" (BART model)"),D7o=l(),fu=a("li"),ode=a("strong"),G7o=o("bert"),O7o=o(" \u2014 "),Qq=a("a"),V7o=o("BertForPreTraining"),X7o=o(" (BERT model)"),z7o=l(),mu=a("li"),rde=a("strong"),W7o=o("big_bird"),Q7o=o(" \u2014 "),Hq=a("a"),H7o=o("BigBirdForPreTraining"),U7o=o(" (BigBird model)"),J7o=l(),gu=a("li"),tde=a("strong"),Y7o=o("camembert"),K7o=o(" \u2014 "),Uq=a("a"),Z7o=o("CamembertForMaskedLM"),eMo=o(" (CamemBERT model)"),oMo=l(),hu=a("li"),ade=a("strong"),rMo=o("ctrl"),tMo=o(" \u2014 "),Jq=a("a"),aMo=o("CTRLLMHeadModel"),nMo=o(" (CTRL model)"),sMo=l(),pu=a("li"),nde=a("strong"),lMo=o("data2vec-text"),iMo=o(" \u2014 "),Yq=a("a"),dMo=o("Data2VecTextForMaskedLM"),cMo=o(" (Data2VecText model)"),fMo=l(),_u=a("li"),sde=a("strong"),mMo=o("deberta"),gMo=o(" \u2014 "),Kq=a("a"),hMo=o("DebertaForMaskedLM"),pMo=o(" (DeBERTa model)"),_Mo=l(),uu=a("li"),lde=a("strong"),uMo=o("deberta-v2"),bMo=o(" \u2014 "),Zq=a("a"),vMo=o("DebertaV2ForMaskedLM"),FMo=o(" (DeBERTa-v2 model)"),TMo=l(),bu=a("li"),ide=a("strong"),MMo=o("distilbert"),EMo=o(" \u2014 "),ej=a("a"),CMo=o("DistilBertForMaskedLM"),wMo=o(" (DistilBERT model)"),AMo=l(),vu=a("li"),dde=a("strong"),yMo=o("electra"),LMo=o(" \u2014 "),oj=a("a"),xMo=o("ElectraForPreTraining"),$Mo=o(" (ELECTRA model)"),kMo=l(),Fu=a("li"),cde=a("strong"),SMo=o("flaubert"),RMo=o(" \u2014 "),rj=a("a"),PMo=o("FlaubertWithLMHeadModel"),BMo=o(" (FlauBERT model)"),IMo=l(),Tu=a("li"),fde=a("strong"),NMo=o("flava"),qMo=o(" \u2014 "),tj=a("a"),jMo=o("FlavaForPreTraining"),DMo=o(" (Flava model)"),GMo=l(),Mu=a("li"),mde=a("strong"),OMo=o("fnet"),VMo=o(" \u2014 "),aj=a("a"),XMo=o("FNetForPreTraining"),zMo=o(" (FNet model)"),WMo=l(),Eu=a("li"),gde=a("strong"),QMo=o("fsmt"),HMo=o(" \u2014 "),nj=a("a"),UMo=o("FSMTForConditionalGeneration"),JMo=o(" (FairSeq Machine-Translation model)"),YMo=l(),Cu=a("li"),hde=a("strong"),KMo=o("funnel"),ZMo=o(" \u2014 "),sj=a("a"),eEo=o("FunnelForPreTraining"),oEo=o(" (Funnel Transformer model)"),rEo=l(),wu=a("li"),pde=a("strong"),tEo=o("gpt2"),aEo=o(" \u2014 "),lj=a("a"),nEo=o("GPT2LMHeadModel"),sEo=o(" (OpenAI GPT-2 model)"),lEo=l(),Au=a("li"),_de=a("strong"),iEo=o("ibert"),dEo=o(" \u2014 "),ij=a("a"),cEo=o("IBertForMaskedLM"),fEo=o(" (I-BERT model)"),mEo=l(),yu=a("li"),ude=a("strong"),gEo=o("layoutlm"),hEo=o(" \u2014 "),dj=a("a"),pEo=o("LayoutLMForMaskedLM"),_Eo=o(" (LayoutLM model)"),uEo=l(),Lu=a("li"),bde=a("strong"),bEo=o("longformer"),vEo=o(" \u2014 "),cj=a("a"),FEo=o("LongformerForMaskedLM"),TEo=o(" (Longformer model)"),MEo=l(),xu=a("li"),vde=a("strong"),EEo=o("lxmert"),CEo=o(" \u2014 "),fj=a("a"),wEo=o("LxmertForPreTraining"),AEo=o(" (LXMERT model)"),yEo=l(),$u=a("li"),Fde=a("strong"),LEo=o("megatron-bert"),xEo=o(" \u2014 "),mj=a("a"),$Eo=o("MegatronBertForPreTraining"),kEo=o(" (MegatronBert model)"),SEo=l(),ku=a("li"),Tde=a("strong"),REo=o("mobilebert"),PEo=o(" \u2014 "),gj=a("a"),BEo=o("MobileBertForPreTraining"),IEo=o(" (MobileBERT model)"),NEo=l(),Su=a("li"),Mde=a("strong"),qEo=o("mpnet"),jEo=o(" \u2014 "),hj=a("a"),DEo=o("MPNetForMaskedLM"),GEo=o(" (MPNet model)"),OEo=l(),Ru=a("li"),Ede=a("strong"),VEo=o("openai-gpt"),XEo=o(" \u2014 "),pj=a("a"),zEo=o("OpenAIGPTLMHeadModel"),WEo=o(" (OpenAI GPT model)"),QEo=l(),Pu=a("li"),Cde=a("strong"),HEo=o("retribert"),UEo=o(" \u2014 "),_j=a("a"),JEo=o("RetriBertModel"),YEo=o(" (RetriBERT model)"),KEo=l(),Bu=a("li"),wde=a("strong"),ZEo=o("roberta"),eCo=o(" \u2014 "),uj=a("a"),oCo=o("RobertaForMaskedLM"),rCo=o(" (RoBERTa model)"),tCo=l(),Iu=a("li"),Ade=a("strong"),aCo=o("splinter"),nCo=o(" \u2014 "),bj=a("a"),sCo=o("SplinterForPreTraining"),lCo=o(" (Splinter model)"),iCo=l(),Nu=a("li"),yde=a("strong"),dCo=o("squeezebert"),cCo=o(" \u2014 "),vj=a("a"),fCo=o("SqueezeBertForMaskedLM"),mCo=o(" (SqueezeBERT model)"),gCo=l(),qu=a("li"),Lde=a("strong"),hCo=o("t5"),pCo=o(" \u2014 "),Fj=a("a"),_Co=o("T5ForConditionalGeneration"),uCo=o(" (T5 model)"),bCo=l(),ju=a("li"),xde=a("strong"),vCo=o("tapas"),FCo=o(" \u2014 "),Tj=a("a"),TCo=o("TapasForMaskedLM"),MCo=o(" (TAPAS model)"),ECo=l(),Du=a("li"),$de=a("strong"),CCo=o("transfo-xl"),wCo=o(" \u2014 "),Mj=a("a"),ACo=o("TransfoXLLMHeadModel"),yCo=o(" (Transformer-XL model)"),LCo=l(),Gu=a("li"),kde=a("strong"),xCo=o("unispeech"),$Co=o(" \u2014 "),Ej=a("a"),kCo=o("UniSpeechForPreTraining"),SCo=o(" (UniSpeech model)"),RCo=l(),Ou=a("li"),Sde=a("strong"),PCo=o("unispeech-sat"),BCo=o(" \u2014 "),Cj=a("a"),ICo=o("UniSpeechSatForPreTraining"),NCo=o(" (UniSpeechSat model)"),qCo=l(),Vu=a("li"),Rde=a("strong"),jCo=o("visual_bert"),DCo=o(" \u2014 "),wj=a("a"),GCo=o("VisualBertForPreTraining"),OCo=o(" (VisualBert model)"),VCo=l(),Xu=a("li"),Pde=a("strong"),XCo=o("vit_mae"),zCo=o(" \u2014 "),Aj=a("a"),WCo=o("ViTMAEForPreTraining"),QCo=o(" (ViTMAE model)"),HCo=l(),zu=a("li"),Bde=a("strong"),UCo=o("wav2vec2"),JCo=o(" \u2014 "),yj=a("a"),YCo=o("Wav2Vec2ForPreTraining"),KCo=o(" (Wav2Vec2 model)"),ZCo=l(),Wu=a("li"),Ide=a("strong"),e3o=o("wav2vec2-conformer"),o3o=o(" \u2014 "),Lj=a("a"),r3o=o("Wav2Vec2ConformerForPreTraining"),t3o=o(" (Wav2Vec2-Conformer model)"),a3o=l(),Qu=a("li"),Nde=a("strong"),n3o=o("xlm"),s3o=o(" \u2014 "),xj=a("a"),l3o=o("XLMWithLMHeadModel"),i3o=o(" (XLM model)"),d3o=l(),Hu=a("li"),qde=a("strong"),c3o=o("xlm-roberta"),f3o=o(" \u2014 "),$j=a("a"),m3o=o("XLMRobertaForMaskedLM"),g3o=o(" (XLM-RoBERTa model)"),h3o=l(),Uu=a("li"),jde=a("strong"),p3o=o("xlm-roberta-xl"),_3o=o(" \u2014 "),kj=a("a"),u3o=o("XLMRobertaXLForMaskedLM"),b3o=o(" (XLM-RoBERTa-XL model)"),v3o=l(),Ju=a("li"),Dde=a("strong"),F3o=o("xlnet"),T3o=o(" \u2014 "),Sj=a("a"),M3o=o("XLNetLMHeadModel"),E3o=o(" (XLNet model)"),C3o=l(),Yu=a("p"),w3o=o("The model is set in evaluation mode by default using "),Gde=a("code"),A3o=o("model.eval()"),y3o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ode=a("code"),L3o=o("model.train()"),x3o=l(),F(Ku.$$.fragment),Zqe=l(),Ri=a("h2"),Zu=a("a"),Vde=a("span"),F(by.$$.fragment),$3o=l(),Xde=a("span"),k3o=o("AutoModelForCausalLM"),eje=l(),$o=a("div"),F(vy.$$.fragment),S3o=l(),Pi=a("p"),R3o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Rj=a("a"),P3o=o("from_pretrained()"),B3o=o(" class method or the "),Pj=a("a"),I3o=o("from_config()"),N3o=o(` class
method.`),q3o=l(),Fy=a("p"),j3o=o("This class cannot be instantiated directly using "),zde=a("code"),D3o=o("__init__()"),G3o=o(" (throws an error)."),O3o=l(),nt=a("div"),F(Ty.$$.fragment),V3o=l(),Wde=a("p"),X3o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),z3o=l(),Bi=a("p"),W3o=o(`Note:
Loading a model from its configuration file does `),Qde=a("strong"),Q3o=o("not"),H3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bj=a("a"),U3o=o("from_pretrained()"),J3o=o(" to load the model weights."),Y3o=l(),F(e2.$$.fragment),K3o=l(),Ke=a("div"),F(My.$$.fragment),Z3o=l(),Hde=a("p"),e0o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),o0o=l(),$a=a("p"),r0o=o("The model class to instantiate is selected based on the "),Ude=a("code"),t0o=o("model_type"),a0o=o(` property of the config object (either
passed as an argument or loaded from `),Jde=a("code"),n0o=o("pretrained_model_name_or_path"),s0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yde=a("code"),l0o=o("pretrained_model_name_or_path"),i0o=o(":"),d0o=l(),z=a("ul"),o2=a("li"),Kde=a("strong"),c0o=o("bart"),f0o=o(" \u2014 "),Ij=a("a"),m0o=o("BartForCausalLM"),g0o=o(" (BART model)"),h0o=l(),r2=a("li"),Zde=a("strong"),p0o=o("bert"),_0o=o(" \u2014 "),Nj=a("a"),u0o=o("BertLMHeadModel"),b0o=o(" (BERT model)"),v0o=l(),t2=a("li"),ece=a("strong"),F0o=o("bert-generation"),T0o=o(" \u2014 "),qj=a("a"),M0o=o("BertGenerationDecoder"),E0o=o(" (Bert Generation model)"),C0o=l(),a2=a("li"),oce=a("strong"),w0o=o("big_bird"),A0o=o(" \u2014 "),jj=a("a"),y0o=o("BigBirdForCausalLM"),L0o=o(" (BigBird model)"),x0o=l(),n2=a("li"),rce=a("strong"),$0o=o("bigbird_pegasus"),k0o=o(" \u2014 "),Dj=a("a"),S0o=o("BigBirdPegasusForCausalLM"),R0o=o(" (BigBirdPegasus model)"),P0o=l(),s2=a("li"),tce=a("strong"),B0o=o("blenderbot"),I0o=o(" \u2014 "),Gj=a("a"),N0o=o("BlenderbotForCausalLM"),q0o=o(" (Blenderbot model)"),j0o=l(),l2=a("li"),ace=a("strong"),D0o=o("blenderbot-small"),G0o=o(" \u2014 "),Oj=a("a"),O0o=o("BlenderbotSmallForCausalLM"),V0o=o(" (BlenderbotSmall model)"),X0o=l(),i2=a("li"),nce=a("strong"),z0o=o("camembert"),W0o=o(" \u2014 "),Vj=a("a"),Q0o=o("CamembertForCausalLM"),H0o=o(" (CamemBERT model)"),U0o=l(),d2=a("li"),sce=a("strong"),J0o=o("ctrl"),Y0o=o(" \u2014 "),Xj=a("a"),K0o=o("CTRLLMHeadModel"),Z0o=o(" (CTRL model)"),ewo=l(),c2=a("li"),lce=a("strong"),owo=o("data2vec-text"),rwo=o(" \u2014 "),zj=a("a"),two=o("Data2VecTextForCausalLM"),awo=o(" (Data2VecText model)"),nwo=l(),f2=a("li"),ice=a("strong"),swo=o("electra"),lwo=o(" \u2014 "),Wj=a("a"),iwo=o("ElectraForCausalLM"),dwo=o(" (ELECTRA model)"),cwo=l(),m2=a("li"),dce=a("strong"),fwo=o("gpt2"),mwo=o(" \u2014 "),Qj=a("a"),gwo=o("GPT2LMHeadModel"),hwo=o(" (OpenAI GPT-2 model)"),pwo=l(),g2=a("li"),cce=a("strong"),_wo=o("gpt_neo"),uwo=o(" \u2014 "),Hj=a("a"),bwo=o("GPTNeoForCausalLM"),vwo=o(" (GPT Neo model)"),Fwo=l(),h2=a("li"),fce=a("strong"),Two=o("gpt_neox"),Mwo=o(" \u2014 "),Uj=a("a"),Ewo=o("GPTNeoXForCausalLM"),Cwo=o(" (GPT NeoX model)"),wwo=l(),p2=a("li"),mce=a("strong"),Awo=o("gptj"),ywo=o(" \u2014 "),Jj=a("a"),Lwo=o("GPTJForCausalLM"),xwo=o(" (GPT-J model)"),$wo=l(),_2=a("li"),gce=a("strong"),kwo=o("marian"),Swo=o(" \u2014 "),Yj=a("a"),Rwo=o("MarianForCausalLM"),Pwo=o(" (Marian model)"),Bwo=l(),u2=a("li"),hce=a("strong"),Iwo=o("mbart"),Nwo=o(" \u2014 "),Kj=a("a"),qwo=o("MBartForCausalLM"),jwo=o(" (mBART model)"),Dwo=l(),b2=a("li"),pce=a("strong"),Gwo=o("megatron-bert"),Owo=o(" \u2014 "),Zj=a("a"),Vwo=o("MegatronBertForCausalLM"),Xwo=o(" (MegatronBert model)"),zwo=l(),v2=a("li"),_ce=a("strong"),Wwo=o("openai-gpt"),Qwo=o(" \u2014 "),eD=a("a"),Hwo=o("OpenAIGPTLMHeadModel"),Uwo=o(" (OpenAI GPT model)"),Jwo=l(),F2=a("li"),uce=a("strong"),Ywo=o("opt"),Kwo=o(" \u2014 "),oD=a("a"),Zwo=o("OPTForCausalLM"),e6o=o(" (OPT model)"),o6o=l(),T2=a("li"),bce=a("strong"),r6o=o("pegasus"),t6o=o(" \u2014 "),rD=a("a"),a6o=o("PegasusForCausalLM"),n6o=o(" (Pegasus model)"),s6o=l(),M2=a("li"),vce=a("strong"),l6o=o("plbart"),i6o=o(" \u2014 "),tD=a("a"),d6o=o("PLBartForCausalLM"),c6o=o(" (PLBart model)"),f6o=l(),E2=a("li"),Fce=a("strong"),m6o=o("prophetnet"),g6o=o(" \u2014 "),aD=a("a"),h6o=o("ProphetNetForCausalLM"),p6o=o(" (ProphetNet model)"),_6o=l(),C2=a("li"),Tce=a("strong"),u6o=o("qdqbert"),b6o=o(" \u2014 "),nD=a("a"),v6o=o("QDQBertLMHeadModel"),F6o=o(" (QDQBert model)"),T6o=l(),w2=a("li"),Mce=a("strong"),M6o=o("reformer"),E6o=o(" \u2014 "),sD=a("a"),C6o=o("ReformerModelWithLMHead"),w6o=o(" (Reformer model)"),A6o=l(),A2=a("li"),Ece=a("strong"),y6o=o("rembert"),L6o=o(" \u2014 "),lD=a("a"),x6o=o("RemBertForCausalLM"),$6o=o(" (RemBERT model)"),k6o=l(),y2=a("li"),Cce=a("strong"),S6o=o("roberta"),R6o=o(" \u2014 "),iD=a("a"),P6o=o("RobertaForCausalLM"),B6o=o(" (RoBERTa model)"),I6o=l(),L2=a("li"),wce=a("strong"),N6o=o("roformer"),q6o=o(" \u2014 "),dD=a("a"),j6o=o("RoFormerForCausalLM"),D6o=o(" (RoFormer model)"),G6o=l(),x2=a("li"),Ace=a("strong"),O6o=o("speech_to_text_2"),V6o=o(" \u2014 "),cD=a("a"),X6o=o("Speech2Text2ForCausalLM"),z6o=o(" (Speech2Text2 model)"),W6o=l(),$2=a("li"),yce=a("strong"),Q6o=o("transfo-xl"),H6o=o(" \u2014 "),fD=a("a"),U6o=o("TransfoXLLMHeadModel"),J6o=o(" (Transformer-XL model)"),Y6o=l(),k2=a("li"),Lce=a("strong"),K6o=o("trocr"),Z6o=o(" \u2014 "),mD=a("a"),eAo=o("TrOCRForCausalLM"),oAo=o(" (TrOCR model)"),rAo=l(),S2=a("li"),xce=a("strong"),tAo=o("xglm"),aAo=o(" \u2014 "),gD=a("a"),nAo=o("XGLMForCausalLM"),sAo=o(" (XGLM model)"),lAo=l(),R2=a("li"),$ce=a("strong"),iAo=o("xlm"),dAo=o(" \u2014 "),hD=a("a"),cAo=o("XLMWithLMHeadModel"),fAo=o(" (XLM model)"),mAo=l(),P2=a("li"),kce=a("strong"),gAo=o("xlm-prophetnet"),hAo=o(" \u2014 "),pD=a("a"),pAo=o("XLMProphetNetForCausalLM"),_Ao=o(" (XLMProphetNet model)"),uAo=l(),B2=a("li"),Sce=a("strong"),bAo=o("xlm-roberta"),vAo=o(" \u2014 "),_D=a("a"),FAo=o("XLMRobertaForCausalLM"),TAo=o(" (XLM-RoBERTa model)"),MAo=l(),I2=a("li"),Rce=a("strong"),EAo=o("xlm-roberta-xl"),CAo=o(" \u2014 "),uD=a("a"),wAo=o("XLMRobertaXLForCausalLM"),AAo=o(" (XLM-RoBERTa-XL model)"),yAo=l(),N2=a("li"),Pce=a("strong"),LAo=o("xlnet"),xAo=o(" \u2014 "),bD=a("a"),$Ao=o("XLNetLMHeadModel"),kAo=o(" (XLNet model)"),SAo=l(),q2=a("p"),RAo=o("The model is set in evaluation mode by default using "),Bce=a("code"),PAo=o("model.eval()"),BAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ice=a("code"),IAo=o("model.train()"),NAo=l(),F(j2.$$.fragment),oje=l(),Ii=a("h2"),D2=a("a"),Nce=a("span"),F(Ey.$$.fragment),qAo=l(),qce=a("span"),jAo=o("AutoModelForMaskedLM"),rje=l(),ko=a("div"),F(Cy.$$.fragment),DAo=l(),Ni=a("p"),GAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),vD=a("a"),OAo=o("from_pretrained()"),VAo=o(" class method or the "),FD=a("a"),XAo=o("from_config()"),zAo=o(` class
method.`),WAo=l(),wy=a("p"),QAo=o("This class cannot be instantiated directly using "),jce=a("code"),HAo=o("__init__()"),UAo=o(" (throws an error)."),JAo=l(),st=a("div"),F(Ay.$$.fragment),YAo=l(),Dce=a("p"),KAo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ZAo=l(),qi=a("p"),eyo=o(`Note:
Loading a model from its configuration file does `),Gce=a("strong"),oyo=o("not"),ryo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TD=a("a"),tyo=o("from_pretrained()"),ayo=o(" to load the model weights."),nyo=l(),F(G2.$$.fragment),syo=l(),Ze=a("div"),F(yy.$$.fragment),lyo=l(),Oce=a("p"),iyo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),dyo=l(),ka=a("p"),cyo=o("The model class to instantiate is selected based on the "),Vce=a("code"),fyo=o("model_type"),myo=o(` property of the config object (either
passed as an argument or loaded from `),Xce=a("code"),gyo=o("pretrained_model_name_or_path"),hyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zce=a("code"),pyo=o("pretrained_model_name_or_path"),_yo=o(":"),uyo=l(),W=a("ul"),O2=a("li"),Wce=a("strong"),byo=o("albert"),vyo=o(" \u2014 "),MD=a("a"),Fyo=o("AlbertForMaskedLM"),Tyo=o(" (ALBERT model)"),Myo=l(),V2=a("li"),Qce=a("strong"),Eyo=o("bart"),Cyo=o(" \u2014 "),ED=a("a"),wyo=o("BartForConditionalGeneration"),Ayo=o(" (BART model)"),yyo=l(),X2=a("li"),Hce=a("strong"),Lyo=o("bert"),xyo=o(" \u2014 "),CD=a("a"),$yo=o("BertForMaskedLM"),kyo=o(" (BERT model)"),Syo=l(),z2=a("li"),Uce=a("strong"),Ryo=o("big_bird"),Pyo=o(" \u2014 "),wD=a("a"),Byo=o("BigBirdForMaskedLM"),Iyo=o(" (BigBird model)"),Nyo=l(),W2=a("li"),Jce=a("strong"),qyo=o("camembert"),jyo=o(" \u2014 "),AD=a("a"),Dyo=o("CamembertForMaskedLM"),Gyo=o(" (CamemBERT model)"),Oyo=l(),Q2=a("li"),Yce=a("strong"),Vyo=o("convbert"),Xyo=o(" \u2014 "),yD=a("a"),zyo=o("ConvBertForMaskedLM"),Wyo=o(" (ConvBERT model)"),Qyo=l(),H2=a("li"),Kce=a("strong"),Hyo=o("data2vec-text"),Uyo=o(" \u2014 "),LD=a("a"),Jyo=o("Data2VecTextForMaskedLM"),Yyo=o(" (Data2VecText model)"),Kyo=l(),U2=a("li"),Zce=a("strong"),Zyo=o("deberta"),eLo=o(" \u2014 "),xD=a("a"),oLo=o("DebertaForMaskedLM"),rLo=o(" (DeBERTa model)"),tLo=l(),J2=a("li"),efe=a("strong"),aLo=o("deberta-v2"),nLo=o(" \u2014 "),$D=a("a"),sLo=o("DebertaV2ForMaskedLM"),lLo=o(" (DeBERTa-v2 model)"),iLo=l(),Y2=a("li"),ofe=a("strong"),dLo=o("distilbert"),cLo=o(" \u2014 "),kD=a("a"),fLo=o("DistilBertForMaskedLM"),mLo=o(" (DistilBERT model)"),gLo=l(),K2=a("li"),rfe=a("strong"),hLo=o("electra"),pLo=o(" \u2014 "),SD=a("a"),_Lo=o("ElectraForMaskedLM"),uLo=o(" (ELECTRA model)"),bLo=l(),Z2=a("li"),tfe=a("strong"),vLo=o("flaubert"),FLo=o(" \u2014 "),RD=a("a"),TLo=o("FlaubertWithLMHeadModel"),MLo=o(" (FlauBERT model)"),ELo=l(),e1=a("li"),afe=a("strong"),CLo=o("fnet"),wLo=o(" \u2014 "),PD=a("a"),ALo=o("FNetForMaskedLM"),yLo=o(" (FNet model)"),LLo=l(),o1=a("li"),nfe=a("strong"),xLo=o("funnel"),$Lo=o(" \u2014 "),BD=a("a"),kLo=o("FunnelForMaskedLM"),SLo=o(" (Funnel Transformer model)"),RLo=l(),r1=a("li"),sfe=a("strong"),PLo=o("ibert"),BLo=o(" \u2014 "),ID=a("a"),ILo=o("IBertForMaskedLM"),NLo=o(" (I-BERT model)"),qLo=l(),t1=a("li"),lfe=a("strong"),jLo=o("layoutlm"),DLo=o(" \u2014 "),ND=a("a"),GLo=o("LayoutLMForMaskedLM"),OLo=o(" (LayoutLM model)"),VLo=l(),a1=a("li"),ife=a("strong"),XLo=o("longformer"),zLo=o(" \u2014 "),qD=a("a"),WLo=o("LongformerForMaskedLM"),QLo=o(" (Longformer model)"),HLo=l(),n1=a("li"),dfe=a("strong"),ULo=o("luke"),JLo=o(" \u2014 "),jD=a("a"),YLo=o("LukeForMaskedLM"),KLo=o(" (LUKE model)"),ZLo=l(),s1=a("li"),cfe=a("strong"),e8o=o("mbart"),o8o=o(" \u2014 "),DD=a("a"),r8o=o("MBartForConditionalGeneration"),t8o=o(" (mBART model)"),a8o=l(),l1=a("li"),ffe=a("strong"),n8o=o("megatron-bert"),s8o=o(" \u2014 "),GD=a("a"),l8o=o("MegatronBertForMaskedLM"),i8o=o(" (MegatronBert model)"),d8o=l(),i1=a("li"),mfe=a("strong"),c8o=o("mobilebert"),f8o=o(" \u2014 "),OD=a("a"),m8o=o("MobileBertForMaskedLM"),g8o=o(" (MobileBERT model)"),h8o=l(),d1=a("li"),gfe=a("strong"),p8o=o("mpnet"),_8o=o(" \u2014 "),VD=a("a"),u8o=o("MPNetForMaskedLM"),b8o=o(" (MPNet model)"),v8o=l(),c1=a("li"),hfe=a("strong"),F8o=o("nystromformer"),T8o=o(" \u2014 "),XD=a("a"),M8o=o("NystromformerForMaskedLM"),E8o=o(" (Nystromformer model)"),C8o=l(),f1=a("li"),pfe=a("strong"),w8o=o("perceiver"),A8o=o(" \u2014 "),zD=a("a"),y8o=o("PerceiverForMaskedLM"),L8o=o(" (Perceiver model)"),x8o=l(),m1=a("li"),_fe=a("strong"),$8o=o("qdqbert"),k8o=o(" \u2014 "),WD=a("a"),S8o=o("QDQBertForMaskedLM"),R8o=o(" (QDQBert model)"),P8o=l(),g1=a("li"),ufe=a("strong"),B8o=o("reformer"),I8o=o(" \u2014 "),QD=a("a"),N8o=o("ReformerForMaskedLM"),q8o=o(" (Reformer model)"),j8o=l(),h1=a("li"),bfe=a("strong"),D8o=o("rembert"),G8o=o(" \u2014 "),HD=a("a"),O8o=o("RemBertForMaskedLM"),V8o=o(" (RemBERT model)"),X8o=l(),p1=a("li"),vfe=a("strong"),z8o=o("roberta"),W8o=o(" \u2014 "),UD=a("a"),Q8o=o("RobertaForMaskedLM"),H8o=o(" (RoBERTa model)"),U8o=l(),_1=a("li"),Ffe=a("strong"),J8o=o("roformer"),Y8o=o(" \u2014 "),JD=a("a"),K8o=o("RoFormerForMaskedLM"),Z8o=o(" (RoFormer model)"),e9o=l(),u1=a("li"),Tfe=a("strong"),o9o=o("squeezebert"),r9o=o(" \u2014 "),YD=a("a"),t9o=o("SqueezeBertForMaskedLM"),a9o=o(" (SqueezeBERT model)"),n9o=l(),b1=a("li"),Mfe=a("strong"),s9o=o("tapas"),l9o=o(" \u2014 "),KD=a("a"),i9o=o("TapasForMaskedLM"),d9o=o(" (TAPAS model)"),c9o=l(),v1=a("li"),Efe=a("strong"),f9o=o("wav2vec2"),m9o=o(" \u2014 "),Cfe=a("code"),g9o=o("Wav2Vec2ForMaskedLM"),h9o=o(" (Wav2Vec2 model)"),p9o=l(),F1=a("li"),wfe=a("strong"),_9o=o("xlm"),u9o=o(" \u2014 "),ZD=a("a"),b9o=o("XLMWithLMHeadModel"),v9o=o(" (XLM model)"),F9o=l(),T1=a("li"),Afe=a("strong"),T9o=o("xlm-roberta"),M9o=o(" \u2014 "),eG=a("a"),E9o=o("XLMRobertaForMaskedLM"),C9o=o(" (XLM-RoBERTa model)"),w9o=l(),M1=a("li"),yfe=a("strong"),A9o=o("xlm-roberta-xl"),y9o=o(" \u2014 "),oG=a("a"),L9o=o("XLMRobertaXLForMaskedLM"),x9o=o(" (XLM-RoBERTa-XL model)"),$9o=l(),E1=a("li"),Lfe=a("strong"),k9o=o("yoso"),S9o=o(" \u2014 "),rG=a("a"),R9o=o("YosoForMaskedLM"),P9o=o(" (YOSO model)"),B9o=l(),C1=a("p"),I9o=o("The model is set in evaluation mode by default using "),xfe=a("code"),N9o=o("model.eval()"),q9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$fe=a("code"),j9o=o("model.train()"),D9o=l(),F(w1.$$.fragment),tje=l(),ji=a("h2"),A1=a("a"),kfe=a("span"),F(Ly.$$.fragment),G9o=l(),Sfe=a("span"),O9o=o("AutoModelForSeq2SeqLM"),aje=l(),So=a("div"),F(xy.$$.fragment),V9o=l(),Di=a("p"),X9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tG=a("a"),z9o=o("from_pretrained()"),W9o=o(" class method or the "),aG=a("a"),Q9o=o("from_config()"),H9o=o(` class
method.`),U9o=l(),$y=a("p"),J9o=o("This class cannot be instantiated directly using "),Rfe=a("code"),Y9o=o("__init__()"),K9o=o(" (throws an error)."),Z9o=l(),lt=a("div"),F(ky.$$.fragment),exo=l(),Pfe=a("p"),oxo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),rxo=l(),Gi=a("p"),txo=o(`Note:
Loading a model from its configuration file does `),Bfe=a("strong"),axo=o("not"),nxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nG=a("a"),sxo=o("from_pretrained()"),lxo=o(" to load the model weights."),ixo=l(),F(y1.$$.fragment),dxo=l(),eo=a("div"),F(Sy.$$.fragment),cxo=l(),Ife=a("p"),fxo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),mxo=l(),Sa=a("p"),gxo=o("The model class to instantiate is selected based on the "),Nfe=a("code"),hxo=o("model_type"),pxo=o(` property of the config object (either
passed as an argument or loaded from `),qfe=a("code"),_xo=o("pretrained_model_name_or_path"),uxo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jfe=a("code"),bxo=o("pretrained_model_name_or_path"),vxo=o(":"),Fxo=l(),_e=a("ul"),L1=a("li"),Dfe=a("strong"),Txo=o("bart"),Mxo=o(" \u2014 "),sG=a("a"),Exo=o("BartForConditionalGeneration"),Cxo=o(" (BART model)"),wxo=l(),x1=a("li"),Gfe=a("strong"),Axo=o("bigbird_pegasus"),yxo=o(" \u2014 "),lG=a("a"),Lxo=o("BigBirdPegasusForConditionalGeneration"),xxo=o(" (BigBirdPegasus model)"),$xo=l(),$1=a("li"),Ofe=a("strong"),kxo=o("blenderbot"),Sxo=o(" \u2014 "),iG=a("a"),Rxo=o("BlenderbotForConditionalGeneration"),Pxo=o(" (Blenderbot model)"),Bxo=l(),k1=a("li"),Vfe=a("strong"),Ixo=o("blenderbot-small"),Nxo=o(" \u2014 "),dG=a("a"),qxo=o("BlenderbotSmallForConditionalGeneration"),jxo=o(" (BlenderbotSmall model)"),Dxo=l(),S1=a("li"),Xfe=a("strong"),Gxo=o("encoder-decoder"),Oxo=o(" \u2014 "),cG=a("a"),Vxo=o("EncoderDecoderModel"),Xxo=o(" (Encoder decoder model)"),zxo=l(),R1=a("li"),zfe=a("strong"),Wxo=o("fsmt"),Qxo=o(" \u2014 "),fG=a("a"),Hxo=o("FSMTForConditionalGeneration"),Uxo=o(" (FairSeq Machine-Translation model)"),Jxo=l(),P1=a("li"),Wfe=a("strong"),Yxo=o("led"),Kxo=o(" \u2014 "),mG=a("a"),Zxo=o("LEDForConditionalGeneration"),e$o=o(" (LED model)"),o$o=l(),B1=a("li"),Qfe=a("strong"),r$o=o("m2m_100"),t$o=o(" \u2014 "),gG=a("a"),a$o=o("M2M100ForConditionalGeneration"),n$o=o(" (M2M100 model)"),s$o=l(),I1=a("li"),Hfe=a("strong"),l$o=o("marian"),i$o=o(" \u2014 "),hG=a("a"),d$o=o("MarianMTModel"),c$o=o(" (Marian model)"),f$o=l(),N1=a("li"),Ufe=a("strong"),m$o=o("mbart"),g$o=o(" \u2014 "),pG=a("a"),h$o=o("MBartForConditionalGeneration"),p$o=o(" (mBART model)"),_$o=l(),q1=a("li"),Jfe=a("strong"),u$o=o("mt5"),b$o=o(" \u2014 "),_G=a("a"),v$o=o("MT5ForConditionalGeneration"),F$o=o(" (mT5 model)"),T$o=l(),j1=a("li"),Yfe=a("strong"),M$o=o("pegasus"),E$o=o(" \u2014 "),uG=a("a"),C$o=o("PegasusForConditionalGeneration"),w$o=o(" (Pegasus model)"),A$o=l(),D1=a("li"),Kfe=a("strong"),y$o=o("plbart"),L$o=o(" \u2014 "),bG=a("a"),x$o=o("PLBartForConditionalGeneration"),$$o=o(" (PLBart model)"),k$o=l(),G1=a("li"),Zfe=a("strong"),S$o=o("prophetnet"),R$o=o(" \u2014 "),vG=a("a"),P$o=o("ProphetNetForConditionalGeneration"),B$o=o(" (ProphetNet model)"),I$o=l(),O1=a("li"),eme=a("strong"),N$o=o("t5"),q$o=o(" \u2014 "),FG=a("a"),j$o=o("T5ForConditionalGeneration"),D$o=o(" (T5 model)"),G$o=l(),V1=a("li"),ome=a("strong"),O$o=o("xlm-prophetnet"),V$o=o(" \u2014 "),TG=a("a"),X$o=o("XLMProphetNetForConditionalGeneration"),z$o=o(" (XLMProphetNet model)"),W$o=l(),X1=a("p"),Q$o=o("The model is set in evaluation mode by default using "),rme=a("code"),H$o=o("model.eval()"),U$o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tme=a("code"),J$o=o("model.train()"),Y$o=l(),F(z1.$$.fragment),nje=l(),Oi=a("h2"),W1=a("a"),ame=a("span"),F(Ry.$$.fragment),K$o=l(),nme=a("span"),Z$o=o("AutoModelForSequenceClassification"),sje=l(),Ro=a("div"),F(Py.$$.fragment),eko=l(),Vi=a("p"),oko=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),MG=a("a"),rko=o("from_pretrained()"),tko=o(" class method or the "),EG=a("a"),ako=o("from_config()"),nko=o(` class
method.`),sko=l(),By=a("p"),lko=o("This class cannot be instantiated directly using "),sme=a("code"),iko=o("__init__()"),dko=o(" (throws an error)."),cko=l(),it=a("div"),F(Iy.$$.fragment),fko=l(),lme=a("p"),mko=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),gko=l(),Xi=a("p"),hko=o(`Note:
Loading a model from its configuration file does `),ime=a("strong"),pko=o("not"),_ko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CG=a("a"),uko=o("from_pretrained()"),bko=o(" to load the model weights."),vko=l(),F(Q1.$$.fragment),Fko=l(),oo=a("div"),F(Ny.$$.fragment),Tko=l(),dme=a("p"),Mko=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Eko=l(),Ra=a("p"),Cko=o("The model class to instantiate is selected based on the "),cme=a("code"),wko=o("model_type"),Ako=o(` property of the config object (either
passed as an argument or loaded from `),fme=a("code"),yko=o("pretrained_model_name_or_path"),Lko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mme=a("code"),xko=o("pretrained_model_name_or_path"),$ko=o(":"),kko=l(),N=a("ul"),H1=a("li"),gme=a("strong"),Sko=o("albert"),Rko=o(" \u2014 "),wG=a("a"),Pko=o("AlbertForSequenceClassification"),Bko=o(" (ALBERT model)"),Iko=l(),U1=a("li"),hme=a("strong"),Nko=o("bart"),qko=o(" \u2014 "),AG=a("a"),jko=o("BartForSequenceClassification"),Dko=o(" (BART model)"),Gko=l(),J1=a("li"),pme=a("strong"),Oko=o("bert"),Vko=o(" \u2014 "),yG=a("a"),Xko=o("BertForSequenceClassification"),zko=o(" (BERT model)"),Wko=l(),Y1=a("li"),_me=a("strong"),Qko=o("big_bird"),Hko=o(" \u2014 "),LG=a("a"),Uko=o("BigBirdForSequenceClassification"),Jko=o(" (BigBird model)"),Yko=l(),K1=a("li"),ume=a("strong"),Kko=o("bigbird_pegasus"),Zko=o(" \u2014 "),xG=a("a"),eSo=o("BigBirdPegasusForSequenceClassification"),oSo=o(" (BigBirdPegasus model)"),rSo=l(),Z1=a("li"),bme=a("strong"),tSo=o("camembert"),aSo=o(" \u2014 "),$G=a("a"),nSo=o("CamembertForSequenceClassification"),sSo=o(" (CamemBERT model)"),lSo=l(),eb=a("li"),vme=a("strong"),iSo=o("canine"),dSo=o(" \u2014 "),kG=a("a"),cSo=o("CanineForSequenceClassification"),fSo=o(" (Canine model)"),mSo=l(),ob=a("li"),Fme=a("strong"),gSo=o("convbert"),hSo=o(" \u2014 "),SG=a("a"),pSo=o("ConvBertForSequenceClassification"),_So=o(" (ConvBERT model)"),uSo=l(),rb=a("li"),Tme=a("strong"),bSo=o("ctrl"),vSo=o(" \u2014 "),RG=a("a"),FSo=o("CTRLForSequenceClassification"),TSo=o(" (CTRL model)"),MSo=l(),tb=a("li"),Mme=a("strong"),ESo=o("data2vec-text"),CSo=o(" \u2014 "),PG=a("a"),wSo=o("Data2VecTextForSequenceClassification"),ASo=o(" (Data2VecText model)"),ySo=l(),ab=a("li"),Eme=a("strong"),LSo=o("deberta"),xSo=o(" \u2014 "),BG=a("a"),$So=o("DebertaForSequenceClassification"),kSo=o(" (DeBERTa model)"),SSo=l(),nb=a("li"),Cme=a("strong"),RSo=o("deberta-v2"),PSo=o(" \u2014 "),IG=a("a"),BSo=o("DebertaV2ForSequenceClassification"),ISo=o(" (DeBERTa-v2 model)"),NSo=l(),sb=a("li"),wme=a("strong"),qSo=o("distilbert"),jSo=o(" \u2014 "),NG=a("a"),DSo=o("DistilBertForSequenceClassification"),GSo=o(" (DistilBERT model)"),OSo=l(),lb=a("li"),Ame=a("strong"),VSo=o("electra"),XSo=o(" \u2014 "),qG=a("a"),zSo=o("ElectraForSequenceClassification"),WSo=o(" (ELECTRA model)"),QSo=l(),ib=a("li"),yme=a("strong"),HSo=o("flaubert"),USo=o(" \u2014 "),jG=a("a"),JSo=o("FlaubertForSequenceClassification"),YSo=o(" (FlauBERT model)"),KSo=l(),db=a("li"),Lme=a("strong"),ZSo=o("fnet"),eRo=o(" \u2014 "),DG=a("a"),oRo=o("FNetForSequenceClassification"),rRo=o(" (FNet model)"),tRo=l(),cb=a("li"),xme=a("strong"),aRo=o("funnel"),nRo=o(" \u2014 "),GG=a("a"),sRo=o("FunnelForSequenceClassification"),lRo=o(" (Funnel Transformer model)"),iRo=l(),fb=a("li"),$me=a("strong"),dRo=o("gpt2"),cRo=o(" \u2014 "),OG=a("a"),fRo=o("GPT2ForSequenceClassification"),mRo=o(" (OpenAI GPT-2 model)"),gRo=l(),mb=a("li"),kme=a("strong"),hRo=o("gpt_neo"),pRo=o(" \u2014 "),VG=a("a"),_Ro=o("GPTNeoForSequenceClassification"),uRo=o(" (GPT Neo model)"),bRo=l(),gb=a("li"),Sme=a("strong"),vRo=o("gptj"),FRo=o(" \u2014 "),XG=a("a"),TRo=o("GPTJForSequenceClassification"),MRo=o(" (GPT-J model)"),ERo=l(),hb=a("li"),Rme=a("strong"),CRo=o("ibert"),wRo=o(" \u2014 "),zG=a("a"),ARo=o("IBertForSequenceClassification"),yRo=o(" (I-BERT model)"),LRo=l(),pb=a("li"),Pme=a("strong"),xRo=o("layoutlm"),$Ro=o(" \u2014 "),WG=a("a"),kRo=o("LayoutLMForSequenceClassification"),SRo=o(" (LayoutLM model)"),RRo=l(),_b=a("li"),Bme=a("strong"),PRo=o("layoutlmv2"),BRo=o(" \u2014 "),QG=a("a"),IRo=o("LayoutLMv2ForSequenceClassification"),NRo=o(" (LayoutLMv2 model)"),qRo=l(),ub=a("li"),Ime=a("strong"),jRo=o("layoutlmv3"),DRo=o(" \u2014 "),HG=a("a"),GRo=o("LayoutLMv3ForSequenceClassification"),ORo=o(" (LayoutLMv3 model)"),VRo=l(),bb=a("li"),Nme=a("strong"),XRo=o("led"),zRo=o(" \u2014 "),UG=a("a"),WRo=o("LEDForSequenceClassification"),QRo=o(" (LED model)"),HRo=l(),vb=a("li"),qme=a("strong"),URo=o("longformer"),JRo=o(" \u2014 "),JG=a("a"),YRo=o("LongformerForSequenceClassification"),KRo=o(" (Longformer model)"),ZRo=l(),Fb=a("li"),jme=a("strong"),ePo=o("mbart"),oPo=o(" \u2014 "),YG=a("a"),rPo=o("MBartForSequenceClassification"),tPo=o(" (mBART model)"),aPo=l(),Tb=a("li"),Dme=a("strong"),nPo=o("megatron-bert"),sPo=o(" \u2014 "),KG=a("a"),lPo=o("MegatronBertForSequenceClassification"),iPo=o(" (MegatronBert model)"),dPo=l(),Mb=a("li"),Gme=a("strong"),cPo=o("mobilebert"),fPo=o(" \u2014 "),ZG=a("a"),mPo=o("MobileBertForSequenceClassification"),gPo=o(" (MobileBERT model)"),hPo=l(),Eb=a("li"),Ome=a("strong"),pPo=o("mpnet"),_Po=o(" \u2014 "),eO=a("a"),uPo=o("MPNetForSequenceClassification"),bPo=o(" (MPNet model)"),vPo=l(),Cb=a("li"),Vme=a("strong"),FPo=o("nystromformer"),TPo=o(" \u2014 "),oO=a("a"),MPo=o("NystromformerForSequenceClassification"),EPo=o(" (Nystromformer model)"),CPo=l(),wb=a("li"),Xme=a("strong"),wPo=o("openai-gpt"),APo=o(" \u2014 "),rO=a("a"),yPo=o("OpenAIGPTForSequenceClassification"),LPo=o(" (OpenAI GPT model)"),xPo=l(),Ab=a("li"),zme=a("strong"),$Po=o("perceiver"),kPo=o(" \u2014 "),tO=a("a"),SPo=o("PerceiverForSequenceClassification"),RPo=o(" (Perceiver model)"),PPo=l(),yb=a("li"),Wme=a("strong"),BPo=o("plbart"),IPo=o(" \u2014 "),aO=a("a"),NPo=o("PLBartForSequenceClassification"),qPo=o(" (PLBart model)"),jPo=l(),Lb=a("li"),Qme=a("strong"),DPo=o("qdqbert"),GPo=o(" \u2014 "),nO=a("a"),OPo=o("QDQBertForSequenceClassification"),VPo=o(" (QDQBert model)"),XPo=l(),xb=a("li"),Hme=a("strong"),zPo=o("reformer"),WPo=o(" \u2014 "),sO=a("a"),QPo=o("ReformerForSequenceClassification"),HPo=o(" (Reformer model)"),UPo=l(),$b=a("li"),Ume=a("strong"),JPo=o("rembert"),YPo=o(" \u2014 "),lO=a("a"),KPo=o("RemBertForSequenceClassification"),ZPo=o(" (RemBERT model)"),eBo=l(),kb=a("li"),Jme=a("strong"),oBo=o("roberta"),rBo=o(" \u2014 "),iO=a("a"),tBo=o("RobertaForSequenceClassification"),aBo=o(" (RoBERTa model)"),nBo=l(),Sb=a("li"),Yme=a("strong"),sBo=o("roformer"),lBo=o(" \u2014 "),dO=a("a"),iBo=o("RoFormerForSequenceClassification"),dBo=o(" (RoFormer model)"),cBo=l(),Rb=a("li"),Kme=a("strong"),fBo=o("squeezebert"),mBo=o(" \u2014 "),cO=a("a"),gBo=o("SqueezeBertForSequenceClassification"),hBo=o(" (SqueezeBERT model)"),pBo=l(),Pb=a("li"),Zme=a("strong"),_Bo=o("tapas"),uBo=o(" \u2014 "),fO=a("a"),bBo=o("TapasForSequenceClassification"),vBo=o(" (TAPAS model)"),FBo=l(),Bb=a("li"),ege=a("strong"),TBo=o("transfo-xl"),MBo=o(" \u2014 "),mO=a("a"),EBo=o("TransfoXLForSequenceClassification"),CBo=o(" (Transformer-XL model)"),wBo=l(),Ib=a("li"),oge=a("strong"),ABo=o("xlm"),yBo=o(" \u2014 "),gO=a("a"),LBo=o("XLMForSequenceClassification"),xBo=o(" (XLM model)"),$Bo=l(),Nb=a("li"),rge=a("strong"),kBo=o("xlm-roberta"),SBo=o(" \u2014 "),hO=a("a"),RBo=o("XLMRobertaForSequenceClassification"),PBo=o(" (XLM-RoBERTa model)"),BBo=l(),qb=a("li"),tge=a("strong"),IBo=o("xlm-roberta-xl"),NBo=o(" \u2014 "),pO=a("a"),qBo=o("XLMRobertaXLForSequenceClassification"),jBo=o(" (XLM-RoBERTa-XL model)"),DBo=l(),jb=a("li"),age=a("strong"),GBo=o("xlnet"),OBo=o(" \u2014 "),_O=a("a"),VBo=o("XLNetForSequenceClassification"),XBo=o(" (XLNet model)"),zBo=l(),Db=a("li"),nge=a("strong"),WBo=o("yoso"),QBo=o(" \u2014 "),uO=a("a"),HBo=o("YosoForSequenceClassification"),UBo=o(" (YOSO model)"),JBo=l(),Gb=a("p"),YBo=o("The model is set in evaluation mode by default using "),sge=a("code"),KBo=o("model.eval()"),ZBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lge=a("code"),eIo=o("model.train()"),oIo=l(),F(Ob.$$.fragment),lje=l(),zi=a("h2"),Vb=a("a"),ige=a("span"),F(qy.$$.fragment),rIo=l(),dge=a("span"),tIo=o("AutoModelForMultipleChoice"),ije=l(),Po=a("div"),F(jy.$$.fragment),aIo=l(),Wi=a("p"),nIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),bO=a("a"),sIo=o("from_pretrained()"),lIo=o(" class method or the "),vO=a("a"),iIo=o("from_config()"),dIo=o(` class
method.`),cIo=l(),Dy=a("p"),fIo=o("This class cannot be instantiated directly using "),cge=a("code"),mIo=o("__init__()"),gIo=o(" (throws an error)."),hIo=l(),dt=a("div"),F(Gy.$$.fragment),pIo=l(),fge=a("p"),_Io=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),uIo=l(),Qi=a("p"),bIo=o(`Note:
Loading a model from its configuration file does `),mge=a("strong"),vIo=o("not"),FIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FO=a("a"),TIo=o("from_pretrained()"),MIo=o(" to load the model weights."),EIo=l(),F(Xb.$$.fragment),CIo=l(),ro=a("div"),F(Oy.$$.fragment),wIo=l(),gge=a("p"),AIo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),yIo=l(),Pa=a("p"),LIo=o("The model class to instantiate is selected based on the "),hge=a("code"),xIo=o("model_type"),$Io=o(` property of the config object (either
passed as an argument or loaded from `),pge=a("code"),kIo=o("pretrained_model_name_or_path"),SIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_ge=a("code"),RIo=o("pretrained_model_name_or_path"),PIo=o(":"),BIo=l(),K=a("ul"),zb=a("li"),uge=a("strong"),IIo=o("albert"),NIo=o(" \u2014 "),TO=a("a"),qIo=o("AlbertForMultipleChoice"),jIo=o(" (ALBERT model)"),DIo=l(),Wb=a("li"),bge=a("strong"),GIo=o("bert"),OIo=o(" \u2014 "),MO=a("a"),VIo=o("BertForMultipleChoice"),XIo=o(" (BERT model)"),zIo=l(),Qb=a("li"),vge=a("strong"),WIo=o("big_bird"),QIo=o(" \u2014 "),EO=a("a"),HIo=o("BigBirdForMultipleChoice"),UIo=o(" (BigBird model)"),JIo=l(),Hb=a("li"),Fge=a("strong"),YIo=o("camembert"),KIo=o(" \u2014 "),CO=a("a"),ZIo=o("CamembertForMultipleChoice"),eNo=o(" (CamemBERT model)"),oNo=l(),Ub=a("li"),Tge=a("strong"),rNo=o("canine"),tNo=o(" \u2014 "),wO=a("a"),aNo=o("CanineForMultipleChoice"),nNo=o(" (Canine model)"),sNo=l(),Jb=a("li"),Mge=a("strong"),lNo=o("convbert"),iNo=o(" \u2014 "),AO=a("a"),dNo=o("ConvBertForMultipleChoice"),cNo=o(" (ConvBERT model)"),fNo=l(),Yb=a("li"),Ege=a("strong"),mNo=o("data2vec-text"),gNo=o(" \u2014 "),yO=a("a"),hNo=o("Data2VecTextForMultipleChoice"),pNo=o(" (Data2VecText model)"),_No=l(),Kb=a("li"),Cge=a("strong"),uNo=o("deberta-v2"),bNo=o(" \u2014 "),LO=a("a"),vNo=o("DebertaV2ForMultipleChoice"),FNo=o(" (DeBERTa-v2 model)"),TNo=l(),Zb=a("li"),wge=a("strong"),MNo=o("distilbert"),ENo=o(" \u2014 "),xO=a("a"),CNo=o("DistilBertForMultipleChoice"),wNo=o(" (DistilBERT model)"),ANo=l(),e4=a("li"),Age=a("strong"),yNo=o("electra"),LNo=o(" \u2014 "),$O=a("a"),xNo=o("ElectraForMultipleChoice"),$No=o(" (ELECTRA model)"),kNo=l(),o4=a("li"),yge=a("strong"),SNo=o("flaubert"),RNo=o(" \u2014 "),kO=a("a"),PNo=o("FlaubertForMultipleChoice"),BNo=o(" (FlauBERT model)"),INo=l(),r4=a("li"),Lge=a("strong"),NNo=o("fnet"),qNo=o(" \u2014 "),SO=a("a"),jNo=o("FNetForMultipleChoice"),DNo=o(" (FNet model)"),GNo=l(),t4=a("li"),xge=a("strong"),ONo=o("funnel"),VNo=o(" \u2014 "),RO=a("a"),XNo=o("FunnelForMultipleChoice"),zNo=o(" (Funnel Transformer model)"),WNo=l(),a4=a("li"),$ge=a("strong"),QNo=o("ibert"),HNo=o(" \u2014 "),PO=a("a"),UNo=o("IBertForMultipleChoice"),JNo=o(" (I-BERT model)"),YNo=l(),n4=a("li"),kge=a("strong"),KNo=o("longformer"),ZNo=o(" \u2014 "),BO=a("a"),eqo=o("LongformerForMultipleChoice"),oqo=o(" (Longformer model)"),rqo=l(),s4=a("li"),Sge=a("strong"),tqo=o("megatron-bert"),aqo=o(" \u2014 "),IO=a("a"),nqo=o("MegatronBertForMultipleChoice"),sqo=o(" (MegatronBert model)"),lqo=l(),l4=a("li"),Rge=a("strong"),iqo=o("mobilebert"),dqo=o(" \u2014 "),NO=a("a"),cqo=o("MobileBertForMultipleChoice"),fqo=o(" (MobileBERT model)"),mqo=l(),i4=a("li"),Pge=a("strong"),gqo=o("mpnet"),hqo=o(" \u2014 "),qO=a("a"),pqo=o("MPNetForMultipleChoice"),_qo=o(" (MPNet model)"),uqo=l(),d4=a("li"),Bge=a("strong"),bqo=o("nystromformer"),vqo=o(" \u2014 "),jO=a("a"),Fqo=o("NystromformerForMultipleChoice"),Tqo=o(" (Nystromformer model)"),Mqo=l(),c4=a("li"),Ige=a("strong"),Eqo=o("qdqbert"),Cqo=o(" \u2014 "),DO=a("a"),wqo=o("QDQBertForMultipleChoice"),Aqo=o(" (QDQBert model)"),yqo=l(),f4=a("li"),Nge=a("strong"),Lqo=o("rembert"),xqo=o(" \u2014 "),GO=a("a"),$qo=o("RemBertForMultipleChoice"),kqo=o(" (RemBERT model)"),Sqo=l(),m4=a("li"),qge=a("strong"),Rqo=o("roberta"),Pqo=o(" \u2014 "),OO=a("a"),Bqo=o("RobertaForMultipleChoice"),Iqo=o(" (RoBERTa model)"),Nqo=l(),g4=a("li"),jge=a("strong"),qqo=o("roformer"),jqo=o(" \u2014 "),VO=a("a"),Dqo=o("RoFormerForMultipleChoice"),Gqo=o(" (RoFormer model)"),Oqo=l(),h4=a("li"),Dge=a("strong"),Vqo=o("squeezebert"),Xqo=o(" \u2014 "),XO=a("a"),zqo=o("SqueezeBertForMultipleChoice"),Wqo=o(" (SqueezeBERT model)"),Qqo=l(),p4=a("li"),Gge=a("strong"),Hqo=o("xlm"),Uqo=o(" \u2014 "),zO=a("a"),Jqo=o("XLMForMultipleChoice"),Yqo=o(" (XLM model)"),Kqo=l(),_4=a("li"),Oge=a("strong"),Zqo=o("xlm-roberta"),ejo=o(" \u2014 "),WO=a("a"),ojo=o("XLMRobertaForMultipleChoice"),rjo=o(" (XLM-RoBERTa model)"),tjo=l(),u4=a("li"),Vge=a("strong"),ajo=o("xlm-roberta-xl"),njo=o(" \u2014 "),QO=a("a"),sjo=o("XLMRobertaXLForMultipleChoice"),ljo=o(" (XLM-RoBERTa-XL model)"),ijo=l(),b4=a("li"),Xge=a("strong"),djo=o("xlnet"),cjo=o(" \u2014 "),HO=a("a"),fjo=o("XLNetForMultipleChoice"),mjo=o(" (XLNet model)"),gjo=l(),v4=a("li"),zge=a("strong"),hjo=o("yoso"),pjo=o(" \u2014 "),UO=a("a"),_jo=o("YosoForMultipleChoice"),ujo=o(" (YOSO model)"),bjo=l(),F4=a("p"),vjo=o("The model is set in evaluation mode by default using "),Wge=a("code"),Fjo=o("model.eval()"),Tjo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qge=a("code"),Mjo=o("model.train()"),Ejo=l(),F(T4.$$.fragment),dje=l(),Hi=a("h2"),M4=a("a"),Hge=a("span"),F(Vy.$$.fragment),Cjo=l(),Uge=a("span"),wjo=o("AutoModelForNextSentencePrediction"),cje=l(),Bo=a("div"),F(Xy.$$.fragment),Ajo=l(),Ui=a("p"),yjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),JO=a("a"),Ljo=o("from_pretrained()"),xjo=o(" class method or the "),YO=a("a"),$jo=o("from_config()"),kjo=o(` class
method.`),Sjo=l(),zy=a("p"),Rjo=o("This class cannot be instantiated directly using "),Jge=a("code"),Pjo=o("__init__()"),Bjo=o(" (throws an error)."),Ijo=l(),ct=a("div"),F(Wy.$$.fragment),Njo=l(),Yge=a("p"),qjo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jjo=l(),Ji=a("p"),Djo=o(`Note:
Loading a model from its configuration file does `),Kge=a("strong"),Gjo=o("not"),Ojo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KO=a("a"),Vjo=o("from_pretrained()"),Xjo=o(" to load the model weights."),zjo=l(),F(E4.$$.fragment),Wjo=l(),to=a("div"),F(Qy.$$.fragment),Qjo=l(),Zge=a("p"),Hjo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Ujo=l(),Ba=a("p"),Jjo=o("The model class to instantiate is selected based on the "),ehe=a("code"),Yjo=o("model_type"),Kjo=o(` property of the config object (either
passed as an argument or loaded from `),ohe=a("code"),Zjo=o("pretrained_model_name_or_path"),eDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rhe=a("code"),oDo=o("pretrained_model_name_or_path"),rDo=o(":"),tDo=l(),Yr=a("ul"),C4=a("li"),the=a("strong"),aDo=o("bert"),nDo=o(" \u2014 "),ZO=a("a"),sDo=o("BertForNextSentencePrediction"),lDo=o(" (BERT model)"),iDo=l(),w4=a("li"),ahe=a("strong"),dDo=o("fnet"),cDo=o(" \u2014 "),eV=a("a"),fDo=o("FNetForNextSentencePrediction"),mDo=o(" (FNet model)"),gDo=l(),A4=a("li"),nhe=a("strong"),hDo=o("megatron-bert"),pDo=o(" \u2014 "),oV=a("a"),_Do=o("MegatronBertForNextSentencePrediction"),uDo=o(" (MegatronBert model)"),bDo=l(),y4=a("li"),she=a("strong"),vDo=o("mobilebert"),FDo=o(" \u2014 "),rV=a("a"),TDo=o("MobileBertForNextSentencePrediction"),MDo=o(" (MobileBERT model)"),EDo=l(),L4=a("li"),lhe=a("strong"),CDo=o("qdqbert"),wDo=o(" \u2014 "),tV=a("a"),ADo=o("QDQBertForNextSentencePrediction"),yDo=o(" (QDQBert model)"),LDo=l(),x4=a("p"),xDo=o("The model is set in evaluation mode by default using "),ihe=a("code"),$Do=o("model.eval()"),kDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dhe=a("code"),SDo=o("model.train()"),RDo=l(),F($4.$$.fragment),fje=l(),Yi=a("h2"),k4=a("a"),che=a("span"),F(Hy.$$.fragment),PDo=l(),fhe=a("span"),BDo=o("AutoModelForTokenClassification"),mje=l(),Io=a("div"),F(Uy.$$.fragment),IDo=l(),Ki=a("p"),NDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),aV=a("a"),qDo=o("from_pretrained()"),jDo=o(" class method or the "),nV=a("a"),DDo=o("from_config()"),GDo=o(` class
method.`),ODo=l(),Jy=a("p"),VDo=o("This class cannot be instantiated directly using "),mhe=a("code"),XDo=o("__init__()"),zDo=o(" (throws an error)."),WDo=l(),ft=a("div"),F(Yy.$$.fragment),QDo=l(),ghe=a("p"),HDo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),UDo=l(),Zi=a("p"),JDo=o(`Note:
Loading a model from its configuration file does `),hhe=a("strong"),YDo=o("not"),KDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sV=a("a"),ZDo=o("from_pretrained()"),eGo=o(" to load the model weights."),oGo=l(),F(S4.$$.fragment),rGo=l(),ao=a("div"),F(Ky.$$.fragment),tGo=l(),phe=a("p"),aGo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),nGo=l(),Ia=a("p"),sGo=o("The model class to instantiate is selected based on the "),_he=a("code"),lGo=o("model_type"),iGo=o(` property of the config object (either
passed as an argument or loaded from `),uhe=a("code"),dGo=o("pretrained_model_name_or_path"),cGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bhe=a("code"),fGo=o("pretrained_model_name_or_path"),mGo=o(":"),gGo=l(),U=a("ul"),R4=a("li"),vhe=a("strong"),hGo=o("albert"),pGo=o(" \u2014 "),lV=a("a"),_Go=o("AlbertForTokenClassification"),uGo=o(" (ALBERT model)"),bGo=l(),P4=a("li"),Fhe=a("strong"),vGo=o("bert"),FGo=o(" \u2014 "),iV=a("a"),TGo=o("BertForTokenClassification"),MGo=o(" (BERT model)"),EGo=l(),B4=a("li"),The=a("strong"),CGo=o("big_bird"),wGo=o(" \u2014 "),dV=a("a"),AGo=o("BigBirdForTokenClassification"),yGo=o(" (BigBird model)"),LGo=l(),I4=a("li"),Mhe=a("strong"),xGo=o("camembert"),$Go=o(" \u2014 "),cV=a("a"),kGo=o("CamembertForTokenClassification"),SGo=o(" (CamemBERT model)"),RGo=l(),N4=a("li"),Ehe=a("strong"),PGo=o("canine"),BGo=o(" \u2014 "),fV=a("a"),IGo=o("CanineForTokenClassification"),NGo=o(" (Canine model)"),qGo=l(),q4=a("li"),Che=a("strong"),jGo=o("convbert"),DGo=o(" \u2014 "),mV=a("a"),GGo=o("ConvBertForTokenClassification"),OGo=o(" (ConvBERT model)"),VGo=l(),j4=a("li"),whe=a("strong"),XGo=o("data2vec-text"),zGo=o(" \u2014 "),gV=a("a"),WGo=o("Data2VecTextForTokenClassification"),QGo=o(" (Data2VecText model)"),HGo=l(),D4=a("li"),Ahe=a("strong"),UGo=o("deberta"),JGo=o(" \u2014 "),hV=a("a"),YGo=o("DebertaForTokenClassification"),KGo=o(" (DeBERTa model)"),ZGo=l(),G4=a("li"),yhe=a("strong"),eOo=o("deberta-v2"),oOo=o(" \u2014 "),pV=a("a"),rOo=o("DebertaV2ForTokenClassification"),tOo=o(" (DeBERTa-v2 model)"),aOo=l(),O4=a("li"),Lhe=a("strong"),nOo=o("distilbert"),sOo=o(" \u2014 "),_V=a("a"),lOo=o("DistilBertForTokenClassification"),iOo=o(" (DistilBERT model)"),dOo=l(),V4=a("li"),xhe=a("strong"),cOo=o("electra"),fOo=o(" \u2014 "),uV=a("a"),mOo=o("ElectraForTokenClassification"),gOo=o(" (ELECTRA model)"),hOo=l(),X4=a("li"),$he=a("strong"),pOo=o("flaubert"),_Oo=o(" \u2014 "),bV=a("a"),uOo=o("FlaubertForTokenClassification"),bOo=o(" (FlauBERT model)"),vOo=l(),z4=a("li"),khe=a("strong"),FOo=o("fnet"),TOo=o(" \u2014 "),vV=a("a"),MOo=o("FNetForTokenClassification"),EOo=o(" (FNet model)"),COo=l(),W4=a("li"),She=a("strong"),wOo=o("funnel"),AOo=o(" \u2014 "),FV=a("a"),yOo=o("FunnelForTokenClassification"),LOo=o(" (Funnel Transformer model)"),xOo=l(),Q4=a("li"),Rhe=a("strong"),$Oo=o("gpt2"),kOo=o(" \u2014 "),TV=a("a"),SOo=o("GPT2ForTokenClassification"),ROo=o(" (OpenAI GPT-2 model)"),POo=l(),H4=a("li"),Phe=a("strong"),BOo=o("ibert"),IOo=o(" \u2014 "),MV=a("a"),NOo=o("IBertForTokenClassification"),qOo=o(" (I-BERT model)"),jOo=l(),U4=a("li"),Bhe=a("strong"),DOo=o("layoutlm"),GOo=o(" \u2014 "),EV=a("a"),OOo=o("LayoutLMForTokenClassification"),VOo=o(" (LayoutLM model)"),XOo=l(),J4=a("li"),Ihe=a("strong"),zOo=o("layoutlmv2"),WOo=o(" \u2014 "),CV=a("a"),QOo=o("LayoutLMv2ForTokenClassification"),HOo=o(" (LayoutLMv2 model)"),UOo=l(),Y4=a("li"),Nhe=a("strong"),JOo=o("layoutlmv3"),YOo=o(" \u2014 "),wV=a("a"),KOo=o("LayoutLMv3ForTokenClassification"),ZOo=o(" (LayoutLMv3 model)"),eVo=l(),K4=a("li"),qhe=a("strong"),oVo=o("longformer"),rVo=o(" \u2014 "),AV=a("a"),tVo=o("LongformerForTokenClassification"),aVo=o(" (Longformer model)"),nVo=l(),Z4=a("li"),jhe=a("strong"),sVo=o("megatron-bert"),lVo=o(" \u2014 "),yV=a("a"),iVo=o("MegatronBertForTokenClassification"),dVo=o(" (MegatronBert model)"),cVo=l(),ev=a("li"),Dhe=a("strong"),fVo=o("mobilebert"),mVo=o(" \u2014 "),LV=a("a"),gVo=o("MobileBertForTokenClassification"),hVo=o(" (MobileBERT model)"),pVo=l(),ov=a("li"),Ghe=a("strong"),_Vo=o("mpnet"),uVo=o(" \u2014 "),xV=a("a"),bVo=o("MPNetForTokenClassification"),vVo=o(" (MPNet model)"),FVo=l(),rv=a("li"),Ohe=a("strong"),TVo=o("nystromformer"),MVo=o(" \u2014 "),$V=a("a"),EVo=o("NystromformerForTokenClassification"),CVo=o(" (Nystromformer model)"),wVo=l(),tv=a("li"),Vhe=a("strong"),AVo=o("qdqbert"),yVo=o(" \u2014 "),kV=a("a"),LVo=o("QDQBertForTokenClassification"),xVo=o(" (QDQBert model)"),$Vo=l(),av=a("li"),Xhe=a("strong"),kVo=o("rembert"),SVo=o(" \u2014 "),SV=a("a"),RVo=o("RemBertForTokenClassification"),PVo=o(" (RemBERT model)"),BVo=l(),nv=a("li"),zhe=a("strong"),IVo=o("roberta"),NVo=o(" \u2014 "),RV=a("a"),qVo=o("RobertaForTokenClassification"),jVo=o(" (RoBERTa model)"),DVo=l(),sv=a("li"),Whe=a("strong"),GVo=o("roformer"),OVo=o(" \u2014 "),PV=a("a"),VVo=o("RoFormerForTokenClassification"),XVo=o(" (RoFormer model)"),zVo=l(),lv=a("li"),Qhe=a("strong"),WVo=o("squeezebert"),QVo=o(" \u2014 "),BV=a("a"),HVo=o("SqueezeBertForTokenClassification"),UVo=o(" (SqueezeBERT model)"),JVo=l(),iv=a("li"),Hhe=a("strong"),YVo=o("xlm"),KVo=o(" \u2014 "),IV=a("a"),ZVo=o("XLMForTokenClassification"),eXo=o(" (XLM model)"),oXo=l(),dv=a("li"),Uhe=a("strong"),rXo=o("xlm-roberta"),tXo=o(" \u2014 "),NV=a("a"),aXo=o("XLMRobertaForTokenClassification"),nXo=o(" (XLM-RoBERTa model)"),sXo=l(),cv=a("li"),Jhe=a("strong"),lXo=o("xlm-roberta-xl"),iXo=o(" \u2014 "),qV=a("a"),dXo=o("XLMRobertaXLForTokenClassification"),cXo=o(" (XLM-RoBERTa-XL model)"),fXo=l(),fv=a("li"),Yhe=a("strong"),mXo=o("xlnet"),gXo=o(" \u2014 "),jV=a("a"),hXo=o("XLNetForTokenClassification"),pXo=o(" (XLNet model)"),_Xo=l(),mv=a("li"),Khe=a("strong"),uXo=o("yoso"),bXo=o(" \u2014 "),DV=a("a"),vXo=o("YosoForTokenClassification"),FXo=o(" (YOSO model)"),TXo=l(),gv=a("p"),MXo=o("The model is set in evaluation mode by default using "),Zhe=a("code"),EXo=o("model.eval()"),CXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),epe=a("code"),wXo=o("model.train()"),AXo=l(),F(hv.$$.fragment),gje=l(),ed=a("h2"),pv=a("a"),ope=a("span"),F(Zy.$$.fragment),yXo=l(),rpe=a("span"),LXo=o("AutoModelForQuestionAnswering"),hje=l(),No=a("div"),F(eL.$$.fragment),xXo=l(),od=a("p"),$Xo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GV=a("a"),kXo=o("from_pretrained()"),SXo=o(" class method or the "),OV=a("a"),RXo=o("from_config()"),PXo=o(` class
method.`),BXo=l(),oL=a("p"),IXo=o("This class cannot be instantiated directly using "),tpe=a("code"),NXo=o("__init__()"),qXo=o(" (throws an error)."),jXo=l(),mt=a("div"),F(rL.$$.fragment),DXo=l(),ape=a("p"),GXo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),OXo=l(),rd=a("p"),VXo=o(`Note:
Loading a model from its configuration file does `),npe=a("strong"),XXo=o("not"),zXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=a("a"),WXo=o("from_pretrained()"),QXo=o(" to load the model weights."),HXo=l(),F(_v.$$.fragment),UXo=l(),no=a("div"),F(tL.$$.fragment),JXo=l(),spe=a("p"),YXo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),KXo=l(),Na=a("p"),ZXo=o("The model class to instantiate is selected based on the "),lpe=a("code"),ezo=o("model_type"),ozo=o(` property of the config object (either
passed as an argument or loaded from `),ipe=a("code"),rzo=o("pretrained_model_name_or_path"),tzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dpe=a("code"),azo=o("pretrained_model_name_or_path"),nzo=o(":"),szo=l(),V=a("ul"),uv=a("li"),cpe=a("strong"),lzo=o("albert"),izo=o(" \u2014 "),XV=a("a"),dzo=o("AlbertForQuestionAnswering"),czo=o(" (ALBERT model)"),fzo=l(),bv=a("li"),fpe=a("strong"),mzo=o("bart"),gzo=o(" \u2014 "),zV=a("a"),hzo=o("BartForQuestionAnswering"),pzo=o(" (BART model)"),_zo=l(),vv=a("li"),mpe=a("strong"),uzo=o("bert"),bzo=o(" \u2014 "),WV=a("a"),vzo=o("BertForQuestionAnswering"),Fzo=o(" (BERT model)"),Tzo=l(),Fv=a("li"),gpe=a("strong"),Mzo=o("big_bird"),Ezo=o(" \u2014 "),QV=a("a"),Czo=o("BigBirdForQuestionAnswering"),wzo=o(" (BigBird model)"),Azo=l(),Tv=a("li"),hpe=a("strong"),yzo=o("bigbird_pegasus"),Lzo=o(" \u2014 "),HV=a("a"),xzo=o("BigBirdPegasusForQuestionAnswering"),$zo=o(" (BigBirdPegasus model)"),kzo=l(),Mv=a("li"),ppe=a("strong"),Szo=o("camembert"),Rzo=o(" \u2014 "),UV=a("a"),Pzo=o("CamembertForQuestionAnswering"),Bzo=o(" (CamemBERT model)"),Izo=l(),Ev=a("li"),_pe=a("strong"),Nzo=o("canine"),qzo=o(" \u2014 "),JV=a("a"),jzo=o("CanineForQuestionAnswering"),Dzo=o(" (Canine model)"),Gzo=l(),Cv=a("li"),upe=a("strong"),Ozo=o("convbert"),Vzo=o(" \u2014 "),YV=a("a"),Xzo=o("ConvBertForQuestionAnswering"),zzo=o(" (ConvBERT model)"),Wzo=l(),wv=a("li"),bpe=a("strong"),Qzo=o("data2vec-text"),Hzo=o(" \u2014 "),KV=a("a"),Uzo=o("Data2VecTextForQuestionAnswering"),Jzo=o(" (Data2VecText model)"),Yzo=l(),Av=a("li"),vpe=a("strong"),Kzo=o("deberta"),Zzo=o(" \u2014 "),ZV=a("a"),eWo=o("DebertaForQuestionAnswering"),oWo=o(" (DeBERTa model)"),rWo=l(),yv=a("li"),Fpe=a("strong"),tWo=o("deberta-v2"),aWo=o(" \u2014 "),eX=a("a"),nWo=o("DebertaV2ForQuestionAnswering"),sWo=o(" (DeBERTa-v2 model)"),lWo=l(),Lv=a("li"),Tpe=a("strong"),iWo=o("distilbert"),dWo=o(" \u2014 "),oX=a("a"),cWo=o("DistilBertForQuestionAnswering"),fWo=o(" (DistilBERT model)"),mWo=l(),xv=a("li"),Mpe=a("strong"),gWo=o("electra"),hWo=o(" \u2014 "),rX=a("a"),pWo=o("ElectraForQuestionAnswering"),_Wo=o(" (ELECTRA model)"),uWo=l(),$v=a("li"),Epe=a("strong"),bWo=o("flaubert"),vWo=o(" \u2014 "),tX=a("a"),FWo=o("FlaubertForQuestionAnsweringSimple"),TWo=o(" (FlauBERT model)"),MWo=l(),kv=a("li"),Cpe=a("strong"),EWo=o("fnet"),CWo=o(" \u2014 "),aX=a("a"),wWo=o("FNetForQuestionAnswering"),AWo=o(" (FNet model)"),yWo=l(),Sv=a("li"),wpe=a("strong"),LWo=o("funnel"),xWo=o(" \u2014 "),nX=a("a"),$Wo=o("FunnelForQuestionAnswering"),kWo=o(" (Funnel Transformer model)"),SWo=l(),Rv=a("li"),Ape=a("strong"),RWo=o("gptj"),PWo=o(" \u2014 "),sX=a("a"),BWo=o("GPTJForQuestionAnswering"),IWo=o(" (GPT-J model)"),NWo=l(),Pv=a("li"),ype=a("strong"),qWo=o("ibert"),jWo=o(" \u2014 "),lX=a("a"),DWo=o("IBertForQuestionAnswering"),GWo=o(" (I-BERT model)"),OWo=l(),Bv=a("li"),Lpe=a("strong"),VWo=o("layoutlmv2"),XWo=o(" \u2014 "),iX=a("a"),zWo=o("LayoutLMv2ForQuestionAnswering"),WWo=o(" (LayoutLMv2 model)"),QWo=l(),Iv=a("li"),xpe=a("strong"),HWo=o("layoutlmv3"),UWo=o(" \u2014 "),dX=a("a"),JWo=o("LayoutLMv3ForQuestionAnswering"),YWo=o(" (LayoutLMv3 model)"),KWo=l(),Nv=a("li"),$pe=a("strong"),ZWo=o("led"),eQo=o(" \u2014 "),cX=a("a"),oQo=o("LEDForQuestionAnswering"),rQo=o(" (LED model)"),tQo=l(),qv=a("li"),kpe=a("strong"),aQo=o("longformer"),nQo=o(" \u2014 "),fX=a("a"),sQo=o("LongformerForQuestionAnswering"),lQo=o(" (Longformer model)"),iQo=l(),jv=a("li"),Spe=a("strong"),dQo=o("lxmert"),cQo=o(" \u2014 "),mX=a("a"),fQo=o("LxmertForQuestionAnswering"),mQo=o(" (LXMERT model)"),gQo=l(),Dv=a("li"),Rpe=a("strong"),hQo=o("mbart"),pQo=o(" \u2014 "),gX=a("a"),_Qo=o("MBartForQuestionAnswering"),uQo=o(" (mBART model)"),bQo=l(),Gv=a("li"),Ppe=a("strong"),vQo=o("megatron-bert"),FQo=o(" \u2014 "),hX=a("a"),TQo=o("MegatronBertForQuestionAnswering"),MQo=o(" (MegatronBert model)"),EQo=l(),Ov=a("li"),Bpe=a("strong"),CQo=o("mobilebert"),wQo=o(" \u2014 "),pX=a("a"),AQo=o("MobileBertForQuestionAnswering"),yQo=o(" (MobileBERT model)"),LQo=l(),Vv=a("li"),Ipe=a("strong"),xQo=o("mpnet"),$Qo=o(" \u2014 "),_X=a("a"),kQo=o("MPNetForQuestionAnswering"),SQo=o(" (MPNet model)"),RQo=l(),Xv=a("li"),Npe=a("strong"),PQo=o("nystromformer"),BQo=o(" \u2014 "),uX=a("a"),IQo=o("NystromformerForQuestionAnswering"),NQo=o(" (Nystromformer model)"),qQo=l(),zv=a("li"),qpe=a("strong"),jQo=o("qdqbert"),DQo=o(" \u2014 "),bX=a("a"),GQo=o("QDQBertForQuestionAnswering"),OQo=o(" (QDQBert model)"),VQo=l(),Wv=a("li"),jpe=a("strong"),XQo=o("reformer"),zQo=o(" \u2014 "),vX=a("a"),WQo=o("ReformerForQuestionAnswering"),QQo=o(" (Reformer model)"),HQo=l(),Qv=a("li"),Dpe=a("strong"),UQo=o("rembert"),JQo=o(" \u2014 "),FX=a("a"),YQo=o("RemBertForQuestionAnswering"),KQo=o(" (RemBERT model)"),ZQo=l(),Hv=a("li"),Gpe=a("strong"),eHo=o("roberta"),oHo=o(" \u2014 "),TX=a("a"),rHo=o("RobertaForQuestionAnswering"),tHo=o(" (RoBERTa model)"),aHo=l(),Uv=a("li"),Ope=a("strong"),nHo=o("roformer"),sHo=o(" \u2014 "),MX=a("a"),lHo=o("RoFormerForQuestionAnswering"),iHo=o(" (RoFormer model)"),dHo=l(),Jv=a("li"),Vpe=a("strong"),cHo=o("splinter"),fHo=o(" \u2014 "),EX=a("a"),mHo=o("SplinterForQuestionAnswering"),gHo=o(" (Splinter model)"),hHo=l(),Yv=a("li"),Xpe=a("strong"),pHo=o("squeezebert"),_Ho=o(" \u2014 "),CX=a("a"),uHo=o("SqueezeBertForQuestionAnswering"),bHo=o(" (SqueezeBERT model)"),vHo=l(),Kv=a("li"),zpe=a("strong"),FHo=o("xlm"),THo=o(" \u2014 "),wX=a("a"),MHo=o("XLMForQuestionAnsweringSimple"),EHo=o(" (XLM model)"),CHo=l(),Zv=a("li"),Wpe=a("strong"),wHo=o("xlm-roberta"),AHo=o(" \u2014 "),AX=a("a"),yHo=o("XLMRobertaForQuestionAnswering"),LHo=o(" (XLM-RoBERTa model)"),xHo=l(),e5=a("li"),Qpe=a("strong"),$Ho=o("xlm-roberta-xl"),kHo=o(" \u2014 "),yX=a("a"),SHo=o("XLMRobertaXLForQuestionAnswering"),RHo=o(" (XLM-RoBERTa-XL model)"),PHo=l(),o5=a("li"),Hpe=a("strong"),BHo=o("xlnet"),IHo=o(" \u2014 "),LX=a("a"),NHo=o("XLNetForQuestionAnsweringSimple"),qHo=o(" (XLNet model)"),jHo=l(),r5=a("li"),Upe=a("strong"),DHo=o("yoso"),GHo=o(" \u2014 "),xX=a("a"),OHo=o("YosoForQuestionAnswering"),VHo=o(" (YOSO model)"),XHo=l(),t5=a("p"),zHo=o("The model is set in evaluation mode by default using "),Jpe=a("code"),WHo=o("model.eval()"),QHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=a("code"),HHo=o("model.train()"),UHo=l(),F(a5.$$.fragment),pje=l(),td=a("h2"),n5=a("a"),Kpe=a("span"),F(aL.$$.fragment),JHo=l(),Zpe=a("span"),YHo=o("AutoModelForTableQuestionAnswering"),_je=l(),qo=a("div"),F(nL.$$.fragment),KHo=l(),ad=a("p"),ZHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$X=a("a"),eUo=o("from_pretrained()"),oUo=o(" class method or the "),kX=a("a"),rUo=o("from_config()"),tUo=o(` class
method.`),aUo=l(),sL=a("p"),nUo=o("This class cannot be instantiated directly using "),e_e=a("code"),sUo=o("__init__()"),lUo=o(" (throws an error)."),iUo=l(),gt=a("div"),F(lL.$$.fragment),dUo=l(),o_e=a("p"),cUo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),fUo=l(),nd=a("p"),mUo=o(`Note:
Loading a model from its configuration file does `),r_e=a("strong"),gUo=o("not"),hUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SX=a("a"),pUo=o("from_pretrained()"),_Uo=o(" to load the model weights."),uUo=l(),F(s5.$$.fragment),bUo=l(),so=a("div"),F(iL.$$.fragment),vUo=l(),t_e=a("p"),FUo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),TUo=l(),qa=a("p"),MUo=o("The model class to instantiate is selected based on the "),a_e=a("code"),EUo=o("model_type"),CUo=o(` property of the config object (either
passed as an argument or loaded from `),n_e=a("code"),wUo=o("pretrained_model_name_or_path"),AUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=a("code"),yUo=o("pretrained_model_name_or_path"),LUo=o(":"),xUo=l(),l_e=a("ul"),l5=a("li"),i_e=a("strong"),$Uo=o("tapas"),kUo=o(" \u2014 "),RX=a("a"),SUo=o("TapasForQuestionAnswering"),RUo=o(" (TAPAS model)"),PUo=l(),i5=a("p"),BUo=o("The model is set in evaluation mode by default using "),d_e=a("code"),IUo=o("model.eval()"),NUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=a("code"),qUo=o("model.train()"),jUo=l(),F(d5.$$.fragment),uje=l(),sd=a("h2"),c5=a("a"),f_e=a("span"),F(dL.$$.fragment),DUo=l(),m_e=a("span"),GUo=o("AutoModelForImageClassification"),bje=l(),jo=a("div"),F(cL.$$.fragment),OUo=l(),ld=a("p"),VUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),PX=a("a"),XUo=o("from_pretrained()"),zUo=o(" class method or the "),BX=a("a"),WUo=o("from_config()"),QUo=o(` class
method.`),HUo=l(),fL=a("p"),UUo=o("This class cannot be instantiated directly using "),g_e=a("code"),JUo=o("__init__()"),YUo=o(" (throws an error)."),KUo=l(),ht=a("div"),F(mL.$$.fragment),ZUo=l(),h_e=a("p"),eJo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),oJo=l(),id=a("p"),rJo=o(`Note:
Loading a model from its configuration file does `),p_e=a("strong"),tJo=o("not"),aJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IX=a("a"),nJo=o("from_pretrained()"),sJo=o(" to load the model weights."),lJo=l(),F(f5.$$.fragment),iJo=l(),lo=a("div"),F(gL.$$.fragment),dJo=l(),__e=a("p"),cJo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),fJo=l(),ja=a("p"),mJo=o("The model class to instantiate is selected based on the "),u_e=a("code"),gJo=o("model_type"),hJo=o(` property of the config object (either
passed as an argument or loaded from `),b_e=a("code"),pJo=o("pretrained_model_name_or_path"),_Jo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v_e=a("code"),uJo=o("pretrained_model_name_or_path"),bJo=o(":"),vJo=l(),ve=a("ul"),m5=a("li"),F_e=a("strong"),FJo=o("beit"),TJo=o(" \u2014 "),NX=a("a"),MJo=o("BeitForImageClassification"),EJo=o(" (BEiT model)"),CJo=l(),g5=a("li"),T_e=a("strong"),wJo=o("convnext"),AJo=o(" \u2014 "),qX=a("a"),yJo=o("ConvNextForImageClassification"),LJo=o(" (ConvNext model)"),xJo=l(),h5=a("li"),M_e=a("strong"),$Jo=o("cvt"),kJo=o(" \u2014 "),jX=a("a"),SJo=o("CvtForImageClassification"),RJo=o(" (CvT model)"),PJo=l(),p5=a("li"),E_e=a("strong"),BJo=o("data2vec-vision"),IJo=o(" \u2014 "),DX=a("a"),NJo=o("Data2VecVisionForImageClassification"),qJo=o(" (Data2VecVision model)"),jJo=l(),Is=a("li"),C_e=a("strong"),DJo=o("deit"),GJo=o(" \u2014 "),GX=a("a"),OJo=o("DeiTForImageClassification"),VJo=o(" or "),OX=a("a"),XJo=o("DeiTForImageClassificationWithTeacher"),zJo=o(" (DeiT model)"),WJo=l(),_5=a("li"),w_e=a("strong"),QJo=o("imagegpt"),HJo=o(" \u2014 "),VX=a("a"),UJo=o("ImageGPTForImageClassification"),JJo=o(" (ImageGPT model)"),YJo=l(),Ns=a("li"),A_e=a("strong"),KJo=o("levit"),ZJo=o(" \u2014 "),XX=a("a"),eYo=o("LevitForImageClassification"),oYo=o(" or "),zX=a("a"),rYo=o("LevitForImageClassificationWithTeacher"),tYo=o(" (LeViT model)"),aYo=l(),pt=a("li"),y_e=a("strong"),nYo=o("perceiver"),sYo=o(" \u2014 "),WX=a("a"),lYo=o("PerceiverForImageClassificationLearned"),iYo=o(" or "),QX=a("a"),dYo=o("PerceiverForImageClassificationFourier"),cYo=o(" or "),HX=a("a"),fYo=o("PerceiverForImageClassificationConvProcessing"),mYo=o(" (Perceiver model)"),gYo=l(),u5=a("li"),L_e=a("strong"),hYo=o("poolformer"),pYo=o(" \u2014 "),UX=a("a"),_Yo=o("PoolFormerForImageClassification"),uYo=o(" (PoolFormer model)"),bYo=l(),b5=a("li"),x_e=a("strong"),vYo=o("regnet"),FYo=o(" \u2014 "),JX=a("a"),TYo=o("RegNetForImageClassification"),MYo=o(" (RegNet model)"),EYo=l(),v5=a("li"),$_e=a("strong"),CYo=o("resnet"),wYo=o(" \u2014 "),YX=a("a"),AYo=o("ResNetForImageClassification"),yYo=o(" (ResNet model)"),LYo=l(),F5=a("li"),k_e=a("strong"),xYo=o("segformer"),$Yo=o(" \u2014 "),KX=a("a"),kYo=o("SegformerForImageClassification"),SYo=o(" (SegFormer model)"),RYo=l(),T5=a("li"),S_e=a("strong"),PYo=o("swin"),BYo=o(" \u2014 "),ZX=a("a"),IYo=o("SwinForImageClassification"),NYo=o(" (Swin model)"),qYo=l(),M5=a("li"),R_e=a("strong"),jYo=o("van"),DYo=o(" \u2014 "),ez=a("a"),GYo=o("VanForImageClassification"),OYo=o(" (VAN model)"),VYo=l(),E5=a("li"),P_e=a("strong"),XYo=o("vit"),zYo=o(" \u2014 "),oz=a("a"),WYo=o("ViTForImageClassification"),QYo=o(" (ViT model)"),HYo=l(),C5=a("p"),UYo=o("The model is set in evaluation mode by default using "),B_e=a("code"),JYo=o("model.eval()"),YYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I_e=a("code"),KYo=o("model.train()"),ZYo=l(),F(w5.$$.fragment),vje=l(),dd=a("h2"),A5=a("a"),N_e=a("span"),F(hL.$$.fragment),eKo=l(),q_e=a("span"),oKo=o("AutoModelForVision2Seq"),Fje=l(),Do=a("div"),F(pL.$$.fragment),rKo=l(),cd=a("p"),tKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),rz=a("a"),aKo=o("from_pretrained()"),nKo=o(" class method or the "),tz=a("a"),sKo=o("from_config()"),lKo=o(` class
method.`),iKo=l(),_L=a("p"),dKo=o("This class cannot be instantiated directly using "),j_e=a("code"),cKo=o("__init__()"),fKo=o(" (throws an error)."),mKo=l(),_t=a("div"),F(uL.$$.fragment),gKo=l(),D_e=a("p"),hKo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pKo=l(),fd=a("p"),_Ko=o(`Note:
Loading a model from its configuration file does `),G_e=a("strong"),uKo=o("not"),bKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),az=a("a"),vKo=o("from_pretrained()"),FKo=o(" to load the model weights."),TKo=l(),F(y5.$$.fragment),MKo=l(),io=a("div"),F(bL.$$.fragment),EKo=l(),O_e=a("p"),CKo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),wKo=l(),Da=a("p"),AKo=o("The model class to instantiate is selected based on the "),V_e=a("code"),yKo=o("model_type"),LKo=o(` property of the config object (either
passed as an argument or loaded from `),X_e=a("code"),xKo=o("pretrained_model_name_or_path"),$Ko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z_e=a("code"),kKo=o("pretrained_model_name_or_path"),SKo=o(":"),RKo=l(),W_e=a("ul"),L5=a("li"),Q_e=a("strong"),PKo=o("vision-encoder-decoder"),BKo=o(" \u2014 "),nz=a("a"),IKo=o("VisionEncoderDecoderModel"),NKo=o(" (Vision Encoder decoder model)"),qKo=l(),x5=a("p"),jKo=o("The model is set in evaluation mode by default using "),H_e=a("code"),DKo=o("model.eval()"),GKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U_e=a("code"),OKo=o("model.train()"),VKo=l(),F($5.$$.fragment),Tje=l(),md=a("h2"),k5=a("a"),J_e=a("span"),F(vL.$$.fragment),XKo=l(),Y_e=a("span"),zKo=o("AutoModelForAudioClassification"),Mje=l(),Go=a("div"),F(FL.$$.fragment),WKo=l(),gd=a("p"),QKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),sz=a("a"),HKo=o("from_pretrained()"),UKo=o(" class method or the "),lz=a("a"),JKo=o("from_config()"),YKo=o(` class
method.`),KKo=l(),TL=a("p"),ZKo=o("This class cannot be instantiated directly using "),K_e=a("code"),eZo=o("__init__()"),oZo=o(" (throws an error)."),rZo=l(),ut=a("div"),F(ML.$$.fragment),tZo=l(),Z_e=a("p"),aZo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),nZo=l(),hd=a("p"),sZo=o(`Note:
Loading a model from its configuration file does `),eue=a("strong"),lZo=o("not"),iZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=a("a"),dZo=o("from_pretrained()"),cZo=o(" to load the model weights."),fZo=l(),F(S5.$$.fragment),mZo=l(),co=a("div"),F(EL.$$.fragment),gZo=l(),oue=a("p"),hZo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),pZo=l(),Ga=a("p"),_Zo=o("The model class to instantiate is selected based on the "),rue=a("code"),uZo=o("model_type"),bZo=o(` property of the config object (either
passed as an argument or loaded from `),tue=a("code"),vZo=o("pretrained_model_name_or_path"),FZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aue=a("code"),TZo=o("pretrained_model_name_or_path"),MZo=o(":"),EZo=l(),Se=a("ul"),R5=a("li"),nue=a("strong"),CZo=o("data2vec-audio"),wZo=o(" \u2014 "),dz=a("a"),AZo=o("Data2VecAudioForSequenceClassification"),yZo=o(" (Data2VecAudio model)"),LZo=l(),P5=a("li"),sue=a("strong"),xZo=o("hubert"),$Zo=o(" \u2014 "),cz=a("a"),kZo=o("HubertForSequenceClassification"),SZo=o(" (Hubert model)"),RZo=l(),B5=a("li"),lue=a("strong"),PZo=o("sew"),BZo=o(" \u2014 "),fz=a("a"),IZo=o("SEWForSequenceClassification"),NZo=o(" (SEW model)"),qZo=l(),I5=a("li"),iue=a("strong"),jZo=o("sew-d"),DZo=o(" \u2014 "),mz=a("a"),GZo=o("SEWDForSequenceClassification"),OZo=o(" (SEW-D model)"),VZo=l(),N5=a("li"),due=a("strong"),XZo=o("unispeech"),zZo=o(" \u2014 "),gz=a("a"),WZo=o("UniSpeechForSequenceClassification"),QZo=o(" (UniSpeech model)"),HZo=l(),q5=a("li"),cue=a("strong"),UZo=o("unispeech-sat"),JZo=o(" \u2014 "),hz=a("a"),YZo=o("UniSpeechSatForSequenceClassification"),KZo=o(" (UniSpeechSat model)"),ZZo=l(),j5=a("li"),fue=a("strong"),eer=o("wav2vec2"),oer=o(" \u2014 "),pz=a("a"),rer=o("Wav2Vec2ForSequenceClassification"),ter=o(" (Wav2Vec2 model)"),aer=l(),D5=a("li"),mue=a("strong"),ner=o("wav2vec2-conformer"),ser=o(" \u2014 "),_z=a("a"),ler=o("Wav2Vec2ConformerForSequenceClassification"),ier=o(" (Wav2Vec2-Conformer model)"),der=l(),G5=a("li"),gue=a("strong"),cer=o("wavlm"),fer=o(" \u2014 "),uz=a("a"),mer=o("WavLMForSequenceClassification"),ger=o(" (WavLM model)"),her=l(),O5=a("p"),per=o("The model is set in evaluation mode by default using "),hue=a("code"),_er=o("model.eval()"),uer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pue=a("code"),ber=o("model.train()"),ver=l(),F(V5.$$.fragment),Eje=l(),pd=a("h2"),X5=a("a"),_ue=a("span"),F(CL.$$.fragment),Fer=l(),uue=a("span"),Ter=o("AutoModelForAudioFrameClassification"),Cje=l(),Oo=a("div"),F(wL.$$.fragment),Mer=l(),_d=a("p"),Eer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),bz=a("a"),Cer=o("from_pretrained()"),wer=o(" class method or the "),vz=a("a"),Aer=o("from_config()"),yer=o(` class
method.`),Ler=l(),AL=a("p"),xer=o("This class cannot be instantiated directly using "),bue=a("code"),$er=o("__init__()"),ker=o(" (throws an error)."),Ser=l(),bt=a("div"),F(yL.$$.fragment),Rer=l(),vue=a("p"),Per=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Ber=l(),ud=a("p"),Ier=o(`Note:
Loading a model from its configuration file does `),Fue=a("strong"),Ner=o("not"),qer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),jer=o("from_pretrained()"),Der=o(" to load the model weights."),Ger=l(),F(z5.$$.fragment),Oer=l(),fo=a("div"),F(LL.$$.fragment),Ver=l(),Tue=a("p"),Xer=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),zer=l(),Oa=a("p"),Wer=o("The model class to instantiate is selected based on the "),Mue=a("code"),Qer=o("model_type"),Her=o(` property of the config object (either
passed as an argument or loaded from `),Eue=a("code"),Uer=o("pretrained_model_name_or_path"),Jer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cue=a("code"),Yer=o("pretrained_model_name_or_path"),Ker=o(":"),Zer=l(),Kr=a("ul"),W5=a("li"),wue=a("strong"),eor=o("data2vec-audio"),oor=o(" \u2014 "),Tz=a("a"),ror=o("Data2VecAudioForAudioFrameClassification"),tor=o(" (Data2VecAudio model)"),aor=l(),Q5=a("li"),Aue=a("strong"),nor=o("unispeech-sat"),sor=o(" \u2014 "),Mz=a("a"),lor=o("UniSpeechSatForAudioFrameClassification"),ior=o(" (UniSpeechSat model)"),dor=l(),H5=a("li"),yue=a("strong"),cor=o("wav2vec2"),mor=o(" \u2014 "),Ez=a("a"),gor=o("Wav2Vec2ForAudioFrameClassification"),hor=o(" (Wav2Vec2 model)"),por=l(),U5=a("li"),Lue=a("strong"),_or=o("wav2vec2-conformer"),uor=o(" \u2014 "),Cz=a("a"),bor=o("Wav2Vec2ConformerForAudioFrameClassification"),vor=o(" (Wav2Vec2-Conformer model)"),For=l(),J5=a("li"),xue=a("strong"),Tor=o("wavlm"),Mor=o(" \u2014 "),wz=a("a"),Eor=o("WavLMForAudioFrameClassification"),Cor=o(" (WavLM model)"),wor=l(),Y5=a("p"),Aor=o("The model is set in evaluation mode by default using "),$ue=a("code"),yor=o("model.eval()"),Lor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kue=a("code"),xor=o("model.train()"),$or=l(),F(K5.$$.fragment),wje=l(),bd=a("h2"),Z5=a("a"),Sue=a("span"),F(xL.$$.fragment),kor=l(),Rue=a("span"),Sor=o("AutoModelForCTC"),Aje=l(),Vo=a("div"),F($L.$$.fragment),Ror=l(),vd=a("p"),Por=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Az=a("a"),Bor=o("from_pretrained()"),Ior=o(" class method or the "),yz=a("a"),Nor=o("from_config()"),qor=o(` class
method.`),jor=l(),kL=a("p"),Dor=o("This class cannot be instantiated directly using "),Pue=a("code"),Gor=o("__init__()"),Oor=o(" (throws an error)."),Vor=l(),vt=a("div"),F(SL.$$.fragment),Xor=l(),Bue=a("p"),zor=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Wor=l(),Fd=a("p"),Qor=o(`Note:
Loading a model from its configuration file does `),Iue=a("strong"),Hor=o("not"),Uor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=a("a"),Jor=o("from_pretrained()"),Yor=o(" to load the model weights."),Kor=l(),F(eF.$$.fragment),Zor=l(),mo=a("div"),F(RL.$$.fragment),err=l(),Nue=a("p"),orr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),rrr=l(),Va=a("p"),trr=o("The model class to instantiate is selected based on the "),que=a("code"),arr=o("model_type"),nrr=o(` property of the config object (either
passed as an argument or loaded from `),jue=a("code"),srr=o("pretrained_model_name_or_path"),lrr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Due=a("code"),irr=o("pretrained_model_name_or_path"),drr=o(":"),crr=l(),Re=a("ul"),oF=a("li"),Gue=a("strong"),frr=o("data2vec-audio"),mrr=o(" \u2014 "),xz=a("a"),grr=o("Data2VecAudioForCTC"),hrr=o(" (Data2VecAudio model)"),prr=l(),rF=a("li"),Oue=a("strong"),_rr=o("hubert"),urr=o(" \u2014 "),$z=a("a"),brr=o("HubertForCTC"),vrr=o(" (Hubert model)"),Frr=l(),tF=a("li"),Vue=a("strong"),Trr=o("sew"),Mrr=o(" \u2014 "),kz=a("a"),Err=o("SEWForCTC"),Crr=o(" (SEW model)"),wrr=l(),aF=a("li"),Xue=a("strong"),Arr=o("sew-d"),yrr=o(" \u2014 "),Sz=a("a"),Lrr=o("SEWDForCTC"),xrr=o(" (SEW-D model)"),$rr=l(),nF=a("li"),zue=a("strong"),krr=o("unispeech"),Srr=o(" \u2014 "),Rz=a("a"),Rrr=o("UniSpeechForCTC"),Prr=o(" (UniSpeech model)"),Brr=l(),sF=a("li"),Wue=a("strong"),Irr=o("unispeech-sat"),Nrr=o(" \u2014 "),Pz=a("a"),qrr=o("UniSpeechSatForCTC"),jrr=o(" (UniSpeechSat model)"),Drr=l(),lF=a("li"),Que=a("strong"),Grr=o("wav2vec2"),Orr=o(" \u2014 "),Bz=a("a"),Vrr=o("Wav2Vec2ForCTC"),Xrr=o(" (Wav2Vec2 model)"),zrr=l(),iF=a("li"),Hue=a("strong"),Wrr=o("wav2vec2-conformer"),Qrr=o(" \u2014 "),Iz=a("a"),Hrr=o("Wav2Vec2ConformerForCTC"),Urr=o(" (Wav2Vec2-Conformer model)"),Jrr=l(),dF=a("li"),Uue=a("strong"),Yrr=o("wavlm"),Krr=o(" \u2014 "),Nz=a("a"),Zrr=o("WavLMForCTC"),etr=o(" (WavLM model)"),otr=l(),cF=a("p"),rtr=o("The model is set in evaluation mode by default using "),Jue=a("code"),ttr=o("model.eval()"),atr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=a("code"),ntr=o("model.train()"),str=l(),F(fF.$$.fragment),yje=l(),Td=a("h2"),mF=a("a"),Kue=a("span"),F(PL.$$.fragment),ltr=l(),Zue=a("span"),itr=o("AutoModelForSpeechSeq2Seq"),Lje=l(),Xo=a("div"),F(BL.$$.fragment),dtr=l(),Md=a("p"),ctr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),qz=a("a"),ftr=o("from_pretrained()"),mtr=o(" class method or the "),jz=a("a"),gtr=o("from_config()"),htr=o(` class
method.`),ptr=l(),IL=a("p"),_tr=o("This class cannot be instantiated directly using "),e2e=a("code"),utr=o("__init__()"),btr=o(" (throws an error)."),vtr=l(),Ft=a("div"),F(NL.$$.fragment),Ftr=l(),o2e=a("p"),Ttr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Mtr=l(),Ed=a("p"),Etr=o(`Note:
Loading a model from its configuration file does `),r2e=a("strong"),Ctr=o("not"),wtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dz=a("a"),Atr=o("from_pretrained()"),ytr=o(" to load the model weights."),Ltr=l(),F(gF.$$.fragment),xtr=l(),go=a("div"),F(qL.$$.fragment),$tr=l(),t2e=a("p"),ktr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Str=l(),Xa=a("p"),Rtr=o("The model class to instantiate is selected based on the "),a2e=a("code"),Ptr=o("model_type"),Btr=o(` property of the config object (either
passed as an argument or loaded from `),n2e=a("code"),Itr=o("pretrained_model_name_or_path"),Ntr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s2e=a("code"),qtr=o("pretrained_model_name_or_path"),jtr=o(":"),Dtr=l(),jL=a("ul"),hF=a("li"),l2e=a("strong"),Gtr=o("speech-encoder-decoder"),Otr=o(" \u2014 "),Gz=a("a"),Vtr=o("SpeechEncoderDecoderModel"),Xtr=o(" (Speech Encoder decoder model)"),ztr=l(),pF=a("li"),i2e=a("strong"),Wtr=o("speech_to_text"),Qtr=o(" \u2014 "),Oz=a("a"),Htr=o("Speech2TextForConditionalGeneration"),Utr=o(" (Speech2Text model)"),Jtr=l(),_F=a("p"),Ytr=o("The model is set in evaluation mode by default using "),d2e=a("code"),Ktr=o("model.eval()"),Ztr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c2e=a("code"),ear=o("model.train()"),oar=l(),F(uF.$$.fragment),xje=l(),Cd=a("h2"),bF=a("a"),f2e=a("span"),F(DL.$$.fragment),rar=l(),m2e=a("span"),tar=o("AutoModelForAudioXVector"),$je=l(),zo=a("div"),F(GL.$$.fragment),aar=l(),wd=a("p"),nar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Vz=a("a"),sar=o("from_pretrained()"),lar=o(" class method or the "),Xz=a("a"),iar=o("from_config()"),dar=o(` class
method.`),car=l(),OL=a("p"),far=o("This class cannot be instantiated directly using "),g2e=a("code"),mar=o("__init__()"),gar=o(" (throws an error)."),har=l(),Tt=a("div"),F(VL.$$.fragment),par=l(),h2e=a("p"),_ar=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),uar=l(),Ad=a("p"),bar=o(`Note:
Loading a model from its configuration file does `),p2e=a("strong"),Far=o("not"),Tar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=a("a"),Mar=o("from_pretrained()"),Ear=o(" to load the model weights."),Car=l(),F(vF.$$.fragment),war=l(),ho=a("div"),F(XL.$$.fragment),Aar=l(),_2e=a("p"),yar=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Lar=l(),za=a("p"),xar=o("The model class to instantiate is selected based on the "),u2e=a("code"),$ar=o("model_type"),kar=o(` property of the config object (either
passed as an argument or loaded from `),b2e=a("code"),Sar=o("pretrained_model_name_or_path"),Rar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v2e=a("code"),Par=o("pretrained_model_name_or_path"),Bar=o(":"),Iar=l(),Zr=a("ul"),FF=a("li"),F2e=a("strong"),Nar=o("data2vec-audio"),qar=o(" \u2014 "),Wz=a("a"),jar=o("Data2VecAudioForXVector"),Dar=o(" (Data2VecAudio model)"),Gar=l(),TF=a("li"),T2e=a("strong"),Oar=o("unispeech-sat"),Var=o(" \u2014 "),Qz=a("a"),Xar=o("UniSpeechSatForXVector"),zar=o(" (UniSpeechSat model)"),War=l(),MF=a("li"),M2e=a("strong"),Qar=o("wav2vec2"),Har=o(" \u2014 "),Hz=a("a"),Uar=o("Wav2Vec2ForXVector"),Jar=o(" (Wav2Vec2 model)"),Yar=l(),EF=a("li"),E2e=a("strong"),Kar=o("wav2vec2-conformer"),Zar=o(" \u2014 "),Uz=a("a"),enr=o("Wav2Vec2ConformerForXVector"),onr=o(" (Wav2Vec2-Conformer model)"),rnr=l(),CF=a("li"),C2e=a("strong"),tnr=o("wavlm"),anr=o(" \u2014 "),Jz=a("a"),nnr=o("WavLMForXVector"),snr=o(" (WavLM model)"),lnr=l(),wF=a("p"),inr=o("The model is set in evaluation mode by default using "),w2e=a("code"),dnr=o("model.eval()"),cnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A2e=a("code"),fnr=o("model.train()"),mnr=l(),F(AF.$$.fragment),kje=l(),yd=a("h2"),yF=a("a"),y2e=a("span"),F(zL.$$.fragment),gnr=l(),L2e=a("span"),hnr=o("AutoModelForMaskedImageModeling"),Sje=l(),Wo=a("div"),F(WL.$$.fragment),pnr=l(),Ld=a("p"),_nr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Yz=a("a"),unr=o("from_pretrained()"),bnr=o(" class method or the "),Kz=a("a"),vnr=o("from_config()"),Fnr=o(` class
method.`),Tnr=l(),QL=a("p"),Mnr=o("This class cannot be instantiated directly using "),x2e=a("code"),Enr=o("__init__()"),Cnr=o(" (throws an error)."),wnr=l(),Mt=a("div"),F(HL.$$.fragment),Anr=l(),$2e=a("p"),ynr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Lnr=l(),xd=a("p"),xnr=o(`Note:
Loading a model from its configuration file does `),k2e=a("strong"),$nr=o("not"),knr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zz=a("a"),Snr=o("from_pretrained()"),Rnr=o(" to load the model weights."),Pnr=l(),F(LF.$$.fragment),Bnr=l(),po=a("div"),F(UL.$$.fragment),Inr=l(),S2e=a("p"),Nnr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),qnr=l(),Wa=a("p"),jnr=o("The model class to instantiate is selected based on the "),R2e=a("code"),Dnr=o("model_type"),Gnr=o(` property of the config object (either
passed as an argument or loaded from `),P2e=a("code"),Onr=o("pretrained_model_name_or_path"),Vnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B2e=a("code"),Xnr=o("pretrained_model_name_or_path"),znr=o(":"),Wnr=l(),$d=a("ul"),xF=a("li"),I2e=a("strong"),Qnr=o("deit"),Hnr=o(" \u2014 "),eW=a("a"),Unr=o("DeiTForMaskedImageModeling"),Jnr=o(" (DeiT model)"),Ynr=l(),$F=a("li"),N2e=a("strong"),Knr=o("swin"),Znr=o(" \u2014 "),oW=a("a"),esr=o("SwinForMaskedImageModeling"),osr=o(" (Swin model)"),rsr=l(),kF=a("li"),q2e=a("strong"),tsr=o("vit"),asr=o(" \u2014 "),rW=a("a"),nsr=o("ViTForMaskedImageModeling"),ssr=o(" (ViT model)"),lsr=l(),SF=a("p"),isr=o("The model is set in evaluation mode by default using "),j2e=a("code"),dsr=o("model.eval()"),csr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D2e=a("code"),fsr=o("model.train()"),msr=l(),F(RF.$$.fragment),Rje=l(),kd=a("h2"),PF=a("a"),G2e=a("span"),F(JL.$$.fragment),gsr=l(),O2e=a("span"),hsr=o("AutoModelForObjectDetection"),Pje=l(),Qo=a("div"),F(YL.$$.fragment),psr=l(),Sd=a("p"),_sr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),tW=a("a"),usr=o("from_pretrained()"),bsr=o(" class method or the "),aW=a("a"),vsr=o("from_config()"),Fsr=o(` class
method.`),Tsr=l(),KL=a("p"),Msr=o("This class cannot be instantiated directly using "),V2e=a("code"),Esr=o("__init__()"),Csr=o(" (throws an error)."),wsr=l(),Et=a("div"),F(ZL.$$.fragment),Asr=l(),X2e=a("p"),ysr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Lsr=l(),Rd=a("p"),xsr=o(`Note:
Loading a model from its configuration file does `),z2e=a("strong"),$sr=o("not"),ksr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nW=a("a"),Ssr=o("from_pretrained()"),Rsr=o(" to load the model weights."),Psr=l(),F(BF.$$.fragment),Bsr=l(),_o=a("div"),F(e8.$$.fragment),Isr=l(),W2e=a("p"),Nsr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),qsr=l(),Qa=a("p"),jsr=o("The model class to instantiate is selected based on the "),Q2e=a("code"),Dsr=o("model_type"),Gsr=o(` property of the config object (either
passed as an argument or loaded from `),H2e=a("code"),Osr=o("pretrained_model_name_or_path"),Vsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=a("code"),Xsr=o("pretrained_model_name_or_path"),zsr=o(":"),Wsr=l(),o8=a("ul"),IF=a("li"),J2e=a("strong"),Qsr=o("detr"),Hsr=o(" \u2014 "),sW=a("a"),Usr=o("DetrForObjectDetection"),Jsr=o(" (DETR model)"),Ysr=l(),NF=a("li"),Y2e=a("strong"),Ksr=o("yolos"),Zsr=o(" \u2014 "),lW=a("a"),elr=o("YolosForObjectDetection"),olr=o(" (YOLOS model)"),rlr=l(),qF=a("p"),tlr=o("The model is set in evaluation mode by default using "),K2e=a("code"),alr=o("model.eval()"),nlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z2e=a("code"),slr=o("model.train()"),llr=l(),F(jF.$$.fragment),Bje=l(),Pd=a("h2"),DF=a("a"),e1e=a("span"),F(r8.$$.fragment),ilr=l(),o1e=a("span"),dlr=o("AutoModelForImageSegmentation"),Ije=l(),Ho=a("div"),F(t8.$$.fragment),clr=l(),Bd=a("p"),flr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),iW=a("a"),mlr=o("from_pretrained()"),glr=o(" class method or the "),dW=a("a"),hlr=o("from_config()"),plr=o(` class
method.`),_lr=l(),a8=a("p"),ulr=o("This class cannot be instantiated directly using "),r1e=a("code"),blr=o("__init__()"),vlr=o(" (throws an error)."),Flr=l(),Ct=a("div"),F(n8.$$.fragment),Tlr=l(),t1e=a("p"),Mlr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Elr=l(),Id=a("p"),Clr=o(`Note:
Loading a model from its configuration file does `),a1e=a("strong"),wlr=o("not"),Alr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cW=a("a"),ylr=o("from_pretrained()"),Llr=o(" to load the model weights."),xlr=l(),F(GF.$$.fragment),$lr=l(),uo=a("div"),F(s8.$$.fragment),klr=l(),n1e=a("p"),Slr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Rlr=l(),Ha=a("p"),Plr=o("The model class to instantiate is selected based on the "),s1e=a("code"),Blr=o("model_type"),Ilr=o(` property of the config object (either
passed as an argument or loaded from `),l1e=a("code"),Nlr=o("pretrained_model_name_or_path"),qlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i1e=a("code"),jlr=o("pretrained_model_name_or_path"),Dlr=o(":"),Glr=l(),d1e=a("ul"),OF=a("li"),c1e=a("strong"),Olr=o("detr"),Vlr=o(" \u2014 "),fW=a("a"),Xlr=o("DetrForSegmentation"),zlr=o(" (DETR model)"),Wlr=l(),VF=a("p"),Qlr=o("The model is set in evaluation mode by default using "),f1e=a("code"),Hlr=o("model.eval()"),Ulr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m1e=a("code"),Jlr=o("model.train()"),Ylr=l(),F(XF.$$.fragment),Nje=l(),Nd=a("h2"),zF=a("a"),g1e=a("span"),F(l8.$$.fragment),Klr=l(),h1e=a("span"),Zlr=o("AutoModelForSemanticSegmentation"),qje=l(),Uo=a("div"),F(i8.$$.fragment),eir=l(),qd=a("p"),oir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),mW=a("a"),rir=o("from_pretrained()"),tir=o(" class method or the "),gW=a("a"),air=o("from_config()"),nir=o(` class
method.`),sir=l(),d8=a("p"),lir=o("This class cannot be instantiated directly using "),p1e=a("code"),iir=o("__init__()"),dir=o(" (throws an error)."),cir=l(),wt=a("div"),F(c8.$$.fragment),fir=l(),_1e=a("p"),mir=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),gir=l(),jd=a("p"),hir=o(`Note:
Loading a model from its configuration file does `),u1e=a("strong"),pir=o("not"),_ir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hW=a("a"),uir=o("from_pretrained()"),bir=o(" to load the model weights."),vir=l(),F(WF.$$.fragment),Fir=l(),bo=a("div"),F(f8.$$.fragment),Tir=l(),b1e=a("p"),Mir=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Eir=l(),Ua=a("p"),Cir=o("The model class to instantiate is selected based on the "),v1e=a("code"),wir=o("model_type"),Air=o(` property of the config object (either
passed as an argument or loaded from `),F1e=a("code"),yir=o("pretrained_model_name_or_path"),Lir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T1e=a("code"),xir=o("pretrained_model_name_or_path"),$ir=o(":"),kir=l(),Ja=a("ul"),QF=a("li"),M1e=a("strong"),Sir=o("beit"),Rir=o(" \u2014 "),pW=a("a"),Pir=o("BeitForSemanticSegmentation"),Bir=o(" (BEiT model)"),Iir=l(),HF=a("li"),E1e=a("strong"),Nir=o("data2vec-vision"),qir=o(" \u2014 "),_W=a("a"),jir=o("Data2VecVisionForSemanticSegmentation"),Dir=o(" (Data2VecVision model)"),Gir=l(),UF=a("li"),C1e=a("strong"),Oir=o("dpt"),Vir=o(" \u2014 "),uW=a("a"),Xir=o("DPTForSemanticSegmentation"),zir=o(" (DPT model)"),Wir=l(),JF=a("li"),w1e=a("strong"),Qir=o("segformer"),Hir=o(" \u2014 "),bW=a("a"),Uir=o("SegformerForSemanticSegmentation"),Jir=o(" (SegFormer model)"),Yir=l(),YF=a("p"),Kir=o("The model is set in evaluation mode by default using "),A1e=a("code"),Zir=o("model.eval()"),edr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y1e=a("code"),odr=o("model.train()"),rdr=l(),F(KF.$$.fragment),jje=l(),Dd=a("h2"),ZF=a("a"),L1e=a("span"),F(m8.$$.fragment),tdr=l(),x1e=a("span"),adr=o("AutoModelForInstanceSegmentation"),Dje=l(),Jo=a("div"),F(g8.$$.fragment),ndr=l(),Gd=a("p"),sdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),vW=a("a"),ldr=o("from_pretrained()"),idr=o(" class method or the "),FW=a("a"),ddr=o("from_config()"),cdr=o(` class
method.`),fdr=l(),h8=a("p"),mdr=o("This class cannot be instantiated directly using "),$1e=a("code"),gdr=o("__init__()"),hdr=o(" (throws an error)."),pdr=l(),At=a("div"),F(p8.$$.fragment),_dr=l(),k1e=a("p"),udr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),bdr=l(),Od=a("p"),vdr=o(`Note:
Loading a model from its configuration file does `),S1e=a("strong"),Fdr=o("not"),Tdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TW=a("a"),Mdr=o("from_pretrained()"),Edr=o(" to load the model weights."),Cdr=l(),F(eT.$$.fragment),wdr=l(),vo=a("div"),F(_8.$$.fragment),Adr=l(),R1e=a("p"),ydr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Ldr=l(),Ya=a("p"),xdr=o("The model class to instantiate is selected based on the "),P1e=a("code"),$dr=o("model_type"),kdr=o(` property of the config object (either
passed as an argument or loaded from `),B1e=a("code"),Sdr=o("pretrained_model_name_or_path"),Rdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=a("code"),Pdr=o("pretrained_model_name_or_path"),Bdr=o(":"),Idr=l(),N1e=a("ul"),oT=a("li"),q1e=a("strong"),Ndr=o("maskformer"),qdr=o(" \u2014 "),MW=a("a"),jdr=o("MaskFormerForInstanceSegmentation"),Ddr=o(" (MaskFormer model)"),Gdr=l(),rT=a("p"),Odr=o("The model is set in evaluation mode by default using "),j1e=a("code"),Vdr=o("model.eval()"),Xdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D1e=a("code"),zdr=o("model.train()"),Wdr=l(),F(tT.$$.fragment),Gje=l(),Vd=a("h2"),aT=a("a"),G1e=a("span"),F(u8.$$.fragment),Qdr=l(),O1e=a("span"),Hdr=o("TFAutoModel"),Oje=l(),Yo=a("div"),F(b8.$$.fragment),Udr=l(),Xd=a("p"),Jdr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),EW=a("a"),Ydr=o("from_pretrained()"),Kdr=o(" class method or the "),CW=a("a"),Zdr=o("from_config()"),ecr=o(` class
method.`),ocr=l(),v8=a("p"),rcr=o("This class cannot be instantiated directly using "),V1e=a("code"),tcr=o("__init__()"),acr=o(" (throws an error)."),ncr=l(),yt=a("div"),F(F8.$$.fragment),scr=l(),X1e=a("p"),lcr=o("Instantiates one of the base model classes of the library from a configuration."),icr=l(),zd=a("p"),dcr=o(`Note:
Loading a model from its configuration file does `),z1e=a("strong"),ccr=o("not"),fcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wW=a("a"),mcr=o("from_pretrained()"),gcr=o(" to load the model weights."),hcr=l(),F(nT.$$.fragment),pcr=l(),wr=a("div"),F(T8.$$.fragment),_cr=l(),W1e=a("p"),ucr=o("Instantiate one of the base model classes of the library from a pretrained model."),bcr=l(),Ka=a("p"),vcr=o("The model class to instantiate is selected based on the "),Q1e=a("code"),Fcr=o("model_type"),Tcr=o(` property of the config object (either
passed as an argument or loaded from `),H1e=a("code"),Mcr=o("pretrained_model_name_or_path"),Ecr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=a("code"),Ccr=o("pretrained_model_name_or_path"),wcr=o(":"),Acr=l(),q=a("ul"),sT=a("li"),J1e=a("strong"),ycr=o("albert"),Lcr=o(" \u2014 "),AW=a("a"),xcr=o("TFAlbertModel"),$cr=o(" (ALBERT model)"),kcr=l(),lT=a("li"),Y1e=a("strong"),Scr=o("bart"),Rcr=o(" \u2014 "),yW=a("a"),Pcr=o("TFBartModel"),Bcr=o(" (BART model)"),Icr=l(),iT=a("li"),K1e=a("strong"),Ncr=o("bert"),qcr=o(" \u2014 "),LW=a("a"),jcr=o("TFBertModel"),Dcr=o(" (BERT model)"),Gcr=l(),dT=a("li"),Z1e=a("strong"),Ocr=o("blenderbot"),Vcr=o(" \u2014 "),xW=a("a"),Xcr=o("TFBlenderbotModel"),zcr=o(" (Blenderbot model)"),Wcr=l(),cT=a("li"),ebe=a("strong"),Qcr=o("blenderbot-small"),Hcr=o(" \u2014 "),$W=a("a"),Ucr=o("TFBlenderbotSmallModel"),Jcr=o(" (BlenderbotSmall model)"),Ycr=l(),fT=a("li"),obe=a("strong"),Kcr=o("camembert"),Zcr=o(" \u2014 "),kW=a("a"),efr=o("TFCamembertModel"),ofr=o(" (CamemBERT model)"),rfr=l(),mT=a("li"),rbe=a("strong"),tfr=o("clip"),afr=o(" \u2014 "),SW=a("a"),nfr=o("TFCLIPModel"),sfr=o(" (CLIP model)"),lfr=l(),gT=a("li"),tbe=a("strong"),ifr=o("convbert"),dfr=o(" \u2014 "),RW=a("a"),cfr=o("TFConvBertModel"),ffr=o(" (ConvBERT model)"),mfr=l(),hT=a("li"),abe=a("strong"),gfr=o("convnext"),hfr=o(" \u2014 "),PW=a("a"),pfr=o("TFConvNextModel"),_fr=o(" (ConvNext model)"),ufr=l(),pT=a("li"),nbe=a("strong"),bfr=o("ctrl"),vfr=o(" \u2014 "),BW=a("a"),Ffr=o("TFCTRLModel"),Tfr=o(" (CTRL model)"),Mfr=l(),_T=a("li"),sbe=a("strong"),Efr=o("data2vec-vision"),Cfr=o(" \u2014 "),IW=a("a"),wfr=o("TFData2VecVisionModel"),Afr=o(" (Data2VecVision model)"),yfr=l(),uT=a("li"),lbe=a("strong"),Lfr=o("deberta"),xfr=o(" \u2014 "),NW=a("a"),$fr=o("TFDebertaModel"),kfr=o(" (DeBERTa model)"),Sfr=l(),bT=a("li"),ibe=a("strong"),Rfr=o("deberta-v2"),Pfr=o(" \u2014 "),qW=a("a"),Bfr=o("TFDebertaV2Model"),Ifr=o(" (DeBERTa-v2 model)"),Nfr=l(),vT=a("li"),dbe=a("strong"),qfr=o("distilbert"),jfr=o(" \u2014 "),jW=a("a"),Dfr=o("TFDistilBertModel"),Gfr=o(" (DistilBERT model)"),Ofr=l(),FT=a("li"),cbe=a("strong"),Vfr=o("dpr"),Xfr=o(" \u2014 "),DW=a("a"),zfr=o("TFDPRQuestionEncoder"),Wfr=o(" (DPR model)"),Qfr=l(),TT=a("li"),fbe=a("strong"),Hfr=o("electra"),Ufr=o(" \u2014 "),GW=a("a"),Jfr=o("TFElectraModel"),Yfr=o(" (ELECTRA model)"),Kfr=l(),MT=a("li"),mbe=a("strong"),Zfr=o("flaubert"),emr=o(" \u2014 "),OW=a("a"),omr=o("TFFlaubertModel"),rmr=o(" (FlauBERT model)"),tmr=l(),qs=a("li"),gbe=a("strong"),amr=o("funnel"),nmr=o(" \u2014 "),VW=a("a"),smr=o("TFFunnelModel"),lmr=o(" or "),XW=a("a"),imr=o("TFFunnelBaseModel"),dmr=o(" (Funnel Transformer model)"),cmr=l(),ET=a("li"),hbe=a("strong"),fmr=o("gpt2"),mmr=o(" \u2014 "),zW=a("a"),gmr=o("TFGPT2Model"),hmr=o(" (OpenAI GPT-2 model)"),pmr=l(),CT=a("li"),pbe=a("strong"),_mr=o("gptj"),umr=o(" \u2014 "),WW=a("a"),bmr=o("TFGPTJModel"),vmr=o(" (GPT-J model)"),Fmr=l(),wT=a("li"),_be=a("strong"),Tmr=o("hubert"),Mmr=o(" \u2014 "),QW=a("a"),Emr=o("TFHubertModel"),Cmr=o(" (Hubert model)"),wmr=l(),AT=a("li"),ube=a("strong"),Amr=o("layoutlm"),ymr=o(" \u2014 "),HW=a("a"),Lmr=o("TFLayoutLMModel"),xmr=o(" (LayoutLM model)"),$mr=l(),yT=a("li"),bbe=a("strong"),kmr=o("led"),Smr=o(" \u2014 "),UW=a("a"),Rmr=o("TFLEDModel"),Pmr=o(" (LED model)"),Bmr=l(),LT=a("li"),vbe=a("strong"),Imr=o("longformer"),Nmr=o(" \u2014 "),JW=a("a"),qmr=o("TFLongformerModel"),jmr=o(" (Longformer model)"),Dmr=l(),xT=a("li"),Fbe=a("strong"),Gmr=o("lxmert"),Omr=o(" \u2014 "),YW=a("a"),Vmr=o("TFLxmertModel"),Xmr=o(" (LXMERT model)"),zmr=l(),$T=a("li"),Tbe=a("strong"),Wmr=o("marian"),Qmr=o(" \u2014 "),KW=a("a"),Hmr=o("TFMarianModel"),Umr=o(" (Marian model)"),Jmr=l(),kT=a("li"),Mbe=a("strong"),Ymr=o("mbart"),Kmr=o(" \u2014 "),ZW=a("a"),Zmr=o("TFMBartModel"),egr=o(" (mBART model)"),ogr=l(),ST=a("li"),Ebe=a("strong"),rgr=o("mobilebert"),tgr=o(" \u2014 "),eQ=a("a"),agr=o("TFMobileBertModel"),ngr=o(" (MobileBERT model)"),sgr=l(),RT=a("li"),Cbe=a("strong"),lgr=o("mpnet"),igr=o(" \u2014 "),oQ=a("a"),dgr=o("TFMPNetModel"),cgr=o(" (MPNet model)"),fgr=l(),PT=a("li"),wbe=a("strong"),mgr=o("mt5"),ggr=o(" \u2014 "),rQ=a("a"),hgr=o("TFMT5Model"),pgr=o(" (mT5 model)"),_gr=l(),BT=a("li"),Abe=a("strong"),ugr=o("openai-gpt"),bgr=o(" \u2014 "),tQ=a("a"),vgr=o("TFOpenAIGPTModel"),Fgr=o(" (OpenAI GPT model)"),Tgr=l(),IT=a("li"),ybe=a("strong"),Mgr=o("opt"),Egr=o(" \u2014 "),aQ=a("a"),Cgr=o("TFOPTModel"),wgr=o(" (OPT model)"),Agr=l(),NT=a("li"),Lbe=a("strong"),ygr=o("pegasus"),Lgr=o(" \u2014 "),nQ=a("a"),xgr=o("TFPegasusModel"),$gr=o(" (Pegasus model)"),kgr=l(),qT=a("li"),xbe=a("strong"),Sgr=o("rembert"),Rgr=o(" \u2014 "),sQ=a("a"),Pgr=o("TFRemBertModel"),Bgr=o(" (RemBERT model)"),Igr=l(),jT=a("li"),$be=a("strong"),Ngr=o("roberta"),qgr=o(" \u2014 "),lQ=a("a"),jgr=o("TFRobertaModel"),Dgr=o(" (RoBERTa model)"),Ggr=l(),DT=a("li"),kbe=a("strong"),Ogr=o("roformer"),Vgr=o(" \u2014 "),iQ=a("a"),Xgr=o("TFRoFormerModel"),zgr=o(" (RoFormer model)"),Wgr=l(),GT=a("li"),Sbe=a("strong"),Qgr=o("speech_to_text"),Hgr=o(" \u2014 "),dQ=a("a"),Ugr=o("TFSpeech2TextModel"),Jgr=o(" (Speech2Text model)"),Ygr=l(),OT=a("li"),Rbe=a("strong"),Kgr=o("swin"),Zgr=o(" \u2014 "),cQ=a("a"),ehr=o("TFSwinModel"),ohr=o(" (Swin model)"),rhr=l(),VT=a("li"),Pbe=a("strong"),thr=o("t5"),ahr=o(" \u2014 "),fQ=a("a"),nhr=o("TFT5Model"),shr=o(" (T5 model)"),lhr=l(),XT=a("li"),Bbe=a("strong"),ihr=o("tapas"),dhr=o(" \u2014 "),mQ=a("a"),chr=o("TFTapasModel"),fhr=o(" (TAPAS model)"),mhr=l(),zT=a("li"),Ibe=a("strong"),ghr=o("transfo-xl"),hhr=o(" \u2014 "),gQ=a("a"),phr=o("TFTransfoXLModel"),_hr=o(" (Transformer-XL model)"),uhr=l(),WT=a("li"),Nbe=a("strong"),bhr=o("vit"),vhr=o(" \u2014 "),hQ=a("a"),Fhr=o("TFViTModel"),Thr=o(" (ViT model)"),Mhr=l(),QT=a("li"),qbe=a("strong"),Ehr=o("vit_mae"),Chr=o(" \u2014 "),pQ=a("a"),whr=o("TFViTMAEModel"),Ahr=o(" (ViTMAE model)"),yhr=l(),HT=a("li"),jbe=a("strong"),Lhr=o("wav2vec2"),xhr=o(" \u2014 "),_Q=a("a"),$hr=o("TFWav2Vec2Model"),khr=o(" (Wav2Vec2 model)"),Shr=l(),UT=a("li"),Dbe=a("strong"),Rhr=o("xlm"),Phr=o(" \u2014 "),uQ=a("a"),Bhr=o("TFXLMModel"),Ihr=o(" (XLM model)"),Nhr=l(),JT=a("li"),Gbe=a("strong"),qhr=o("xlm-roberta"),jhr=o(" \u2014 "),bQ=a("a"),Dhr=o("TFXLMRobertaModel"),Ghr=o(" (XLM-RoBERTa model)"),Ohr=l(),YT=a("li"),Obe=a("strong"),Vhr=o("xlnet"),Xhr=o(" \u2014 "),vQ=a("a"),zhr=o("TFXLNetModel"),Whr=o(" (XLNet model)"),Qhr=l(),F(KT.$$.fragment),Vje=l(),Wd=a("h2"),ZT=a("a"),Vbe=a("span"),F(M8.$$.fragment),Hhr=l(),Xbe=a("span"),Uhr=o("TFAutoModelForPreTraining"),Xje=l(),Ko=a("div"),F(E8.$$.fragment),Jhr=l(),Qd=a("p"),Yhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),FQ=a("a"),Khr=o("from_pretrained()"),Zhr=o(" class method or the "),TQ=a("a"),epr=o("from_config()"),opr=o(` class
method.`),rpr=l(),C8=a("p"),tpr=o("This class cannot be instantiated directly using "),zbe=a("code"),apr=o("__init__()"),npr=o(" (throws an error)."),spr=l(),Lt=a("div"),F(w8.$$.fragment),lpr=l(),Wbe=a("p"),ipr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),dpr=l(),Hd=a("p"),cpr=o(`Note:
Loading a model from its configuration file does `),Qbe=a("strong"),fpr=o("not"),mpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MQ=a("a"),gpr=o("from_pretrained()"),hpr=o(" to load the model weights."),ppr=l(),F(e7.$$.fragment),_pr=l(),Ar=a("div"),F(A8.$$.fragment),upr=l(),Hbe=a("p"),bpr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),vpr=l(),Za=a("p"),Fpr=o("The model class to instantiate is selected based on the "),Ube=a("code"),Tpr=o("model_type"),Mpr=o(` property of the config object (either
passed as an argument or loaded from `),Jbe=a("code"),Epr=o("pretrained_model_name_or_path"),Cpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ybe=a("code"),wpr=o("pretrained_model_name_or_path"),Apr=o(":"),ypr=l(),se=a("ul"),o7=a("li"),Kbe=a("strong"),Lpr=o("albert"),xpr=o(" \u2014 "),EQ=a("a"),$pr=o("TFAlbertForPreTraining"),kpr=o(" (ALBERT model)"),Spr=l(),r7=a("li"),Zbe=a("strong"),Rpr=o("bart"),Ppr=o(" \u2014 "),CQ=a("a"),Bpr=o("TFBartForConditionalGeneration"),Ipr=o(" (BART model)"),Npr=l(),t7=a("li"),e4e=a("strong"),qpr=o("bert"),jpr=o(" \u2014 "),wQ=a("a"),Dpr=o("TFBertForPreTraining"),Gpr=o(" (BERT model)"),Opr=l(),a7=a("li"),o4e=a("strong"),Vpr=o("camembert"),Xpr=o(" \u2014 "),AQ=a("a"),zpr=o("TFCamembertForMaskedLM"),Wpr=o(" (CamemBERT model)"),Qpr=l(),n7=a("li"),r4e=a("strong"),Hpr=o("ctrl"),Upr=o(" \u2014 "),yQ=a("a"),Jpr=o("TFCTRLLMHeadModel"),Ypr=o(" (CTRL model)"),Kpr=l(),s7=a("li"),t4e=a("strong"),Zpr=o("distilbert"),e_r=o(" \u2014 "),LQ=a("a"),o_r=o("TFDistilBertForMaskedLM"),r_r=o(" (DistilBERT model)"),t_r=l(),l7=a("li"),a4e=a("strong"),a_r=o("electra"),n_r=o(" \u2014 "),xQ=a("a"),s_r=o("TFElectraForPreTraining"),l_r=o(" (ELECTRA model)"),i_r=l(),i7=a("li"),n4e=a("strong"),d_r=o("flaubert"),c_r=o(" \u2014 "),$Q=a("a"),f_r=o("TFFlaubertWithLMHeadModel"),m_r=o(" (FlauBERT model)"),g_r=l(),d7=a("li"),s4e=a("strong"),h_r=o("funnel"),p_r=o(" \u2014 "),kQ=a("a"),__r=o("TFFunnelForPreTraining"),u_r=o(" (Funnel Transformer model)"),b_r=l(),c7=a("li"),l4e=a("strong"),v_r=o("gpt2"),F_r=o(" \u2014 "),SQ=a("a"),T_r=o("TFGPT2LMHeadModel"),M_r=o(" (OpenAI GPT-2 model)"),E_r=l(),f7=a("li"),i4e=a("strong"),C_r=o("layoutlm"),w_r=o(" \u2014 "),RQ=a("a"),A_r=o("TFLayoutLMForMaskedLM"),y_r=o(" (LayoutLM model)"),L_r=l(),m7=a("li"),d4e=a("strong"),x_r=o("lxmert"),$_r=o(" \u2014 "),PQ=a("a"),k_r=o("TFLxmertForPreTraining"),S_r=o(" (LXMERT model)"),R_r=l(),g7=a("li"),c4e=a("strong"),P_r=o("mobilebert"),B_r=o(" \u2014 "),BQ=a("a"),I_r=o("TFMobileBertForPreTraining"),N_r=o(" (MobileBERT model)"),q_r=l(),h7=a("li"),f4e=a("strong"),j_r=o("mpnet"),D_r=o(" \u2014 "),IQ=a("a"),G_r=o("TFMPNetForMaskedLM"),O_r=o(" (MPNet model)"),V_r=l(),p7=a("li"),m4e=a("strong"),X_r=o("openai-gpt"),z_r=o(" \u2014 "),NQ=a("a"),W_r=o("TFOpenAIGPTLMHeadModel"),Q_r=o(" (OpenAI GPT model)"),H_r=l(),_7=a("li"),g4e=a("strong"),U_r=o("roberta"),J_r=o(" \u2014 "),qQ=a("a"),Y_r=o("TFRobertaForMaskedLM"),K_r=o(" (RoBERTa model)"),Z_r=l(),u7=a("li"),h4e=a("strong"),eur=o("t5"),our=o(" \u2014 "),jQ=a("a"),rur=o("TFT5ForConditionalGeneration"),tur=o(" (T5 model)"),aur=l(),b7=a("li"),p4e=a("strong"),nur=o("tapas"),sur=o(" \u2014 "),DQ=a("a"),lur=o("TFTapasForMaskedLM"),iur=o(" (TAPAS model)"),dur=l(),v7=a("li"),_4e=a("strong"),cur=o("transfo-xl"),fur=o(" \u2014 "),GQ=a("a"),mur=o("TFTransfoXLLMHeadModel"),gur=o(" (Transformer-XL model)"),hur=l(),F7=a("li"),u4e=a("strong"),pur=o("vit_mae"),_ur=o(" \u2014 "),OQ=a("a"),uur=o("TFViTMAEForPreTraining"),bur=o(" (ViTMAE model)"),vur=l(),T7=a("li"),b4e=a("strong"),Fur=o("xlm"),Tur=o(" \u2014 "),VQ=a("a"),Mur=o("TFXLMWithLMHeadModel"),Eur=o(" (XLM model)"),Cur=l(),M7=a("li"),v4e=a("strong"),wur=o("xlm-roberta"),Aur=o(" \u2014 "),XQ=a("a"),yur=o("TFXLMRobertaForMaskedLM"),Lur=o(" (XLM-RoBERTa model)"),xur=l(),E7=a("li"),F4e=a("strong"),$ur=o("xlnet"),kur=o(" \u2014 "),zQ=a("a"),Sur=o("TFXLNetLMHeadModel"),Rur=o(" (XLNet model)"),Pur=l(),F(C7.$$.fragment),zje=l(),Ud=a("h2"),w7=a("a"),T4e=a("span"),F(y8.$$.fragment),Bur=l(),M4e=a("span"),Iur=o("TFAutoModelForCausalLM"),Wje=l(),Zo=a("div"),F(L8.$$.fragment),Nur=l(),Jd=a("p"),qur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),WQ=a("a"),jur=o("from_pretrained()"),Dur=o(" class method or the "),QQ=a("a"),Gur=o("from_config()"),Our=o(` class
method.`),Vur=l(),x8=a("p"),Xur=o("This class cannot be instantiated directly using "),E4e=a("code"),zur=o("__init__()"),Wur=o(" (throws an error)."),Qur=l(),xt=a("div"),F($8.$$.fragment),Hur=l(),C4e=a("p"),Uur=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Jur=l(),Yd=a("p"),Yur=o(`Note:
Loading a model from its configuration file does `),w4e=a("strong"),Kur=o("not"),Zur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HQ=a("a"),e2r=o("from_pretrained()"),o2r=o(" to load the model weights."),r2r=l(),F(A7.$$.fragment),t2r=l(),yr=a("div"),F(k8.$$.fragment),a2r=l(),A4e=a("p"),n2r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),s2r=l(),en=a("p"),l2r=o("The model class to instantiate is selected based on the "),y4e=a("code"),i2r=o("model_type"),d2r=o(` property of the config object (either
passed as an argument or loaded from `),L4e=a("code"),c2r=o("pretrained_model_name_or_path"),f2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x4e=a("code"),m2r=o("pretrained_model_name_or_path"),g2r=o(":"),h2r=l(),Me=a("ul"),y7=a("li"),$4e=a("strong"),p2r=o("bert"),_2r=o(" \u2014 "),UQ=a("a"),u2r=o("TFBertLMHeadModel"),b2r=o(" (BERT model)"),v2r=l(),L7=a("li"),k4e=a("strong"),F2r=o("camembert"),T2r=o(" \u2014 "),JQ=a("a"),M2r=o("TFCamembertForCausalLM"),E2r=o(" (CamemBERT model)"),C2r=l(),x7=a("li"),S4e=a("strong"),w2r=o("ctrl"),A2r=o(" \u2014 "),YQ=a("a"),y2r=o("TFCTRLLMHeadModel"),L2r=o(" (CTRL model)"),x2r=l(),$7=a("li"),R4e=a("strong"),$2r=o("gpt2"),k2r=o(" \u2014 "),KQ=a("a"),S2r=o("TFGPT2LMHeadModel"),R2r=o(" (OpenAI GPT-2 model)"),P2r=l(),k7=a("li"),P4e=a("strong"),B2r=o("gptj"),I2r=o(" \u2014 "),ZQ=a("a"),N2r=o("TFGPTJForCausalLM"),q2r=o(" (GPT-J model)"),j2r=l(),S7=a("li"),B4e=a("strong"),D2r=o("openai-gpt"),G2r=o(" \u2014 "),eH=a("a"),O2r=o("TFOpenAIGPTLMHeadModel"),V2r=o(" (OpenAI GPT model)"),X2r=l(),R7=a("li"),I4e=a("strong"),z2r=o("opt"),W2r=o(" \u2014 "),oH=a("a"),Q2r=o("TFOPTForCausalLM"),H2r=o(" (OPT model)"),U2r=l(),P7=a("li"),N4e=a("strong"),J2r=o("rembert"),Y2r=o(" \u2014 "),rH=a("a"),K2r=o("TFRemBertForCausalLM"),Z2r=o(" (RemBERT model)"),e1r=l(),B7=a("li"),q4e=a("strong"),o1r=o("roberta"),r1r=o(" \u2014 "),tH=a("a"),t1r=o("TFRobertaForCausalLM"),a1r=o(" (RoBERTa model)"),n1r=l(),I7=a("li"),j4e=a("strong"),s1r=o("roformer"),l1r=o(" \u2014 "),aH=a("a"),i1r=o("TFRoFormerForCausalLM"),d1r=o(" (RoFormer model)"),c1r=l(),N7=a("li"),D4e=a("strong"),f1r=o("transfo-xl"),m1r=o(" \u2014 "),nH=a("a"),g1r=o("TFTransfoXLLMHeadModel"),h1r=o(" (Transformer-XL model)"),p1r=l(),q7=a("li"),G4e=a("strong"),_1r=o("xlm"),u1r=o(" \u2014 "),sH=a("a"),b1r=o("TFXLMWithLMHeadModel"),v1r=o(" (XLM model)"),F1r=l(),j7=a("li"),O4e=a("strong"),T1r=o("xlnet"),M1r=o(" \u2014 "),lH=a("a"),E1r=o("TFXLNetLMHeadModel"),C1r=o(" (XLNet model)"),w1r=l(),F(D7.$$.fragment),Qje=l(),Kd=a("h2"),G7=a("a"),V4e=a("span"),F(S8.$$.fragment),A1r=l(),X4e=a("span"),y1r=o("TFAutoModelForImageClassification"),Hje=l(),er=a("div"),F(R8.$$.fragment),L1r=l(),Zd=a("p"),x1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iH=a("a"),$1r=o("from_pretrained()"),k1r=o(" class method or the "),dH=a("a"),S1r=o("from_config()"),R1r=o(` class
method.`),P1r=l(),P8=a("p"),B1r=o("This class cannot be instantiated directly using "),z4e=a("code"),I1r=o("__init__()"),N1r=o(" (throws an error)."),q1r=l(),$t=a("div"),F(B8.$$.fragment),j1r=l(),W4e=a("p"),D1r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),G1r=l(),ec=a("p"),O1r=o(`Note:
Loading a model from its configuration file does `),Q4e=a("strong"),V1r=o("not"),X1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=a("a"),z1r=o("from_pretrained()"),W1r=o(" to load the model weights."),Q1r=l(),F(O7.$$.fragment),H1r=l(),Lr=a("div"),F(I8.$$.fragment),U1r=l(),H4e=a("p"),J1r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Y1r=l(),on=a("p"),K1r=o("The model class to instantiate is selected based on the "),U4e=a("code"),Z1r=o("model_type"),ebr=o(` property of the config object (either
passed as an argument or loaded from `),J4e=a("code"),obr=o("pretrained_model_name_or_path"),rbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y4e=a("code"),tbr=o("pretrained_model_name_or_path"),abr=o(":"),nbr=l(),rn=a("ul"),V7=a("li"),K4e=a("strong"),sbr=o("convnext"),lbr=o(" \u2014 "),fH=a("a"),ibr=o("TFConvNextForImageClassification"),dbr=o(" (ConvNext model)"),cbr=l(),X7=a("li"),Z4e=a("strong"),fbr=o("data2vec-vision"),mbr=o(" \u2014 "),mH=a("a"),gbr=o("TFData2VecVisionForImageClassification"),hbr=o(" (Data2VecVision model)"),pbr=l(),z7=a("li"),eve=a("strong"),_br=o("swin"),ubr=o(" \u2014 "),gH=a("a"),bbr=o("TFSwinForImageClassification"),vbr=o(" (Swin model)"),Fbr=l(),W7=a("li"),ove=a("strong"),Tbr=o("vit"),Mbr=o(" \u2014 "),hH=a("a"),Ebr=o("TFViTForImageClassification"),Cbr=o(" (ViT model)"),wbr=l(),F(Q7.$$.fragment),Uje=l(),oc=a("h2"),H7=a("a"),rve=a("span"),F(N8.$$.fragment),Abr=l(),tve=a("span"),ybr=o("TFAutoModelForMaskedLM"),Jje=l(),or=a("div"),F(q8.$$.fragment),Lbr=l(),rc=a("p"),xbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pH=a("a"),$br=o("from_pretrained()"),kbr=o(" class method or the "),_H=a("a"),Sbr=o("from_config()"),Rbr=o(` class
method.`),Pbr=l(),j8=a("p"),Bbr=o("This class cannot be instantiated directly using "),ave=a("code"),Ibr=o("__init__()"),Nbr=o(" (throws an error)."),qbr=l(),kt=a("div"),F(D8.$$.fragment),jbr=l(),nve=a("p"),Dbr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gbr=l(),tc=a("p"),Obr=o(`Note:
Loading a model from its configuration file does `),sve=a("strong"),Vbr=o("not"),Xbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uH=a("a"),zbr=o("from_pretrained()"),Wbr=o(" to load the model weights."),Qbr=l(),F(U7.$$.fragment),Hbr=l(),xr=a("div"),F(G8.$$.fragment),Ubr=l(),lve=a("p"),Jbr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Ybr=l(),tn=a("p"),Kbr=o("The model class to instantiate is selected based on the "),ive=a("code"),Zbr=o("model_type"),e4r=o(` property of the config object (either
passed as an argument or loaded from `),dve=a("code"),o4r=o("pretrained_model_name_or_path"),r4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cve=a("code"),t4r=o("pretrained_model_name_or_path"),a4r=o(":"),n4r=l(),ie=a("ul"),J7=a("li"),fve=a("strong"),s4r=o("albert"),l4r=o(" \u2014 "),bH=a("a"),i4r=o("TFAlbertForMaskedLM"),d4r=o(" (ALBERT model)"),c4r=l(),Y7=a("li"),mve=a("strong"),f4r=o("bert"),m4r=o(" \u2014 "),vH=a("a"),g4r=o("TFBertForMaskedLM"),h4r=o(" (BERT model)"),p4r=l(),K7=a("li"),gve=a("strong"),_4r=o("camembert"),u4r=o(" \u2014 "),FH=a("a"),b4r=o("TFCamembertForMaskedLM"),v4r=o(" (CamemBERT model)"),F4r=l(),Z7=a("li"),hve=a("strong"),T4r=o("convbert"),M4r=o(" \u2014 "),TH=a("a"),E4r=o("TFConvBertForMaskedLM"),C4r=o(" (ConvBERT model)"),w4r=l(),eM=a("li"),pve=a("strong"),A4r=o("deberta"),y4r=o(" \u2014 "),MH=a("a"),L4r=o("TFDebertaForMaskedLM"),x4r=o(" (DeBERTa model)"),$4r=l(),oM=a("li"),_ve=a("strong"),k4r=o("deberta-v2"),S4r=o(" \u2014 "),EH=a("a"),R4r=o("TFDebertaV2ForMaskedLM"),P4r=o(" (DeBERTa-v2 model)"),B4r=l(),rM=a("li"),uve=a("strong"),I4r=o("distilbert"),N4r=o(" \u2014 "),CH=a("a"),q4r=o("TFDistilBertForMaskedLM"),j4r=o(" (DistilBERT model)"),D4r=l(),tM=a("li"),bve=a("strong"),G4r=o("electra"),O4r=o(" \u2014 "),wH=a("a"),V4r=o("TFElectraForMaskedLM"),X4r=o(" (ELECTRA model)"),z4r=l(),aM=a("li"),vve=a("strong"),W4r=o("flaubert"),Q4r=o(" \u2014 "),AH=a("a"),H4r=o("TFFlaubertWithLMHeadModel"),U4r=o(" (FlauBERT model)"),J4r=l(),nM=a("li"),Fve=a("strong"),Y4r=o("funnel"),K4r=o(" \u2014 "),yH=a("a"),Z4r=o("TFFunnelForMaskedLM"),evr=o(" (Funnel Transformer model)"),ovr=l(),sM=a("li"),Tve=a("strong"),rvr=o("layoutlm"),tvr=o(" \u2014 "),LH=a("a"),avr=o("TFLayoutLMForMaskedLM"),nvr=o(" (LayoutLM model)"),svr=l(),lM=a("li"),Mve=a("strong"),lvr=o("longformer"),ivr=o(" \u2014 "),xH=a("a"),dvr=o("TFLongformerForMaskedLM"),cvr=o(" (Longformer model)"),fvr=l(),iM=a("li"),Eve=a("strong"),mvr=o("mobilebert"),gvr=o(" \u2014 "),$H=a("a"),hvr=o("TFMobileBertForMaskedLM"),pvr=o(" (MobileBERT model)"),_vr=l(),dM=a("li"),Cve=a("strong"),uvr=o("mpnet"),bvr=o(" \u2014 "),kH=a("a"),vvr=o("TFMPNetForMaskedLM"),Fvr=o(" (MPNet model)"),Tvr=l(),cM=a("li"),wve=a("strong"),Mvr=o("rembert"),Evr=o(" \u2014 "),SH=a("a"),Cvr=o("TFRemBertForMaskedLM"),wvr=o(" (RemBERT model)"),Avr=l(),fM=a("li"),Ave=a("strong"),yvr=o("roberta"),Lvr=o(" \u2014 "),RH=a("a"),xvr=o("TFRobertaForMaskedLM"),$vr=o(" (RoBERTa model)"),kvr=l(),mM=a("li"),yve=a("strong"),Svr=o("roformer"),Rvr=o(" \u2014 "),PH=a("a"),Pvr=o("TFRoFormerForMaskedLM"),Bvr=o(" (RoFormer model)"),Ivr=l(),gM=a("li"),Lve=a("strong"),Nvr=o("tapas"),qvr=o(" \u2014 "),BH=a("a"),jvr=o("TFTapasForMaskedLM"),Dvr=o(" (TAPAS model)"),Gvr=l(),hM=a("li"),xve=a("strong"),Ovr=o("xlm"),Vvr=o(" \u2014 "),IH=a("a"),Xvr=o("TFXLMWithLMHeadModel"),zvr=o(" (XLM model)"),Wvr=l(),pM=a("li"),$ve=a("strong"),Qvr=o("xlm-roberta"),Hvr=o(" \u2014 "),NH=a("a"),Uvr=o("TFXLMRobertaForMaskedLM"),Jvr=o(" (XLM-RoBERTa model)"),Yvr=l(),F(_M.$$.fragment),Yje=l(),ac=a("h2"),uM=a("a"),kve=a("span"),F(O8.$$.fragment),Kvr=l(),Sve=a("span"),Zvr=o("TFAutoModelForSeq2SeqLM"),Kje=l(),rr=a("div"),F(V8.$$.fragment),e5r=l(),nc=a("p"),o5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qH=a("a"),r5r=o("from_pretrained()"),t5r=o(" class method or the "),jH=a("a"),a5r=o("from_config()"),n5r=o(` class
method.`),s5r=l(),X8=a("p"),l5r=o("This class cannot be instantiated directly using "),Rve=a("code"),i5r=o("__init__()"),d5r=o(" (throws an error)."),c5r=l(),St=a("div"),F(z8.$$.fragment),f5r=l(),Pve=a("p"),m5r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),g5r=l(),sc=a("p"),h5r=o(`Note:
Loading a model from its configuration file does `),Bve=a("strong"),p5r=o("not"),_5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DH=a("a"),u5r=o("from_pretrained()"),b5r=o(" to load the model weights."),v5r=l(),F(bM.$$.fragment),F5r=l(),$r=a("div"),F(W8.$$.fragment),T5r=l(),Ive=a("p"),M5r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),E5r=l(),an=a("p"),C5r=o("The model class to instantiate is selected based on the "),Nve=a("code"),w5r=o("model_type"),A5r=o(` property of the config object (either
passed as an argument or loaded from `),qve=a("code"),y5r=o("pretrained_model_name_or_path"),L5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jve=a("code"),x5r=o("pretrained_model_name_or_path"),$5r=o(":"),k5r=l(),ye=a("ul"),vM=a("li"),Dve=a("strong"),S5r=o("bart"),R5r=o(" \u2014 "),GH=a("a"),P5r=o("TFBartForConditionalGeneration"),B5r=o(" (BART model)"),I5r=l(),FM=a("li"),Gve=a("strong"),N5r=o("blenderbot"),q5r=o(" \u2014 "),OH=a("a"),j5r=o("TFBlenderbotForConditionalGeneration"),D5r=o(" (Blenderbot model)"),G5r=l(),TM=a("li"),Ove=a("strong"),O5r=o("blenderbot-small"),V5r=o(" \u2014 "),VH=a("a"),X5r=o("TFBlenderbotSmallForConditionalGeneration"),z5r=o(" (BlenderbotSmall model)"),W5r=l(),MM=a("li"),Vve=a("strong"),Q5r=o("encoder-decoder"),H5r=o(" \u2014 "),XH=a("a"),U5r=o("TFEncoderDecoderModel"),J5r=o(" (Encoder decoder model)"),Y5r=l(),EM=a("li"),Xve=a("strong"),K5r=o("led"),Z5r=o(" \u2014 "),zH=a("a"),eFr=o("TFLEDForConditionalGeneration"),oFr=o(" (LED model)"),rFr=l(),CM=a("li"),zve=a("strong"),tFr=o("marian"),aFr=o(" \u2014 "),WH=a("a"),nFr=o("TFMarianMTModel"),sFr=o(" (Marian model)"),lFr=l(),wM=a("li"),Wve=a("strong"),iFr=o("mbart"),dFr=o(" \u2014 "),QH=a("a"),cFr=o("TFMBartForConditionalGeneration"),fFr=o(" (mBART model)"),mFr=l(),AM=a("li"),Qve=a("strong"),gFr=o("mt5"),hFr=o(" \u2014 "),HH=a("a"),pFr=o("TFMT5ForConditionalGeneration"),_Fr=o(" (mT5 model)"),uFr=l(),yM=a("li"),Hve=a("strong"),bFr=o("pegasus"),vFr=o(" \u2014 "),UH=a("a"),FFr=o("TFPegasusForConditionalGeneration"),TFr=o(" (Pegasus model)"),MFr=l(),LM=a("li"),Uve=a("strong"),EFr=o("t5"),CFr=o(" \u2014 "),JH=a("a"),wFr=o("TFT5ForConditionalGeneration"),AFr=o(" (T5 model)"),yFr=l(),F(xM.$$.fragment),Zje=l(),lc=a("h2"),$M=a("a"),Jve=a("span"),F(Q8.$$.fragment),LFr=l(),Yve=a("span"),xFr=o("TFAutoModelForSequenceClassification"),eDe=l(),tr=a("div"),F(H8.$$.fragment),$Fr=l(),ic=a("p"),kFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),YH=a("a"),SFr=o("from_pretrained()"),RFr=o(" class method or the "),KH=a("a"),PFr=o("from_config()"),BFr=o(` class
method.`),IFr=l(),U8=a("p"),NFr=o("This class cannot be instantiated directly using "),Kve=a("code"),qFr=o("__init__()"),jFr=o(" (throws an error)."),DFr=l(),Rt=a("div"),F(J8.$$.fragment),GFr=l(),Zve=a("p"),OFr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),VFr=l(),dc=a("p"),XFr=o(`Note:
Loading a model from its configuration file does `),e5e=a("strong"),zFr=o("not"),WFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=a("a"),QFr=o("from_pretrained()"),HFr=o(" to load the model weights."),UFr=l(),F(kM.$$.fragment),JFr=l(),kr=a("div"),F(Y8.$$.fragment),YFr=l(),o5e=a("p"),KFr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ZFr=l(),nn=a("p"),eTr=o("The model class to instantiate is selected based on the "),r5e=a("code"),oTr=o("model_type"),rTr=o(` property of the config object (either
passed as an argument or loaded from `),t5e=a("code"),tTr=o("pretrained_model_name_or_path"),aTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a5e=a("code"),nTr=o("pretrained_model_name_or_path"),sTr=o(":"),lTr=l(),oe=a("ul"),SM=a("li"),n5e=a("strong"),iTr=o("albert"),dTr=o(" \u2014 "),eU=a("a"),cTr=o("TFAlbertForSequenceClassification"),fTr=o(" (ALBERT model)"),mTr=l(),RM=a("li"),s5e=a("strong"),gTr=o("bert"),hTr=o(" \u2014 "),oU=a("a"),pTr=o("TFBertForSequenceClassification"),_Tr=o(" (BERT model)"),uTr=l(),PM=a("li"),l5e=a("strong"),bTr=o("camembert"),vTr=o(" \u2014 "),rU=a("a"),FTr=o("TFCamembertForSequenceClassification"),TTr=o(" (CamemBERT model)"),MTr=l(),BM=a("li"),i5e=a("strong"),ETr=o("convbert"),CTr=o(" \u2014 "),tU=a("a"),wTr=o("TFConvBertForSequenceClassification"),ATr=o(" (ConvBERT model)"),yTr=l(),IM=a("li"),d5e=a("strong"),LTr=o("ctrl"),xTr=o(" \u2014 "),aU=a("a"),$Tr=o("TFCTRLForSequenceClassification"),kTr=o(" (CTRL model)"),STr=l(),NM=a("li"),c5e=a("strong"),RTr=o("deberta"),PTr=o(" \u2014 "),nU=a("a"),BTr=o("TFDebertaForSequenceClassification"),ITr=o(" (DeBERTa model)"),NTr=l(),qM=a("li"),f5e=a("strong"),qTr=o("deberta-v2"),jTr=o(" \u2014 "),sU=a("a"),DTr=o("TFDebertaV2ForSequenceClassification"),GTr=o(" (DeBERTa-v2 model)"),OTr=l(),jM=a("li"),m5e=a("strong"),VTr=o("distilbert"),XTr=o(" \u2014 "),lU=a("a"),zTr=o("TFDistilBertForSequenceClassification"),WTr=o(" (DistilBERT model)"),QTr=l(),DM=a("li"),g5e=a("strong"),HTr=o("electra"),UTr=o(" \u2014 "),iU=a("a"),JTr=o("TFElectraForSequenceClassification"),YTr=o(" (ELECTRA model)"),KTr=l(),GM=a("li"),h5e=a("strong"),ZTr=o("flaubert"),e7r=o(" \u2014 "),dU=a("a"),o7r=o("TFFlaubertForSequenceClassification"),r7r=o(" (FlauBERT model)"),t7r=l(),OM=a("li"),p5e=a("strong"),a7r=o("funnel"),n7r=o(" \u2014 "),cU=a("a"),s7r=o("TFFunnelForSequenceClassification"),l7r=o(" (Funnel Transformer model)"),i7r=l(),VM=a("li"),_5e=a("strong"),d7r=o("gpt2"),c7r=o(" \u2014 "),fU=a("a"),f7r=o("TFGPT2ForSequenceClassification"),m7r=o(" (OpenAI GPT-2 model)"),g7r=l(),XM=a("li"),u5e=a("strong"),h7r=o("gptj"),p7r=o(" \u2014 "),mU=a("a"),_7r=o("TFGPTJForSequenceClassification"),u7r=o(" (GPT-J model)"),b7r=l(),zM=a("li"),b5e=a("strong"),v7r=o("layoutlm"),F7r=o(" \u2014 "),gU=a("a"),T7r=o("TFLayoutLMForSequenceClassification"),M7r=o(" (LayoutLM model)"),E7r=l(),WM=a("li"),v5e=a("strong"),C7r=o("longformer"),w7r=o(" \u2014 "),hU=a("a"),A7r=o("TFLongformerForSequenceClassification"),y7r=o(" (Longformer model)"),L7r=l(),QM=a("li"),F5e=a("strong"),x7r=o("mobilebert"),$7r=o(" \u2014 "),pU=a("a"),k7r=o("TFMobileBertForSequenceClassification"),S7r=o(" (MobileBERT model)"),R7r=l(),HM=a("li"),T5e=a("strong"),P7r=o("mpnet"),B7r=o(" \u2014 "),_U=a("a"),I7r=o("TFMPNetForSequenceClassification"),N7r=o(" (MPNet model)"),q7r=l(),UM=a("li"),M5e=a("strong"),j7r=o("openai-gpt"),D7r=o(" \u2014 "),uU=a("a"),G7r=o("TFOpenAIGPTForSequenceClassification"),O7r=o(" (OpenAI GPT model)"),V7r=l(),JM=a("li"),E5e=a("strong"),X7r=o("rembert"),z7r=o(" \u2014 "),bU=a("a"),W7r=o("TFRemBertForSequenceClassification"),Q7r=o(" (RemBERT model)"),H7r=l(),YM=a("li"),C5e=a("strong"),U7r=o("roberta"),J7r=o(" \u2014 "),vU=a("a"),Y7r=o("TFRobertaForSequenceClassification"),K7r=o(" (RoBERTa model)"),Z7r=l(),KM=a("li"),w5e=a("strong"),eMr=o("roformer"),oMr=o(" \u2014 "),FU=a("a"),rMr=o("TFRoFormerForSequenceClassification"),tMr=o(" (RoFormer model)"),aMr=l(),ZM=a("li"),A5e=a("strong"),nMr=o("tapas"),sMr=o(" \u2014 "),TU=a("a"),lMr=o("TFTapasForSequenceClassification"),iMr=o(" (TAPAS model)"),dMr=l(),eE=a("li"),y5e=a("strong"),cMr=o("transfo-xl"),fMr=o(" \u2014 "),MU=a("a"),mMr=o("TFTransfoXLForSequenceClassification"),gMr=o(" (Transformer-XL model)"),hMr=l(),oE=a("li"),L5e=a("strong"),pMr=o("xlm"),_Mr=o(" \u2014 "),EU=a("a"),uMr=o("TFXLMForSequenceClassification"),bMr=o(" (XLM model)"),vMr=l(),rE=a("li"),x5e=a("strong"),FMr=o("xlm-roberta"),TMr=o(" \u2014 "),CU=a("a"),MMr=o("TFXLMRobertaForSequenceClassification"),EMr=o(" (XLM-RoBERTa model)"),CMr=l(),tE=a("li"),$5e=a("strong"),wMr=o("xlnet"),AMr=o(" \u2014 "),wU=a("a"),yMr=o("TFXLNetForSequenceClassification"),LMr=o(" (XLNet model)"),xMr=l(),F(aE.$$.fragment),oDe=l(),cc=a("h2"),nE=a("a"),k5e=a("span"),F(K8.$$.fragment),$Mr=l(),S5e=a("span"),kMr=o("TFAutoModelForMultipleChoice"),rDe=l(),ar=a("div"),F(Z8.$$.fragment),SMr=l(),fc=a("p"),RMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),AU=a("a"),PMr=o("from_pretrained()"),BMr=o(" class method or the "),yU=a("a"),IMr=o("from_config()"),NMr=o(` class
method.`),qMr=l(),e9=a("p"),jMr=o("This class cannot be instantiated directly using "),R5e=a("code"),DMr=o("__init__()"),GMr=o(" (throws an error)."),OMr=l(),Pt=a("div"),F(o9.$$.fragment),VMr=l(),P5e=a("p"),XMr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),zMr=l(),mc=a("p"),WMr=o(`Note:
Loading a model from its configuration file does `),B5e=a("strong"),QMr=o("not"),HMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),UMr=o("from_pretrained()"),JMr=o(" to load the model weights."),YMr=l(),F(sE.$$.fragment),KMr=l(),Sr=a("div"),F(r9.$$.fragment),ZMr=l(),I5e=a("p"),eEr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),oEr=l(),sn=a("p"),rEr=o("The model class to instantiate is selected based on the "),N5e=a("code"),tEr=o("model_type"),aEr=o(` property of the config object (either
passed as an argument or loaded from `),q5e=a("code"),nEr=o("pretrained_model_name_or_path"),sEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j5e=a("code"),lEr=o("pretrained_model_name_or_path"),iEr=o(":"),dEr=l(),pe=a("ul"),lE=a("li"),D5e=a("strong"),cEr=o("albert"),fEr=o(" \u2014 "),xU=a("a"),mEr=o("TFAlbertForMultipleChoice"),gEr=o(" (ALBERT model)"),hEr=l(),iE=a("li"),G5e=a("strong"),pEr=o("bert"),_Er=o(" \u2014 "),$U=a("a"),uEr=o("TFBertForMultipleChoice"),bEr=o(" (BERT model)"),vEr=l(),dE=a("li"),O5e=a("strong"),FEr=o("camembert"),TEr=o(" \u2014 "),kU=a("a"),MEr=o("TFCamembertForMultipleChoice"),EEr=o(" (CamemBERT model)"),CEr=l(),cE=a("li"),V5e=a("strong"),wEr=o("convbert"),AEr=o(" \u2014 "),SU=a("a"),yEr=o("TFConvBertForMultipleChoice"),LEr=o(" (ConvBERT model)"),xEr=l(),fE=a("li"),X5e=a("strong"),$Er=o("distilbert"),kEr=o(" \u2014 "),RU=a("a"),SEr=o("TFDistilBertForMultipleChoice"),REr=o(" (DistilBERT model)"),PEr=l(),mE=a("li"),z5e=a("strong"),BEr=o("electra"),IEr=o(" \u2014 "),PU=a("a"),NEr=o("TFElectraForMultipleChoice"),qEr=o(" (ELECTRA model)"),jEr=l(),gE=a("li"),W5e=a("strong"),DEr=o("flaubert"),GEr=o(" \u2014 "),BU=a("a"),OEr=o("TFFlaubertForMultipleChoice"),VEr=o(" (FlauBERT model)"),XEr=l(),hE=a("li"),Q5e=a("strong"),zEr=o("funnel"),WEr=o(" \u2014 "),IU=a("a"),QEr=o("TFFunnelForMultipleChoice"),HEr=o(" (Funnel Transformer model)"),UEr=l(),pE=a("li"),H5e=a("strong"),JEr=o("longformer"),YEr=o(" \u2014 "),NU=a("a"),KEr=o("TFLongformerForMultipleChoice"),ZEr=o(" (Longformer model)"),eCr=l(),_E=a("li"),U5e=a("strong"),oCr=o("mobilebert"),rCr=o(" \u2014 "),qU=a("a"),tCr=o("TFMobileBertForMultipleChoice"),aCr=o(" (MobileBERT model)"),nCr=l(),uE=a("li"),J5e=a("strong"),sCr=o("mpnet"),lCr=o(" \u2014 "),jU=a("a"),iCr=o("TFMPNetForMultipleChoice"),dCr=o(" (MPNet model)"),cCr=l(),bE=a("li"),Y5e=a("strong"),fCr=o("rembert"),mCr=o(" \u2014 "),DU=a("a"),gCr=o("TFRemBertForMultipleChoice"),hCr=o(" (RemBERT model)"),pCr=l(),vE=a("li"),K5e=a("strong"),_Cr=o("roberta"),uCr=o(" \u2014 "),GU=a("a"),bCr=o("TFRobertaForMultipleChoice"),vCr=o(" (RoBERTa model)"),FCr=l(),FE=a("li"),Z5e=a("strong"),TCr=o("roformer"),MCr=o(" \u2014 "),OU=a("a"),ECr=o("TFRoFormerForMultipleChoice"),CCr=o(" (RoFormer model)"),wCr=l(),TE=a("li"),eFe=a("strong"),ACr=o("xlm"),yCr=o(" \u2014 "),VU=a("a"),LCr=o("TFXLMForMultipleChoice"),xCr=o(" (XLM model)"),$Cr=l(),ME=a("li"),oFe=a("strong"),kCr=o("xlm-roberta"),SCr=o(" \u2014 "),XU=a("a"),RCr=o("TFXLMRobertaForMultipleChoice"),PCr=o(" (XLM-RoBERTa model)"),BCr=l(),EE=a("li"),rFe=a("strong"),ICr=o("xlnet"),NCr=o(" \u2014 "),zU=a("a"),qCr=o("TFXLNetForMultipleChoice"),jCr=o(" (XLNet model)"),DCr=l(),F(CE.$$.fragment),tDe=l(),gc=a("h2"),wE=a("a"),tFe=a("span"),F(t9.$$.fragment),GCr=l(),aFe=a("span"),OCr=o("TFAutoModelForNextSentencePrediction"),aDe=l(),nr=a("div"),F(a9.$$.fragment),VCr=l(),hc=a("p"),XCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),WU=a("a"),zCr=o("from_pretrained()"),WCr=o(" class method or the "),QU=a("a"),QCr=o("from_config()"),HCr=o(` class
method.`),UCr=l(),n9=a("p"),JCr=o("This class cannot be instantiated directly using "),nFe=a("code"),YCr=o("__init__()"),KCr=o(" (throws an error)."),ZCr=l(),Bt=a("div"),F(s9.$$.fragment),e3r=l(),sFe=a("p"),o3r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),r3r=l(),pc=a("p"),t3r=o(`Note:
Loading a model from its configuration file does `),lFe=a("strong"),a3r=o("not"),n3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=a("a"),s3r=o("from_pretrained()"),l3r=o(" to load the model weights."),i3r=l(),F(AE.$$.fragment),d3r=l(),Rr=a("div"),F(l9.$$.fragment),c3r=l(),iFe=a("p"),f3r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),m3r=l(),ln=a("p"),g3r=o("The model class to instantiate is selected based on the "),dFe=a("code"),h3r=o("model_type"),p3r=o(` property of the config object (either
passed as an argument or loaded from `),cFe=a("code"),_3r=o("pretrained_model_name_or_path"),u3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fFe=a("code"),b3r=o("pretrained_model_name_or_path"),v3r=o(":"),F3r=l(),i9=a("ul"),yE=a("li"),mFe=a("strong"),T3r=o("bert"),M3r=o(" \u2014 "),UU=a("a"),E3r=o("TFBertForNextSentencePrediction"),C3r=o(" (BERT model)"),w3r=l(),LE=a("li"),gFe=a("strong"),A3r=o("mobilebert"),y3r=o(" \u2014 "),JU=a("a"),L3r=o("TFMobileBertForNextSentencePrediction"),x3r=o(" (MobileBERT model)"),$3r=l(),F(xE.$$.fragment),nDe=l(),_c=a("h2"),$E=a("a"),hFe=a("span"),F(d9.$$.fragment),k3r=l(),pFe=a("span"),S3r=o("TFAutoModelForTableQuestionAnswering"),sDe=l(),sr=a("div"),F(c9.$$.fragment),R3r=l(),uc=a("p"),P3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),YU=a("a"),B3r=o("from_pretrained()"),I3r=o(" class method or the "),KU=a("a"),N3r=o("from_config()"),q3r=o(` class
method.`),j3r=l(),f9=a("p"),D3r=o("This class cannot be instantiated directly using "),_Fe=a("code"),G3r=o("__init__()"),O3r=o(" (throws an error)."),V3r=l(),It=a("div"),F(m9.$$.fragment),X3r=l(),uFe=a("p"),z3r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),W3r=l(),bc=a("p"),Q3r=o(`Note:
Loading a model from its configuration file does `),bFe=a("strong"),H3r=o("not"),U3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZU=a("a"),J3r=o("from_pretrained()"),Y3r=o(" to load the model weights."),K3r=l(),F(kE.$$.fragment),Z3r=l(),Pr=a("div"),F(g9.$$.fragment),e0r=l(),vFe=a("p"),o0r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),r0r=l(),dn=a("p"),t0r=o("The model class to instantiate is selected based on the "),FFe=a("code"),a0r=o("model_type"),n0r=o(` property of the config object (either
passed as an argument or loaded from `),TFe=a("code"),s0r=o("pretrained_model_name_or_path"),l0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MFe=a("code"),i0r=o("pretrained_model_name_or_path"),d0r=o(":"),c0r=l(),EFe=a("ul"),SE=a("li"),CFe=a("strong"),f0r=o("tapas"),m0r=o(" \u2014 "),eJ=a("a"),g0r=o("TFTapasForQuestionAnswering"),h0r=o(" (TAPAS model)"),p0r=l(),F(RE.$$.fragment),lDe=l(),vc=a("h2"),PE=a("a"),wFe=a("span"),F(h9.$$.fragment),_0r=l(),AFe=a("span"),u0r=o("TFAutoModelForTokenClassification"),iDe=l(),lr=a("div"),F(p9.$$.fragment),b0r=l(),Fc=a("p"),v0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),oJ=a("a"),F0r=o("from_pretrained()"),T0r=o(" class method or the "),rJ=a("a"),M0r=o("from_config()"),E0r=o(` class
method.`),C0r=l(),_9=a("p"),w0r=o("This class cannot be instantiated directly using "),yFe=a("code"),A0r=o("__init__()"),y0r=o(" (throws an error)."),L0r=l(),Nt=a("div"),F(u9.$$.fragment),x0r=l(),LFe=a("p"),$0r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),k0r=l(),Tc=a("p"),S0r=o(`Note:
Loading a model from its configuration file does `),xFe=a("strong"),R0r=o("not"),P0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tJ=a("a"),B0r=o("from_pretrained()"),I0r=o(" to load the model weights."),N0r=l(),F(BE.$$.fragment),q0r=l(),Br=a("div"),F(b9.$$.fragment),j0r=l(),$Fe=a("p"),D0r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),G0r=l(),cn=a("p"),O0r=o("The model class to instantiate is selected based on the "),kFe=a("code"),V0r=o("model_type"),X0r=o(` property of the config object (either
passed as an argument or loaded from `),SFe=a("code"),z0r=o("pretrained_model_name_or_path"),W0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RFe=a("code"),Q0r=o("pretrained_model_name_or_path"),H0r=o(":"),U0r=l(),de=a("ul"),IE=a("li"),PFe=a("strong"),J0r=o("albert"),Y0r=o(" \u2014 "),aJ=a("a"),K0r=o("TFAlbertForTokenClassification"),Z0r=o(" (ALBERT model)"),ewr=l(),NE=a("li"),BFe=a("strong"),owr=o("bert"),rwr=o(" \u2014 "),nJ=a("a"),twr=o("TFBertForTokenClassification"),awr=o(" (BERT model)"),nwr=l(),qE=a("li"),IFe=a("strong"),swr=o("camembert"),lwr=o(" \u2014 "),sJ=a("a"),iwr=o("TFCamembertForTokenClassification"),dwr=o(" (CamemBERT model)"),cwr=l(),jE=a("li"),NFe=a("strong"),fwr=o("convbert"),mwr=o(" \u2014 "),lJ=a("a"),gwr=o("TFConvBertForTokenClassification"),hwr=o(" (ConvBERT model)"),pwr=l(),DE=a("li"),qFe=a("strong"),_wr=o("deberta"),uwr=o(" \u2014 "),iJ=a("a"),bwr=o("TFDebertaForTokenClassification"),vwr=o(" (DeBERTa model)"),Fwr=l(),GE=a("li"),jFe=a("strong"),Twr=o("deberta-v2"),Mwr=o(" \u2014 "),dJ=a("a"),Ewr=o("TFDebertaV2ForTokenClassification"),Cwr=o(" (DeBERTa-v2 model)"),wwr=l(),OE=a("li"),DFe=a("strong"),Awr=o("distilbert"),ywr=o(" \u2014 "),cJ=a("a"),Lwr=o("TFDistilBertForTokenClassification"),xwr=o(" (DistilBERT model)"),$wr=l(),VE=a("li"),GFe=a("strong"),kwr=o("electra"),Swr=o(" \u2014 "),fJ=a("a"),Rwr=o("TFElectraForTokenClassification"),Pwr=o(" (ELECTRA model)"),Bwr=l(),XE=a("li"),OFe=a("strong"),Iwr=o("flaubert"),Nwr=o(" \u2014 "),mJ=a("a"),qwr=o("TFFlaubertForTokenClassification"),jwr=o(" (FlauBERT model)"),Dwr=l(),zE=a("li"),VFe=a("strong"),Gwr=o("funnel"),Owr=o(" \u2014 "),gJ=a("a"),Vwr=o("TFFunnelForTokenClassification"),Xwr=o(" (Funnel Transformer model)"),zwr=l(),WE=a("li"),XFe=a("strong"),Wwr=o("layoutlm"),Qwr=o(" \u2014 "),hJ=a("a"),Hwr=o("TFLayoutLMForTokenClassification"),Uwr=o(" (LayoutLM model)"),Jwr=l(),QE=a("li"),zFe=a("strong"),Ywr=o("longformer"),Kwr=o(" \u2014 "),pJ=a("a"),Zwr=o("TFLongformerForTokenClassification"),e6r=o(" (Longformer model)"),o6r=l(),HE=a("li"),WFe=a("strong"),r6r=o("mobilebert"),t6r=o(" \u2014 "),_J=a("a"),a6r=o("TFMobileBertForTokenClassification"),n6r=o(" (MobileBERT model)"),s6r=l(),UE=a("li"),QFe=a("strong"),l6r=o("mpnet"),i6r=o(" \u2014 "),uJ=a("a"),d6r=o("TFMPNetForTokenClassification"),c6r=o(" (MPNet model)"),f6r=l(),JE=a("li"),HFe=a("strong"),m6r=o("rembert"),g6r=o(" \u2014 "),bJ=a("a"),h6r=o("TFRemBertForTokenClassification"),p6r=o(" (RemBERT model)"),_6r=l(),YE=a("li"),UFe=a("strong"),u6r=o("roberta"),b6r=o(" \u2014 "),vJ=a("a"),v6r=o("TFRobertaForTokenClassification"),F6r=o(" (RoBERTa model)"),T6r=l(),KE=a("li"),JFe=a("strong"),M6r=o("roformer"),E6r=o(" \u2014 "),FJ=a("a"),C6r=o("TFRoFormerForTokenClassification"),w6r=o(" (RoFormer model)"),A6r=l(),ZE=a("li"),YFe=a("strong"),y6r=o("xlm"),L6r=o(" \u2014 "),TJ=a("a"),x6r=o("TFXLMForTokenClassification"),$6r=o(" (XLM model)"),k6r=l(),eC=a("li"),KFe=a("strong"),S6r=o("xlm-roberta"),R6r=o(" \u2014 "),MJ=a("a"),P6r=o("TFXLMRobertaForTokenClassification"),B6r=o(" (XLM-RoBERTa model)"),I6r=l(),oC=a("li"),ZFe=a("strong"),N6r=o("xlnet"),q6r=o(" \u2014 "),EJ=a("a"),j6r=o("TFXLNetForTokenClassification"),D6r=o(" (XLNet model)"),G6r=l(),F(rC.$$.fragment),dDe=l(),Mc=a("h2"),tC=a("a"),eTe=a("span"),F(v9.$$.fragment),O6r=l(),oTe=a("span"),V6r=o("TFAutoModelForQuestionAnswering"),cDe=l(),ir=a("div"),F(F9.$$.fragment),X6r=l(),Ec=a("p"),z6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),CJ=a("a"),W6r=o("from_pretrained()"),Q6r=o(" class method or the "),wJ=a("a"),H6r=o("from_config()"),U6r=o(` class
method.`),J6r=l(),T9=a("p"),Y6r=o("This class cannot be instantiated directly using "),rTe=a("code"),K6r=o("__init__()"),Z6r=o(" (throws an error)."),eAr=l(),qt=a("div"),F(M9.$$.fragment),oAr=l(),tTe=a("p"),rAr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),tAr=l(),Cc=a("p"),aAr=o(`Note:
Loading a model from its configuration file does `),aTe=a("strong"),nAr=o("not"),sAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AJ=a("a"),lAr=o("from_pretrained()"),iAr=o(" to load the model weights."),dAr=l(),F(aC.$$.fragment),cAr=l(),Ir=a("div"),F(E9.$$.fragment),fAr=l(),nTe=a("p"),mAr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),gAr=l(),fn=a("p"),hAr=o("The model class to instantiate is selected based on the "),sTe=a("code"),pAr=o("model_type"),_Ar=o(` property of the config object (either
passed as an argument or loaded from `),lTe=a("code"),uAr=o("pretrained_model_name_or_path"),bAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=a("code"),vAr=o("pretrained_model_name_or_path"),FAr=o(":"),TAr=l(),ce=a("ul"),nC=a("li"),dTe=a("strong"),MAr=o("albert"),EAr=o(" \u2014 "),yJ=a("a"),CAr=o("TFAlbertForQuestionAnswering"),wAr=o(" (ALBERT model)"),AAr=l(),sC=a("li"),cTe=a("strong"),yAr=o("bert"),LAr=o(" \u2014 "),LJ=a("a"),xAr=o("TFBertForQuestionAnswering"),$Ar=o(" (BERT model)"),kAr=l(),lC=a("li"),fTe=a("strong"),SAr=o("camembert"),RAr=o(" \u2014 "),xJ=a("a"),PAr=o("TFCamembertForQuestionAnswering"),BAr=o(" (CamemBERT model)"),IAr=l(),iC=a("li"),mTe=a("strong"),NAr=o("convbert"),qAr=o(" \u2014 "),$J=a("a"),jAr=o("TFConvBertForQuestionAnswering"),DAr=o(" (ConvBERT model)"),GAr=l(),dC=a("li"),gTe=a("strong"),OAr=o("deberta"),VAr=o(" \u2014 "),kJ=a("a"),XAr=o("TFDebertaForQuestionAnswering"),zAr=o(" (DeBERTa model)"),WAr=l(),cC=a("li"),hTe=a("strong"),QAr=o("deberta-v2"),HAr=o(" \u2014 "),SJ=a("a"),UAr=o("TFDebertaV2ForQuestionAnswering"),JAr=o(" (DeBERTa-v2 model)"),YAr=l(),fC=a("li"),pTe=a("strong"),KAr=o("distilbert"),ZAr=o(" \u2014 "),RJ=a("a"),eyr=o("TFDistilBertForQuestionAnswering"),oyr=o(" (DistilBERT model)"),ryr=l(),mC=a("li"),_Te=a("strong"),tyr=o("electra"),ayr=o(" \u2014 "),PJ=a("a"),nyr=o("TFElectraForQuestionAnswering"),syr=o(" (ELECTRA model)"),lyr=l(),gC=a("li"),uTe=a("strong"),iyr=o("flaubert"),dyr=o(" \u2014 "),BJ=a("a"),cyr=o("TFFlaubertForQuestionAnsweringSimple"),fyr=o(" (FlauBERT model)"),myr=l(),hC=a("li"),bTe=a("strong"),gyr=o("funnel"),hyr=o(" \u2014 "),IJ=a("a"),pyr=o("TFFunnelForQuestionAnswering"),_yr=o(" (Funnel Transformer model)"),uyr=l(),pC=a("li"),vTe=a("strong"),byr=o("gptj"),vyr=o(" \u2014 "),NJ=a("a"),Fyr=o("TFGPTJForQuestionAnswering"),Tyr=o(" (GPT-J model)"),Myr=l(),_C=a("li"),FTe=a("strong"),Eyr=o("longformer"),Cyr=o(" \u2014 "),qJ=a("a"),wyr=o("TFLongformerForQuestionAnswering"),Ayr=o(" (Longformer model)"),yyr=l(),uC=a("li"),TTe=a("strong"),Lyr=o("mobilebert"),xyr=o(" \u2014 "),jJ=a("a"),$yr=o("TFMobileBertForQuestionAnswering"),kyr=o(" (MobileBERT model)"),Syr=l(),bC=a("li"),MTe=a("strong"),Ryr=o("mpnet"),Pyr=o(" \u2014 "),DJ=a("a"),Byr=o("TFMPNetForQuestionAnswering"),Iyr=o(" (MPNet model)"),Nyr=l(),vC=a("li"),ETe=a("strong"),qyr=o("rembert"),jyr=o(" \u2014 "),GJ=a("a"),Dyr=o("TFRemBertForQuestionAnswering"),Gyr=o(" (RemBERT model)"),Oyr=l(),FC=a("li"),CTe=a("strong"),Vyr=o("roberta"),Xyr=o(" \u2014 "),OJ=a("a"),zyr=o("TFRobertaForQuestionAnswering"),Wyr=o(" (RoBERTa model)"),Qyr=l(),TC=a("li"),wTe=a("strong"),Hyr=o("roformer"),Uyr=o(" \u2014 "),VJ=a("a"),Jyr=o("TFRoFormerForQuestionAnswering"),Yyr=o(" (RoFormer model)"),Kyr=l(),MC=a("li"),ATe=a("strong"),Zyr=o("xlm"),eLr=o(" \u2014 "),XJ=a("a"),oLr=o("TFXLMForQuestionAnsweringSimple"),rLr=o(" (XLM model)"),tLr=l(),EC=a("li"),yTe=a("strong"),aLr=o("xlm-roberta"),nLr=o(" \u2014 "),zJ=a("a"),sLr=o("TFXLMRobertaForQuestionAnswering"),lLr=o(" (XLM-RoBERTa model)"),iLr=l(),CC=a("li"),LTe=a("strong"),dLr=o("xlnet"),cLr=o(" \u2014 "),WJ=a("a"),fLr=o("TFXLNetForQuestionAnsweringSimple"),mLr=o(" (XLNet model)"),gLr=l(),F(wC.$$.fragment),fDe=l(),wc=a("h2"),AC=a("a"),xTe=a("span"),F(C9.$$.fragment),hLr=l(),$Te=a("span"),pLr=o("TFAutoModelForVision2Seq"),mDe=l(),dr=a("div"),F(w9.$$.fragment),_Lr=l(),Ac=a("p"),uLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),QJ=a("a"),bLr=o("from_pretrained()"),vLr=o(" class method or the "),HJ=a("a"),FLr=o("from_config()"),TLr=o(` class
method.`),MLr=l(),A9=a("p"),ELr=o("This class cannot be instantiated directly using "),kTe=a("code"),CLr=o("__init__()"),wLr=o(" (throws an error)."),ALr=l(),jt=a("div"),F(y9.$$.fragment),yLr=l(),STe=a("p"),LLr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),xLr=l(),yc=a("p"),$Lr=o(`Note:
Loading a model from its configuration file does `),RTe=a("strong"),kLr=o("not"),SLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UJ=a("a"),RLr=o("from_pretrained()"),PLr=o(" to load the model weights."),BLr=l(),F(yC.$$.fragment),ILr=l(),Nr=a("div"),F(L9.$$.fragment),NLr=l(),PTe=a("p"),qLr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),jLr=l(),mn=a("p"),DLr=o("The model class to instantiate is selected based on the "),BTe=a("code"),GLr=o("model_type"),OLr=o(` property of the config object (either
passed as an argument or loaded from `),ITe=a("code"),VLr=o("pretrained_model_name_or_path"),XLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=a("code"),zLr=o("pretrained_model_name_or_path"),WLr=o(":"),QLr=l(),qTe=a("ul"),LC=a("li"),jTe=a("strong"),HLr=o("vision-encoder-decoder"),ULr=o(" \u2014 "),JJ=a("a"),JLr=o("TFVisionEncoderDecoderModel"),YLr=o(" (Vision Encoder decoder model)"),KLr=l(),F(xC.$$.fragment),gDe=l(),Lc=a("h2"),$C=a("a"),DTe=a("span"),F(x9.$$.fragment),ZLr=l(),GTe=a("span"),e8r=o("TFAutoModelForSpeechSeq2Seq"),hDe=l(),cr=a("div"),F($9.$$.fragment),o8r=l(),xc=a("p"),r8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),YJ=a("a"),t8r=o("from_pretrained()"),a8r=o(" class method or the "),KJ=a("a"),n8r=o("from_config()"),s8r=o(` class
method.`),l8r=l(),k9=a("p"),i8r=o("This class cannot be instantiated directly using "),OTe=a("code"),d8r=o("__init__()"),c8r=o(" (throws an error)."),f8r=l(),Dt=a("div"),F(S9.$$.fragment),m8r=l(),VTe=a("p"),g8r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),h8r=l(),$c=a("p"),p8r=o(`Note:
Loading a model from its configuration file does `),XTe=a("strong"),_8r=o("not"),u8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZJ=a("a"),b8r=o("from_pretrained()"),v8r=o(" to load the model weights."),F8r=l(),F(kC.$$.fragment),T8r=l(),qr=a("div"),F(R9.$$.fragment),M8r=l(),zTe=a("p"),E8r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),C8r=l(),gn=a("p"),w8r=o("The model class to instantiate is selected based on the "),WTe=a("code"),A8r=o("model_type"),y8r=o(` property of the config object (either
passed as an argument or loaded from `),QTe=a("code"),L8r=o("pretrained_model_name_or_path"),x8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HTe=a("code"),$8r=o("pretrained_model_name_or_path"),k8r=o(":"),S8r=l(),UTe=a("ul"),SC=a("li"),JTe=a("strong"),R8r=o("speech_to_text"),P8r=o(" \u2014 "),eY=a("a"),B8r=o("TFSpeech2TextForConditionalGeneration"),I8r=o(" (Speech2Text model)"),N8r=l(),F(RC.$$.fragment),pDe=l(),kc=a("h2"),PC=a("a"),YTe=a("span"),F(P9.$$.fragment),q8r=l(),KTe=a("span"),j8r=o("FlaxAutoModel"),_De=l(),fr=a("div"),F(B9.$$.fragment),D8r=l(),Sc=a("p"),G8r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oY=a("a"),O8r=o("from_pretrained()"),V8r=o(" class method or the "),rY=a("a"),X8r=o("from_config()"),z8r=o(` class
method.`),W8r=l(),I9=a("p"),Q8r=o("This class cannot be instantiated directly using "),ZTe=a("code"),H8r=o("__init__()"),U8r=o(" (throws an error)."),J8r=l(),Gt=a("div"),F(N9.$$.fragment),Y8r=l(),e7e=a("p"),K8r=o("Instantiates one of the base model classes of the library from a configuration."),Z8r=l(),Rc=a("p"),e9r=o(`Note:
Loading a model from its configuration file does `),o7e=a("strong"),o9r=o("not"),r9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=a("a"),t9r=o("from_pretrained()"),a9r=o(" to load the model weights."),n9r=l(),F(BC.$$.fragment),s9r=l(),jr=a("div"),F(q9.$$.fragment),l9r=l(),r7e=a("p"),i9r=o("Instantiate one of the base model classes of the library from a pretrained model."),d9r=l(),hn=a("p"),c9r=o("The model class to instantiate is selected based on the "),t7e=a("code"),f9r=o("model_type"),m9r=o(` property of the config object (either
passed as an argument or loaded from `),a7e=a("code"),g9r=o("pretrained_model_name_or_path"),h9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=a("code"),p9r=o("pretrained_model_name_or_path"),_9r=o(":"),u9r=l(),re=a("ul"),IC=a("li"),s7e=a("strong"),b9r=o("albert"),v9r=o(" \u2014 "),aY=a("a"),F9r=o("FlaxAlbertModel"),T9r=o(" (ALBERT model)"),M9r=l(),NC=a("li"),l7e=a("strong"),E9r=o("bart"),C9r=o(" \u2014 "),nY=a("a"),w9r=o("FlaxBartModel"),A9r=o(" (BART model)"),y9r=l(),qC=a("li"),i7e=a("strong"),L9r=o("beit"),x9r=o(" \u2014 "),sY=a("a"),$9r=o("FlaxBeitModel"),k9r=o(" (BEiT model)"),S9r=l(),jC=a("li"),d7e=a("strong"),R9r=o("bert"),P9r=o(" \u2014 "),lY=a("a"),B9r=o("FlaxBertModel"),I9r=o(" (BERT model)"),N9r=l(),DC=a("li"),c7e=a("strong"),q9r=o("big_bird"),j9r=o(" \u2014 "),iY=a("a"),D9r=o("FlaxBigBirdModel"),G9r=o(" (BigBird model)"),O9r=l(),GC=a("li"),f7e=a("strong"),V9r=o("blenderbot"),X9r=o(" \u2014 "),dY=a("a"),z9r=o("FlaxBlenderbotModel"),W9r=o(" (Blenderbot model)"),Q9r=l(),OC=a("li"),m7e=a("strong"),H9r=o("blenderbot-small"),U9r=o(" \u2014 "),cY=a("a"),J9r=o("FlaxBlenderbotSmallModel"),Y9r=o(" (BlenderbotSmall model)"),K9r=l(),VC=a("li"),g7e=a("strong"),Z9r=o("clip"),exr=o(" \u2014 "),fY=a("a"),oxr=o("FlaxCLIPModel"),rxr=o(" (CLIP model)"),txr=l(),XC=a("li"),h7e=a("strong"),axr=o("distilbert"),nxr=o(" \u2014 "),mY=a("a"),sxr=o("FlaxDistilBertModel"),lxr=o(" (DistilBERT model)"),ixr=l(),zC=a("li"),p7e=a("strong"),dxr=o("electra"),cxr=o(" \u2014 "),gY=a("a"),fxr=o("FlaxElectraModel"),mxr=o(" (ELECTRA model)"),gxr=l(),WC=a("li"),_7e=a("strong"),hxr=o("gpt2"),pxr=o(" \u2014 "),hY=a("a"),_xr=o("FlaxGPT2Model"),uxr=o(" (OpenAI GPT-2 model)"),bxr=l(),QC=a("li"),u7e=a("strong"),vxr=o("gpt_neo"),Fxr=o(" \u2014 "),pY=a("a"),Txr=o("FlaxGPTNeoModel"),Mxr=o(" (GPT Neo model)"),Exr=l(),HC=a("li"),b7e=a("strong"),Cxr=o("gptj"),wxr=o(" \u2014 "),_Y=a("a"),Axr=o("FlaxGPTJModel"),yxr=o(" (GPT-J model)"),Lxr=l(),UC=a("li"),v7e=a("strong"),xxr=o("marian"),$xr=o(" \u2014 "),uY=a("a"),kxr=o("FlaxMarianModel"),Sxr=o(" (Marian model)"),Rxr=l(),JC=a("li"),F7e=a("strong"),Pxr=o("mbart"),Bxr=o(" \u2014 "),bY=a("a"),Ixr=o("FlaxMBartModel"),Nxr=o(" (mBART model)"),qxr=l(),YC=a("li"),T7e=a("strong"),jxr=o("mt5"),Dxr=o(" \u2014 "),vY=a("a"),Gxr=o("FlaxMT5Model"),Oxr=o(" (mT5 model)"),Vxr=l(),KC=a("li"),M7e=a("strong"),Xxr=o("opt"),zxr=o(" \u2014 "),FY=a("a"),Wxr=o("FlaxOPTModel"),Qxr=o(" (OPT model)"),Hxr=l(),ZC=a("li"),E7e=a("strong"),Uxr=o("pegasus"),Jxr=o(" \u2014 "),TY=a("a"),Yxr=o("FlaxPegasusModel"),Kxr=o(" (Pegasus model)"),Zxr=l(),e3=a("li"),C7e=a("strong"),e$r=o("roberta"),o$r=o(" \u2014 "),MY=a("a"),r$r=o("FlaxRobertaModel"),t$r=o(" (RoBERTa model)"),a$r=l(),o3=a("li"),w7e=a("strong"),n$r=o("roformer"),s$r=o(" \u2014 "),EY=a("a"),l$r=o("FlaxRoFormerModel"),i$r=o(" (RoFormer model)"),d$r=l(),r3=a("li"),A7e=a("strong"),c$r=o("t5"),f$r=o(" \u2014 "),CY=a("a"),m$r=o("FlaxT5Model"),g$r=o(" (T5 model)"),h$r=l(),t3=a("li"),y7e=a("strong"),p$r=o("vision-text-dual-encoder"),_$r=o(" \u2014 "),wY=a("a"),u$r=o("FlaxVisionTextDualEncoderModel"),b$r=o(" (VisionTextDualEncoder model)"),v$r=l(),a3=a("li"),L7e=a("strong"),F$r=o("vit"),T$r=o(" \u2014 "),AY=a("a"),M$r=o("FlaxViTModel"),E$r=o(" (ViT model)"),C$r=l(),n3=a("li"),x7e=a("strong"),w$r=o("wav2vec2"),A$r=o(" \u2014 "),yY=a("a"),y$r=o("FlaxWav2Vec2Model"),L$r=o(" (Wav2Vec2 model)"),x$r=l(),s3=a("li"),$7e=a("strong"),$$r=o("xglm"),k$r=o(" \u2014 "),LY=a("a"),S$r=o("FlaxXGLMModel"),R$r=o(" (XGLM model)"),P$r=l(),l3=a("li"),k7e=a("strong"),B$r=o("xlm-roberta"),I$r=o(" \u2014 "),xY=a("a"),N$r=o("FlaxXLMRobertaModel"),q$r=o(" (XLM-RoBERTa model)"),j$r=l(),F(i3.$$.fragment),uDe=l(),Pc=a("h2"),d3=a("a"),S7e=a("span"),F(j9.$$.fragment),D$r=l(),R7e=a("span"),G$r=o("FlaxAutoModelForCausalLM"),bDe=l(),mr=a("div"),F(D9.$$.fragment),O$r=l(),Bc=a("p"),V$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),$Y=a("a"),X$r=o("from_pretrained()"),z$r=o(" class method or the "),kY=a("a"),W$r=o("from_config()"),Q$r=o(` class
method.`),H$r=l(),G9=a("p"),U$r=o("This class cannot be instantiated directly using "),P7e=a("code"),J$r=o("__init__()"),Y$r=o(" (throws an error)."),K$r=l(),Ot=a("div"),F(O9.$$.fragment),Z$r=l(),B7e=a("p"),ekr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),okr=l(),Ic=a("p"),rkr=o(`Note:
Loading a model from its configuration file does `),I7e=a("strong"),tkr=o("not"),akr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=a("a"),nkr=o("from_pretrained()"),skr=o(" to load the model weights."),lkr=l(),F(c3.$$.fragment),ikr=l(),Dr=a("div"),F(V9.$$.fragment),dkr=l(),N7e=a("p"),ckr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),fkr=l(),pn=a("p"),mkr=o("The model class to instantiate is selected based on the "),q7e=a("code"),gkr=o("model_type"),hkr=o(` property of the config object (either
passed as an argument or loaded from `),j7e=a("code"),pkr=o("pretrained_model_name_or_path"),_kr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D7e=a("code"),ukr=o("pretrained_model_name_or_path"),bkr=o(":"),vkr=l(),Le=a("ul"),f3=a("li"),G7e=a("strong"),Fkr=o("bart"),Tkr=o(" \u2014 "),RY=a("a"),Mkr=o("FlaxBartForCausalLM"),Ekr=o(" (BART model)"),Ckr=l(),m3=a("li"),O7e=a("strong"),wkr=o("bert"),Akr=o(" \u2014 "),PY=a("a"),ykr=o("FlaxBertForCausalLM"),Lkr=o(" (BERT model)"),xkr=l(),g3=a("li"),V7e=a("strong"),$kr=o("big_bird"),kkr=o(" \u2014 "),BY=a("a"),Skr=o("FlaxBigBirdForCausalLM"),Rkr=o(" (BigBird model)"),Pkr=l(),h3=a("li"),X7e=a("strong"),Bkr=o("electra"),Ikr=o(" \u2014 "),IY=a("a"),Nkr=o("FlaxElectraForCausalLM"),qkr=o(" (ELECTRA model)"),jkr=l(),p3=a("li"),z7e=a("strong"),Dkr=o("gpt2"),Gkr=o(" \u2014 "),NY=a("a"),Okr=o("FlaxGPT2LMHeadModel"),Vkr=o(" (OpenAI GPT-2 model)"),Xkr=l(),_3=a("li"),W7e=a("strong"),zkr=o("gpt_neo"),Wkr=o(" \u2014 "),qY=a("a"),Qkr=o("FlaxGPTNeoForCausalLM"),Hkr=o(" (GPT Neo model)"),Ukr=l(),u3=a("li"),Q7e=a("strong"),Jkr=o("gptj"),Ykr=o(" \u2014 "),jY=a("a"),Kkr=o("FlaxGPTJForCausalLM"),Zkr=o(" (GPT-J model)"),eSr=l(),b3=a("li"),H7e=a("strong"),oSr=o("opt"),rSr=o(" \u2014 "),DY=a("a"),tSr=o("FlaxOPTForCausalLM"),aSr=o(" (OPT model)"),nSr=l(),v3=a("li"),U7e=a("strong"),sSr=o("roberta"),lSr=o(" \u2014 "),GY=a("a"),iSr=o("FlaxRobertaForCausalLM"),dSr=o(" (RoBERTa model)"),cSr=l(),F3=a("li"),J7e=a("strong"),fSr=o("xglm"),mSr=o(" \u2014 "),OY=a("a"),gSr=o("FlaxXGLMForCausalLM"),hSr=o(" (XGLM model)"),pSr=l(),F(T3.$$.fragment),vDe=l(),Nc=a("h2"),M3=a("a"),Y7e=a("span"),F(X9.$$.fragment),_Sr=l(),K7e=a("span"),uSr=o("FlaxAutoModelForPreTraining"),FDe=l(),gr=a("div"),F(z9.$$.fragment),bSr=l(),qc=a("p"),vSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VY=a("a"),FSr=o("from_pretrained()"),TSr=o(" class method or the "),XY=a("a"),MSr=o("from_config()"),ESr=o(` class
method.`),CSr=l(),W9=a("p"),wSr=o("This class cannot be instantiated directly using "),Z7e=a("code"),ASr=o("__init__()"),ySr=o(" (throws an error)."),LSr=l(),Vt=a("div"),F(Q9.$$.fragment),xSr=l(),eMe=a("p"),$Sr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),kSr=l(),jc=a("p"),SSr=o(`Note:
Loading a model from its configuration file does `),oMe=a("strong"),RSr=o("not"),PSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zY=a("a"),BSr=o("from_pretrained()"),ISr=o(" to load the model weights."),NSr=l(),F(E3.$$.fragment),qSr=l(),Gr=a("div"),F(H9.$$.fragment),jSr=l(),rMe=a("p"),DSr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),GSr=l(),_n=a("p"),OSr=o("The model class to instantiate is selected based on the "),tMe=a("code"),VSr=o("model_type"),XSr=o(` property of the config object (either
passed as an argument or loaded from `),aMe=a("code"),zSr=o("pretrained_model_name_or_path"),WSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=a("code"),QSr=o("pretrained_model_name_or_path"),HSr=o(":"),USr=l(),Ee=a("ul"),C3=a("li"),sMe=a("strong"),JSr=o("albert"),YSr=o(" \u2014 "),WY=a("a"),KSr=o("FlaxAlbertForPreTraining"),ZSr=o(" (ALBERT model)"),eRr=l(),w3=a("li"),lMe=a("strong"),oRr=o("bart"),rRr=o(" \u2014 "),QY=a("a"),tRr=o("FlaxBartForConditionalGeneration"),aRr=o(" (BART model)"),nRr=l(),A3=a("li"),iMe=a("strong"),sRr=o("bert"),lRr=o(" \u2014 "),HY=a("a"),iRr=o("FlaxBertForPreTraining"),dRr=o(" (BERT model)"),cRr=l(),y3=a("li"),dMe=a("strong"),fRr=o("big_bird"),mRr=o(" \u2014 "),UY=a("a"),gRr=o("FlaxBigBirdForPreTraining"),hRr=o(" (BigBird model)"),pRr=l(),L3=a("li"),cMe=a("strong"),_Rr=o("electra"),uRr=o(" \u2014 "),JY=a("a"),bRr=o("FlaxElectraForPreTraining"),vRr=o(" (ELECTRA model)"),FRr=l(),x3=a("li"),fMe=a("strong"),TRr=o("mbart"),MRr=o(" \u2014 "),YY=a("a"),ERr=o("FlaxMBartForConditionalGeneration"),CRr=o(" (mBART model)"),wRr=l(),$3=a("li"),mMe=a("strong"),ARr=o("mt5"),yRr=o(" \u2014 "),KY=a("a"),LRr=o("FlaxMT5ForConditionalGeneration"),xRr=o(" (mT5 model)"),$Rr=l(),k3=a("li"),gMe=a("strong"),kRr=o("roberta"),SRr=o(" \u2014 "),ZY=a("a"),RRr=o("FlaxRobertaForMaskedLM"),PRr=o(" (RoBERTa model)"),BRr=l(),S3=a("li"),hMe=a("strong"),IRr=o("roformer"),NRr=o(" \u2014 "),eK=a("a"),qRr=o("FlaxRoFormerForMaskedLM"),jRr=o(" (RoFormer model)"),DRr=l(),R3=a("li"),pMe=a("strong"),GRr=o("t5"),ORr=o(" \u2014 "),oK=a("a"),VRr=o("FlaxT5ForConditionalGeneration"),XRr=o(" (T5 model)"),zRr=l(),P3=a("li"),_Me=a("strong"),WRr=o("wav2vec2"),QRr=o(" \u2014 "),rK=a("a"),HRr=o("FlaxWav2Vec2ForPreTraining"),URr=o(" (Wav2Vec2 model)"),JRr=l(),B3=a("li"),uMe=a("strong"),YRr=o("xlm-roberta"),KRr=o(" \u2014 "),tK=a("a"),ZRr=o("FlaxXLMRobertaForMaskedLM"),ePr=o(" (XLM-RoBERTa model)"),oPr=l(),F(I3.$$.fragment),TDe=l(),Dc=a("h2"),N3=a("a"),bMe=a("span"),F(U9.$$.fragment),rPr=l(),vMe=a("span"),tPr=o("FlaxAutoModelForMaskedLM"),MDe=l(),hr=a("div"),F(J9.$$.fragment),aPr=l(),Gc=a("p"),nPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aK=a("a"),sPr=o("from_pretrained()"),lPr=o(" class method or the "),nK=a("a"),iPr=o("from_config()"),dPr=o(` class
method.`),cPr=l(),Y9=a("p"),fPr=o("This class cannot be instantiated directly using "),FMe=a("code"),mPr=o("__init__()"),gPr=o(" (throws an error)."),hPr=l(),Xt=a("div"),F(K9.$$.fragment),pPr=l(),TMe=a("p"),_Pr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),uPr=l(),Oc=a("p"),bPr=o(`Note:
Loading a model from its configuration file does `),MMe=a("strong"),vPr=o("not"),FPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sK=a("a"),TPr=o("from_pretrained()"),MPr=o(" to load the model weights."),EPr=l(),F(q3.$$.fragment),CPr=l(),Or=a("div"),F(Z9.$$.fragment),wPr=l(),EMe=a("p"),APr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),yPr=l(),un=a("p"),LPr=o("The model class to instantiate is selected based on the "),CMe=a("code"),xPr=o("model_type"),$Pr=o(` property of the config object (either
passed as an argument or loaded from `),wMe=a("code"),kPr=o("pretrained_model_name_or_path"),SPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AMe=a("code"),RPr=o("pretrained_model_name_or_path"),PPr=o(":"),BPr=l(),xe=a("ul"),j3=a("li"),yMe=a("strong"),IPr=o("albert"),NPr=o(" \u2014 "),lK=a("a"),qPr=o("FlaxAlbertForMaskedLM"),jPr=o(" (ALBERT model)"),DPr=l(),D3=a("li"),LMe=a("strong"),GPr=o("bart"),OPr=o(" \u2014 "),iK=a("a"),VPr=o("FlaxBartForConditionalGeneration"),XPr=o(" (BART model)"),zPr=l(),G3=a("li"),xMe=a("strong"),WPr=o("bert"),QPr=o(" \u2014 "),dK=a("a"),HPr=o("FlaxBertForMaskedLM"),UPr=o(" (BERT model)"),JPr=l(),O3=a("li"),$Me=a("strong"),YPr=o("big_bird"),KPr=o(" \u2014 "),cK=a("a"),ZPr=o("FlaxBigBirdForMaskedLM"),eBr=o(" (BigBird model)"),oBr=l(),V3=a("li"),kMe=a("strong"),rBr=o("distilbert"),tBr=o(" \u2014 "),fK=a("a"),aBr=o("FlaxDistilBertForMaskedLM"),nBr=o(" (DistilBERT model)"),sBr=l(),X3=a("li"),SMe=a("strong"),lBr=o("electra"),iBr=o(" \u2014 "),mK=a("a"),dBr=o("FlaxElectraForMaskedLM"),cBr=o(" (ELECTRA model)"),fBr=l(),z3=a("li"),RMe=a("strong"),mBr=o("mbart"),gBr=o(" \u2014 "),gK=a("a"),hBr=o("FlaxMBartForConditionalGeneration"),pBr=o(" (mBART model)"),_Br=l(),W3=a("li"),PMe=a("strong"),uBr=o("roberta"),bBr=o(" \u2014 "),hK=a("a"),vBr=o("FlaxRobertaForMaskedLM"),FBr=o(" (RoBERTa model)"),TBr=l(),Q3=a("li"),BMe=a("strong"),MBr=o("roformer"),EBr=o(" \u2014 "),pK=a("a"),CBr=o("FlaxRoFormerForMaskedLM"),wBr=o(" (RoFormer model)"),ABr=l(),H3=a("li"),IMe=a("strong"),yBr=o("xlm-roberta"),LBr=o(" \u2014 "),_K=a("a"),xBr=o("FlaxXLMRobertaForMaskedLM"),$Br=o(" (XLM-RoBERTa model)"),kBr=l(),F(U3.$$.fragment),EDe=l(),Vc=a("h2"),J3=a("a"),NMe=a("span"),F(ex.$$.fragment),SBr=l(),qMe=a("span"),RBr=o("FlaxAutoModelForSeq2SeqLM"),CDe=l(),pr=a("div"),F(ox.$$.fragment),PBr=l(),Xc=a("p"),BBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uK=a("a"),IBr=o("from_pretrained()"),NBr=o(" class method or the "),bK=a("a"),qBr=o("from_config()"),jBr=o(` class
method.`),DBr=l(),rx=a("p"),GBr=o("This class cannot be instantiated directly using "),jMe=a("code"),OBr=o("__init__()"),VBr=o(" (throws an error)."),XBr=l(),zt=a("div"),F(tx.$$.fragment),zBr=l(),DMe=a("p"),WBr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),QBr=l(),zc=a("p"),HBr=o(`Note:
Loading a model from its configuration file does `),GMe=a("strong"),UBr=o("not"),JBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=a("a"),YBr=o("from_pretrained()"),KBr=o(" to load the model weights."),ZBr=l(),F(Y3.$$.fragment),eIr=l(),Vr=a("div"),F(ax.$$.fragment),oIr=l(),OMe=a("p"),rIr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),tIr=l(),bn=a("p"),aIr=o("The model class to instantiate is selected based on the "),VMe=a("code"),nIr=o("model_type"),sIr=o(` property of the config object (either
passed as an argument or loaded from `),XMe=a("code"),lIr=o("pretrained_model_name_or_path"),iIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zMe=a("code"),dIr=o("pretrained_model_name_or_path"),cIr=o(":"),fIr=l(),Pe=a("ul"),K3=a("li"),WMe=a("strong"),mIr=o("bart"),gIr=o(" \u2014 "),FK=a("a"),hIr=o("FlaxBartForConditionalGeneration"),pIr=o(" (BART model)"),_Ir=l(),Z3=a("li"),QMe=a("strong"),uIr=o("blenderbot"),bIr=o(" \u2014 "),TK=a("a"),vIr=o("FlaxBlenderbotForConditionalGeneration"),FIr=o(" (Blenderbot model)"),TIr=l(),e0=a("li"),HMe=a("strong"),MIr=o("blenderbot-small"),EIr=o(" \u2014 "),MK=a("a"),CIr=o("FlaxBlenderbotSmallForConditionalGeneration"),wIr=o(" (BlenderbotSmall model)"),AIr=l(),o0=a("li"),UMe=a("strong"),yIr=o("encoder-decoder"),LIr=o(" \u2014 "),EK=a("a"),xIr=o("FlaxEncoderDecoderModel"),$Ir=o(" (Encoder decoder model)"),kIr=l(),r0=a("li"),JMe=a("strong"),SIr=o("marian"),RIr=o(" \u2014 "),CK=a("a"),PIr=o("FlaxMarianMTModel"),BIr=o(" (Marian model)"),IIr=l(),t0=a("li"),YMe=a("strong"),NIr=o("mbart"),qIr=o(" \u2014 "),wK=a("a"),jIr=o("FlaxMBartForConditionalGeneration"),DIr=o(" (mBART model)"),GIr=l(),a0=a("li"),KMe=a("strong"),OIr=o("mt5"),VIr=o(" \u2014 "),AK=a("a"),XIr=o("FlaxMT5ForConditionalGeneration"),zIr=o(" (mT5 model)"),WIr=l(),n0=a("li"),ZMe=a("strong"),QIr=o("pegasus"),HIr=o(" \u2014 "),yK=a("a"),UIr=o("FlaxPegasusForConditionalGeneration"),JIr=o(" (Pegasus model)"),YIr=l(),s0=a("li"),eEe=a("strong"),KIr=o("t5"),ZIr=o(" \u2014 "),LK=a("a"),eNr=o("FlaxT5ForConditionalGeneration"),oNr=o(" (T5 model)"),rNr=l(),F(l0.$$.fragment),wDe=l(),Wc=a("h2"),i0=a("a"),oEe=a("span"),F(nx.$$.fragment),tNr=l(),rEe=a("span"),aNr=o("FlaxAutoModelForSequenceClassification"),ADe=l(),_r=a("div"),F(sx.$$.fragment),nNr=l(),Qc=a("p"),sNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),xK=a("a"),lNr=o("from_pretrained()"),iNr=o(" class method or the "),$K=a("a"),dNr=o("from_config()"),cNr=o(` class
method.`),fNr=l(),lx=a("p"),mNr=o("This class cannot be instantiated directly using "),tEe=a("code"),gNr=o("__init__()"),hNr=o(" (throws an error)."),pNr=l(),Wt=a("div"),F(ix.$$.fragment),_Nr=l(),aEe=a("p"),uNr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),bNr=l(),Hc=a("p"),vNr=o(`Note:
Loading a model from its configuration file does `),nEe=a("strong"),FNr=o("not"),TNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=a("a"),MNr=o("from_pretrained()"),ENr=o(" to load the model weights."),CNr=l(),F(d0.$$.fragment),wNr=l(),Xr=a("div"),F(dx.$$.fragment),ANr=l(),sEe=a("p"),yNr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),LNr=l(),vn=a("p"),xNr=o("The model class to instantiate is selected based on the "),lEe=a("code"),$Nr=o("model_type"),kNr=o(` property of the config object (either
passed as an argument or loaded from `),iEe=a("code"),SNr=o("pretrained_model_name_or_path"),RNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dEe=a("code"),PNr=o("pretrained_model_name_or_path"),BNr=o(":"),INr=l(),$e=a("ul"),c0=a("li"),cEe=a("strong"),NNr=o("albert"),qNr=o(" \u2014 "),SK=a("a"),jNr=o("FlaxAlbertForSequenceClassification"),DNr=o(" (ALBERT model)"),GNr=l(),f0=a("li"),fEe=a("strong"),ONr=o("bart"),VNr=o(" \u2014 "),RK=a("a"),XNr=o("FlaxBartForSequenceClassification"),zNr=o(" (BART model)"),WNr=l(),m0=a("li"),mEe=a("strong"),QNr=o("bert"),HNr=o(" \u2014 "),PK=a("a"),UNr=o("FlaxBertForSequenceClassification"),JNr=o(" (BERT model)"),YNr=l(),g0=a("li"),gEe=a("strong"),KNr=o("big_bird"),ZNr=o(" \u2014 "),BK=a("a"),eqr=o("FlaxBigBirdForSequenceClassification"),oqr=o(" (BigBird model)"),rqr=l(),h0=a("li"),hEe=a("strong"),tqr=o("distilbert"),aqr=o(" \u2014 "),IK=a("a"),nqr=o("FlaxDistilBertForSequenceClassification"),sqr=o(" (DistilBERT model)"),lqr=l(),p0=a("li"),pEe=a("strong"),iqr=o("electra"),dqr=o(" \u2014 "),NK=a("a"),cqr=o("FlaxElectraForSequenceClassification"),fqr=o(" (ELECTRA model)"),mqr=l(),_0=a("li"),_Ee=a("strong"),gqr=o("mbart"),hqr=o(" \u2014 "),qK=a("a"),pqr=o("FlaxMBartForSequenceClassification"),_qr=o(" (mBART model)"),uqr=l(),u0=a("li"),uEe=a("strong"),bqr=o("roberta"),vqr=o(" \u2014 "),jK=a("a"),Fqr=o("FlaxRobertaForSequenceClassification"),Tqr=o(" (RoBERTa model)"),Mqr=l(),b0=a("li"),bEe=a("strong"),Eqr=o("roformer"),Cqr=o(" \u2014 "),DK=a("a"),wqr=o("FlaxRoFormerForSequenceClassification"),Aqr=o(" (RoFormer model)"),yqr=l(),v0=a("li"),vEe=a("strong"),Lqr=o("xlm-roberta"),xqr=o(" \u2014 "),GK=a("a"),$qr=o("FlaxXLMRobertaForSequenceClassification"),kqr=o(" (XLM-RoBERTa model)"),Sqr=l(),F(F0.$$.fragment),yDe=l(),Uc=a("h2"),T0=a("a"),FEe=a("span"),F(cx.$$.fragment),Rqr=l(),TEe=a("span"),Pqr=o("FlaxAutoModelForQuestionAnswering"),LDe=l(),ur=a("div"),F(fx.$$.fragment),Bqr=l(),Jc=a("p"),Iqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),OK=a("a"),Nqr=o("from_pretrained()"),qqr=o(" class method or the "),VK=a("a"),jqr=o("from_config()"),Dqr=o(` class
method.`),Gqr=l(),mx=a("p"),Oqr=o("This class cannot be instantiated directly using "),MEe=a("code"),Vqr=o("__init__()"),Xqr=o(" (throws an error)."),zqr=l(),Qt=a("div"),F(gx.$$.fragment),Wqr=l(),EEe=a("p"),Qqr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Hqr=l(),Yc=a("p"),Uqr=o(`Note:
Loading a model from its configuration file does `),CEe=a("strong"),Jqr=o("not"),Yqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=a("a"),Kqr=o("from_pretrained()"),Zqr=o(" to load the model weights."),ejr=l(),F(M0.$$.fragment),ojr=l(),zr=a("div"),F(hx.$$.fragment),rjr=l(),wEe=a("p"),tjr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ajr=l(),Fn=a("p"),njr=o("The model class to instantiate is selected based on the "),AEe=a("code"),sjr=o("model_type"),ljr=o(` property of the config object (either
passed as an argument or loaded from `),yEe=a("code"),ijr=o("pretrained_model_name_or_path"),djr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=a("code"),cjr=o("pretrained_model_name_or_path"),fjr=o(":"),mjr=l(),ke=a("ul"),E0=a("li"),xEe=a("strong"),gjr=o("albert"),hjr=o(" \u2014 "),zK=a("a"),pjr=o("FlaxAlbertForQuestionAnswering"),_jr=o(" (ALBERT model)"),ujr=l(),C0=a("li"),$Ee=a("strong"),bjr=o("bart"),vjr=o(" \u2014 "),WK=a("a"),Fjr=o("FlaxBartForQuestionAnswering"),Tjr=o(" (BART model)"),Mjr=l(),w0=a("li"),kEe=a("strong"),Ejr=o("bert"),Cjr=o(" \u2014 "),QK=a("a"),wjr=o("FlaxBertForQuestionAnswering"),Ajr=o(" (BERT model)"),yjr=l(),A0=a("li"),SEe=a("strong"),Ljr=o("big_bird"),xjr=o(" \u2014 "),HK=a("a"),$jr=o("FlaxBigBirdForQuestionAnswering"),kjr=o(" (BigBird model)"),Sjr=l(),y0=a("li"),REe=a("strong"),Rjr=o("distilbert"),Pjr=o(" \u2014 "),UK=a("a"),Bjr=o("FlaxDistilBertForQuestionAnswering"),Ijr=o(" (DistilBERT model)"),Njr=l(),L0=a("li"),PEe=a("strong"),qjr=o("electra"),jjr=o(" \u2014 "),JK=a("a"),Djr=o("FlaxElectraForQuestionAnswering"),Gjr=o(" (ELECTRA model)"),Ojr=l(),x0=a("li"),BEe=a("strong"),Vjr=o("mbart"),Xjr=o(" \u2014 "),YK=a("a"),zjr=o("FlaxMBartForQuestionAnswering"),Wjr=o(" (mBART model)"),Qjr=l(),$0=a("li"),IEe=a("strong"),Hjr=o("roberta"),Ujr=o(" \u2014 "),KK=a("a"),Jjr=o("FlaxRobertaForQuestionAnswering"),Yjr=o(" (RoBERTa model)"),Kjr=l(),k0=a("li"),NEe=a("strong"),Zjr=o("roformer"),eDr=o(" \u2014 "),ZK=a("a"),oDr=o("FlaxRoFormerForQuestionAnswering"),rDr=o(" (RoFormer model)"),tDr=l(),S0=a("li"),qEe=a("strong"),aDr=o("xlm-roberta"),nDr=o(" \u2014 "),eZ=a("a"),sDr=o("FlaxXLMRobertaForQuestionAnswering"),lDr=o(" (XLM-RoBERTa model)"),iDr=l(),F(R0.$$.fragment),xDe=l(),Kc=a("h2"),P0=a("a"),jEe=a("span"),F(px.$$.fragment),dDr=l(),DEe=a("span"),cDr=o("FlaxAutoModelForTokenClassification"),$De=l(),br=a("div"),F(_x.$$.fragment),fDr=l(),Zc=a("p"),mDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),oZ=a("a"),gDr=o("from_pretrained()"),hDr=o(" class method or the "),rZ=a("a"),pDr=o("from_config()"),_Dr=o(` class
method.`),uDr=l(),ux=a("p"),bDr=o("This class cannot be instantiated directly using "),GEe=a("code"),vDr=o("__init__()"),FDr=o(" (throws an error)."),TDr=l(),Ht=a("div"),F(bx.$$.fragment),MDr=l(),OEe=a("p"),EDr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),CDr=l(),ef=a("p"),wDr=o(`Note:
Loading a model from its configuration file does `),VEe=a("strong"),ADr=o("not"),yDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tZ=a("a"),LDr=o("from_pretrained()"),xDr=o(" to load the model weights."),$Dr=l(),F(B0.$$.fragment),kDr=l(),Wr=a("div"),F(vx.$$.fragment),SDr=l(),XEe=a("p"),RDr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),PDr=l(),Tn=a("p"),BDr=o("The model class to instantiate is selected based on the "),zEe=a("code"),IDr=o("model_type"),NDr=o(` property of the config object (either
passed as an argument or loaded from `),WEe=a("code"),qDr=o("pretrained_model_name_or_path"),jDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=a("code"),DDr=o("pretrained_model_name_or_path"),GDr=o(":"),ODr=l(),Ge=a("ul"),I0=a("li"),HEe=a("strong"),VDr=o("albert"),XDr=o(" \u2014 "),aZ=a("a"),zDr=o("FlaxAlbertForTokenClassification"),WDr=o(" (ALBERT model)"),QDr=l(),N0=a("li"),UEe=a("strong"),HDr=o("bert"),UDr=o(" \u2014 "),nZ=a("a"),JDr=o("FlaxBertForTokenClassification"),YDr=o(" (BERT model)"),KDr=l(),q0=a("li"),JEe=a("strong"),ZDr=o("big_bird"),eGr=o(" \u2014 "),sZ=a("a"),oGr=o("FlaxBigBirdForTokenClassification"),rGr=o(" (BigBird model)"),tGr=l(),j0=a("li"),YEe=a("strong"),aGr=o("distilbert"),nGr=o(" \u2014 "),lZ=a("a"),sGr=o("FlaxDistilBertForTokenClassification"),lGr=o(" (DistilBERT model)"),iGr=l(),D0=a("li"),KEe=a("strong"),dGr=o("electra"),cGr=o(" \u2014 "),iZ=a("a"),fGr=o("FlaxElectraForTokenClassification"),mGr=o(" (ELECTRA model)"),gGr=l(),G0=a("li"),ZEe=a("strong"),hGr=o("roberta"),pGr=o(" \u2014 "),dZ=a("a"),_Gr=o("FlaxRobertaForTokenClassification"),uGr=o(" (RoBERTa model)"),bGr=l(),O0=a("li"),eCe=a("strong"),vGr=o("roformer"),FGr=o(" \u2014 "),cZ=a("a"),TGr=o("FlaxRoFormerForTokenClassification"),MGr=o(" (RoFormer model)"),EGr=l(),V0=a("li"),oCe=a("strong"),CGr=o("xlm-roberta"),wGr=o(" \u2014 "),fZ=a("a"),AGr=o("FlaxXLMRobertaForTokenClassification"),yGr=o(" (XLM-RoBERTa model)"),LGr=l(),F(X0.$$.fragment),kDe=l(),of=a("h2"),z0=a("a"),rCe=a("span"),F(Fx.$$.fragment),xGr=l(),tCe=a("span"),$Gr=o("FlaxAutoModelForMultipleChoice"),SDe=l(),vr=a("div"),F(Tx.$$.fragment),kGr=l(),rf=a("p"),SGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),mZ=a("a"),RGr=o("from_pretrained()"),PGr=o(" class method or the "),gZ=a("a"),BGr=o("from_config()"),IGr=o(` class
method.`),NGr=l(),Mx=a("p"),qGr=o("This class cannot be instantiated directly using "),aCe=a("code"),jGr=o("__init__()"),DGr=o(" (throws an error)."),GGr=l(),Ut=a("div"),F(Ex.$$.fragment),OGr=l(),nCe=a("p"),VGr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),XGr=l(),tf=a("p"),zGr=o(`Note:
Loading a model from its configuration file does `),sCe=a("strong"),WGr=o("not"),QGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hZ=a("a"),HGr=o("from_pretrained()"),UGr=o(" to load the model weights."),JGr=l(),F(W0.$$.fragment),YGr=l(),Qr=a("div"),F(Cx.$$.fragment),KGr=l(),lCe=a("p"),ZGr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),eOr=l(),Mn=a("p"),oOr=o("The model class to instantiate is selected based on the "),iCe=a("code"),rOr=o("model_type"),tOr=o(` property of the config object (either
passed as an argument or loaded from `),dCe=a("code"),aOr=o("pretrained_model_name_or_path"),nOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=a("code"),sOr=o("pretrained_model_name_or_path"),lOr=o(":"),iOr=l(),Oe=a("ul"),Q0=a("li"),fCe=a("strong"),dOr=o("albert"),cOr=o(" \u2014 "),pZ=a("a"),fOr=o("FlaxAlbertForMultipleChoice"),mOr=o(" (ALBERT model)"),gOr=l(),H0=a("li"),mCe=a("strong"),hOr=o("bert"),pOr=o(" \u2014 "),_Z=a("a"),_Or=o("FlaxBertForMultipleChoice"),uOr=o(" (BERT model)"),bOr=l(),U0=a("li"),gCe=a("strong"),vOr=o("big_bird"),FOr=o(" \u2014 "),uZ=a("a"),TOr=o("FlaxBigBirdForMultipleChoice"),MOr=o(" (BigBird model)"),EOr=l(),J0=a("li"),hCe=a("strong"),COr=o("distilbert"),wOr=o(" \u2014 "),bZ=a("a"),AOr=o("FlaxDistilBertForMultipleChoice"),yOr=o(" (DistilBERT model)"),LOr=l(),Y0=a("li"),pCe=a("strong"),xOr=o("electra"),$Or=o(" \u2014 "),vZ=a("a"),kOr=o("FlaxElectraForMultipleChoice"),SOr=o(" (ELECTRA model)"),ROr=l(),K0=a("li"),_Ce=a("strong"),POr=o("roberta"),BOr=o(" \u2014 "),FZ=a("a"),IOr=o("FlaxRobertaForMultipleChoice"),NOr=o(" (RoBERTa model)"),qOr=l(),Z0=a("li"),uCe=a("strong"),jOr=o("roformer"),DOr=o(" \u2014 "),TZ=a("a"),GOr=o("FlaxRoFormerForMultipleChoice"),OOr=o(" (RoFormer model)"),VOr=l(),ew=a("li"),bCe=a("strong"),XOr=o("xlm-roberta"),zOr=o(" \u2014 "),MZ=a("a"),WOr=o("FlaxXLMRobertaForMultipleChoice"),QOr=o(" (XLM-RoBERTa model)"),HOr=l(),F(ow.$$.fragment),RDe=l(),af=a("h2"),rw=a("a"),vCe=a("span"),F(wx.$$.fragment),UOr=l(),FCe=a("span"),JOr=o("FlaxAutoModelForNextSentencePrediction"),PDe=l(),Fr=a("div"),F(Ax.$$.fragment),YOr=l(),nf=a("p"),KOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),EZ=a("a"),ZOr=o("from_pretrained()"),eVr=o(" class method or the "),CZ=a("a"),oVr=o("from_config()"),rVr=o(` class
method.`),tVr=l(),yx=a("p"),aVr=o("This class cannot be instantiated directly using "),TCe=a("code"),nVr=o("__init__()"),sVr=o(" (throws an error)."),lVr=l(),Jt=a("div"),F(Lx.$$.fragment),iVr=l(),MCe=a("p"),dVr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),cVr=l(),sf=a("p"),fVr=o(`Note:
Loading a model from its configuration file does `),ECe=a("strong"),mVr=o("not"),gVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=a("a"),hVr=o("from_pretrained()"),pVr=o(" to load the model weights."),_Vr=l(),F(tw.$$.fragment),uVr=l(),Hr=a("div"),F(xx.$$.fragment),bVr=l(),CCe=a("p"),vVr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),FVr=l(),En=a("p"),TVr=o("The model class to instantiate is selected based on the "),wCe=a("code"),MVr=o("model_type"),EVr=o(` property of the config object (either
passed as an argument or loaded from `),ACe=a("code"),CVr=o("pretrained_model_name_or_path"),wVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yCe=a("code"),AVr=o("pretrained_model_name_or_path"),yVr=o(":"),LVr=l(),LCe=a("ul"),aw=a("li"),xCe=a("strong"),xVr=o("bert"),$Vr=o(" \u2014 "),AZ=a("a"),kVr=o("FlaxBertForNextSentencePrediction"),SVr=o(" (BERT model)"),RVr=l(),F(nw.$$.fragment),BDe=l(),lf=a("h2"),sw=a("a"),$Ce=a("span"),F($x.$$.fragment),PVr=l(),kCe=a("span"),BVr=o("FlaxAutoModelForImageClassification"),IDe=l(),Tr=a("div"),F(kx.$$.fragment),IVr=l(),df=a("p"),NVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),yZ=a("a"),qVr=o("from_pretrained()"),jVr=o(" class method or the "),LZ=a("a"),DVr=o("from_config()"),GVr=o(` class
method.`),OVr=l(),Sx=a("p"),VVr=o("This class cannot be instantiated directly using "),SCe=a("code"),XVr=o("__init__()"),zVr=o(" (throws an error)."),WVr=l(),Yt=a("div"),F(Rx.$$.fragment),QVr=l(),RCe=a("p"),HVr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),UVr=l(),cf=a("p"),JVr=o(`Note:
Loading a model from its configuration file does `),PCe=a("strong"),YVr=o("not"),KVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xZ=a("a"),ZVr=o("from_pretrained()"),eXr=o(" to load the model weights."),oXr=l(),F(lw.$$.fragment),rXr=l(),Ur=a("div"),F(Px.$$.fragment),tXr=l(),BCe=a("p"),aXr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),nXr=l(),Cn=a("p"),sXr=o("The model class to instantiate is selected based on the "),ICe=a("code"),lXr=o("model_type"),iXr=o(` property of the config object (either
passed as an argument or loaded from `),NCe=a("code"),dXr=o("pretrained_model_name_or_path"),cXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qCe=a("code"),fXr=o("pretrained_model_name_or_path"),mXr=o(":"),gXr=l(),Bx=a("ul"),iw=a("li"),jCe=a("strong"),hXr=o("beit"),pXr=o(" \u2014 "),$Z=a("a"),_Xr=o("FlaxBeitForImageClassification"),uXr=o(" (BEiT model)"),bXr=l(),dw=a("li"),DCe=a("strong"),vXr=o("vit"),FXr=o(" \u2014 "),kZ=a("a"),TXr=o("FlaxViTForImageClassification"),MXr=o(" (ViT model)"),EXr=l(),F(cw.$$.fragment),NDe=l(),ff=a("h2"),fw=a("a"),GCe=a("span"),F(Ix.$$.fragment),CXr=l(),OCe=a("span"),wXr=o("FlaxAutoModelForVision2Seq"),qDe=l(),Mr=a("div"),F(Nx.$$.fragment),AXr=l(),mf=a("p"),yXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),SZ=a("a"),LXr=o("from_pretrained()"),xXr=o(" class method or the "),RZ=a("a"),$Xr=o("from_config()"),kXr=o(` class
method.`),SXr=l(),qx=a("p"),RXr=o("This class cannot be instantiated directly using "),VCe=a("code"),PXr=o("__init__()"),BXr=o(" (throws an error)."),IXr=l(),Kt=a("div"),F(jx.$$.fragment),NXr=l(),XCe=a("p"),qXr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),jXr=l(),gf=a("p"),DXr=o(`Note:
Loading a model from its configuration file does `),zCe=a("strong"),GXr=o("not"),OXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PZ=a("a"),VXr=o("from_pretrained()"),XXr=o(" to load the model weights."),zXr=l(),F(mw.$$.fragment),WXr=l(),Jr=a("div"),F(Dx.$$.fragment),QXr=l(),WCe=a("p"),HXr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),UXr=l(),wn=a("p"),JXr=o("The model class to instantiate is selected based on the "),QCe=a("code"),YXr=o("model_type"),KXr=o(` property of the config object (either
passed as an argument or loaded from `),HCe=a("code"),ZXr=o("pretrained_model_name_or_path"),ezr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UCe=a("code"),ozr=o("pretrained_model_name_or_path"),rzr=o(":"),tzr=l(),JCe=a("ul"),gw=a("li"),YCe=a("strong"),azr=o("vision-encoder-decoder"),nzr=o(" \u2014 "),BZ=a("a"),szr=o("FlaxVisionEncoderDecoderModel"),lzr=o(" (Vision Encoder decoder model)"),izr=l(),F(hw.$$.fragment),this.h()},l(f){const u=iSt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var Gx=s(p);m=n(Gx,"A",{id:!0,class:!0,href:!0});var KCe=s(m);_=n(KCe,"SPAN",{});var ZCe=s(_);T(d.$$.fragment,ZCe),ZCe.forEach(t),KCe.forEach(t),h=i(Gx),Mo=n(Gx,"SPAN",{});var e3e=s(Mo);gi=r(e3e,"Auto Classes"),e3e.forEach(t),Gx.forEach(t),uf=i(f),rt=n(f,"P",{});var Ox=s(rt);hi=r(Ox,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),pi=n(Ox,"CODE",{});var o3e=s(pi);SA=r(o3e,"from_pretrained()"),o3e.forEach(t),bf=r(Ox,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ox.forEach(t),De=i(f),We=n(f,"P",{});var An=s(We);_i=r(An,"Instantiating one of "),yn=n(An,"A",{href:!0});var r3e=s(yn);RA=r(r3e,"AutoConfig"),r3e.forEach(t),Ln=r(An,", "),xn=n(An,"A",{href:!0});var t3e=s(xn);PA=r(t3e,"AutoModel"),t3e.forEach(t),ui=r(An,`, and
`),$n=n(An,"A",{href:!0});var a3e=s($n);BA=r(a3e,"AutoTokenizer"),a3e.forEach(t),bi=r(An," will directly create a class of the relevant architecture. For instance"),An.forEach(t),vf=i(f),T(Ca.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var Vx=s(Ae);rk=r(Vx,"will create a model that is an instance of "),vi=n(Vx,"A",{href:!0});var n3e=s(vi);tk=r(n3e,"BertModel"),n3e.forEach(t),ak=r(Vx,"."),Vx.forEach(t),Eo=i(f),wa=n(f,"P",{});var Xx=s(wa);nk=r(Xx,"There is one class of "),Ff=n(Xx,"CODE",{});var s3e=s(Ff);sk=r(s3e,"AutoModel"),s3e.forEach(t),QOe=r(Xx," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Xx.forEach(t),Iqe=i(f),Fi=n(f,"H2",{class:!0});var zx=s(Fi);Tf=n(zx,"A",{id:!0,class:!0,href:!0});var l3e=s(Tf);Loe=n(l3e,"SPAN",{});var i3e=s(Loe);T(IA.$$.fragment,i3e),i3e.forEach(t),l3e.forEach(t),HOe=i(zx),xoe=n(zx,"SPAN",{});var d3e=s(xoe);UOe=r(d3e,"Extending the Auto Classes"),d3e.forEach(t),zx.forEach(t),Nqe=i(f),kn=n(f,"P",{});var hf=s(kn);JOe=r(hf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),$oe=n(hf,"CODE",{});var c3e=s($oe);YOe=r(c3e,"NewModel"),c3e.forEach(t),KOe=r(hf,", make sure you have a "),koe=n(hf,"CODE",{});var f3e=s(koe);ZOe=r(f3e,"NewModelConfig"),f3e.forEach(t),eVe=r(hf,` then you can add those to the auto
classes like this:`),hf.forEach(t),qqe=i(f),T(NA.$$.fragment,f),jqe=i(f),lk=n(f,"P",{});var m3e=s(lk);oVe=r(m3e,"You will then be able to use the auto classes like you would usually do!"),m3e.forEach(t),Dqe=i(f),T(Mf.$$.fragment,f),Gqe=i(f),Ti=n(f,"H2",{class:!0});var Wx=s(Ti);Ef=n(Wx,"A",{id:!0,class:!0,href:!0});var g3e=s(Ef);Soe=n(g3e,"SPAN",{});var h3e=s(Soe);T(qA.$$.fragment,h3e),h3e.forEach(t),g3e.forEach(t),rVe=i(Wx),Roe=n(Wx,"SPAN",{});var p3e=s(Roe);tVe=r(p3e,"AutoConfig"),p3e.forEach(t),Wx.forEach(t),Oqe=i(f),Co=n(f,"DIV",{class:!0});var et=s(Co);T(jA.$$.fragment,et),aVe=i(et),DA=n(et,"P",{});var Qx=s(DA);nVe=r(Qx,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),ik=n(Qx,"A",{href:!0});var _3e=s(ik);sVe=r(_3e,"from_pretrained()"),_3e.forEach(t),lVe=r(Qx," class method."),Qx.forEach(t),iVe=i(et),GA=n(et,"P",{});var Hx=s(GA);dVe=r(Hx,"This class cannot be instantiated directly using "),Poe=n(Hx,"CODE",{});var u3e=s(Poe);cVe=r(u3e,"__init__()"),u3e.forEach(t),fVe=r(Hx," (throws an error)."),Hx.forEach(t),mVe=i(et),Er=n(et,"DIV",{class:!0});var ot=s(Er);T(OA.$$.fragment,ot),gVe=i(ot),Boe=n(ot,"P",{});var b3e=s(Boe);hVe=r(b3e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),b3e.forEach(t),pVe=i(ot),Mi=n(ot,"P",{});var pf=s(Mi);_Ve=r(pf,"The configuration class to instantiate is selected based on the "),Ioe=n(pf,"CODE",{});var v3e=s(Ioe);uVe=r(v3e,"model_type"),v3e.forEach(t),bVe=r(pf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Noe=n(pf,"CODE",{});var F3e=s(Noe);vVe=r(F3e,"pretrained_model_name_or_path"),F3e.forEach(t),FVe=r(pf,":"),pf.forEach(t),TVe=i(ot),A=n(ot,"UL",{});var y=s(A);Cf=n(y,"LI",{});var pw=s(Cf);qoe=n(pw,"STRONG",{});var T3e=s(qoe);MVe=r(T3e,"albert"),T3e.forEach(t),EVe=r(pw," \u2014 "),dk=n(pw,"A",{href:!0});var M3e=s(dk);CVe=r(M3e,"AlbertConfig"),M3e.forEach(t),wVe=r(pw," (ALBERT model)"),pw.forEach(t),AVe=i(y),wf=n(y,"LI",{});var _w=s(wf);joe=n(_w,"STRONG",{});var E3e=s(joe);yVe=r(E3e,"bart"),E3e.forEach(t),LVe=r(_w," \u2014 "),ck=n(_w,"A",{href:!0});var C3e=s(ck);xVe=r(C3e,"BartConfig"),C3e.forEach(t),$Ve=r(_w," (BART model)"),_w.forEach(t),kVe=i(y),Af=n(y,"LI",{});var uw=s(Af);Doe=n(uw,"STRONG",{});var w3e=s(Doe);SVe=r(w3e,"beit"),w3e.forEach(t),RVe=r(uw," \u2014 "),fk=n(uw,"A",{href:!0});var A3e=s(fk);PVe=r(A3e,"BeitConfig"),A3e.forEach(t),BVe=r(uw," (BEiT model)"),uw.forEach(t),IVe=i(y),yf=n(y,"LI",{});var bw=s(yf);Goe=n(bw,"STRONG",{});var y3e=s(Goe);NVe=r(y3e,"bert"),y3e.forEach(t),qVe=r(bw," \u2014 "),mk=n(bw,"A",{href:!0});var L3e=s(mk);jVe=r(L3e,"BertConfig"),L3e.forEach(t),DVe=r(bw," (BERT model)"),bw.forEach(t),GVe=i(y),Lf=n(y,"LI",{});var vw=s(Lf);Ooe=n(vw,"STRONG",{});var x3e=s(Ooe);OVe=r(x3e,"bert-generation"),x3e.forEach(t),VVe=r(vw," \u2014 "),gk=n(vw,"A",{href:!0});var $3e=s(gk);XVe=r($3e,"BertGenerationConfig"),$3e.forEach(t),zVe=r(vw," (Bert Generation model)"),vw.forEach(t),WVe=i(y),xf=n(y,"LI",{});var Fw=s(xf);Voe=n(Fw,"STRONG",{});var k3e=s(Voe);QVe=r(k3e,"big_bird"),k3e.forEach(t),HVe=r(Fw," \u2014 "),hk=n(Fw,"A",{href:!0});var S3e=s(hk);UVe=r(S3e,"BigBirdConfig"),S3e.forEach(t),JVe=r(Fw," (BigBird model)"),Fw.forEach(t),YVe=i(y),$f=n(y,"LI",{});var Tw=s($f);Xoe=n(Tw,"STRONG",{});var R3e=s(Xoe);KVe=r(R3e,"bigbird_pegasus"),R3e.forEach(t),ZVe=r(Tw," \u2014 "),pk=n(Tw,"A",{href:!0});var P3e=s(pk);eXe=r(P3e,"BigBirdPegasusConfig"),P3e.forEach(t),oXe=r(Tw," (BigBirdPegasus model)"),Tw.forEach(t),rXe=i(y),kf=n(y,"LI",{});var Mw=s(kf);zoe=n(Mw,"STRONG",{});var B3e=s(zoe);tXe=r(B3e,"blenderbot"),B3e.forEach(t),aXe=r(Mw," \u2014 "),_k=n(Mw,"A",{href:!0});var I3e=s(_k);nXe=r(I3e,"BlenderbotConfig"),I3e.forEach(t),sXe=r(Mw," (Blenderbot model)"),Mw.forEach(t),lXe=i(y),Sf=n(y,"LI",{});var Ew=s(Sf);Woe=n(Ew,"STRONG",{});var N3e=s(Woe);iXe=r(N3e,"blenderbot-small"),N3e.forEach(t),dXe=r(Ew," \u2014 "),uk=n(Ew,"A",{href:!0});var q3e=s(uk);cXe=r(q3e,"BlenderbotSmallConfig"),q3e.forEach(t),fXe=r(Ew," (BlenderbotSmall model)"),Ew.forEach(t),mXe=i(y),Rf=n(y,"LI",{});var Cw=s(Rf);Qoe=n(Cw,"STRONG",{});var j3e=s(Qoe);gXe=r(j3e,"camembert"),j3e.forEach(t),hXe=r(Cw," \u2014 "),bk=n(Cw,"A",{href:!0});var D3e=s(bk);pXe=r(D3e,"CamembertConfig"),D3e.forEach(t),_Xe=r(Cw," (CamemBERT model)"),Cw.forEach(t),uXe=i(y),Pf=n(y,"LI",{});var ww=s(Pf);Hoe=n(ww,"STRONG",{});var G3e=s(Hoe);bXe=r(G3e,"canine"),G3e.forEach(t),vXe=r(ww," \u2014 "),vk=n(ww,"A",{href:!0});var O3e=s(vk);FXe=r(O3e,"CanineConfig"),O3e.forEach(t),TXe=r(ww," (Canine model)"),ww.forEach(t),MXe=i(y),Bf=n(y,"LI",{});var Aw=s(Bf);Uoe=n(Aw,"STRONG",{});var V3e=s(Uoe);EXe=r(V3e,"clip"),V3e.forEach(t),CXe=r(Aw," \u2014 "),Fk=n(Aw,"A",{href:!0});var X3e=s(Fk);wXe=r(X3e,"CLIPConfig"),X3e.forEach(t),AXe=r(Aw," (CLIP model)"),Aw.forEach(t),yXe=i(y),If=n(y,"LI",{});var yw=s(If);Joe=n(yw,"STRONG",{});var z3e=s(Joe);LXe=r(z3e,"convbert"),z3e.forEach(t),xXe=r(yw," \u2014 "),Tk=n(yw,"A",{href:!0});var W3e=s(Tk);$Xe=r(W3e,"ConvBertConfig"),W3e.forEach(t),kXe=r(yw," (ConvBERT model)"),yw.forEach(t),SXe=i(y),Nf=n(y,"LI",{});var Lw=s(Nf);Yoe=n(Lw,"STRONG",{});var Q3e=s(Yoe);RXe=r(Q3e,"convnext"),Q3e.forEach(t),PXe=r(Lw," \u2014 "),Mk=n(Lw,"A",{href:!0});var H3e=s(Mk);BXe=r(H3e,"ConvNextConfig"),H3e.forEach(t),IXe=r(Lw," (ConvNext model)"),Lw.forEach(t),NXe=i(y),qf=n(y,"LI",{});var xw=s(qf);Koe=n(xw,"STRONG",{});var U3e=s(Koe);qXe=r(U3e,"ctrl"),U3e.forEach(t),jXe=r(xw," \u2014 "),Ek=n(xw,"A",{href:!0});var J3e=s(Ek);DXe=r(J3e,"CTRLConfig"),J3e.forEach(t),GXe=r(xw," (CTRL model)"),xw.forEach(t),OXe=i(y),jf=n(y,"LI",{});var $w=s(jf);Zoe=n($w,"STRONG",{});var Y3e=s(Zoe);VXe=r(Y3e,"cvt"),Y3e.forEach(t),XXe=r($w," \u2014 "),Ck=n($w,"A",{href:!0});var K3e=s(Ck);zXe=r(K3e,"CvtConfig"),K3e.forEach(t),WXe=r($w," (CvT model)"),$w.forEach(t),QXe=i(y),Df=n(y,"LI",{});var kw=s(Df);ere=n(kw,"STRONG",{});var Z3e=s(ere);HXe=r(Z3e,"data2vec-audio"),Z3e.forEach(t),UXe=r(kw," \u2014 "),wk=n(kw,"A",{href:!0});var e0e=s(wk);JXe=r(e0e,"Data2VecAudioConfig"),e0e.forEach(t),YXe=r(kw," (Data2VecAudio model)"),kw.forEach(t),KXe=i(y),Gf=n(y,"LI",{});var Sw=s(Gf);ore=n(Sw,"STRONG",{});var o0e=s(ore);ZXe=r(o0e,"data2vec-text"),o0e.forEach(t),eze=r(Sw," \u2014 "),Ak=n(Sw,"A",{href:!0});var r0e=s(Ak);oze=r(r0e,"Data2VecTextConfig"),r0e.forEach(t),rze=r(Sw," (Data2VecText model)"),Sw.forEach(t),tze=i(y),Of=n(y,"LI",{});var Rw=s(Of);rre=n(Rw,"STRONG",{});var t0e=s(rre);aze=r(t0e,"data2vec-vision"),t0e.forEach(t),nze=r(Rw," \u2014 "),yk=n(Rw,"A",{href:!0});var a0e=s(yk);sze=r(a0e,"Data2VecVisionConfig"),a0e.forEach(t),lze=r(Rw," (Data2VecVision model)"),Rw.forEach(t),ize=i(y),Vf=n(y,"LI",{});var Pw=s(Vf);tre=n(Pw,"STRONG",{});var n0e=s(tre);dze=r(n0e,"deberta"),n0e.forEach(t),cze=r(Pw," \u2014 "),Lk=n(Pw,"A",{href:!0});var s0e=s(Lk);fze=r(s0e,"DebertaConfig"),s0e.forEach(t),mze=r(Pw," (DeBERTa model)"),Pw.forEach(t),gze=i(y),Xf=n(y,"LI",{});var Bw=s(Xf);are=n(Bw,"STRONG",{});var l0e=s(are);hze=r(l0e,"deberta-v2"),l0e.forEach(t),pze=r(Bw," \u2014 "),xk=n(Bw,"A",{href:!0});var i0e=s(xk);_ze=r(i0e,"DebertaV2Config"),i0e.forEach(t),uze=r(Bw," (DeBERTa-v2 model)"),Bw.forEach(t),bze=i(y),zf=n(y,"LI",{});var Iw=s(zf);nre=n(Iw,"STRONG",{});var d0e=s(nre);vze=r(d0e,"decision_transformer"),d0e.forEach(t),Fze=r(Iw," \u2014 "),$k=n(Iw,"A",{href:!0});var c0e=s($k);Tze=r(c0e,"DecisionTransformerConfig"),c0e.forEach(t),Mze=r(Iw," (Decision Transformer model)"),Iw.forEach(t),Eze=i(y),Wf=n(y,"LI",{});var Nw=s(Wf);sre=n(Nw,"STRONG",{});var f0e=s(sre);Cze=r(f0e,"deit"),f0e.forEach(t),wze=r(Nw," \u2014 "),kk=n(Nw,"A",{href:!0});var czr=s(kk);Aze=r(czr,"DeiTConfig"),czr.forEach(t),yze=r(Nw," (DeiT model)"),Nw.forEach(t),Lze=i(y),Qf=n(y,"LI",{});var m0e=s(Qf);lre=n(m0e,"STRONG",{});var fzr=s(lre);xze=r(fzr,"detr"),fzr.forEach(t),$ze=r(m0e," \u2014 "),Sk=n(m0e,"A",{href:!0});var mzr=s(Sk);kze=r(mzr,"DetrConfig"),mzr.forEach(t),Sze=r(m0e," (DETR model)"),m0e.forEach(t),Rze=i(y),Hf=n(y,"LI",{});var g0e=s(Hf);ire=n(g0e,"STRONG",{});var gzr=s(ire);Pze=r(gzr,"distilbert"),gzr.forEach(t),Bze=r(g0e," \u2014 "),Rk=n(g0e,"A",{href:!0});var hzr=s(Rk);Ize=r(hzr,"DistilBertConfig"),hzr.forEach(t),Nze=r(g0e," (DistilBERT model)"),g0e.forEach(t),qze=i(y),Uf=n(y,"LI",{});var h0e=s(Uf);dre=n(h0e,"STRONG",{});var pzr=s(dre);jze=r(pzr,"dpr"),pzr.forEach(t),Dze=r(h0e," \u2014 "),Pk=n(h0e,"A",{href:!0});var _zr=s(Pk);Gze=r(_zr,"DPRConfig"),_zr.forEach(t),Oze=r(h0e," (DPR model)"),h0e.forEach(t),Vze=i(y),Jf=n(y,"LI",{});var p0e=s(Jf);cre=n(p0e,"STRONG",{});var uzr=s(cre);Xze=r(uzr,"dpt"),uzr.forEach(t),zze=r(p0e," \u2014 "),Bk=n(p0e,"A",{href:!0});var bzr=s(Bk);Wze=r(bzr,"DPTConfig"),bzr.forEach(t),Qze=r(p0e," (DPT model)"),p0e.forEach(t),Hze=i(y),Yf=n(y,"LI",{});var _0e=s(Yf);fre=n(_0e,"STRONG",{});var vzr=s(fre);Uze=r(vzr,"electra"),vzr.forEach(t),Jze=r(_0e," \u2014 "),Ik=n(_0e,"A",{href:!0});var Fzr=s(Ik);Yze=r(Fzr,"ElectraConfig"),Fzr.forEach(t),Kze=r(_0e," (ELECTRA model)"),_0e.forEach(t),Zze=i(y),Kf=n(y,"LI",{});var u0e=s(Kf);mre=n(u0e,"STRONG",{});var Tzr=s(mre);eWe=r(Tzr,"encoder-decoder"),Tzr.forEach(t),oWe=r(u0e," \u2014 "),Nk=n(u0e,"A",{href:!0});var Mzr=s(Nk);rWe=r(Mzr,"EncoderDecoderConfig"),Mzr.forEach(t),tWe=r(u0e," (Encoder decoder model)"),u0e.forEach(t),aWe=i(y),Zf=n(y,"LI",{});var b0e=s(Zf);gre=n(b0e,"STRONG",{});var Ezr=s(gre);nWe=r(Ezr,"flaubert"),Ezr.forEach(t),sWe=r(b0e," \u2014 "),qk=n(b0e,"A",{href:!0});var Czr=s(qk);lWe=r(Czr,"FlaubertConfig"),Czr.forEach(t),iWe=r(b0e," (FlauBERT model)"),b0e.forEach(t),dWe=i(y),em=n(y,"LI",{});var v0e=s(em);hre=n(v0e,"STRONG",{});var wzr=s(hre);cWe=r(wzr,"flava"),wzr.forEach(t),fWe=r(v0e," \u2014 "),jk=n(v0e,"A",{href:!0});var Azr=s(jk);mWe=r(Azr,"FlavaConfig"),Azr.forEach(t),gWe=r(v0e," (Flava model)"),v0e.forEach(t),hWe=i(y),om=n(y,"LI",{});var F0e=s(om);pre=n(F0e,"STRONG",{});var yzr=s(pre);pWe=r(yzr,"fnet"),yzr.forEach(t),_We=r(F0e," \u2014 "),Dk=n(F0e,"A",{href:!0});var Lzr=s(Dk);uWe=r(Lzr,"FNetConfig"),Lzr.forEach(t),bWe=r(F0e," (FNet model)"),F0e.forEach(t),vWe=i(y),rm=n(y,"LI",{});var T0e=s(rm);_re=n(T0e,"STRONG",{});var xzr=s(_re);FWe=r(xzr,"fsmt"),xzr.forEach(t),TWe=r(T0e," \u2014 "),Gk=n(T0e,"A",{href:!0});var $zr=s(Gk);MWe=r($zr,"FSMTConfig"),$zr.forEach(t),EWe=r(T0e," (FairSeq Machine-Translation model)"),T0e.forEach(t),CWe=i(y),tm=n(y,"LI",{});var M0e=s(tm);ure=n(M0e,"STRONG",{});var kzr=s(ure);wWe=r(kzr,"funnel"),kzr.forEach(t),AWe=r(M0e," \u2014 "),Ok=n(M0e,"A",{href:!0});var Szr=s(Ok);yWe=r(Szr,"FunnelConfig"),Szr.forEach(t),LWe=r(M0e," (Funnel Transformer model)"),M0e.forEach(t),xWe=i(y),am=n(y,"LI",{});var E0e=s(am);bre=n(E0e,"STRONG",{});var Rzr=s(bre);$We=r(Rzr,"glpn"),Rzr.forEach(t),kWe=r(E0e," \u2014 "),Vk=n(E0e,"A",{href:!0});var Pzr=s(Vk);SWe=r(Pzr,"GLPNConfig"),Pzr.forEach(t),RWe=r(E0e," (GLPN model)"),E0e.forEach(t),PWe=i(y),nm=n(y,"LI",{});var C0e=s(nm);vre=n(C0e,"STRONG",{});var Bzr=s(vre);BWe=r(Bzr,"gpt2"),Bzr.forEach(t),IWe=r(C0e," \u2014 "),Xk=n(C0e,"A",{href:!0});var Izr=s(Xk);NWe=r(Izr,"GPT2Config"),Izr.forEach(t),qWe=r(C0e," (OpenAI GPT-2 model)"),C0e.forEach(t),jWe=i(y),sm=n(y,"LI",{});var w0e=s(sm);Fre=n(w0e,"STRONG",{});var Nzr=s(Fre);DWe=r(Nzr,"gpt_neo"),Nzr.forEach(t),GWe=r(w0e," \u2014 "),zk=n(w0e,"A",{href:!0});var qzr=s(zk);OWe=r(qzr,"GPTNeoConfig"),qzr.forEach(t),VWe=r(w0e," (GPT Neo model)"),w0e.forEach(t),XWe=i(y),lm=n(y,"LI",{});var A0e=s(lm);Tre=n(A0e,"STRONG",{});var jzr=s(Tre);zWe=r(jzr,"gpt_neox"),jzr.forEach(t),WWe=r(A0e," \u2014 "),Wk=n(A0e,"A",{href:!0});var Dzr=s(Wk);QWe=r(Dzr,"GPTNeoXConfig"),Dzr.forEach(t),HWe=r(A0e," (GPT NeoX model)"),A0e.forEach(t),UWe=i(y),im=n(y,"LI",{});var y0e=s(im);Mre=n(y0e,"STRONG",{});var Gzr=s(Mre);JWe=r(Gzr,"gptj"),Gzr.forEach(t),YWe=r(y0e," \u2014 "),Qk=n(y0e,"A",{href:!0});var Ozr=s(Qk);KWe=r(Ozr,"GPTJConfig"),Ozr.forEach(t),ZWe=r(y0e," (GPT-J model)"),y0e.forEach(t),eQe=i(y),dm=n(y,"LI",{});var L0e=s(dm);Ere=n(L0e,"STRONG",{});var Vzr=s(Ere);oQe=r(Vzr,"hubert"),Vzr.forEach(t),rQe=r(L0e," \u2014 "),Hk=n(L0e,"A",{href:!0});var Xzr=s(Hk);tQe=r(Xzr,"HubertConfig"),Xzr.forEach(t),aQe=r(L0e," (Hubert model)"),L0e.forEach(t),nQe=i(y),cm=n(y,"LI",{});var x0e=s(cm);Cre=n(x0e,"STRONG",{});var zzr=s(Cre);sQe=r(zzr,"ibert"),zzr.forEach(t),lQe=r(x0e," \u2014 "),Uk=n(x0e,"A",{href:!0});var Wzr=s(Uk);iQe=r(Wzr,"IBertConfig"),Wzr.forEach(t),dQe=r(x0e," (I-BERT model)"),x0e.forEach(t),cQe=i(y),fm=n(y,"LI",{});var $0e=s(fm);wre=n($0e,"STRONG",{});var Qzr=s(wre);fQe=r(Qzr,"imagegpt"),Qzr.forEach(t),mQe=r($0e," \u2014 "),Jk=n($0e,"A",{href:!0});var Hzr=s(Jk);gQe=r(Hzr,"ImageGPTConfig"),Hzr.forEach(t),hQe=r($0e," (ImageGPT model)"),$0e.forEach(t),pQe=i(y),mm=n(y,"LI",{});var k0e=s(mm);Are=n(k0e,"STRONG",{});var Uzr=s(Are);_Qe=r(Uzr,"layoutlm"),Uzr.forEach(t),uQe=r(k0e," \u2014 "),Yk=n(k0e,"A",{href:!0});var Jzr=s(Yk);bQe=r(Jzr,"LayoutLMConfig"),Jzr.forEach(t),vQe=r(k0e," (LayoutLM model)"),k0e.forEach(t),FQe=i(y),gm=n(y,"LI",{});var S0e=s(gm);yre=n(S0e,"STRONG",{});var Yzr=s(yre);TQe=r(Yzr,"layoutlmv2"),Yzr.forEach(t),MQe=r(S0e," \u2014 "),Kk=n(S0e,"A",{href:!0});var Kzr=s(Kk);EQe=r(Kzr,"LayoutLMv2Config"),Kzr.forEach(t),CQe=r(S0e," (LayoutLMv2 model)"),S0e.forEach(t),wQe=i(y),hm=n(y,"LI",{});var R0e=s(hm);Lre=n(R0e,"STRONG",{});var Zzr=s(Lre);AQe=r(Zzr,"layoutlmv3"),Zzr.forEach(t),yQe=r(R0e," \u2014 "),Zk=n(R0e,"A",{href:!0});var eWr=s(Zk);LQe=r(eWr,"LayoutLMv3Config"),eWr.forEach(t),xQe=r(R0e," (LayoutLMv3 model)"),R0e.forEach(t),$Qe=i(y),pm=n(y,"LI",{});var P0e=s(pm);xre=n(P0e,"STRONG",{});var oWr=s(xre);kQe=r(oWr,"led"),oWr.forEach(t),SQe=r(P0e," \u2014 "),eS=n(P0e,"A",{href:!0});var rWr=s(eS);RQe=r(rWr,"LEDConfig"),rWr.forEach(t),PQe=r(P0e," (LED model)"),P0e.forEach(t),BQe=i(y),_m=n(y,"LI",{});var B0e=s(_m);$re=n(B0e,"STRONG",{});var tWr=s($re);IQe=r(tWr,"levit"),tWr.forEach(t),NQe=r(B0e," \u2014 "),oS=n(B0e,"A",{href:!0});var aWr=s(oS);qQe=r(aWr,"LevitConfig"),aWr.forEach(t),jQe=r(B0e," (LeViT model)"),B0e.forEach(t),DQe=i(y),um=n(y,"LI",{});var I0e=s(um);kre=n(I0e,"STRONG",{});var nWr=s(kre);GQe=r(nWr,"longformer"),nWr.forEach(t),OQe=r(I0e," \u2014 "),rS=n(I0e,"A",{href:!0});var sWr=s(rS);VQe=r(sWr,"LongformerConfig"),sWr.forEach(t),XQe=r(I0e," (Longformer model)"),I0e.forEach(t),zQe=i(y),bm=n(y,"LI",{});var N0e=s(bm);Sre=n(N0e,"STRONG",{});var lWr=s(Sre);WQe=r(lWr,"luke"),lWr.forEach(t),QQe=r(N0e," \u2014 "),tS=n(N0e,"A",{href:!0});var iWr=s(tS);HQe=r(iWr,"LukeConfig"),iWr.forEach(t),UQe=r(N0e," (LUKE model)"),N0e.forEach(t),JQe=i(y),vm=n(y,"LI",{});var q0e=s(vm);Rre=n(q0e,"STRONG",{});var dWr=s(Rre);YQe=r(dWr,"lxmert"),dWr.forEach(t),KQe=r(q0e," \u2014 "),aS=n(q0e,"A",{href:!0});var cWr=s(aS);ZQe=r(cWr,"LxmertConfig"),cWr.forEach(t),eHe=r(q0e," (LXMERT model)"),q0e.forEach(t),oHe=i(y),Fm=n(y,"LI",{});var j0e=s(Fm);Pre=n(j0e,"STRONG",{});var fWr=s(Pre);rHe=r(fWr,"m2m_100"),fWr.forEach(t),tHe=r(j0e," \u2014 "),nS=n(j0e,"A",{href:!0});var mWr=s(nS);aHe=r(mWr,"M2M100Config"),mWr.forEach(t),nHe=r(j0e," (M2M100 model)"),j0e.forEach(t),sHe=i(y),Tm=n(y,"LI",{});var D0e=s(Tm);Bre=n(D0e,"STRONG",{});var gWr=s(Bre);lHe=r(gWr,"marian"),gWr.forEach(t),iHe=r(D0e," \u2014 "),sS=n(D0e,"A",{href:!0});var hWr=s(sS);dHe=r(hWr,"MarianConfig"),hWr.forEach(t),cHe=r(D0e," (Marian model)"),D0e.forEach(t),fHe=i(y),Mm=n(y,"LI",{});var G0e=s(Mm);Ire=n(G0e,"STRONG",{});var pWr=s(Ire);mHe=r(pWr,"maskformer"),pWr.forEach(t),gHe=r(G0e," \u2014 "),lS=n(G0e,"A",{href:!0});var _Wr=s(lS);hHe=r(_Wr,"MaskFormerConfig"),_Wr.forEach(t),pHe=r(G0e," (MaskFormer model)"),G0e.forEach(t),_He=i(y),Em=n(y,"LI",{});var O0e=s(Em);Nre=n(O0e,"STRONG",{});var uWr=s(Nre);uHe=r(uWr,"mbart"),uWr.forEach(t),bHe=r(O0e," \u2014 "),iS=n(O0e,"A",{href:!0});var bWr=s(iS);vHe=r(bWr,"MBartConfig"),bWr.forEach(t),FHe=r(O0e," (mBART model)"),O0e.forEach(t),THe=i(y),Cm=n(y,"LI",{});var V0e=s(Cm);qre=n(V0e,"STRONG",{});var vWr=s(qre);MHe=r(vWr,"megatron-bert"),vWr.forEach(t),EHe=r(V0e," \u2014 "),dS=n(V0e,"A",{href:!0});var FWr=s(dS);CHe=r(FWr,"MegatronBertConfig"),FWr.forEach(t),wHe=r(V0e," (MegatronBert model)"),V0e.forEach(t),AHe=i(y),wm=n(y,"LI",{});var X0e=s(wm);jre=n(X0e,"STRONG",{});var TWr=s(jre);yHe=r(TWr,"mobilebert"),TWr.forEach(t),LHe=r(X0e," \u2014 "),cS=n(X0e,"A",{href:!0});var MWr=s(cS);xHe=r(MWr,"MobileBertConfig"),MWr.forEach(t),$He=r(X0e," (MobileBERT model)"),X0e.forEach(t),kHe=i(y),Am=n(y,"LI",{});var z0e=s(Am);Dre=n(z0e,"STRONG",{});var EWr=s(Dre);SHe=r(EWr,"mpnet"),EWr.forEach(t),RHe=r(z0e," \u2014 "),fS=n(z0e,"A",{href:!0});var CWr=s(fS);PHe=r(CWr,"MPNetConfig"),CWr.forEach(t),BHe=r(z0e," (MPNet model)"),z0e.forEach(t),IHe=i(y),ym=n(y,"LI",{});var W0e=s(ym);Gre=n(W0e,"STRONG",{});var wWr=s(Gre);NHe=r(wWr,"mt5"),wWr.forEach(t),qHe=r(W0e," \u2014 "),mS=n(W0e,"A",{href:!0});var AWr=s(mS);jHe=r(AWr,"MT5Config"),AWr.forEach(t),DHe=r(W0e," (mT5 model)"),W0e.forEach(t),GHe=i(y),Lm=n(y,"LI",{});var Q0e=s(Lm);Ore=n(Q0e,"STRONG",{});var yWr=s(Ore);OHe=r(yWr,"nystromformer"),yWr.forEach(t),VHe=r(Q0e," \u2014 "),gS=n(Q0e,"A",{href:!0});var LWr=s(gS);XHe=r(LWr,"NystromformerConfig"),LWr.forEach(t),zHe=r(Q0e," (Nystromformer model)"),Q0e.forEach(t),WHe=i(y),xm=n(y,"LI",{});var H0e=s(xm);Vre=n(H0e,"STRONG",{});var xWr=s(Vre);QHe=r(xWr,"openai-gpt"),xWr.forEach(t),HHe=r(H0e," \u2014 "),hS=n(H0e,"A",{href:!0});var $Wr=s(hS);UHe=r($Wr,"OpenAIGPTConfig"),$Wr.forEach(t),JHe=r(H0e," (OpenAI GPT model)"),H0e.forEach(t),YHe=i(y),$m=n(y,"LI",{});var U0e=s($m);Xre=n(U0e,"STRONG",{});var kWr=s(Xre);KHe=r(kWr,"opt"),kWr.forEach(t),ZHe=r(U0e," \u2014 "),pS=n(U0e,"A",{href:!0});var SWr=s(pS);eUe=r(SWr,"OPTConfig"),SWr.forEach(t),oUe=r(U0e," (OPT model)"),U0e.forEach(t),rUe=i(y),km=n(y,"LI",{});var J0e=s(km);zre=n(J0e,"STRONG",{});var RWr=s(zre);tUe=r(RWr,"pegasus"),RWr.forEach(t),aUe=r(J0e," \u2014 "),_S=n(J0e,"A",{href:!0});var PWr=s(_S);nUe=r(PWr,"PegasusConfig"),PWr.forEach(t),sUe=r(J0e," (Pegasus model)"),J0e.forEach(t),lUe=i(y),Sm=n(y,"LI",{});var Y0e=s(Sm);Wre=n(Y0e,"STRONG",{});var BWr=s(Wre);iUe=r(BWr,"perceiver"),BWr.forEach(t),dUe=r(Y0e," \u2014 "),uS=n(Y0e,"A",{href:!0});var IWr=s(uS);cUe=r(IWr,"PerceiverConfig"),IWr.forEach(t),fUe=r(Y0e," (Perceiver model)"),Y0e.forEach(t),mUe=i(y),Rm=n(y,"LI",{});var K0e=s(Rm);Qre=n(K0e,"STRONG",{});var NWr=s(Qre);gUe=r(NWr,"plbart"),NWr.forEach(t),hUe=r(K0e," \u2014 "),bS=n(K0e,"A",{href:!0});var qWr=s(bS);pUe=r(qWr,"PLBartConfig"),qWr.forEach(t),_Ue=r(K0e," (PLBart model)"),K0e.forEach(t),uUe=i(y),Pm=n(y,"LI",{});var Z0e=s(Pm);Hre=n(Z0e,"STRONG",{});var jWr=s(Hre);bUe=r(jWr,"poolformer"),jWr.forEach(t),vUe=r(Z0e," \u2014 "),vS=n(Z0e,"A",{href:!0});var DWr=s(vS);FUe=r(DWr,"PoolFormerConfig"),DWr.forEach(t),TUe=r(Z0e," (PoolFormer model)"),Z0e.forEach(t),MUe=i(y),Bm=n(y,"LI",{});var ewe=s(Bm);Ure=n(ewe,"STRONG",{});var GWr=s(Ure);EUe=r(GWr,"prophetnet"),GWr.forEach(t),CUe=r(ewe," \u2014 "),FS=n(ewe,"A",{href:!0});var OWr=s(FS);wUe=r(OWr,"ProphetNetConfig"),OWr.forEach(t),AUe=r(ewe," (ProphetNet model)"),ewe.forEach(t),yUe=i(y),Im=n(y,"LI",{});var owe=s(Im);Jre=n(owe,"STRONG",{});var VWr=s(Jre);LUe=r(VWr,"qdqbert"),VWr.forEach(t),xUe=r(owe," \u2014 "),TS=n(owe,"A",{href:!0});var XWr=s(TS);$Ue=r(XWr,"QDQBertConfig"),XWr.forEach(t),kUe=r(owe," (QDQBert model)"),owe.forEach(t),SUe=i(y),Nm=n(y,"LI",{});var rwe=s(Nm);Yre=n(rwe,"STRONG",{});var zWr=s(Yre);RUe=r(zWr,"rag"),zWr.forEach(t),PUe=r(rwe," \u2014 "),MS=n(rwe,"A",{href:!0});var WWr=s(MS);BUe=r(WWr,"RagConfig"),WWr.forEach(t),IUe=r(rwe," (RAG model)"),rwe.forEach(t),NUe=i(y),qm=n(y,"LI",{});var twe=s(qm);Kre=n(twe,"STRONG",{});var QWr=s(Kre);qUe=r(QWr,"realm"),QWr.forEach(t),jUe=r(twe," \u2014 "),ES=n(twe,"A",{href:!0});var HWr=s(ES);DUe=r(HWr,"RealmConfig"),HWr.forEach(t),GUe=r(twe," (Realm model)"),twe.forEach(t),OUe=i(y),jm=n(y,"LI",{});var awe=s(jm);Zre=n(awe,"STRONG",{});var UWr=s(Zre);VUe=r(UWr,"reformer"),UWr.forEach(t),XUe=r(awe," \u2014 "),CS=n(awe,"A",{href:!0});var JWr=s(CS);zUe=r(JWr,"ReformerConfig"),JWr.forEach(t),WUe=r(awe," (Reformer model)"),awe.forEach(t),QUe=i(y),Dm=n(y,"LI",{});var nwe=s(Dm);ete=n(nwe,"STRONG",{});var YWr=s(ete);HUe=r(YWr,"regnet"),YWr.forEach(t),UUe=r(nwe," \u2014 "),wS=n(nwe,"A",{href:!0});var KWr=s(wS);JUe=r(KWr,"RegNetConfig"),KWr.forEach(t),YUe=r(nwe," (RegNet model)"),nwe.forEach(t),KUe=i(y),Gm=n(y,"LI",{});var swe=s(Gm);ote=n(swe,"STRONG",{});var ZWr=s(ote);ZUe=r(ZWr,"rembert"),ZWr.forEach(t),eJe=r(swe," \u2014 "),AS=n(swe,"A",{href:!0});var eQr=s(AS);oJe=r(eQr,"RemBertConfig"),eQr.forEach(t),rJe=r(swe," (RemBERT model)"),swe.forEach(t),tJe=i(y),Om=n(y,"LI",{});var lwe=s(Om);rte=n(lwe,"STRONG",{});var oQr=s(rte);aJe=r(oQr,"resnet"),oQr.forEach(t),nJe=r(lwe," \u2014 "),yS=n(lwe,"A",{href:!0});var rQr=s(yS);sJe=r(rQr,"ResNetConfig"),rQr.forEach(t),lJe=r(lwe," (ResNet model)"),lwe.forEach(t),iJe=i(y),Vm=n(y,"LI",{});var iwe=s(Vm);tte=n(iwe,"STRONG",{});var tQr=s(tte);dJe=r(tQr,"retribert"),tQr.forEach(t),cJe=r(iwe," \u2014 "),LS=n(iwe,"A",{href:!0});var aQr=s(LS);fJe=r(aQr,"RetriBertConfig"),aQr.forEach(t),mJe=r(iwe," (RetriBERT model)"),iwe.forEach(t),gJe=i(y),Xm=n(y,"LI",{});var dwe=s(Xm);ate=n(dwe,"STRONG",{});var nQr=s(ate);hJe=r(nQr,"roberta"),nQr.forEach(t),pJe=r(dwe," \u2014 "),xS=n(dwe,"A",{href:!0});var sQr=s(xS);_Je=r(sQr,"RobertaConfig"),sQr.forEach(t),uJe=r(dwe," (RoBERTa model)"),dwe.forEach(t),bJe=i(y),zm=n(y,"LI",{});var cwe=s(zm);nte=n(cwe,"STRONG",{});var lQr=s(nte);vJe=r(lQr,"roformer"),lQr.forEach(t),FJe=r(cwe," \u2014 "),$S=n(cwe,"A",{href:!0});var iQr=s($S);TJe=r(iQr,"RoFormerConfig"),iQr.forEach(t),MJe=r(cwe," (RoFormer model)"),cwe.forEach(t),EJe=i(y),Wm=n(y,"LI",{});var fwe=s(Wm);ste=n(fwe,"STRONG",{});var dQr=s(ste);CJe=r(dQr,"segformer"),dQr.forEach(t),wJe=r(fwe," \u2014 "),kS=n(fwe,"A",{href:!0});var cQr=s(kS);AJe=r(cQr,"SegformerConfig"),cQr.forEach(t),yJe=r(fwe," (SegFormer model)"),fwe.forEach(t),LJe=i(y),Qm=n(y,"LI",{});var mwe=s(Qm);lte=n(mwe,"STRONG",{});var fQr=s(lte);xJe=r(fQr,"sew"),fQr.forEach(t),$Je=r(mwe," \u2014 "),SS=n(mwe,"A",{href:!0});var mQr=s(SS);kJe=r(mQr,"SEWConfig"),mQr.forEach(t),SJe=r(mwe," (SEW model)"),mwe.forEach(t),RJe=i(y),Hm=n(y,"LI",{});var gwe=s(Hm);ite=n(gwe,"STRONG",{});var gQr=s(ite);PJe=r(gQr,"sew-d"),gQr.forEach(t),BJe=r(gwe," \u2014 "),RS=n(gwe,"A",{href:!0});var hQr=s(RS);IJe=r(hQr,"SEWDConfig"),hQr.forEach(t),NJe=r(gwe," (SEW-D model)"),gwe.forEach(t),qJe=i(y),Um=n(y,"LI",{});var hwe=s(Um);dte=n(hwe,"STRONG",{});var pQr=s(dte);jJe=r(pQr,"speech-encoder-decoder"),pQr.forEach(t),DJe=r(hwe," \u2014 "),PS=n(hwe,"A",{href:!0});var _Qr=s(PS);GJe=r(_Qr,"SpeechEncoderDecoderConfig"),_Qr.forEach(t),OJe=r(hwe," (Speech Encoder decoder model)"),hwe.forEach(t),VJe=i(y),Jm=n(y,"LI",{});var pwe=s(Jm);cte=n(pwe,"STRONG",{});var uQr=s(cte);XJe=r(uQr,"speech_to_text"),uQr.forEach(t),zJe=r(pwe," \u2014 "),BS=n(pwe,"A",{href:!0});var bQr=s(BS);WJe=r(bQr,"Speech2TextConfig"),bQr.forEach(t),QJe=r(pwe," (Speech2Text model)"),pwe.forEach(t),HJe=i(y),Ym=n(y,"LI",{});var _we=s(Ym);fte=n(_we,"STRONG",{});var vQr=s(fte);UJe=r(vQr,"speech_to_text_2"),vQr.forEach(t),JJe=r(_we," \u2014 "),IS=n(_we,"A",{href:!0});var FQr=s(IS);YJe=r(FQr,"Speech2Text2Config"),FQr.forEach(t),KJe=r(_we," (Speech2Text2 model)"),_we.forEach(t),ZJe=i(y),Km=n(y,"LI",{});var uwe=s(Km);mte=n(uwe,"STRONG",{});var TQr=s(mte);eYe=r(TQr,"splinter"),TQr.forEach(t),oYe=r(uwe," \u2014 "),NS=n(uwe,"A",{href:!0});var MQr=s(NS);rYe=r(MQr,"SplinterConfig"),MQr.forEach(t),tYe=r(uwe," (Splinter model)"),uwe.forEach(t),aYe=i(y),Zm=n(y,"LI",{});var bwe=s(Zm);gte=n(bwe,"STRONG",{});var EQr=s(gte);nYe=r(EQr,"squeezebert"),EQr.forEach(t),sYe=r(bwe," \u2014 "),qS=n(bwe,"A",{href:!0});var CQr=s(qS);lYe=r(CQr,"SqueezeBertConfig"),CQr.forEach(t),iYe=r(bwe," (SqueezeBERT model)"),bwe.forEach(t),dYe=i(y),eg=n(y,"LI",{});var vwe=s(eg);hte=n(vwe,"STRONG",{});var wQr=s(hte);cYe=r(wQr,"swin"),wQr.forEach(t),fYe=r(vwe," \u2014 "),jS=n(vwe,"A",{href:!0});var AQr=s(jS);mYe=r(AQr,"SwinConfig"),AQr.forEach(t),gYe=r(vwe," (Swin model)"),vwe.forEach(t),hYe=i(y),og=n(y,"LI",{});var Fwe=s(og);pte=n(Fwe,"STRONG",{});var yQr=s(pte);pYe=r(yQr,"t5"),yQr.forEach(t),_Ye=r(Fwe," \u2014 "),DS=n(Fwe,"A",{href:!0});var LQr=s(DS);uYe=r(LQr,"T5Config"),LQr.forEach(t),bYe=r(Fwe," (T5 model)"),Fwe.forEach(t),vYe=i(y),rg=n(y,"LI",{});var Twe=s(rg);_te=n(Twe,"STRONG",{});var xQr=s(_te);FYe=r(xQr,"tapas"),xQr.forEach(t),TYe=r(Twe," \u2014 "),GS=n(Twe,"A",{href:!0});var $Qr=s(GS);MYe=r($Qr,"TapasConfig"),$Qr.forEach(t),EYe=r(Twe," (TAPAS model)"),Twe.forEach(t),CYe=i(y),tg=n(y,"LI",{});var Mwe=s(tg);ute=n(Mwe,"STRONG",{});var kQr=s(ute);wYe=r(kQr,"trajectory_transformer"),kQr.forEach(t),AYe=r(Mwe," \u2014 "),OS=n(Mwe,"A",{href:!0});var SQr=s(OS);yYe=r(SQr,"TrajectoryTransformerConfig"),SQr.forEach(t),LYe=r(Mwe," (Trajectory Transformer model)"),Mwe.forEach(t),xYe=i(y),ag=n(y,"LI",{});var Ewe=s(ag);bte=n(Ewe,"STRONG",{});var RQr=s(bte);$Ye=r(RQr,"transfo-xl"),RQr.forEach(t),kYe=r(Ewe," \u2014 "),VS=n(Ewe,"A",{href:!0});var PQr=s(VS);SYe=r(PQr,"TransfoXLConfig"),PQr.forEach(t),RYe=r(Ewe," (Transformer-XL model)"),Ewe.forEach(t),PYe=i(y),ng=n(y,"LI",{});var Cwe=s(ng);vte=n(Cwe,"STRONG",{});var BQr=s(vte);BYe=r(BQr,"trocr"),BQr.forEach(t),IYe=r(Cwe," \u2014 "),XS=n(Cwe,"A",{href:!0});var IQr=s(XS);NYe=r(IQr,"TrOCRConfig"),IQr.forEach(t),qYe=r(Cwe," (TrOCR model)"),Cwe.forEach(t),jYe=i(y),sg=n(y,"LI",{});var wwe=s(sg);Fte=n(wwe,"STRONG",{});var NQr=s(Fte);DYe=r(NQr,"unispeech"),NQr.forEach(t),GYe=r(wwe," \u2014 "),zS=n(wwe,"A",{href:!0});var qQr=s(zS);OYe=r(qQr,"UniSpeechConfig"),qQr.forEach(t),VYe=r(wwe," (UniSpeech model)"),wwe.forEach(t),XYe=i(y),lg=n(y,"LI",{});var Awe=s(lg);Tte=n(Awe,"STRONG",{});var jQr=s(Tte);zYe=r(jQr,"unispeech-sat"),jQr.forEach(t),WYe=r(Awe," \u2014 "),WS=n(Awe,"A",{href:!0});var DQr=s(WS);QYe=r(DQr,"UniSpeechSatConfig"),DQr.forEach(t),HYe=r(Awe," (UniSpeechSat model)"),Awe.forEach(t),UYe=i(y),ig=n(y,"LI",{});var ywe=s(ig);Mte=n(ywe,"STRONG",{});var GQr=s(Mte);JYe=r(GQr,"van"),GQr.forEach(t),YYe=r(ywe," \u2014 "),QS=n(ywe,"A",{href:!0});var OQr=s(QS);KYe=r(OQr,"VanConfig"),OQr.forEach(t),ZYe=r(ywe," (VAN model)"),ywe.forEach(t),eKe=i(y),dg=n(y,"LI",{});var Lwe=s(dg);Ete=n(Lwe,"STRONG",{});var VQr=s(Ete);oKe=r(VQr,"vilt"),VQr.forEach(t),rKe=r(Lwe," \u2014 "),HS=n(Lwe,"A",{href:!0});var XQr=s(HS);tKe=r(XQr,"ViltConfig"),XQr.forEach(t),aKe=r(Lwe," (ViLT model)"),Lwe.forEach(t),nKe=i(y),cg=n(y,"LI",{});var xwe=s(cg);Cte=n(xwe,"STRONG",{});var zQr=s(Cte);sKe=r(zQr,"vision-encoder-decoder"),zQr.forEach(t),lKe=r(xwe," \u2014 "),US=n(xwe,"A",{href:!0});var WQr=s(US);iKe=r(WQr,"VisionEncoderDecoderConfig"),WQr.forEach(t),dKe=r(xwe," (Vision Encoder decoder model)"),xwe.forEach(t),cKe=i(y),fg=n(y,"LI",{});var $we=s(fg);wte=n($we,"STRONG",{});var QQr=s(wte);fKe=r(QQr,"vision-text-dual-encoder"),QQr.forEach(t),mKe=r($we," \u2014 "),JS=n($we,"A",{href:!0});var HQr=s(JS);gKe=r(HQr,"VisionTextDualEncoderConfig"),HQr.forEach(t),hKe=r($we," (VisionTextDualEncoder model)"),$we.forEach(t),pKe=i(y),mg=n(y,"LI",{});var kwe=s(mg);Ate=n(kwe,"STRONG",{});var UQr=s(Ate);_Ke=r(UQr,"visual_bert"),UQr.forEach(t),uKe=r(kwe," \u2014 "),YS=n(kwe,"A",{href:!0});var JQr=s(YS);bKe=r(JQr,"VisualBertConfig"),JQr.forEach(t),vKe=r(kwe," (VisualBert model)"),kwe.forEach(t),FKe=i(y),gg=n(y,"LI",{});var Swe=s(gg);yte=n(Swe,"STRONG",{});var YQr=s(yte);TKe=r(YQr,"vit"),YQr.forEach(t),MKe=r(Swe," \u2014 "),KS=n(Swe,"A",{href:!0});var KQr=s(KS);EKe=r(KQr,"ViTConfig"),KQr.forEach(t),CKe=r(Swe," (ViT model)"),Swe.forEach(t),wKe=i(y),hg=n(y,"LI",{});var Rwe=s(hg);Lte=n(Rwe,"STRONG",{});var ZQr=s(Lte);AKe=r(ZQr,"vit_mae"),ZQr.forEach(t),yKe=r(Rwe," \u2014 "),ZS=n(Rwe,"A",{href:!0});var eHr=s(ZS);LKe=r(eHr,"ViTMAEConfig"),eHr.forEach(t),xKe=r(Rwe," (ViTMAE model)"),Rwe.forEach(t),$Ke=i(y),pg=n(y,"LI",{});var Pwe=s(pg);xte=n(Pwe,"STRONG",{});var oHr=s(xte);kKe=r(oHr,"wav2vec2"),oHr.forEach(t),SKe=r(Pwe," \u2014 "),eR=n(Pwe,"A",{href:!0});var rHr=s(eR);RKe=r(rHr,"Wav2Vec2Config"),rHr.forEach(t),PKe=r(Pwe," (Wav2Vec2 model)"),Pwe.forEach(t),BKe=i(y),_g=n(y,"LI",{});var Bwe=s(_g);$te=n(Bwe,"STRONG",{});var tHr=s($te);IKe=r(tHr,"wav2vec2-conformer"),tHr.forEach(t),NKe=r(Bwe," \u2014 "),oR=n(Bwe,"A",{href:!0});var aHr=s(oR);qKe=r(aHr,"Wav2Vec2ConformerConfig"),aHr.forEach(t),jKe=r(Bwe," (Wav2Vec2-Conformer model)"),Bwe.forEach(t),DKe=i(y),ug=n(y,"LI",{});var Iwe=s(ug);kte=n(Iwe,"STRONG",{});var nHr=s(kte);GKe=r(nHr,"wavlm"),nHr.forEach(t),OKe=r(Iwe," \u2014 "),rR=n(Iwe,"A",{href:!0});var sHr=s(rR);VKe=r(sHr,"WavLMConfig"),sHr.forEach(t),XKe=r(Iwe," (WavLM model)"),Iwe.forEach(t),zKe=i(y),bg=n(y,"LI",{});var Nwe=s(bg);Ste=n(Nwe,"STRONG",{});var lHr=s(Ste);WKe=r(lHr,"xglm"),lHr.forEach(t),QKe=r(Nwe," \u2014 "),tR=n(Nwe,"A",{href:!0});var iHr=s(tR);HKe=r(iHr,"XGLMConfig"),iHr.forEach(t),UKe=r(Nwe," (XGLM model)"),Nwe.forEach(t),JKe=i(y),vg=n(y,"LI",{});var qwe=s(vg);Rte=n(qwe,"STRONG",{});var dHr=s(Rte);YKe=r(dHr,"xlm"),dHr.forEach(t),KKe=r(qwe," \u2014 "),aR=n(qwe,"A",{href:!0});var cHr=s(aR);ZKe=r(cHr,"XLMConfig"),cHr.forEach(t),eZe=r(qwe," (XLM model)"),qwe.forEach(t),oZe=i(y),Fg=n(y,"LI",{});var jwe=s(Fg);Pte=n(jwe,"STRONG",{});var fHr=s(Pte);rZe=r(fHr,"xlm-prophetnet"),fHr.forEach(t),tZe=r(jwe," \u2014 "),nR=n(jwe,"A",{href:!0});var mHr=s(nR);aZe=r(mHr,"XLMProphetNetConfig"),mHr.forEach(t),nZe=r(jwe," (XLMProphetNet model)"),jwe.forEach(t),sZe=i(y),Tg=n(y,"LI",{});var Dwe=s(Tg);Bte=n(Dwe,"STRONG",{});var gHr=s(Bte);lZe=r(gHr,"xlm-roberta"),gHr.forEach(t),iZe=r(Dwe," \u2014 "),sR=n(Dwe,"A",{href:!0});var hHr=s(sR);dZe=r(hHr,"XLMRobertaConfig"),hHr.forEach(t),cZe=r(Dwe," (XLM-RoBERTa model)"),Dwe.forEach(t),fZe=i(y),Mg=n(y,"LI",{});var Gwe=s(Mg);Ite=n(Gwe,"STRONG",{});var pHr=s(Ite);mZe=r(pHr,"xlm-roberta-xl"),pHr.forEach(t),gZe=r(Gwe," \u2014 "),lR=n(Gwe,"A",{href:!0});var _Hr=s(lR);hZe=r(_Hr,"XLMRobertaXLConfig"),_Hr.forEach(t),pZe=r(Gwe," (XLM-RoBERTa-XL model)"),Gwe.forEach(t),_Ze=i(y),Eg=n(y,"LI",{});var Owe=s(Eg);Nte=n(Owe,"STRONG",{});var uHr=s(Nte);uZe=r(uHr,"xlnet"),uHr.forEach(t),bZe=r(Owe," \u2014 "),iR=n(Owe,"A",{href:!0});var bHr=s(iR);vZe=r(bHr,"XLNetConfig"),bHr.forEach(t),FZe=r(Owe," (XLNet model)"),Owe.forEach(t),TZe=i(y),Cg=n(y,"LI",{});var Vwe=s(Cg);qte=n(Vwe,"STRONG",{});var vHr=s(qte);MZe=r(vHr,"yolos"),vHr.forEach(t),EZe=r(Vwe," \u2014 "),dR=n(Vwe,"A",{href:!0});var FHr=s(dR);CZe=r(FHr,"YolosConfig"),FHr.forEach(t),wZe=r(Vwe," (YOLOS model)"),Vwe.forEach(t),AZe=i(y),wg=n(y,"LI",{});var Xwe=s(wg);jte=n(Xwe,"STRONG",{});var THr=s(jte);yZe=r(THr,"yoso"),THr.forEach(t),LZe=r(Xwe," \u2014 "),cR=n(Xwe,"A",{href:!0});var MHr=s(cR);xZe=r(MHr,"YosoConfig"),MHr.forEach(t),$Ze=r(Xwe," (YOSO model)"),Xwe.forEach(t),y.forEach(t),kZe=i(ot),T(Ag.$$.fragment,ot),ot.forEach(t),SZe=i(et),yg=n(et,"DIV",{class:!0});var DDe=s(yg);T(VA.$$.fragment,DDe),RZe=i(DDe),Dte=n(DDe,"P",{});var EHr=s(Dte);PZe=r(EHr,"Register a new configuration for this class."),EHr.forEach(t),DDe.forEach(t),et.forEach(t),Vqe=i(f),Ei=n(f,"H2",{class:!0});var GDe=s(Ei);Lg=n(GDe,"A",{id:!0,class:!0,href:!0});var CHr=s(Lg);Gte=n(CHr,"SPAN",{});var wHr=s(Gte);T(XA.$$.fragment,wHr),wHr.forEach(t),CHr.forEach(t),BZe=i(GDe),Ote=n(GDe,"SPAN",{});var AHr=s(Ote);IZe=r(AHr,"AutoTokenizer"),AHr.forEach(t),GDe.forEach(t),Xqe=i(f),wo=n(f,"DIV",{class:!0});var js=s(wo);T(zA.$$.fragment,js),NZe=i(js),WA=n(js,"P",{});var ODe=s(WA);qZe=r(ODe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),fR=n(ODe,"A",{href:!0});var yHr=s(fR);jZe=r(yHr,"AutoTokenizer.from_pretrained()"),yHr.forEach(t),DZe=r(ODe," class method."),ODe.forEach(t),GZe=i(js),QA=n(js,"P",{});var VDe=s(QA);OZe=r(VDe,"This class cannot be instantiated directly using "),Vte=n(VDe,"CODE",{});var LHr=s(Vte);VZe=r(LHr,"__init__()"),LHr.forEach(t),XZe=r(VDe," (throws an error)."),VDe.forEach(t),zZe=i(js),Cr=n(js,"DIV",{class:!0});var Ds=s(Cr);T(HA.$$.fragment,Ds),WZe=i(Ds),Xte=n(Ds,"P",{});var xHr=s(Xte);QZe=r(xHr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),xHr.forEach(t),HZe=i(Ds),Aa=n(Ds,"P",{});var qw=s(Aa);UZe=r(qw,"The tokenizer class to instantiate is selected based on the "),zte=n(qw,"CODE",{});var $Hr=s(zte);JZe=r($Hr,"model_type"),$Hr.forEach(t),YZe=r(qw,` property of the config object (either
passed as an argument or loaded from `),Wte=n(qw,"CODE",{});var kHr=s(Wte);KZe=r(kHr,"pretrained_model_name_or_path"),kHr.forEach(t),ZZe=r(qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qte=n(qw,"CODE",{});var SHr=s(Qte);eeo=r(SHr,"pretrained_model_name_or_path"),SHr.forEach(t),oeo=r(qw,":"),qw.forEach(t),reo=i(Ds),k=n(Ds,"UL",{});var S=s(k);Sn=n(S,"LI",{});var Ux=s(Sn);Hte=n(Ux,"STRONG",{});var RHr=s(Hte);teo=r(RHr,"albert"),RHr.forEach(t),aeo=r(Ux," \u2014 "),mR=n(Ux,"A",{href:!0});var PHr=s(mR);neo=r(PHr,"AlbertTokenizer"),PHr.forEach(t),seo=r(Ux," or "),gR=n(Ux,"A",{href:!0});var BHr=s(gR);leo=r(BHr,"AlbertTokenizerFast"),BHr.forEach(t),ieo=r(Ux," (ALBERT model)"),Ux.forEach(t),deo=i(S),Rn=n(S,"LI",{});var Jx=s(Rn);Ute=n(Jx,"STRONG",{});var IHr=s(Ute);ceo=r(IHr,"bart"),IHr.forEach(t),feo=r(Jx," \u2014 "),hR=n(Jx,"A",{href:!0});var NHr=s(hR);meo=r(NHr,"BartTokenizer"),NHr.forEach(t),geo=r(Jx," or "),pR=n(Jx,"A",{href:!0});var qHr=s(pR);heo=r(qHr,"BartTokenizerFast"),qHr.forEach(t),peo=r(Jx," (BART model)"),Jx.forEach(t),_eo=i(S),Pn=n(S,"LI",{});var Yx=s(Pn);Jte=n(Yx,"STRONG",{});var jHr=s(Jte);ueo=r(jHr,"barthez"),jHr.forEach(t),beo=r(Yx," \u2014 "),_R=n(Yx,"A",{href:!0});var DHr=s(_R);veo=r(DHr,"BarthezTokenizer"),DHr.forEach(t),Feo=r(Yx," or "),uR=n(Yx,"A",{href:!0});var GHr=s(uR);Teo=r(GHr,"BarthezTokenizerFast"),GHr.forEach(t),Meo=r(Yx," (BARThez model)"),Yx.forEach(t),Eeo=i(S),Bn=n(S,"LI",{});var Kx=s(Bn);Yte=n(Kx,"STRONG",{});var OHr=s(Yte);Ceo=r(OHr,"bartpho"),OHr.forEach(t),weo=r(Kx," \u2014 "),bR=n(Kx,"A",{href:!0});var VHr=s(bR);Aeo=r(VHr,"BartphoTokenizer"),VHr.forEach(t),yeo=r(Kx," or "),vR=n(Kx,"A",{href:!0});var XHr=s(vR);Leo=r(XHr,"BartphoTokenizerFast"),XHr.forEach(t),xeo=r(Kx," (BARTpho model)"),Kx.forEach(t),$eo=i(S),In=n(S,"LI",{});var Zx=s(In);Kte=n(Zx,"STRONG",{});var zHr=s(Kte);keo=r(zHr,"bert"),zHr.forEach(t),Seo=r(Zx," \u2014 "),FR=n(Zx,"A",{href:!0});var WHr=s(FR);Reo=r(WHr,"BertTokenizer"),WHr.forEach(t),Peo=r(Zx," or "),TR=n(Zx,"A",{href:!0});var QHr=s(TR);Beo=r(QHr,"BertTokenizerFast"),QHr.forEach(t),Ieo=r(Zx," (BERT model)"),Zx.forEach(t),Neo=i(S),xg=n(S,"LI",{});var zwe=s(xg);Zte=n(zwe,"STRONG",{});var HHr=s(Zte);qeo=r(HHr,"bert-generation"),HHr.forEach(t),jeo=r(zwe," \u2014 "),MR=n(zwe,"A",{href:!0});var UHr=s(MR);Deo=r(UHr,"BertGenerationTokenizer"),UHr.forEach(t),Geo=r(zwe," (Bert Generation model)"),zwe.forEach(t),Oeo=i(S),$g=n(S,"LI",{});var Wwe=s($g);eae=n(Wwe,"STRONG",{});var JHr=s(eae);Veo=r(JHr,"bert-japanese"),JHr.forEach(t),Xeo=r(Wwe," \u2014 "),ER=n(Wwe,"A",{href:!0});var YHr=s(ER);zeo=r(YHr,"BertJapaneseTokenizer"),YHr.forEach(t),Weo=r(Wwe," (BertJapanese model)"),Wwe.forEach(t),Qeo=i(S),kg=n(S,"LI",{});var Qwe=s(kg);oae=n(Qwe,"STRONG",{});var KHr=s(oae);Heo=r(KHr,"bertweet"),KHr.forEach(t),Ueo=r(Qwe," \u2014 "),CR=n(Qwe,"A",{href:!0});var ZHr=s(CR);Jeo=r(ZHr,"BertweetTokenizer"),ZHr.forEach(t),Yeo=r(Qwe," (Bertweet model)"),Qwe.forEach(t),Keo=i(S),Nn=n(S,"LI",{});var e$=s(Nn);rae=n(e$,"STRONG",{});var eUr=s(rae);Zeo=r(eUr,"big_bird"),eUr.forEach(t),eoo=r(e$," \u2014 "),wR=n(e$,"A",{href:!0});var oUr=s(wR);ooo=r(oUr,"BigBirdTokenizer"),oUr.forEach(t),roo=r(e$," or "),AR=n(e$,"A",{href:!0});var rUr=s(AR);too=r(rUr,"BigBirdTokenizerFast"),rUr.forEach(t),aoo=r(e$," (BigBird model)"),e$.forEach(t),noo=i(S),qn=n(S,"LI",{});var o$=s(qn);tae=n(o$,"STRONG",{});var tUr=s(tae);soo=r(tUr,"bigbird_pegasus"),tUr.forEach(t),loo=r(o$," \u2014 "),yR=n(o$,"A",{href:!0});var aUr=s(yR);ioo=r(aUr,"PegasusTokenizer"),aUr.forEach(t),doo=r(o$," or "),LR=n(o$,"A",{href:!0});var nUr=s(LR);coo=r(nUr,"PegasusTokenizerFast"),nUr.forEach(t),foo=r(o$," (BigBirdPegasus model)"),o$.forEach(t),moo=i(S),jn=n(S,"LI",{});var r$=s(jn);aae=n(r$,"STRONG",{});var sUr=s(aae);goo=r(sUr,"blenderbot"),sUr.forEach(t),hoo=r(r$," \u2014 "),xR=n(r$,"A",{href:!0});var lUr=s(xR);poo=r(lUr,"BlenderbotTokenizer"),lUr.forEach(t),_oo=r(r$," or "),$R=n(r$,"A",{href:!0});var iUr=s($R);uoo=r(iUr,"BlenderbotTokenizerFast"),iUr.forEach(t),boo=r(r$," (Blenderbot model)"),r$.forEach(t),voo=i(S),Sg=n(S,"LI",{});var Hwe=s(Sg);nae=n(Hwe,"STRONG",{});var dUr=s(nae);Foo=r(dUr,"blenderbot-small"),dUr.forEach(t),Too=r(Hwe," \u2014 "),kR=n(Hwe,"A",{href:!0});var cUr=s(kR);Moo=r(cUr,"BlenderbotSmallTokenizer"),cUr.forEach(t),Eoo=r(Hwe," (BlenderbotSmall model)"),Hwe.forEach(t),Coo=i(S),Rg=n(S,"LI",{});var Uwe=s(Rg);sae=n(Uwe,"STRONG",{});var fUr=s(sae);woo=r(fUr,"byt5"),fUr.forEach(t),Aoo=r(Uwe," \u2014 "),SR=n(Uwe,"A",{href:!0});var mUr=s(SR);yoo=r(mUr,"ByT5Tokenizer"),mUr.forEach(t),Loo=r(Uwe," (ByT5 model)"),Uwe.forEach(t),xoo=i(S),Dn=n(S,"LI",{});var t$=s(Dn);lae=n(t$,"STRONG",{});var gUr=s(lae);$oo=r(gUr,"camembert"),gUr.forEach(t),koo=r(t$," \u2014 "),RR=n(t$,"A",{href:!0});var hUr=s(RR);Soo=r(hUr,"CamembertTokenizer"),hUr.forEach(t),Roo=r(t$," or "),PR=n(t$,"A",{href:!0});var pUr=s(PR);Poo=r(pUr,"CamembertTokenizerFast"),pUr.forEach(t),Boo=r(t$," (CamemBERT model)"),t$.forEach(t),Ioo=i(S),Pg=n(S,"LI",{});var Jwe=s(Pg);iae=n(Jwe,"STRONG",{});var _Ur=s(iae);Noo=r(_Ur,"canine"),_Ur.forEach(t),qoo=r(Jwe," \u2014 "),BR=n(Jwe,"A",{href:!0});var uUr=s(BR);joo=r(uUr,"CanineTokenizer"),uUr.forEach(t),Doo=r(Jwe," (Canine model)"),Jwe.forEach(t),Goo=i(S),Gn=n(S,"LI",{});var a$=s(Gn);dae=n(a$,"STRONG",{});var bUr=s(dae);Ooo=r(bUr,"clip"),bUr.forEach(t),Voo=r(a$," \u2014 "),IR=n(a$,"A",{href:!0});var vUr=s(IR);Xoo=r(vUr,"CLIPTokenizer"),vUr.forEach(t),zoo=r(a$," or "),NR=n(a$,"A",{href:!0});var FUr=s(NR);Woo=r(FUr,"CLIPTokenizerFast"),FUr.forEach(t),Qoo=r(a$," (CLIP model)"),a$.forEach(t),Hoo=i(S),On=n(S,"LI",{});var n$=s(On);cae=n(n$,"STRONG",{});var TUr=s(cae);Uoo=r(TUr,"convbert"),TUr.forEach(t),Joo=r(n$," \u2014 "),qR=n(n$,"A",{href:!0});var MUr=s(qR);Yoo=r(MUr,"ConvBertTokenizer"),MUr.forEach(t),Koo=r(n$," or "),jR=n(n$,"A",{href:!0});var EUr=s(jR);Zoo=r(EUr,"ConvBertTokenizerFast"),EUr.forEach(t),ero=r(n$," (ConvBERT model)"),n$.forEach(t),oro=i(S),Vn=n(S,"LI",{});var s$=s(Vn);fae=n(s$,"STRONG",{});var CUr=s(fae);rro=r(CUr,"cpm"),CUr.forEach(t),tro=r(s$," \u2014 "),DR=n(s$,"A",{href:!0});var wUr=s(DR);aro=r(wUr,"CpmTokenizer"),wUr.forEach(t),nro=r(s$," or "),GR=n(s$,"A",{href:!0});var AUr=s(GR);sro=r(AUr,"CpmTokenizerFast"),AUr.forEach(t),lro=r(s$," (CPM model)"),s$.forEach(t),iro=i(S),Bg=n(S,"LI",{});var Ywe=s(Bg);mae=n(Ywe,"STRONG",{});var yUr=s(mae);dro=r(yUr,"ctrl"),yUr.forEach(t),cro=r(Ywe," \u2014 "),OR=n(Ywe,"A",{href:!0});var LUr=s(OR);fro=r(LUr,"CTRLTokenizer"),LUr.forEach(t),mro=r(Ywe," (CTRL model)"),Ywe.forEach(t),gro=i(S),Xn=n(S,"LI",{});var l$=s(Xn);gae=n(l$,"STRONG",{});var xUr=s(gae);hro=r(xUr,"data2vec-text"),xUr.forEach(t),pro=r(l$," \u2014 "),VR=n(l$,"A",{href:!0});var $Ur=s(VR);_ro=r($Ur,"RobertaTokenizer"),$Ur.forEach(t),uro=r(l$," or "),XR=n(l$,"A",{href:!0});var kUr=s(XR);bro=r(kUr,"RobertaTokenizerFast"),kUr.forEach(t),vro=r(l$," (Data2VecText model)"),l$.forEach(t),Fro=i(S),zn=n(S,"LI",{});var i$=s(zn);hae=n(i$,"STRONG",{});var SUr=s(hae);Tro=r(SUr,"deberta"),SUr.forEach(t),Mro=r(i$," \u2014 "),zR=n(i$,"A",{href:!0});var RUr=s(zR);Ero=r(RUr,"DebertaTokenizer"),RUr.forEach(t),Cro=r(i$," or "),WR=n(i$,"A",{href:!0});var PUr=s(WR);wro=r(PUr,"DebertaTokenizerFast"),PUr.forEach(t),Aro=r(i$," (DeBERTa model)"),i$.forEach(t),yro=i(S),Wn=n(S,"LI",{});var d$=s(Wn);pae=n(d$,"STRONG",{});var BUr=s(pae);Lro=r(BUr,"deberta-v2"),BUr.forEach(t),xro=r(d$," \u2014 "),QR=n(d$,"A",{href:!0});var IUr=s(QR);$ro=r(IUr,"DebertaV2Tokenizer"),IUr.forEach(t),kro=r(d$," or "),HR=n(d$,"A",{href:!0});var NUr=s(HR);Sro=r(NUr,"DebertaV2TokenizerFast"),NUr.forEach(t),Rro=r(d$," (DeBERTa-v2 model)"),d$.forEach(t),Pro=i(S),Qn=n(S,"LI",{});var c$=s(Qn);_ae=n(c$,"STRONG",{});var qUr=s(_ae);Bro=r(qUr,"distilbert"),qUr.forEach(t),Iro=r(c$," \u2014 "),UR=n(c$,"A",{href:!0});var jUr=s(UR);Nro=r(jUr,"DistilBertTokenizer"),jUr.forEach(t),qro=r(c$," or "),JR=n(c$,"A",{href:!0});var DUr=s(JR);jro=r(DUr,"DistilBertTokenizerFast"),DUr.forEach(t),Dro=r(c$," (DistilBERT model)"),c$.forEach(t),Gro=i(S),Hn=n(S,"LI",{});var f$=s(Hn);uae=n(f$,"STRONG",{});var GUr=s(uae);Oro=r(GUr,"dpr"),GUr.forEach(t),Vro=r(f$," \u2014 "),YR=n(f$,"A",{href:!0});var OUr=s(YR);Xro=r(OUr,"DPRQuestionEncoderTokenizer"),OUr.forEach(t),zro=r(f$," or "),KR=n(f$,"A",{href:!0});var VUr=s(KR);Wro=r(VUr,"DPRQuestionEncoderTokenizerFast"),VUr.forEach(t),Qro=r(f$," (DPR model)"),f$.forEach(t),Hro=i(S),Un=n(S,"LI",{});var m$=s(Un);bae=n(m$,"STRONG",{});var XUr=s(bae);Uro=r(XUr,"electra"),XUr.forEach(t),Jro=r(m$," \u2014 "),ZR=n(m$,"A",{href:!0});var zUr=s(ZR);Yro=r(zUr,"ElectraTokenizer"),zUr.forEach(t),Kro=r(m$," or "),eP=n(m$,"A",{href:!0});var WUr=s(eP);Zro=r(WUr,"ElectraTokenizerFast"),WUr.forEach(t),eto=r(m$," (ELECTRA model)"),m$.forEach(t),oto=i(S),Ig=n(S,"LI",{});var Kwe=s(Ig);vae=n(Kwe,"STRONG",{});var QUr=s(vae);rto=r(QUr,"flaubert"),QUr.forEach(t),tto=r(Kwe," \u2014 "),oP=n(Kwe,"A",{href:!0});var HUr=s(oP);ato=r(HUr,"FlaubertTokenizer"),HUr.forEach(t),nto=r(Kwe," (FlauBERT model)"),Kwe.forEach(t),sto=i(S),Jn=n(S,"LI",{});var g$=s(Jn);Fae=n(g$,"STRONG",{});var UUr=s(Fae);lto=r(UUr,"fnet"),UUr.forEach(t),ito=r(g$," \u2014 "),rP=n(g$,"A",{href:!0});var JUr=s(rP);dto=r(JUr,"FNetTokenizer"),JUr.forEach(t),cto=r(g$," or "),tP=n(g$,"A",{href:!0});var YUr=s(tP);fto=r(YUr,"FNetTokenizerFast"),YUr.forEach(t),mto=r(g$," (FNet model)"),g$.forEach(t),gto=i(S),Ng=n(S,"LI",{});var Zwe=s(Ng);Tae=n(Zwe,"STRONG",{});var KUr=s(Tae);hto=r(KUr,"fsmt"),KUr.forEach(t),pto=r(Zwe," \u2014 "),aP=n(Zwe,"A",{href:!0});var ZUr=s(aP);_to=r(ZUr,"FSMTTokenizer"),ZUr.forEach(t),uto=r(Zwe," (FairSeq Machine-Translation model)"),Zwe.forEach(t),bto=i(S),Yn=n(S,"LI",{});var h$=s(Yn);Mae=n(h$,"STRONG",{});var eJr=s(Mae);vto=r(eJr,"funnel"),eJr.forEach(t),Fto=r(h$," \u2014 "),nP=n(h$,"A",{href:!0});var oJr=s(nP);Tto=r(oJr,"FunnelTokenizer"),oJr.forEach(t),Mto=r(h$," or "),sP=n(h$,"A",{href:!0});var rJr=s(sP);Eto=r(rJr,"FunnelTokenizerFast"),rJr.forEach(t),Cto=r(h$," (Funnel Transformer model)"),h$.forEach(t),wto=i(S),Kn=n(S,"LI",{});var p$=s(Kn);Eae=n(p$,"STRONG",{});var tJr=s(Eae);Ato=r(tJr,"gpt2"),tJr.forEach(t),yto=r(p$," \u2014 "),lP=n(p$,"A",{href:!0});var aJr=s(lP);Lto=r(aJr,"GPT2Tokenizer"),aJr.forEach(t),xto=r(p$," or "),iP=n(p$,"A",{href:!0});var nJr=s(iP);$to=r(nJr,"GPT2TokenizerFast"),nJr.forEach(t),kto=r(p$," (OpenAI GPT-2 model)"),p$.forEach(t),Sto=i(S),Zn=n(S,"LI",{});var _$=s(Zn);Cae=n(_$,"STRONG",{});var sJr=s(Cae);Rto=r(sJr,"gpt_neo"),sJr.forEach(t),Pto=r(_$," \u2014 "),dP=n(_$,"A",{href:!0});var lJr=s(dP);Bto=r(lJr,"GPT2Tokenizer"),lJr.forEach(t),Ito=r(_$," or "),cP=n(_$,"A",{href:!0});var iJr=s(cP);Nto=r(iJr,"GPT2TokenizerFast"),iJr.forEach(t),qto=r(_$," (GPT Neo model)"),_$.forEach(t),jto=i(S),qg=n(S,"LI",{});var e6e=s(qg);wae=n(e6e,"STRONG",{});var dJr=s(wae);Dto=r(dJr,"gpt_neox"),dJr.forEach(t),Gto=r(e6e," \u2014 "),fP=n(e6e,"A",{href:!0});var cJr=s(fP);Oto=r(cJr,"GPTNeoXTokenizerFast"),cJr.forEach(t),Vto=r(e6e," (GPT NeoX model)"),e6e.forEach(t),Xto=i(S),es=n(S,"LI",{});var u$=s(es);Aae=n(u$,"STRONG",{});var fJr=s(Aae);zto=r(fJr,"gptj"),fJr.forEach(t),Wto=r(u$," \u2014 "),mP=n(u$,"A",{href:!0});var mJr=s(mP);Qto=r(mJr,"GPT2Tokenizer"),mJr.forEach(t),Hto=r(u$," or "),gP=n(u$,"A",{href:!0});var gJr=s(gP);Uto=r(gJr,"GPT2TokenizerFast"),gJr.forEach(t),Jto=r(u$," (GPT-J model)"),u$.forEach(t),Yto=i(S),os=n(S,"LI",{});var b$=s(os);yae=n(b$,"STRONG",{});var hJr=s(yae);Kto=r(hJr,"herbert"),hJr.forEach(t),Zto=r(b$," \u2014 "),hP=n(b$,"A",{href:!0});var pJr=s(hP);eao=r(pJr,"HerbertTokenizer"),pJr.forEach(t),oao=r(b$," or "),pP=n(b$,"A",{href:!0});var _Jr=s(pP);rao=r(_Jr,"HerbertTokenizerFast"),_Jr.forEach(t),tao=r(b$," (HerBERT model)"),b$.forEach(t),aao=i(S),jg=n(S,"LI",{});var o6e=s(jg);Lae=n(o6e,"STRONG",{});var uJr=s(Lae);nao=r(uJr,"hubert"),uJr.forEach(t),sao=r(o6e," \u2014 "),_P=n(o6e,"A",{href:!0});var bJr=s(_P);lao=r(bJr,"Wav2Vec2CTCTokenizer"),bJr.forEach(t),iao=r(o6e," (Hubert model)"),o6e.forEach(t),dao=i(S),rs=n(S,"LI",{});var v$=s(rs);xae=n(v$,"STRONG",{});var vJr=s(xae);cao=r(vJr,"ibert"),vJr.forEach(t),fao=r(v$," \u2014 "),uP=n(v$,"A",{href:!0});var FJr=s(uP);mao=r(FJr,"RobertaTokenizer"),FJr.forEach(t),gao=r(v$," or "),bP=n(v$,"A",{href:!0});var TJr=s(bP);hao=r(TJr,"RobertaTokenizerFast"),TJr.forEach(t),pao=r(v$," (I-BERT model)"),v$.forEach(t),_ao=i(S),ts=n(S,"LI",{});var F$=s(ts);$ae=n(F$,"STRONG",{});var MJr=s($ae);uao=r(MJr,"layoutlm"),MJr.forEach(t),bao=r(F$," \u2014 "),vP=n(F$,"A",{href:!0});var EJr=s(vP);vao=r(EJr,"LayoutLMTokenizer"),EJr.forEach(t),Fao=r(F$," or "),FP=n(F$,"A",{href:!0});var CJr=s(FP);Tao=r(CJr,"LayoutLMTokenizerFast"),CJr.forEach(t),Mao=r(F$," (LayoutLM model)"),F$.forEach(t),Eao=i(S),as=n(S,"LI",{});var T$=s(as);kae=n(T$,"STRONG",{});var wJr=s(kae);Cao=r(wJr,"layoutlmv2"),wJr.forEach(t),wao=r(T$," \u2014 "),TP=n(T$,"A",{href:!0});var AJr=s(TP);Aao=r(AJr,"LayoutLMv2Tokenizer"),AJr.forEach(t),yao=r(T$," or "),MP=n(T$,"A",{href:!0});var yJr=s(MP);Lao=r(yJr,"LayoutLMv2TokenizerFast"),yJr.forEach(t),xao=r(T$," (LayoutLMv2 model)"),T$.forEach(t),$ao=i(S),ns=n(S,"LI",{});var M$=s(ns);Sae=n(M$,"STRONG",{});var LJr=s(Sae);kao=r(LJr,"layoutlmv3"),LJr.forEach(t),Sao=r(M$," \u2014 "),EP=n(M$,"A",{href:!0});var xJr=s(EP);Rao=r(xJr,"LayoutLMv3Tokenizer"),xJr.forEach(t),Pao=r(M$," or "),CP=n(M$,"A",{href:!0});var $Jr=s(CP);Bao=r($Jr,"LayoutLMv3TokenizerFast"),$Jr.forEach(t),Iao=r(M$," (LayoutLMv3 model)"),M$.forEach(t),Nao=i(S),ss=n(S,"LI",{});var E$=s(ss);Rae=n(E$,"STRONG",{});var kJr=s(Rae);qao=r(kJr,"layoutxlm"),kJr.forEach(t),jao=r(E$," \u2014 "),wP=n(E$,"A",{href:!0});var SJr=s(wP);Dao=r(SJr,"LayoutXLMTokenizer"),SJr.forEach(t),Gao=r(E$," or "),AP=n(E$,"A",{href:!0});var RJr=s(AP);Oao=r(RJr,"LayoutXLMTokenizerFast"),RJr.forEach(t),Vao=r(E$," (LayoutXLM model)"),E$.forEach(t),Xao=i(S),ls=n(S,"LI",{});var C$=s(ls);Pae=n(C$,"STRONG",{});var PJr=s(Pae);zao=r(PJr,"led"),PJr.forEach(t),Wao=r(C$," \u2014 "),yP=n(C$,"A",{href:!0});var BJr=s(yP);Qao=r(BJr,"LEDTokenizer"),BJr.forEach(t),Hao=r(C$," or "),LP=n(C$,"A",{href:!0});var IJr=s(LP);Uao=r(IJr,"LEDTokenizerFast"),IJr.forEach(t),Jao=r(C$," (LED model)"),C$.forEach(t),Yao=i(S),is=n(S,"LI",{});var w$=s(is);Bae=n(w$,"STRONG",{});var NJr=s(Bae);Kao=r(NJr,"longformer"),NJr.forEach(t),Zao=r(w$," \u2014 "),xP=n(w$,"A",{href:!0});var qJr=s(xP);eno=r(qJr,"LongformerTokenizer"),qJr.forEach(t),ono=r(w$," or "),$P=n(w$,"A",{href:!0});var jJr=s($P);rno=r(jJr,"LongformerTokenizerFast"),jJr.forEach(t),tno=r(w$," (Longformer model)"),w$.forEach(t),ano=i(S),Dg=n(S,"LI",{});var r6e=s(Dg);Iae=n(r6e,"STRONG",{});var DJr=s(Iae);nno=r(DJr,"luke"),DJr.forEach(t),sno=r(r6e," \u2014 "),kP=n(r6e,"A",{href:!0});var GJr=s(kP);lno=r(GJr,"LukeTokenizer"),GJr.forEach(t),ino=r(r6e," (LUKE model)"),r6e.forEach(t),dno=i(S),ds=n(S,"LI",{});var A$=s(ds);Nae=n(A$,"STRONG",{});var OJr=s(Nae);cno=r(OJr,"lxmert"),OJr.forEach(t),fno=r(A$," \u2014 "),SP=n(A$,"A",{href:!0});var VJr=s(SP);mno=r(VJr,"LxmertTokenizer"),VJr.forEach(t),gno=r(A$," or "),RP=n(A$,"A",{href:!0});var XJr=s(RP);hno=r(XJr,"LxmertTokenizerFast"),XJr.forEach(t),pno=r(A$," (LXMERT model)"),A$.forEach(t),_no=i(S),Gg=n(S,"LI",{});var t6e=s(Gg);qae=n(t6e,"STRONG",{});var zJr=s(qae);uno=r(zJr,"m2m_100"),zJr.forEach(t),bno=r(t6e," \u2014 "),PP=n(t6e,"A",{href:!0});var WJr=s(PP);vno=r(WJr,"M2M100Tokenizer"),WJr.forEach(t),Fno=r(t6e," (M2M100 model)"),t6e.forEach(t),Tno=i(S),Og=n(S,"LI",{});var a6e=s(Og);jae=n(a6e,"STRONG",{});var QJr=s(jae);Mno=r(QJr,"marian"),QJr.forEach(t),Eno=r(a6e," \u2014 "),BP=n(a6e,"A",{href:!0});var HJr=s(BP);Cno=r(HJr,"MarianTokenizer"),HJr.forEach(t),wno=r(a6e," (Marian model)"),a6e.forEach(t),Ano=i(S),cs=n(S,"LI",{});var y$=s(cs);Dae=n(y$,"STRONG",{});var UJr=s(Dae);yno=r(UJr,"mbart"),UJr.forEach(t),Lno=r(y$," \u2014 "),IP=n(y$,"A",{href:!0});var JJr=s(IP);xno=r(JJr,"MBartTokenizer"),JJr.forEach(t),$no=r(y$," or "),NP=n(y$,"A",{href:!0});var YJr=s(NP);kno=r(YJr,"MBartTokenizerFast"),YJr.forEach(t),Sno=r(y$," (mBART model)"),y$.forEach(t),Rno=i(S),fs=n(S,"LI",{});var L$=s(fs);Gae=n(L$,"STRONG",{});var KJr=s(Gae);Pno=r(KJr,"mbart50"),KJr.forEach(t),Bno=r(L$," \u2014 "),qP=n(L$,"A",{href:!0});var ZJr=s(qP);Ino=r(ZJr,"MBart50Tokenizer"),ZJr.forEach(t),Nno=r(L$," or "),jP=n(L$,"A",{href:!0});var eYr=s(jP);qno=r(eYr,"MBart50TokenizerFast"),eYr.forEach(t),jno=r(L$," (mBART-50 model)"),L$.forEach(t),Dno=i(S),ms=n(S,"LI",{});var x$=s(ms);Oae=n(x$,"STRONG",{});var oYr=s(Oae);Gno=r(oYr,"megatron-bert"),oYr.forEach(t),Ono=r(x$," \u2014 "),DP=n(x$,"A",{href:!0});var rYr=s(DP);Vno=r(rYr,"BertTokenizer"),rYr.forEach(t),Xno=r(x$," or "),GP=n(x$,"A",{href:!0});var tYr=s(GP);zno=r(tYr,"BertTokenizerFast"),tYr.forEach(t),Wno=r(x$," (MegatronBert model)"),x$.forEach(t),Qno=i(S),Vg=n(S,"LI",{});var n6e=s(Vg);Vae=n(n6e,"STRONG",{});var aYr=s(Vae);Hno=r(aYr,"mluke"),aYr.forEach(t),Uno=r(n6e," \u2014 "),OP=n(n6e,"A",{href:!0});var nYr=s(OP);Jno=r(nYr,"MLukeTokenizer"),nYr.forEach(t),Yno=r(n6e," (mLUKE model)"),n6e.forEach(t),Kno=i(S),gs=n(S,"LI",{});var $$=s(gs);Xae=n($$,"STRONG",{});var sYr=s(Xae);Zno=r(sYr,"mobilebert"),sYr.forEach(t),eso=r($$," \u2014 "),VP=n($$,"A",{href:!0});var lYr=s(VP);oso=r(lYr,"MobileBertTokenizer"),lYr.forEach(t),rso=r($$," or "),XP=n($$,"A",{href:!0});var iYr=s(XP);tso=r(iYr,"MobileBertTokenizerFast"),iYr.forEach(t),aso=r($$," (MobileBERT model)"),$$.forEach(t),nso=i(S),hs=n(S,"LI",{});var k$=s(hs);zae=n(k$,"STRONG",{});var dYr=s(zae);sso=r(dYr,"mpnet"),dYr.forEach(t),lso=r(k$," \u2014 "),zP=n(k$,"A",{href:!0});var cYr=s(zP);iso=r(cYr,"MPNetTokenizer"),cYr.forEach(t),dso=r(k$," or "),WP=n(k$,"A",{href:!0});var fYr=s(WP);cso=r(fYr,"MPNetTokenizerFast"),fYr.forEach(t),fso=r(k$," (MPNet model)"),k$.forEach(t),mso=i(S),ps=n(S,"LI",{});var S$=s(ps);Wae=n(S$,"STRONG",{});var mYr=s(Wae);gso=r(mYr,"mt5"),mYr.forEach(t),hso=r(S$," \u2014 "),QP=n(S$,"A",{href:!0});var gYr=s(QP);pso=r(gYr,"MT5Tokenizer"),gYr.forEach(t),_so=r(S$," or "),HP=n(S$,"A",{href:!0});var hYr=s(HP);uso=r(hYr,"MT5TokenizerFast"),hYr.forEach(t),bso=r(S$," (mT5 model)"),S$.forEach(t),vso=i(S),_s=n(S,"LI",{});var R$=s(_s);Qae=n(R$,"STRONG",{});var pYr=s(Qae);Fso=r(pYr,"nystromformer"),pYr.forEach(t),Tso=r(R$," \u2014 "),UP=n(R$,"A",{href:!0});var _Yr=s(UP);Mso=r(_Yr,"AlbertTokenizer"),_Yr.forEach(t),Eso=r(R$," or "),JP=n(R$,"A",{href:!0});var uYr=s(JP);Cso=r(uYr,"AlbertTokenizerFast"),uYr.forEach(t),wso=r(R$," (Nystromformer model)"),R$.forEach(t),Aso=i(S),us=n(S,"LI",{});var P$=s(us);Hae=n(P$,"STRONG",{});var bYr=s(Hae);yso=r(bYr,"openai-gpt"),bYr.forEach(t),Lso=r(P$," \u2014 "),YP=n(P$,"A",{href:!0});var vYr=s(YP);xso=r(vYr,"OpenAIGPTTokenizer"),vYr.forEach(t),$so=r(P$," or "),KP=n(P$,"A",{href:!0});var FYr=s(KP);kso=r(FYr,"OpenAIGPTTokenizerFast"),FYr.forEach(t),Sso=r(P$," (OpenAI GPT model)"),P$.forEach(t),Rso=i(S),Xg=n(S,"LI",{});var s6e=s(Xg);Uae=n(s6e,"STRONG",{});var TYr=s(Uae);Pso=r(TYr,"opt"),TYr.forEach(t),Bso=r(s6e," \u2014 "),ZP=n(s6e,"A",{href:!0});var MYr=s(ZP);Iso=r(MYr,"GPT2Tokenizer"),MYr.forEach(t),Nso=r(s6e," (OPT model)"),s6e.forEach(t),qso=i(S),bs=n(S,"LI",{});var B$=s(bs);Jae=n(B$,"STRONG",{});var EYr=s(Jae);jso=r(EYr,"pegasus"),EYr.forEach(t),Dso=r(B$," \u2014 "),eB=n(B$,"A",{href:!0});var CYr=s(eB);Gso=r(CYr,"PegasusTokenizer"),CYr.forEach(t),Oso=r(B$," or "),oB=n(B$,"A",{href:!0});var wYr=s(oB);Vso=r(wYr,"PegasusTokenizerFast"),wYr.forEach(t),Xso=r(B$," (Pegasus model)"),B$.forEach(t),zso=i(S),zg=n(S,"LI",{});var l6e=s(zg);Yae=n(l6e,"STRONG",{});var AYr=s(Yae);Wso=r(AYr,"perceiver"),AYr.forEach(t),Qso=r(l6e," \u2014 "),rB=n(l6e,"A",{href:!0});var yYr=s(rB);Hso=r(yYr,"PerceiverTokenizer"),yYr.forEach(t),Uso=r(l6e," (Perceiver model)"),l6e.forEach(t),Jso=i(S),Wg=n(S,"LI",{});var i6e=s(Wg);Kae=n(i6e,"STRONG",{});var LYr=s(Kae);Yso=r(LYr,"phobert"),LYr.forEach(t),Kso=r(i6e," \u2014 "),tB=n(i6e,"A",{href:!0});var xYr=s(tB);Zso=r(xYr,"PhobertTokenizer"),xYr.forEach(t),elo=r(i6e," (PhoBERT model)"),i6e.forEach(t),olo=i(S),Qg=n(S,"LI",{});var d6e=s(Qg);Zae=n(d6e,"STRONG",{});var $Yr=s(Zae);rlo=r($Yr,"plbart"),$Yr.forEach(t),tlo=r(d6e," \u2014 "),aB=n(d6e,"A",{href:!0});var kYr=s(aB);alo=r(kYr,"PLBartTokenizer"),kYr.forEach(t),nlo=r(d6e," (PLBart model)"),d6e.forEach(t),slo=i(S),Hg=n(S,"LI",{});var c6e=s(Hg);ene=n(c6e,"STRONG",{});var SYr=s(ene);llo=r(SYr,"prophetnet"),SYr.forEach(t),ilo=r(c6e," \u2014 "),nB=n(c6e,"A",{href:!0});var RYr=s(nB);dlo=r(RYr,"ProphetNetTokenizer"),RYr.forEach(t),clo=r(c6e," (ProphetNet model)"),c6e.forEach(t),flo=i(S),vs=n(S,"LI",{});var I$=s(vs);one=n(I$,"STRONG",{});var PYr=s(one);mlo=r(PYr,"qdqbert"),PYr.forEach(t),glo=r(I$," \u2014 "),sB=n(I$,"A",{href:!0});var BYr=s(sB);hlo=r(BYr,"BertTokenizer"),BYr.forEach(t),plo=r(I$," or "),lB=n(I$,"A",{href:!0});var IYr=s(lB);_lo=r(IYr,"BertTokenizerFast"),IYr.forEach(t),ulo=r(I$," (QDQBert model)"),I$.forEach(t),blo=i(S),Ug=n(S,"LI",{});var f6e=s(Ug);rne=n(f6e,"STRONG",{});var NYr=s(rne);vlo=r(NYr,"rag"),NYr.forEach(t),Flo=r(f6e," \u2014 "),iB=n(f6e,"A",{href:!0});var qYr=s(iB);Tlo=r(qYr,"RagTokenizer"),qYr.forEach(t),Mlo=r(f6e," (RAG model)"),f6e.forEach(t),Elo=i(S),Fs=n(S,"LI",{});var N$=s(Fs);tne=n(N$,"STRONG",{});var jYr=s(tne);Clo=r(jYr,"realm"),jYr.forEach(t),wlo=r(N$," \u2014 "),dB=n(N$,"A",{href:!0});var DYr=s(dB);Alo=r(DYr,"RealmTokenizer"),DYr.forEach(t),ylo=r(N$," or "),cB=n(N$,"A",{href:!0});var GYr=s(cB);Llo=r(GYr,"RealmTokenizerFast"),GYr.forEach(t),xlo=r(N$," (Realm model)"),N$.forEach(t),$lo=i(S),Ts=n(S,"LI",{});var q$=s(Ts);ane=n(q$,"STRONG",{});var OYr=s(ane);klo=r(OYr,"reformer"),OYr.forEach(t),Slo=r(q$," \u2014 "),fB=n(q$,"A",{href:!0});var VYr=s(fB);Rlo=r(VYr,"ReformerTokenizer"),VYr.forEach(t),Plo=r(q$," or "),mB=n(q$,"A",{href:!0});var XYr=s(mB);Blo=r(XYr,"ReformerTokenizerFast"),XYr.forEach(t),Ilo=r(q$," (Reformer model)"),q$.forEach(t),Nlo=i(S),Ms=n(S,"LI",{});var j$=s(Ms);nne=n(j$,"STRONG",{});var zYr=s(nne);qlo=r(zYr,"rembert"),zYr.forEach(t),jlo=r(j$," \u2014 "),gB=n(j$,"A",{href:!0});var WYr=s(gB);Dlo=r(WYr,"RemBertTokenizer"),WYr.forEach(t),Glo=r(j$," or "),hB=n(j$,"A",{href:!0});var QYr=s(hB);Olo=r(QYr,"RemBertTokenizerFast"),QYr.forEach(t),Vlo=r(j$," (RemBERT model)"),j$.forEach(t),Xlo=i(S),Es=n(S,"LI",{});var D$=s(Es);sne=n(D$,"STRONG",{});var HYr=s(sne);zlo=r(HYr,"retribert"),HYr.forEach(t),Wlo=r(D$," \u2014 "),pB=n(D$,"A",{href:!0});var UYr=s(pB);Qlo=r(UYr,"RetriBertTokenizer"),UYr.forEach(t),Hlo=r(D$," or "),_B=n(D$,"A",{href:!0});var JYr=s(_B);Ulo=r(JYr,"RetriBertTokenizerFast"),JYr.forEach(t),Jlo=r(D$," (RetriBERT model)"),D$.forEach(t),Ylo=i(S),Cs=n(S,"LI",{});var G$=s(Cs);lne=n(G$,"STRONG",{});var YYr=s(lne);Klo=r(YYr,"roberta"),YYr.forEach(t),Zlo=r(G$," \u2014 "),uB=n(G$,"A",{href:!0});var KYr=s(uB);eio=r(KYr,"RobertaTokenizer"),KYr.forEach(t),oio=r(G$," or "),bB=n(G$,"A",{href:!0});var ZYr=s(bB);rio=r(ZYr,"RobertaTokenizerFast"),ZYr.forEach(t),tio=r(G$," (RoBERTa model)"),G$.forEach(t),aio=i(S),ws=n(S,"LI",{});var O$=s(ws);ine=n(O$,"STRONG",{});var eKr=s(ine);nio=r(eKr,"roformer"),eKr.forEach(t),sio=r(O$," \u2014 "),vB=n(O$,"A",{href:!0});var oKr=s(vB);lio=r(oKr,"RoFormerTokenizer"),oKr.forEach(t),iio=r(O$," or "),FB=n(O$,"A",{href:!0});var rKr=s(FB);dio=r(rKr,"RoFormerTokenizerFast"),rKr.forEach(t),cio=r(O$," (RoFormer model)"),O$.forEach(t),fio=i(S),Jg=n(S,"LI",{});var m6e=s(Jg);dne=n(m6e,"STRONG",{});var tKr=s(dne);mio=r(tKr,"speech_to_text"),tKr.forEach(t),gio=r(m6e," \u2014 "),TB=n(m6e,"A",{href:!0});var aKr=s(TB);hio=r(aKr,"Speech2TextTokenizer"),aKr.forEach(t),pio=r(m6e," (Speech2Text model)"),m6e.forEach(t),_io=i(S),Yg=n(S,"LI",{});var g6e=s(Yg);cne=n(g6e,"STRONG",{});var nKr=s(cne);uio=r(nKr,"speech_to_text_2"),nKr.forEach(t),bio=r(g6e," \u2014 "),MB=n(g6e,"A",{href:!0});var sKr=s(MB);vio=r(sKr,"Speech2Text2Tokenizer"),sKr.forEach(t),Fio=r(g6e," (Speech2Text2 model)"),g6e.forEach(t),Tio=i(S),As=n(S,"LI",{});var V$=s(As);fne=n(V$,"STRONG",{});var lKr=s(fne);Mio=r(lKr,"splinter"),lKr.forEach(t),Eio=r(V$," \u2014 "),EB=n(V$,"A",{href:!0});var iKr=s(EB);Cio=r(iKr,"SplinterTokenizer"),iKr.forEach(t),wio=r(V$," or "),CB=n(V$,"A",{href:!0});var dKr=s(CB);Aio=r(dKr,"SplinterTokenizerFast"),dKr.forEach(t),yio=r(V$," (Splinter model)"),V$.forEach(t),Lio=i(S),ys=n(S,"LI",{});var X$=s(ys);mne=n(X$,"STRONG",{});var cKr=s(mne);xio=r(cKr,"squeezebert"),cKr.forEach(t),$io=r(X$," \u2014 "),wB=n(X$,"A",{href:!0});var fKr=s(wB);kio=r(fKr,"SqueezeBertTokenizer"),fKr.forEach(t),Sio=r(X$," or "),AB=n(X$,"A",{href:!0});var mKr=s(AB);Rio=r(mKr,"SqueezeBertTokenizerFast"),mKr.forEach(t),Pio=r(X$," (SqueezeBERT model)"),X$.forEach(t),Bio=i(S),Ls=n(S,"LI",{});var z$=s(Ls);gne=n(z$,"STRONG",{});var gKr=s(gne);Iio=r(gKr,"t5"),gKr.forEach(t),Nio=r(z$," \u2014 "),yB=n(z$,"A",{href:!0});var hKr=s(yB);qio=r(hKr,"T5Tokenizer"),hKr.forEach(t),jio=r(z$," or "),LB=n(z$,"A",{href:!0});var pKr=s(LB);Dio=r(pKr,"T5TokenizerFast"),pKr.forEach(t),Gio=r(z$," (T5 model)"),z$.forEach(t),Oio=i(S),Kg=n(S,"LI",{});var h6e=s(Kg);hne=n(h6e,"STRONG",{});var _Kr=s(hne);Vio=r(_Kr,"tapas"),_Kr.forEach(t),Xio=r(h6e," \u2014 "),xB=n(h6e,"A",{href:!0});var uKr=s(xB);zio=r(uKr,"TapasTokenizer"),uKr.forEach(t),Wio=r(h6e," (TAPAS model)"),h6e.forEach(t),Qio=i(S),Zg=n(S,"LI",{});var p6e=s(Zg);pne=n(p6e,"STRONG",{});var bKr=s(pne);Hio=r(bKr,"tapex"),bKr.forEach(t),Uio=r(p6e," \u2014 "),$B=n(p6e,"A",{href:!0});var vKr=s($B);Jio=r(vKr,"TapexTokenizer"),vKr.forEach(t),Yio=r(p6e," (TAPEX model)"),p6e.forEach(t),Kio=i(S),eh=n(S,"LI",{});var _6e=s(eh);_ne=n(_6e,"STRONG",{});var FKr=s(_ne);Zio=r(FKr,"transfo-xl"),FKr.forEach(t),edo=r(_6e," \u2014 "),kB=n(_6e,"A",{href:!0});var TKr=s(kB);odo=r(TKr,"TransfoXLTokenizer"),TKr.forEach(t),rdo=r(_6e," (Transformer-XL model)"),_6e.forEach(t),tdo=i(S),xs=n(S,"LI",{});var W$=s(xs);une=n(W$,"STRONG",{});var MKr=s(une);ado=r(MKr,"visual_bert"),MKr.forEach(t),ndo=r(W$," \u2014 "),SB=n(W$,"A",{href:!0});var EKr=s(SB);sdo=r(EKr,"BertTokenizer"),EKr.forEach(t),ldo=r(W$," or "),RB=n(W$,"A",{href:!0});var CKr=s(RB);ido=r(CKr,"BertTokenizerFast"),CKr.forEach(t),ddo=r(W$," (VisualBert model)"),W$.forEach(t),cdo=i(S),oh=n(S,"LI",{});var u6e=s(oh);bne=n(u6e,"STRONG",{});var wKr=s(bne);fdo=r(wKr,"wav2vec2"),wKr.forEach(t),mdo=r(u6e," \u2014 "),PB=n(u6e,"A",{href:!0});var AKr=s(PB);gdo=r(AKr,"Wav2Vec2CTCTokenizer"),AKr.forEach(t),hdo=r(u6e," (Wav2Vec2 model)"),u6e.forEach(t),pdo=i(S),rh=n(S,"LI",{});var b6e=s(rh);vne=n(b6e,"STRONG",{});var yKr=s(vne);_do=r(yKr,"wav2vec2-conformer"),yKr.forEach(t),udo=r(b6e," \u2014 "),BB=n(b6e,"A",{href:!0});var LKr=s(BB);bdo=r(LKr,"Wav2Vec2CTCTokenizer"),LKr.forEach(t),vdo=r(b6e," (Wav2Vec2-Conformer model)"),b6e.forEach(t),Fdo=i(S),th=n(S,"LI",{});var v6e=s(th);Fne=n(v6e,"STRONG",{});var xKr=s(Fne);Tdo=r(xKr,"wav2vec2_phoneme"),xKr.forEach(t),Mdo=r(v6e," \u2014 "),IB=n(v6e,"A",{href:!0});var $Kr=s(IB);Edo=r($Kr,"Wav2Vec2PhonemeCTCTokenizer"),$Kr.forEach(t),Cdo=r(v6e," (Wav2Vec2Phoneme model)"),v6e.forEach(t),wdo=i(S),$s=n(S,"LI",{});var Q$=s($s);Tne=n(Q$,"STRONG",{});var kKr=s(Tne);Ado=r(kKr,"xglm"),kKr.forEach(t),ydo=r(Q$," \u2014 "),NB=n(Q$,"A",{href:!0});var SKr=s(NB);Ldo=r(SKr,"XGLMTokenizer"),SKr.forEach(t),xdo=r(Q$," or "),qB=n(Q$,"A",{href:!0});var RKr=s(qB);$do=r(RKr,"XGLMTokenizerFast"),RKr.forEach(t),kdo=r(Q$," (XGLM model)"),Q$.forEach(t),Sdo=i(S),ah=n(S,"LI",{});var F6e=s(ah);Mne=n(F6e,"STRONG",{});var PKr=s(Mne);Rdo=r(PKr,"xlm"),PKr.forEach(t),Pdo=r(F6e," \u2014 "),jB=n(F6e,"A",{href:!0});var BKr=s(jB);Bdo=r(BKr,"XLMTokenizer"),BKr.forEach(t),Ido=r(F6e," (XLM model)"),F6e.forEach(t),Ndo=i(S),nh=n(S,"LI",{});var T6e=s(nh);Ene=n(T6e,"STRONG",{});var IKr=s(Ene);qdo=r(IKr,"xlm-prophetnet"),IKr.forEach(t),jdo=r(T6e," \u2014 "),DB=n(T6e,"A",{href:!0});var NKr=s(DB);Ddo=r(NKr,"XLMProphetNetTokenizer"),NKr.forEach(t),Gdo=r(T6e," (XLMProphetNet model)"),T6e.forEach(t),Odo=i(S),ks=n(S,"LI",{});var H$=s(ks);Cne=n(H$,"STRONG",{});var qKr=s(Cne);Vdo=r(qKr,"xlm-roberta"),qKr.forEach(t),Xdo=r(H$," \u2014 "),GB=n(H$,"A",{href:!0});var jKr=s(GB);zdo=r(jKr,"XLMRobertaTokenizer"),jKr.forEach(t),Wdo=r(H$," or "),OB=n(H$,"A",{href:!0});var DKr=s(OB);Qdo=r(DKr,"XLMRobertaTokenizerFast"),DKr.forEach(t),Hdo=r(H$," (XLM-RoBERTa model)"),H$.forEach(t),Udo=i(S),Ss=n(S,"LI",{});var U$=s(Ss);wne=n(U$,"STRONG",{});var GKr=s(wne);Jdo=r(GKr,"xlm-roberta-xl"),GKr.forEach(t),Ydo=r(U$," \u2014 "),VB=n(U$,"A",{href:!0});var OKr=s(VB);Kdo=r(OKr,"RobertaTokenizer"),OKr.forEach(t),Zdo=r(U$," or "),XB=n(U$,"A",{href:!0});var VKr=s(XB);eco=r(VKr,"RobertaTokenizerFast"),VKr.forEach(t),oco=r(U$," (XLM-RoBERTa-XL model)"),U$.forEach(t),rco=i(S),Rs=n(S,"LI",{});var J$=s(Rs);Ane=n(J$,"STRONG",{});var XKr=s(Ane);tco=r(XKr,"xlnet"),XKr.forEach(t),aco=r(J$," \u2014 "),zB=n(J$,"A",{href:!0});var zKr=s(zB);nco=r(zKr,"XLNetTokenizer"),zKr.forEach(t),sco=r(J$," or "),WB=n(J$,"A",{href:!0});var WKr=s(WB);lco=r(WKr,"XLNetTokenizerFast"),WKr.forEach(t),ico=r(J$," (XLNet model)"),J$.forEach(t),dco=i(S),Ps=n(S,"LI",{});var Y$=s(Ps);yne=n(Y$,"STRONG",{});var QKr=s(yne);cco=r(QKr,"yoso"),QKr.forEach(t),fco=r(Y$," \u2014 "),QB=n(Y$,"A",{href:!0});var HKr=s(QB);mco=r(HKr,"AlbertTokenizer"),HKr.forEach(t),gco=r(Y$," or "),HB=n(Y$,"A",{href:!0});var UKr=s(HB);hco=r(UKr,"AlbertTokenizerFast"),UKr.forEach(t),pco=r(Y$," (YOSO model)"),Y$.forEach(t),S.forEach(t),_co=i(Ds),T(sh.$$.fragment,Ds),Ds.forEach(t),uco=i(js),lh=n(js,"DIV",{class:!0});var XDe=s(lh);T(UA.$$.fragment,XDe),bco=i(XDe),Lne=n(XDe,"P",{});var JKr=s(Lne);vco=r(JKr,"Register a new tokenizer in this mapping."),JKr.forEach(t),XDe.forEach(t),js.forEach(t),zqe=i(f),Ci=n(f,"H2",{class:!0});var zDe=s(Ci);ih=n(zDe,"A",{id:!0,class:!0,href:!0});var YKr=s(ih);xne=n(YKr,"SPAN",{});var KKr=s(xne);T(JA.$$.fragment,KKr),KKr.forEach(t),YKr.forEach(t),Fco=i(zDe),$ne=n(zDe,"SPAN",{});var ZKr=s($ne);Tco=r(ZKr,"AutoFeatureExtractor"),ZKr.forEach(t),zDe.forEach(t),Wqe=i(f),Ao=n(f,"DIV",{class:!0});var Gs=s(Ao);T(YA.$$.fragment,Gs),Mco=i(Gs),KA=n(Gs,"P",{});var WDe=s(KA);Eco=r(WDe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),UB=n(WDe,"A",{href:!0});var eZr=s(UB);Cco=r(eZr,"AutoFeatureExtractor.from_pretrained()"),eZr.forEach(t),wco=r(WDe," class method."),WDe.forEach(t),Aco=i(Gs),ZA=n(Gs,"P",{});var QDe=s(ZA);yco=r(QDe,"This class cannot be instantiated directly using "),kne=n(QDe,"CODE",{});var oZr=s(kne);Lco=r(oZr,"__init__()"),oZr.forEach(t),xco=r(QDe," (throws an error)."),QDe.forEach(t),$co=i(Gs),He=n(Gs,"DIV",{class:!0});var Zt=s(He);T(ey.$$.fragment,Zt),kco=i(Zt),Sne=n(Zt,"P",{});var rZr=s(Sne);Sco=r(rZr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),rZr.forEach(t),Rco=i(Zt),ya=n(Zt,"P",{});var jw=s(ya);Pco=r(jw,"The feature extractor class to instantiate is selected based on the "),Rne=n(jw,"CODE",{});var tZr=s(Rne);Bco=r(tZr,"model_type"),tZr.forEach(t),Ico=r(jw,` property of the config object
(either passed as an argument or loaded from `),Pne=n(jw,"CODE",{});var aZr=s(Pne);Nco=r(aZr,"pretrained_model_name_or_path"),aZr.forEach(t),qco=r(jw,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Bne=n(jw,"CODE",{});var nZr=s(Bne);jco=r(nZr,"pretrained_model_name_or_path"),nZr.forEach(t),Dco=r(jw,":"),jw.forEach(t),Gco=i(Zt),Y=n(Zt,"UL",{});var Z=s(Y);dh=n(Z,"LI",{});var M6e=s(dh);Ine=n(M6e,"STRONG",{});var sZr=s(Ine);Oco=r(sZr,"beit"),sZr.forEach(t),Vco=r(M6e," \u2014 "),JB=n(M6e,"A",{href:!0});var lZr=s(JB);Xco=r(lZr,"BeitFeatureExtractor"),lZr.forEach(t),zco=r(M6e," (BEiT model)"),M6e.forEach(t),Wco=i(Z),ch=n(Z,"LI",{});var E6e=s(ch);Nne=n(E6e,"STRONG",{});var iZr=s(Nne);Qco=r(iZr,"clip"),iZr.forEach(t),Hco=r(E6e," \u2014 "),YB=n(E6e,"A",{href:!0});var dZr=s(YB);Uco=r(dZr,"CLIPFeatureExtractor"),dZr.forEach(t),Jco=r(E6e," (CLIP model)"),E6e.forEach(t),Yco=i(Z),fh=n(Z,"LI",{});var C6e=s(fh);qne=n(C6e,"STRONG",{});var cZr=s(qne);Kco=r(cZr,"convnext"),cZr.forEach(t),Zco=r(C6e," \u2014 "),KB=n(C6e,"A",{href:!0});var fZr=s(KB);efo=r(fZr,"ConvNextFeatureExtractor"),fZr.forEach(t),ofo=r(C6e," (ConvNext model)"),C6e.forEach(t),rfo=i(Z),mh=n(Z,"LI",{});var w6e=s(mh);jne=n(w6e,"STRONG",{});var mZr=s(jne);tfo=r(mZr,"cvt"),mZr.forEach(t),afo=r(w6e," \u2014 "),ZB=n(w6e,"A",{href:!0});var gZr=s(ZB);nfo=r(gZr,"ConvNextFeatureExtractor"),gZr.forEach(t),sfo=r(w6e," (CvT model)"),w6e.forEach(t),lfo=i(Z),gh=n(Z,"LI",{});var A6e=s(gh);Dne=n(A6e,"STRONG",{});var hZr=s(Dne);ifo=r(hZr,"data2vec-audio"),hZr.forEach(t),dfo=r(A6e," \u2014 "),eI=n(A6e,"A",{href:!0});var pZr=s(eI);cfo=r(pZr,"Wav2Vec2FeatureExtractor"),pZr.forEach(t),ffo=r(A6e," (Data2VecAudio model)"),A6e.forEach(t),mfo=i(Z),hh=n(Z,"LI",{});var y6e=s(hh);Gne=n(y6e,"STRONG",{});var _Zr=s(Gne);gfo=r(_Zr,"data2vec-vision"),_Zr.forEach(t),hfo=r(y6e," \u2014 "),oI=n(y6e,"A",{href:!0});var uZr=s(oI);pfo=r(uZr,"BeitFeatureExtractor"),uZr.forEach(t),_fo=r(y6e," (Data2VecVision model)"),y6e.forEach(t),ufo=i(Z),ph=n(Z,"LI",{});var L6e=s(ph);One=n(L6e,"STRONG",{});var bZr=s(One);bfo=r(bZr,"deit"),bZr.forEach(t),vfo=r(L6e," \u2014 "),rI=n(L6e,"A",{href:!0});var vZr=s(rI);Ffo=r(vZr,"DeiTFeatureExtractor"),vZr.forEach(t),Tfo=r(L6e," (DeiT model)"),L6e.forEach(t),Mfo=i(Z),_h=n(Z,"LI",{});var x6e=s(_h);Vne=n(x6e,"STRONG",{});var FZr=s(Vne);Efo=r(FZr,"detr"),FZr.forEach(t),Cfo=r(x6e," \u2014 "),tI=n(x6e,"A",{href:!0});var TZr=s(tI);wfo=r(TZr,"DetrFeatureExtractor"),TZr.forEach(t),Afo=r(x6e," (DETR model)"),x6e.forEach(t),yfo=i(Z),uh=n(Z,"LI",{});var $6e=s(uh);Xne=n($6e,"STRONG",{});var MZr=s(Xne);Lfo=r(MZr,"dpt"),MZr.forEach(t),xfo=r($6e," \u2014 "),aI=n($6e,"A",{href:!0});var EZr=s(aI);$fo=r(EZr,"DPTFeatureExtractor"),EZr.forEach(t),kfo=r($6e," (DPT model)"),$6e.forEach(t),Sfo=i(Z),bh=n(Z,"LI",{});var k6e=s(bh);zne=n(k6e,"STRONG",{});var CZr=s(zne);Rfo=r(CZr,"flava"),CZr.forEach(t),Pfo=r(k6e," \u2014 "),nI=n(k6e,"A",{href:!0});var wZr=s(nI);Bfo=r(wZr,"FlavaFeatureExtractor"),wZr.forEach(t),Ifo=r(k6e," (Flava model)"),k6e.forEach(t),Nfo=i(Z),vh=n(Z,"LI",{});var S6e=s(vh);Wne=n(S6e,"STRONG",{});var AZr=s(Wne);qfo=r(AZr,"glpn"),AZr.forEach(t),jfo=r(S6e," \u2014 "),sI=n(S6e,"A",{href:!0});var yZr=s(sI);Dfo=r(yZr,"GLPNFeatureExtractor"),yZr.forEach(t),Gfo=r(S6e," (GLPN model)"),S6e.forEach(t),Ofo=i(Z),Fh=n(Z,"LI",{});var R6e=s(Fh);Qne=n(R6e,"STRONG",{});var LZr=s(Qne);Vfo=r(LZr,"hubert"),LZr.forEach(t),Xfo=r(R6e," \u2014 "),lI=n(R6e,"A",{href:!0});var xZr=s(lI);zfo=r(xZr,"Wav2Vec2FeatureExtractor"),xZr.forEach(t),Wfo=r(R6e," (Hubert model)"),R6e.forEach(t),Qfo=i(Z),Th=n(Z,"LI",{});var P6e=s(Th);Hne=n(P6e,"STRONG",{});var $Zr=s(Hne);Hfo=r($Zr,"imagegpt"),$Zr.forEach(t),Ufo=r(P6e," \u2014 "),iI=n(P6e,"A",{href:!0});var kZr=s(iI);Jfo=r(kZr,"ImageGPTFeatureExtractor"),kZr.forEach(t),Yfo=r(P6e," (ImageGPT model)"),P6e.forEach(t),Kfo=i(Z),Mh=n(Z,"LI",{});var B6e=s(Mh);Une=n(B6e,"STRONG",{});var SZr=s(Une);Zfo=r(SZr,"layoutlmv2"),SZr.forEach(t),emo=r(B6e," \u2014 "),dI=n(B6e,"A",{href:!0});var RZr=s(dI);omo=r(RZr,"LayoutLMv2FeatureExtractor"),RZr.forEach(t),rmo=r(B6e," (LayoutLMv2 model)"),B6e.forEach(t),tmo=i(Z),Eh=n(Z,"LI",{});var I6e=s(Eh);Jne=n(I6e,"STRONG",{});var PZr=s(Jne);amo=r(PZr,"layoutlmv3"),PZr.forEach(t),nmo=r(I6e," \u2014 "),cI=n(I6e,"A",{href:!0});var BZr=s(cI);smo=r(BZr,"LayoutLMv3FeatureExtractor"),BZr.forEach(t),lmo=r(I6e," (LayoutLMv3 model)"),I6e.forEach(t),imo=i(Z),Ch=n(Z,"LI",{});var N6e=s(Ch);Yne=n(N6e,"STRONG",{});var IZr=s(Yne);dmo=r(IZr,"levit"),IZr.forEach(t),cmo=r(N6e," \u2014 "),fI=n(N6e,"A",{href:!0});var NZr=s(fI);fmo=r(NZr,"LevitFeatureExtractor"),NZr.forEach(t),mmo=r(N6e," (LeViT model)"),N6e.forEach(t),gmo=i(Z),wh=n(Z,"LI",{});var q6e=s(wh);Kne=n(q6e,"STRONG",{});var qZr=s(Kne);hmo=r(qZr,"maskformer"),qZr.forEach(t),pmo=r(q6e," \u2014 "),mI=n(q6e,"A",{href:!0});var jZr=s(mI);_mo=r(jZr,"MaskFormerFeatureExtractor"),jZr.forEach(t),umo=r(q6e," (MaskFormer model)"),q6e.forEach(t),bmo=i(Z),Ah=n(Z,"LI",{});var j6e=s(Ah);Zne=n(j6e,"STRONG",{});var DZr=s(Zne);vmo=r(DZr,"perceiver"),DZr.forEach(t),Fmo=r(j6e," \u2014 "),gI=n(j6e,"A",{href:!0});var GZr=s(gI);Tmo=r(GZr,"PerceiverFeatureExtractor"),GZr.forEach(t),Mmo=r(j6e," (Perceiver model)"),j6e.forEach(t),Emo=i(Z),yh=n(Z,"LI",{});var D6e=s(yh);ese=n(D6e,"STRONG",{});var OZr=s(ese);Cmo=r(OZr,"poolformer"),OZr.forEach(t),wmo=r(D6e," \u2014 "),hI=n(D6e,"A",{href:!0});var VZr=s(hI);Amo=r(VZr,"PoolFormerFeatureExtractor"),VZr.forEach(t),ymo=r(D6e," (PoolFormer model)"),D6e.forEach(t),Lmo=i(Z),Lh=n(Z,"LI",{});var G6e=s(Lh);ose=n(G6e,"STRONG",{});var XZr=s(ose);xmo=r(XZr,"regnet"),XZr.forEach(t),$mo=r(G6e," \u2014 "),pI=n(G6e,"A",{href:!0});var zZr=s(pI);kmo=r(zZr,"ConvNextFeatureExtractor"),zZr.forEach(t),Smo=r(G6e," (RegNet model)"),G6e.forEach(t),Rmo=i(Z),xh=n(Z,"LI",{});var O6e=s(xh);rse=n(O6e,"STRONG",{});var WZr=s(rse);Pmo=r(WZr,"resnet"),WZr.forEach(t),Bmo=r(O6e," \u2014 "),_I=n(O6e,"A",{href:!0});var QZr=s(_I);Imo=r(QZr,"ConvNextFeatureExtractor"),QZr.forEach(t),Nmo=r(O6e," (ResNet model)"),O6e.forEach(t),qmo=i(Z),$h=n(Z,"LI",{});var V6e=s($h);tse=n(V6e,"STRONG",{});var HZr=s(tse);jmo=r(HZr,"segformer"),HZr.forEach(t),Dmo=r(V6e," \u2014 "),uI=n(V6e,"A",{href:!0});var UZr=s(uI);Gmo=r(UZr,"SegformerFeatureExtractor"),UZr.forEach(t),Omo=r(V6e," (SegFormer model)"),V6e.forEach(t),Vmo=i(Z),kh=n(Z,"LI",{});var X6e=s(kh);ase=n(X6e,"STRONG",{});var JZr=s(ase);Xmo=r(JZr,"speech_to_text"),JZr.forEach(t),zmo=r(X6e," \u2014 "),bI=n(X6e,"A",{href:!0});var YZr=s(bI);Wmo=r(YZr,"Speech2TextFeatureExtractor"),YZr.forEach(t),Qmo=r(X6e," (Speech2Text model)"),X6e.forEach(t),Hmo=i(Z),Sh=n(Z,"LI",{});var z6e=s(Sh);nse=n(z6e,"STRONG",{});var KZr=s(nse);Umo=r(KZr,"swin"),KZr.forEach(t),Jmo=r(z6e," \u2014 "),vI=n(z6e,"A",{href:!0});var ZZr=s(vI);Ymo=r(ZZr,"ViTFeatureExtractor"),ZZr.forEach(t),Kmo=r(z6e," (Swin model)"),z6e.forEach(t),Zmo=i(Z),Rh=n(Z,"LI",{});var W6e=s(Rh);sse=n(W6e,"STRONG",{});var eet=s(sse);ego=r(eet,"van"),eet.forEach(t),ogo=r(W6e," \u2014 "),FI=n(W6e,"A",{href:!0});var oet=s(FI);rgo=r(oet,"ConvNextFeatureExtractor"),oet.forEach(t),tgo=r(W6e," (VAN model)"),W6e.forEach(t),ago=i(Z),Ph=n(Z,"LI",{});var Q6e=s(Ph);lse=n(Q6e,"STRONG",{});var ret=s(lse);ngo=r(ret,"vit"),ret.forEach(t),sgo=r(Q6e," \u2014 "),TI=n(Q6e,"A",{href:!0});var tet=s(TI);lgo=r(tet,"ViTFeatureExtractor"),tet.forEach(t),igo=r(Q6e," (ViT model)"),Q6e.forEach(t),dgo=i(Z),Bh=n(Z,"LI",{});var H6e=s(Bh);ise=n(H6e,"STRONG",{});var aet=s(ise);cgo=r(aet,"vit_mae"),aet.forEach(t),fgo=r(H6e," \u2014 "),MI=n(H6e,"A",{href:!0});var net=s(MI);mgo=r(net,"ViTFeatureExtractor"),net.forEach(t),ggo=r(H6e," (ViTMAE model)"),H6e.forEach(t),hgo=i(Z),Ih=n(Z,"LI",{});var U6e=s(Ih);dse=n(U6e,"STRONG",{});var set=s(dse);pgo=r(set,"wav2vec2"),set.forEach(t),_go=r(U6e," \u2014 "),EI=n(U6e,"A",{href:!0});var iet=s(EI);ugo=r(iet,"Wav2Vec2FeatureExtractor"),iet.forEach(t),bgo=r(U6e," (Wav2Vec2 model)"),U6e.forEach(t),vgo=i(Z),Nh=n(Z,"LI",{});var J6e=s(Nh);cse=n(J6e,"STRONG",{});var det=s(cse);Fgo=r(det,"wav2vec2-conformer"),det.forEach(t),Tgo=r(J6e," \u2014 "),CI=n(J6e,"A",{href:!0});var cet=s(CI);Mgo=r(cet,"Wav2Vec2FeatureExtractor"),cet.forEach(t),Ego=r(J6e," (Wav2Vec2-Conformer model)"),J6e.forEach(t),Cgo=i(Z),qh=n(Z,"LI",{});var Y6e=s(qh);fse=n(Y6e,"STRONG",{});var fet=s(fse);wgo=r(fet,"yolos"),fet.forEach(t),Ago=r(Y6e," \u2014 "),wI=n(Y6e,"A",{href:!0});var met=s(wI);ygo=r(met,"YolosFeatureExtractor"),met.forEach(t),Lgo=r(Y6e," (YOLOS model)"),Y6e.forEach(t),Z.forEach(t),xgo=i(Zt),T(jh.$$.fragment,Zt),$go=i(Zt),T(Dh.$$.fragment,Zt),Zt.forEach(t),kgo=i(Gs),Gh=n(Gs,"DIV",{class:!0});var HDe=s(Gh);T(oy.$$.fragment,HDe),Sgo=i(HDe),mse=n(HDe,"P",{});var get=s(mse);Rgo=r(get,"Register a new feature extractor for this class."),get.forEach(t),HDe.forEach(t),Gs.forEach(t),Qqe=i(f),wi=n(f,"H2",{class:!0});var UDe=s(wi);Oh=n(UDe,"A",{id:!0,class:!0,href:!0});var het=s(Oh);gse=n(het,"SPAN",{});var pet=s(gse);T(ry.$$.fragment,pet),pet.forEach(t),het.forEach(t),Pgo=i(UDe),hse=n(UDe,"SPAN",{});var _et=s(hse);Bgo=r(_et,"AutoProcessor"),_et.forEach(t),UDe.forEach(t),Hqe=i(f),yo=n(f,"DIV",{class:!0});var Os=s(yo);T(ty.$$.fragment,Os),Igo=i(Os),ay=n(Os,"P",{});var JDe=s(ay);Ngo=r(JDe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),AI=n(JDe,"A",{href:!0});var uet=s(AI);qgo=r(uet,"AutoProcessor.from_pretrained()"),uet.forEach(t),jgo=r(JDe," class method."),JDe.forEach(t),Dgo=i(Os),ny=n(Os,"P",{});var YDe=s(ny);Ggo=r(YDe,"This class cannot be instantiated directly using "),pse=n(YDe,"CODE",{});var bet=s(pse);Ogo=r(bet,"__init__()"),bet.forEach(t),Vgo=r(YDe," (throws an error)."),YDe.forEach(t),Xgo=i(Os),Ue=n(Os,"DIV",{class:!0});var ea=s(Ue);T(sy.$$.fragment,ea),zgo=i(ea),_se=n(ea,"P",{});var vet=s(_se);Wgo=r(vet,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),vet.forEach(t),Qgo=i(ea),Ai=n(ea,"P",{});var IZ=s(Ai);Hgo=r(IZ,"The processor class to instantiate is selected based on the "),use=n(IZ,"CODE",{});var Fet=s(use);Ugo=r(Fet,"model_type"),Fet.forEach(t),Jgo=r(IZ,` property of the config object (either
passed as an argument or loaded from `),bse=n(IZ,"CODE",{});var Tet=s(bse);Ygo=r(Tet,"pretrained_model_name_or_path"),Tet.forEach(t),Kgo=r(IZ," if possible):"),IZ.forEach(t),Zgo=i(ea),he=n(ea,"UL",{});var ue=s(he);Vh=n(ue,"LI",{});var K6e=s(Vh);vse=n(K6e,"STRONG",{});var Met=s(vse);eho=r(Met,"clip"),Met.forEach(t),oho=r(K6e," \u2014 "),yI=n(K6e,"A",{href:!0});var Eet=s(yI);rho=r(Eet,"CLIPProcessor"),Eet.forEach(t),tho=r(K6e," (CLIP model)"),K6e.forEach(t),aho=i(ue),Xh=n(ue,"LI",{});var Z6e=s(Xh);Fse=n(Z6e,"STRONG",{});var Cet=s(Fse);nho=r(Cet,"flava"),Cet.forEach(t),sho=r(Z6e," \u2014 "),Tse=n(Z6e,"CODE",{});var wet=s(Tse);lho=r(wet,"FLAVAProcessor"),wet.forEach(t),iho=r(Z6e," (Flava model)"),Z6e.forEach(t),dho=i(ue),zh=n(ue,"LI",{});var eAe=s(zh);Mse=n(eAe,"STRONG",{});var Aet=s(Mse);cho=r(Aet,"layoutlmv2"),Aet.forEach(t),fho=r(eAe," \u2014 "),LI=n(eAe,"A",{href:!0});var yet=s(LI);mho=r(yet,"LayoutLMv2Processor"),yet.forEach(t),gho=r(eAe," (LayoutLMv2 model)"),eAe.forEach(t),hho=i(ue),Wh=n(ue,"LI",{});var oAe=s(Wh);Ese=n(oAe,"STRONG",{});var Let=s(Ese);pho=r(Let,"layoutlmv3"),Let.forEach(t),_ho=r(oAe," \u2014 "),xI=n(oAe,"A",{href:!0});var xet=s(xI);uho=r(xet,"LayoutLMv3Processor"),xet.forEach(t),bho=r(oAe," (LayoutLMv3 model)"),oAe.forEach(t),vho=i(ue),Qh=n(ue,"LI",{});var rAe=s(Qh);Cse=n(rAe,"STRONG",{});var $et=s(Cse);Fho=r($et,"layoutxlm"),$et.forEach(t),Tho=r(rAe," \u2014 "),$I=n(rAe,"A",{href:!0});var ket=s($I);Mho=r(ket,"LayoutXLMProcessor"),ket.forEach(t),Eho=r(rAe," (LayoutXLM model)"),rAe.forEach(t),Cho=i(ue),Hh=n(ue,"LI",{});var tAe=s(Hh);wse=n(tAe,"STRONG",{});var Set=s(wse);who=r(Set,"sew"),Set.forEach(t),Aho=r(tAe," \u2014 "),kI=n(tAe,"A",{href:!0});var Ret=s(kI);yho=r(Ret,"Wav2Vec2Processor"),Ret.forEach(t),Lho=r(tAe," (SEW model)"),tAe.forEach(t),xho=i(ue),Uh=n(ue,"LI",{});var aAe=s(Uh);Ase=n(aAe,"STRONG",{});var Pet=s(Ase);$ho=r(Pet,"sew-d"),Pet.forEach(t),kho=r(aAe," \u2014 "),SI=n(aAe,"A",{href:!0});var Bet=s(SI);Sho=r(Bet,"Wav2Vec2Processor"),Bet.forEach(t),Rho=r(aAe," (SEW-D model)"),aAe.forEach(t),Pho=i(ue),Jh=n(ue,"LI",{});var nAe=s(Jh);yse=n(nAe,"STRONG",{});var Iet=s(yse);Bho=r(Iet,"speech_to_text"),Iet.forEach(t),Iho=r(nAe," \u2014 "),RI=n(nAe,"A",{href:!0});var Net=s(RI);Nho=r(Net,"Speech2TextProcessor"),Net.forEach(t),qho=r(nAe," (Speech2Text model)"),nAe.forEach(t),jho=i(ue),Yh=n(ue,"LI",{});var sAe=s(Yh);Lse=n(sAe,"STRONG",{});var qet=s(Lse);Dho=r(qet,"speech_to_text_2"),qet.forEach(t),Gho=r(sAe," \u2014 "),PI=n(sAe,"A",{href:!0});var jet=s(PI);Oho=r(jet,"Speech2Text2Processor"),jet.forEach(t),Vho=r(sAe," (Speech2Text2 model)"),sAe.forEach(t),Xho=i(ue),Kh=n(ue,"LI",{});var lAe=s(Kh);xse=n(lAe,"STRONG",{});var Det=s(xse);zho=r(Det,"trocr"),Det.forEach(t),Who=r(lAe," \u2014 "),BI=n(lAe,"A",{href:!0});var Get=s(BI);Qho=r(Get,"TrOCRProcessor"),Get.forEach(t),Hho=r(lAe," (TrOCR model)"),lAe.forEach(t),Uho=i(ue),Zh=n(ue,"LI",{});var iAe=s(Zh);$se=n(iAe,"STRONG",{});var Oet=s($se);Jho=r(Oet,"unispeech"),Oet.forEach(t),Yho=r(iAe," \u2014 "),II=n(iAe,"A",{href:!0});var Vet=s(II);Kho=r(Vet,"Wav2Vec2Processor"),Vet.forEach(t),Zho=r(iAe," (UniSpeech model)"),iAe.forEach(t),epo=i(ue),ep=n(ue,"LI",{});var dAe=s(ep);kse=n(dAe,"STRONG",{});var Xet=s(kse);opo=r(Xet,"unispeech-sat"),Xet.forEach(t),rpo=r(dAe," \u2014 "),NI=n(dAe,"A",{href:!0});var zet=s(NI);tpo=r(zet,"Wav2Vec2Processor"),zet.forEach(t),apo=r(dAe," (UniSpeechSat model)"),dAe.forEach(t),npo=i(ue),op=n(ue,"LI",{});var cAe=s(op);Sse=n(cAe,"STRONG",{});var Wet=s(Sse);spo=r(Wet,"vilt"),Wet.forEach(t),lpo=r(cAe," \u2014 "),qI=n(cAe,"A",{href:!0});var Qet=s(qI);ipo=r(Qet,"ViltProcessor"),Qet.forEach(t),dpo=r(cAe," (ViLT model)"),cAe.forEach(t),cpo=i(ue),rp=n(ue,"LI",{});var fAe=s(rp);Rse=n(fAe,"STRONG",{});var Het=s(Rse);fpo=r(Het,"vision-text-dual-encoder"),Het.forEach(t),mpo=r(fAe," \u2014 "),jI=n(fAe,"A",{href:!0});var Uet=s(jI);gpo=r(Uet,"VisionTextDualEncoderProcessor"),Uet.forEach(t),hpo=r(fAe," (VisionTextDualEncoder model)"),fAe.forEach(t),ppo=i(ue),tp=n(ue,"LI",{});var mAe=s(tp);Pse=n(mAe,"STRONG",{});var Jet=s(Pse);_po=r(Jet,"wav2vec2"),Jet.forEach(t),upo=r(mAe," \u2014 "),DI=n(mAe,"A",{href:!0});var Yet=s(DI);bpo=r(Yet,"Wav2Vec2Processor"),Yet.forEach(t),vpo=r(mAe," (Wav2Vec2 model)"),mAe.forEach(t),Fpo=i(ue),ap=n(ue,"LI",{});var gAe=s(ap);Bse=n(gAe,"STRONG",{});var Ket=s(Bse);Tpo=r(Ket,"wav2vec2-conformer"),Ket.forEach(t),Mpo=r(gAe," \u2014 "),GI=n(gAe,"A",{href:!0});var Zet=s(GI);Epo=r(Zet,"Wav2Vec2Processor"),Zet.forEach(t),Cpo=r(gAe," (Wav2Vec2-Conformer model)"),gAe.forEach(t),wpo=i(ue),np=n(ue,"LI",{});var hAe=s(np);Ise=n(hAe,"STRONG",{});var eot=s(Ise);Apo=r(eot,"wavlm"),eot.forEach(t),ypo=r(hAe," \u2014 "),OI=n(hAe,"A",{href:!0});var oot=s(OI);Lpo=r(oot,"Wav2Vec2Processor"),oot.forEach(t),xpo=r(hAe," (WavLM model)"),hAe.forEach(t),ue.forEach(t),$po=i(ea),T(sp.$$.fragment,ea),kpo=i(ea),T(lp.$$.fragment,ea),ea.forEach(t),Spo=i(Os),ip=n(Os,"DIV",{class:!0});var KDe=s(ip);T(ly.$$.fragment,KDe),Rpo=i(KDe),Nse=n(KDe,"P",{});var rot=s(Nse);Ppo=r(rot,"Register a new processor for this class."),rot.forEach(t),KDe.forEach(t),Os.forEach(t),Uqe=i(f),yi=n(f,"H2",{class:!0});var ZDe=s(yi);dp=n(ZDe,"A",{id:!0,class:!0,href:!0});var tot=s(dp);qse=n(tot,"SPAN",{});var aot=s(qse);T(iy.$$.fragment,aot),aot.forEach(t),tot.forEach(t),Bpo=i(ZDe),jse=n(ZDe,"SPAN",{});var not=s(jse);Ipo=r(not,"AutoModel"),not.forEach(t),ZDe.forEach(t),Jqe=i(f),Lo=n(f,"DIV",{class:!0});var Vs=s(Lo);T(dy.$$.fragment,Vs),Npo=i(Vs),Li=n(Vs,"P",{});var NZ=s(Li);qpo=r(NZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),VI=n(NZ,"A",{href:!0});var sot=s(VI);jpo=r(sot,"from_pretrained()"),sot.forEach(t),Dpo=r(NZ," class method or the "),XI=n(NZ,"A",{href:!0});var lot=s(XI);Gpo=r(lot,"from_config()"),lot.forEach(t),Opo=r(NZ,` class
method.`),NZ.forEach(t),Vpo=i(Vs),cy=n(Vs,"P",{});var eGe=s(cy);Xpo=r(eGe,"This class cannot be instantiated directly using "),Dse=n(eGe,"CODE",{});var iot=s(Dse);zpo=r(iot,"__init__()"),iot.forEach(t),Wpo=r(eGe," (throws an error)."),eGe.forEach(t),Qpo=i(Vs),tt=n(Vs,"DIV",{class:!0});var Dw=s(tt);T(fy.$$.fragment,Dw),Hpo=i(Dw),Gse=n(Dw,"P",{});var dot=s(Gse);Upo=r(dot,"Instantiates one of the base model classes of the library from a configuration."),dot.forEach(t),Jpo=i(Dw),xi=n(Dw,"P",{});var qZ=s(xi);Ypo=r(qZ,`Note:
Loading a model from its configuration file does `),Ose=n(qZ,"STRONG",{});var cot=s(Ose);Kpo=r(cot,"not"),cot.forEach(t),Zpo=r(qZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),zI=n(qZ,"A",{href:!0});var fot=s(zI);e_o=r(fot,"from_pretrained()"),fot.forEach(t),o_o=r(qZ," to load the model weights."),qZ.forEach(t),r_o=i(Dw),T(cp.$$.fragment,Dw),Dw.forEach(t),t_o=i(Vs),Je=n(Vs,"DIV",{class:!0});var oa=s(Je);T(my.$$.fragment,oa),a_o=i(oa),Vse=n(oa,"P",{});var mot=s(Vse);n_o=r(mot,"Instantiate one of the base model classes of the library from a pretrained model."),mot.forEach(t),s_o=i(oa),La=n(oa,"P",{});var Gw=s(La);l_o=r(Gw,"The model class to instantiate is selected based on the "),Xse=n(Gw,"CODE",{});var got=s(Xse);i_o=r(got,"model_type"),got.forEach(t),d_o=r(Gw,` property of the config object (either
passed as an argument or loaded from `),zse=n(Gw,"CODE",{});var hot=s(zse);c_o=r(hot,"pretrained_model_name_or_path"),hot.forEach(t),f_o=r(Gw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wse=n(Gw,"CODE",{});var pot=s(Wse);m_o=r(pot,"pretrained_model_name_or_path"),pot.forEach(t),g_o=r(Gw,":"),Gw.forEach(t),h_o=i(oa),x=n(oa,"UL",{});var $=s(x);fp=n($,"LI",{});var pAe=s(fp);Qse=n(pAe,"STRONG",{});var _ot=s(Qse);p_o=r(_ot,"albert"),_ot.forEach(t),__o=r(pAe," \u2014 "),WI=n(pAe,"A",{href:!0});var uot=s(WI);u_o=r(uot,"AlbertModel"),uot.forEach(t),b_o=r(pAe," (ALBERT model)"),pAe.forEach(t),v_o=i($),mp=n($,"LI",{});var _Ae=s(mp);Hse=n(_Ae,"STRONG",{});var bot=s(Hse);F_o=r(bot,"bart"),bot.forEach(t),T_o=r(_Ae," \u2014 "),QI=n(_Ae,"A",{href:!0});var vot=s(QI);M_o=r(vot,"BartModel"),vot.forEach(t),E_o=r(_Ae," (BART model)"),_Ae.forEach(t),C_o=i($),gp=n($,"LI",{});var uAe=s(gp);Use=n(uAe,"STRONG",{});var Fot=s(Use);w_o=r(Fot,"beit"),Fot.forEach(t),A_o=r(uAe," \u2014 "),HI=n(uAe,"A",{href:!0});var Tot=s(HI);y_o=r(Tot,"BeitModel"),Tot.forEach(t),L_o=r(uAe," (BEiT model)"),uAe.forEach(t),x_o=i($),hp=n($,"LI",{});var bAe=s(hp);Jse=n(bAe,"STRONG",{});var Mot=s(Jse);$_o=r(Mot,"bert"),Mot.forEach(t),k_o=r(bAe," \u2014 "),UI=n(bAe,"A",{href:!0});var Eot=s(UI);S_o=r(Eot,"BertModel"),Eot.forEach(t),R_o=r(bAe," (BERT model)"),bAe.forEach(t),P_o=i($),pp=n($,"LI",{});var vAe=s(pp);Yse=n(vAe,"STRONG",{});var Cot=s(Yse);B_o=r(Cot,"bert-generation"),Cot.forEach(t),I_o=r(vAe," \u2014 "),JI=n(vAe,"A",{href:!0});var wot=s(JI);N_o=r(wot,"BertGenerationEncoder"),wot.forEach(t),q_o=r(vAe," (Bert Generation model)"),vAe.forEach(t),j_o=i($),_p=n($,"LI",{});var FAe=s(_p);Kse=n(FAe,"STRONG",{});var Aot=s(Kse);D_o=r(Aot,"big_bird"),Aot.forEach(t),G_o=r(FAe," \u2014 "),YI=n(FAe,"A",{href:!0});var yot=s(YI);O_o=r(yot,"BigBirdModel"),yot.forEach(t),V_o=r(FAe," (BigBird model)"),FAe.forEach(t),X_o=i($),up=n($,"LI",{});var TAe=s(up);Zse=n(TAe,"STRONG",{});var Lot=s(Zse);z_o=r(Lot,"bigbird_pegasus"),Lot.forEach(t),W_o=r(TAe," \u2014 "),KI=n(TAe,"A",{href:!0});var xot=s(KI);Q_o=r(xot,"BigBirdPegasusModel"),xot.forEach(t),H_o=r(TAe," (BigBirdPegasus model)"),TAe.forEach(t),U_o=i($),bp=n($,"LI",{});var MAe=s(bp);ele=n(MAe,"STRONG",{});var $ot=s(ele);J_o=r($ot,"blenderbot"),$ot.forEach(t),Y_o=r(MAe," \u2014 "),ZI=n(MAe,"A",{href:!0});var kot=s(ZI);K_o=r(kot,"BlenderbotModel"),kot.forEach(t),Z_o=r(MAe," (Blenderbot model)"),MAe.forEach(t),euo=i($),vp=n($,"LI",{});var EAe=s(vp);ole=n(EAe,"STRONG",{});var Sot=s(ole);ouo=r(Sot,"blenderbot-small"),Sot.forEach(t),ruo=r(EAe," \u2014 "),eN=n(EAe,"A",{href:!0});var Rot=s(eN);tuo=r(Rot,"BlenderbotSmallModel"),Rot.forEach(t),auo=r(EAe," (BlenderbotSmall model)"),EAe.forEach(t),nuo=i($),Fp=n($,"LI",{});var CAe=s(Fp);rle=n(CAe,"STRONG",{});var Pot=s(rle);suo=r(Pot,"camembert"),Pot.forEach(t),luo=r(CAe," \u2014 "),oN=n(CAe,"A",{href:!0});var Bot=s(oN);iuo=r(Bot,"CamembertModel"),Bot.forEach(t),duo=r(CAe," (CamemBERT model)"),CAe.forEach(t),cuo=i($),Tp=n($,"LI",{});var wAe=s(Tp);tle=n(wAe,"STRONG",{});var Iot=s(tle);fuo=r(Iot,"canine"),Iot.forEach(t),muo=r(wAe," \u2014 "),rN=n(wAe,"A",{href:!0});var Not=s(rN);guo=r(Not,"CanineModel"),Not.forEach(t),huo=r(wAe," (Canine model)"),wAe.forEach(t),puo=i($),Mp=n($,"LI",{});var AAe=s(Mp);ale=n(AAe,"STRONG",{});var qot=s(ale);_uo=r(qot,"clip"),qot.forEach(t),uuo=r(AAe," \u2014 "),tN=n(AAe,"A",{href:!0});var jot=s(tN);buo=r(jot,"CLIPModel"),jot.forEach(t),vuo=r(AAe," (CLIP model)"),AAe.forEach(t),Fuo=i($),Ep=n($,"LI",{});var yAe=s(Ep);nle=n(yAe,"STRONG",{});var Dot=s(nle);Tuo=r(Dot,"convbert"),Dot.forEach(t),Muo=r(yAe," \u2014 "),aN=n(yAe,"A",{href:!0});var Got=s(aN);Euo=r(Got,"ConvBertModel"),Got.forEach(t),Cuo=r(yAe," (ConvBERT model)"),yAe.forEach(t),wuo=i($),Cp=n($,"LI",{});var LAe=s(Cp);sle=n(LAe,"STRONG",{});var Oot=s(sle);Auo=r(Oot,"convnext"),Oot.forEach(t),yuo=r(LAe," \u2014 "),nN=n(LAe,"A",{href:!0});var Vot=s(nN);Luo=r(Vot,"ConvNextModel"),Vot.forEach(t),xuo=r(LAe," (ConvNext model)"),LAe.forEach(t),$uo=i($),wp=n($,"LI",{});var xAe=s(wp);lle=n(xAe,"STRONG",{});var Xot=s(lle);kuo=r(Xot,"ctrl"),Xot.forEach(t),Suo=r(xAe," \u2014 "),sN=n(xAe,"A",{href:!0});var zot=s(sN);Ruo=r(zot,"CTRLModel"),zot.forEach(t),Puo=r(xAe," (CTRL model)"),xAe.forEach(t),Buo=i($),Ap=n($,"LI",{});var $Ae=s(Ap);ile=n($Ae,"STRONG",{});var Wot=s(ile);Iuo=r(Wot,"cvt"),Wot.forEach(t),Nuo=r($Ae," \u2014 "),lN=n($Ae,"A",{href:!0});var Qot=s(lN);quo=r(Qot,"CvtModel"),Qot.forEach(t),juo=r($Ae," (CvT model)"),$Ae.forEach(t),Duo=i($),yp=n($,"LI",{});var kAe=s(yp);dle=n(kAe,"STRONG",{});var Hot=s(dle);Guo=r(Hot,"data2vec-audio"),Hot.forEach(t),Ouo=r(kAe," \u2014 "),iN=n(kAe,"A",{href:!0});var Uot=s(iN);Vuo=r(Uot,"Data2VecAudioModel"),Uot.forEach(t),Xuo=r(kAe," (Data2VecAudio model)"),kAe.forEach(t),zuo=i($),Lp=n($,"LI",{});var SAe=s(Lp);cle=n(SAe,"STRONG",{});var Jot=s(cle);Wuo=r(Jot,"data2vec-text"),Jot.forEach(t),Quo=r(SAe," \u2014 "),dN=n(SAe,"A",{href:!0});var Yot=s(dN);Huo=r(Yot,"Data2VecTextModel"),Yot.forEach(t),Uuo=r(SAe," (Data2VecText model)"),SAe.forEach(t),Juo=i($),xp=n($,"LI",{});var RAe=s(xp);fle=n(RAe,"STRONG",{});var Kot=s(fle);Yuo=r(Kot,"data2vec-vision"),Kot.forEach(t),Kuo=r(RAe," \u2014 "),cN=n(RAe,"A",{href:!0});var Zot=s(cN);Zuo=r(Zot,"Data2VecVisionModel"),Zot.forEach(t),e2o=r(RAe," (Data2VecVision model)"),RAe.forEach(t),o2o=i($),$p=n($,"LI",{});var PAe=s($p);mle=n(PAe,"STRONG",{});var ert=s(mle);r2o=r(ert,"deberta"),ert.forEach(t),t2o=r(PAe," \u2014 "),fN=n(PAe,"A",{href:!0});var ort=s(fN);a2o=r(ort,"DebertaModel"),ort.forEach(t),n2o=r(PAe," (DeBERTa model)"),PAe.forEach(t),s2o=i($),kp=n($,"LI",{});var BAe=s(kp);gle=n(BAe,"STRONG",{});var rrt=s(gle);l2o=r(rrt,"deberta-v2"),rrt.forEach(t),i2o=r(BAe," \u2014 "),mN=n(BAe,"A",{href:!0});var trt=s(mN);d2o=r(trt,"DebertaV2Model"),trt.forEach(t),c2o=r(BAe," (DeBERTa-v2 model)"),BAe.forEach(t),f2o=i($),Sp=n($,"LI",{});var IAe=s(Sp);hle=n(IAe,"STRONG",{});var art=s(hle);m2o=r(art,"decision_transformer"),art.forEach(t),g2o=r(IAe," \u2014 "),gN=n(IAe,"A",{href:!0});var nrt=s(gN);h2o=r(nrt,"DecisionTransformerModel"),nrt.forEach(t),p2o=r(IAe," (Decision Transformer model)"),IAe.forEach(t),_2o=i($),Rp=n($,"LI",{});var NAe=s(Rp);ple=n(NAe,"STRONG",{});var srt=s(ple);u2o=r(srt,"deit"),srt.forEach(t),b2o=r(NAe," \u2014 "),hN=n(NAe,"A",{href:!0});var lrt=s(hN);v2o=r(lrt,"DeiTModel"),lrt.forEach(t),F2o=r(NAe," (DeiT model)"),NAe.forEach(t),T2o=i($),Pp=n($,"LI",{});var qAe=s(Pp);_le=n(qAe,"STRONG",{});var irt=s(_le);M2o=r(irt,"detr"),irt.forEach(t),E2o=r(qAe," \u2014 "),pN=n(qAe,"A",{href:!0});var drt=s(pN);C2o=r(drt,"DetrModel"),drt.forEach(t),w2o=r(qAe," (DETR model)"),qAe.forEach(t),A2o=i($),Bp=n($,"LI",{});var jAe=s(Bp);ule=n(jAe,"STRONG",{});var crt=s(ule);y2o=r(crt,"distilbert"),crt.forEach(t),L2o=r(jAe," \u2014 "),_N=n(jAe,"A",{href:!0});var frt=s(_N);x2o=r(frt,"DistilBertModel"),frt.forEach(t),$2o=r(jAe," (DistilBERT model)"),jAe.forEach(t),k2o=i($),Ip=n($,"LI",{});var DAe=s(Ip);ble=n(DAe,"STRONG",{});var mrt=s(ble);S2o=r(mrt,"dpr"),mrt.forEach(t),R2o=r(DAe," \u2014 "),uN=n(DAe,"A",{href:!0});var grt=s(uN);P2o=r(grt,"DPRQuestionEncoder"),grt.forEach(t),B2o=r(DAe," (DPR model)"),DAe.forEach(t),I2o=i($),Np=n($,"LI",{});var GAe=s(Np);vle=n(GAe,"STRONG",{});var hrt=s(vle);N2o=r(hrt,"dpt"),hrt.forEach(t),q2o=r(GAe," \u2014 "),bN=n(GAe,"A",{href:!0});var prt=s(bN);j2o=r(prt,"DPTModel"),prt.forEach(t),D2o=r(GAe," (DPT model)"),GAe.forEach(t),G2o=i($),qp=n($,"LI",{});var OAe=s(qp);Fle=n(OAe,"STRONG",{});var _rt=s(Fle);O2o=r(_rt,"electra"),_rt.forEach(t),V2o=r(OAe," \u2014 "),vN=n(OAe,"A",{href:!0});var urt=s(vN);X2o=r(urt,"ElectraModel"),urt.forEach(t),z2o=r(OAe," (ELECTRA model)"),OAe.forEach(t),W2o=i($),jp=n($,"LI",{});var VAe=s(jp);Tle=n(VAe,"STRONG",{});var brt=s(Tle);Q2o=r(brt,"flaubert"),brt.forEach(t),H2o=r(VAe," \u2014 "),FN=n(VAe,"A",{href:!0});var vrt=s(FN);U2o=r(vrt,"FlaubertModel"),vrt.forEach(t),J2o=r(VAe," (FlauBERT model)"),VAe.forEach(t),Y2o=i($),Dp=n($,"LI",{});var XAe=s(Dp);Mle=n(XAe,"STRONG",{});var Frt=s(Mle);K2o=r(Frt,"flava"),Frt.forEach(t),Z2o=r(XAe," \u2014 "),TN=n(XAe,"A",{href:!0});var Trt=s(TN);e1o=r(Trt,"FlavaModel"),Trt.forEach(t),o1o=r(XAe," (Flava model)"),XAe.forEach(t),r1o=i($),Gp=n($,"LI",{});var zAe=s(Gp);Ele=n(zAe,"STRONG",{});var Mrt=s(Ele);t1o=r(Mrt,"fnet"),Mrt.forEach(t),a1o=r(zAe," \u2014 "),MN=n(zAe,"A",{href:!0});var Ert=s(MN);n1o=r(Ert,"FNetModel"),Ert.forEach(t),s1o=r(zAe," (FNet model)"),zAe.forEach(t),l1o=i($),Op=n($,"LI",{});var WAe=s(Op);Cle=n(WAe,"STRONG",{});var Crt=s(Cle);i1o=r(Crt,"fsmt"),Crt.forEach(t),d1o=r(WAe," \u2014 "),EN=n(WAe,"A",{href:!0});var wrt=s(EN);c1o=r(wrt,"FSMTModel"),wrt.forEach(t),f1o=r(WAe," (FairSeq Machine-Translation model)"),WAe.forEach(t),m1o=i($),Bs=n($,"LI",{});var K$=s(Bs);wle=n(K$,"STRONG",{});var Art=s(wle);g1o=r(Art,"funnel"),Art.forEach(t),h1o=r(K$," \u2014 "),CN=n(K$,"A",{href:!0});var yrt=s(CN);p1o=r(yrt,"FunnelModel"),yrt.forEach(t),_1o=r(K$," or "),wN=n(K$,"A",{href:!0});var Lrt=s(wN);u1o=r(Lrt,"FunnelBaseModel"),Lrt.forEach(t),b1o=r(K$," (Funnel Transformer model)"),K$.forEach(t),v1o=i($),Vp=n($,"LI",{});var QAe=s(Vp);Ale=n(QAe,"STRONG",{});var xrt=s(Ale);F1o=r(xrt,"glpn"),xrt.forEach(t),T1o=r(QAe," \u2014 "),AN=n(QAe,"A",{href:!0});var $rt=s(AN);M1o=r($rt,"GLPNModel"),$rt.forEach(t),E1o=r(QAe," (GLPN model)"),QAe.forEach(t),C1o=i($),Xp=n($,"LI",{});var HAe=s(Xp);yle=n(HAe,"STRONG",{});var krt=s(yle);w1o=r(krt,"gpt2"),krt.forEach(t),A1o=r(HAe," \u2014 "),yN=n(HAe,"A",{href:!0});var Srt=s(yN);y1o=r(Srt,"GPT2Model"),Srt.forEach(t),L1o=r(HAe," (OpenAI GPT-2 model)"),HAe.forEach(t),x1o=i($),zp=n($,"LI",{});var UAe=s(zp);Lle=n(UAe,"STRONG",{});var Rrt=s(Lle);$1o=r(Rrt,"gpt_neo"),Rrt.forEach(t),k1o=r(UAe," \u2014 "),LN=n(UAe,"A",{href:!0});var Prt=s(LN);S1o=r(Prt,"GPTNeoModel"),Prt.forEach(t),R1o=r(UAe," (GPT Neo model)"),UAe.forEach(t),P1o=i($),Wp=n($,"LI",{});var JAe=s(Wp);xle=n(JAe,"STRONG",{});var Brt=s(xle);B1o=r(Brt,"gpt_neox"),Brt.forEach(t),I1o=r(JAe," \u2014 "),xN=n(JAe,"A",{href:!0});var Irt=s(xN);N1o=r(Irt,"GPTNeoXModel"),Irt.forEach(t),q1o=r(JAe," (GPT NeoX model)"),JAe.forEach(t),j1o=i($),Qp=n($,"LI",{});var YAe=s(Qp);$le=n(YAe,"STRONG",{});var Nrt=s($le);D1o=r(Nrt,"gptj"),Nrt.forEach(t),G1o=r(YAe," \u2014 "),$N=n(YAe,"A",{href:!0});var qrt=s($N);O1o=r(qrt,"GPTJModel"),qrt.forEach(t),V1o=r(YAe," (GPT-J model)"),YAe.forEach(t),X1o=i($),Hp=n($,"LI",{});var KAe=s(Hp);kle=n(KAe,"STRONG",{});var jrt=s(kle);z1o=r(jrt,"hubert"),jrt.forEach(t),W1o=r(KAe," \u2014 "),kN=n(KAe,"A",{href:!0});var Drt=s(kN);Q1o=r(Drt,"HubertModel"),Drt.forEach(t),H1o=r(KAe," (Hubert model)"),KAe.forEach(t),U1o=i($),Up=n($,"LI",{});var ZAe=s(Up);Sle=n(ZAe,"STRONG",{});var Grt=s(Sle);J1o=r(Grt,"ibert"),Grt.forEach(t),Y1o=r(ZAe," \u2014 "),SN=n(ZAe,"A",{href:!0});var Ort=s(SN);K1o=r(Ort,"IBertModel"),Ort.forEach(t),Z1o=r(ZAe," (I-BERT model)"),ZAe.forEach(t),ebo=i($),Jp=n($,"LI",{});var eye=s(Jp);Rle=n(eye,"STRONG",{});var Vrt=s(Rle);obo=r(Vrt,"imagegpt"),Vrt.forEach(t),rbo=r(eye," \u2014 "),RN=n(eye,"A",{href:!0});var Xrt=s(RN);tbo=r(Xrt,"ImageGPTModel"),Xrt.forEach(t),abo=r(eye," (ImageGPT model)"),eye.forEach(t),nbo=i($),Yp=n($,"LI",{});var oye=s(Yp);Ple=n(oye,"STRONG",{});var zrt=s(Ple);sbo=r(zrt,"layoutlm"),zrt.forEach(t),lbo=r(oye," \u2014 "),PN=n(oye,"A",{href:!0});var Wrt=s(PN);ibo=r(Wrt,"LayoutLMModel"),Wrt.forEach(t),dbo=r(oye," (LayoutLM model)"),oye.forEach(t),cbo=i($),Kp=n($,"LI",{});var rye=s(Kp);Ble=n(rye,"STRONG",{});var Qrt=s(Ble);fbo=r(Qrt,"layoutlmv2"),Qrt.forEach(t),mbo=r(rye," \u2014 "),BN=n(rye,"A",{href:!0});var Hrt=s(BN);gbo=r(Hrt,"LayoutLMv2Model"),Hrt.forEach(t),hbo=r(rye," (LayoutLMv2 model)"),rye.forEach(t),pbo=i($),Zp=n($,"LI",{});var tye=s(Zp);Ile=n(tye,"STRONG",{});var Urt=s(Ile);_bo=r(Urt,"layoutlmv3"),Urt.forEach(t),ubo=r(tye," \u2014 "),IN=n(tye,"A",{href:!0});var Jrt=s(IN);bbo=r(Jrt,"LayoutLMv3Model"),Jrt.forEach(t),vbo=r(tye," (LayoutLMv3 model)"),tye.forEach(t),Fbo=i($),e_=n($,"LI",{});var aye=s(e_);Nle=n(aye,"STRONG",{});var Yrt=s(Nle);Tbo=r(Yrt,"led"),Yrt.forEach(t),Mbo=r(aye," \u2014 "),NN=n(aye,"A",{href:!0});var Krt=s(NN);Ebo=r(Krt,"LEDModel"),Krt.forEach(t),Cbo=r(aye," (LED model)"),aye.forEach(t),wbo=i($),o_=n($,"LI",{});var nye=s(o_);qle=n(nye,"STRONG",{});var Zrt=s(qle);Abo=r(Zrt,"levit"),Zrt.forEach(t),ybo=r(nye," \u2014 "),qN=n(nye,"A",{href:!0});var ett=s(qN);Lbo=r(ett,"LevitModel"),ett.forEach(t),xbo=r(nye," (LeViT model)"),nye.forEach(t),$bo=i($),r_=n($,"LI",{});var sye=s(r_);jle=n(sye,"STRONG",{});var ott=s(jle);kbo=r(ott,"longformer"),ott.forEach(t),Sbo=r(sye," \u2014 "),jN=n(sye,"A",{href:!0});var rtt=s(jN);Rbo=r(rtt,"LongformerModel"),rtt.forEach(t),Pbo=r(sye," (Longformer model)"),sye.forEach(t),Bbo=i($),t_=n($,"LI",{});var lye=s(t_);Dle=n(lye,"STRONG",{});var ttt=s(Dle);Ibo=r(ttt,"luke"),ttt.forEach(t),Nbo=r(lye," \u2014 "),DN=n(lye,"A",{href:!0});var att=s(DN);qbo=r(att,"LukeModel"),att.forEach(t),jbo=r(lye," (LUKE model)"),lye.forEach(t),Dbo=i($),a_=n($,"LI",{});var iye=s(a_);Gle=n(iye,"STRONG",{});var ntt=s(Gle);Gbo=r(ntt,"lxmert"),ntt.forEach(t),Obo=r(iye," \u2014 "),GN=n(iye,"A",{href:!0});var stt=s(GN);Vbo=r(stt,"LxmertModel"),stt.forEach(t),Xbo=r(iye," (LXMERT model)"),iye.forEach(t),zbo=i($),n_=n($,"LI",{});var dye=s(n_);Ole=n(dye,"STRONG",{});var ltt=s(Ole);Wbo=r(ltt,"m2m_100"),ltt.forEach(t),Qbo=r(dye," \u2014 "),ON=n(dye,"A",{href:!0});var itt=s(ON);Hbo=r(itt,"M2M100Model"),itt.forEach(t),Ubo=r(dye," (M2M100 model)"),dye.forEach(t),Jbo=i($),s_=n($,"LI",{});var cye=s(s_);Vle=n(cye,"STRONG",{});var dtt=s(Vle);Ybo=r(dtt,"marian"),dtt.forEach(t),Kbo=r(cye," \u2014 "),VN=n(cye,"A",{href:!0});var ctt=s(VN);Zbo=r(ctt,"MarianModel"),ctt.forEach(t),e4o=r(cye," (Marian model)"),cye.forEach(t),o4o=i($),l_=n($,"LI",{});var fye=s(l_);Xle=n(fye,"STRONG",{});var ftt=s(Xle);r4o=r(ftt,"maskformer"),ftt.forEach(t),t4o=r(fye," \u2014 "),XN=n(fye,"A",{href:!0});var mtt=s(XN);a4o=r(mtt,"MaskFormerModel"),mtt.forEach(t),n4o=r(fye," (MaskFormer model)"),fye.forEach(t),s4o=i($),i_=n($,"LI",{});var mye=s(i_);zle=n(mye,"STRONG",{});var gtt=s(zle);l4o=r(gtt,"mbart"),gtt.forEach(t),i4o=r(mye," \u2014 "),zN=n(mye,"A",{href:!0});var htt=s(zN);d4o=r(htt,"MBartModel"),htt.forEach(t),c4o=r(mye," (mBART model)"),mye.forEach(t),f4o=i($),d_=n($,"LI",{});var gye=s(d_);Wle=n(gye,"STRONG",{});var ptt=s(Wle);m4o=r(ptt,"megatron-bert"),ptt.forEach(t),g4o=r(gye," \u2014 "),WN=n(gye,"A",{href:!0});var _tt=s(WN);h4o=r(_tt,"MegatronBertModel"),_tt.forEach(t),p4o=r(gye," (MegatronBert model)"),gye.forEach(t),_4o=i($),c_=n($,"LI",{});var hye=s(c_);Qle=n(hye,"STRONG",{});var utt=s(Qle);u4o=r(utt,"mobilebert"),utt.forEach(t),b4o=r(hye," \u2014 "),QN=n(hye,"A",{href:!0});var btt=s(QN);v4o=r(btt,"MobileBertModel"),btt.forEach(t),F4o=r(hye," (MobileBERT model)"),hye.forEach(t),T4o=i($),f_=n($,"LI",{});var pye=s(f_);Hle=n(pye,"STRONG",{});var vtt=s(Hle);M4o=r(vtt,"mpnet"),vtt.forEach(t),E4o=r(pye," \u2014 "),HN=n(pye,"A",{href:!0});var Ftt=s(HN);C4o=r(Ftt,"MPNetModel"),Ftt.forEach(t),w4o=r(pye," (MPNet model)"),pye.forEach(t),A4o=i($),m_=n($,"LI",{});var _ye=s(m_);Ule=n(_ye,"STRONG",{});var Ttt=s(Ule);y4o=r(Ttt,"mt5"),Ttt.forEach(t),L4o=r(_ye," \u2014 "),UN=n(_ye,"A",{href:!0});var Mtt=s(UN);x4o=r(Mtt,"MT5Model"),Mtt.forEach(t),$4o=r(_ye," (mT5 model)"),_ye.forEach(t),k4o=i($),g_=n($,"LI",{});var uye=s(g_);Jle=n(uye,"STRONG",{});var Ett=s(Jle);S4o=r(Ett,"nystromformer"),Ett.forEach(t),R4o=r(uye," \u2014 "),JN=n(uye,"A",{href:!0});var Ctt=s(JN);P4o=r(Ctt,"NystromformerModel"),Ctt.forEach(t),B4o=r(uye," (Nystromformer model)"),uye.forEach(t),I4o=i($),h_=n($,"LI",{});var bye=s(h_);Yle=n(bye,"STRONG",{});var wtt=s(Yle);N4o=r(wtt,"openai-gpt"),wtt.forEach(t),q4o=r(bye," \u2014 "),YN=n(bye,"A",{href:!0});var Att=s(YN);j4o=r(Att,"OpenAIGPTModel"),Att.forEach(t),D4o=r(bye," (OpenAI GPT model)"),bye.forEach(t),G4o=i($),p_=n($,"LI",{});var vye=s(p_);Kle=n(vye,"STRONG",{});var ytt=s(Kle);O4o=r(ytt,"opt"),ytt.forEach(t),V4o=r(vye," \u2014 "),KN=n(vye,"A",{href:!0});var Ltt=s(KN);X4o=r(Ltt,"OPTModel"),Ltt.forEach(t),z4o=r(vye," (OPT model)"),vye.forEach(t),W4o=i($),__=n($,"LI",{});var Fye=s(__);Zle=n(Fye,"STRONG",{});var xtt=s(Zle);Q4o=r(xtt,"pegasus"),xtt.forEach(t),H4o=r(Fye," \u2014 "),ZN=n(Fye,"A",{href:!0});var $tt=s(ZN);U4o=r($tt,"PegasusModel"),$tt.forEach(t),J4o=r(Fye," (Pegasus model)"),Fye.forEach(t),Y4o=i($),u_=n($,"LI",{});var Tye=s(u_);eie=n(Tye,"STRONG",{});var ktt=s(eie);K4o=r(ktt,"perceiver"),ktt.forEach(t),Z4o=r(Tye," \u2014 "),eq=n(Tye,"A",{href:!0});var Stt=s(eq);evo=r(Stt,"PerceiverModel"),Stt.forEach(t),ovo=r(Tye," (Perceiver model)"),Tye.forEach(t),rvo=i($),b_=n($,"LI",{});var Mye=s(b_);oie=n(Mye,"STRONG",{});var Rtt=s(oie);tvo=r(Rtt,"plbart"),Rtt.forEach(t),avo=r(Mye," \u2014 "),oq=n(Mye,"A",{href:!0});var Ptt=s(oq);nvo=r(Ptt,"PLBartModel"),Ptt.forEach(t),svo=r(Mye," (PLBart model)"),Mye.forEach(t),lvo=i($),v_=n($,"LI",{});var Eye=s(v_);rie=n(Eye,"STRONG",{});var Btt=s(rie);ivo=r(Btt,"poolformer"),Btt.forEach(t),dvo=r(Eye," \u2014 "),rq=n(Eye,"A",{href:!0});var Itt=s(rq);cvo=r(Itt,"PoolFormerModel"),Itt.forEach(t),fvo=r(Eye," (PoolFormer model)"),Eye.forEach(t),mvo=i($),F_=n($,"LI",{});var Cye=s(F_);tie=n(Cye,"STRONG",{});var Ntt=s(tie);gvo=r(Ntt,"prophetnet"),Ntt.forEach(t),hvo=r(Cye," \u2014 "),tq=n(Cye,"A",{href:!0});var qtt=s(tq);pvo=r(qtt,"ProphetNetModel"),qtt.forEach(t),_vo=r(Cye," (ProphetNet model)"),Cye.forEach(t),uvo=i($),T_=n($,"LI",{});var wye=s(T_);aie=n(wye,"STRONG",{});var jtt=s(aie);bvo=r(jtt,"qdqbert"),jtt.forEach(t),vvo=r(wye," \u2014 "),aq=n(wye,"A",{href:!0});var Dtt=s(aq);Fvo=r(Dtt,"QDQBertModel"),Dtt.forEach(t),Tvo=r(wye," (QDQBert model)"),wye.forEach(t),Mvo=i($),M_=n($,"LI",{});var Aye=s(M_);nie=n(Aye,"STRONG",{});var Gtt=s(nie);Evo=r(Gtt,"reformer"),Gtt.forEach(t),Cvo=r(Aye," \u2014 "),nq=n(Aye,"A",{href:!0});var Ott=s(nq);wvo=r(Ott,"ReformerModel"),Ott.forEach(t),Avo=r(Aye," (Reformer model)"),Aye.forEach(t),yvo=i($),E_=n($,"LI",{});var yye=s(E_);sie=n(yye,"STRONG",{});var Vtt=s(sie);Lvo=r(Vtt,"regnet"),Vtt.forEach(t),xvo=r(yye," \u2014 "),sq=n(yye,"A",{href:!0});var Xtt=s(sq);$vo=r(Xtt,"RegNetModel"),Xtt.forEach(t),kvo=r(yye," (RegNet model)"),yye.forEach(t),Svo=i($),C_=n($,"LI",{});var Lye=s(C_);lie=n(Lye,"STRONG",{});var ztt=s(lie);Rvo=r(ztt,"rembert"),ztt.forEach(t),Pvo=r(Lye," \u2014 "),lq=n(Lye,"A",{href:!0});var Wtt=s(lq);Bvo=r(Wtt,"RemBertModel"),Wtt.forEach(t),Ivo=r(Lye," (RemBERT model)"),Lye.forEach(t),Nvo=i($),w_=n($,"LI",{});var xye=s(w_);iie=n(xye,"STRONG",{});var Qtt=s(iie);qvo=r(Qtt,"resnet"),Qtt.forEach(t),jvo=r(xye," \u2014 "),iq=n(xye,"A",{href:!0});var Htt=s(iq);Dvo=r(Htt,"ResNetModel"),Htt.forEach(t),Gvo=r(xye," (ResNet model)"),xye.forEach(t),Ovo=i($),A_=n($,"LI",{});var $ye=s(A_);die=n($ye,"STRONG",{});var Utt=s(die);Vvo=r(Utt,"retribert"),Utt.forEach(t),Xvo=r($ye," \u2014 "),dq=n($ye,"A",{href:!0});var Jtt=s(dq);zvo=r(Jtt,"RetriBertModel"),Jtt.forEach(t),Wvo=r($ye," (RetriBERT model)"),$ye.forEach(t),Qvo=i($),y_=n($,"LI",{});var kye=s(y_);cie=n(kye,"STRONG",{});var Ytt=s(cie);Hvo=r(Ytt,"roberta"),Ytt.forEach(t),Uvo=r(kye," \u2014 "),cq=n(kye,"A",{href:!0});var Ktt=s(cq);Jvo=r(Ktt,"RobertaModel"),Ktt.forEach(t),Yvo=r(kye," (RoBERTa model)"),kye.forEach(t),Kvo=i($),L_=n($,"LI",{});var Sye=s(L_);fie=n(Sye,"STRONG",{});var Ztt=s(fie);Zvo=r(Ztt,"roformer"),Ztt.forEach(t),e5o=r(Sye," \u2014 "),fq=n(Sye,"A",{href:!0});var eat=s(fq);o5o=r(eat,"RoFormerModel"),eat.forEach(t),r5o=r(Sye," (RoFormer model)"),Sye.forEach(t),t5o=i($),x_=n($,"LI",{});var Rye=s(x_);mie=n(Rye,"STRONG",{});var oat=s(mie);a5o=r(oat,"segformer"),oat.forEach(t),n5o=r(Rye," \u2014 "),mq=n(Rye,"A",{href:!0});var rat=s(mq);s5o=r(rat,"SegformerModel"),rat.forEach(t),l5o=r(Rye," (SegFormer model)"),Rye.forEach(t),i5o=i($),$_=n($,"LI",{});var Pye=s($_);gie=n(Pye,"STRONG",{});var tat=s(gie);d5o=r(tat,"sew"),tat.forEach(t),c5o=r(Pye," \u2014 "),gq=n(Pye,"A",{href:!0});var aat=s(gq);f5o=r(aat,"SEWModel"),aat.forEach(t),m5o=r(Pye," (SEW model)"),Pye.forEach(t),g5o=i($),k_=n($,"LI",{});var Bye=s(k_);hie=n(Bye,"STRONG",{});var nat=s(hie);h5o=r(nat,"sew-d"),nat.forEach(t),p5o=r(Bye," \u2014 "),hq=n(Bye,"A",{href:!0});var sat=s(hq);_5o=r(sat,"SEWDModel"),sat.forEach(t),u5o=r(Bye," (SEW-D model)"),Bye.forEach(t),b5o=i($),S_=n($,"LI",{});var Iye=s(S_);pie=n(Iye,"STRONG",{});var lat=s(pie);v5o=r(lat,"speech_to_text"),lat.forEach(t),F5o=r(Iye," \u2014 "),pq=n(Iye,"A",{href:!0});var iat=s(pq);T5o=r(iat,"Speech2TextModel"),iat.forEach(t),M5o=r(Iye," (Speech2Text model)"),Iye.forEach(t),E5o=i($),R_=n($,"LI",{});var Nye=s(R_);_ie=n(Nye,"STRONG",{});var dat=s(_ie);C5o=r(dat,"splinter"),dat.forEach(t),w5o=r(Nye," \u2014 "),_q=n(Nye,"A",{href:!0});var cat=s(_q);A5o=r(cat,"SplinterModel"),cat.forEach(t),y5o=r(Nye," (Splinter model)"),Nye.forEach(t),L5o=i($),P_=n($,"LI",{});var qye=s(P_);uie=n(qye,"STRONG",{});var fat=s(uie);x5o=r(fat,"squeezebert"),fat.forEach(t),$5o=r(qye," \u2014 "),uq=n(qye,"A",{href:!0});var mat=s(uq);k5o=r(mat,"SqueezeBertModel"),mat.forEach(t),S5o=r(qye," (SqueezeBERT model)"),qye.forEach(t),R5o=i($),B_=n($,"LI",{});var jye=s(B_);bie=n(jye,"STRONG",{});var gat=s(bie);P5o=r(gat,"swin"),gat.forEach(t),B5o=r(jye," \u2014 "),bq=n(jye,"A",{href:!0});var hat=s(bq);I5o=r(hat,"SwinModel"),hat.forEach(t),N5o=r(jye," (Swin model)"),jye.forEach(t),q5o=i($),I_=n($,"LI",{});var Dye=s(I_);vie=n(Dye,"STRONG",{});var pat=s(vie);j5o=r(pat,"t5"),pat.forEach(t),D5o=r(Dye," \u2014 "),vq=n(Dye,"A",{href:!0});var _at=s(vq);G5o=r(_at,"T5Model"),_at.forEach(t),O5o=r(Dye," (T5 model)"),Dye.forEach(t),V5o=i($),N_=n($,"LI",{});var Gye=s(N_);Fie=n(Gye,"STRONG",{});var uat=s(Fie);X5o=r(uat,"tapas"),uat.forEach(t),z5o=r(Gye," \u2014 "),Fq=n(Gye,"A",{href:!0});var bat=s(Fq);W5o=r(bat,"TapasModel"),bat.forEach(t),Q5o=r(Gye," (TAPAS model)"),Gye.forEach(t),H5o=i($),q_=n($,"LI",{});var Oye=s(q_);Tie=n(Oye,"STRONG",{});var vat=s(Tie);U5o=r(vat,"trajectory_transformer"),vat.forEach(t),J5o=r(Oye," \u2014 "),Tq=n(Oye,"A",{href:!0});var Fat=s(Tq);Y5o=r(Fat,"TrajectoryTransformerModel"),Fat.forEach(t),K5o=r(Oye," (Trajectory Transformer model)"),Oye.forEach(t),Z5o=i($),j_=n($,"LI",{});var Vye=s(j_);Mie=n(Vye,"STRONG",{});var Tat=s(Mie);eFo=r(Tat,"transfo-xl"),Tat.forEach(t),oFo=r(Vye," \u2014 "),Mq=n(Vye,"A",{href:!0});var Mat=s(Mq);rFo=r(Mat,"TransfoXLModel"),Mat.forEach(t),tFo=r(Vye," (Transformer-XL model)"),Vye.forEach(t),aFo=i($),D_=n($,"LI",{});var Xye=s(D_);Eie=n(Xye,"STRONG",{});var Eat=s(Eie);nFo=r(Eat,"unispeech"),Eat.forEach(t),sFo=r(Xye," \u2014 "),Eq=n(Xye,"A",{href:!0});var Cat=s(Eq);lFo=r(Cat,"UniSpeechModel"),Cat.forEach(t),iFo=r(Xye," (UniSpeech model)"),Xye.forEach(t),dFo=i($),G_=n($,"LI",{});var zye=s(G_);Cie=n(zye,"STRONG",{});var wat=s(Cie);cFo=r(wat,"unispeech-sat"),wat.forEach(t),fFo=r(zye," \u2014 "),Cq=n(zye,"A",{href:!0});var Aat=s(Cq);mFo=r(Aat,"UniSpeechSatModel"),Aat.forEach(t),gFo=r(zye," (UniSpeechSat model)"),zye.forEach(t),hFo=i($),O_=n($,"LI",{});var Wye=s(O_);wie=n(Wye,"STRONG",{});var yat=s(wie);pFo=r(yat,"van"),yat.forEach(t),_Fo=r(Wye," \u2014 "),wq=n(Wye,"A",{href:!0});var Lat=s(wq);uFo=r(Lat,"VanModel"),Lat.forEach(t),bFo=r(Wye," (VAN model)"),Wye.forEach(t),vFo=i($),V_=n($,"LI",{});var Qye=s(V_);Aie=n(Qye,"STRONG",{});var xat=s(Aie);FFo=r(xat,"vilt"),xat.forEach(t),TFo=r(Qye," \u2014 "),Aq=n(Qye,"A",{href:!0});var $at=s(Aq);MFo=r($at,"ViltModel"),$at.forEach(t),EFo=r(Qye," (ViLT model)"),Qye.forEach(t),CFo=i($),X_=n($,"LI",{});var Hye=s(X_);yie=n(Hye,"STRONG",{});var kat=s(yie);wFo=r(kat,"vision-text-dual-encoder"),kat.forEach(t),AFo=r(Hye," \u2014 "),yq=n(Hye,"A",{href:!0});var Sat=s(yq);yFo=r(Sat,"VisionTextDualEncoderModel"),Sat.forEach(t),LFo=r(Hye," (VisionTextDualEncoder model)"),Hye.forEach(t),xFo=i($),z_=n($,"LI",{});var Uye=s(z_);Lie=n(Uye,"STRONG",{});var Rat=s(Lie);$Fo=r(Rat,"visual_bert"),Rat.forEach(t),kFo=r(Uye," \u2014 "),Lq=n(Uye,"A",{href:!0});var Pat=s(Lq);SFo=r(Pat,"VisualBertModel"),Pat.forEach(t),RFo=r(Uye," (VisualBert model)"),Uye.forEach(t),PFo=i($),W_=n($,"LI",{});var Jye=s(W_);xie=n(Jye,"STRONG",{});var Bat=s(xie);BFo=r(Bat,"vit"),Bat.forEach(t),IFo=r(Jye," \u2014 "),xq=n(Jye,"A",{href:!0});var Iat=s(xq);NFo=r(Iat,"ViTModel"),Iat.forEach(t),qFo=r(Jye," (ViT model)"),Jye.forEach(t),jFo=i($),Q_=n($,"LI",{});var Yye=s(Q_);$ie=n(Yye,"STRONG",{});var Nat=s($ie);DFo=r(Nat,"vit_mae"),Nat.forEach(t),GFo=r(Yye," \u2014 "),$q=n(Yye,"A",{href:!0});var qat=s($q);OFo=r(qat,"ViTMAEModel"),qat.forEach(t),VFo=r(Yye," (ViTMAE model)"),Yye.forEach(t),XFo=i($),H_=n($,"LI",{});var Kye=s(H_);kie=n(Kye,"STRONG",{});var jat=s(kie);zFo=r(jat,"wav2vec2"),jat.forEach(t),WFo=r(Kye," \u2014 "),kq=n(Kye,"A",{href:!0});var Dat=s(kq);QFo=r(Dat,"Wav2Vec2Model"),Dat.forEach(t),HFo=r(Kye," (Wav2Vec2 model)"),Kye.forEach(t),UFo=i($),U_=n($,"LI",{});var Zye=s(U_);Sie=n(Zye,"STRONG",{});var Gat=s(Sie);JFo=r(Gat,"wav2vec2-conformer"),Gat.forEach(t),YFo=r(Zye," \u2014 "),Sq=n(Zye,"A",{href:!0});var Oat=s(Sq);KFo=r(Oat,"Wav2Vec2ConformerModel"),Oat.forEach(t),ZFo=r(Zye," (Wav2Vec2-Conformer model)"),Zye.forEach(t),eTo=i($),J_=n($,"LI",{});var eLe=s(J_);Rie=n(eLe,"STRONG",{});var Vat=s(Rie);oTo=r(Vat,"wavlm"),Vat.forEach(t),rTo=r(eLe," \u2014 "),Rq=n(eLe,"A",{href:!0});var Xat=s(Rq);tTo=r(Xat,"WavLMModel"),Xat.forEach(t),aTo=r(eLe," (WavLM model)"),eLe.forEach(t),nTo=i($),Y_=n($,"LI",{});var oLe=s(Y_);Pie=n(oLe,"STRONG",{});var zat=s(Pie);sTo=r(zat,"xglm"),zat.forEach(t),lTo=r(oLe," \u2014 "),Pq=n(oLe,"A",{href:!0});var Wat=s(Pq);iTo=r(Wat,"XGLMModel"),Wat.forEach(t),dTo=r(oLe," (XGLM model)"),oLe.forEach(t),cTo=i($),K_=n($,"LI",{});var rLe=s(K_);Bie=n(rLe,"STRONG",{});var Qat=s(Bie);fTo=r(Qat,"xlm"),Qat.forEach(t),mTo=r(rLe," \u2014 "),Bq=n(rLe,"A",{href:!0});var Hat=s(Bq);gTo=r(Hat,"XLMModel"),Hat.forEach(t),hTo=r(rLe," (XLM model)"),rLe.forEach(t),pTo=i($),Z_=n($,"LI",{});var tLe=s(Z_);Iie=n(tLe,"STRONG",{});var Uat=s(Iie);_To=r(Uat,"xlm-prophetnet"),Uat.forEach(t),uTo=r(tLe," \u2014 "),Iq=n(tLe,"A",{href:!0});var Jat=s(Iq);bTo=r(Jat,"XLMProphetNetModel"),Jat.forEach(t),vTo=r(tLe," (XLMProphetNet model)"),tLe.forEach(t),FTo=i($),eu=n($,"LI",{});var aLe=s(eu);Nie=n(aLe,"STRONG",{});var Yat=s(Nie);TTo=r(Yat,"xlm-roberta"),Yat.forEach(t),MTo=r(aLe," \u2014 "),Nq=n(aLe,"A",{href:!0});var Kat=s(Nq);ETo=r(Kat,"XLMRobertaModel"),Kat.forEach(t),CTo=r(aLe," (XLM-RoBERTa model)"),aLe.forEach(t),wTo=i($),ou=n($,"LI",{});var nLe=s(ou);qie=n(nLe,"STRONG",{});var Zat=s(qie);ATo=r(Zat,"xlm-roberta-xl"),Zat.forEach(t),yTo=r(nLe," \u2014 "),qq=n(nLe,"A",{href:!0});var ent=s(qq);LTo=r(ent,"XLMRobertaXLModel"),ent.forEach(t),xTo=r(nLe," (XLM-RoBERTa-XL model)"),nLe.forEach(t),$To=i($),ru=n($,"LI",{});var sLe=s(ru);jie=n(sLe,"STRONG",{});var ont=s(jie);kTo=r(ont,"xlnet"),ont.forEach(t),STo=r(sLe," \u2014 "),jq=n(sLe,"A",{href:!0});var rnt=s(jq);RTo=r(rnt,"XLNetModel"),rnt.forEach(t),PTo=r(sLe," (XLNet model)"),sLe.forEach(t),BTo=i($),tu=n($,"LI",{});var lLe=s(tu);Die=n(lLe,"STRONG",{});var tnt=s(Die);ITo=r(tnt,"yolos"),tnt.forEach(t),NTo=r(lLe," \u2014 "),Dq=n(lLe,"A",{href:!0});var ant=s(Dq);qTo=r(ant,"YolosModel"),ant.forEach(t),jTo=r(lLe," (YOLOS model)"),lLe.forEach(t),DTo=i($),au=n($,"LI",{});var iLe=s(au);Gie=n(iLe,"STRONG",{});var nnt=s(Gie);GTo=r(nnt,"yoso"),nnt.forEach(t),OTo=r(iLe," \u2014 "),Gq=n(iLe,"A",{href:!0});var snt=s(Gq);VTo=r(snt,"YosoModel"),snt.forEach(t),XTo=r(iLe," (YOSO model)"),iLe.forEach(t),$.forEach(t),zTo=i(oa),nu=n(oa,"P",{});var dLe=s(nu);WTo=r(dLe,"The model is set in evaluation mode by default using "),Oie=n(dLe,"CODE",{});var lnt=s(Oie);QTo=r(lnt,"model.eval()"),lnt.forEach(t),HTo=r(dLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vie=n(dLe,"CODE",{});var int=s(Vie);UTo=r(int,"model.train()"),int.forEach(t),dLe.forEach(t),JTo=i(oa),T(su.$$.fragment,oa),oa.forEach(t),Vs.forEach(t),Yqe=i(f),$i=n(f,"H2",{class:!0});var oGe=s($i);lu=n(oGe,"A",{id:!0,class:!0,href:!0});var dnt=s(lu);Xie=n(dnt,"SPAN",{});var cnt=s(Xie);T(gy.$$.fragment,cnt),cnt.forEach(t),dnt.forEach(t),YTo=i(oGe),zie=n(oGe,"SPAN",{});var fnt=s(zie);KTo=r(fnt,"AutoModelForPreTraining"),fnt.forEach(t),oGe.forEach(t),Kqe=i(f),xo=n(f,"DIV",{class:!0});var Xs=s(xo);T(hy.$$.fragment,Xs),ZTo=i(Xs),ki=n(Xs,"P",{});var jZ=s(ki);e7o=r(jZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Oq=n(jZ,"A",{href:!0});var mnt=s(Oq);o7o=r(mnt,"from_pretrained()"),mnt.forEach(t),r7o=r(jZ," class method or the "),Vq=n(jZ,"A",{href:!0});var gnt=s(Vq);t7o=r(gnt,"from_config()"),gnt.forEach(t),a7o=r(jZ,` class
method.`),jZ.forEach(t),n7o=i(Xs),py=n(Xs,"P",{});var rGe=s(py);s7o=r(rGe,"This class cannot be instantiated directly using "),Wie=n(rGe,"CODE",{});var hnt=s(Wie);l7o=r(hnt,"__init__()"),hnt.forEach(t),i7o=r(rGe," (throws an error)."),rGe.forEach(t),d7o=i(Xs),at=n(Xs,"DIV",{class:!0});var Ow=s(at);T(_y.$$.fragment,Ow),c7o=i(Ow),Qie=n(Ow,"P",{});var pnt=s(Qie);f7o=r(pnt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),pnt.forEach(t),m7o=i(Ow),Si=n(Ow,"P",{});var DZ=s(Si);g7o=r(DZ,`Note:
Loading a model from its configuration file does `),Hie=n(DZ,"STRONG",{});var _nt=s(Hie);h7o=r(_nt,"not"),_nt.forEach(t),p7o=r(DZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xq=n(DZ,"A",{href:!0});var unt=s(Xq);_7o=r(unt,"from_pretrained()"),unt.forEach(t),u7o=r(DZ," to load the model weights."),DZ.forEach(t),b7o=i(Ow),T(iu.$$.fragment,Ow),Ow.forEach(t),v7o=i(Xs),Ye=n(Xs,"DIV",{class:!0});var ra=s(Ye);T(uy.$$.fragment,ra),F7o=i(ra),Uie=n(ra,"P",{});var bnt=s(Uie);T7o=r(bnt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),bnt.forEach(t),M7o=i(ra),xa=n(ra,"P",{});var Vw=s(xa);E7o=r(Vw,"The model class to instantiate is selected based on the "),Jie=n(Vw,"CODE",{});var vnt=s(Jie);C7o=r(vnt,"model_type"),vnt.forEach(t),w7o=r(Vw,` property of the config object (either
passed as an argument or loaded from `),Yie=n(Vw,"CODE",{});var Fnt=s(Yie);A7o=r(Fnt,"pretrained_model_name_or_path"),Fnt.forEach(t),y7o=r(Vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kie=n(Vw,"CODE",{});var Tnt=s(Kie);L7o=r(Tnt,"pretrained_model_name_or_path"),Tnt.forEach(t),x7o=r(Vw,":"),Vw.forEach(t),$7o=i(ra),G=n(ra,"UL",{});var O=s(G);du=n(O,"LI",{});var cLe=s(du);Zie=n(cLe,"STRONG",{});var Mnt=s(Zie);k7o=r(Mnt,"albert"),Mnt.forEach(t),S7o=r(cLe," \u2014 "),zq=n(cLe,"A",{href:!0});var Ent=s(zq);R7o=r(Ent,"AlbertForPreTraining"),Ent.forEach(t),P7o=r(cLe," (ALBERT model)"),cLe.forEach(t),B7o=i(O),cu=n(O,"LI",{});var fLe=s(cu);ede=n(fLe,"STRONG",{});var Cnt=s(ede);I7o=r(Cnt,"bart"),Cnt.forEach(t),N7o=r(fLe," \u2014 "),Wq=n(fLe,"A",{href:!0});var wnt=s(Wq);q7o=r(wnt,"BartForConditionalGeneration"),wnt.forEach(t),j7o=r(fLe," (BART model)"),fLe.forEach(t),D7o=i(O),fu=n(O,"LI",{});var mLe=s(fu);ode=n(mLe,"STRONG",{});var Ant=s(ode);G7o=r(Ant,"bert"),Ant.forEach(t),O7o=r(mLe," \u2014 "),Qq=n(mLe,"A",{href:!0});var ynt=s(Qq);V7o=r(ynt,"BertForPreTraining"),ynt.forEach(t),X7o=r(mLe," (BERT model)"),mLe.forEach(t),z7o=i(O),mu=n(O,"LI",{});var gLe=s(mu);rde=n(gLe,"STRONG",{});var Lnt=s(rde);W7o=r(Lnt,"big_bird"),Lnt.forEach(t),Q7o=r(gLe," \u2014 "),Hq=n(gLe,"A",{href:!0});var xnt=s(Hq);H7o=r(xnt,"BigBirdForPreTraining"),xnt.forEach(t),U7o=r(gLe," (BigBird model)"),gLe.forEach(t),J7o=i(O),gu=n(O,"LI",{});var hLe=s(gu);tde=n(hLe,"STRONG",{});var $nt=s(tde);Y7o=r($nt,"camembert"),$nt.forEach(t),K7o=r(hLe," \u2014 "),Uq=n(hLe,"A",{href:!0});var knt=s(Uq);Z7o=r(knt,"CamembertForMaskedLM"),knt.forEach(t),eMo=r(hLe," (CamemBERT model)"),hLe.forEach(t),oMo=i(O),hu=n(O,"LI",{});var pLe=s(hu);ade=n(pLe,"STRONG",{});var Snt=s(ade);rMo=r(Snt,"ctrl"),Snt.forEach(t),tMo=r(pLe," \u2014 "),Jq=n(pLe,"A",{href:!0});var Rnt=s(Jq);aMo=r(Rnt,"CTRLLMHeadModel"),Rnt.forEach(t),nMo=r(pLe," (CTRL model)"),pLe.forEach(t),sMo=i(O),pu=n(O,"LI",{});var _Le=s(pu);nde=n(_Le,"STRONG",{});var Pnt=s(nde);lMo=r(Pnt,"data2vec-text"),Pnt.forEach(t),iMo=r(_Le," \u2014 "),Yq=n(_Le,"A",{href:!0});var Bnt=s(Yq);dMo=r(Bnt,"Data2VecTextForMaskedLM"),Bnt.forEach(t),cMo=r(_Le," (Data2VecText model)"),_Le.forEach(t),fMo=i(O),_u=n(O,"LI",{});var uLe=s(_u);sde=n(uLe,"STRONG",{});var Int=s(sde);mMo=r(Int,"deberta"),Int.forEach(t),gMo=r(uLe," \u2014 "),Kq=n(uLe,"A",{href:!0});var Nnt=s(Kq);hMo=r(Nnt,"DebertaForMaskedLM"),Nnt.forEach(t),pMo=r(uLe," (DeBERTa model)"),uLe.forEach(t),_Mo=i(O),uu=n(O,"LI",{});var bLe=s(uu);lde=n(bLe,"STRONG",{});var qnt=s(lde);uMo=r(qnt,"deberta-v2"),qnt.forEach(t),bMo=r(bLe," \u2014 "),Zq=n(bLe,"A",{href:!0});var jnt=s(Zq);vMo=r(jnt,"DebertaV2ForMaskedLM"),jnt.forEach(t),FMo=r(bLe," (DeBERTa-v2 model)"),bLe.forEach(t),TMo=i(O),bu=n(O,"LI",{});var vLe=s(bu);ide=n(vLe,"STRONG",{});var Dnt=s(ide);MMo=r(Dnt,"distilbert"),Dnt.forEach(t),EMo=r(vLe," \u2014 "),ej=n(vLe,"A",{href:!0});var Gnt=s(ej);CMo=r(Gnt,"DistilBertForMaskedLM"),Gnt.forEach(t),wMo=r(vLe," (DistilBERT model)"),vLe.forEach(t),AMo=i(O),vu=n(O,"LI",{});var FLe=s(vu);dde=n(FLe,"STRONG",{});var Ont=s(dde);yMo=r(Ont,"electra"),Ont.forEach(t),LMo=r(FLe," \u2014 "),oj=n(FLe,"A",{href:!0});var Vnt=s(oj);xMo=r(Vnt,"ElectraForPreTraining"),Vnt.forEach(t),$Mo=r(FLe," (ELECTRA model)"),FLe.forEach(t),kMo=i(O),Fu=n(O,"LI",{});var TLe=s(Fu);cde=n(TLe,"STRONG",{});var Xnt=s(cde);SMo=r(Xnt,"flaubert"),Xnt.forEach(t),RMo=r(TLe," \u2014 "),rj=n(TLe,"A",{href:!0});var znt=s(rj);PMo=r(znt,"FlaubertWithLMHeadModel"),znt.forEach(t),BMo=r(TLe," (FlauBERT model)"),TLe.forEach(t),IMo=i(O),Tu=n(O,"LI",{});var MLe=s(Tu);fde=n(MLe,"STRONG",{});var Wnt=s(fde);NMo=r(Wnt,"flava"),Wnt.forEach(t),qMo=r(MLe," \u2014 "),tj=n(MLe,"A",{href:!0});var Qnt=s(tj);jMo=r(Qnt,"FlavaForPreTraining"),Qnt.forEach(t),DMo=r(MLe," (Flava model)"),MLe.forEach(t),GMo=i(O),Mu=n(O,"LI",{});var ELe=s(Mu);mde=n(ELe,"STRONG",{});var Hnt=s(mde);OMo=r(Hnt,"fnet"),Hnt.forEach(t),VMo=r(ELe," \u2014 "),aj=n(ELe,"A",{href:!0});var Unt=s(aj);XMo=r(Unt,"FNetForPreTraining"),Unt.forEach(t),zMo=r(ELe," (FNet model)"),ELe.forEach(t),WMo=i(O),Eu=n(O,"LI",{});var CLe=s(Eu);gde=n(CLe,"STRONG",{});var Jnt=s(gde);QMo=r(Jnt,"fsmt"),Jnt.forEach(t),HMo=r(CLe," \u2014 "),nj=n(CLe,"A",{href:!0});var Ynt=s(nj);UMo=r(Ynt,"FSMTForConditionalGeneration"),Ynt.forEach(t),JMo=r(CLe," (FairSeq Machine-Translation model)"),CLe.forEach(t),YMo=i(O),Cu=n(O,"LI",{});var wLe=s(Cu);hde=n(wLe,"STRONG",{});var Knt=s(hde);KMo=r(Knt,"funnel"),Knt.forEach(t),ZMo=r(wLe," \u2014 "),sj=n(wLe,"A",{href:!0});var Znt=s(sj);eEo=r(Znt,"FunnelForPreTraining"),Znt.forEach(t),oEo=r(wLe," (Funnel Transformer model)"),wLe.forEach(t),rEo=i(O),wu=n(O,"LI",{});var ALe=s(wu);pde=n(ALe,"STRONG",{});var est=s(pde);tEo=r(est,"gpt2"),est.forEach(t),aEo=r(ALe," \u2014 "),lj=n(ALe,"A",{href:!0});var ost=s(lj);nEo=r(ost,"GPT2LMHeadModel"),ost.forEach(t),sEo=r(ALe," (OpenAI GPT-2 model)"),ALe.forEach(t),lEo=i(O),Au=n(O,"LI",{});var yLe=s(Au);_de=n(yLe,"STRONG",{});var rst=s(_de);iEo=r(rst,"ibert"),rst.forEach(t),dEo=r(yLe," \u2014 "),ij=n(yLe,"A",{href:!0});var tst=s(ij);cEo=r(tst,"IBertForMaskedLM"),tst.forEach(t),fEo=r(yLe," (I-BERT model)"),yLe.forEach(t),mEo=i(O),yu=n(O,"LI",{});var LLe=s(yu);ude=n(LLe,"STRONG",{});var ast=s(ude);gEo=r(ast,"layoutlm"),ast.forEach(t),hEo=r(LLe," \u2014 "),dj=n(LLe,"A",{href:!0});var nst=s(dj);pEo=r(nst,"LayoutLMForMaskedLM"),nst.forEach(t),_Eo=r(LLe," (LayoutLM model)"),LLe.forEach(t),uEo=i(O),Lu=n(O,"LI",{});var xLe=s(Lu);bde=n(xLe,"STRONG",{});var sst=s(bde);bEo=r(sst,"longformer"),sst.forEach(t),vEo=r(xLe," \u2014 "),cj=n(xLe,"A",{href:!0});var lst=s(cj);FEo=r(lst,"LongformerForMaskedLM"),lst.forEach(t),TEo=r(xLe," (Longformer model)"),xLe.forEach(t),MEo=i(O),xu=n(O,"LI",{});var $Le=s(xu);vde=n($Le,"STRONG",{});var ist=s(vde);EEo=r(ist,"lxmert"),ist.forEach(t),CEo=r($Le," \u2014 "),fj=n($Le,"A",{href:!0});var dst=s(fj);wEo=r(dst,"LxmertForPreTraining"),dst.forEach(t),AEo=r($Le," (LXMERT model)"),$Le.forEach(t),yEo=i(O),$u=n(O,"LI",{});var kLe=s($u);Fde=n(kLe,"STRONG",{});var cst=s(Fde);LEo=r(cst,"megatron-bert"),cst.forEach(t),xEo=r(kLe," \u2014 "),mj=n(kLe,"A",{href:!0});var fst=s(mj);$Eo=r(fst,"MegatronBertForPreTraining"),fst.forEach(t),kEo=r(kLe," (MegatronBert model)"),kLe.forEach(t),SEo=i(O),ku=n(O,"LI",{});var SLe=s(ku);Tde=n(SLe,"STRONG",{});var mst=s(Tde);REo=r(mst,"mobilebert"),mst.forEach(t),PEo=r(SLe," \u2014 "),gj=n(SLe,"A",{href:!0});var gst=s(gj);BEo=r(gst,"MobileBertForPreTraining"),gst.forEach(t),IEo=r(SLe," (MobileBERT model)"),SLe.forEach(t),NEo=i(O),Su=n(O,"LI",{});var RLe=s(Su);Mde=n(RLe,"STRONG",{});var hst=s(Mde);qEo=r(hst,"mpnet"),hst.forEach(t),jEo=r(RLe," \u2014 "),hj=n(RLe,"A",{href:!0});var pst=s(hj);DEo=r(pst,"MPNetForMaskedLM"),pst.forEach(t),GEo=r(RLe," (MPNet model)"),RLe.forEach(t),OEo=i(O),Ru=n(O,"LI",{});var PLe=s(Ru);Ede=n(PLe,"STRONG",{});var _st=s(Ede);VEo=r(_st,"openai-gpt"),_st.forEach(t),XEo=r(PLe," \u2014 "),pj=n(PLe,"A",{href:!0});var ust=s(pj);zEo=r(ust,"OpenAIGPTLMHeadModel"),ust.forEach(t),WEo=r(PLe," (OpenAI GPT model)"),PLe.forEach(t),QEo=i(O),Pu=n(O,"LI",{});var BLe=s(Pu);Cde=n(BLe,"STRONG",{});var bst=s(Cde);HEo=r(bst,"retribert"),bst.forEach(t),UEo=r(BLe," \u2014 "),_j=n(BLe,"A",{href:!0});var vst=s(_j);JEo=r(vst,"RetriBertModel"),vst.forEach(t),YEo=r(BLe," (RetriBERT model)"),BLe.forEach(t),KEo=i(O),Bu=n(O,"LI",{});var ILe=s(Bu);wde=n(ILe,"STRONG",{});var Fst=s(wde);ZEo=r(Fst,"roberta"),Fst.forEach(t),eCo=r(ILe," \u2014 "),uj=n(ILe,"A",{href:!0});var Tst=s(uj);oCo=r(Tst,"RobertaForMaskedLM"),Tst.forEach(t),rCo=r(ILe," (RoBERTa model)"),ILe.forEach(t),tCo=i(O),Iu=n(O,"LI",{});var NLe=s(Iu);Ade=n(NLe,"STRONG",{});var Mst=s(Ade);aCo=r(Mst,"splinter"),Mst.forEach(t),nCo=r(NLe," \u2014 "),bj=n(NLe,"A",{href:!0});var Est=s(bj);sCo=r(Est,"SplinterForPreTraining"),Est.forEach(t),lCo=r(NLe," (Splinter model)"),NLe.forEach(t),iCo=i(O),Nu=n(O,"LI",{});var qLe=s(Nu);yde=n(qLe,"STRONG",{});var Cst=s(yde);dCo=r(Cst,"squeezebert"),Cst.forEach(t),cCo=r(qLe," \u2014 "),vj=n(qLe,"A",{href:!0});var wst=s(vj);fCo=r(wst,"SqueezeBertForMaskedLM"),wst.forEach(t),mCo=r(qLe," (SqueezeBERT model)"),qLe.forEach(t),gCo=i(O),qu=n(O,"LI",{});var jLe=s(qu);Lde=n(jLe,"STRONG",{});var Ast=s(Lde);hCo=r(Ast,"t5"),Ast.forEach(t),pCo=r(jLe," \u2014 "),Fj=n(jLe,"A",{href:!0});var yst=s(Fj);_Co=r(yst,"T5ForConditionalGeneration"),yst.forEach(t),uCo=r(jLe," (T5 model)"),jLe.forEach(t),bCo=i(O),ju=n(O,"LI",{});var DLe=s(ju);xde=n(DLe,"STRONG",{});var Lst=s(xde);vCo=r(Lst,"tapas"),Lst.forEach(t),FCo=r(DLe," \u2014 "),Tj=n(DLe,"A",{href:!0});var xst=s(Tj);TCo=r(xst,"TapasForMaskedLM"),xst.forEach(t),MCo=r(DLe," (TAPAS model)"),DLe.forEach(t),ECo=i(O),Du=n(O,"LI",{});var GLe=s(Du);$de=n(GLe,"STRONG",{});var $st=s($de);CCo=r($st,"transfo-xl"),$st.forEach(t),wCo=r(GLe," \u2014 "),Mj=n(GLe,"A",{href:!0});var kst=s(Mj);ACo=r(kst,"TransfoXLLMHeadModel"),kst.forEach(t),yCo=r(GLe," (Transformer-XL model)"),GLe.forEach(t),LCo=i(O),Gu=n(O,"LI",{});var OLe=s(Gu);kde=n(OLe,"STRONG",{});var Sst=s(kde);xCo=r(Sst,"unispeech"),Sst.forEach(t),$Co=r(OLe," \u2014 "),Ej=n(OLe,"A",{href:!0});var Rst=s(Ej);kCo=r(Rst,"UniSpeechForPreTraining"),Rst.forEach(t),SCo=r(OLe," (UniSpeech model)"),OLe.forEach(t),RCo=i(O),Ou=n(O,"LI",{});var VLe=s(Ou);Sde=n(VLe,"STRONG",{});var Pst=s(Sde);PCo=r(Pst,"unispeech-sat"),Pst.forEach(t),BCo=r(VLe," \u2014 "),Cj=n(VLe,"A",{href:!0});var Bst=s(Cj);ICo=r(Bst,"UniSpeechSatForPreTraining"),Bst.forEach(t),NCo=r(VLe," (UniSpeechSat model)"),VLe.forEach(t),qCo=i(O),Vu=n(O,"LI",{});var XLe=s(Vu);Rde=n(XLe,"STRONG",{});var Ist=s(Rde);jCo=r(Ist,"visual_bert"),Ist.forEach(t),DCo=r(XLe," \u2014 "),wj=n(XLe,"A",{href:!0});var Nst=s(wj);GCo=r(Nst,"VisualBertForPreTraining"),Nst.forEach(t),OCo=r(XLe," (VisualBert model)"),XLe.forEach(t),VCo=i(O),Xu=n(O,"LI",{});var zLe=s(Xu);Pde=n(zLe,"STRONG",{});var qst=s(Pde);XCo=r(qst,"vit_mae"),qst.forEach(t),zCo=r(zLe," \u2014 "),Aj=n(zLe,"A",{href:!0});var jst=s(Aj);WCo=r(jst,"ViTMAEForPreTraining"),jst.forEach(t),QCo=r(zLe," (ViTMAE model)"),zLe.forEach(t),HCo=i(O),zu=n(O,"LI",{});var WLe=s(zu);Bde=n(WLe,"STRONG",{});var Dst=s(Bde);UCo=r(Dst,"wav2vec2"),Dst.forEach(t),JCo=r(WLe," \u2014 "),yj=n(WLe,"A",{href:!0});var Gst=s(yj);YCo=r(Gst,"Wav2Vec2ForPreTraining"),Gst.forEach(t),KCo=r(WLe," (Wav2Vec2 model)"),WLe.forEach(t),ZCo=i(O),Wu=n(O,"LI",{});var QLe=s(Wu);Ide=n(QLe,"STRONG",{});var Ost=s(Ide);e3o=r(Ost,"wav2vec2-conformer"),Ost.forEach(t),o3o=r(QLe," \u2014 "),Lj=n(QLe,"A",{href:!0});var Vst=s(Lj);r3o=r(Vst,"Wav2Vec2ConformerForPreTraining"),Vst.forEach(t),t3o=r(QLe," (Wav2Vec2-Conformer model)"),QLe.forEach(t),a3o=i(O),Qu=n(O,"LI",{});var HLe=s(Qu);Nde=n(HLe,"STRONG",{});var Xst=s(Nde);n3o=r(Xst,"xlm"),Xst.forEach(t),s3o=r(HLe," \u2014 "),xj=n(HLe,"A",{href:!0});var zst=s(xj);l3o=r(zst,"XLMWithLMHeadModel"),zst.forEach(t),i3o=r(HLe," (XLM model)"),HLe.forEach(t),d3o=i(O),Hu=n(O,"LI",{});var ULe=s(Hu);qde=n(ULe,"STRONG",{});var Wst=s(qde);c3o=r(Wst,"xlm-roberta"),Wst.forEach(t),f3o=r(ULe," \u2014 "),$j=n(ULe,"A",{href:!0});var Qst=s($j);m3o=r(Qst,"XLMRobertaForMaskedLM"),Qst.forEach(t),g3o=r(ULe," (XLM-RoBERTa model)"),ULe.forEach(t),h3o=i(O),Uu=n(O,"LI",{});var JLe=s(Uu);jde=n(JLe,"STRONG",{});var Hst=s(jde);p3o=r(Hst,"xlm-roberta-xl"),Hst.forEach(t),_3o=r(JLe," \u2014 "),kj=n(JLe,"A",{href:!0});var Ust=s(kj);u3o=r(Ust,"XLMRobertaXLForMaskedLM"),Ust.forEach(t),b3o=r(JLe," (XLM-RoBERTa-XL model)"),JLe.forEach(t),v3o=i(O),Ju=n(O,"LI",{});var YLe=s(Ju);Dde=n(YLe,"STRONG",{});var Jst=s(Dde);F3o=r(Jst,"xlnet"),Jst.forEach(t),T3o=r(YLe," \u2014 "),Sj=n(YLe,"A",{href:!0});var Yst=s(Sj);M3o=r(Yst,"XLNetLMHeadModel"),Yst.forEach(t),E3o=r(YLe," (XLNet model)"),YLe.forEach(t),O.forEach(t),C3o=i(ra),Yu=n(ra,"P",{});var KLe=s(Yu);w3o=r(KLe,"The model is set in evaluation mode by default using "),Gde=n(KLe,"CODE",{});var Kst=s(Gde);A3o=r(Kst,"model.eval()"),Kst.forEach(t),y3o=r(KLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ode=n(KLe,"CODE",{});var Zst=s(Ode);L3o=r(Zst,"model.train()"),Zst.forEach(t),KLe.forEach(t),x3o=i(ra),T(Ku.$$.fragment,ra),ra.forEach(t),Xs.forEach(t),Zqe=i(f),Ri=n(f,"H2",{class:!0});var tGe=s(Ri);Zu=n(tGe,"A",{id:!0,class:!0,href:!0});var elt=s(Zu);Vde=n(elt,"SPAN",{});var olt=s(Vde);T(by.$$.fragment,olt),olt.forEach(t),elt.forEach(t),$3o=i(tGe),Xde=n(tGe,"SPAN",{});var rlt=s(Xde);k3o=r(rlt,"AutoModelForCausalLM"),rlt.forEach(t),tGe.forEach(t),eje=i(f),$o=n(f,"DIV",{class:!0});var zs=s($o);T(vy.$$.fragment,zs),S3o=i(zs),Pi=n(zs,"P",{});var GZ=s(Pi);R3o=r(GZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Rj=n(GZ,"A",{href:!0});var tlt=s(Rj);P3o=r(tlt,"from_pretrained()"),tlt.forEach(t),B3o=r(GZ," class method or the "),Pj=n(GZ,"A",{href:!0});var alt=s(Pj);I3o=r(alt,"from_config()"),alt.forEach(t),N3o=r(GZ,` class
method.`),GZ.forEach(t),q3o=i(zs),Fy=n(zs,"P",{});var aGe=s(Fy);j3o=r(aGe,"This class cannot be instantiated directly using "),zde=n(aGe,"CODE",{});var nlt=s(zde);D3o=r(nlt,"__init__()"),nlt.forEach(t),G3o=r(aGe," (throws an error)."),aGe.forEach(t),O3o=i(zs),nt=n(zs,"DIV",{class:!0});var Xw=s(nt);T(Ty.$$.fragment,Xw),V3o=i(Xw),Wde=n(Xw,"P",{});var slt=s(Wde);X3o=r(slt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),slt.forEach(t),z3o=i(Xw),Bi=n(Xw,"P",{});var OZ=s(Bi);W3o=r(OZ,`Note:
Loading a model from its configuration file does `),Qde=n(OZ,"STRONG",{});var llt=s(Qde);Q3o=r(llt,"not"),llt.forEach(t),H3o=r(OZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bj=n(OZ,"A",{href:!0});var ilt=s(Bj);U3o=r(ilt,"from_pretrained()"),ilt.forEach(t),J3o=r(OZ," to load the model weights."),OZ.forEach(t),Y3o=i(Xw),T(e2.$$.fragment,Xw),Xw.forEach(t),K3o=i(zs),Ke=n(zs,"DIV",{class:!0});var ta=s(Ke);T(My.$$.fragment,ta),Z3o=i(ta),Hde=n(ta,"P",{});var dlt=s(Hde);e0o=r(dlt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),dlt.forEach(t),o0o=i(ta),$a=n(ta,"P",{});var zw=s($a);r0o=r(zw,"The model class to instantiate is selected based on the "),Ude=n(zw,"CODE",{});var clt=s(Ude);t0o=r(clt,"model_type"),clt.forEach(t),a0o=r(zw,` property of the config object (either
passed as an argument or loaded from `),Jde=n(zw,"CODE",{});var flt=s(Jde);n0o=r(flt,"pretrained_model_name_or_path"),flt.forEach(t),s0o=r(zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yde=n(zw,"CODE",{});var mlt=s(Yde);l0o=r(mlt,"pretrained_model_name_or_path"),mlt.forEach(t),i0o=r(zw,":"),zw.forEach(t),d0o=i(ta),z=n(ta,"UL",{});var Q=s(z);o2=n(Q,"LI",{});var ZLe=s(o2);Kde=n(ZLe,"STRONG",{});var glt=s(Kde);c0o=r(glt,"bart"),glt.forEach(t),f0o=r(ZLe," \u2014 "),Ij=n(ZLe,"A",{href:!0});var hlt=s(Ij);m0o=r(hlt,"BartForCausalLM"),hlt.forEach(t),g0o=r(ZLe," (BART model)"),ZLe.forEach(t),h0o=i(Q),r2=n(Q,"LI",{});var e8e=s(r2);Zde=n(e8e,"STRONG",{});var plt=s(Zde);p0o=r(plt,"bert"),plt.forEach(t),_0o=r(e8e," \u2014 "),Nj=n(e8e,"A",{href:!0});var _lt=s(Nj);u0o=r(_lt,"BertLMHeadModel"),_lt.forEach(t),b0o=r(e8e," (BERT model)"),e8e.forEach(t),v0o=i(Q),t2=n(Q,"LI",{});var o8e=s(t2);ece=n(o8e,"STRONG",{});var ult=s(ece);F0o=r(ult,"bert-generation"),ult.forEach(t),T0o=r(o8e," \u2014 "),qj=n(o8e,"A",{href:!0});var blt=s(qj);M0o=r(blt,"BertGenerationDecoder"),blt.forEach(t),E0o=r(o8e," (Bert Generation model)"),o8e.forEach(t),C0o=i(Q),a2=n(Q,"LI",{});var r8e=s(a2);oce=n(r8e,"STRONG",{});var vlt=s(oce);w0o=r(vlt,"big_bird"),vlt.forEach(t),A0o=r(r8e," \u2014 "),jj=n(r8e,"A",{href:!0});var Flt=s(jj);y0o=r(Flt,"BigBirdForCausalLM"),Flt.forEach(t),L0o=r(r8e," (BigBird model)"),r8e.forEach(t),x0o=i(Q),n2=n(Q,"LI",{});var t8e=s(n2);rce=n(t8e,"STRONG",{});var Tlt=s(rce);$0o=r(Tlt,"bigbird_pegasus"),Tlt.forEach(t),k0o=r(t8e," \u2014 "),Dj=n(t8e,"A",{href:!0});var Mlt=s(Dj);S0o=r(Mlt,"BigBirdPegasusForCausalLM"),Mlt.forEach(t),R0o=r(t8e," (BigBirdPegasus model)"),t8e.forEach(t),P0o=i(Q),s2=n(Q,"LI",{});var a8e=s(s2);tce=n(a8e,"STRONG",{});var Elt=s(tce);B0o=r(Elt,"blenderbot"),Elt.forEach(t),I0o=r(a8e," \u2014 "),Gj=n(a8e,"A",{href:!0});var Clt=s(Gj);N0o=r(Clt,"BlenderbotForCausalLM"),Clt.forEach(t),q0o=r(a8e," (Blenderbot model)"),a8e.forEach(t),j0o=i(Q),l2=n(Q,"LI",{});var n8e=s(l2);ace=n(n8e,"STRONG",{});var wlt=s(ace);D0o=r(wlt,"blenderbot-small"),wlt.forEach(t),G0o=r(n8e," \u2014 "),Oj=n(n8e,"A",{href:!0});var Alt=s(Oj);O0o=r(Alt,"BlenderbotSmallForCausalLM"),Alt.forEach(t),V0o=r(n8e," (BlenderbotSmall model)"),n8e.forEach(t),X0o=i(Q),i2=n(Q,"LI",{});var s8e=s(i2);nce=n(s8e,"STRONG",{});var ylt=s(nce);z0o=r(ylt,"camembert"),ylt.forEach(t),W0o=r(s8e," \u2014 "),Vj=n(s8e,"A",{href:!0});var Llt=s(Vj);Q0o=r(Llt,"CamembertForCausalLM"),Llt.forEach(t),H0o=r(s8e," (CamemBERT model)"),s8e.forEach(t),U0o=i(Q),d2=n(Q,"LI",{});var l8e=s(d2);sce=n(l8e,"STRONG",{});var xlt=s(sce);J0o=r(xlt,"ctrl"),xlt.forEach(t),Y0o=r(l8e," \u2014 "),Xj=n(l8e,"A",{href:!0});var $lt=s(Xj);K0o=r($lt,"CTRLLMHeadModel"),$lt.forEach(t),Z0o=r(l8e," (CTRL model)"),l8e.forEach(t),ewo=i(Q),c2=n(Q,"LI",{});var i8e=s(c2);lce=n(i8e,"STRONG",{});var klt=s(lce);owo=r(klt,"data2vec-text"),klt.forEach(t),rwo=r(i8e," \u2014 "),zj=n(i8e,"A",{href:!0});var Slt=s(zj);two=r(Slt,"Data2VecTextForCausalLM"),Slt.forEach(t),awo=r(i8e," (Data2VecText model)"),i8e.forEach(t),nwo=i(Q),f2=n(Q,"LI",{});var d8e=s(f2);ice=n(d8e,"STRONG",{});var Rlt=s(ice);swo=r(Rlt,"electra"),Rlt.forEach(t),lwo=r(d8e," \u2014 "),Wj=n(d8e,"A",{href:!0});var Plt=s(Wj);iwo=r(Plt,"ElectraForCausalLM"),Plt.forEach(t),dwo=r(d8e," (ELECTRA model)"),d8e.forEach(t),cwo=i(Q),m2=n(Q,"LI",{});var c8e=s(m2);dce=n(c8e,"STRONG",{});var Blt=s(dce);fwo=r(Blt,"gpt2"),Blt.forEach(t),mwo=r(c8e," \u2014 "),Qj=n(c8e,"A",{href:!0});var Ilt=s(Qj);gwo=r(Ilt,"GPT2LMHeadModel"),Ilt.forEach(t),hwo=r(c8e," (OpenAI GPT-2 model)"),c8e.forEach(t),pwo=i(Q),g2=n(Q,"LI",{});var f8e=s(g2);cce=n(f8e,"STRONG",{});var Nlt=s(cce);_wo=r(Nlt,"gpt_neo"),Nlt.forEach(t),uwo=r(f8e," \u2014 "),Hj=n(f8e,"A",{href:!0});var qlt=s(Hj);bwo=r(qlt,"GPTNeoForCausalLM"),qlt.forEach(t),vwo=r(f8e," (GPT Neo model)"),f8e.forEach(t),Fwo=i(Q),h2=n(Q,"LI",{});var m8e=s(h2);fce=n(m8e,"STRONG",{});var jlt=s(fce);Two=r(jlt,"gpt_neox"),jlt.forEach(t),Mwo=r(m8e," \u2014 "),Uj=n(m8e,"A",{href:!0});var Dlt=s(Uj);Ewo=r(Dlt,"GPTNeoXForCausalLM"),Dlt.forEach(t),Cwo=r(m8e," (GPT NeoX model)"),m8e.forEach(t),wwo=i(Q),p2=n(Q,"LI",{});var g8e=s(p2);mce=n(g8e,"STRONG",{});var Glt=s(mce);Awo=r(Glt,"gptj"),Glt.forEach(t),ywo=r(g8e," \u2014 "),Jj=n(g8e,"A",{href:!0});var Olt=s(Jj);Lwo=r(Olt,"GPTJForCausalLM"),Olt.forEach(t),xwo=r(g8e," (GPT-J model)"),g8e.forEach(t),$wo=i(Q),_2=n(Q,"LI",{});var h8e=s(_2);gce=n(h8e,"STRONG",{});var Vlt=s(gce);kwo=r(Vlt,"marian"),Vlt.forEach(t),Swo=r(h8e," \u2014 "),Yj=n(h8e,"A",{href:!0});var Xlt=s(Yj);Rwo=r(Xlt,"MarianForCausalLM"),Xlt.forEach(t),Pwo=r(h8e," (Marian model)"),h8e.forEach(t),Bwo=i(Q),u2=n(Q,"LI",{});var p8e=s(u2);hce=n(p8e,"STRONG",{});var zlt=s(hce);Iwo=r(zlt,"mbart"),zlt.forEach(t),Nwo=r(p8e," \u2014 "),Kj=n(p8e,"A",{href:!0});var Wlt=s(Kj);qwo=r(Wlt,"MBartForCausalLM"),Wlt.forEach(t),jwo=r(p8e," (mBART model)"),p8e.forEach(t),Dwo=i(Q),b2=n(Q,"LI",{});var _8e=s(b2);pce=n(_8e,"STRONG",{});var Qlt=s(pce);Gwo=r(Qlt,"megatron-bert"),Qlt.forEach(t),Owo=r(_8e," \u2014 "),Zj=n(_8e,"A",{href:!0});var Hlt=s(Zj);Vwo=r(Hlt,"MegatronBertForCausalLM"),Hlt.forEach(t),Xwo=r(_8e," (MegatronBert model)"),_8e.forEach(t),zwo=i(Q),v2=n(Q,"LI",{});var u8e=s(v2);_ce=n(u8e,"STRONG",{});var Ult=s(_ce);Wwo=r(Ult,"openai-gpt"),Ult.forEach(t),Qwo=r(u8e," \u2014 "),eD=n(u8e,"A",{href:!0});var Jlt=s(eD);Hwo=r(Jlt,"OpenAIGPTLMHeadModel"),Jlt.forEach(t),Uwo=r(u8e," (OpenAI GPT model)"),u8e.forEach(t),Jwo=i(Q),F2=n(Q,"LI",{});var b8e=s(F2);uce=n(b8e,"STRONG",{});var Ylt=s(uce);Ywo=r(Ylt,"opt"),Ylt.forEach(t),Kwo=r(b8e," \u2014 "),oD=n(b8e,"A",{href:!0});var Klt=s(oD);Zwo=r(Klt,"OPTForCausalLM"),Klt.forEach(t),e6o=r(b8e," (OPT model)"),b8e.forEach(t),o6o=i(Q),T2=n(Q,"LI",{});var v8e=s(T2);bce=n(v8e,"STRONG",{});var Zlt=s(bce);r6o=r(Zlt,"pegasus"),Zlt.forEach(t),t6o=r(v8e," \u2014 "),rD=n(v8e,"A",{href:!0});var eit=s(rD);a6o=r(eit,"PegasusForCausalLM"),eit.forEach(t),n6o=r(v8e," (Pegasus model)"),v8e.forEach(t),s6o=i(Q),M2=n(Q,"LI",{});var F8e=s(M2);vce=n(F8e,"STRONG",{});var oit=s(vce);l6o=r(oit,"plbart"),oit.forEach(t),i6o=r(F8e," \u2014 "),tD=n(F8e,"A",{href:!0});var rit=s(tD);d6o=r(rit,"PLBartForCausalLM"),rit.forEach(t),c6o=r(F8e," (PLBart model)"),F8e.forEach(t),f6o=i(Q),E2=n(Q,"LI",{});var T8e=s(E2);Fce=n(T8e,"STRONG",{});var tit=s(Fce);m6o=r(tit,"prophetnet"),tit.forEach(t),g6o=r(T8e," \u2014 "),aD=n(T8e,"A",{href:!0});var ait=s(aD);h6o=r(ait,"ProphetNetForCausalLM"),ait.forEach(t),p6o=r(T8e," (ProphetNet model)"),T8e.forEach(t),_6o=i(Q),C2=n(Q,"LI",{});var M8e=s(C2);Tce=n(M8e,"STRONG",{});var nit=s(Tce);u6o=r(nit,"qdqbert"),nit.forEach(t),b6o=r(M8e," \u2014 "),nD=n(M8e,"A",{href:!0});var sit=s(nD);v6o=r(sit,"QDQBertLMHeadModel"),sit.forEach(t),F6o=r(M8e," (QDQBert model)"),M8e.forEach(t),T6o=i(Q),w2=n(Q,"LI",{});var E8e=s(w2);Mce=n(E8e,"STRONG",{});var lit=s(Mce);M6o=r(lit,"reformer"),lit.forEach(t),E6o=r(E8e," \u2014 "),sD=n(E8e,"A",{href:!0});var iit=s(sD);C6o=r(iit,"ReformerModelWithLMHead"),iit.forEach(t),w6o=r(E8e," (Reformer model)"),E8e.forEach(t),A6o=i(Q),A2=n(Q,"LI",{});var C8e=s(A2);Ece=n(C8e,"STRONG",{});var dit=s(Ece);y6o=r(dit,"rembert"),dit.forEach(t),L6o=r(C8e," \u2014 "),lD=n(C8e,"A",{href:!0});var cit=s(lD);x6o=r(cit,"RemBertForCausalLM"),cit.forEach(t),$6o=r(C8e," (RemBERT model)"),C8e.forEach(t),k6o=i(Q),y2=n(Q,"LI",{});var w8e=s(y2);Cce=n(w8e,"STRONG",{});var fit=s(Cce);S6o=r(fit,"roberta"),fit.forEach(t),R6o=r(w8e," \u2014 "),iD=n(w8e,"A",{href:!0});var mit=s(iD);P6o=r(mit,"RobertaForCausalLM"),mit.forEach(t),B6o=r(w8e," (RoBERTa model)"),w8e.forEach(t),I6o=i(Q),L2=n(Q,"LI",{});var A8e=s(L2);wce=n(A8e,"STRONG",{});var git=s(wce);N6o=r(git,"roformer"),git.forEach(t),q6o=r(A8e," \u2014 "),dD=n(A8e,"A",{href:!0});var hit=s(dD);j6o=r(hit,"RoFormerForCausalLM"),hit.forEach(t),D6o=r(A8e," (RoFormer model)"),A8e.forEach(t),G6o=i(Q),x2=n(Q,"LI",{});var y8e=s(x2);Ace=n(y8e,"STRONG",{});var pit=s(Ace);O6o=r(pit,"speech_to_text_2"),pit.forEach(t),V6o=r(y8e," \u2014 "),cD=n(y8e,"A",{href:!0});var _it=s(cD);X6o=r(_it,"Speech2Text2ForCausalLM"),_it.forEach(t),z6o=r(y8e," (Speech2Text2 model)"),y8e.forEach(t),W6o=i(Q),$2=n(Q,"LI",{});var L8e=s($2);yce=n(L8e,"STRONG",{});var uit=s(yce);Q6o=r(uit,"transfo-xl"),uit.forEach(t),H6o=r(L8e," \u2014 "),fD=n(L8e,"A",{href:!0});var bit=s(fD);U6o=r(bit,"TransfoXLLMHeadModel"),bit.forEach(t),J6o=r(L8e," (Transformer-XL model)"),L8e.forEach(t),Y6o=i(Q),k2=n(Q,"LI",{});var x8e=s(k2);Lce=n(x8e,"STRONG",{});var vit=s(Lce);K6o=r(vit,"trocr"),vit.forEach(t),Z6o=r(x8e," \u2014 "),mD=n(x8e,"A",{href:!0});var Fit=s(mD);eAo=r(Fit,"TrOCRForCausalLM"),Fit.forEach(t),oAo=r(x8e," (TrOCR model)"),x8e.forEach(t),rAo=i(Q),S2=n(Q,"LI",{});var $8e=s(S2);xce=n($8e,"STRONG",{});var Tit=s(xce);tAo=r(Tit,"xglm"),Tit.forEach(t),aAo=r($8e," \u2014 "),gD=n($8e,"A",{href:!0});var Mit=s(gD);nAo=r(Mit,"XGLMForCausalLM"),Mit.forEach(t),sAo=r($8e," (XGLM model)"),$8e.forEach(t),lAo=i(Q),R2=n(Q,"LI",{});var k8e=s(R2);$ce=n(k8e,"STRONG",{});var Eit=s($ce);iAo=r(Eit,"xlm"),Eit.forEach(t),dAo=r(k8e," \u2014 "),hD=n(k8e,"A",{href:!0});var Cit=s(hD);cAo=r(Cit,"XLMWithLMHeadModel"),Cit.forEach(t),fAo=r(k8e," (XLM model)"),k8e.forEach(t),mAo=i(Q),P2=n(Q,"LI",{});var S8e=s(P2);kce=n(S8e,"STRONG",{});var wit=s(kce);gAo=r(wit,"xlm-prophetnet"),wit.forEach(t),hAo=r(S8e," \u2014 "),pD=n(S8e,"A",{href:!0});var Ait=s(pD);pAo=r(Ait,"XLMProphetNetForCausalLM"),Ait.forEach(t),_Ao=r(S8e," (XLMProphetNet model)"),S8e.forEach(t),uAo=i(Q),B2=n(Q,"LI",{});var R8e=s(B2);Sce=n(R8e,"STRONG",{});var yit=s(Sce);bAo=r(yit,"xlm-roberta"),yit.forEach(t),vAo=r(R8e," \u2014 "),_D=n(R8e,"A",{href:!0});var Lit=s(_D);FAo=r(Lit,"XLMRobertaForCausalLM"),Lit.forEach(t),TAo=r(R8e," (XLM-RoBERTa model)"),R8e.forEach(t),MAo=i(Q),I2=n(Q,"LI",{});var P8e=s(I2);Rce=n(P8e,"STRONG",{});var xit=s(Rce);EAo=r(xit,"xlm-roberta-xl"),xit.forEach(t),CAo=r(P8e," \u2014 "),uD=n(P8e,"A",{href:!0});var $it=s(uD);wAo=r($it,"XLMRobertaXLForCausalLM"),$it.forEach(t),AAo=r(P8e," (XLM-RoBERTa-XL model)"),P8e.forEach(t),yAo=i(Q),N2=n(Q,"LI",{});var B8e=s(N2);Pce=n(B8e,"STRONG",{});var kit=s(Pce);LAo=r(kit,"xlnet"),kit.forEach(t),xAo=r(B8e," \u2014 "),bD=n(B8e,"A",{href:!0});var Sit=s(bD);$Ao=r(Sit,"XLNetLMHeadModel"),Sit.forEach(t),kAo=r(B8e," (XLNet model)"),B8e.forEach(t),Q.forEach(t),SAo=i(ta),q2=n(ta,"P",{});var I8e=s(q2);RAo=r(I8e,"The model is set in evaluation mode by default using "),Bce=n(I8e,"CODE",{});var Rit=s(Bce);PAo=r(Rit,"model.eval()"),Rit.forEach(t),BAo=r(I8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ice=n(I8e,"CODE",{});var Pit=s(Ice);IAo=r(Pit,"model.train()"),Pit.forEach(t),I8e.forEach(t),NAo=i(ta),T(j2.$$.fragment,ta),ta.forEach(t),zs.forEach(t),oje=i(f),Ii=n(f,"H2",{class:!0});var nGe=s(Ii);D2=n(nGe,"A",{id:!0,class:!0,href:!0});var Bit=s(D2);Nce=n(Bit,"SPAN",{});var Iit=s(Nce);T(Ey.$$.fragment,Iit),Iit.forEach(t),Bit.forEach(t),qAo=i(nGe),qce=n(nGe,"SPAN",{});var Nit=s(qce);jAo=r(Nit,"AutoModelForMaskedLM"),Nit.forEach(t),nGe.forEach(t),rje=i(f),ko=n(f,"DIV",{class:!0});var Ws=s(ko);T(Cy.$$.fragment,Ws),DAo=i(Ws),Ni=n(Ws,"P",{});var VZ=s(Ni);GAo=r(VZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),vD=n(VZ,"A",{href:!0});var qit=s(vD);OAo=r(qit,"from_pretrained()"),qit.forEach(t),VAo=r(VZ," class method or the "),FD=n(VZ,"A",{href:!0});var jit=s(FD);XAo=r(jit,"from_config()"),jit.forEach(t),zAo=r(VZ,` class
method.`),VZ.forEach(t),WAo=i(Ws),wy=n(Ws,"P",{});var sGe=s(wy);QAo=r(sGe,"This class cannot be instantiated directly using "),jce=n(sGe,"CODE",{});var Dit=s(jce);HAo=r(Dit,"__init__()"),Dit.forEach(t),UAo=r(sGe," (throws an error)."),sGe.forEach(t),JAo=i(Ws),st=n(Ws,"DIV",{class:!0});var Ww=s(st);T(Ay.$$.fragment,Ww),YAo=i(Ww),Dce=n(Ww,"P",{});var Git=s(Dce);KAo=r(Git,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Git.forEach(t),ZAo=i(Ww),qi=n(Ww,"P",{});var XZ=s(qi);eyo=r(XZ,`Note:
Loading a model from its configuration file does `),Gce=n(XZ,"STRONG",{});var Oit=s(Gce);oyo=r(Oit,"not"),Oit.forEach(t),ryo=r(XZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),TD=n(XZ,"A",{href:!0});var Vit=s(TD);tyo=r(Vit,"from_pretrained()"),Vit.forEach(t),ayo=r(XZ," to load the model weights."),XZ.forEach(t),nyo=i(Ww),T(G2.$$.fragment,Ww),Ww.forEach(t),syo=i(Ws),Ze=n(Ws,"DIV",{class:!0});var aa=s(Ze);T(yy.$$.fragment,aa),lyo=i(aa),Oce=n(aa,"P",{});var Xit=s(Oce);iyo=r(Xit,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xit.forEach(t),dyo=i(aa),ka=n(aa,"P",{});var Qw=s(ka);cyo=r(Qw,"The model class to instantiate is selected based on the "),Vce=n(Qw,"CODE",{});var zit=s(Vce);fyo=r(zit,"model_type"),zit.forEach(t),myo=r(Qw,` property of the config object (either
passed as an argument or loaded from `),Xce=n(Qw,"CODE",{});var Wit=s(Xce);gyo=r(Wit,"pretrained_model_name_or_path"),Wit.forEach(t),hyo=r(Qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zce=n(Qw,"CODE",{});var Qit=s(zce);pyo=r(Qit,"pretrained_model_name_or_path"),Qit.forEach(t),_yo=r(Qw,":"),Qw.forEach(t),uyo=i(aa),W=n(aa,"UL",{});var H=s(W);O2=n(H,"LI",{});var N8e=s(O2);Wce=n(N8e,"STRONG",{});var Hit=s(Wce);byo=r(Hit,"albert"),Hit.forEach(t),vyo=r(N8e," \u2014 "),MD=n(N8e,"A",{href:!0});var Uit=s(MD);Fyo=r(Uit,"AlbertForMaskedLM"),Uit.forEach(t),Tyo=r(N8e," (ALBERT model)"),N8e.forEach(t),Myo=i(H),V2=n(H,"LI",{});var q8e=s(V2);Qce=n(q8e,"STRONG",{});var Jit=s(Qce);Eyo=r(Jit,"bart"),Jit.forEach(t),Cyo=r(q8e," \u2014 "),ED=n(q8e,"A",{href:!0});var Yit=s(ED);wyo=r(Yit,"BartForConditionalGeneration"),Yit.forEach(t),Ayo=r(q8e," (BART model)"),q8e.forEach(t),yyo=i(H),X2=n(H,"LI",{});var j8e=s(X2);Hce=n(j8e,"STRONG",{});var Kit=s(Hce);Lyo=r(Kit,"bert"),Kit.forEach(t),xyo=r(j8e," \u2014 "),CD=n(j8e,"A",{href:!0});var Zit=s(CD);$yo=r(Zit,"BertForMaskedLM"),Zit.forEach(t),kyo=r(j8e," (BERT model)"),j8e.forEach(t),Syo=i(H),z2=n(H,"LI",{});var D8e=s(z2);Uce=n(D8e,"STRONG",{});var edt=s(Uce);Ryo=r(edt,"big_bird"),edt.forEach(t),Pyo=r(D8e," \u2014 "),wD=n(D8e,"A",{href:!0});var odt=s(wD);Byo=r(odt,"BigBirdForMaskedLM"),odt.forEach(t),Iyo=r(D8e," (BigBird model)"),D8e.forEach(t),Nyo=i(H),W2=n(H,"LI",{});var G8e=s(W2);Jce=n(G8e,"STRONG",{});var rdt=s(Jce);qyo=r(rdt,"camembert"),rdt.forEach(t),jyo=r(G8e," \u2014 "),AD=n(G8e,"A",{href:!0});var tdt=s(AD);Dyo=r(tdt,"CamembertForMaskedLM"),tdt.forEach(t),Gyo=r(G8e," (CamemBERT model)"),G8e.forEach(t),Oyo=i(H),Q2=n(H,"LI",{});var O8e=s(Q2);Yce=n(O8e,"STRONG",{});var adt=s(Yce);Vyo=r(adt,"convbert"),adt.forEach(t),Xyo=r(O8e," \u2014 "),yD=n(O8e,"A",{href:!0});var ndt=s(yD);zyo=r(ndt,"ConvBertForMaskedLM"),ndt.forEach(t),Wyo=r(O8e," (ConvBERT model)"),O8e.forEach(t),Qyo=i(H),H2=n(H,"LI",{});var V8e=s(H2);Kce=n(V8e,"STRONG",{});var sdt=s(Kce);Hyo=r(sdt,"data2vec-text"),sdt.forEach(t),Uyo=r(V8e," \u2014 "),LD=n(V8e,"A",{href:!0});var ldt=s(LD);Jyo=r(ldt,"Data2VecTextForMaskedLM"),ldt.forEach(t),Yyo=r(V8e," (Data2VecText model)"),V8e.forEach(t),Kyo=i(H),U2=n(H,"LI",{});var X8e=s(U2);Zce=n(X8e,"STRONG",{});var idt=s(Zce);Zyo=r(idt,"deberta"),idt.forEach(t),eLo=r(X8e," \u2014 "),xD=n(X8e,"A",{href:!0});var ddt=s(xD);oLo=r(ddt,"DebertaForMaskedLM"),ddt.forEach(t),rLo=r(X8e," (DeBERTa model)"),X8e.forEach(t),tLo=i(H),J2=n(H,"LI",{});var z8e=s(J2);efe=n(z8e,"STRONG",{});var cdt=s(efe);aLo=r(cdt,"deberta-v2"),cdt.forEach(t),nLo=r(z8e," \u2014 "),$D=n(z8e,"A",{href:!0});var fdt=s($D);sLo=r(fdt,"DebertaV2ForMaskedLM"),fdt.forEach(t),lLo=r(z8e," (DeBERTa-v2 model)"),z8e.forEach(t),iLo=i(H),Y2=n(H,"LI",{});var W8e=s(Y2);ofe=n(W8e,"STRONG",{});var mdt=s(ofe);dLo=r(mdt,"distilbert"),mdt.forEach(t),cLo=r(W8e," \u2014 "),kD=n(W8e,"A",{href:!0});var gdt=s(kD);fLo=r(gdt,"DistilBertForMaskedLM"),gdt.forEach(t),mLo=r(W8e," (DistilBERT model)"),W8e.forEach(t),gLo=i(H),K2=n(H,"LI",{});var Q8e=s(K2);rfe=n(Q8e,"STRONG",{});var hdt=s(rfe);hLo=r(hdt,"electra"),hdt.forEach(t),pLo=r(Q8e," \u2014 "),SD=n(Q8e,"A",{href:!0});var pdt=s(SD);_Lo=r(pdt,"ElectraForMaskedLM"),pdt.forEach(t),uLo=r(Q8e," (ELECTRA model)"),Q8e.forEach(t),bLo=i(H),Z2=n(H,"LI",{});var H8e=s(Z2);tfe=n(H8e,"STRONG",{});var _dt=s(tfe);vLo=r(_dt,"flaubert"),_dt.forEach(t),FLo=r(H8e," \u2014 "),RD=n(H8e,"A",{href:!0});var udt=s(RD);TLo=r(udt,"FlaubertWithLMHeadModel"),udt.forEach(t),MLo=r(H8e," (FlauBERT model)"),H8e.forEach(t),ELo=i(H),e1=n(H,"LI",{});var U8e=s(e1);afe=n(U8e,"STRONG",{});var bdt=s(afe);CLo=r(bdt,"fnet"),bdt.forEach(t),wLo=r(U8e," \u2014 "),PD=n(U8e,"A",{href:!0});var vdt=s(PD);ALo=r(vdt,"FNetForMaskedLM"),vdt.forEach(t),yLo=r(U8e," (FNet model)"),U8e.forEach(t),LLo=i(H),o1=n(H,"LI",{});var J8e=s(o1);nfe=n(J8e,"STRONG",{});var Fdt=s(nfe);xLo=r(Fdt,"funnel"),Fdt.forEach(t),$Lo=r(J8e," \u2014 "),BD=n(J8e,"A",{href:!0});var Tdt=s(BD);kLo=r(Tdt,"FunnelForMaskedLM"),Tdt.forEach(t),SLo=r(J8e," (Funnel Transformer model)"),J8e.forEach(t),RLo=i(H),r1=n(H,"LI",{});var Y8e=s(r1);sfe=n(Y8e,"STRONG",{});var Mdt=s(sfe);PLo=r(Mdt,"ibert"),Mdt.forEach(t),BLo=r(Y8e," \u2014 "),ID=n(Y8e,"A",{href:!0});var Edt=s(ID);ILo=r(Edt,"IBertForMaskedLM"),Edt.forEach(t),NLo=r(Y8e," (I-BERT model)"),Y8e.forEach(t),qLo=i(H),t1=n(H,"LI",{});var K8e=s(t1);lfe=n(K8e,"STRONG",{});var Cdt=s(lfe);jLo=r(Cdt,"layoutlm"),Cdt.forEach(t),DLo=r(K8e," \u2014 "),ND=n(K8e,"A",{href:!0});var wdt=s(ND);GLo=r(wdt,"LayoutLMForMaskedLM"),wdt.forEach(t),OLo=r(K8e," (LayoutLM model)"),K8e.forEach(t),VLo=i(H),a1=n(H,"LI",{});var Z8e=s(a1);ife=n(Z8e,"STRONG",{});var Adt=s(ife);XLo=r(Adt,"longformer"),Adt.forEach(t),zLo=r(Z8e," \u2014 "),qD=n(Z8e,"A",{href:!0});var ydt=s(qD);WLo=r(ydt,"LongformerForMaskedLM"),ydt.forEach(t),QLo=r(Z8e," (Longformer model)"),Z8e.forEach(t),HLo=i(H),n1=n(H,"LI",{});var e9e=s(n1);dfe=n(e9e,"STRONG",{});var Ldt=s(dfe);ULo=r(Ldt,"luke"),Ldt.forEach(t),JLo=r(e9e," \u2014 "),jD=n(e9e,"A",{href:!0});var xdt=s(jD);YLo=r(xdt,"LukeForMaskedLM"),xdt.forEach(t),KLo=r(e9e," (LUKE model)"),e9e.forEach(t),ZLo=i(H),s1=n(H,"LI",{});var o9e=s(s1);cfe=n(o9e,"STRONG",{});var $dt=s(cfe);e8o=r($dt,"mbart"),$dt.forEach(t),o8o=r(o9e," \u2014 "),DD=n(o9e,"A",{href:!0});var kdt=s(DD);r8o=r(kdt,"MBartForConditionalGeneration"),kdt.forEach(t),t8o=r(o9e," (mBART model)"),o9e.forEach(t),a8o=i(H),l1=n(H,"LI",{});var r9e=s(l1);ffe=n(r9e,"STRONG",{});var Sdt=s(ffe);n8o=r(Sdt,"megatron-bert"),Sdt.forEach(t),s8o=r(r9e," \u2014 "),GD=n(r9e,"A",{href:!0});var Rdt=s(GD);l8o=r(Rdt,"MegatronBertForMaskedLM"),Rdt.forEach(t),i8o=r(r9e," (MegatronBert model)"),r9e.forEach(t),d8o=i(H),i1=n(H,"LI",{});var t9e=s(i1);mfe=n(t9e,"STRONG",{});var Pdt=s(mfe);c8o=r(Pdt,"mobilebert"),Pdt.forEach(t),f8o=r(t9e," \u2014 "),OD=n(t9e,"A",{href:!0});var Bdt=s(OD);m8o=r(Bdt,"MobileBertForMaskedLM"),Bdt.forEach(t),g8o=r(t9e," (MobileBERT model)"),t9e.forEach(t),h8o=i(H),d1=n(H,"LI",{});var a9e=s(d1);gfe=n(a9e,"STRONG",{});var Idt=s(gfe);p8o=r(Idt,"mpnet"),Idt.forEach(t),_8o=r(a9e," \u2014 "),VD=n(a9e,"A",{href:!0});var Ndt=s(VD);u8o=r(Ndt,"MPNetForMaskedLM"),Ndt.forEach(t),b8o=r(a9e," (MPNet model)"),a9e.forEach(t),v8o=i(H),c1=n(H,"LI",{});var n9e=s(c1);hfe=n(n9e,"STRONG",{});var qdt=s(hfe);F8o=r(qdt,"nystromformer"),qdt.forEach(t),T8o=r(n9e," \u2014 "),XD=n(n9e,"A",{href:!0});var jdt=s(XD);M8o=r(jdt,"NystromformerForMaskedLM"),jdt.forEach(t),E8o=r(n9e," (Nystromformer model)"),n9e.forEach(t),C8o=i(H),f1=n(H,"LI",{});var s9e=s(f1);pfe=n(s9e,"STRONG",{});var Ddt=s(pfe);w8o=r(Ddt,"perceiver"),Ddt.forEach(t),A8o=r(s9e," \u2014 "),zD=n(s9e,"A",{href:!0});var Gdt=s(zD);y8o=r(Gdt,"PerceiverForMaskedLM"),Gdt.forEach(t),L8o=r(s9e," (Perceiver model)"),s9e.forEach(t),x8o=i(H),m1=n(H,"LI",{});var l9e=s(m1);_fe=n(l9e,"STRONG",{});var Odt=s(_fe);$8o=r(Odt,"qdqbert"),Odt.forEach(t),k8o=r(l9e," \u2014 "),WD=n(l9e,"A",{href:!0});var Vdt=s(WD);S8o=r(Vdt,"QDQBertForMaskedLM"),Vdt.forEach(t),R8o=r(l9e," (QDQBert model)"),l9e.forEach(t),P8o=i(H),g1=n(H,"LI",{});var i9e=s(g1);ufe=n(i9e,"STRONG",{});var Xdt=s(ufe);B8o=r(Xdt,"reformer"),Xdt.forEach(t),I8o=r(i9e," \u2014 "),QD=n(i9e,"A",{href:!0});var zdt=s(QD);N8o=r(zdt,"ReformerForMaskedLM"),zdt.forEach(t),q8o=r(i9e," (Reformer model)"),i9e.forEach(t),j8o=i(H),h1=n(H,"LI",{});var d9e=s(h1);bfe=n(d9e,"STRONG",{});var Wdt=s(bfe);D8o=r(Wdt,"rembert"),Wdt.forEach(t),G8o=r(d9e," \u2014 "),HD=n(d9e,"A",{href:!0});var Qdt=s(HD);O8o=r(Qdt,"RemBertForMaskedLM"),Qdt.forEach(t),V8o=r(d9e," (RemBERT model)"),d9e.forEach(t),X8o=i(H),p1=n(H,"LI",{});var c9e=s(p1);vfe=n(c9e,"STRONG",{});var Hdt=s(vfe);z8o=r(Hdt,"roberta"),Hdt.forEach(t),W8o=r(c9e," \u2014 "),UD=n(c9e,"A",{href:!0});var Udt=s(UD);Q8o=r(Udt,"RobertaForMaskedLM"),Udt.forEach(t),H8o=r(c9e," (RoBERTa model)"),c9e.forEach(t),U8o=i(H),_1=n(H,"LI",{});var f9e=s(_1);Ffe=n(f9e,"STRONG",{});var Jdt=s(Ffe);J8o=r(Jdt,"roformer"),Jdt.forEach(t),Y8o=r(f9e," \u2014 "),JD=n(f9e,"A",{href:!0});var Ydt=s(JD);K8o=r(Ydt,"RoFormerForMaskedLM"),Ydt.forEach(t),Z8o=r(f9e," (RoFormer model)"),f9e.forEach(t),e9o=i(H),u1=n(H,"LI",{});var m9e=s(u1);Tfe=n(m9e,"STRONG",{});var Kdt=s(Tfe);o9o=r(Kdt,"squeezebert"),Kdt.forEach(t),r9o=r(m9e," \u2014 "),YD=n(m9e,"A",{href:!0});var Zdt=s(YD);t9o=r(Zdt,"SqueezeBertForMaskedLM"),Zdt.forEach(t),a9o=r(m9e," (SqueezeBERT model)"),m9e.forEach(t),n9o=i(H),b1=n(H,"LI",{});var g9e=s(b1);Mfe=n(g9e,"STRONG",{});var ect=s(Mfe);s9o=r(ect,"tapas"),ect.forEach(t),l9o=r(g9e," \u2014 "),KD=n(g9e,"A",{href:!0});var oct=s(KD);i9o=r(oct,"TapasForMaskedLM"),oct.forEach(t),d9o=r(g9e," (TAPAS model)"),g9e.forEach(t),c9o=i(H),v1=n(H,"LI",{});var h9e=s(v1);Efe=n(h9e,"STRONG",{});var rct=s(Efe);f9o=r(rct,"wav2vec2"),rct.forEach(t),m9o=r(h9e," \u2014 "),Cfe=n(h9e,"CODE",{});var tct=s(Cfe);g9o=r(tct,"Wav2Vec2ForMaskedLM"),tct.forEach(t),h9o=r(h9e," (Wav2Vec2 model)"),h9e.forEach(t),p9o=i(H),F1=n(H,"LI",{});var p9e=s(F1);wfe=n(p9e,"STRONG",{});var act=s(wfe);_9o=r(act,"xlm"),act.forEach(t),u9o=r(p9e," \u2014 "),ZD=n(p9e,"A",{href:!0});var nct=s(ZD);b9o=r(nct,"XLMWithLMHeadModel"),nct.forEach(t),v9o=r(p9e," (XLM model)"),p9e.forEach(t),F9o=i(H),T1=n(H,"LI",{});var _9e=s(T1);Afe=n(_9e,"STRONG",{});var sct=s(Afe);T9o=r(sct,"xlm-roberta"),sct.forEach(t),M9o=r(_9e," \u2014 "),eG=n(_9e,"A",{href:!0});var lct=s(eG);E9o=r(lct,"XLMRobertaForMaskedLM"),lct.forEach(t),C9o=r(_9e," (XLM-RoBERTa model)"),_9e.forEach(t),w9o=i(H),M1=n(H,"LI",{});var u9e=s(M1);yfe=n(u9e,"STRONG",{});var ict=s(yfe);A9o=r(ict,"xlm-roberta-xl"),ict.forEach(t),y9o=r(u9e," \u2014 "),oG=n(u9e,"A",{href:!0});var dct=s(oG);L9o=r(dct,"XLMRobertaXLForMaskedLM"),dct.forEach(t),x9o=r(u9e," (XLM-RoBERTa-XL model)"),u9e.forEach(t),$9o=i(H),E1=n(H,"LI",{});var b9e=s(E1);Lfe=n(b9e,"STRONG",{});var cct=s(Lfe);k9o=r(cct,"yoso"),cct.forEach(t),S9o=r(b9e," \u2014 "),rG=n(b9e,"A",{href:!0});var fct=s(rG);R9o=r(fct,"YosoForMaskedLM"),fct.forEach(t),P9o=r(b9e," (YOSO model)"),b9e.forEach(t),H.forEach(t),B9o=i(aa),C1=n(aa,"P",{});var v9e=s(C1);I9o=r(v9e,"The model is set in evaluation mode by default using "),xfe=n(v9e,"CODE",{});var mct=s(xfe);N9o=r(mct,"model.eval()"),mct.forEach(t),q9o=r(v9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$fe=n(v9e,"CODE",{});var gct=s($fe);j9o=r(gct,"model.train()"),gct.forEach(t),v9e.forEach(t),D9o=i(aa),T(w1.$$.fragment,aa),aa.forEach(t),Ws.forEach(t),tje=i(f),ji=n(f,"H2",{class:!0});var lGe=s(ji);A1=n(lGe,"A",{id:!0,class:!0,href:!0});var hct=s(A1);kfe=n(hct,"SPAN",{});var pct=s(kfe);T(Ly.$$.fragment,pct),pct.forEach(t),hct.forEach(t),G9o=i(lGe),Sfe=n(lGe,"SPAN",{});var _ct=s(Sfe);O9o=r(_ct,"AutoModelForSeq2SeqLM"),_ct.forEach(t),lGe.forEach(t),aje=i(f),So=n(f,"DIV",{class:!0});var Qs=s(So);T(xy.$$.fragment,Qs),V9o=i(Qs),Di=n(Qs,"P",{});var zZ=s(Di);X9o=r(zZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tG=n(zZ,"A",{href:!0});var uct=s(tG);z9o=r(uct,"from_pretrained()"),uct.forEach(t),W9o=r(zZ," class method or the "),aG=n(zZ,"A",{href:!0});var bct=s(aG);Q9o=r(bct,"from_config()"),bct.forEach(t),H9o=r(zZ,` class
method.`),zZ.forEach(t),U9o=i(Qs),$y=n(Qs,"P",{});var iGe=s($y);J9o=r(iGe,"This class cannot be instantiated directly using "),Rfe=n(iGe,"CODE",{});var vct=s(Rfe);Y9o=r(vct,"__init__()"),vct.forEach(t),K9o=r(iGe," (throws an error)."),iGe.forEach(t),Z9o=i(Qs),lt=n(Qs,"DIV",{class:!0});var Hw=s(lt);T(ky.$$.fragment,Hw),exo=i(Hw),Pfe=n(Hw,"P",{});var Fct=s(Pfe);oxo=r(Fct,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Fct.forEach(t),rxo=i(Hw),Gi=n(Hw,"P",{});var WZ=s(Gi);txo=r(WZ,`Note:
Loading a model from its configuration file does `),Bfe=n(WZ,"STRONG",{});var Tct=s(Bfe);axo=r(Tct,"not"),Tct.forEach(t),nxo=r(WZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),nG=n(WZ,"A",{href:!0});var Mct=s(nG);sxo=r(Mct,"from_pretrained()"),Mct.forEach(t),lxo=r(WZ," to load the model weights."),WZ.forEach(t),ixo=i(Hw),T(y1.$$.fragment,Hw),Hw.forEach(t),dxo=i(Qs),eo=n(Qs,"DIV",{class:!0});var na=s(eo);T(Sy.$$.fragment,na),cxo=i(na),Ife=n(na,"P",{});var Ect=s(Ife);fxo=r(Ect,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ect.forEach(t),mxo=i(na),Sa=n(na,"P",{});var Uw=s(Sa);gxo=r(Uw,"The model class to instantiate is selected based on the "),Nfe=n(Uw,"CODE",{});var Cct=s(Nfe);hxo=r(Cct,"model_type"),Cct.forEach(t),pxo=r(Uw,` property of the config object (either
passed as an argument or loaded from `),qfe=n(Uw,"CODE",{});var wct=s(qfe);_xo=r(wct,"pretrained_model_name_or_path"),wct.forEach(t),uxo=r(Uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jfe=n(Uw,"CODE",{});var Act=s(jfe);bxo=r(Act,"pretrained_model_name_or_path"),Act.forEach(t),vxo=r(Uw,":"),Uw.forEach(t),Fxo=i(na),_e=n(na,"UL",{});var Fe=s(_e);L1=n(Fe,"LI",{});var F9e=s(L1);Dfe=n(F9e,"STRONG",{});var yct=s(Dfe);Txo=r(yct,"bart"),yct.forEach(t),Mxo=r(F9e," \u2014 "),sG=n(F9e,"A",{href:!0});var Lct=s(sG);Exo=r(Lct,"BartForConditionalGeneration"),Lct.forEach(t),Cxo=r(F9e," (BART model)"),F9e.forEach(t),wxo=i(Fe),x1=n(Fe,"LI",{});var T9e=s(x1);Gfe=n(T9e,"STRONG",{});var xct=s(Gfe);Axo=r(xct,"bigbird_pegasus"),xct.forEach(t),yxo=r(T9e," \u2014 "),lG=n(T9e,"A",{href:!0});var $ct=s(lG);Lxo=r($ct,"BigBirdPegasusForConditionalGeneration"),$ct.forEach(t),xxo=r(T9e," (BigBirdPegasus model)"),T9e.forEach(t),$xo=i(Fe),$1=n(Fe,"LI",{});var M9e=s($1);Ofe=n(M9e,"STRONG",{});var kct=s(Ofe);kxo=r(kct,"blenderbot"),kct.forEach(t),Sxo=r(M9e," \u2014 "),iG=n(M9e,"A",{href:!0});var Sct=s(iG);Rxo=r(Sct,"BlenderbotForConditionalGeneration"),Sct.forEach(t),Pxo=r(M9e," (Blenderbot model)"),M9e.forEach(t),Bxo=i(Fe),k1=n(Fe,"LI",{});var E9e=s(k1);Vfe=n(E9e,"STRONG",{});var Rct=s(Vfe);Ixo=r(Rct,"blenderbot-small"),Rct.forEach(t),Nxo=r(E9e," \u2014 "),dG=n(E9e,"A",{href:!0});var Pct=s(dG);qxo=r(Pct,"BlenderbotSmallForConditionalGeneration"),Pct.forEach(t),jxo=r(E9e," (BlenderbotSmall model)"),E9e.forEach(t),Dxo=i(Fe),S1=n(Fe,"LI",{});var C9e=s(S1);Xfe=n(C9e,"STRONG",{});var Bct=s(Xfe);Gxo=r(Bct,"encoder-decoder"),Bct.forEach(t),Oxo=r(C9e," \u2014 "),cG=n(C9e,"A",{href:!0});var Ict=s(cG);Vxo=r(Ict,"EncoderDecoderModel"),Ict.forEach(t),Xxo=r(C9e," (Encoder decoder model)"),C9e.forEach(t),zxo=i(Fe),R1=n(Fe,"LI",{});var w9e=s(R1);zfe=n(w9e,"STRONG",{});var Nct=s(zfe);Wxo=r(Nct,"fsmt"),Nct.forEach(t),Qxo=r(w9e," \u2014 "),fG=n(w9e,"A",{href:!0});var qct=s(fG);Hxo=r(qct,"FSMTForConditionalGeneration"),qct.forEach(t),Uxo=r(w9e," (FairSeq Machine-Translation model)"),w9e.forEach(t),Jxo=i(Fe),P1=n(Fe,"LI",{});var A9e=s(P1);Wfe=n(A9e,"STRONG",{});var jct=s(Wfe);Yxo=r(jct,"led"),jct.forEach(t),Kxo=r(A9e," \u2014 "),mG=n(A9e,"A",{href:!0});var Dct=s(mG);Zxo=r(Dct,"LEDForConditionalGeneration"),Dct.forEach(t),e$o=r(A9e," (LED model)"),A9e.forEach(t),o$o=i(Fe),B1=n(Fe,"LI",{});var y9e=s(B1);Qfe=n(y9e,"STRONG",{});var Gct=s(Qfe);r$o=r(Gct,"m2m_100"),Gct.forEach(t),t$o=r(y9e," \u2014 "),gG=n(y9e,"A",{href:!0});var Oct=s(gG);a$o=r(Oct,"M2M100ForConditionalGeneration"),Oct.forEach(t),n$o=r(y9e," (M2M100 model)"),y9e.forEach(t),s$o=i(Fe),I1=n(Fe,"LI",{});var L9e=s(I1);Hfe=n(L9e,"STRONG",{});var Vct=s(Hfe);l$o=r(Vct,"marian"),Vct.forEach(t),i$o=r(L9e," \u2014 "),hG=n(L9e,"A",{href:!0});var Xct=s(hG);d$o=r(Xct,"MarianMTModel"),Xct.forEach(t),c$o=r(L9e," (Marian model)"),L9e.forEach(t),f$o=i(Fe),N1=n(Fe,"LI",{});var x9e=s(N1);Ufe=n(x9e,"STRONG",{});var zct=s(Ufe);m$o=r(zct,"mbart"),zct.forEach(t),g$o=r(x9e," \u2014 "),pG=n(x9e,"A",{href:!0});var Wct=s(pG);h$o=r(Wct,"MBartForConditionalGeneration"),Wct.forEach(t),p$o=r(x9e," (mBART model)"),x9e.forEach(t),_$o=i(Fe),q1=n(Fe,"LI",{});var $9e=s(q1);Jfe=n($9e,"STRONG",{});var Qct=s(Jfe);u$o=r(Qct,"mt5"),Qct.forEach(t),b$o=r($9e," \u2014 "),_G=n($9e,"A",{href:!0});var Hct=s(_G);v$o=r(Hct,"MT5ForConditionalGeneration"),Hct.forEach(t),F$o=r($9e," (mT5 model)"),$9e.forEach(t),T$o=i(Fe),j1=n(Fe,"LI",{});var k9e=s(j1);Yfe=n(k9e,"STRONG",{});var Uct=s(Yfe);M$o=r(Uct,"pegasus"),Uct.forEach(t),E$o=r(k9e," \u2014 "),uG=n(k9e,"A",{href:!0});var Jct=s(uG);C$o=r(Jct,"PegasusForConditionalGeneration"),Jct.forEach(t),w$o=r(k9e," (Pegasus model)"),k9e.forEach(t),A$o=i(Fe),D1=n(Fe,"LI",{});var S9e=s(D1);Kfe=n(S9e,"STRONG",{});var Yct=s(Kfe);y$o=r(Yct,"plbart"),Yct.forEach(t),L$o=r(S9e," \u2014 "),bG=n(S9e,"A",{href:!0});var Kct=s(bG);x$o=r(Kct,"PLBartForConditionalGeneration"),Kct.forEach(t),$$o=r(S9e," (PLBart model)"),S9e.forEach(t),k$o=i(Fe),G1=n(Fe,"LI",{});var R9e=s(G1);Zfe=n(R9e,"STRONG",{});var Zct=s(Zfe);S$o=r(Zct,"prophetnet"),Zct.forEach(t),R$o=r(R9e," \u2014 "),vG=n(R9e,"A",{href:!0});var eft=s(vG);P$o=r(eft,"ProphetNetForConditionalGeneration"),eft.forEach(t),B$o=r(R9e," (ProphetNet model)"),R9e.forEach(t),I$o=i(Fe),O1=n(Fe,"LI",{});var P9e=s(O1);eme=n(P9e,"STRONG",{});var oft=s(eme);N$o=r(oft,"t5"),oft.forEach(t),q$o=r(P9e," \u2014 "),FG=n(P9e,"A",{href:!0});var rft=s(FG);j$o=r(rft,"T5ForConditionalGeneration"),rft.forEach(t),D$o=r(P9e," (T5 model)"),P9e.forEach(t),G$o=i(Fe),V1=n(Fe,"LI",{});var B9e=s(V1);ome=n(B9e,"STRONG",{});var tft=s(ome);O$o=r(tft,"xlm-prophetnet"),tft.forEach(t),V$o=r(B9e," \u2014 "),TG=n(B9e,"A",{href:!0});var aft=s(TG);X$o=r(aft,"XLMProphetNetForConditionalGeneration"),aft.forEach(t),z$o=r(B9e," (XLMProphetNet model)"),B9e.forEach(t),Fe.forEach(t),W$o=i(na),X1=n(na,"P",{});var I9e=s(X1);Q$o=r(I9e,"The model is set in evaluation mode by default using "),rme=n(I9e,"CODE",{});var nft=s(rme);H$o=r(nft,"model.eval()"),nft.forEach(t),U$o=r(I9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tme=n(I9e,"CODE",{});var sft=s(tme);J$o=r(sft,"model.train()"),sft.forEach(t),I9e.forEach(t),Y$o=i(na),T(z1.$$.fragment,na),na.forEach(t),Qs.forEach(t),nje=i(f),Oi=n(f,"H2",{class:!0});var dGe=s(Oi);W1=n(dGe,"A",{id:!0,class:!0,href:!0});var lft=s(W1);ame=n(lft,"SPAN",{});var ift=s(ame);T(Ry.$$.fragment,ift),ift.forEach(t),lft.forEach(t),K$o=i(dGe),nme=n(dGe,"SPAN",{});var dft=s(nme);Z$o=r(dft,"AutoModelForSequenceClassification"),dft.forEach(t),dGe.forEach(t),sje=i(f),Ro=n(f,"DIV",{class:!0});var Hs=s(Ro);T(Py.$$.fragment,Hs),eko=i(Hs),Vi=n(Hs,"P",{});var QZ=s(Vi);oko=r(QZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),MG=n(QZ,"A",{href:!0});var cft=s(MG);rko=r(cft,"from_pretrained()"),cft.forEach(t),tko=r(QZ," class method or the "),EG=n(QZ,"A",{href:!0});var fft=s(EG);ako=r(fft,"from_config()"),fft.forEach(t),nko=r(QZ,` class
method.`),QZ.forEach(t),sko=i(Hs),By=n(Hs,"P",{});var cGe=s(By);lko=r(cGe,"This class cannot be instantiated directly using "),sme=n(cGe,"CODE",{});var mft=s(sme);iko=r(mft,"__init__()"),mft.forEach(t),dko=r(cGe," (throws an error)."),cGe.forEach(t),cko=i(Hs),it=n(Hs,"DIV",{class:!0});var Jw=s(it);T(Iy.$$.fragment,Jw),fko=i(Jw),lme=n(Jw,"P",{});var gft=s(lme);mko=r(gft,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),gft.forEach(t),gko=i(Jw),Xi=n(Jw,"P",{});var HZ=s(Xi);hko=r(HZ,`Note:
Loading a model from its configuration file does `),ime=n(HZ,"STRONG",{});var hft=s(ime);pko=r(hft,"not"),hft.forEach(t),_ko=r(HZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),CG=n(HZ,"A",{href:!0});var pft=s(CG);uko=r(pft,"from_pretrained()"),pft.forEach(t),bko=r(HZ," to load the model weights."),HZ.forEach(t),vko=i(Jw),T(Q1.$$.fragment,Jw),Jw.forEach(t),Fko=i(Hs),oo=n(Hs,"DIV",{class:!0});var sa=s(oo);T(Ny.$$.fragment,sa),Tko=i(sa),dme=n(sa,"P",{});var _ft=s(dme);Mko=r(_ft,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_ft.forEach(t),Eko=i(sa),Ra=n(sa,"P",{});var Yw=s(Ra);Cko=r(Yw,"The model class to instantiate is selected based on the "),cme=n(Yw,"CODE",{});var uft=s(cme);wko=r(uft,"model_type"),uft.forEach(t),Ako=r(Yw,` property of the config object (either
passed as an argument or loaded from `),fme=n(Yw,"CODE",{});var bft=s(fme);yko=r(bft,"pretrained_model_name_or_path"),bft.forEach(t),Lko=r(Yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mme=n(Yw,"CODE",{});var vft=s(mme);xko=r(vft,"pretrained_model_name_or_path"),vft.forEach(t),$ko=r(Yw,":"),Yw.forEach(t),kko=i(sa),N=n(sa,"UL",{});var j=s(N);H1=n(j,"LI",{});var N9e=s(H1);gme=n(N9e,"STRONG",{});var Fft=s(gme);Sko=r(Fft,"albert"),Fft.forEach(t),Rko=r(N9e," \u2014 "),wG=n(N9e,"A",{href:!0});var Tft=s(wG);Pko=r(Tft,"AlbertForSequenceClassification"),Tft.forEach(t),Bko=r(N9e," (ALBERT model)"),N9e.forEach(t),Iko=i(j),U1=n(j,"LI",{});var q9e=s(U1);hme=n(q9e,"STRONG",{});var Mft=s(hme);Nko=r(Mft,"bart"),Mft.forEach(t),qko=r(q9e," \u2014 "),AG=n(q9e,"A",{href:!0});var Eft=s(AG);jko=r(Eft,"BartForSequenceClassification"),Eft.forEach(t),Dko=r(q9e," (BART model)"),q9e.forEach(t),Gko=i(j),J1=n(j,"LI",{});var j9e=s(J1);pme=n(j9e,"STRONG",{});var Cft=s(pme);Oko=r(Cft,"bert"),Cft.forEach(t),Vko=r(j9e," \u2014 "),yG=n(j9e,"A",{href:!0});var wft=s(yG);Xko=r(wft,"BertForSequenceClassification"),wft.forEach(t),zko=r(j9e," (BERT model)"),j9e.forEach(t),Wko=i(j),Y1=n(j,"LI",{});var D9e=s(Y1);_me=n(D9e,"STRONG",{});var Aft=s(_me);Qko=r(Aft,"big_bird"),Aft.forEach(t),Hko=r(D9e," \u2014 "),LG=n(D9e,"A",{href:!0});var yft=s(LG);Uko=r(yft,"BigBirdForSequenceClassification"),yft.forEach(t),Jko=r(D9e," (BigBird model)"),D9e.forEach(t),Yko=i(j),K1=n(j,"LI",{});var G9e=s(K1);ume=n(G9e,"STRONG",{});var Lft=s(ume);Kko=r(Lft,"bigbird_pegasus"),Lft.forEach(t),Zko=r(G9e," \u2014 "),xG=n(G9e,"A",{href:!0});var xft=s(xG);eSo=r(xft,"BigBirdPegasusForSequenceClassification"),xft.forEach(t),oSo=r(G9e," (BigBirdPegasus model)"),G9e.forEach(t),rSo=i(j),Z1=n(j,"LI",{});var O9e=s(Z1);bme=n(O9e,"STRONG",{});var $ft=s(bme);tSo=r($ft,"camembert"),$ft.forEach(t),aSo=r(O9e," \u2014 "),$G=n(O9e,"A",{href:!0});var kft=s($G);nSo=r(kft,"CamembertForSequenceClassification"),kft.forEach(t),sSo=r(O9e," (CamemBERT model)"),O9e.forEach(t),lSo=i(j),eb=n(j,"LI",{});var V9e=s(eb);vme=n(V9e,"STRONG",{});var Sft=s(vme);iSo=r(Sft,"canine"),Sft.forEach(t),dSo=r(V9e," \u2014 "),kG=n(V9e,"A",{href:!0});var Rft=s(kG);cSo=r(Rft,"CanineForSequenceClassification"),Rft.forEach(t),fSo=r(V9e," (Canine model)"),V9e.forEach(t),mSo=i(j),ob=n(j,"LI",{});var X9e=s(ob);Fme=n(X9e,"STRONG",{});var Pft=s(Fme);gSo=r(Pft,"convbert"),Pft.forEach(t),hSo=r(X9e," \u2014 "),SG=n(X9e,"A",{href:!0});var Bft=s(SG);pSo=r(Bft,"ConvBertForSequenceClassification"),Bft.forEach(t),_So=r(X9e," (ConvBERT model)"),X9e.forEach(t),uSo=i(j),rb=n(j,"LI",{});var z9e=s(rb);Tme=n(z9e,"STRONG",{});var Ift=s(Tme);bSo=r(Ift,"ctrl"),Ift.forEach(t),vSo=r(z9e," \u2014 "),RG=n(z9e,"A",{href:!0});var Nft=s(RG);FSo=r(Nft,"CTRLForSequenceClassification"),Nft.forEach(t),TSo=r(z9e," (CTRL model)"),z9e.forEach(t),MSo=i(j),tb=n(j,"LI",{});var W9e=s(tb);Mme=n(W9e,"STRONG",{});var qft=s(Mme);ESo=r(qft,"data2vec-text"),qft.forEach(t),CSo=r(W9e," \u2014 "),PG=n(W9e,"A",{href:!0});var jft=s(PG);wSo=r(jft,"Data2VecTextForSequenceClassification"),jft.forEach(t),ASo=r(W9e," (Data2VecText model)"),W9e.forEach(t),ySo=i(j),ab=n(j,"LI",{});var Q9e=s(ab);Eme=n(Q9e,"STRONG",{});var Dft=s(Eme);LSo=r(Dft,"deberta"),Dft.forEach(t),xSo=r(Q9e," \u2014 "),BG=n(Q9e,"A",{href:!0});var Gft=s(BG);$So=r(Gft,"DebertaForSequenceClassification"),Gft.forEach(t),kSo=r(Q9e," (DeBERTa model)"),Q9e.forEach(t),SSo=i(j),nb=n(j,"LI",{});var H9e=s(nb);Cme=n(H9e,"STRONG",{});var Oft=s(Cme);RSo=r(Oft,"deberta-v2"),Oft.forEach(t),PSo=r(H9e," \u2014 "),IG=n(H9e,"A",{href:!0});var Vft=s(IG);BSo=r(Vft,"DebertaV2ForSequenceClassification"),Vft.forEach(t),ISo=r(H9e," (DeBERTa-v2 model)"),H9e.forEach(t),NSo=i(j),sb=n(j,"LI",{});var U9e=s(sb);wme=n(U9e,"STRONG",{});var Xft=s(wme);qSo=r(Xft,"distilbert"),Xft.forEach(t),jSo=r(U9e," \u2014 "),NG=n(U9e,"A",{href:!0});var zft=s(NG);DSo=r(zft,"DistilBertForSequenceClassification"),zft.forEach(t),GSo=r(U9e," (DistilBERT model)"),U9e.forEach(t),OSo=i(j),lb=n(j,"LI",{});var J9e=s(lb);Ame=n(J9e,"STRONG",{});var Wft=s(Ame);VSo=r(Wft,"electra"),Wft.forEach(t),XSo=r(J9e," \u2014 "),qG=n(J9e,"A",{href:!0});var Qft=s(qG);zSo=r(Qft,"ElectraForSequenceClassification"),Qft.forEach(t),WSo=r(J9e," (ELECTRA model)"),J9e.forEach(t),QSo=i(j),ib=n(j,"LI",{});var Y9e=s(ib);yme=n(Y9e,"STRONG",{});var Hft=s(yme);HSo=r(Hft,"flaubert"),Hft.forEach(t),USo=r(Y9e," \u2014 "),jG=n(Y9e,"A",{href:!0});var Uft=s(jG);JSo=r(Uft,"FlaubertForSequenceClassification"),Uft.forEach(t),YSo=r(Y9e," (FlauBERT model)"),Y9e.forEach(t),KSo=i(j),db=n(j,"LI",{});var K9e=s(db);Lme=n(K9e,"STRONG",{});var Jft=s(Lme);ZSo=r(Jft,"fnet"),Jft.forEach(t),eRo=r(K9e," \u2014 "),DG=n(K9e,"A",{href:!0});var Yft=s(DG);oRo=r(Yft,"FNetForSequenceClassification"),Yft.forEach(t),rRo=r(K9e," (FNet model)"),K9e.forEach(t),tRo=i(j),cb=n(j,"LI",{});var Z9e=s(cb);xme=n(Z9e,"STRONG",{});var Kft=s(xme);aRo=r(Kft,"funnel"),Kft.forEach(t),nRo=r(Z9e," \u2014 "),GG=n(Z9e,"A",{href:!0});var Zft=s(GG);sRo=r(Zft,"FunnelForSequenceClassification"),Zft.forEach(t),lRo=r(Z9e," (Funnel Transformer model)"),Z9e.forEach(t),iRo=i(j),fb=n(j,"LI",{});var exe=s(fb);$me=n(exe,"STRONG",{});var emt=s($me);dRo=r(emt,"gpt2"),emt.forEach(t),cRo=r(exe," \u2014 "),OG=n(exe,"A",{href:!0});var omt=s(OG);fRo=r(omt,"GPT2ForSequenceClassification"),omt.forEach(t),mRo=r(exe," (OpenAI GPT-2 model)"),exe.forEach(t),gRo=i(j),mb=n(j,"LI",{});var oxe=s(mb);kme=n(oxe,"STRONG",{});var rmt=s(kme);hRo=r(rmt,"gpt_neo"),rmt.forEach(t),pRo=r(oxe," \u2014 "),VG=n(oxe,"A",{href:!0});var tmt=s(VG);_Ro=r(tmt,"GPTNeoForSequenceClassification"),tmt.forEach(t),uRo=r(oxe," (GPT Neo model)"),oxe.forEach(t),bRo=i(j),gb=n(j,"LI",{});var rxe=s(gb);Sme=n(rxe,"STRONG",{});var amt=s(Sme);vRo=r(amt,"gptj"),amt.forEach(t),FRo=r(rxe," \u2014 "),XG=n(rxe,"A",{href:!0});var nmt=s(XG);TRo=r(nmt,"GPTJForSequenceClassification"),nmt.forEach(t),MRo=r(rxe," (GPT-J model)"),rxe.forEach(t),ERo=i(j),hb=n(j,"LI",{});var txe=s(hb);Rme=n(txe,"STRONG",{});var smt=s(Rme);CRo=r(smt,"ibert"),smt.forEach(t),wRo=r(txe," \u2014 "),zG=n(txe,"A",{href:!0});var lmt=s(zG);ARo=r(lmt,"IBertForSequenceClassification"),lmt.forEach(t),yRo=r(txe," (I-BERT model)"),txe.forEach(t),LRo=i(j),pb=n(j,"LI",{});var axe=s(pb);Pme=n(axe,"STRONG",{});var imt=s(Pme);xRo=r(imt,"layoutlm"),imt.forEach(t),$Ro=r(axe," \u2014 "),WG=n(axe,"A",{href:!0});var dmt=s(WG);kRo=r(dmt,"LayoutLMForSequenceClassification"),dmt.forEach(t),SRo=r(axe," (LayoutLM model)"),axe.forEach(t),RRo=i(j),_b=n(j,"LI",{});var nxe=s(_b);Bme=n(nxe,"STRONG",{});var cmt=s(Bme);PRo=r(cmt,"layoutlmv2"),cmt.forEach(t),BRo=r(nxe," \u2014 "),QG=n(nxe,"A",{href:!0});var fmt=s(QG);IRo=r(fmt,"LayoutLMv2ForSequenceClassification"),fmt.forEach(t),NRo=r(nxe," (LayoutLMv2 model)"),nxe.forEach(t),qRo=i(j),ub=n(j,"LI",{});var sxe=s(ub);Ime=n(sxe,"STRONG",{});var mmt=s(Ime);jRo=r(mmt,"layoutlmv3"),mmt.forEach(t),DRo=r(sxe," \u2014 "),HG=n(sxe,"A",{href:!0});var gmt=s(HG);GRo=r(gmt,"LayoutLMv3ForSequenceClassification"),gmt.forEach(t),ORo=r(sxe," (LayoutLMv3 model)"),sxe.forEach(t),VRo=i(j),bb=n(j,"LI",{});var lxe=s(bb);Nme=n(lxe,"STRONG",{});var hmt=s(Nme);XRo=r(hmt,"led"),hmt.forEach(t),zRo=r(lxe," \u2014 "),UG=n(lxe,"A",{href:!0});var pmt=s(UG);WRo=r(pmt,"LEDForSequenceClassification"),pmt.forEach(t),QRo=r(lxe," (LED model)"),lxe.forEach(t),HRo=i(j),vb=n(j,"LI",{});var ixe=s(vb);qme=n(ixe,"STRONG",{});var _mt=s(qme);URo=r(_mt,"longformer"),_mt.forEach(t),JRo=r(ixe," \u2014 "),JG=n(ixe,"A",{href:!0});var umt=s(JG);YRo=r(umt,"LongformerForSequenceClassification"),umt.forEach(t),KRo=r(ixe," (Longformer model)"),ixe.forEach(t),ZRo=i(j),Fb=n(j,"LI",{});var dxe=s(Fb);jme=n(dxe,"STRONG",{});var bmt=s(jme);ePo=r(bmt,"mbart"),bmt.forEach(t),oPo=r(dxe," \u2014 "),YG=n(dxe,"A",{href:!0});var vmt=s(YG);rPo=r(vmt,"MBartForSequenceClassification"),vmt.forEach(t),tPo=r(dxe," (mBART model)"),dxe.forEach(t),aPo=i(j),Tb=n(j,"LI",{});var cxe=s(Tb);Dme=n(cxe,"STRONG",{});var Fmt=s(Dme);nPo=r(Fmt,"megatron-bert"),Fmt.forEach(t),sPo=r(cxe," \u2014 "),KG=n(cxe,"A",{href:!0});var Tmt=s(KG);lPo=r(Tmt,"MegatronBertForSequenceClassification"),Tmt.forEach(t),iPo=r(cxe," (MegatronBert model)"),cxe.forEach(t),dPo=i(j),Mb=n(j,"LI",{});var fxe=s(Mb);Gme=n(fxe,"STRONG",{});var Mmt=s(Gme);cPo=r(Mmt,"mobilebert"),Mmt.forEach(t),fPo=r(fxe," \u2014 "),ZG=n(fxe,"A",{href:!0});var Emt=s(ZG);mPo=r(Emt,"MobileBertForSequenceClassification"),Emt.forEach(t),gPo=r(fxe," (MobileBERT model)"),fxe.forEach(t),hPo=i(j),Eb=n(j,"LI",{});var mxe=s(Eb);Ome=n(mxe,"STRONG",{});var Cmt=s(Ome);pPo=r(Cmt,"mpnet"),Cmt.forEach(t),_Po=r(mxe," \u2014 "),eO=n(mxe,"A",{href:!0});var wmt=s(eO);uPo=r(wmt,"MPNetForSequenceClassification"),wmt.forEach(t),bPo=r(mxe," (MPNet model)"),mxe.forEach(t),vPo=i(j),Cb=n(j,"LI",{});var gxe=s(Cb);Vme=n(gxe,"STRONG",{});var Amt=s(Vme);FPo=r(Amt,"nystromformer"),Amt.forEach(t),TPo=r(gxe," \u2014 "),oO=n(gxe,"A",{href:!0});var ymt=s(oO);MPo=r(ymt,"NystromformerForSequenceClassification"),ymt.forEach(t),EPo=r(gxe," (Nystromformer model)"),gxe.forEach(t),CPo=i(j),wb=n(j,"LI",{});var hxe=s(wb);Xme=n(hxe,"STRONG",{});var Lmt=s(Xme);wPo=r(Lmt,"openai-gpt"),Lmt.forEach(t),APo=r(hxe," \u2014 "),rO=n(hxe,"A",{href:!0});var xmt=s(rO);yPo=r(xmt,"OpenAIGPTForSequenceClassification"),xmt.forEach(t),LPo=r(hxe," (OpenAI GPT model)"),hxe.forEach(t),xPo=i(j),Ab=n(j,"LI",{});var pxe=s(Ab);zme=n(pxe,"STRONG",{});var $mt=s(zme);$Po=r($mt,"perceiver"),$mt.forEach(t),kPo=r(pxe," \u2014 "),tO=n(pxe,"A",{href:!0});var kmt=s(tO);SPo=r(kmt,"PerceiverForSequenceClassification"),kmt.forEach(t),RPo=r(pxe," (Perceiver model)"),pxe.forEach(t),PPo=i(j),yb=n(j,"LI",{});var _xe=s(yb);Wme=n(_xe,"STRONG",{});var Smt=s(Wme);BPo=r(Smt,"plbart"),Smt.forEach(t),IPo=r(_xe," \u2014 "),aO=n(_xe,"A",{href:!0});var Rmt=s(aO);NPo=r(Rmt,"PLBartForSequenceClassification"),Rmt.forEach(t),qPo=r(_xe," (PLBart model)"),_xe.forEach(t),jPo=i(j),Lb=n(j,"LI",{});var uxe=s(Lb);Qme=n(uxe,"STRONG",{});var Pmt=s(Qme);DPo=r(Pmt,"qdqbert"),Pmt.forEach(t),GPo=r(uxe," \u2014 "),nO=n(uxe,"A",{href:!0});var Bmt=s(nO);OPo=r(Bmt,"QDQBertForSequenceClassification"),Bmt.forEach(t),VPo=r(uxe," (QDQBert model)"),uxe.forEach(t),XPo=i(j),xb=n(j,"LI",{});var bxe=s(xb);Hme=n(bxe,"STRONG",{});var Imt=s(Hme);zPo=r(Imt,"reformer"),Imt.forEach(t),WPo=r(bxe," \u2014 "),sO=n(bxe,"A",{href:!0});var Nmt=s(sO);QPo=r(Nmt,"ReformerForSequenceClassification"),Nmt.forEach(t),HPo=r(bxe," (Reformer model)"),bxe.forEach(t),UPo=i(j),$b=n(j,"LI",{});var vxe=s($b);Ume=n(vxe,"STRONG",{});var qmt=s(Ume);JPo=r(qmt,"rembert"),qmt.forEach(t),YPo=r(vxe," \u2014 "),lO=n(vxe,"A",{href:!0});var jmt=s(lO);KPo=r(jmt,"RemBertForSequenceClassification"),jmt.forEach(t),ZPo=r(vxe," (RemBERT model)"),vxe.forEach(t),eBo=i(j),kb=n(j,"LI",{});var Fxe=s(kb);Jme=n(Fxe,"STRONG",{});var Dmt=s(Jme);oBo=r(Dmt,"roberta"),Dmt.forEach(t),rBo=r(Fxe," \u2014 "),iO=n(Fxe,"A",{href:!0});var Gmt=s(iO);tBo=r(Gmt,"RobertaForSequenceClassification"),Gmt.forEach(t),aBo=r(Fxe," (RoBERTa model)"),Fxe.forEach(t),nBo=i(j),Sb=n(j,"LI",{});var Txe=s(Sb);Yme=n(Txe,"STRONG",{});var Omt=s(Yme);sBo=r(Omt,"roformer"),Omt.forEach(t),lBo=r(Txe," \u2014 "),dO=n(Txe,"A",{href:!0});var Vmt=s(dO);iBo=r(Vmt,"RoFormerForSequenceClassification"),Vmt.forEach(t),dBo=r(Txe," (RoFormer model)"),Txe.forEach(t),cBo=i(j),Rb=n(j,"LI",{});var Mxe=s(Rb);Kme=n(Mxe,"STRONG",{});var Xmt=s(Kme);fBo=r(Xmt,"squeezebert"),Xmt.forEach(t),mBo=r(Mxe," \u2014 "),cO=n(Mxe,"A",{href:!0});var zmt=s(cO);gBo=r(zmt,"SqueezeBertForSequenceClassification"),zmt.forEach(t),hBo=r(Mxe," (SqueezeBERT model)"),Mxe.forEach(t),pBo=i(j),Pb=n(j,"LI",{});var Exe=s(Pb);Zme=n(Exe,"STRONG",{});var Wmt=s(Zme);_Bo=r(Wmt,"tapas"),Wmt.forEach(t),uBo=r(Exe," \u2014 "),fO=n(Exe,"A",{href:!0});var Qmt=s(fO);bBo=r(Qmt,"TapasForSequenceClassification"),Qmt.forEach(t),vBo=r(Exe," (TAPAS model)"),Exe.forEach(t),FBo=i(j),Bb=n(j,"LI",{});var Cxe=s(Bb);ege=n(Cxe,"STRONG",{});var Hmt=s(ege);TBo=r(Hmt,"transfo-xl"),Hmt.forEach(t),MBo=r(Cxe," \u2014 "),mO=n(Cxe,"A",{href:!0});var Umt=s(mO);EBo=r(Umt,"TransfoXLForSequenceClassification"),Umt.forEach(t),CBo=r(Cxe," (Transformer-XL model)"),Cxe.forEach(t),wBo=i(j),Ib=n(j,"LI",{});var wxe=s(Ib);oge=n(wxe,"STRONG",{});var Jmt=s(oge);ABo=r(Jmt,"xlm"),Jmt.forEach(t),yBo=r(wxe," \u2014 "),gO=n(wxe,"A",{href:!0});var Ymt=s(gO);LBo=r(Ymt,"XLMForSequenceClassification"),Ymt.forEach(t),xBo=r(wxe," (XLM model)"),wxe.forEach(t),$Bo=i(j),Nb=n(j,"LI",{});var Axe=s(Nb);rge=n(Axe,"STRONG",{});var Kmt=s(rge);kBo=r(Kmt,"xlm-roberta"),Kmt.forEach(t),SBo=r(Axe," \u2014 "),hO=n(Axe,"A",{href:!0});var Zmt=s(hO);RBo=r(Zmt,"XLMRobertaForSequenceClassification"),Zmt.forEach(t),PBo=r(Axe," (XLM-RoBERTa model)"),Axe.forEach(t),BBo=i(j),qb=n(j,"LI",{});var yxe=s(qb);tge=n(yxe,"STRONG",{});var egt=s(tge);IBo=r(egt,"xlm-roberta-xl"),egt.forEach(t),NBo=r(yxe," \u2014 "),pO=n(yxe,"A",{href:!0});var ogt=s(pO);qBo=r(ogt,"XLMRobertaXLForSequenceClassification"),ogt.forEach(t),jBo=r(yxe," (XLM-RoBERTa-XL model)"),yxe.forEach(t),DBo=i(j),jb=n(j,"LI",{});var Lxe=s(jb);age=n(Lxe,"STRONG",{});var rgt=s(age);GBo=r(rgt,"xlnet"),rgt.forEach(t),OBo=r(Lxe," \u2014 "),_O=n(Lxe,"A",{href:!0});var tgt=s(_O);VBo=r(tgt,"XLNetForSequenceClassification"),tgt.forEach(t),XBo=r(Lxe," (XLNet model)"),Lxe.forEach(t),zBo=i(j),Db=n(j,"LI",{});var xxe=s(Db);nge=n(xxe,"STRONG",{});var agt=s(nge);WBo=r(agt,"yoso"),agt.forEach(t),QBo=r(xxe," \u2014 "),uO=n(xxe,"A",{href:!0});var ngt=s(uO);HBo=r(ngt,"YosoForSequenceClassification"),ngt.forEach(t),UBo=r(xxe," (YOSO model)"),xxe.forEach(t),j.forEach(t),JBo=i(sa),Gb=n(sa,"P",{});var $xe=s(Gb);YBo=r($xe,"The model is set in evaluation mode by default using "),sge=n($xe,"CODE",{});var sgt=s(sge);KBo=r(sgt,"model.eval()"),sgt.forEach(t),ZBo=r($xe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lge=n($xe,"CODE",{});var lgt=s(lge);eIo=r(lgt,"model.train()"),lgt.forEach(t),$xe.forEach(t),oIo=i(sa),T(Ob.$$.fragment,sa),sa.forEach(t),Hs.forEach(t),lje=i(f),zi=n(f,"H2",{class:!0});var fGe=s(zi);Vb=n(fGe,"A",{id:!0,class:!0,href:!0});var igt=s(Vb);ige=n(igt,"SPAN",{});var dgt=s(ige);T(qy.$$.fragment,dgt),dgt.forEach(t),igt.forEach(t),rIo=i(fGe),dge=n(fGe,"SPAN",{});var cgt=s(dge);tIo=r(cgt,"AutoModelForMultipleChoice"),cgt.forEach(t),fGe.forEach(t),ije=i(f),Po=n(f,"DIV",{class:!0});var Us=s(Po);T(jy.$$.fragment,Us),aIo=i(Us),Wi=n(Us,"P",{});var UZ=s(Wi);nIo=r(UZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),bO=n(UZ,"A",{href:!0});var fgt=s(bO);sIo=r(fgt,"from_pretrained()"),fgt.forEach(t),lIo=r(UZ," class method or the "),vO=n(UZ,"A",{href:!0});var mgt=s(vO);iIo=r(mgt,"from_config()"),mgt.forEach(t),dIo=r(UZ,` class
method.`),UZ.forEach(t),cIo=i(Us),Dy=n(Us,"P",{});var mGe=s(Dy);fIo=r(mGe,"This class cannot be instantiated directly using "),cge=n(mGe,"CODE",{});var ggt=s(cge);mIo=r(ggt,"__init__()"),ggt.forEach(t),gIo=r(mGe," (throws an error)."),mGe.forEach(t),hIo=i(Us),dt=n(Us,"DIV",{class:!0});var Kw=s(dt);T(Gy.$$.fragment,Kw),pIo=i(Kw),fge=n(Kw,"P",{});var hgt=s(fge);_Io=r(hgt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),hgt.forEach(t),uIo=i(Kw),Qi=n(Kw,"P",{});var JZ=s(Qi);bIo=r(JZ,`Note:
Loading a model from its configuration file does `),mge=n(JZ,"STRONG",{});var pgt=s(mge);vIo=r(pgt,"not"),pgt.forEach(t),FIo=r(JZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),FO=n(JZ,"A",{href:!0});var _gt=s(FO);TIo=r(_gt,"from_pretrained()"),_gt.forEach(t),MIo=r(JZ," to load the model weights."),JZ.forEach(t),EIo=i(Kw),T(Xb.$$.fragment,Kw),Kw.forEach(t),CIo=i(Us),ro=n(Us,"DIV",{class:!0});var la=s(ro);T(Oy.$$.fragment,la),wIo=i(la),gge=n(la,"P",{});var ugt=s(gge);AIo=r(ugt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ugt.forEach(t),yIo=i(la),Pa=n(la,"P",{});var Zw=s(Pa);LIo=r(Zw,"The model class to instantiate is selected based on the "),hge=n(Zw,"CODE",{});var bgt=s(hge);xIo=r(bgt,"model_type"),bgt.forEach(t),$Io=r(Zw,` property of the config object (either
passed as an argument or loaded from `),pge=n(Zw,"CODE",{});var vgt=s(pge);kIo=r(vgt,"pretrained_model_name_or_path"),vgt.forEach(t),SIo=r(Zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_ge=n(Zw,"CODE",{});var Fgt=s(_ge);RIo=r(Fgt,"pretrained_model_name_or_path"),Fgt.forEach(t),PIo=r(Zw,":"),Zw.forEach(t),BIo=i(la),K=n(la,"UL",{});var ee=s(K);zb=n(ee,"LI",{});var kxe=s(zb);uge=n(kxe,"STRONG",{});var Tgt=s(uge);IIo=r(Tgt,"albert"),Tgt.forEach(t),NIo=r(kxe," \u2014 "),TO=n(kxe,"A",{href:!0});var Mgt=s(TO);qIo=r(Mgt,"AlbertForMultipleChoice"),Mgt.forEach(t),jIo=r(kxe," (ALBERT model)"),kxe.forEach(t),DIo=i(ee),Wb=n(ee,"LI",{});var Sxe=s(Wb);bge=n(Sxe,"STRONG",{});var Egt=s(bge);GIo=r(Egt,"bert"),Egt.forEach(t),OIo=r(Sxe," \u2014 "),MO=n(Sxe,"A",{href:!0});var Cgt=s(MO);VIo=r(Cgt,"BertForMultipleChoice"),Cgt.forEach(t),XIo=r(Sxe," (BERT model)"),Sxe.forEach(t),zIo=i(ee),Qb=n(ee,"LI",{});var Rxe=s(Qb);vge=n(Rxe,"STRONG",{});var wgt=s(vge);WIo=r(wgt,"big_bird"),wgt.forEach(t),QIo=r(Rxe," \u2014 "),EO=n(Rxe,"A",{href:!0});var Agt=s(EO);HIo=r(Agt,"BigBirdForMultipleChoice"),Agt.forEach(t),UIo=r(Rxe," (BigBird model)"),Rxe.forEach(t),JIo=i(ee),Hb=n(ee,"LI",{});var Pxe=s(Hb);Fge=n(Pxe,"STRONG",{});var ygt=s(Fge);YIo=r(ygt,"camembert"),ygt.forEach(t),KIo=r(Pxe," \u2014 "),CO=n(Pxe,"A",{href:!0});var Lgt=s(CO);ZIo=r(Lgt,"CamembertForMultipleChoice"),Lgt.forEach(t),eNo=r(Pxe," (CamemBERT model)"),Pxe.forEach(t),oNo=i(ee),Ub=n(ee,"LI",{});var Bxe=s(Ub);Tge=n(Bxe,"STRONG",{});var xgt=s(Tge);rNo=r(xgt,"canine"),xgt.forEach(t),tNo=r(Bxe," \u2014 "),wO=n(Bxe,"A",{href:!0});var $gt=s(wO);aNo=r($gt,"CanineForMultipleChoice"),$gt.forEach(t),nNo=r(Bxe," (Canine model)"),Bxe.forEach(t),sNo=i(ee),Jb=n(ee,"LI",{});var Ixe=s(Jb);Mge=n(Ixe,"STRONG",{});var kgt=s(Mge);lNo=r(kgt,"convbert"),kgt.forEach(t),iNo=r(Ixe," \u2014 "),AO=n(Ixe,"A",{href:!0});var Sgt=s(AO);dNo=r(Sgt,"ConvBertForMultipleChoice"),Sgt.forEach(t),cNo=r(Ixe," (ConvBERT model)"),Ixe.forEach(t),fNo=i(ee),Yb=n(ee,"LI",{});var Nxe=s(Yb);Ege=n(Nxe,"STRONG",{});var Rgt=s(Ege);mNo=r(Rgt,"data2vec-text"),Rgt.forEach(t),gNo=r(Nxe," \u2014 "),yO=n(Nxe,"A",{href:!0});var Pgt=s(yO);hNo=r(Pgt,"Data2VecTextForMultipleChoice"),Pgt.forEach(t),pNo=r(Nxe," (Data2VecText model)"),Nxe.forEach(t),_No=i(ee),Kb=n(ee,"LI",{});var qxe=s(Kb);Cge=n(qxe,"STRONG",{});var Bgt=s(Cge);uNo=r(Bgt,"deberta-v2"),Bgt.forEach(t),bNo=r(qxe," \u2014 "),LO=n(qxe,"A",{href:!0});var Igt=s(LO);vNo=r(Igt,"DebertaV2ForMultipleChoice"),Igt.forEach(t),FNo=r(qxe," (DeBERTa-v2 model)"),qxe.forEach(t),TNo=i(ee),Zb=n(ee,"LI",{});var jxe=s(Zb);wge=n(jxe,"STRONG",{});var Ngt=s(wge);MNo=r(Ngt,"distilbert"),Ngt.forEach(t),ENo=r(jxe," \u2014 "),xO=n(jxe,"A",{href:!0});var qgt=s(xO);CNo=r(qgt,"DistilBertForMultipleChoice"),qgt.forEach(t),wNo=r(jxe," (DistilBERT model)"),jxe.forEach(t),ANo=i(ee),e4=n(ee,"LI",{});var Dxe=s(e4);Age=n(Dxe,"STRONG",{});var jgt=s(Age);yNo=r(jgt,"electra"),jgt.forEach(t),LNo=r(Dxe," \u2014 "),$O=n(Dxe,"A",{href:!0});var Dgt=s($O);xNo=r(Dgt,"ElectraForMultipleChoice"),Dgt.forEach(t),$No=r(Dxe," (ELECTRA model)"),Dxe.forEach(t),kNo=i(ee),o4=n(ee,"LI",{});var Gxe=s(o4);yge=n(Gxe,"STRONG",{});var Ggt=s(yge);SNo=r(Ggt,"flaubert"),Ggt.forEach(t),RNo=r(Gxe," \u2014 "),kO=n(Gxe,"A",{href:!0});var Ogt=s(kO);PNo=r(Ogt,"FlaubertForMultipleChoice"),Ogt.forEach(t),BNo=r(Gxe," (FlauBERT model)"),Gxe.forEach(t),INo=i(ee),r4=n(ee,"LI",{});var Oxe=s(r4);Lge=n(Oxe,"STRONG",{});var Vgt=s(Lge);NNo=r(Vgt,"fnet"),Vgt.forEach(t),qNo=r(Oxe," \u2014 "),SO=n(Oxe,"A",{href:!0});var Xgt=s(SO);jNo=r(Xgt,"FNetForMultipleChoice"),Xgt.forEach(t),DNo=r(Oxe," (FNet model)"),Oxe.forEach(t),GNo=i(ee),t4=n(ee,"LI",{});var Vxe=s(t4);xge=n(Vxe,"STRONG",{});var zgt=s(xge);ONo=r(zgt,"funnel"),zgt.forEach(t),VNo=r(Vxe," \u2014 "),RO=n(Vxe,"A",{href:!0});var Wgt=s(RO);XNo=r(Wgt,"FunnelForMultipleChoice"),Wgt.forEach(t),zNo=r(Vxe," (Funnel Transformer model)"),Vxe.forEach(t),WNo=i(ee),a4=n(ee,"LI",{});var Xxe=s(a4);$ge=n(Xxe,"STRONG",{});var Qgt=s($ge);QNo=r(Qgt,"ibert"),Qgt.forEach(t),HNo=r(Xxe," \u2014 "),PO=n(Xxe,"A",{href:!0});var Hgt=s(PO);UNo=r(Hgt,"IBertForMultipleChoice"),Hgt.forEach(t),JNo=r(Xxe," (I-BERT model)"),Xxe.forEach(t),YNo=i(ee),n4=n(ee,"LI",{});var zxe=s(n4);kge=n(zxe,"STRONG",{});var Ugt=s(kge);KNo=r(Ugt,"longformer"),Ugt.forEach(t),ZNo=r(zxe," \u2014 "),BO=n(zxe,"A",{href:!0});var Jgt=s(BO);eqo=r(Jgt,"LongformerForMultipleChoice"),Jgt.forEach(t),oqo=r(zxe," (Longformer model)"),zxe.forEach(t),rqo=i(ee),s4=n(ee,"LI",{});var Wxe=s(s4);Sge=n(Wxe,"STRONG",{});var Ygt=s(Sge);tqo=r(Ygt,"megatron-bert"),Ygt.forEach(t),aqo=r(Wxe," \u2014 "),IO=n(Wxe,"A",{href:!0});var Kgt=s(IO);nqo=r(Kgt,"MegatronBertForMultipleChoice"),Kgt.forEach(t),sqo=r(Wxe," (MegatronBert model)"),Wxe.forEach(t),lqo=i(ee),l4=n(ee,"LI",{});var Qxe=s(l4);Rge=n(Qxe,"STRONG",{});var Zgt=s(Rge);iqo=r(Zgt,"mobilebert"),Zgt.forEach(t),dqo=r(Qxe," \u2014 "),NO=n(Qxe,"A",{href:!0});var eht=s(NO);cqo=r(eht,"MobileBertForMultipleChoice"),eht.forEach(t),fqo=r(Qxe," (MobileBERT model)"),Qxe.forEach(t),mqo=i(ee),i4=n(ee,"LI",{});var Hxe=s(i4);Pge=n(Hxe,"STRONG",{});var oht=s(Pge);gqo=r(oht,"mpnet"),oht.forEach(t),hqo=r(Hxe," \u2014 "),qO=n(Hxe,"A",{href:!0});var rht=s(qO);pqo=r(rht,"MPNetForMultipleChoice"),rht.forEach(t),_qo=r(Hxe," (MPNet model)"),Hxe.forEach(t),uqo=i(ee),d4=n(ee,"LI",{});var Uxe=s(d4);Bge=n(Uxe,"STRONG",{});var tht=s(Bge);bqo=r(tht,"nystromformer"),tht.forEach(t),vqo=r(Uxe," \u2014 "),jO=n(Uxe,"A",{href:!0});var aht=s(jO);Fqo=r(aht,"NystromformerForMultipleChoice"),aht.forEach(t),Tqo=r(Uxe," (Nystromformer model)"),Uxe.forEach(t),Mqo=i(ee),c4=n(ee,"LI",{});var Jxe=s(c4);Ige=n(Jxe,"STRONG",{});var nht=s(Ige);Eqo=r(nht,"qdqbert"),nht.forEach(t),Cqo=r(Jxe," \u2014 "),DO=n(Jxe,"A",{href:!0});var sht=s(DO);wqo=r(sht,"QDQBertForMultipleChoice"),sht.forEach(t),Aqo=r(Jxe," (QDQBert model)"),Jxe.forEach(t),yqo=i(ee),f4=n(ee,"LI",{});var Yxe=s(f4);Nge=n(Yxe,"STRONG",{});var lht=s(Nge);Lqo=r(lht,"rembert"),lht.forEach(t),xqo=r(Yxe," \u2014 "),GO=n(Yxe,"A",{href:!0});var iht=s(GO);$qo=r(iht,"RemBertForMultipleChoice"),iht.forEach(t),kqo=r(Yxe," (RemBERT model)"),Yxe.forEach(t),Sqo=i(ee),m4=n(ee,"LI",{});var Kxe=s(m4);qge=n(Kxe,"STRONG",{});var dht=s(qge);Rqo=r(dht,"roberta"),dht.forEach(t),Pqo=r(Kxe," \u2014 "),OO=n(Kxe,"A",{href:!0});var cht=s(OO);Bqo=r(cht,"RobertaForMultipleChoice"),cht.forEach(t),Iqo=r(Kxe," (RoBERTa model)"),Kxe.forEach(t),Nqo=i(ee),g4=n(ee,"LI",{});var Zxe=s(g4);jge=n(Zxe,"STRONG",{});var fht=s(jge);qqo=r(fht,"roformer"),fht.forEach(t),jqo=r(Zxe," \u2014 "),VO=n(Zxe,"A",{href:!0});var mht=s(VO);Dqo=r(mht,"RoFormerForMultipleChoice"),mht.forEach(t),Gqo=r(Zxe," (RoFormer model)"),Zxe.forEach(t),Oqo=i(ee),h4=n(ee,"LI",{});var e$e=s(h4);Dge=n(e$e,"STRONG",{});var ght=s(Dge);Vqo=r(ght,"squeezebert"),ght.forEach(t),Xqo=r(e$e," \u2014 "),XO=n(e$e,"A",{href:!0});var hht=s(XO);zqo=r(hht,"SqueezeBertForMultipleChoice"),hht.forEach(t),Wqo=r(e$e," (SqueezeBERT model)"),e$e.forEach(t),Qqo=i(ee),p4=n(ee,"LI",{});var o$e=s(p4);Gge=n(o$e,"STRONG",{});var pht=s(Gge);Hqo=r(pht,"xlm"),pht.forEach(t),Uqo=r(o$e," \u2014 "),zO=n(o$e,"A",{href:!0});var _ht=s(zO);Jqo=r(_ht,"XLMForMultipleChoice"),_ht.forEach(t),Yqo=r(o$e," (XLM model)"),o$e.forEach(t),Kqo=i(ee),_4=n(ee,"LI",{});var r$e=s(_4);Oge=n(r$e,"STRONG",{});var uht=s(Oge);Zqo=r(uht,"xlm-roberta"),uht.forEach(t),ejo=r(r$e," \u2014 "),WO=n(r$e,"A",{href:!0});var bht=s(WO);ojo=r(bht,"XLMRobertaForMultipleChoice"),bht.forEach(t),rjo=r(r$e," (XLM-RoBERTa model)"),r$e.forEach(t),tjo=i(ee),u4=n(ee,"LI",{});var t$e=s(u4);Vge=n(t$e,"STRONG",{});var vht=s(Vge);ajo=r(vht,"xlm-roberta-xl"),vht.forEach(t),njo=r(t$e," \u2014 "),QO=n(t$e,"A",{href:!0});var Fht=s(QO);sjo=r(Fht,"XLMRobertaXLForMultipleChoice"),Fht.forEach(t),ljo=r(t$e," (XLM-RoBERTa-XL model)"),t$e.forEach(t),ijo=i(ee),b4=n(ee,"LI",{});var a$e=s(b4);Xge=n(a$e,"STRONG",{});var Tht=s(Xge);djo=r(Tht,"xlnet"),Tht.forEach(t),cjo=r(a$e," \u2014 "),HO=n(a$e,"A",{href:!0});var Mht=s(HO);fjo=r(Mht,"XLNetForMultipleChoice"),Mht.forEach(t),mjo=r(a$e," (XLNet model)"),a$e.forEach(t),gjo=i(ee),v4=n(ee,"LI",{});var n$e=s(v4);zge=n(n$e,"STRONG",{});var Eht=s(zge);hjo=r(Eht,"yoso"),Eht.forEach(t),pjo=r(n$e," \u2014 "),UO=n(n$e,"A",{href:!0});var Cht=s(UO);_jo=r(Cht,"YosoForMultipleChoice"),Cht.forEach(t),ujo=r(n$e," (YOSO model)"),n$e.forEach(t),ee.forEach(t),bjo=i(la),F4=n(la,"P",{});var s$e=s(F4);vjo=r(s$e,"The model is set in evaluation mode by default using "),Wge=n(s$e,"CODE",{});var wht=s(Wge);Fjo=r(wht,"model.eval()"),wht.forEach(t),Tjo=r(s$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qge=n(s$e,"CODE",{});var Aht=s(Qge);Mjo=r(Aht,"model.train()"),Aht.forEach(t),s$e.forEach(t),Ejo=i(la),T(T4.$$.fragment,la),la.forEach(t),Us.forEach(t),dje=i(f),Hi=n(f,"H2",{class:!0});var gGe=s(Hi);M4=n(gGe,"A",{id:!0,class:!0,href:!0});var yht=s(M4);Hge=n(yht,"SPAN",{});var Lht=s(Hge);T(Vy.$$.fragment,Lht),Lht.forEach(t),yht.forEach(t),Cjo=i(gGe),Uge=n(gGe,"SPAN",{});var xht=s(Uge);wjo=r(xht,"AutoModelForNextSentencePrediction"),xht.forEach(t),gGe.forEach(t),cje=i(f),Bo=n(f,"DIV",{class:!0});var Js=s(Bo);T(Xy.$$.fragment,Js),Ajo=i(Js),Ui=n(Js,"P",{});var YZ=s(Ui);yjo=r(YZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),JO=n(YZ,"A",{href:!0});var $ht=s(JO);Ljo=r($ht,"from_pretrained()"),$ht.forEach(t),xjo=r(YZ," class method or the "),YO=n(YZ,"A",{href:!0});var kht=s(YO);$jo=r(kht,"from_config()"),kht.forEach(t),kjo=r(YZ,` class
method.`),YZ.forEach(t),Sjo=i(Js),zy=n(Js,"P",{});var hGe=s(zy);Rjo=r(hGe,"This class cannot be instantiated directly using "),Jge=n(hGe,"CODE",{});var Sht=s(Jge);Pjo=r(Sht,"__init__()"),Sht.forEach(t),Bjo=r(hGe," (throws an error)."),hGe.forEach(t),Ijo=i(Js),ct=n(Js,"DIV",{class:!0});var e6=s(ct);T(Wy.$$.fragment,e6),Njo=i(e6),Yge=n(e6,"P",{});var Rht=s(Yge);qjo=r(Rht,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Rht.forEach(t),jjo=i(e6),Ji=n(e6,"P",{});var KZ=s(Ji);Djo=r(KZ,`Note:
Loading a model from its configuration file does `),Kge=n(KZ,"STRONG",{});var Pht=s(Kge);Gjo=r(Pht,"not"),Pht.forEach(t),Ojo=r(KZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),KO=n(KZ,"A",{href:!0});var Bht=s(KO);Vjo=r(Bht,"from_pretrained()"),Bht.forEach(t),Xjo=r(KZ," to load the model weights."),KZ.forEach(t),zjo=i(e6),T(E4.$$.fragment,e6),e6.forEach(t),Wjo=i(Js),to=n(Js,"DIV",{class:!0});var ia=s(to);T(Qy.$$.fragment,ia),Qjo=i(ia),Zge=n(ia,"P",{});var Iht=s(Zge);Hjo=r(Iht,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Iht.forEach(t),Ujo=i(ia),Ba=n(ia,"P",{});var o6=s(Ba);Jjo=r(o6,"The model class to instantiate is selected based on the "),ehe=n(o6,"CODE",{});var Nht=s(ehe);Yjo=r(Nht,"model_type"),Nht.forEach(t),Kjo=r(o6,` property of the config object (either
passed as an argument or loaded from `),ohe=n(o6,"CODE",{});var qht=s(ohe);Zjo=r(qht,"pretrained_model_name_or_path"),qht.forEach(t),eDo=r(o6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rhe=n(o6,"CODE",{});var jht=s(rhe);oDo=r(jht,"pretrained_model_name_or_path"),jht.forEach(t),rDo=r(o6,":"),o6.forEach(t),tDo=i(ia),Yr=n(ia,"UL",{});var Ys=s(Yr);C4=n(Ys,"LI",{});var l$e=s(C4);the=n(l$e,"STRONG",{});var Dht=s(the);aDo=r(Dht,"bert"),Dht.forEach(t),nDo=r(l$e," \u2014 "),ZO=n(l$e,"A",{href:!0});var Ght=s(ZO);sDo=r(Ght,"BertForNextSentencePrediction"),Ght.forEach(t),lDo=r(l$e," (BERT model)"),l$e.forEach(t),iDo=i(Ys),w4=n(Ys,"LI",{});var i$e=s(w4);ahe=n(i$e,"STRONG",{});var Oht=s(ahe);dDo=r(Oht,"fnet"),Oht.forEach(t),cDo=r(i$e," \u2014 "),eV=n(i$e,"A",{href:!0});var Vht=s(eV);fDo=r(Vht,"FNetForNextSentencePrediction"),Vht.forEach(t),mDo=r(i$e," (FNet model)"),i$e.forEach(t),gDo=i(Ys),A4=n(Ys,"LI",{});var d$e=s(A4);nhe=n(d$e,"STRONG",{});var Xht=s(nhe);hDo=r(Xht,"megatron-bert"),Xht.forEach(t),pDo=r(d$e," \u2014 "),oV=n(d$e,"A",{href:!0});var zht=s(oV);_Do=r(zht,"MegatronBertForNextSentencePrediction"),zht.forEach(t),uDo=r(d$e," (MegatronBert model)"),d$e.forEach(t),bDo=i(Ys),y4=n(Ys,"LI",{});var c$e=s(y4);she=n(c$e,"STRONG",{});var Wht=s(she);vDo=r(Wht,"mobilebert"),Wht.forEach(t),FDo=r(c$e," \u2014 "),rV=n(c$e,"A",{href:!0});var Qht=s(rV);TDo=r(Qht,"MobileBertForNextSentencePrediction"),Qht.forEach(t),MDo=r(c$e," (MobileBERT model)"),c$e.forEach(t),EDo=i(Ys),L4=n(Ys,"LI",{});var f$e=s(L4);lhe=n(f$e,"STRONG",{});var Hht=s(lhe);CDo=r(Hht,"qdqbert"),Hht.forEach(t),wDo=r(f$e," \u2014 "),tV=n(f$e,"A",{href:!0});var Uht=s(tV);ADo=r(Uht,"QDQBertForNextSentencePrediction"),Uht.forEach(t),yDo=r(f$e," (QDQBert model)"),f$e.forEach(t),Ys.forEach(t),LDo=i(ia),x4=n(ia,"P",{});var m$e=s(x4);xDo=r(m$e,"The model is set in evaluation mode by default using "),ihe=n(m$e,"CODE",{});var Jht=s(ihe);$Do=r(Jht,"model.eval()"),Jht.forEach(t),kDo=r(m$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dhe=n(m$e,"CODE",{});var Yht=s(dhe);SDo=r(Yht,"model.train()"),Yht.forEach(t),m$e.forEach(t),RDo=i(ia),T($4.$$.fragment,ia),ia.forEach(t),Js.forEach(t),fje=i(f),Yi=n(f,"H2",{class:!0});var pGe=s(Yi);k4=n(pGe,"A",{id:!0,class:!0,href:!0});var Kht=s(k4);che=n(Kht,"SPAN",{});var Zht=s(che);T(Hy.$$.fragment,Zht),Zht.forEach(t),Kht.forEach(t),PDo=i(pGe),fhe=n(pGe,"SPAN",{});var ept=s(fhe);BDo=r(ept,"AutoModelForTokenClassification"),ept.forEach(t),pGe.forEach(t),mje=i(f),Io=n(f,"DIV",{class:!0});var Ks=s(Io);T(Uy.$$.fragment,Ks),IDo=i(Ks),Ki=n(Ks,"P",{});var ZZ=s(Ki);NDo=r(ZZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),aV=n(ZZ,"A",{href:!0});var opt=s(aV);qDo=r(opt,"from_pretrained()"),opt.forEach(t),jDo=r(ZZ," class method or the "),nV=n(ZZ,"A",{href:!0});var rpt=s(nV);DDo=r(rpt,"from_config()"),rpt.forEach(t),GDo=r(ZZ,` class
method.`),ZZ.forEach(t),ODo=i(Ks),Jy=n(Ks,"P",{});var _Ge=s(Jy);VDo=r(_Ge,"This class cannot be instantiated directly using "),mhe=n(_Ge,"CODE",{});var tpt=s(mhe);XDo=r(tpt,"__init__()"),tpt.forEach(t),zDo=r(_Ge," (throws an error)."),_Ge.forEach(t),WDo=i(Ks),ft=n(Ks,"DIV",{class:!0});var r6=s(ft);T(Yy.$$.fragment,r6),QDo=i(r6),ghe=n(r6,"P",{});var apt=s(ghe);HDo=r(apt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),apt.forEach(t),UDo=i(r6),Zi=n(r6,"P",{});var eee=s(Zi);JDo=r(eee,`Note:
Loading a model from its configuration file does `),hhe=n(eee,"STRONG",{});var npt=s(hhe);YDo=r(npt,"not"),npt.forEach(t),KDo=r(eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),sV=n(eee,"A",{href:!0});var spt=s(sV);ZDo=r(spt,"from_pretrained()"),spt.forEach(t),eGo=r(eee," to load the model weights."),eee.forEach(t),oGo=i(r6),T(S4.$$.fragment,r6),r6.forEach(t),rGo=i(Ks),ao=n(Ks,"DIV",{class:!0});var da=s(ao);T(Ky.$$.fragment,da),tGo=i(da),phe=n(da,"P",{});var lpt=s(phe);aGo=r(lpt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),lpt.forEach(t),nGo=i(da),Ia=n(da,"P",{});var t6=s(Ia);sGo=r(t6,"The model class to instantiate is selected based on the "),_he=n(t6,"CODE",{});var ipt=s(_he);lGo=r(ipt,"model_type"),ipt.forEach(t),iGo=r(t6,` property of the config object (either
passed as an argument or loaded from `),uhe=n(t6,"CODE",{});var dpt=s(uhe);dGo=r(dpt,"pretrained_model_name_or_path"),dpt.forEach(t),cGo=r(t6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bhe=n(t6,"CODE",{});var cpt=s(bhe);fGo=r(cpt,"pretrained_model_name_or_path"),cpt.forEach(t),mGo=r(t6,":"),t6.forEach(t),gGo=i(da),U=n(da,"UL",{});var J=s(U);R4=n(J,"LI",{});var g$e=s(R4);vhe=n(g$e,"STRONG",{});var fpt=s(vhe);hGo=r(fpt,"albert"),fpt.forEach(t),pGo=r(g$e," \u2014 "),lV=n(g$e,"A",{href:!0});var mpt=s(lV);_Go=r(mpt,"AlbertForTokenClassification"),mpt.forEach(t),uGo=r(g$e," (ALBERT model)"),g$e.forEach(t),bGo=i(J),P4=n(J,"LI",{});var h$e=s(P4);Fhe=n(h$e,"STRONG",{});var gpt=s(Fhe);vGo=r(gpt,"bert"),gpt.forEach(t),FGo=r(h$e," \u2014 "),iV=n(h$e,"A",{href:!0});var hpt=s(iV);TGo=r(hpt,"BertForTokenClassification"),hpt.forEach(t),MGo=r(h$e," (BERT model)"),h$e.forEach(t),EGo=i(J),B4=n(J,"LI",{});var p$e=s(B4);The=n(p$e,"STRONG",{});var ppt=s(The);CGo=r(ppt,"big_bird"),ppt.forEach(t),wGo=r(p$e," \u2014 "),dV=n(p$e,"A",{href:!0});var _pt=s(dV);AGo=r(_pt,"BigBirdForTokenClassification"),_pt.forEach(t),yGo=r(p$e," (BigBird model)"),p$e.forEach(t),LGo=i(J),I4=n(J,"LI",{});var _$e=s(I4);Mhe=n(_$e,"STRONG",{});var upt=s(Mhe);xGo=r(upt,"camembert"),upt.forEach(t),$Go=r(_$e," \u2014 "),cV=n(_$e,"A",{href:!0});var bpt=s(cV);kGo=r(bpt,"CamembertForTokenClassification"),bpt.forEach(t),SGo=r(_$e," (CamemBERT model)"),_$e.forEach(t),RGo=i(J),N4=n(J,"LI",{});var u$e=s(N4);Ehe=n(u$e,"STRONG",{});var vpt=s(Ehe);PGo=r(vpt,"canine"),vpt.forEach(t),BGo=r(u$e," \u2014 "),fV=n(u$e,"A",{href:!0});var Fpt=s(fV);IGo=r(Fpt,"CanineForTokenClassification"),Fpt.forEach(t),NGo=r(u$e," (Canine model)"),u$e.forEach(t),qGo=i(J),q4=n(J,"LI",{});var b$e=s(q4);Che=n(b$e,"STRONG",{});var Tpt=s(Che);jGo=r(Tpt,"convbert"),Tpt.forEach(t),DGo=r(b$e," \u2014 "),mV=n(b$e,"A",{href:!0});var Mpt=s(mV);GGo=r(Mpt,"ConvBertForTokenClassification"),Mpt.forEach(t),OGo=r(b$e," (ConvBERT model)"),b$e.forEach(t),VGo=i(J),j4=n(J,"LI",{});var v$e=s(j4);whe=n(v$e,"STRONG",{});var Ept=s(whe);XGo=r(Ept,"data2vec-text"),Ept.forEach(t),zGo=r(v$e," \u2014 "),gV=n(v$e,"A",{href:!0});var Cpt=s(gV);WGo=r(Cpt,"Data2VecTextForTokenClassification"),Cpt.forEach(t),QGo=r(v$e," (Data2VecText model)"),v$e.forEach(t),HGo=i(J),D4=n(J,"LI",{});var F$e=s(D4);Ahe=n(F$e,"STRONG",{});var wpt=s(Ahe);UGo=r(wpt,"deberta"),wpt.forEach(t),JGo=r(F$e," \u2014 "),hV=n(F$e,"A",{href:!0});var Apt=s(hV);YGo=r(Apt,"DebertaForTokenClassification"),Apt.forEach(t),KGo=r(F$e," (DeBERTa model)"),F$e.forEach(t),ZGo=i(J),G4=n(J,"LI",{});var T$e=s(G4);yhe=n(T$e,"STRONG",{});var ypt=s(yhe);eOo=r(ypt,"deberta-v2"),ypt.forEach(t),oOo=r(T$e," \u2014 "),pV=n(T$e,"A",{href:!0});var Lpt=s(pV);rOo=r(Lpt,"DebertaV2ForTokenClassification"),Lpt.forEach(t),tOo=r(T$e," (DeBERTa-v2 model)"),T$e.forEach(t),aOo=i(J),O4=n(J,"LI",{});var M$e=s(O4);Lhe=n(M$e,"STRONG",{});var xpt=s(Lhe);nOo=r(xpt,"distilbert"),xpt.forEach(t),sOo=r(M$e," \u2014 "),_V=n(M$e,"A",{href:!0});var $pt=s(_V);lOo=r($pt,"DistilBertForTokenClassification"),$pt.forEach(t),iOo=r(M$e," (DistilBERT model)"),M$e.forEach(t),dOo=i(J),V4=n(J,"LI",{});var E$e=s(V4);xhe=n(E$e,"STRONG",{});var kpt=s(xhe);cOo=r(kpt,"electra"),kpt.forEach(t),fOo=r(E$e," \u2014 "),uV=n(E$e,"A",{href:!0});var Spt=s(uV);mOo=r(Spt,"ElectraForTokenClassification"),Spt.forEach(t),gOo=r(E$e," (ELECTRA model)"),E$e.forEach(t),hOo=i(J),X4=n(J,"LI",{});var C$e=s(X4);$he=n(C$e,"STRONG",{});var Rpt=s($he);pOo=r(Rpt,"flaubert"),Rpt.forEach(t),_Oo=r(C$e," \u2014 "),bV=n(C$e,"A",{href:!0});var Ppt=s(bV);uOo=r(Ppt,"FlaubertForTokenClassification"),Ppt.forEach(t),bOo=r(C$e," (FlauBERT model)"),C$e.forEach(t),vOo=i(J),z4=n(J,"LI",{});var w$e=s(z4);khe=n(w$e,"STRONG",{});var Bpt=s(khe);FOo=r(Bpt,"fnet"),Bpt.forEach(t),TOo=r(w$e," \u2014 "),vV=n(w$e,"A",{href:!0});var Ipt=s(vV);MOo=r(Ipt,"FNetForTokenClassification"),Ipt.forEach(t),EOo=r(w$e," (FNet model)"),w$e.forEach(t),COo=i(J),W4=n(J,"LI",{});var A$e=s(W4);She=n(A$e,"STRONG",{});var Npt=s(She);wOo=r(Npt,"funnel"),Npt.forEach(t),AOo=r(A$e," \u2014 "),FV=n(A$e,"A",{href:!0});var qpt=s(FV);yOo=r(qpt,"FunnelForTokenClassification"),qpt.forEach(t),LOo=r(A$e," (Funnel Transformer model)"),A$e.forEach(t),xOo=i(J),Q4=n(J,"LI",{});var y$e=s(Q4);Rhe=n(y$e,"STRONG",{});var jpt=s(Rhe);$Oo=r(jpt,"gpt2"),jpt.forEach(t),kOo=r(y$e," \u2014 "),TV=n(y$e,"A",{href:!0});var Dpt=s(TV);SOo=r(Dpt,"GPT2ForTokenClassification"),Dpt.forEach(t),ROo=r(y$e," (OpenAI GPT-2 model)"),y$e.forEach(t),POo=i(J),H4=n(J,"LI",{});var L$e=s(H4);Phe=n(L$e,"STRONG",{});var Gpt=s(Phe);BOo=r(Gpt,"ibert"),Gpt.forEach(t),IOo=r(L$e," \u2014 "),MV=n(L$e,"A",{href:!0});var Opt=s(MV);NOo=r(Opt,"IBertForTokenClassification"),Opt.forEach(t),qOo=r(L$e," (I-BERT model)"),L$e.forEach(t),jOo=i(J),U4=n(J,"LI",{});var x$e=s(U4);Bhe=n(x$e,"STRONG",{});var Vpt=s(Bhe);DOo=r(Vpt,"layoutlm"),Vpt.forEach(t),GOo=r(x$e," \u2014 "),EV=n(x$e,"A",{href:!0});var Xpt=s(EV);OOo=r(Xpt,"LayoutLMForTokenClassification"),Xpt.forEach(t),VOo=r(x$e," (LayoutLM model)"),x$e.forEach(t),XOo=i(J),J4=n(J,"LI",{});var $$e=s(J4);Ihe=n($$e,"STRONG",{});var zpt=s(Ihe);zOo=r(zpt,"layoutlmv2"),zpt.forEach(t),WOo=r($$e," \u2014 "),CV=n($$e,"A",{href:!0});var Wpt=s(CV);QOo=r(Wpt,"LayoutLMv2ForTokenClassification"),Wpt.forEach(t),HOo=r($$e," (LayoutLMv2 model)"),$$e.forEach(t),UOo=i(J),Y4=n(J,"LI",{});var k$e=s(Y4);Nhe=n(k$e,"STRONG",{});var Qpt=s(Nhe);JOo=r(Qpt,"layoutlmv3"),Qpt.forEach(t),YOo=r(k$e," \u2014 "),wV=n(k$e,"A",{href:!0});var Hpt=s(wV);KOo=r(Hpt,"LayoutLMv3ForTokenClassification"),Hpt.forEach(t),ZOo=r(k$e," (LayoutLMv3 model)"),k$e.forEach(t),eVo=i(J),K4=n(J,"LI",{});var S$e=s(K4);qhe=n(S$e,"STRONG",{});var Upt=s(qhe);oVo=r(Upt,"longformer"),Upt.forEach(t),rVo=r(S$e," \u2014 "),AV=n(S$e,"A",{href:!0});var Jpt=s(AV);tVo=r(Jpt,"LongformerForTokenClassification"),Jpt.forEach(t),aVo=r(S$e," (Longformer model)"),S$e.forEach(t),nVo=i(J),Z4=n(J,"LI",{});var R$e=s(Z4);jhe=n(R$e,"STRONG",{});var Ypt=s(jhe);sVo=r(Ypt,"megatron-bert"),Ypt.forEach(t),lVo=r(R$e," \u2014 "),yV=n(R$e,"A",{href:!0});var Kpt=s(yV);iVo=r(Kpt,"MegatronBertForTokenClassification"),Kpt.forEach(t),dVo=r(R$e," (MegatronBert model)"),R$e.forEach(t),cVo=i(J),ev=n(J,"LI",{});var P$e=s(ev);Dhe=n(P$e,"STRONG",{});var Zpt=s(Dhe);fVo=r(Zpt,"mobilebert"),Zpt.forEach(t),mVo=r(P$e," \u2014 "),LV=n(P$e,"A",{href:!0});var e_t=s(LV);gVo=r(e_t,"MobileBertForTokenClassification"),e_t.forEach(t),hVo=r(P$e," (MobileBERT model)"),P$e.forEach(t),pVo=i(J),ov=n(J,"LI",{});var B$e=s(ov);Ghe=n(B$e,"STRONG",{});var o_t=s(Ghe);_Vo=r(o_t,"mpnet"),o_t.forEach(t),uVo=r(B$e," \u2014 "),xV=n(B$e,"A",{href:!0});var r_t=s(xV);bVo=r(r_t,"MPNetForTokenClassification"),r_t.forEach(t),vVo=r(B$e," (MPNet model)"),B$e.forEach(t),FVo=i(J),rv=n(J,"LI",{});var I$e=s(rv);Ohe=n(I$e,"STRONG",{});var t_t=s(Ohe);TVo=r(t_t,"nystromformer"),t_t.forEach(t),MVo=r(I$e," \u2014 "),$V=n(I$e,"A",{href:!0});var a_t=s($V);EVo=r(a_t,"NystromformerForTokenClassification"),a_t.forEach(t),CVo=r(I$e," (Nystromformer model)"),I$e.forEach(t),wVo=i(J),tv=n(J,"LI",{});var N$e=s(tv);Vhe=n(N$e,"STRONG",{});var n_t=s(Vhe);AVo=r(n_t,"qdqbert"),n_t.forEach(t),yVo=r(N$e," \u2014 "),kV=n(N$e,"A",{href:!0});var s_t=s(kV);LVo=r(s_t,"QDQBertForTokenClassification"),s_t.forEach(t),xVo=r(N$e," (QDQBert model)"),N$e.forEach(t),$Vo=i(J),av=n(J,"LI",{});var q$e=s(av);Xhe=n(q$e,"STRONG",{});var l_t=s(Xhe);kVo=r(l_t,"rembert"),l_t.forEach(t),SVo=r(q$e," \u2014 "),SV=n(q$e,"A",{href:!0});var i_t=s(SV);RVo=r(i_t,"RemBertForTokenClassification"),i_t.forEach(t),PVo=r(q$e," (RemBERT model)"),q$e.forEach(t),BVo=i(J),nv=n(J,"LI",{});var j$e=s(nv);zhe=n(j$e,"STRONG",{});var d_t=s(zhe);IVo=r(d_t,"roberta"),d_t.forEach(t),NVo=r(j$e," \u2014 "),RV=n(j$e,"A",{href:!0});var c_t=s(RV);qVo=r(c_t,"RobertaForTokenClassification"),c_t.forEach(t),jVo=r(j$e," (RoBERTa model)"),j$e.forEach(t),DVo=i(J),sv=n(J,"LI",{});var D$e=s(sv);Whe=n(D$e,"STRONG",{});var f_t=s(Whe);GVo=r(f_t,"roformer"),f_t.forEach(t),OVo=r(D$e," \u2014 "),PV=n(D$e,"A",{href:!0});var m_t=s(PV);VVo=r(m_t,"RoFormerForTokenClassification"),m_t.forEach(t),XVo=r(D$e," (RoFormer model)"),D$e.forEach(t),zVo=i(J),lv=n(J,"LI",{});var G$e=s(lv);Qhe=n(G$e,"STRONG",{});var g_t=s(Qhe);WVo=r(g_t,"squeezebert"),g_t.forEach(t),QVo=r(G$e," \u2014 "),BV=n(G$e,"A",{href:!0});var h_t=s(BV);HVo=r(h_t,"SqueezeBertForTokenClassification"),h_t.forEach(t),UVo=r(G$e," (SqueezeBERT model)"),G$e.forEach(t),JVo=i(J),iv=n(J,"LI",{});var O$e=s(iv);Hhe=n(O$e,"STRONG",{});var p_t=s(Hhe);YVo=r(p_t,"xlm"),p_t.forEach(t),KVo=r(O$e," \u2014 "),IV=n(O$e,"A",{href:!0});var __t=s(IV);ZVo=r(__t,"XLMForTokenClassification"),__t.forEach(t),eXo=r(O$e," (XLM model)"),O$e.forEach(t),oXo=i(J),dv=n(J,"LI",{});var V$e=s(dv);Uhe=n(V$e,"STRONG",{});var u_t=s(Uhe);rXo=r(u_t,"xlm-roberta"),u_t.forEach(t),tXo=r(V$e," \u2014 "),NV=n(V$e,"A",{href:!0});var b_t=s(NV);aXo=r(b_t,"XLMRobertaForTokenClassification"),b_t.forEach(t),nXo=r(V$e," (XLM-RoBERTa model)"),V$e.forEach(t),sXo=i(J),cv=n(J,"LI",{});var X$e=s(cv);Jhe=n(X$e,"STRONG",{});var v_t=s(Jhe);lXo=r(v_t,"xlm-roberta-xl"),v_t.forEach(t),iXo=r(X$e," \u2014 "),qV=n(X$e,"A",{href:!0});var F_t=s(qV);dXo=r(F_t,"XLMRobertaXLForTokenClassification"),F_t.forEach(t),cXo=r(X$e," (XLM-RoBERTa-XL model)"),X$e.forEach(t),fXo=i(J),fv=n(J,"LI",{});var z$e=s(fv);Yhe=n(z$e,"STRONG",{});var T_t=s(Yhe);mXo=r(T_t,"xlnet"),T_t.forEach(t),gXo=r(z$e," \u2014 "),jV=n(z$e,"A",{href:!0});var M_t=s(jV);hXo=r(M_t,"XLNetForTokenClassification"),M_t.forEach(t),pXo=r(z$e," (XLNet model)"),z$e.forEach(t),_Xo=i(J),mv=n(J,"LI",{});var W$e=s(mv);Khe=n(W$e,"STRONG",{});var E_t=s(Khe);uXo=r(E_t,"yoso"),E_t.forEach(t),bXo=r(W$e," \u2014 "),DV=n(W$e,"A",{href:!0});var C_t=s(DV);vXo=r(C_t,"YosoForTokenClassification"),C_t.forEach(t),FXo=r(W$e," (YOSO model)"),W$e.forEach(t),J.forEach(t),TXo=i(da),gv=n(da,"P",{});var Q$e=s(gv);MXo=r(Q$e,"The model is set in evaluation mode by default using "),Zhe=n(Q$e,"CODE",{});var w_t=s(Zhe);EXo=r(w_t,"model.eval()"),w_t.forEach(t),CXo=r(Q$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),epe=n(Q$e,"CODE",{});var A_t=s(epe);wXo=r(A_t,"model.train()"),A_t.forEach(t),Q$e.forEach(t),AXo=i(da),T(hv.$$.fragment,da),da.forEach(t),Ks.forEach(t),gje=i(f),ed=n(f,"H2",{class:!0});var uGe=s(ed);pv=n(uGe,"A",{id:!0,class:!0,href:!0});var y_t=s(pv);ope=n(y_t,"SPAN",{});var L_t=s(ope);T(Zy.$$.fragment,L_t),L_t.forEach(t),y_t.forEach(t),yXo=i(uGe),rpe=n(uGe,"SPAN",{});var x_t=s(rpe);LXo=r(x_t,"AutoModelForQuestionAnswering"),x_t.forEach(t),uGe.forEach(t),hje=i(f),No=n(f,"DIV",{class:!0});var Zs=s(No);T(eL.$$.fragment,Zs),xXo=i(Zs),od=n(Zs,"P",{});var oee=s(od);$Xo=r(oee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GV=n(oee,"A",{href:!0});var $_t=s(GV);kXo=r($_t,"from_pretrained()"),$_t.forEach(t),SXo=r(oee," class method or the "),OV=n(oee,"A",{href:!0});var k_t=s(OV);RXo=r(k_t,"from_config()"),k_t.forEach(t),PXo=r(oee,` class
method.`),oee.forEach(t),BXo=i(Zs),oL=n(Zs,"P",{});var bGe=s(oL);IXo=r(bGe,"This class cannot be instantiated directly using "),tpe=n(bGe,"CODE",{});var S_t=s(tpe);NXo=r(S_t,"__init__()"),S_t.forEach(t),qXo=r(bGe," (throws an error)."),bGe.forEach(t),jXo=i(Zs),mt=n(Zs,"DIV",{class:!0});var a6=s(mt);T(rL.$$.fragment,a6),DXo=i(a6),ape=n(a6,"P",{});var R_t=s(ape);GXo=r(R_t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),R_t.forEach(t),OXo=i(a6),rd=n(a6,"P",{});var ree=s(rd);VXo=r(ree,`Note:
Loading a model from its configuration file does `),npe=n(ree,"STRONG",{});var P_t=s(npe);XXo=r(P_t,"not"),P_t.forEach(t),zXo=r(ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=n(ree,"A",{href:!0});var B_t=s(VV);WXo=r(B_t,"from_pretrained()"),B_t.forEach(t),QXo=r(ree," to load the model weights."),ree.forEach(t),HXo=i(a6),T(_v.$$.fragment,a6),a6.forEach(t),UXo=i(Zs),no=n(Zs,"DIV",{class:!0});var ca=s(no);T(tL.$$.fragment,ca),JXo=i(ca),spe=n(ca,"P",{});var I_t=s(spe);YXo=r(I_t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),I_t.forEach(t),KXo=i(ca),Na=n(ca,"P",{});var n6=s(Na);ZXo=r(n6,"The model class to instantiate is selected based on the "),lpe=n(n6,"CODE",{});var N_t=s(lpe);ezo=r(N_t,"model_type"),N_t.forEach(t),ozo=r(n6,` property of the config object (either
passed as an argument or loaded from `),ipe=n(n6,"CODE",{});var q_t=s(ipe);rzo=r(q_t,"pretrained_model_name_or_path"),q_t.forEach(t),tzo=r(n6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dpe=n(n6,"CODE",{});var j_t=s(dpe);azo=r(j_t,"pretrained_model_name_or_path"),j_t.forEach(t),nzo=r(n6,":"),n6.forEach(t),szo=i(ca),V=n(ca,"UL",{});var X=s(V);uv=n(X,"LI",{});var H$e=s(uv);cpe=n(H$e,"STRONG",{});var D_t=s(cpe);lzo=r(D_t,"albert"),D_t.forEach(t),izo=r(H$e," \u2014 "),XV=n(H$e,"A",{href:!0});var G_t=s(XV);dzo=r(G_t,"AlbertForQuestionAnswering"),G_t.forEach(t),czo=r(H$e," (ALBERT model)"),H$e.forEach(t),fzo=i(X),bv=n(X,"LI",{});var U$e=s(bv);fpe=n(U$e,"STRONG",{});var O_t=s(fpe);mzo=r(O_t,"bart"),O_t.forEach(t),gzo=r(U$e," \u2014 "),zV=n(U$e,"A",{href:!0});var V_t=s(zV);hzo=r(V_t,"BartForQuestionAnswering"),V_t.forEach(t),pzo=r(U$e," (BART model)"),U$e.forEach(t),_zo=i(X),vv=n(X,"LI",{});var J$e=s(vv);mpe=n(J$e,"STRONG",{});var X_t=s(mpe);uzo=r(X_t,"bert"),X_t.forEach(t),bzo=r(J$e," \u2014 "),WV=n(J$e,"A",{href:!0});var z_t=s(WV);vzo=r(z_t,"BertForQuestionAnswering"),z_t.forEach(t),Fzo=r(J$e," (BERT model)"),J$e.forEach(t),Tzo=i(X),Fv=n(X,"LI",{});var Y$e=s(Fv);gpe=n(Y$e,"STRONG",{});var W_t=s(gpe);Mzo=r(W_t,"big_bird"),W_t.forEach(t),Ezo=r(Y$e," \u2014 "),QV=n(Y$e,"A",{href:!0});var Q_t=s(QV);Czo=r(Q_t,"BigBirdForQuestionAnswering"),Q_t.forEach(t),wzo=r(Y$e," (BigBird model)"),Y$e.forEach(t),Azo=i(X),Tv=n(X,"LI",{});var K$e=s(Tv);hpe=n(K$e,"STRONG",{});var H_t=s(hpe);yzo=r(H_t,"bigbird_pegasus"),H_t.forEach(t),Lzo=r(K$e," \u2014 "),HV=n(K$e,"A",{href:!0});var U_t=s(HV);xzo=r(U_t,"BigBirdPegasusForQuestionAnswering"),U_t.forEach(t),$zo=r(K$e," (BigBirdPegasus model)"),K$e.forEach(t),kzo=i(X),Mv=n(X,"LI",{});var Z$e=s(Mv);ppe=n(Z$e,"STRONG",{});var J_t=s(ppe);Szo=r(J_t,"camembert"),J_t.forEach(t),Rzo=r(Z$e," \u2014 "),UV=n(Z$e,"A",{href:!0});var Y_t=s(UV);Pzo=r(Y_t,"CamembertForQuestionAnswering"),Y_t.forEach(t),Bzo=r(Z$e," (CamemBERT model)"),Z$e.forEach(t),Izo=i(X),Ev=n(X,"LI",{});var eke=s(Ev);_pe=n(eke,"STRONG",{});var K_t=s(_pe);Nzo=r(K_t,"canine"),K_t.forEach(t),qzo=r(eke," \u2014 "),JV=n(eke,"A",{href:!0});var Z_t=s(JV);jzo=r(Z_t,"CanineForQuestionAnswering"),Z_t.forEach(t),Dzo=r(eke," (Canine model)"),eke.forEach(t),Gzo=i(X),Cv=n(X,"LI",{});var oke=s(Cv);upe=n(oke,"STRONG",{});var eut=s(upe);Ozo=r(eut,"convbert"),eut.forEach(t),Vzo=r(oke," \u2014 "),YV=n(oke,"A",{href:!0});var out=s(YV);Xzo=r(out,"ConvBertForQuestionAnswering"),out.forEach(t),zzo=r(oke," (ConvBERT model)"),oke.forEach(t),Wzo=i(X),wv=n(X,"LI",{});var rke=s(wv);bpe=n(rke,"STRONG",{});var rut=s(bpe);Qzo=r(rut,"data2vec-text"),rut.forEach(t),Hzo=r(rke," \u2014 "),KV=n(rke,"A",{href:!0});var tut=s(KV);Uzo=r(tut,"Data2VecTextForQuestionAnswering"),tut.forEach(t),Jzo=r(rke," (Data2VecText model)"),rke.forEach(t),Yzo=i(X),Av=n(X,"LI",{});var tke=s(Av);vpe=n(tke,"STRONG",{});var aut=s(vpe);Kzo=r(aut,"deberta"),aut.forEach(t),Zzo=r(tke," \u2014 "),ZV=n(tke,"A",{href:!0});var nut=s(ZV);eWo=r(nut,"DebertaForQuestionAnswering"),nut.forEach(t),oWo=r(tke," (DeBERTa model)"),tke.forEach(t),rWo=i(X),yv=n(X,"LI",{});var ake=s(yv);Fpe=n(ake,"STRONG",{});var sut=s(Fpe);tWo=r(sut,"deberta-v2"),sut.forEach(t),aWo=r(ake," \u2014 "),eX=n(ake,"A",{href:!0});var lut=s(eX);nWo=r(lut,"DebertaV2ForQuestionAnswering"),lut.forEach(t),sWo=r(ake," (DeBERTa-v2 model)"),ake.forEach(t),lWo=i(X),Lv=n(X,"LI",{});var nke=s(Lv);Tpe=n(nke,"STRONG",{});var iut=s(Tpe);iWo=r(iut,"distilbert"),iut.forEach(t),dWo=r(nke," \u2014 "),oX=n(nke,"A",{href:!0});var dut=s(oX);cWo=r(dut,"DistilBertForQuestionAnswering"),dut.forEach(t),fWo=r(nke," (DistilBERT model)"),nke.forEach(t),mWo=i(X),xv=n(X,"LI",{});var ske=s(xv);Mpe=n(ske,"STRONG",{});var cut=s(Mpe);gWo=r(cut,"electra"),cut.forEach(t),hWo=r(ske," \u2014 "),rX=n(ske,"A",{href:!0});var fut=s(rX);pWo=r(fut,"ElectraForQuestionAnswering"),fut.forEach(t),_Wo=r(ske," (ELECTRA model)"),ske.forEach(t),uWo=i(X),$v=n(X,"LI",{});var lke=s($v);Epe=n(lke,"STRONG",{});var mut=s(Epe);bWo=r(mut,"flaubert"),mut.forEach(t),vWo=r(lke," \u2014 "),tX=n(lke,"A",{href:!0});var gut=s(tX);FWo=r(gut,"FlaubertForQuestionAnsweringSimple"),gut.forEach(t),TWo=r(lke," (FlauBERT model)"),lke.forEach(t),MWo=i(X),kv=n(X,"LI",{});var ike=s(kv);Cpe=n(ike,"STRONG",{});var hut=s(Cpe);EWo=r(hut,"fnet"),hut.forEach(t),CWo=r(ike," \u2014 "),aX=n(ike,"A",{href:!0});var put=s(aX);wWo=r(put,"FNetForQuestionAnswering"),put.forEach(t),AWo=r(ike," (FNet model)"),ike.forEach(t),yWo=i(X),Sv=n(X,"LI",{});var dke=s(Sv);wpe=n(dke,"STRONG",{});var _ut=s(wpe);LWo=r(_ut,"funnel"),_ut.forEach(t),xWo=r(dke," \u2014 "),nX=n(dke,"A",{href:!0});var uut=s(nX);$Wo=r(uut,"FunnelForQuestionAnswering"),uut.forEach(t),kWo=r(dke," (Funnel Transformer model)"),dke.forEach(t),SWo=i(X),Rv=n(X,"LI",{});var cke=s(Rv);Ape=n(cke,"STRONG",{});var but=s(Ape);RWo=r(but,"gptj"),but.forEach(t),PWo=r(cke," \u2014 "),sX=n(cke,"A",{href:!0});var vut=s(sX);BWo=r(vut,"GPTJForQuestionAnswering"),vut.forEach(t),IWo=r(cke," (GPT-J model)"),cke.forEach(t),NWo=i(X),Pv=n(X,"LI",{});var fke=s(Pv);ype=n(fke,"STRONG",{});var Fut=s(ype);qWo=r(Fut,"ibert"),Fut.forEach(t),jWo=r(fke," \u2014 "),lX=n(fke,"A",{href:!0});var Tut=s(lX);DWo=r(Tut,"IBertForQuestionAnswering"),Tut.forEach(t),GWo=r(fke," (I-BERT model)"),fke.forEach(t),OWo=i(X),Bv=n(X,"LI",{});var mke=s(Bv);Lpe=n(mke,"STRONG",{});var Mut=s(Lpe);VWo=r(Mut,"layoutlmv2"),Mut.forEach(t),XWo=r(mke," \u2014 "),iX=n(mke,"A",{href:!0});var Eut=s(iX);zWo=r(Eut,"LayoutLMv2ForQuestionAnswering"),Eut.forEach(t),WWo=r(mke," (LayoutLMv2 model)"),mke.forEach(t),QWo=i(X),Iv=n(X,"LI",{});var gke=s(Iv);xpe=n(gke,"STRONG",{});var Cut=s(xpe);HWo=r(Cut,"layoutlmv3"),Cut.forEach(t),UWo=r(gke," \u2014 "),dX=n(gke,"A",{href:!0});var wut=s(dX);JWo=r(wut,"LayoutLMv3ForQuestionAnswering"),wut.forEach(t),YWo=r(gke," (LayoutLMv3 model)"),gke.forEach(t),KWo=i(X),Nv=n(X,"LI",{});var hke=s(Nv);$pe=n(hke,"STRONG",{});var Aut=s($pe);ZWo=r(Aut,"led"),Aut.forEach(t),eQo=r(hke," \u2014 "),cX=n(hke,"A",{href:!0});var yut=s(cX);oQo=r(yut,"LEDForQuestionAnswering"),yut.forEach(t),rQo=r(hke," (LED model)"),hke.forEach(t),tQo=i(X),qv=n(X,"LI",{});var pke=s(qv);kpe=n(pke,"STRONG",{});var Lut=s(kpe);aQo=r(Lut,"longformer"),Lut.forEach(t),nQo=r(pke," \u2014 "),fX=n(pke,"A",{href:!0});var xut=s(fX);sQo=r(xut,"LongformerForQuestionAnswering"),xut.forEach(t),lQo=r(pke," (Longformer model)"),pke.forEach(t),iQo=i(X),jv=n(X,"LI",{});var _ke=s(jv);Spe=n(_ke,"STRONG",{});var $ut=s(Spe);dQo=r($ut,"lxmert"),$ut.forEach(t),cQo=r(_ke," \u2014 "),mX=n(_ke,"A",{href:!0});var kut=s(mX);fQo=r(kut,"LxmertForQuestionAnswering"),kut.forEach(t),mQo=r(_ke," (LXMERT model)"),_ke.forEach(t),gQo=i(X),Dv=n(X,"LI",{});var uke=s(Dv);Rpe=n(uke,"STRONG",{});var Sut=s(Rpe);hQo=r(Sut,"mbart"),Sut.forEach(t),pQo=r(uke," \u2014 "),gX=n(uke,"A",{href:!0});var Rut=s(gX);_Qo=r(Rut,"MBartForQuestionAnswering"),Rut.forEach(t),uQo=r(uke," (mBART model)"),uke.forEach(t),bQo=i(X),Gv=n(X,"LI",{});var bke=s(Gv);Ppe=n(bke,"STRONG",{});var Put=s(Ppe);vQo=r(Put,"megatron-bert"),Put.forEach(t),FQo=r(bke," \u2014 "),hX=n(bke,"A",{href:!0});var But=s(hX);TQo=r(But,"MegatronBertForQuestionAnswering"),But.forEach(t),MQo=r(bke," (MegatronBert model)"),bke.forEach(t),EQo=i(X),Ov=n(X,"LI",{});var vke=s(Ov);Bpe=n(vke,"STRONG",{});var Iut=s(Bpe);CQo=r(Iut,"mobilebert"),Iut.forEach(t),wQo=r(vke," \u2014 "),pX=n(vke,"A",{href:!0});var Nut=s(pX);AQo=r(Nut,"MobileBertForQuestionAnswering"),Nut.forEach(t),yQo=r(vke," (MobileBERT model)"),vke.forEach(t),LQo=i(X),Vv=n(X,"LI",{});var Fke=s(Vv);Ipe=n(Fke,"STRONG",{});var qut=s(Ipe);xQo=r(qut,"mpnet"),qut.forEach(t),$Qo=r(Fke," \u2014 "),_X=n(Fke,"A",{href:!0});var jut=s(_X);kQo=r(jut,"MPNetForQuestionAnswering"),jut.forEach(t),SQo=r(Fke," (MPNet model)"),Fke.forEach(t),RQo=i(X),Xv=n(X,"LI",{});var Tke=s(Xv);Npe=n(Tke,"STRONG",{});var Dut=s(Npe);PQo=r(Dut,"nystromformer"),Dut.forEach(t),BQo=r(Tke," \u2014 "),uX=n(Tke,"A",{href:!0});var Gut=s(uX);IQo=r(Gut,"NystromformerForQuestionAnswering"),Gut.forEach(t),NQo=r(Tke," (Nystromformer model)"),Tke.forEach(t),qQo=i(X),zv=n(X,"LI",{});var Mke=s(zv);qpe=n(Mke,"STRONG",{});var Out=s(qpe);jQo=r(Out,"qdqbert"),Out.forEach(t),DQo=r(Mke," \u2014 "),bX=n(Mke,"A",{href:!0});var Vut=s(bX);GQo=r(Vut,"QDQBertForQuestionAnswering"),Vut.forEach(t),OQo=r(Mke," (QDQBert model)"),Mke.forEach(t),VQo=i(X),Wv=n(X,"LI",{});var Eke=s(Wv);jpe=n(Eke,"STRONG",{});var Xut=s(jpe);XQo=r(Xut,"reformer"),Xut.forEach(t),zQo=r(Eke," \u2014 "),vX=n(Eke,"A",{href:!0});var zut=s(vX);WQo=r(zut,"ReformerForQuestionAnswering"),zut.forEach(t),QQo=r(Eke," (Reformer model)"),Eke.forEach(t),HQo=i(X),Qv=n(X,"LI",{});var Cke=s(Qv);Dpe=n(Cke,"STRONG",{});var Wut=s(Dpe);UQo=r(Wut,"rembert"),Wut.forEach(t),JQo=r(Cke," \u2014 "),FX=n(Cke,"A",{href:!0});var Qut=s(FX);YQo=r(Qut,"RemBertForQuestionAnswering"),Qut.forEach(t),KQo=r(Cke," (RemBERT model)"),Cke.forEach(t),ZQo=i(X),Hv=n(X,"LI",{});var wke=s(Hv);Gpe=n(wke,"STRONG",{});var Hut=s(Gpe);eHo=r(Hut,"roberta"),Hut.forEach(t),oHo=r(wke," \u2014 "),TX=n(wke,"A",{href:!0});var Uut=s(TX);rHo=r(Uut,"RobertaForQuestionAnswering"),Uut.forEach(t),tHo=r(wke," (RoBERTa model)"),wke.forEach(t),aHo=i(X),Uv=n(X,"LI",{});var Ake=s(Uv);Ope=n(Ake,"STRONG",{});var Jut=s(Ope);nHo=r(Jut,"roformer"),Jut.forEach(t),sHo=r(Ake," \u2014 "),MX=n(Ake,"A",{href:!0});var Yut=s(MX);lHo=r(Yut,"RoFormerForQuestionAnswering"),Yut.forEach(t),iHo=r(Ake," (RoFormer model)"),Ake.forEach(t),dHo=i(X),Jv=n(X,"LI",{});var yke=s(Jv);Vpe=n(yke,"STRONG",{});var Kut=s(Vpe);cHo=r(Kut,"splinter"),Kut.forEach(t),fHo=r(yke," \u2014 "),EX=n(yke,"A",{href:!0});var Zut=s(EX);mHo=r(Zut,"SplinterForQuestionAnswering"),Zut.forEach(t),gHo=r(yke," (Splinter model)"),yke.forEach(t),hHo=i(X),Yv=n(X,"LI",{});var Lke=s(Yv);Xpe=n(Lke,"STRONG",{});var e2t=s(Xpe);pHo=r(e2t,"squeezebert"),e2t.forEach(t),_Ho=r(Lke," \u2014 "),CX=n(Lke,"A",{href:!0});var o2t=s(CX);uHo=r(o2t,"SqueezeBertForQuestionAnswering"),o2t.forEach(t),bHo=r(Lke," (SqueezeBERT model)"),Lke.forEach(t),vHo=i(X),Kv=n(X,"LI",{});var xke=s(Kv);zpe=n(xke,"STRONG",{});var r2t=s(zpe);FHo=r(r2t,"xlm"),r2t.forEach(t),THo=r(xke," \u2014 "),wX=n(xke,"A",{href:!0});var t2t=s(wX);MHo=r(t2t,"XLMForQuestionAnsweringSimple"),t2t.forEach(t),EHo=r(xke," (XLM model)"),xke.forEach(t),CHo=i(X),Zv=n(X,"LI",{});var $ke=s(Zv);Wpe=n($ke,"STRONG",{});var a2t=s(Wpe);wHo=r(a2t,"xlm-roberta"),a2t.forEach(t),AHo=r($ke," \u2014 "),AX=n($ke,"A",{href:!0});var n2t=s(AX);yHo=r(n2t,"XLMRobertaForQuestionAnswering"),n2t.forEach(t),LHo=r($ke," (XLM-RoBERTa model)"),$ke.forEach(t),xHo=i(X),e5=n(X,"LI",{});var kke=s(e5);Qpe=n(kke,"STRONG",{});var s2t=s(Qpe);$Ho=r(s2t,"xlm-roberta-xl"),s2t.forEach(t),kHo=r(kke," \u2014 "),yX=n(kke,"A",{href:!0});var l2t=s(yX);SHo=r(l2t,"XLMRobertaXLForQuestionAnswering"),l2t.forEach(t),RHo=r(kke," (XLM-RoBERTa-XL model)"),kke.forEach(t),PHo=i(X),o5=n(X,"LI",{});var Ske=s(o5);Hpe=n(Ske,"STRONG",{});var i2t=s(Hpe);BHo=r(i2t,"xlnet"),i2t.forEach(t),IHo=r(Ske," \u2014 "),LX=n(Ske,"A",{href:!0});var d2t=s(LX);NHo=r(d2t,"XLNetForQuestionAnsweringSimple"),d2t.forEach(t),qHo=r(Ske," (XLNet model)"),Ske.forEach(t),jHo=i(X),r5=n(X,"LI",{});var Rke=s(r5);Upe=n(Rke,"STRONG",{});var c2t=s(Upe);DHo=r(c2t,"yoso"),c2t.forEach(t),GHo=r(Rke," \u2014 "),xX=n(Rke,"A",{href:!0});var f2t=s(xX);OHo=r(f2t,"YosoForQuestionAnswering"),f2t.forEach(t),VHo=r(Rke," (YOSO model)"),Rke.forEach(t),X.forEach(t),XHo=i(ca),t5=n(ca,"P",{});var Pke=s(t5);zHo=r(Pke,"The model is set in evaluation mode by default using "),Jpe=n(Pke,"CODE",{});var m2t=s(Jpe);WHo=r(m2t,"model.eval()"),m2t.forEach(t),QHo=r(Pke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=n(Pke,"CODE",{});var g2t=s(Ype);HHo=r(g2t,"model.train()"),g2t.forEach(t),Pke.forEach(t),UHo=i(ca),T(a5.$$.fragment,ca),ca.forEach(t),Zs.forEach(t),pje=i(f),td=n(f,"H2",{class:!0});var vGe=s(td);n5=n(vGe,"A",{id:!0,class:!0,href:!0});var h2t=s(n5);Kpe=n(h2t,"SPAN",{});var p2t=s(Kpe);T(aL.$$.fragment,p2t),p2t.forEach(t),h2t.forEach(t),JHo=i(vGe),Zpe=n(vGe,"SPAN",{});var _2t=s(Zpe);YHo=r(_2t,"AutoModelForTableQuestionAnswering"),_2t.forEach(t),vGe.forEach(t),_je=i(f),qo=n(f,"DIV",{class:!0});var el=s(qo);T(nL.$$.fragment,el),KHo=i(el),ad=n(el,"P",{});var tee=s(ad);ZHo=r(tee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$X=n(tee,"A",{href:!0});var u2t=s($X);eUo=r(u2t,"from_pretrained()"),u2t.forEach(t),oUo=r(tee," class method or the "),kX=n(tee,"A",{href:!0});var b2t=s(kX);rUo=r(b2t,"from_config()"),b2t.forEach(t),tUo=r(tee,` class
method.`),tee.forEach(t),aUo=i(el),sL=n(el,"P",{});var FGe=s(sL);nUo=r(FGe,"This class cannot be instantiated directly using "),e_e=n(FGe,"CODE",{});var v2t=s(e_e);sUo=r(v2t,"__init__()"),v2t.forEach(t),lUo=r(FGe," (throws an error)."),FGe.forEach(t),iUo=i(el),gt=n(el,"DIV",{class:!0});var s6=s(gt);T(lL.$$.fragment,s6),dUo=i(s6),o_e=n(s6,"P",{});var F2t=s(o_e);cUo=r(F2t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),F2t.forEach(t),fUo=i(s6),nd=n(s6,"P",{});var aee=s(nd);mUo=r(aee,`Note:
Loading a model from its configuration file does `),r_e=n(aee,"STRONG",{});var T2t=s(r_e);gUo=r(T2t,"not"),T2t.forEach(t),hUo=r(aee,` load the model weights. It only affects the
model\u2019s configuration. Use `),SX=n(aee,"A",{href:!0});var M2t=s(SX);pUo=r(M2t,"from_pretrained()"),M2t.forEach(t),_Uo=r(aee," to load the model weights."),aee.forEach(t),uUo=i(s6),T(s5.$$.fragment,s6),s6.forEach(t),bUo=i(el),so=n(el,"DIV",{class:!0});var fa=s(so);T(iL.$$.fragment,fa),vUo=i(fa),t_e=n(fa,"P",{});var E2t=s(t_e);FUo=r(E2t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),E2t.forEach(t),TUo=i(fa),qa=n(fa,"P",{});var l6=s(qa);MUo=r(l6,"The model class to instantiate is selected based on the "),a_e=n(l6,"CODE",{});var C2t=s(a_e);EUo=r(C2t,"model_type"),C2t.forEach(t),CUo=r(l6,` property of the config object (either
passed as an argument or loaded from `),n_e=n(l6,"CODE",{});var w2t=s(n_e);wUo=r(w2t,"pretrained_model_name_or_path"),w2t.forEach(t),AUo=r(l6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=n(l6,"CODE",{});var A2t=s(s_e);yUo=r(A2t,"pretrained_model_name_or_path"),A2t.forEach(t),LUo=r(l6,":"),l6.forEach(t),xUo=i(fa),l_e=n(fa,"UL",{});var y2t=s(l_e);l5=n(y2t,"LI",{});var Bke=s(l5);i_e=n(Bke,"STRONG",{});var L2t=s(i_e);$Uo=r(L2t,"tapas"),L2t.forEach(t),kUo=r(Bke," \u2014 "),RX=n(Bke,"A",{href:!0});var x2t=s(RX);SUo=r(x2t,"TapasForQuestionAnswering"),x2t.forEach(t),RUo=r(Bke," (TAPAS model)"),Bke.forEach(t),y2t.forEach(t),PUo=i(fa),i5=n(fa,"P",{});var Ike=s(i5);BUo=r(Ike,"The model is set in evaluation mode by default using "),d_e=n(Ike,"CODE",{});var $2t=s(d_e);IUo=r($2t,"model.eval()"),$2t.forEach(t),NUo=r(Ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=n(Ike,"CODE",{});var k2t=s(c_e);qUo=r(k2t,"model.train()"),k2t.forEach(t),Ike.forEach(t),jUo=i(fa),T(d5.$$.fragment,fa),fa.forEach(t),el.forEach(t),uje=i(f),sd=n(f,"H2",{class:!0});var TGe=s(sd);c5=n(TGe,"A",{id:!0,class:!0,href:!0});var S2t=s(c5);f_e=n(S2t,"SPAN",{});var R2t=s(f_e);T(dL.$$.fragment,R2t),R2t.forEach(t),S2t.forEach(t),DUo=i(TGe),m_e=n(TGe,"SPAN",{});var P2t=s(m_e);GUo=r(P2t,"AutoModelForImageClassification"),P2t.forEach(t),TGe.forEach(t),bje=i(f),jo=n(f,"DIV",{class:!0});var ol=s(jo);T(cL.$$.fragment,ol),OUo=i(ol),ld=n(ol,"P",{});var nee=s(ld);VUo=r(nee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),PX=n(nee,"A",{href:!0});var B2t=s(PX);XUo=r(B2t,"from_pretrained()"),B2t.forEach(t),zUo=r(nee," class method or the "),BX=n(nee,"A",{href:!0});var I2t=s(BX);WUo=r(I2t,"from_config()"),I2t.forEach(t),QUo=r(nee,` class
method.`),nee.forEach(t),HUo=i(ol),fL=n(ol,"P",{});var MGe=s(fL);UUo=r(MGe,"This class cannot be instantiated directly using "),g_e=n(MGe,"CODE",{});var N2t=s(g_e);JUo=r(N2t,"__init__()"),N2t.forEach(t),YUo=r(MGe," (throws an error)."),MGe.forEach(t),KUo=i(ol),ht=n(ol,"DIV",{class:!0});var i6=s(ht);T(mL.$$.fragment,i6),ZUo=i(i6),h_e=n(i6,"P",{});var q2t=s(h_e);eJo=r(q2t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),q2t.forEach(t),oJo=i(i6),id=n(i6,"P",{});var see=s(id);rJo=r(see,`Note:
Loading a model from its configuration file does `),p_e=n(see,"STRONG",{});var j2t=s(p_e);tJo=r(j2t,"not"),j2t.forEach(t),aJo=r(see,` load the model weights. It only affects the
model\u2019s configuration. Use `),IX=n(see,"A",{href:!0});var D2t=s(IX);nJo=r(D2t,"from_pretrained()"),D2t.forEach(t),sJo=r(see," to load the model weights."),see.forEach(t),lJo=i(i6),T(f5.$$.fragment,i6),i6.forEach(t),iJo=i(ol),lo=n(ol,"DIV",{class:!0});var ma=s(lo);T(gL.$$.fragment,ma),dJo=i(ma),__e=n(ma,"P",{});var G2t=s(__e);cJo=r(G2t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),G2t.forEach(t),fJo=i(ma),ja=n(ma,"P",{});var d6=s(ja);mJo=r(d6,"The model class to instantiate is selected based on the "),u_e=n(d6,"CODE",{});var O2t=s(u_e);gJo=r(O2t,"model_type"),O2t.forEach(t),hJo=r(d6,` property of the config object (either
passed as an argument or loaded from `),b_e=n(d6,"CODE",{});var V2t=s(b_e);pJo=r(V2t,"pretrained_model_name_or_path"),V2t.forEach(t),_Jo=r(d6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v_e=n(d6,"CODE",{});var X2t=s(v_e);uJo=r(X2t,"pretrained_model_name_or_path"),X2t.forEach(t),bJo=r(d6,":"),d6.forEach(t),vJo=i(ma),ve=n(ma,"UL",{});var Te=s(ve);m5=n(Te,"LI",{});var Nke=s(m5);F_e=n(Nke,"STRONG",{});var z2t=s(F_e);FJo=r(z2t,"beit"),z2t.forEach(t),TJo=r(Nke," \u2014 "),NX=n(Nke,"A",{href:!0});var W2t=s(NX);MJo=r(W2t,"BeitForImageClassification"),W2t.forEach(t),EJo=r(Nke," (BEiT model)"),Nke.forEach(t),CJo=i(Te),g5=n(Te,"LI",{});var qke=s(g5);T_e=n(qke,"STRONG",{});var Q2t=s(T_e);wJo=r(Q2t,"convnext"),Q2t.forEach(t),AJo=r(qke," \u2014 "),qX=n(qke,"A",{href:!0});var H2t=s(qX);yJo=r(H2t,"ConvNextForImageClassification"),H2t.forEach(t),LJo=r(qke," (ConvNext model)"),qke.forEach(t),xJo=i(Te),h5=n(Te,"LI",{});var jke=s(h5);M_e=n(jke,"STRONG",{});var U2t=s(M_e);$Jo=r(U2t,"cvt"),U2t.forEach(t),kJo=r(jke," \u2014 "),jX=n(jke,"A",{href:!0});var J2t=s(jX);SJo=r(J2t,"CvtForImageClassification"),J2t.forEach(t),RJo=r(jke," (CvT model)"),jke.forEach(t),PJo=i(Te),p5=n(Te,"LI",{});var Dke=s(p5);E_e=n(Dke,"STRONG",{});var Y2t=s(E_e);BJo=r(Y2t,"data2vec-vision"),Y2t.forEach(t),IJo=r(Dke," \u2014 "),DX=n(Dke,"A",{href:!0});var K2t=s(DX);NJo=r(K2t,"Data2VecVisionForImageClassification"),K2t.forEach(t),qJo=r(Dke," (Data2VecVision model)"),Dke.forEach(t),jJo=i(Te),Is=n(Te,"LI",{});var Z$=s(Is);C_e=n(Z$,"STRONG",{});var Z2t=s(C_e);DJo=r(Z2t,"deit"),Z2t.forEach(t),GJo=r(Z$," \u2014 "),GX=n(Z$,"A",{href:!0});var e1t=s(GX);OJo=r(e1t,"DeiTForImageClassification"),e1t.forEach(t),VJo=r(Z$," or "),OX=n(Z$,"A",{href:!0});var o1t=s(OX);XJo=r(o1t,"DeiTForImageClassificationWithTeacher"),o1t.forEach(t),zJo=r(Z$," (DeiT model)"),Z$.forEach(t),WJo=i(Te),_5=n(Te,"LI",{});var Gke=s(_5);w_e=n(Gke,"STRONG",{});var r1t=s(w_e);QJo=r(r1t,"imagegpt"),r1t.forEach(t),HJo=r(Gke," \u2014 "),VX=n(Gke,"A",{href:!0});var t1t=s(VX);UJo=r(t1t,"ImageGPTForImageClassification"),t1t.forEach(t),JJo=r(Gke," (ImageGPT model)"),Gke.forEach(t),YJo=i(Te),Ns=n(Te,"LI",{});var ek=s(Ns);A_e=n(ek,"STRONG",{});var a1t=s(A_e);KJo=r(a1t,"levit"),a1t.forEach(t),ZJo=r(ek," \u2014 "),XX=n(ek,"A",{href:!0});var n1t=s(XX);eYo=r(n1t,"LevitForImageClassification"),n1t.forEach(t),oYo=r(ek," or "),zX=n(ek,"A",{href:!0});var s1t=s(zX);rYo=r(s1t,"LevitForImageClassificationWithTeacher"),s1t.forEach(t),tYo=r(ek," (LeViT model)"),ek.forEach(t),aYo=i(Te),pt=n(Te,"LI",{});var _f=s(pt);y_e=n(_f,"STRONG",{});var l1t=s(y_e);nYo=r(l1t,"perceiver"),l1t.forEach(t),sYo=r(_f," \u2014 "),WX=n(_f,"A",{href:!0});var i1t=s(WX);lYo=r(i1t,"PerceiverForImageClassificationLearned"),i1t.forEach(t),iYo=r(_f," or "),QX=n(_f,"A",{href:!0});var d1t=s(QX);dYo=r(d1t,"PerceiverForImageClassificationFourier"),d1t.forEach(t),cYo=r(_f," or "),HX=n(_f,"A",{href:!0});var c1t=s(HX);fYo=r(c1t,"PerceiverForImageClassificationConvProcessing"),c1t.forEach(t),mYo=r(_f," (Perceiver model)"),_f.forEach(t),gYo=i(Te),u5=n(Te,"LI",{});var Oke=s(u5);L_e=n(Oke,"STRONG",{});var f1t=s(L_e);hYo=r(f1t,"poolformer"),f1t.forEach(t),pYo=r(Oke," \u2014 "),UX=n(Oke,"A",{href:!0});var m1t=s(UX);_Yo=r(m1t,"PoolFormerForImageClassification"),m1t.forEach(t),uYo=r(Oke," (PoolFormer model)"),Oke.forEach(t),bYo=i(Te),b5=n(Te,"LI",{});var Vke=s(b5);x_e=n(Vke,"STRONG",{});var g1t=s(x_e);vYo=r(g1t,"regnet"),g1t.forEach(t),FYo=r(Vke," \u2014 "),JX=n(Vke,"A",{href:!0});var h1t=s(JX);TYo=r(h1t,"RegNetForImageClassification"),h1t.forEach(t),MYo=r(Vke," (RegNet model)"),Vke.forEach(t),EYo=i(Te),v5=n(Te,"LI",{});var Xke=s(v5);$_e=n(Xke,"STRONG",{});var p1t=s($_e);CYo=r(p1t,"resnet"),p1t.forEach(t),wYo=r(Xke," \u2014 "),YX=n(Xke,"A",{href:!0});var _1t=s(YX);AYo=r(_1t,"ResNetForImageClassification"),_1t.forEach(t),yYo=r(Xke," (ResNet model)"),Xke.forEach(t),LYo=i(Te),F5=n(Te,"LI",{});var zke=s(F5);k_e=n(zke,"STRONG",{});var u1t=s(k_e);xYo=r(u1t,"segformer"),u1t.forEach(t),$Yo=r(zke," \u2014 "),KX=n(zke,"A",{href:!0});var b1t=s(KX);kYo=r(b1t,"SegformerForImageClassification"),b1t.forEach(t),SYo=r(zke," (SegFormer model)"),zke.forEach(t),RYo=i(Te),T5=n(Te,"LI",{});var Wke=s(T5);S_e=n(Wke,"STRONG",{});var v1t=s(S_e);PYo=r(v1t,"swin"),v1t.forEach(t),BYo=r(Wke," \u2014 "),ZX=n(Wke,"A",{href:!0});var F1t=s(ZX);IYo=r(F1t,"SwinForImageClassification"),F1t.forEach(t),NYo=r(Wke," (Swin model)"),Wke.forEach(t),qYo=i(Te),M5=n(Te,"LI",{});var Qke=s(M5);R_e=n(Qke,"STRONG",{});var T1t=s(R_e);jYo=r(T1t,"van"),T1t.forEach(t),DYo=r(Qke," \u2014 "),ez=n(Qke,"A",{href:!0});var M1t=s(ez);GYo=r(M1t,"VanForImageClassification"),M1t.forEach(t),OYo=r(Qke," (VAN model)"),Qke.forEach(t),VYo=i(Te),E5=n(Te,"LI",{});var Hke=s(E5);P_e=n(Hke,"STRONG",{});var E1t=s(P_e);XYo=r(E1t,"vit"),E1t.forEach(t),zYo=r(Hke," \u2014 "),oz=n(Hke,"A",{href:!0});var C1t=s(oz);WYo=r(C1t,"ViTForImageClassification"),C1t.forEach(t),QYo=r(Hke," (ViT model)"),Hke.forEach(t),Te.forEach(t),HYo=i(ma),C5=n(ma,"P",{});var Uke=s(C5);UYo=r(Uke,"The model is set in evaluation mode by default using "),B_e=n(Uke,"CODE",{});var w1t=s(B_e);JYo=r(w1t,"model.eval()"),w1t.forEach(t),YYo=r(Uke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I_e=n(Uke,"CODE",{});var A1t=s(I_e);KYo=r(A1t,"model.train()"),A1t.forEach(t),Uke.forEach(t),ZYo=i(ma),T(w5.$$.fragment,ma),ma.forEach(t),ol.forEach(t),vje=i(f),dd=n(f,"H2",{class:!0});var EGe=s(dd);A5=n(EGe,"A",{id:!0,class:!0,href:!0});var y1t=s(A5);N_e=n(y1t,"SPAN",{});var L1t=s(N_e);T(hL.$$.fragment,L1t),L1t.forEach(t),y1t.forEach(t),eKo=i(EGe),q_e=n(EGe,"SPAN",{});var x1t=s(q_e);oKo=r(x1t,"AutoModelForVision2Seq"),x1t.forEach(t),EGe.forEach(t),Fje=i(f),Do=n(f,"DIV",{class:!0});var rl=s(Do);T(pL.$$.fragment,rl),rKo=i(rl),cd=n(rl,"P",{});var lee=s(cd);tKo=r(lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),rz=n(lee,"A",{href:!0});var $1t=s(rz);aKo=r($1t,"from_pretrained()"),$1t.forEach(t),nKo=r(lee," class method or the "),tz=n(lee,"A",{href:!0});var k1t=s(tz);sKo=r(k1t,"from_config()"),k1t.forEach(t),lKo=r(lee,` class
method.`),lee.forEach(t),iKo=i(rl),_L=n(rl,"P",{});var CGe=s(_L);dKo=r(CGe,"This class cannot be instantiated directly using "),j_e=n(CGe,"CODE",{});var S1t=s(j_e);cKo=r(S1t,"__init__()"),S1t.forEach(t),fKo=r(CGe," (throws an error)."),CGe.forEach(t),mKo=i(rl),_t=n(rl,"DIV",{class:!0});var c6=s(_t);T(uL.$$.fragment,c6),gKo=i(c6),D_e=n(c6,"P",{});var R1t=s(D_e);hKo=r(R1t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),R1t.forEach(t),pKo=i(c6),fd=n(c6,"P",{});var iee=s(fd);_Ko=r(iee,`Note:
Loading a model from its configuration file does `),G_e=n(iee,"STRONG",{});var P1t=s(G_e);uKo=r(P1t,"not"),P1t.forEach(t),bKo=r(iee,` load the model weights. It only affects the
model\u2019s configuration. Use `),az=n(iee,"A",{href:!0});var B1t=s(az);vKo=r(B1t,"from_pretrained()"),B1t.forEach(t),FKo=r(iee," to load the model weights."),iee.forEach(t),TKo=i(c6),T(y5.$$.fragment,c6),c6.forEach(t),MKo=i(rl),io=n(rl,"DIV",{class:!0});var ga=s(io);T(bL.$$.fragment,ga),EKo=i(ga),O_e=n(ga,"P",{});var I1t=s(O_e);CKo=r(I1t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),I1t.forEach(t),wKo=i(ga),Da=n(ga,"P",{});var f6=s(Da);AKo=r(f6,"The model class to instantiate is selected based on the "),V_e=n(f6,"CODE",{});var N1t=s(V_e);yKo=r(N1t,"model_type"),N1t.forEach(t),LKo=r(f6,` property of the config object (either
passed as an argument or loaded from `),X_e=n(f6,"CODE",{});var q1t=s(X_e);xKo=r(q1t,"pretrained_model_name_or_path"),q1t.forEach(t),$Ko=r(f6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z_e=n(f6,"CODE",{});var j1t=s(z_e);kKo=r(j1t,"pretrained_model_name_or_path"),j1t.forEach(t),SKo=r(f6,":"),f6.forEach(t),RKo=i(ga),W_e=n(ga,"UL",{});var D1t=s(W_e);L5=n(D1t,"LI",{});var Jke=s(L5);Q_e=n(Jke,"STRONG",{});var G1t=s(Q_e);PKo=r(G1t,"vision-encoder-decoder"),G1t.forEach(t),BKo=r(Jke," \u2014 "),nz=n(Jke,"A",{href:!0});var O1t=s(nz);IKo=r(O1t,"VisionEncoderDecoderModel"),O1t.forEach(t),NKo=r(Jke," (Vision Encoder decoder model)"),Jke.forEach(t),D1t.forEach(t),qKo=i(ga),x5=n(ga,"P",{});var Yke=s(x5);jKo=r(Yke,"The model is set in evaluation mode by default using "),H_e=n(Yke,"CODE",{});var V1t=s(H_e);DKo=r(V1t,"model.eval()"),V1t.forEach(t),GKo=r(Yke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U_e=n(Yke,"CODE",{});var X1t=s(U_e);OKo=r(X1t,"model.train()"),X1t.forEach(t),Yke.forEach(t),VKo=i(ga),T($5.$$.fragment,ga),ga.forEach(t),rl.forEach(t),Tje=i(f),md=n(f,"H2",{class:!0});var wGe=s(md);k5=n(wGe,"A",{id:!0,class:!0,href:!0});var z1t=s(k5);J_e=n(z1t,"SPAN",{});var W1t=s(J_e);T(vL.$$.fragment,W1t),W1t.forEach(t),z1t.forEach(t),XKo=i(wGe),Y_e=n(wGe,"SPAN",{});var Q1t=s(Y_e);zKo=r(Q1t,"AutoModelForAudioClassification"),Q1t.forEach(t),wGe.forEach(t),Mje=i(f),Go=n(f,"DIV",{class:!0});var tl=s(Go);T(FL.$$.fragment,tl),WKo=i(tl),gd=n(tl,"P",{});var dee=s(gd);QKo=r(dee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),sz=n(dee,"A",{href:!0});var H1t=s(sz);HKo=r(H1t,"from_pretrained()"),H1t.forEach(t),UKo=r(dee," class method or the "),lz=n(dee,"A",{href:!0});var U1t=s(lz);JKo=r(U1t,"from_config()"),U1t.forEach(t),YKo=r(dee,` class
method.`),dee.forEach(t),KKo=i(tl),TL=n(tl,"P",{});var AGe=s(TL);ZKo=r(AGe,"This class cannot be instantiated directly using "),K_e=n(AGe,"CODE",{});var J1t=s(K_e);eZo=r(J1t,"__init__()"),J1t.forEach(t),oZo=r(AGe," (throws an error)."),AGe.forEach(t),rZo=i(tl),ut=n(tl,"DIV",{class:!0});var m6=s(ut);T(ML.$$.fragment,m6),tZo=i(m6),Z_e=n(m6,"P",{});var Y1t=s(Z_e);aZo=r(Y1t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Y1t.forEach(t),nZo=i(m6),hd=n(m6,"P",{});var cee=s(hd);sZo=r(cee,`Note:
Loading a model from its configuration file does `),eue=n(cee,"STRONG",{});var K1t=s(eue);lZo=r(K1t,"not"),K1t.forEach(t),iZo=r(cee,` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=n(cee,"A",{href:!0});var Z1t=s(iz);dZo=r(Z1t,"from_pretrained()"),Z1t.forEach(t),cZo=r(cee," to load the model weights."),cee.forEach(t),fZo=i(m6),T(S5.$$.fragment,m6),m6.forEach(t),mZo=i(tl),co=n(tl,"DIV",{class:!0});var ha=s(co);T(EL.$$.fragment,ha),gZo=i(ha),oue=n(ha,"P",{});var ebt=s(oue);hZo=r(ebt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),ebt.forEach(t),pZo=i(ha),Ga=n(ha,"P",{});var g6=s(Ga);_Zo=r(g6,"The model class to instantiate is selected based on the "),rue=n(g6,"CODE",{});var obt=s(rue);uZo=r(obt,"model_type"),obt.forEach(t),bZo=r(g6,` property of the config object (either
passed as an argument or loaded from `),tue=n(g6,"CODE",{});var rbt=s(tue);vZo=r(rbt,"pretrained_model_name_or_path"),rbt.forEach(t),FZo=r(g6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aue=n(g6,"CODE",{});var tbt=s(aue);TZo=r(tbt,"pretrained_model_name_or_path"),tbt.forEach(t),MZo=r(g6,":"),g6.forEach(t),EZo=i(ha),Se=n(ha,"UL",{});var Ve=s(Se);R5=n(Ve,"LI",{});var Kke=s(R5);nue=n(Kke,"STRONG",{});var abt=s(nue);CZo=r(abt,"data2vec-audio"),abt.forEach(t),wZo=r(Kke," \u2014 "),dz=n(Kke,"A",{href:!0});var nbt=s(dz);AZo=r(nbt,"Data2VecAudioForSequenceClassification"),nbt.forEach(t),yZo=r(Kke," (Data2VecAudio model)"),Kke.forEach(t),LZo=i(Ve),P5=n(Ve,"LI",{});var Zke=s(P5);sue=n(Zke,"STRONG",{});var sbt=s(sue);xZo=r(sbt,"hubert"),sbt.forEach(t),$Zo=r(Zke," \u2014 "),cz=n(Zke,"A",{href:!0});var lbt=s(cz);kZo=r(lbt,"HubertForSequenceClassification"),lbt.forEach(t),SZo=r(Zke," (Hubert model)"),Zke.forEach(t),RZo=i(Ve),B5=n(Ve,"LI",{});var eSe=s(B5);lue=n(eSe,"STRONG",{});var ibt=s(lue);PZo=r(ibt,"sew"),ibt.forEach(t),BZo=r(eSe," \u2014 "),fz=n(eSe,"A",{href:!0});var dbt=s(fz);IZo=r(dbt,"SEWForSequenceClassification"),dbt.forEach(t),NZo=r(eSe," (SEW model)"),eSe.forEach(t),qZo=i(Ve),I5=n(Ve,"LI",{});var oSe=s(I5);iue=n(oSe,"STRONG",{});var cbt=s(iue);jZo=r(cbt,"sew-d"),cbt.forEach(t),DZo=r(oSe," \u2014 "),mz=n(oSe,"A",{href:!0});var fbt=s(mz);GZo=r(fbt,"SEWDForSequenceClassification"),fbt.forEach(t),OZo=r(oSe," (SEW-D model)"),oSe.forEach(t),VZo=i(Ve),N5=n(Ve,"LI",{});var rSe=s(N5);due=n(rSe,"STRONG",{});var mbt=s(due);XZo=r(mbt,"unispeech"),mbt.forEach(t),zZo=r(rSe," \u2014 "),gz=n(rSe,"A",{href:!0});var gbt=s(gz);WZo=r(gbt,"UniSpeechForSequenceClassification"),gbt.forEach(t),QZo=r(rSe," (UniSpeech model)"),rSe.forEach(t),HZo=i(Ve),q5=n(Ve,"LI",{});var tSe=s(q5);cue=n(tSe,"STRONG",{});var hbt=s(cue);UZo=r(hbt,"unispeech-sat"),hbt.forEach(t),JZo=r(tSe," \u2014 "),hz=n(tSe,"A",{href:!0});var pbt=s(hz);YZo=r(pbt,"UniSpeechSatForSequenceClassification"),pbt.forEach(t),KZo=r(tSe," (UniSpeechSat model)"),tSe.forEach(t),ZZo=i(Ve),j5=n(Ve,"LI",{});var aSe=s(j5);fue=n(aSe,"STRONG",{});var _bt=s(fue);eer=r(_bt,"wav2vec2"),_bt.forEach(t),oer=r(aSe," \u2014 "),pz=n(aSe,"A",{href:!0});var ubt=s(pz);rer=r(ubt,"Wav2Vec2ForSequenceClassification"),ubt.forEach(t),ter=r(aSe," (Wav2Vec2 model)"),aSe.forEach(t),aer=i(Ve),D5=n(Ve,"LI",{});var nSe=s(D5);mue=n(nSe,"STRONG",{});var bbt=s(mue);ner=r(bbt,"wav2vec2-conformer"),bbt.forEach(t),ser=r(nSe," \u2014 "),_z=n(nSe,"A",{href:!0});var vbt=s(_z);ler=r(vbt,"Wav2Vec2ConformerForSequenceClassification"),vbt.forEach(t),ier=r(nSe," (Wav2Vec2-Conformer model)"),nSe.forEach(t),der=i(Ve),G5=n(Ve,"LI",{});var sSe=s(G5);gue=n(sSe,"STRONG",{});var Fbt=s(gue);cer=r(Fbt,"wavlm"),Fbt.forEach(t),fer=r(sSe," \u2014 "),uz=n(sSe,"A",{href:!0});var Tbt=s(uz);mer=r(Tbt,"WavLMForSequenceClassification"),Tbt.forEach(t),ger=r(sSe," (WavLM model)"),sSe.forEach(t),Ve.forEach(t),her=i(ha),O5=n(ha,"P",{});var lSe=s(O5);per=r(lSe,"The model is set in evaluation mode by default using "),hue=n(lSe,"CODE",{});var Mbt=s(hue);_er=r(Mbt,"model.eval()"),Mbt.forEach(t),uer=r(lSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pue=n(lSe,"CODE",{});var Ebt=s(pue);ber=r(Ebt,"model.train()"),Ebt.forEach(t),lSe.forEach(t),ver=i(ha),T(V5.$$.fragment,ha),ha.forEach(t),tl.forEach(t),Eje=i(f),pd=n(f,"H2",{class:!0});var yGe=s(pd);X5=n(yGe,"A",{id:!0,class:!0,href:!0});var Cbt=s(X5);_ue=n(Cbt,"SPAN",{});var wbt=s(_ue);T(CL.$$.fragment,wbt),wbt.forEach(t),Cbt.forEach(t),Fer=i(yGe),uue=n(yGe,"SPAN",{});var Abt=s(uue);Ter=r(Abt,"AutoModelForAudioFrameClassification"),Abt.forEach(t),yGe.forEach(t),Cje=i(f),Oo=n(f,"DIV",{class:!0});var al=s(Oo);T(wL.$$.fragment,al),Mer=i(al),_d=n(al,"P",{});var fee=s(_d);Eer=r(fee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),bz=n(fee,"A",{href:!0});var ybt=s(bz);Cer=r(ybt,"from_pretrained()"),ybt.forEach(t),wer=r(fee," class method or the "),vz=n(fee,"A",{href:!0});var Lbt=s(vz);Aer=r(Lbt,"from_config()"),Lbt.forEach(t),yer=r(fee,` class
method.`),fee.forEach(t),Ler=i(al),AL=n(al,"P",{});var LGe=s(AL);xer=r(LGe,"This class cannot be instantiated directly using "),bue=n(LGe,"CODE",{});var xbt=s(bue);$er=r(xbt,"__init__()"),xbt.forEach(t),ker=r(LGe," (throws an error)."),LGe.forEach(t),Ser=i(al),bt=n(al,"DIV",{class:!0});var h6=s(bt);T(yL.$$.fragment,h6),Rer=i(h6),vue=n(h6,"P",{});var $bt=s(vue);Per=r($bt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),$bt.forEach(t),Ber=i(h6),ud=n(h6,"P",{});var mee=s(ud);Ier=r(mee,`Note:
Loading a model from its configuration file does `),Fue=n(mee,"STRONG",{});var kbt=s(Fue);Ner=r(kbt,"not"),kbt.forEach(t),qer=r(mee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(mee,"A",{href:!0});var Sbt=s(Fz);jer=r(Sbt,"from_pretrained()"),Sbt.forEach(t),Der=r(mee," to load the model weights."),mee.forEach(t),Ger=i(h6),T(z5.$$.fragment,h6),h6.forEach(t),Oer=i(al),fo=n(al,"DIV",{class:!0});var pa=s(fo);T(LL.$$.fragment,pa),Ver=i(pa),Tue=n(pa,"P",{});var Rbt=s(Tue);Xer=r(Rbt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Rbt.forEach(t),zer=i(pa),Oa=n(pa,"P",{});var p6=s(Oa);Wer=r(p6,"The model class to instantiate is selected based on the "),Mue=n(p6,"CODE",{});var Pbt=s(Mue);Qer=r(Pbt,"model_type"),Pbt.forEach(t),Her=r(p6,` property of the config object (either
passed as an argument or loaded from `),Eue=n(p6,"CODE",{});var Bbt=s(Eue);Uer=r(Bbt,"pretrained_model_name_or_path"),Bbt.forEach(t),Jer=r(p6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cue=n(p6,"CODE",{});var Ibt=s(Cue);Yer=r(Ibt,"pretrained_model_name_or_path"),Ibt.forEach(t),Ker=r(p6,":"),p6.forEach(t),Zer=i(pa),Kr=n(pa,"UL",{});var nl=s(Kr);W5=n(nl,"LI",{});var iSe=s(W5);wue=n(iSe,"STRONG",{});var Nbt=s(wue);eor=r(Nbt,"data2vec-audio"),Nbt.forEach(t),oor=r(iSe," \u2014 "),Tz=n(iSe,"A",{href:!0});var qbt=s(Tz);ror=r(qbt,"Data2VecAudioForAudioFrameClassification"),qbt.forEach(t),tor=r(iSe," (Data2VecAudio model)"),iSe.forEach(t),aor=i(nl),Q5=n(nl,"LI",{});var dSe=s(Q5);Aue=n(dSe,"STRONG",{});var jbt=s(Aue);nor=r(jbt,"unispeech-sat"),jbt.forEach(t),sor=r(dSe," \u2014 "),Mz=n(dSe,"A",{href:!0});var Dbt=s(Mz);lor=r(Dbt,"UniSpeechSatForAudioFrameClassification"),Dbt.forEach(t),ior=r(dSe," (UniSpeechSat model)"),dSe.forEach(t),dor=i(nl),H5=n(nl,"LI",{});var cSe=s(H5);yue=n(cSe,"STRONG",{});var Gbt=s(yue);cor=r(Gbt,"wav2vec2"),Gbt.forEach(t),mor=r(cSe," \u2014 "),Ez=n(cSe,"A",{href:!0});var Obt=s(Ez);gor=r(Obt,"Wav2Vec2ForAudioFrameClassification"),Obt.forEach(t),hor=r(cSe," (Wav2Vec2 model)"),cSe.forEach(t),por=i(nl),U5=n(nl,"LI",{});var fSe=s(U5);Lue=n(fSe,"STRONG",{});var Vbt=s(Lue);_or=r(Vbt,"wav2vec2-conformer"),Vbt.forEach(t),uor=r(fSe," \u2014 "),Cz=n(fSe,"A",{href:!0});var Xbt=s(Cz);bor=r(Xbt,"Wav2Vec2ConformerForAudioFrameClassification"),Xbt.forEach(t),vor=r(fSe," (Wav2Vec2-Conformer model)"),fSe.forEach(t),For=i(nl),J5=n(nl,"LI",{});var mSe=s(J5);xue=n(mSe,"STRONG",{});var zbt=s(xue);Tor=r(zbt,"wavlm"),zbt.forEach(t),Mor=r(mSe," \u2014 "),wz=n(mSe,"A",{href:!0});var Wbt=s(wz);Eor=r(Wbt,"WavLMForAudioFrameClassification"),Wbt.forEach(t),Cor=r(mSe," (WavLM model)"),mSe.forEach(t),nl.forEach(t),wor=i(pa),Y5=n(pa,"P",{});var gSe=s(Y5);Aor=r(gSe,"The model is set in evaluation mode by default using "),$ue=n(gSe,"CODE",{});var Qbt=s($ue);yor=r(Qbt,"model.eval()"),Qbt.forEach(t),Lor=r(gSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kue=n(gSe,"CODE",{});var Hbt=s(kue);xor=r(Hbt,"model.train()"),Hbt.forEach(t),gSe.forEach(t),$or=i(pa),T(K5.$$.fragment,pa),pa.forEach(t),al.forEach(t),wje=i(f),bd=n(f,"H2",{class:!0});var xGe=s(bd);Z5=n(xGe,"A",{id:!0,class:!0,href:!0});var Ubt=s(Z5);Sue=n(Ubt,"SPAN",{});var Jbt=s(Sue);T(xL.$$.fragment,Jbt),Jbt.forEach(t),Ubt.forEach(t),kor=i(xGe),Rue=n(xGe,"SPAN",{});var Ybt=s(Rue);Sor=r(Ybt,"AutoModelForCTC"),Ybt.forEach(t),xGe.forEach(t),Aje=i(f),Vo=n(f,"DIV",{class:!0});var sl=s(Vo);T($L.$$.fragment,sl),Ror=i(sl),vd=n(sl,"P",{});var gee=s(vd);Por=r(gee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Az=n(gee,"A",{href:!0});var Kbt=s(Az);Bor=r(Kbt,"from_pretrained()"),Kbt.forEach(t),Ior=r(gee," class method or the "),yz=n(gee,"A",{href:!0});var Zbt=s(yz);Nor=r(Zbt,"from_config()"),Zbt.forEach(t),qor=r(gee,` class
method.`),gee.forEach(t),jor=i(sl),kL=n(sl,"P",{});var $Ge=s(kL);Dor=r($Ge,"This class cannot be instantiated directly using "),Pue=n($Ge,"CODE",{});var e4t=s(Pue);Gor=r(e4t,"__init__()"),e4t.forEach(t),Oor=r($Ge," (throws an error)."),$Ge.forEach(t),Vor=i(sl),vt=n(sl,"DIV",{class:!0});var _6=s(vt);T(SL.$$.fragment,_6),Xor=i(_6),Bue=n(_6,"P",{});var o4t=s(Bue);zor=r(o4t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),o4t.forEach(t),Wor=i(_6),Fd=n(_6,"P",{});var hee=s(Fd);Qor=r(hee,`Note:
Loading a model from its configuration file does `),Iue=n(hee,"STRONG",{});var r4t=s(Iue);Hor=r(r4t,"not"),r4t.forEach(t),Uor=r(hee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=n(hee,"A",{href:!0});var t4t=s(Lz);Jor=r(t4t,"from_pretrained()"),t4t.forEach(t),Yor=r(hee," to load the model weights."),hee.forEach(t),Kor=i(_6),T(eF.$$.fragment,_6),_6.forEach(t),Zor=i(sl),mo=n(sl,"DIV",{class:!0});var _a=s(mo);T(RL.$$.fragment,_a),err=i(_a),Nue=n(_a,"P",{});var a4t=s(Nue);orr=r(a4t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),a4t.forEach(t),rrr=i(_a),Va=n(_a,"P",{});var u6=s(Va);trr=r(u6,"The model class to instantiate is selected based on the "),que=n(u6,"CODE",{});var n4t=s(que);arr=r(n4t,"model_type"),n4t.forEach(t),nrr=r(u6,` property of the config object (either
passed as an argument or loaded from `),jue=n(u6,"CODE",{});var s4t=s(jue);srr=r(s4t,"pretrained_model_name_or_path"),s4t.forEach(t),lrr=r(u6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Due=n(u6,"CODE",{});var l4t=s(Due);irr=r(l4t,"pretrained_model_name_or_path"),l4t.forEach(t),drr=r(u6,":"),u6.forEach(t),crr=i(_a),Re=n(_a,"UL",{});var Xe=s(Re);oF=n(Xe,"LI",{});var hSe=s(oF);Gue=n(hSe,"STRONG",{});var i4t=s(Gue);frr=r(i4t,"data2vec-audio"),i4t.forEach(t),mrr=r(hSe," \u2014 "),xz=n(hSe,"A",{href:!0});var d4t=s(xz);grr=r(d4t,"Data2VecAudioForCTC"),d4t.forEach(t),hrr=r(hSe," (Data2VecAudio model)"),hSe.forEach(t),prr=i(Xe),rF=n(Xe,"LI",{});var pSe=s(rF);Oue=n(pSe,"STRONG",{});var c4t=s(Oue);_rr=r(c4t,"hubert"),c4t.forEach(t),urr=r(pSe," \u2014 "),$z=n(pSe,"A",{href:!0});var f4t=s($z);brr=r(f4t,"HubertForCTC"),f4t.forEach(t),vrr=r(pSe," (Hubert model)"),pSe.forEach(t),Frr=i(Xe),tF=n(Xe,"LI",{});var _Se=s(tF);Vue=n(_Se,"STRONG",{});var m4t=s(Vue);Trr=r(m4t,"sew"),m4t.forEach(t),Mrr=r(_Se," \u2014 "),kz=n(_Se,"A",{href:!0});var g4t=s(kz);Err=r(g4t,"SEWForCTC"),g4t.forEach(t),Crr=r(_Se," (SEW model)"),_Se.forEach(t),wrr=i(Xe),aF=n(Xe,"LI",{});var uSe=s(aF);Xue=n(uSe,"STRONG",{});var h4t=s(Xue);Arr=r(h4t,"sew-d"),h4t.forEach(t),yrr=r(uSe," \u2014 "),Sz=n(uSe,"A",{href:!0});var p4t=s(Sz);Lrr=r(p4t,"SEWDForCTC"),p4t.forEach(t),xrr=r(uSe," (SEW-D model)"),uSe.forEach(t),$rr=i(Xe),nF=n(Xe,"LI",{});var bSe=s(nF);zue=n(bSe,"STRONG",{});var _4t=s(zue);krr=r(_4t,"unispeech"),_4t.forEach(t),Srr=r(bSe," \u2014 "),Rz=n(bSe,"A",{href:!0});var u4t=s(Rz);Rrr=r(u4t,"UniSpeechForCTC"),u4t.forEach(t),Prr=r(bSe," (UniSpeech model)"),bSe.forEach(t),Brr=i(Xe),sF=n(Xe,"LI",{});var vSe=s(sF);Wue=n(vSe,"STRONG",{});var b4t=s(Wue);Irr=r(b4t,"unispeech-sat"),b4t.forEach(t),Nrr=r(vSe," \u2014 "),Pz=n(vSe,"A",{href:!0});var v4t=s(Pz);qrr=r(v4t,"UniSpeechSatForCTC"),v4t.forEach(t),jrr=r(vSe," (UniSpeechSat model)"),vSe.forEach(t),Drr=i(Xe),lF=n(Xe,"LI",{});var FSe=s(lF);Que=n(FSe,"STRONG",{});var F4t=s(Que);Grr=r(F4t,"wav2vec2"),F4t.forEach(t),Orr=r(FSe," \u2014 "),Bz=n(FSe,"A",{href:!0});var T4t=s(Bz);Vrr=r(T4t,"Wav2Vec2ForCTC"),T4t.forEach(t),Xrr=r(FSe," (Wav2Vec2 model)"),FSe.forEach(t),zrr=i(Xe),iF=n(Xe,"LI",{});var TSe=s(iF);Hue=n(TSe,"STRONG",{});var M4t=s(Hue);Wrr=r(M4t,"wav2vec2-conformer"),M4t.forEach(t),Qrr=r(TSe," \u2014 "),Iz=n(TSe,"A",{href:!0});var E4t=s(Iz);Hrr=r(E4t,"Wav2Vec2ConformerForCTC"),E4t.forEach(t),Urr=r(TSe," (Wav2Vec2-Conformer model)"),TSe.forEach(t),Jrr=i(Xe),dF=n(Xe,"LI",{});var MSe=s(dF);Uue=n(MSe,"STRONG",{});var C4t=s(Uue);Yrr=r(C4t,"wavlm"),C4t.forEach(t),Krr=r(MSe," \u2014 "),Nz=n(MSe,"A",{href:!0});var w4t=s(Nz);Zrr=r(w4t,"WavLMForCTC"),w4t.forEach(t),etr=r(MSe," (WavLM model)"),MSe.forEach(t),Xe.forEach(t),otr=i(_a),cF=n(_a,"P",{});var ESe=s(cF);rtr=r(ESe,"The model is set in evaluation mode by default using "),Jue=n(ESe,"CODE",{});var A4t=s(Jue);ttr=r(A4t,"model.eval()"),A4t.forEach(t),atr=r(ESe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=n(ESe,"CODE",{});var y4t=s(Yue);ntr=r(y4t,"model.train()"),y4t.forEach(t),ESe.forEach(t),str=i(_a),T(fF.$$.fragment,_a),_a.forEach(t),sl.forEach(t),yje=i(f),Td=n(f,"H2",{class:!0});var kGe=s(Td);mF=n(kGe,"A",{id:!0,class:!0,href:!0});var L4t=s(mF);Kue=n(L4t,"SPAN",{});var x4t=s(Kue);T(PL.$$.fragment,x4t),x4t.forEach(t),L4t.forEach(t),ltr=i(kGe),Zue=n(kGe,"SPAN",{});var $4t=s(Zue);itr=r($4t,"AutoModelForSpeechSeq2Seq"),$4t.forEach(t),kGe.forEach(t),Lje=i(f),Xo=n(f,"DIV",{class:!0});var ll=s(Xo);T(BL.$$.fragment,ll),dtr=i(ll),Md=n(ll,"P",{});var pee=s(Md);ctr=r(pee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),qz=n(pee,"A",{href:!0});var k4t=s(qz);ftr=r(k4t,"from_pretrained()"),k4t.forEach(t),mtr=r(pee," class method or the "),jz=n(pee,"A",{href:!0});var S4t=s(jz);gtr=r(S4t,"from_config()"),S4t.forEach(t),htr=r(pee,` class
method.`),pee.forEach(t),ptr=i(ll),IL=n(ll,"P",{});var SGe=s(IL);_tr=r(SGe,"This class cannot be instantiated directly using "),e2e=n(SGe,"CODE",{});var R4t=s(e2e);utr=r(R4t,"__init__()"),R4t.forEach(t),btr=r(SGe," (throws an error)."),SGe.forEach(t),vtr=i(ll),Ft=n(ll,"DIV",{class:!0});var b6=s(Ft);T(NL.$$.fragment,b6),Ftr=i(b6),o2e=n(b6,"P",{});var P4t=s(o2e);Ttr=r(P4t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),P4t.forEach(t),Mtr=i(b6),Ed=n(b6,"P",{});var _ee=s(Ed);Etr=r(_ee,`Note:
Loading a model from its configuration file does `),r2e=n(_ee,"STRONG",{});var B4t=s(r2e);Ctr=r(B4t,"not"),B4t.forEach(t),wtr=r(_ee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dz=n(_ee,"A",{href:!0});var I4t=s(Dz);Atr=r(I4t,"from_pretrained()"),I4t.forEach(t),ytr=r(_ee," to load the model weights."),_ee.forEach(t),Ltr=i(b6),T(gF.$$.fragment,b6),b6.forEach(t),xtr=i(ll),go=n(ll,"DIV",{class:!0});var ua=s(go);T(qL.$$.fragment,ua),$tr=i(ua),t2e=n(ua,"P",{});var N4t=s(t2e);ktr=r(N4t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),N4t.forEach(t),Str=i(ua),Xa=n(ua,"P",{});var v6=s(Xa);Rtr=r(v6,"The model class to instantiate is selected based on the "),a2e=n(v6,"CODE",{});var q4t=s(a2e);Ptr=r(q4t,"model_type"),q4t.forEach(t),Btr=r(v6,` property of the config object (either
passed as an argument or loaded from `),n2e=n(v6,"CODE",{});var j4t=s(n2e);Itr=r(j4t,"pretrained_model_name_or_path"),j4t.forEach(t),Ntr=r(v6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s2e=n(v6,"CODE",{});var D4t=s(s2e);qtr=r(D4t,"pretrained_model_name_or_path"),D4t.forEach(t),jtr=r(v6,":"),v6.forEach(t),Dtr=i(ua),jL=n(ua,"UL",{});var RGe=s(jL);hF=n(RGe,"LI",{});var CSe=s(hF);l2e=n(CSe,"STRONG",{});var G4t=s(l2e);Gtr=r(G4t,"speech-encoder-decoder"),G4t.forEach(t),Otr=r(CSe," \u2014 "),Gz=n(CSe,"A",{href:!0});var O4t=s(Gz);Vtr=r(O4t,"SpeechEncoderDecoderModel"),O4t.forEach(t),Xtr=r(CSe," (Speech Encoder decoder model)"),CSe.forEach(t),ztr=i(RGe),pF=n(RGe,"LI",{});var wSe=s(pF);i2e=n(wSe,"STRONG",{});var V4t=s(i2e);Wtr=r(V4t,"speech_to_text"),V4t.forEach(t),Qtr=r(wSe," \u2014 "),Oz=n(wSe,"A",{href:!0});var X4t=s(Oz);Htr=r(X4t,"Speech2TextForConditionalGeneration"),X4t.forEach(t),Utr=r(wSe," (Speech2Text model)"),wSe.forEach(t),RGe.forEach(t),Jtr=i(ua),_F=n(ua,"P",{});var ASe=s(_F);Ytr=r(ASe,"The model is set in evaluation mode by default using "),d2e=n(ASe,"CODE",{});var z4t=s(d2e);Ktr=r(z4t,"model.eval()"),z4t.forEach(t),Ztr=r(ASe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c2e=n(ASe,"CODE",{});var W4t=s(c2e);ear=r(W4t,"model.train()"),W4t.forEach(t),ASe.forEach(t),oar=i(ua),T(uF.$$.fragment,ua),ua.forEach(t),ll.forEach(t),xje=i(f),Cd=n(f,"H2",{class:!0});var PGe=s(Cd);bF=n(PGe,"A",{id:!0,class:!0,href:!0});var Q4t=s(bF);f2e=n(Q4t,"SPAN",{});var H4t=s(f2e);T(DL.$$.fragment,H4t),H4t.forEach(t),Q4t.forEach(t),rar=i(PGe),m2e=n(PGe,"SPAN",{});var U4t=s(m2e);tar=r(U4t,"AutoModelForAudioXVector"),U4t.forEach(t),PGe.forEach(t),$je=i(f),zo=n(f,"DIV",{class:!0});var il=s(zo);T(GL.$$.fragment,il),aar=i(il),wd=n(il,"P",{});var uee=s(wd);nar=r(uee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Vz=n(uee,"A",{href:!0});var J4t=s(Vz);sar=r(J4t,"from_pretrained()"),J4t.forEach(t),lar=r(uee," class method or the "),Xz=n(uee,"A",{href:!0});var Y4t=s(Xz);iar=r(Y4t,"from_config()"),Y4t.forEach(t),dar=r(uee,` class
method.`),uee.forEach(t),car=i(il),OL=n(il,"P",{});var BGe=s(OL);far=r(BGe,"This class cannot be instantiated directly using "),g2e=n(BGe,"CODE",{});var K4t=s(g2e);mar=r(K4t,"__init__()"),K4t.forEach(t),gar=r(BGe," (throws an error)."),BGe.forEach(t),har=i(il),Tt=n(il,"DIV",{class:!0});var F6=s(Tt);T(VL.$$.fragment,F6),par=i(F6),h2e=n(F6,"P",{});var Z4t=s(h2e);_ar=r(Z4t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Z4t.forEach(t),uar=i(F6),Ad=n(F6,"P",{});var bee=s(Ad);bar=r(bee,`Note:
Loading a model from its configuration file does `),p2e=n(bee,"STRONG",{});var evt=s(p2e);Far=r(evt,"not"),evt.forEach(t),Tar=r(bee,` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=n(bee,"A",{href:!0});var ovt=s(zz);Mar=r(ovt,"from_pretrained()"),ovt.forEach(t),Ear=r(bee," to load the model weights."),bee.forEach(t),Car=i(F6),T(vF.$$.fragment,F6),F6.forEach(t),war=i(il),ho=n(il,"DIV",{class:!0});var ba=s(ho);T(XL.$$.fragment,ba),Aar=i(ba),_2e=n(ba,"P",{});var rvt=s(_2e);yar=r(rvt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),rvt.forEach(t),Lar=i(ba),za=n(ba,"P",{});var T6=s(za);xar=r(T6,"The model class to instantiate is selected based on the "),u2e=n(T6,"CODE",{});var tvt=s(u2e);$ar=r(tvt,"model_type"),tvt.forEach(t),kar=r(T6,` property of the config object (either
passed as an argument or loaded from `),b2e=n(T6,"CODE",{});var avt=s(b2e);Sar=r(avt,"pretrained_model_name_or_path"),avt.forEach(t),Rar=r(T6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v2e=n(T6,"CODE",{});var nvt=s(v2e);Par=r(nvt,"pretrained_model_name_or_path"),nvt.forEach(t),Bar=r(T6,":"),T6.forEach(t),Iar=i(ba),Zr=n(ba,"UL",{});var dl=s(Zr);FF=n(dl,"LI",{});var ySe=s(FF);F2e=n(ySe,"STRONG",{});var svt=s(F2e);Nar=r(svt,"data2vec-audio"),svt.forEach(t),qar=r(ySe," \u2014 "),Wz=n(ySe,"A",{href:!0});var lvt=s(Wz);jar=r(lvt,"Data2VecAudioForXVector"),lvt.forEach(t),Dar=r(ySe," (Data2VecAudio model)"),ySe.forEach(t),Gar=i(dl),TF=n(dl,"LI",{});var LSe=s(TF);T2e=n(LSe,"STRONG",{});var ivt=s(T2e);Oar=r(ivt,"unispeech-sat"),ivt.forEach(t),Var=r(LSe," \u2014 "),Qz=n(LSe,"A",{href:!0});var dvt=s(Qz);Xar=r(dvt,"UniSpeechSatForXVector"),dvt.forEach(t),zar=r(LSe," (UniSpeechSat model)"),LSe.forEach(t),War=i(dl),MF=n(dl,"LI",{});var xSe=s(MF);M2e=n(xSe,"STRONG",{});var cvt=s(M2e);Qar=r(cvt,"wav2vec2"),cvt.forEach(t),Har=r(xSe," \u2014 "),Hz=n(xSe,"A",{href:!0});var fvt=s(Hz);Uar=r(fvt,"Wav2Vec2ForXVector"),fvt.forEach(t),Jar=r(xSe," (Wav2Vec2 model)"),xSe.forEach(t),Yar=i(dl),EF=n(dl,"LI",{});var $Se=s(EF);E2e=n($Se,"STRONG",{});var mvt=s(E2e);Kar=r(mvt,"wav2vec2-conformer"),mvt.forEach(t),Zar=r($Se," \u2014 "),Uz=n($Se,"A",{href:!0});var gvt=s(Uz);enr=r(gvt,"Wav2Vec2ConformerForXVector"),gvt.forEach(t),onr=r($Se," (Wav2Vec2-Conformer model)"),$Se.forEach(t),rnr=i(dl),CF=n(dl,"LI",{});var kSe=s(CF);C2e=n(kSe,"STRONG",{});var hvt=s(C2e);tnr=r(hvt,"wavlm"),hvt.forEach(t),anr=r(kSe," \u2014 "),Jz=n(kSe,"A",{href:!0});var pvt=s(Jz);nnr=r(pvt,"WavLMForXVector"),pvt.forEach(t),snr=r(kSe," (WavLM model)"),kSe.forEach(t),dl.forEach(t),lnr=i(ba),wF=n(ba,"P",{});var SSe=s(wF);inr=r(SSe,"The model is set in evaluation mode by default using "),w2e=n(SSe,"CODE",{});var _vt=s(w2e);dnr=r(_vt,"model.eval()"),_vt.forEach(t),cnr=r(SSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A2e=n(SSe,"CODE",{});var uvt=s(A2e);fnr=r(uvt,"model.train()"),uvt.forEach(t),SSe.forEach(t),mnr=i(ba),T(AF.$$.fragment,ba),ba.forEach(t),il.forEach(t),kje=i(f),yd=n(f,"H2",{class:!0});var IGe=s(yd);yF=n(IGe,"A",{id:!0,class:!0,href:!0});var bvt=s(yF);y2e=n(bvt,"SPAN",{});var vvt=s(y2e);T(zL.$$.fragment,vvt),vvt.forEach(t),bvt.forEach(t),gnr=i(IGe),L2e=n(IGe,"SPAN",{});var Fvt=s(L2e);hnr=r(Fvt,"AutoModelForMaskedImageModeling"),Fvt.forEach(t),IGe.forEach(t),Sje=i(f),Wo=n(f,"DIV",{class:!0});var cl=s(Wo);T(WL.$$.fragment,cl),pnr=i(cl),Ld=n(cl,"P",{});var vee=s(Ld);_nr=r(vee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Yz=n(vee,"A",{href:!0});var Tvt=s(Yz);unr=r(Tvt,"from_pretrained()"),Tvt.forEach(t),bnr=r(vee," class method or the "),Kz=n(vee,"A",{href:!0});var Mvt=s(Kz);vnr=r(Mvt,"from_config()"),Mvt.forEach(t),Fnr=r(vee,` class
method.`),vee.forEach(t),Tnr=i(cl),QL=n(cl,"P",{});var NGe=s(QL);Mnr=r(NGe,"This class cannot be instantiated directly using "),x2e=n(NGe,"CODE",{});var Evt=s(x2e);Enr=r(Evt,"__init__()"),Evt.forEach(t),Cnr=r(NGe," (throws an error)."),NGe.forEach(t),wnr=i(cl),Mt=n(cl,"DIV",{class:!0});var M6=s(Mt);T(HL.$$.fragment,M6),Anr=i(M6),$2e=n(M6,"P",{});var Cvt=s($2e);ynr=r(Cvt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Cvt.forEach(t),Lnr=i(M6),xd=n(M6,"P",{});var Fee=s(xd);xnr=r(Fee,`Note:
Loading a model from its configuration file does `),k2e=n(Fee,"STRONG",{});var wvt=s(k2e);$nr=r(wvt,"not"),wvt.forEach(t),knr=r(Fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zz=n(Fee,"A",{href:!0});var Avt=s(Zz);Snr=r(Avt,"from_pretrained()"),Avt.forEach(t),Rnr=r(Fee," to load the model weights."),Fee.forEach(t),Pnr=i(M6),T(LF.$$.fragment,M6),M6.forEach(t),Bnr=i(cl),po=n(cl,"DIV",{class:!0});var va=s(po);T(UL.$$.fragment,va),Inr=i(va),S2e=n(va,"P",{});var yvt=s(S2e);Nnr=r(yvt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),yvt.forEach(t),qnr=i(va),Wa=n(va,"P",{});var E6=s(Wa);jnr=r(E6,"The model class to instantiate is selected based on the "),R2e=n(E6,"CODE",{});var Lvt=s(R2e);Dnr=r(Lvt,"model_type"),Lvt.forEach(t),Gnr=r(E6,` property of the config object (either
passed as an argument or loaded from `),P2e=n(E6,"CODE",{});var xvt=s(P2e);Onr=r(xvt,"pretrained_model_name_or_path"),xvt.forEach(t),Vnr=r(E6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B2e=n(E6,"CODE",{});var $vt=s(B2e);Xnr=r($vt,"pretrained_model_name_or_path"),$vt.forEach(t),znr=r(E6,":"),E6.forEach(t),Wnr=i(va),$d=n(va,"UL",{});var Tee=s($d);xF=n(Tee,"LI",{});var RSe=s(xF);I2e=n(RSe,"STRONG",{});var kvt=s(I2e);Qnr=r(kvt,"deit"),kvt.forEach(t),Hnr=r(RSe," \u2014 "),eW=n(RSe,"A",{href:!0});var Svt=s(eW);Unr=r(Svt,"DeiTForMaskedImageModeling"),Svt.forEach(t),Jnr=r(RSe," (DeiT model)"),RSe.forEach(t),Ynr=i(Tee),$F=n(Tee,"LI",{});var PSe=s($F);N2e=n(PSe,"STRONG",{});var Rvt=s(N2e);Knr=r(Rvt,"swin"),Rvt.forEach(t),Znr=r(PSe," \u2014 "),oW=n(PSe,"A",{href:!0});var Pvt=s(oW);esr=r(Pvt,"SwinForMaskedImageModeling"),Pvt.forEach(t),osr=r(PSe," (Swin model)"),PSe.forEach(t),rsr=i(Tee),kF=n(Tee,"LI",{});var BSe=s(kF);q2e=n(BSe,"STRONG",{});var Bvt=s(q2e);tsr=r(Bvt,"vit"),Bvt.forEach(t),asr=r(BSe," \u2014 "),rW=n(BSe,"A",{href:!0});var Ivt=s(rW);nsr=r(Ivt,"ViTForMaskedImageModeling"),Ivt.forEach(t),ssr=r(BSe," (ViT model)"),BSe.forEach(t),Tee.forEach(t),lsr=i(va),SF=n(va,"P",{});var ISe=s(SF);isr=r(ISe,"The model is set in evaluation mode by default using "),j2e=n(ISe,"CODE",{});var Nvt=s(j2e);dsr=r(Nvt,"model.eval()"),Nvt.forEach(t),csr=r(ISe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D2e=n(ISe,"CODE",{});var qvt=s(D2e);fsr=r(qvt,"model.train()"),qvt.forEach(t),ISe.forEach(t),msr=i(va),T(RF.$$.fragment,va),va.forEach(t),cl.forEach(t),Rje=i(f),kd=n(f,"H2",{class:!0});var qGe=s(kd);PF=n(qGe,"A",{id:!0,class:!0,href:!0});var jvt=s(PF);G2e=n(jvt,"SPAN",{});var Dvt=s(G2e);T(JL.$$.fragment,Dvt),Dvt.forEach(t),jvt.forEach(t),gsr=i(qGe),O2e=n(qGe,"SPAN",{});var Gvt=s(O2e);hsr=r(Gvt,"AutoModelForObjectDetection"),Gvt.forEach(t),qGe.forEach(t),Pje=i(f),Qo=n(f,"DIV",{class:!0});var fl=s(Qo);T(YL.$$.fragment,fl),psr=i(fl),Sd=n(fl,"P",{});var Mee=s(Sd);_sr=r(Mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),tW=n(Mee,"A",{href:!0});var Ovt=s(tW);usr=r(Ovt,"from_pretrained()"),Ovt.forEach(t),bsr=r(Mee," class method or the "),aW=n(Mee,"A",{href:!0});var Vvt=s(aW);vsr=r(Vvt,"from_config()"),Vvt.forEach(t),Fsr=r(Mee,` class
method.`),Mee.forEach(t),Tsr=i(fl),KL=n(fl,"P",{});var jGe=s(KL);Msr=r(jGe,"This class cannot be instantiated directly using "),V2e=n(jGe,"CODE",{});var Xvt=s(V2e);Esr=r(Xvt,"__init__()"),Xvt.forEach(t),Csr=r(jGe," (throws an error)."),jGe.forEach(t),wsr=i(fl),Et=n(fl,"DIV",{class:!0});var C6=s(Et);T(ZL.$$.fragment,C6),Asr=i(C6),X2e=n(C6,"P",{});var zvt=s(X2e);ysr=r(zvt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),zvt.forEach(t),Lsr=i(C6),Rd=n(C6,"P",{});var Eee=s(Rd);xsr=r(Eee,`Note:
Loading a model from its configuration file does `),z2e=n(Eee,"STRONG",{});var Wvt=s(z2e);$sr=r(Wvt,"not"),Wvt.forEach(t),ksr=r(Eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),nW=n(Eee,"A",{href:!0});var Qvt=s(nW);Ssr=r(Qvt,"from_pretrained()"),Qvt.forEach(t),Rsr=r(Eee," to load the model weights."),Eee.forEach(t),Psr=i(C6),T(BF.$$.fragment,C6),C6.forEach(t),Bsr=i(fl),_o=n(fl,"DIV",{class:!0});var Fa=s(_o);T(e8.$$.fragment,Fa),Isr=i(Fa),W2e=n(Fa,"P",{});var Hvt=s(W2e);Nsr=r(Hvt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Hvt.forEach(t),qsr=i(Fa),Qa=n(Fa,"P",{});var w6=s(Qa);jsr=r(w6,"The model class to instantiate is selected based on the "),Q2e=n(w6,"CODE",{});var Uvt=s(Q2e);Dsr=r(Uvt,"model_type"),Uvt.forEach(t),Gsr=r(w6,` property of the config object (either
passed as an argument or loaded from `),H2e=n(w6,"CODE",{});var Jvt=s(H2e);Osr=r(Jvt,"pretrained_model_name_or_path"),Jvt.forEach(t),Vsr=r(w6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=n(w6,"CODE",{});var Yvt=s(U2e);Xsr=r(Yvt,"pretrained_model_name_or_path"),Yvt.forEach(t),zsr=r(w6,":"),w6.forEach(t),Wsr=i(Fa),o8=n(Fa,"UL",{});var DGe=s(o8);IF=n(DGe,"LI",{});var NSe=s(IF);J2e=n(NSe,"STRONG",{});var Kvt=s(J2e);Qsr=r(Kvt,"detr"),Kvt.forEach(t),Hsr=r(NSe," \u2014 "),sW=n(NSe,"A",{href:!0});var Zvt=s(sW);Usr=r(Zvt,"DetrForObjectDetection"),Zvt.forEach(t),Jsr=r(NSe," (DETR model)"),NSe.forEach(t),Ysr=i(DGe),NF=n(DGe,"LI",{});var qSe=s(NF);Y2e=n(qSe,"STRONG",{});var e5t=s(Y2e);Ksr=r(e5t,"yolos"),e5t.forEach(t),Zsr=r(qSe," \u2014 "),lW=n(qSe,"A",{href:!0});var o5t=s(lW);elr=r(o5t,"YolosForObjectDetection"),o5t.forEach(t),olr=r(qSe," (YOLOS model)"),qSe.forEach(t),DGe.forEach(t),rlr=i(Fa),qF=n(Fa,"P",{});var jSe=s(qF);tlr=r(jSe,"The model is set in evaluation mode by default using "),K2e=n(jSe,"CODE",{});var r5t=s(K2e);alr=r(r5t,"model.eval()"),r5t.forEach(t),nlr=r(jSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z2e=n(jSe,"CODE",{});var t5t=s(Z2e);slr=r(t5t,"model.train()"),t5t.forEach(t),jSe.forEach(t),llr=i(Fa),T(jF.$$.fragment,Fa),Fa.forEach(t),fl.forEach(t),Bje=i(f),Pd=n(f,"H2",{class:!0});var GGe=s(Pd);DF=n(GGe,"A",{id:!0,class:!0,href:!0});var a5t=s(DF);e1e=n(a5t,"SPAN",{});var n5t=s(e1e);T(r8.$$.fragment,n5t),n5t.forEach(t),a5t.forEach(t),ilr=i(GGe),o1e=n(GGe,"SPAN",{});var s5t=s(o1e);dlr=r(s5t,"AutoModelForImageSegmentation"),s5t.forEach(t),GGe.forEach(t),Ije=i(f),Ho=n(f,"DIV",{class:!0});var ml=s(Ho);T(t8.$$.fragment,ml),clr=i(ml),Bd=n(ml,"P",{});var Cee=s(Bd);flr=r(Cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),iW=n(Cee,"A",{href:!0});var l5t=s(iW);mlr=r(l5t,"from_pretrained()"),l5t.forEach(t),glr=r(Cee," class method or the "),dW=n(Cee,"A",{href:!0});var i5t=s(dW);hlr=r(i5t,"from_config()"),i5t.forEach(t),plr=r(Cee,` class
method.`),Cee.forEach(t),_lr=i(ml),a8=n(ml,"P",{});var OGe=s(a8);ulr=r(OGe,"This class cannot be instantiated directly using "),r1e=n(OGe,"CODE",{});var d5t=s(r1e);blr=r(d5t,"__init__()"),d5t.forEach(t),vlr=r(OGe," (throws an error)."),OGe.forEach(t),Flr=i(ml),Ct=n(ml,"DIV",{class:!0});var A6=s(Ct);T(n8.$$.fragment,A6),Tlr=i(A6),t1e=n(A6,"P",{});var c5t=s(t1e);Mlr=r(c5t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),c5t.forEach(t),Elr=i(A6),Id=n(A6,"P",{});var wee=s(Id);Clr=r(wee,`Note:
Loading a model from its configuration file does `),a1e=n(wee,"STRONG",{});var f5t=s(a1e);wlr=r(f5t,"not"),f5t.forEach(t),Alr=r(wee,` load the model weights. It only affects the
model\u2019s configuration. Use `),cW=n(wee,"A",{href:!0});var m5t=s(cW);ylr=r(m5t,"from_pretrained()"),m5t.forEach(t),Llr=r(wee," to load the model weights."),wee.forEach(t),xlr=i(A6),T(GF.$$.fragment,A6),A6.forEach(t),$lr=i(ml),uo=n(ml,"DIV",{class:!0});var Ta=s(uo);T(s8.$$.fragment,Ta),klr=i(Ta),n1e=n(Ta,"P",{});var g5t=s(n1e);Slr=r(g5t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),g5t.forEach(t),Rlr=i(Ta),Ha=n(Ta,"P",{});var y6=s(Ha);Plr=r(y6,"The model class to instantiate is selected based on the "),s1e=n(y6,"CODE",{});var h5t=s(s1e);Blr=r(h5t,"model_type"),h5t.forEach(t),Ilr=r(y6,` property of the config object (either
passed as an argument or loaded from `),l1e=n(y6,"CODE",{});var p5t=s(l1e);Nlr=r(p5t,"pretrained_model_name_or_path"),p5t.forEach(t),qlr=r(y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i1e=n(y6,"CODE",{});var _5t=s(i1e);jlr=r(_5t,"pretrained_model_name_or_path"),_5t.forEach(t),Dlr=r(y6,":"),y6.forEach(t),Glr=i(Ta),d1e=n(Ta,"UL",{});var u5t=s(d1e);OF=n(u5t,"LI",{});var DSe=s(OF);c1e=n(DSe,"STRONG",{});var b5t=s(c1e);Olr=r(b5t,"detr"),b5t.forEach(t),Vlr=r(DSe," \u2014 "),fW=n(DSe,"A",{href:!0});var v5t=s(fW);Xlr=r(v5t,"DetrForSegmentation"),v5t.forEach(t),zlr=r(DSe," (DETR model)"),DSe.forEach(t),u5t.forEach(t),Wlr=i(Ta),VF=n(Ta,"P",{});var GSe=s(VF);Qlr=r(GSe,"The model is set in evaluation mode by default using "),f1e=n(GSe,"CODE",{});var F5t=s(f1e);Hlr=r(F5t,"model.eval()"),F5t.forEach(t),Ulr=r(GSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m1e=n(GSe,"CODE",{});var T5t=s(m1e);Jlr=r(T5t,"model.train()"),T5t.forEach(t),GSe.forEach(t),Ylr=i(Ta),T(XF.$$.fragment,Ta),Ta.forEach(t),ml.forEach(t),Nje=i(f),Nd=n(f,"H2",{class:!0});var VGe=s(Nd);zF=n(VGe,"A",{id:!0,class:!0,href:!0});var M5t=s(zF);g1e=n(M5t,"SPAN",{});var E5t=s(g1e);T(l8.$$.fragment,E5t),E5t.forEach(t),M5t.forEach(t),Klr=i(VGe),h1e=n(VGe,"SPAN",{});var C5t=s(h1e);Zlr=r(C5t,"AutoModelForSemanticSegmentation"),C5t.forEach(t),VGe.forEach(t),qje=i(f),Uo=n(f,"DIV",{class:!0});var gl=s(Uo);T(i8.$$.fragment,gl),eir=i(gl),qd=n(gl,"P",{});var Aee=s(qd);oir=r(Aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),mW=n(Aee,"A",{href:!0});var w5t=s(mW);rir=r(w5t,"from_pretrained()"),w5t.forEach(t),tir=r(Aee," class method or the "),gW=n(Aee,"A",{href:!0});var A5t=s(gW);air=r(A5t,"from_config()"),A5t.forEach(t),nir=r(Aee,` class
method.`),Aee.forEach(t),sir=i(gl),d8=n(gl,"P",{});var XGe=s(d8);lir=r(XGe,"This class cannot be instantiated directly using "),p1e=n(XGe,"CODE",{});var y5t=s(p1e);iir=r(y5t,"__init__()"),y5t.forEach(t),dir=r(XGe," (throws an error)."),XGe.forEach(t),cir=i(gl),wt=n(gl,"DIV",{class:!0});var L6=s(wt);T(c8.$$.fragment,L6),fir=i(L6),_1e=n(L6,"P",{});var L5t=s(_1e);mir=r(L5t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),L5t.forEach(t),gir=i(L6),jd=n(L6,"P",{});var yee=s(jd);hir=r(yee,`Note:
Loading a model from its configuration file does `),u1e=n(yee,"STRONG",{});var x5t=s(u1e);pir=r(x5t,"not"),x5t.forEach(t),_ir=r(yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),hW=n(yee,"A",{href:!0});var $5t=s(hW);uir=r($5t,"from_pretrained()"),$5t.forEach(t),bir=r(yee," to load the model weights."),yee.forEach(t),vir=i(L6),T(WF.$$.fragment,L6),L6.forEach(t),Fir=i(gl),bo=n(gl,"DIV",{class:!0});var Ma=s(bo);T(f8.$$.fragment,Ma),Tir=i(Ma),b1e=n(Ma,"P",{});var k5t=s(b1e);Mir=r(k5t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),k5t.forEach(t),Eir=i(Ma),Ua=n(Ma,"P",{});var x6=s(Ua);Cir=r(x6,"The model class to instantiate is selected based on the "),v1e=n(x6,"CODE",{});var S5t=s(v1e);wir=r(S5t,"model_type"),S5t.forEach(t),Air=r(x6,` property of the config object (either
passed as an argument or loaded from `),F1e=n(x6,"CODE",{});var R5t=s(F1e);yir=r(R5t,"pretrained_model_name_or_path"),R5t.forEach(t),Lir=r(x6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T1e=n(x6,"CODE",{});var P5t=s(T1e);xir=r(P5t,"pretrained_model_name_or_path"),P5t.forEach(t),$ir=r(x6,":"),x6.forEach(t),kir=i(Ma),Ja=n(Ma,"UL",{});var $6=s(Ja);QF=n($6,"LI",{});var OSe=s(QF);M1e=n(OSe,"STRONG",{});var B5t=s(M1e);Sir=r(B5t,"beit"),B5t.forEach(t),Rir=r(OSe," \u2014 "),pW=n(OSe,"A",{href:!0});var I5t=s(pW);Pir=r(I5t,"BeitForSemanticSegmentation"),I5t.forEach(t),Bir=r(OSe," (BEiT model)"),OSe.forEach(t),Iir=i($6),HF=n($6,"LI",{});var VSe=s(HF);E1e=n(VSe,"STRONG",{});var N5t=s(E1e);Nir=r(N5t,"data2vec-vision"),N5t.forEach(t),qir=r(VSe," \u2014 "),_W=n(VSe,"A",{href:!0});var q5t=s(_W);jir=r(q5t,"Data2VecVisionForSemanticSegmentation"),q5t.forEach(t),Dir=r(VSe," (Data2VecVision model)"),VSe.forEach(t),Gir=i($6),UF=n($6,"LI",{});var XSe=s(UF);C1e=n(XSe,"STRONG",{});var j5t=s(C1e);Oir=r(j5t,"dpt"),j5t.forEach(t),Vir=r(XSe," \u2014 "),uW=n(XSe,"A",{href:!0});var D5t=s(uW);Xir=r(D5t,"DPTForSemanticSegmentation"),D5t.forEach(t),zir=r(XSe," (DPT model)"),XSe.forEach(t),Wir=i($6),JF=n($6,"LI",{});var zSe=s(JF);w1e=n(zSe,"STRONG",{});var G5t=s(w1e);Qir=r(G5t,"segformer"),G5t.forEach(t),Hir=r(zSe," \u2014 "),bW=n(zSe,"A",{href:!0});var O5t=s(bW);Uir=r(O5t,"SegformerForSemanticSegmentation"),O5t.forEach(t),Jir=r(zSe," (SegFormer model)"),zSe.forEach(t),$6.forEach(t),Yir=i(Ma),YF=n(Ma,"P",{});var WSe=s(YF);Kir=r(WSe,"The model is set in evaluation mode by default using "),A1e=n(WSe,"CODE",{});var V5t=s(A1e);Zir=r(V5t,"model.eval()"),V5t.forEach(t),edr=r(WSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y1e=n(WSe,"CODE",{});var X5t=s(y1e);odr=r(X5t,"model.train()"),X5t.forEach(t),WSe.forEach(t),rdr=i(Ma),T(KF.$$.fragment,Ma),Ma.forEach(t),gl.forEach(t),jje=i(f),Dd=n(f,"H2",{class:!0});var zGe=s(Dd);ZF=n(zGe,"A",{id:!0,class:!0,href:!0});var z5t=s(ZF);L1e=n(z5t,"SPAN",{});var W5t=s(L1e);T(m8.$$.fragment,W5t),W5t.forEach(t),z5t.forEach(t),tdr=i(zGe),x1e=n(zGe,"SPAN",{});var Q5t=s(x1e);adr=r(Q5t,"AutoModelForInstanceSegmentation"),Q5t.forEach(t),zGe.forEach(t),Dje=i(f),Jo=n(f,"DIV",{class:!0});var hl=s(Jo);T(g8.$$.fragment,hl),ndr=i(hl),Gd=n(hl,"P",{});var Lee=s(Gd);sdr=r(Lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),vW=n(Lee,"A",{href:!0});var H5t=s(vW);ldr=r(H5t,"from_pretrained()"),H5t.forEach(t),idr=r(Lee," class method or the "),FW=n(Lee,"A",{href:!0});var U5t=s(FW);ddr=r(U5t,"from_config()"),U5t.forEach(t),cdr=r(Lee,` class
method.`),Lee.forEach(t),fdr=i(hl),h8=n(hl,"P",{});var WGe=s(h8);mdr=r(WGe,"This class cannot be instantiated directly using "),$1e=n(WGe,"CODE",{});var J5t=s($1e);gdr=r(J5t,"__init__()"),J5t.forEach(t),hdr=r(WGe," (throws an error)."),WGe.forEach(t),pdr=i(hl),At=n(hl,"DIV",{class:!0});var k6=s(At);T(p8.$$.fragment,k6),_dr=i(k6),k1e=n(k6,"P",{});var Y5t=s(k1e);udr=r(Y5t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Y5t.forEach(t),bdr=i(k6),Od=n(k6,"P",{});var xee=s(Od);vdr=r(xee,`Note:
Loading a model from its configuration file does `),S1e=n(xee,"STRONG",{});var K5t=s(S1e);Fdr=r(K5t,"not"),K5t.forEach(t),Tdr=r(xee,` load the model weights. It only affects the
model\u2019s configuration. Use `),TW=n(xee,"A",{href:!0});var Z5t=s(TW);Mdr=r(Z5t,"from_pretrained()"),Z5t.forEach(t),Edr=r(xee," to load the model weights."),xee.forEach(t),Cdr=i(k6),T(eT.$$.fragment,k6),k6.forEach(t),wdr=i(hl),vo=n(hl,"DIV",{class:!0});var Ea=s(vo);T(_8.$$.fragment,Ea),Adr=i(Ea),R1e=n(Ea,"P",{});var eFt=s(R1e);ydr=r(eFt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),eFt.forEach(t),Ldr=i(Ea),Ya=n(Ea,"P",{});var S6=s(Ya);xdr=r(S6,"The model class to instantiate is selected based on the "),P1e=n(S6,"CODE",{});var oFt=s(P1e);$dr=r(oFt,"model_type"),oFt.forEach(t),kdr=r(S6,` property of the config object (either
passed as an argument or loaded from `),B1e=n(S6,"CODE",{});var rFt=s(B1e);Sdr=r(rFt,"pretrained_model_name_or_path"),rFt.forEach(t),Rdr=r(S6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=n(S6,"CODE",{});var tFt=s(I1e);Pdr=r(tFt,"pretrained_model_name_or_path"),tFt.forEach(t),Bdr=r(S6,":"),S6.forEach(t),Idr=i(Ea),N1e=n(Ea,"UL",{});var aFt=s(N1e);oT=n(aFt,"LI",{});var QSe=s(oT);q1e=n(QSe,"STRONG",{});var nFt=s(q1e);Ndr=r(nFt,"maskformer"),nFt.forEach(t),qdr=r(QSe," \u2014 "),MW=n(QSe,"A",{href:!0});var sFt=s(MW);jdr=r(sFt,"MaskFormerForInstanceSegmentation"),sFt.forEach(t),Ddr=r(QSe," (MaskFormer model)"),QSe.forEach(t),aFt.forEach(t),Gdr=i(Ea),rT=n(Ea,"P",{});var HSe=s(rT);Odr=r(HSe,"The model is set in evaluation mode by default using "),j1e=n(HSe,"CODE",{});var lFt=s(j1e);Vdr=r(lFt,"model.eval()"),lFt.forEach(t),Xdr=r(HSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D1e=n(HSe,"CODE",{});var iFt=s(D1e);zdr=r(iFt,"model.train()"),iFt.forEach(t),HSe.forEach(t),Wdr=i(Ea),T(tT.$$.fragment,Ea),Ea.forEach(t),hl.forEach(t),Gje=i(f),Vd=n(f,"H2",{class:!0});var QGe=s(Vd);aT=n(QGe,"A",{id:!0,class:!0,href:!0});var dFt=s(aT);G1e=n(dFt,"SPAN",{});var cFt=s(G1e);T(u8.$$.fragment,cFt),cFt.forEach(t),dFt.forEach(t),Qdr=i(QGe),O1e=n(QGe,"SPAN",{});var fFt=s(O1e);Hdr=r(fFt,"TFAutoModel"),fFt.forEach(t),QGe.forEach(t),Oje=i(f),Yo=n(f,"DIV",{class:!0});var pl=s(Yo);T(b8.$$.fragment,pl),Udr=i(pl),Xd=n(pl,"P",{});var $ee=s(Xd);Jdr=r($ee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),EW=n($ee,"A",{href:!0});var mFt=s(EW);Ydr=r(mFt,"from_pretrained()"),mFt.forEach(t),Kdr=r($ee," class method or the "),CW=n($ee,"A",{href:!0});var gFt=s(CW);Zdr=r(gFt,"from_config()"),gFt.forEach(t),ecr=r($ee,` class
method.`),$ee.forEach(t),ocr=i(pl),v8=n(pl,"P",{});var HGe=s(v8);rcr=r(HGe,"This class cannot be instantiated directly using "),V1e=n(HGe,"CODE",{});var hFt=s(V1e);tcr=r(hFt,"__init__()"),hFt.forEach(t),acr=r(HGe," (throws an error)."),HGe.forEach(t),ncr=i(pl),yt=n(pl,"DIV",{class:!0});var R6=s(yt);T(F8.$$.fragment,R6),scr=i(R6),X1e=n(R6,"P",{});var pFt=s(X1e);lcr=r(pFt,"Instantiates one of the base model classes of the library from a configuration."),pFt.forEach(t),icr=i(R6),zd=n(R6,"P",{});var kee=s(zd);dcr=r(kee,`Note:
Loading a model from its configuration file does `),z1e=n(kee,"STRONG",{});var _Ft=s(z1e);ccr=r(_Ft,"not"),_Ft.forEach(t),fcr=r(kee,` load the model weights. It only affects the
model\u2019s configuration. Use `),wW=n(kee,"A",{href:!0});var uFt=s(wW);mcr=r(uFt,"from_pretrained()"),uFt.forEach(t),gcr=r(kee," to load the model weights."),kee.forEach(t),hcr=i(R6),T(nT.$$.fragment,R6),R6.forEach(t),pcr=i(pl),wr=n(pl,"DIV",{class:!0});var _l=s(wr);T(T8.$$.fragment,_l),_cr=i(_l),W1e=n(_l,"P",{});var bFt=s(W1e);ucr=r(bFt,"Instantiate one of the base model classes of the library from a pretrained model."),bFt.forEach(t),bcr=i(_l),Ka=n(_l,"P",{});var P6=s(Ka);vcr=r(P6,"The model class to instantiate is selected based on the "),Q1e=n(P6,"CODE",{});var vFt=s(Q1e);Fcr=r(vFt,"model_type"),vFt.forEach(t),Tcr=r(P6,` property of the config object (either
passed as an argument or loaded from `),H1e=n(P6,"CODE",{});var FFt=s(H1e);Mcr=r(FFt,"pretrained_model_name_or_path"),FFt.forEach(t),Ecr=r(P6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=n(P6,"CODE",{});var TFt=s(U1e);Ccr=r(TFt,"pretrained_model_name_or_path"),TFt.forEach(t),wcr=r(P6,":"),P6.forEach(t),Acr=i(_l),q=n(_l,"UL",{});var D=s(q);sT=n(D,"LI",{});var USe=s(sT);J1e=n(USe,"STRONG",{});var MFt=s(J1e);ycr=r(MFt,"albert"),MFt.forEach(t),Lcr=r(USe," \u2014 "),AW=n(USe,"A",{href:!0});var EFt=s(AW);xcr=r(EFt,"TFAlbertModel"),EFt.forEach(t),$cr=r(USe," (ALBERT model)"),USe.forEach(t),kcr=i(D),lT=n(D,"LI",{});var JSe=s(lT);Y1e=n(JSe,"STRONG",{});var CFt=s(Y1e);Scr=r(CFt,"bart"),CFt.forEach(t),Rcr=r(JSe," \u2014 "),yW=n(JSe,"A",{href:!0});var wFt=s(yW);Pcr=r(wFt,"TFBartModel"),wFt.forEach(t),Bcr=r(JSe," (BART model)"),JSe.forEach(t),Icr=i(D),iT=n(D,"LI",{});var YSe=s(iT);K1e=n(YSe,"STRONG",{});var AFt=s(K1e);Ncr=r(AFt,"bert"),AFt.forEach(t),qcr=r(YSe," \u2014 "),LW=n(YSe,"A",{href:!0});var yFt=s(LW);jcr=r(yFt,"TFBertModel"),yFt.forEach(t),Dcr=r(YSe," (BERT model)"),YSe.forEach(t),Gcr=i(D),dT=n(D,"LI",{});var KSe=s(dT);Z1e=n(KSe,"STRONG",{});var LFt=s(Z1e);Ocr=r(LFt,"blenderbot"),LFt.forEach(t),Vcr=r(KSe," \u2014 "),xW=n(KSe,"A",{href:!0});var xFt=s(xW);Xcr=r(xFt,"TFBlenderbotModel"),xFt.forEach(t),zcr=r(KSe," (Blenderbot model)"),KSe.forEach(t),Wcr=i(D),cT=n(D,"LI",{});var ZSe=s(cT);ebe=n(ZSe,"STRONG",{});var $Ft=s(ebe);Qcr=r($Ft,"blenderbot-small"),$Ft.forEach(t),Hcr=r(ZSe," \u2014 "),$W=n(ZSe,"A",{href:!0});var kFt=s($W);Ucr=r(kFt,"TFBlenderbotSmallModel"),kFt.forEach(t),Jcr=r(ZSe," (BlenderbotSmall model)"),ZSe.forEach(t),Ycr=i(D),fT=n(D,"LI",{});var eRe=s(fT);obe=n(eRe,"STRONG",{});var SFt=s(obe);Kcr=r(SFt,"camembert"),SFt.forEach(t),Zcr=r(eRe," \u2014 "),kW=n(eRe,"A",{href:!0});var RFt=s(kW);efr=r(RFt,"TFCamembertModel"),RFt.forEach(t),ofr=r(eRe," (CamemBERT model)"),eRe.forEach(t),rfr=i(D),mT=n(D,"LI",{});var oRe=s(mT);rbe=n(oRe,"STRONG",{});var PFt=s(rbe);tfr=r(PFt,"clip"),PFt.forEach(t),afr=r(oRe," \u2014 "),SW=n(oRe,"A",{href:!0});var BFt=s(SW);nfr=r(BFt,"TFCLIPModel"),BFt.forEach(t),sfr=r(oRe," (CLIP model)"),oRe.forEach(t),lfr=i(D),gT=n(D,"LI",{});var rRe=s(gT);tbe=n(rRe,"STRONG",{});var IFt=s(tbe);ifr=r(IFt,"convbert"),IFt.forEach(t),dfr=r(rRe," \u2014 "),RW=n(rRe,"A",{href:!0});var NFt=s(RW);cfr=r(NFt,"TFConvBertModel"),NFt.forEach(t),ffr=r(rRe," (ConvBERT model)"),rRe.forEach(t),mfr=i(D),hT=n(D,"LI",{});var tRe=s(hT);abe=n(tRe,"STRONG",{});var qFt=s(abe);gfr=r(qFt,"convnext"),qFt.forEach(t),hfr=r(tRe," \u2014 "),PW=n(tRe,"A",{href:!0});var jFt=s(PW);pfr=r(jFt,"TFConvNextModel"),jFt.forEach(t),_fr=r(tRe," (ConvNext model)"),tRe.forEach(t),ufr=i(D),pT=n(D,"LI",{});var aRe=s(pT);nbe=n(aRe,"STRONG",{});var DFt=s(nbe);bfr=r(DFt,"ctrl"),DFt.forEach(t),vfr=r(aRe," \u2014 "),BW=n(aRe,"A",{href:!0});var GFt=s(BW);Ffr=r(GFt,"TFCTRLModel"),GFt.forEach(t),Tfr=r(aRe," (CTRL model)"),aRe.forEach(t),Mfr=i(D),_T=n(D,"LI",{});var nRe=s(_T);sbe=n(nRe,"STRONG",{});var OFt=s(sbe);Efr=r(OFt,"data2vec-vision"),OFt.forEach(t),Cfr=r(nRe," \u2014 "),IW=n(nRe,"A",{href:!0});var VFt=s(IW);wfr=r(VFt,"TFData2VecVisionModel"),VFt.forEach(t),Afr=r(nRe," (Data2VecVision model)"),nRe.forEach(t),yfr=i(D),uT=n(D,"LI",{});var sRe=s(uT);lbe=n(sRe,"STRONG",{});var XFt=s(lbe);Lfr=r(XFt,"deberta"),XFt.forEach(t),xfr=r(sRe," \u2014 "),NW=n(sRe,"A",{href:!0});var zFt=s(NW);$fr=r(zFt,"TFDebertaModel"),zFt.forEach(t),kfr=r(sRe," (DeBERTa model)"),sRe.forEach(t),Sfr=i(D),bT=n(D,"LI",{});var lRe=s(bT);ibe=n(lRe,"STRONG",{});var WFt=s(ibe);Rfr=r(WFt,"deberta-v2"),WFt.forEach(t),Pfr=r(lRe," \u2014 "),qW=n(lRe,"A",{href:!0});var QFt=s(qW);Bfr=r(QFt,"TFDebertaV2Model"),QFt.forEach(t),Ifr=r(lRe," (DeBERTa-v2 model)"),lRe.forEach(t),Nfr=i(D),vT=n(D,"LI",{});var iRe=s(vT);dbe=n(iRe,"STRONG",{});var HFt=s(dbe);qfr=r(HFt,"distilbert"),HFt.forEach(t),jfr=r(iRe," \u2014 "),jW=n(iRe,"A",{href:!0});var UFt=s(jW);Dfr=r(UFt,"TFDistilBertModel"),UFt.forEach(t),Gfr=r(iRe," (DistilBERT model)"),iRe.forEach(t),Ofr=i(D),FT=n(D,"LI",{});var dRe=s(FT);cbe=n(dRe,"STRONG",{});var JFt=s(cbe);Vfr=r(JFt,"dpr"),JFt.forEach(t),Xfr=r(dRe," \u2014 "),DW=n(dRe,"A",{href:!0});var YFt=s(DW);zfr=r(YFt,"TFDPRQuestionEncoder"),YFt.forEach(t),Wfr=r(dRe," (DPR model)"),dRe.forEach(t),Qfr=i(D),TT=n(D,"LI",{});var cRe=s(TT);fbe=n(cRe,"STRONG",{});var KFt=s(fbe);Hfr=r(KFt,"electra"),KFt.forEach(t),Ufr=r(cRe," \u2014 "),GW=n(cRe,"A",{href:!0});var ZFt=s(GW);Jfr=r(ZFt,"TFElectraModel"),ZFt.forEach(t),Yfr=r(cRe," (ELECTRA model)"),cRe.forEach(t),Kfr=i(D),MT=n(D,"LI",{});var fRe=s(MT);mbe=n(fRe,"STRONG",{});var eTt=s(mbe);Zfr=r(eTt,"flaubert"),eTt.forEach(t),emr=r(fRe," \u2014 "),OW=n(fRe,"A",{href:!0});var oTt=s(OW);omr=r(oTt,"TFFlaubertModel"),oTt.forEach(t),rmr=r(fRe," (FlauBERT model)"),fRe.forEach(t),tmr=i(D),qs=n(D,"LI",{});var ok=s(qs);gbe=n(ok,"STRONG",{});var rTt=s(gbe);amr=r(rTt,"funnel"),rTt.forEach(t),nmr=r(ok," \u2014 "),VW=n(ok,"A",{href:!0});var tTt=s(VW);smr=r(tTt,"TFFunnelModel"),tTt.forEach(t),lmr=r(ok," or "),XW=n(ok,"A",{href:!0});var aTt=s(XW);imr=r(aTt,"TFFunnelBaseModel"),aTt.forEach(t),dmr=r(ok," (Funnel Transformer model)"),ok.forEach(t),cmr=i(D),ET=n(D,"LI",{});var mRe=s(ET);hbe=n(mRe,"STRONG",{});var nTt=s(hbe);fmr=r(nTt,"gpt2"),nTt.forEach(t),mmr=r(mRe," \u2014 "),zW=n(mRe,"A",{href:!0});var sTt=s(zW);gmr=r(sTt,"TFGPT2Model"),sTt.forEach(t),hmr=r(mRe," (OpenAI GPT-2 model)"),mRe.forEach(t),pmr=i(D),CT=n(D,"LI",{});var gRe=s(CT);pbe=n(gRe,"STRONG",{});var lTt=s(pbe);_mr=r(lTt,"gptj"),lTt.forEach(t),umr=r(gRe," \u2014 "),WW=n(gRe,"A",{href:!0});var iTt=s(WW);bmr=r(iTt,"TFGPTJModel"),iTt.forEach(t),vmr=r(gRe," (GPT-J model)"),gRe.forEach(t),Fmr=i(D),wT=n(D,"LI",{});var hRe=s(wT);_be=n(hRe,"STRONG",{});var dTt=s(_be);Tmr=r(dTt,"hubert"),dTt.forEach(t),Mmr=r(hRe," \u2014 "),QW=n(hRe,"A",{href:!0});var cTt=s(QW);Emr=r(cTt,"TFHubertModel"),cTt.forEach(t),Cmr=r(hRe," (Hubert model)"),hRe.forEach(t),wmr=i(D),AT=n(D,"LI",{});var pRe=s(AT);ube=n(pRe,"STRONG",{});var fTt=s(ube);Amr=r(fTt,"layoutlm"),fTt.forEach(t),ymr=r(pRe," \u2014 "),HW=n(pRe,"A",{href:!0});var mTt=s(HW);Lmr=r(mTt,"TFLayoutLMModel"),mTt.forEach(t),xmr=r(pRe," (LayoutLM model)"),pRe.forEach(t),$mr=i(D),yT=n(D,"LI",{});var _Re=s(yT);bbe=n(_Re,"STRONG",{});var gTt=s(bbe);kmr=r(gTt,"led"),gTt.forEach(t),Smr=r(_Re," \u2014 "),UW=n(_Re,"A",{href:!0});var hTt=s(UW);Rmr=r(hTt,"TFLEDModel"),hTt.forEach(t),Pmr=r(_Re," (LED model)"),_Re.forEach(t),Bmr=i(D),LT=n(D,"LI",{});var uRe=s(LT);vbe=n(uRe,"STRONG",{});var pTt=s(vbe);Imr=r(pTt,"longformer"),pTt.forEach(t),Nmr=r(uRe," \u2014 "),JW=n(uRe,"A",{href:!0});var _Tt=s(JW);qmr=r(_Tt,"TFLongformerModel"),_Tt.forEach(t),jmr=r(uRe," (Longformer model)"),uRe.forEach(t),Dmr=i(D),xT=n(D,"LI",{});var bRe=s(xT);Fbe=n(bRe,"STRONG",{});var uTt=s(Fbe);Gmr=r(uTt,"lxmert"),uTt.forEach(t),Omr=r(bRe," \u2014 "),YW=n(bRe,"A",{href:!0});var bTt=s(YW);Vmr=r(bTt,"TFLxmertModel"),bTt.forEach(t),Xmr=r(bRe," (LXMERT model)"),bRe.forEach(t),zmr=i(D),$T=n(D,"LI",{});var vRe=s($T);Tbe=n(vRe,"STRONG",{});var vTt=s(Tbe);Wmr=r(vTt,"marian"),vTt.forEach(t),Qmr=r(vRe," \u2014 "),KW=n(vRe,"A",{href:!0});var FTt=s(KW);Hmr=r(FTt,"TFMarianModel"),FTt.forEach(t),Umr=r(vRe," (Marian model)"),vRe.forEach(t),Jmr=i(D),kT=n(D,"LI",{});var FRe=s(kT);Mbe=n(FRe,"STRONG",{});var TTt=s(Mbe);Ymr=r(TTt,"mbart"),TTt.forEach(t),Kmr=r(FRe," \u2014 "),ZW=n(FRe,"A",{href:!0});var MTt=s(ZW);Zmr=r(MTt,"TFMBartModel"),MTt.forEach(t),egr=r(FRe," (mBART model)"),FRe.forEach(t),ogr=i(D),ST=n(D,"LI",{});var TRe=s(ST);Ebe=n(TRe,"STRONG",{});var ETt=s(Ebe);rgr=r(ETt,"mobilebert"),ETt.forEach(t),tgr=r(TRe," \u2014 "),eQ=n(TRe,"A",{href:!0});var CTt=s(eQ);agr=r(CTt,"TFMobileBertModel"),CTt.forEach(t),ngr=r(TRe," (MobileBERT model)"),TRe.forEach(t),sgr=i(D),RT=n(D,"LI",{});var MRe=s(RT);Cbe=n(MRe,"STRONG",{});var wTt=s(Cbe);lgr=r(wTt,"mpnet"),wTt.forEach(t),igr=r(MRe," \u2014 "),oQ=n(MRe,"A",{href:!0});var ATt=s(oQ);dgr=r(ATt,"TFMPNetModel"),ATt.forEach(t),cgr=r(MRe," (MPNet model)"),MRe.forEach(t),fgr=i(D),PT=n(D,"LI",{});var ERe=s(PT);wbe=n(ERe,"STRONG",{});var yTt=s(wbe);mgr=r(yTt,"mt5"),yTt.forEach(t),ggr=r(ERe," \u2014 "),rQ=n(ERe,"A",{href:!0});var LTt=s(rQ);hgr=r(LTt,"TFMT5Model"),LTt.forEach(t),pgr=r(ERe," (mT5 model)"),ERe.forEach(t),_gr=i(D),BT=n(D,"LI",{});var CRe=s(BT);Abe=n(CRe,"STRONG",{});var xTt=s(Abe);ugr=r(xTt,"openai-gpt"),xTt.forEach(t),bgr=r(CRe," \u2014 "),tQ=n(CRe,"A",{href:!0});var $Tt=s(tQ);vgr=r($Tt,"TFOpenAIGPTModel"),$Tt.forEach(t),Fgr=r(CRe," (OpenAI GPT model)"),CRe.forEach(t),Tgr=i(D),IT=n(D,"LI",{});var wRe=s(IT);ybe=n(wRe,"STRONG",{});var kTt=s(ybe);Mgr=r(kTt,"opt"),kTt.forEach(t),Egr=r(wRe," \u2014 "),aQ=n(wRe,"A",{href:!0});var STt=s(aQ);Cgr=r(STt,"TFOPTModel"),STt.forEach(t),wgr=r(wRe," (OPT model)"),wRe.forEach(t),Agr=i(D),NT=n(D,"LI",{});var ARe=s(NT);Lbe=n(ARe,"STRONG",{});var RTt=s(Lbe);ygr=r(RTt,"pegasus"),RTt.forEach(t),Lgr=r(ARe," \u2014 "),nQ=n(ARe,"A",{href:!0});var PTt=s(nQ);xgr=r(PTt,"TFPegasusModel"),PTt.forEach(t),$gr=r(ARe," (Pegasus model)"),ARe.forEach(t),kgr=i(D),qT=n(D,"LI",{});var yRe=s(qT);xbe=n(yRe,"STRONG",{});var BTt=s(xbe);Sgr=r(BTt,"rembert"),BTt.forEach(t),Rgr=r(yRe," \u2014 "),sQ=n(yRe,"A",{href:!0});var ITt=s(sQ);Pgr=r(ITt,"TFRemBertModel"),ITt.forEach(t),Bgr=r(yRe," (RemBERT model)"),yRe.forEach(t),Igr=i(D),jT=n(D,"LI",{});var LRe=s(jT);$be=n(LRe,"STRONG",{});var NTt=s($be);Ngr=r(NTt,"roberta"),NTt.forEach(t),qgr=r(LRe," \u2014 "),lQ=n(LRe,"A",{href:!0});var qTt=s(lQ);jgr=r(qTt,"TFRobertaModel"),qTt.forEach(t),Dgr=r(LRe," (RoBERTa model)"),LRe.forEach(t),Ggr=i(D),DT=n(D,"LI",{});var xRe=s(DT);kbe=n(xRe,"STRONG",{});var jTt=s(kbe);Ogr=r(jTt,"roformer"),jTt.forEach(t),Vgr=r(xRe," \u2014 "),iQ=n(xRe,"A",{href:!0});var DTt=s(iQ);Xgr=r(DTt,"TFRoFormerModel"),DTt.forEach(t),zgr=r(xRe," (RoFormer model)"),xRe.forEach(t),Wgr=i(D),GT=n(D,"LI",{});var $Re=s(GT);Sbe=n($Re,"STRONG",{});var GTt=s(Sbe);Qgr=r(GTt,"speech_to_text"),GTt.forEach(t),Hgr=r($Re," \u2014 "),dQ=n($Re,"A",{href:!0});var OTt=s(dQ);Ugr=r(OTt,"TFSpeech2TextModel"),OTt.forEach(t),Jgr=r($Re," (Speech2Text model)"),$Re.forEach(t),Ygr=i(D),OT=n(D,"LI",{});var kRe=s(OT);Rbe=n(kRe,"STRONG",{});var VTt=s(Rbe);Kgr=r(VTt,"swin"),VTt.forEach(t),Zgr=r(kRe," \u2014 "),cQ=n(kRe,"A",{href:!0});var XTt=s(cQ);ehr=r(XTt,"TFSwinModel"),XTt.forEach(t),ohr=r(kRe," (Swin model)"),kRe.forEach(t),rhr=i(D),VT=n(D,"LI",{});var SRe=s(VT);Pbe=n(SRe,"STRONG",{});var zTt=s(Pbe);thr=r(zTt,"t5"),zTt.forEach(t),ahr=r(SRe," \u2014 "),fQ=n(SRe,"A",{href:!0});var WTt=s(fQ);nhr=r(WTt,"TFT5Model"),WTt.forEach(t),shr=r(SRe," (T5 model)"),SRe.forEach(t),lhr=i(D),XT=n(D,"LI",{});var RRe=s(XT);Bbe=n(RRe,"STRONG",{});var QTt=s(Bbe);ihr=r(QTt,"tapas"),QTt.forEach(t),dhr=r(RRe," \u2014 "),mQ=n(RRe,"A",{href:!0});var HTt=s(mQ);chr=r(HTt,"TFTapasModel"),HTt.forEach(t),fhr=r(RRe," (TAPAS model)"),RRe.forEach(t),mhr=i(D),zT=n(D,"LI",{});var PRe=s(zT);Ibe=n(PRe,"STRONG",{});var UTt=s(Ibe);ghr=r(UTt,"transfo-xl"),UTt.forEach(t),hhr=r(PRe," \u2014 "),gQ=n(PRe,"A",{href:!0});var JTt=s(gQ);phr=r(JTt,"TFTransfoXLModel"),JTt.forEach(t),_hr=r(PRe," (Transformer-XL model)"),PRe.forEach(t),uhr=i(D),WT=n(D,"LI",{});var BRe=s(WT);Nbe=n(BRe,"STRONG",{});var YTt=s(Nbe);bhr=r(YTt,"vit"),YTt.forEach(t),vhr=r(BRe," \u2014 "),hQ=n(BRe,"A",{href:!0});var KTt=s(hQ);Fhr=r(KTt,"TFViTModel"),KTt.forEach(t),Thr=r(BRe," (ViT model)"),BRe.forEach(t),Mhr=i(D),QT=n(D,"LI",{});var IRe=s(QT);qbe=n(IRe,"STRONG",{});var ZTt=s(qbe);Ehr=r(ZTt,"vit_mae"),ZTt.forEach(t),Chr=r(IRe," \u2014 "),pQ=n(IRe,"A",{href:!0});var e7t=s(pQ);whr=r(e7t,"TFViTMAEModel"),e7t.forEach(t),Ahr=r(IRe," (ViTMAE model)"),IRe.forEach(t),yhr=i(D),HT=n(D,"LI",{});var NRe=s(HT);jbe=n(NRe,"STRONG",{});var o7t=s(jbe);Lhr=r(o7t,"wav2vec2"),o7t.forEach(t),xhr=r(NRe," \u2014 "),_Q=n(NRe,"A",{href:!0});var r7t=s(_Q);$hr=r(r7t,"TFWav2Vec2Model"),r7t.forEach(t),khr=r(NRe," (Wav2Vec2 model)"),NRe.forEach(t),Shr=i(D),UT=n(D,"LI",{});var qRe=s(UT);Dbe=n(qRe,"STRONG",{});var t7t=s(Dbe);Rhr=r(t7t,"xlm"),t7t.forEach(t),Phr=r(qRe," \u2014 "),uQ=n(qRe,"A",{href:!0});var a7t=s(uQ);Bhr=r(a7t,"TFXLMModel"),a7t.forEach(t),Ihr=r(qRe," (XLM model)"),qRe.forEach(t),Nhr=i(D),JT=n(D,"LI",{});var jRe=s(JT);Gbe=n(jRe,"STRONG",{});var n7t=s(Gbe);qhr=r(n7t,"xlm-roberta"),n7t.forEach(t),jhr=r(jRe," \u2014 "),bQ=n(jRe,"A",{href:!0});var s7t=s(bQ);Dhr=r(s7t,"TFXLMRobertaModel"),s7t.forEach(t),Ghr=r(jRe," (XLM-RoBERTa model)"),jRe.forEach(t),Ohr=i(D),YT=n(D,"LI",{});var DRe=s(YT);Obe=n(DRe,"STRONG",{});var l7t=s(Obe);Vhr=r(l7t,"xlnet"),l7t.forEach(t),Xhr=r(DRe," \u2014 "),vQ=n(DRe,"A",{href:!0});var i7t=s(vQ);zhr=r(i7t,"TFXLNetModel"),i7t.forEach(t),Whr=r(DRe," (XLNet model)"),DRe.forEach(t),D.forEach(t),Qhr=i(_l),T(KT.$$.fragment,_l),_l.forEach(t),pl.forEach(t),Vje=i(f),Wd=n(f,"H2",{class:!0});var UGe=s(Wd);ZT=n(UGe,"A",{id:!0,class:!0,href:!0});var d7t=s(ZT);Vbe=n(d7t,"SPAN",{});var c7t=s(Vbe);T(M8.$$.fragment,c7t),c7t.forEach(t),d7t.forEach(t),Hhr=i(UGe),Xbe=n(UGe,"SPAN",{});var f7t=s(Xbe);Uhr=r(f7t,"TFAutoModelForPreTraining"),f7t.forEach(t),UGe.forEach(t),Xje=i(f),Ko=n(f,"DIV",{class:!0});var ul=s(Ko);T(E8.$$.fragment,ul),Jhr=i(ul),Qd=n(ul,"P",{});var See=s(Qd);Yhr=r(See,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),FQ=n(See,"A",{href:!0});var m7t=s(FQ);Khr=r(m7t,"from_pretrained()"),m7t.forEach(t),Zhr=r(See," class method or the "),TQ=n(See,"A",{href:!0});var g7t=s(TQ);epr=r(g7t,"from_config()"),g7t.forEach(t),opr=r(See,` class
method.`),See.forEach(t),rpr=i(ul),C8=n(ul,"P",{});var JGe=s(C8);tpr=r(JGe,"This class cannot be instantiated directly using "),zbe=n(JGe,"CODE",{});var h7t=s(zbe);apr=r(h7t,"__init__()"),h7t.forEach(t),npr=r(JGe," (throws an error)."),JGe.forEach(t),spr=i(ul),Lt=n(ul,"DIV",{class:!0});var B6=s(Lt);T(w8.$$.fragment,B6),lpr=i(B6),Wbe=n(B6,"P",{});var p7t=s(Wbe);ipr=r(p7t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),p7t.forEach(t),dpr=i(B6),Hd=n(B6,"P",{});var Ree=s(Hd);cpr=r(Ree,`Note:
Loading a model from its configuration file does `),Qbe=n(Ree,"STRONG",{});var _7t=s(Qbe);fpr=r(_7t,"not"),_7t.forEach(t),mpr=r(Ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),MQ=n(Ree,"A",{href:!0});var u7t=s(MQ);gpr=r(u7t,"from_pretrained()"),u7t.forEach(t),hpr=r(Ree," to load the model weights."),Ree.forEach(t),ppr=i(B6),T(e7.$$.fragment,B6),B6.forEach(t),_pr=i(ul),Ar=n(ul,"DIV",{class:!0});var bl=s(Ar);T(A8.$$.fragment,bl),upr=i(bl),Hbe=n(bl,"P",{});var b7t=s(Hbe);bpr=r(b7t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),b7t.forEach(t),vpr=i(bl),Za=n(bl,"P",{});var I6=s(Za);Fpr=r(I6,"The model class to instantiate is selected based on the "),Ube=n(I6,"CODE",{});var v7t=s(Ube);Tpr=r(v7t,"model_type"),v7t.forEach(t),Mpr=r(I6,` property of the config object (either
passed as an argument or loaded from `),Jbe=n(I6,"CODE",{});var F7t=s(Jbe);Epr=r(F7t,"pretrained_model_name_or_path"),F7t.forEach(t),Cpr=r(I6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ybe=n(I6,"CODE",{});var T7t=s(Ybe);wpr=r(T7t,"pretrained_model_name_or_path"),T7t.forEach(t),Apr=r(I6,":"),I6.forEach(t),ypr=i(bl),se=n(bl,"UL",{});var le=s(se);o7=n(le,"LI",{});var GRe=s(o7);Kbe=n(GRe,"STRONG",{});var M7t=s(Kbe);Lpr=r(M7t,"albert"),M7t.forEach(t),xpr=r(GRe," \u2014 "),EQ=n(GRe,"A",{href:!0});var E7t=s(EQ);$pr=r(E7t,"TFAlbertForPreTraining"),E7t.forEach(t),kpr=r(GRe," (ALBERT model)"),GRe.forEach(t),Spr=i(le),r7=n(le,"LI",{});var ORe=s(r7);Zbe=n(ORe,"STRONG",{});var C7t=s(Zbe);Rpr=r(C7t,"bart"),C7t.forEach(t),Ppr=r(ORe," \u2014 "),CQ=n(ORe,"A",{href:!0});var w7t=s(CQ);Bpr=r(w7t,"TFBartForConditionalGeneration"),w7t.forEach(t),Ipr=r(ORe," (BART model)"),ORe.forEach(t),Npr=i(le),t7=n(le,"LI",{});var VRe=s(t7);e4e=n(VRe,"STRONG",{});var A7t=s(e4e);qpr=r(A7t,"bert"),A7t.forEach(t),jpr=r(VRe," \u2014 "),wQ=n(VRe,"A",{href:!0});var y7t=s(wQ);Dpr=r(y7t,"TFBertForPreTraining"),y7t.forEach(t),Gpr=r(VRe," (BERT model)"),VRe.forEach(t),Opr=i(le),a7=n(le,"LI",{});var XRe=s(a7);o4e=n(XRe,"STRONG",{});var L7t=s(o4e);Vpr=r(L7t,"camembert"),L7t.forEach(t),Xpr=r(XRe," \u2014 "),AQ=n(XRe,"A",{href:!0});var x7t=s(AQ);zpr=r(x7t,"TFCamembertForMaskedLM"),x7t.forEach(t),Wpr=r(XRe," (CamemBERT model)"),XRe.forEach(t),Qpr=i(le),n7=n(le,"LI",{});var zRe=s(n7);r4e=n(zRe,"STRONG",{});var $7t=s(r4e);Hpr=r($7t,"ctrl"),$7t.forEach(t),Upr=r(zRe," \u2014 "),yQ=n(zRe,"A",{href:!0});var k7t=s(yQ);Jpr=r(k7t,"TFCTRLLMHeadModel"),k7t.forEach(t),Ypr=r(zRe," (CTRL model)"),zRe.forEach(t),Kpr=i(le),s7=n(le,"LI",{});var WRe=s(s7);t4e=n(WRe,"STRONG",{});var S7t=s(t4e);Zpr=r(S7t,"distilbert"),S7t.forEach(t),e_r=r(WRe," \u2014 "),LQ=n(WRe,"A",{href:!0});var R7t=s(LQ);o_r=r(R7t,"TFDistilBertForMaskedLM"),R7t.forEach(t),r_r=r(WRe," (DistilBERT model)"),WRe.forEach(t),t_r=i(le),l7=n(le,"LI",{});var QRe=s(l7);a4e=n(QRe,"STRONG",{});var P7t=s(a4e);a_r=r(P7t,"electra"),P7t.forEach(t),n_r=r(QRe," \u2014 "),xQ=n(QRe,"A",{href:!0});var B7t=s(xQ);s_r=r(B7t,"TFElectraForPreTraining"),B7t.forEach(t),l_r=r(QRe," (ELECTRA model)"),QRe.forEach(t),i_r=i(le),i7=n(le,"LI",{});var HRe=s(i7);n4e=n(HRe,"STRONG",{});var I7t=s(n4e);d_r=r(I7t,"flaubert"),I7t.forEach(t),c_r=r(HRe," \u2014 "),$Q=n(HRe,"A",{href:!0});var N7t=s($Q);f_r=r(N7t,"TFFlaubertWithLMHeadModel"),N7t.forEach(t),m_r=r(HRe," (FlauBERT model)"),HRe.forEach(t),g_r=i(le),d7=n(le,"LI",{});var URe=s(d7);s4e=n(URe,"STRONG",{});var q7t=s(s4e);h_r=r(q7t,"funnel"),q7t.forEach(t),p_r=r(URe," \u2014 "),kQ=n(URe,"A",{href:!0});var j7t=s(kQ);__r=r(j7t,"TFFunnelForPreTraining"),j7t.forEach(t),u_r=r(URe," (Funnel Transformer model)"),URe.forEach(t),b_r=i(le),c7=n(le,"LI",{});var JRe=s(c7);l4e=n(JRe,"STRONG",{});var D7t=s(l4e);v_r=r(D7t,"gpt2"),D7t.forEach(t),F_r=r(JRe," \u2014 "),SQ=n(JRe,"A",{href:!0});var G7t=s(SQ);T_r=r(G7t,"TFGPT2LMHeadModel"),G7t.forEach(t),M_r=r(JRe," (OpenAI GPT-2 model)"),JRe.forEach(t),E_r=i(le),f7=n(le,"LI",{});var YRe=s(f7);i4e=n(YRe,"STRONG",{});var O7t=s(i4e);C_r=r(O7t,"layoutlm"),O7t.forEach(t),w_r=r(YRe," \u2014 "),RQ=n(YRe,"A",{href:!0});var V7t=s(RQ);A_r=r(V7t,"TFLayoutLMForMaskedLM"),V7t.forEach(t),y_r=r(YRe," (LayoutLM model)"),YRe.forEach(t),L_r=i(le),m7=n(le,"LI",{});var KRe=s(m7);d4e=n(KRe,"STRONG",{});var X7t=s(d4e);x_r=r(X7t,"lxmert"),X7t.forEach(t),$_r=r(KRe," \u2014 "),PQ=n(KRe,"A",{href:!0});var z7t=s(PQ);k_r=r(z7t,"TFLxmertForPreTraining"),z7t.forEach(t),S_r=r(KRe," (LXMERT model)"),KRe.forEach(t),R_r=i(le),g7=n(le,"LI",{});var ZRe=s(g7);c4e=n(ZRe,"STRONG",{});var W7t=s(c4e);P_r=r(W7t,"mobilebert"),W7t.forEach(t),B_r=r(ZRe," \u2014 "),BQ=n(ZRe,"A",{href:!0});var Q7t=s(BQ);I_r=r(Q7t,"TFMobileBertForPreTraining"),Q7t.forEach(t),N_r=r(ZRe," (MobileBERT model)"),ZRe.forEach(t),q_r=i(le),h7=n(le,"LI",{});var ePe=s(h7);f4e=n(ePe,"STRONG",{});var H7t=s(f4e);j_r=r(H7t,"mpnet"),H7t.forEach(t),D_r=r(ePe," \u2014 "),IQ=n(ePe,"A",{href:!0});var U7t=s(IQ);G_r=r(U7t,"TFMPNetForMaskedLM"),U7t.forEach(t),O_r=r(ePe," (MPNet model)"),ePe.forEach(t),V_r=i(le),p7=n(le,"LI",{});var oPe=s(p7);m4e=n(oPe,"STRONG",{});var J7t=s(m4e);X_r=r(J7t,"openai-gpt"),J7t.forEach(t),z_r=r(oPe," \u2014 "),NQ=n(oPe,"A",{href:!0});var Y7t=s(NQ);W_r=r(Y7t,"TFOpenAIGPTLMHeadModel"),Y7t.forEach(t),Q_r=r(oPe," (OpenAI GPT model)"),oPe.forEach(t),H_r=i(le),_7=n(le,"LI",{});var rPe=s(_7);g4e=n(rPe,"STRONG",{});var K7t=s(g4e);U_r=r(K7t,"roberta"),K7t.forEach(t),J_r=r(rPe," \u2014 "),qQ=n(rPe,"A",{href:!0});var Z7t=s(qQ);Y_r=r(Z7t,"TFRobertaForMaskedLM"),Z7t.forEach(t),K_r=r(rPe," (RoBERTa model)"),rPe.forEach(t),Z_r=i(le),u7=n(le,"LI",{});var tPe=s(u7);h4e=n(tPe,"STRONG",{});var eMt=s(h4e);eur=r(eMt,"t5"),eMt.forEach(t),our=r(tPe," \u2014 "),jQ=n(tPe,"A",{href:!0});var oMt=s(jQ);rur=r(oMt,"TFT5ForConditionalGeneration"),oMt.forEach(t),tur=r(tPe," (T5 model)"),tPe.forEach(t),aur=i(le),b7=n(le,"LI",{});var aPe=s(b7);p4e=n(aPe,"STRONG",{});var rMt=s(p4e);nur=r(rMt,"tapas"),rMt.forEach(t),sur=r(aPe," \u2014 "),DQ=n(aPe,"A",{href:!0});var tMt=s(DQ);lur=r(tMt,"TFTapasForMaskedLM"),tMt.forEach(t),iur=r(aPe," (TAPAS model)"),aPe.forEach(t),dur=i(le),v7=n(le,"LI",{});var nPe=s(v7);_4e=n(nPe,"STRONG",{});var aMt=s(_4e);cur=r(aMt,"transfo-xl"),aMt.forEach(t),fur=r(nPe," \u2014 "),GQ=n(nPe,"A",{href:!0});var nMt=s(GQ);mur=r(nMt,"TFTransfoXLLMHeadModel"),nMt.forEach(t),gur=r(nPe," (Transformer-XL model)"),nPe.forEach(t),hur=i(le),F7=n(le,"LI",{});var sPe=s(F7);u4e=n(sPe,"STRONG",{});var sMt=s(u4e);pur=r(sMt,"vit_mae"),sMt.forEach(t),_ur=r(sPe," \u2014 "),OQ=n(sPe,"A",{href:!0});var lMt=s(OQ);uur=r(lMt,"TFViTMAEForPreTraining"),lMt.forEach(t),bur=r(sPe," (ViTMAE model)"),sPe.forEach(t),vur=i(le),T7=n(le,"LI",{});var lPe=s(T7);b4e=n(lPe,"STRONG",{});var iMt=s(b4e);Fur=r(iMt,"xlm"),iMt.forEach(t),Tur=r(lPe," \u2014 "),VQ=n(lPe,"A",{href:!0});var dMt=s(VQ);Mur=r(dMt,"TFXLMWithLMHeadModel"),dMt.forEach(t),Eur=r(lPe," (XLM model)"),lPe.forEach(t),Cur=i(le),M7=n(le,"LI",{});var iPe=s(M7);v4e=n(iPe,"STRONG",{});var cMt=s(v4e);wur=r(cMt,"xlm-roberta"),cMt.forEach(t),Aur=r(iPe," \u2014 "),XQ=n(iPe,"A",{href:!0});var fMt=s(XQ);yur=r(fMt,"TFXLMRobertaForMaskedLM"),fMt.forEach(t),Lur=r(iPe," (XLM-RoBERTa model)"),iPe.forEach(t),xur=i(le),E7=n(le,"LI",{});var dPe=s(E7);F4e=n(dPe,"STRONG",{});var mMt=s(F4e);$ur=r(mMt,"xlnet"),mMt.forEach(t),kur=r(dPe," \u2014 "),zQ=n(dPe,"A",{href:!0});var gMt=s(zQ);Sur=r(gMt,"TFXLNetLMHeadModel"),gMt.forEach(t),Rur=r(dPe," (XLNet model)"),dPe.forEach(t),le.forEach(t),Pur=i(bl),T(C7.$$.fragment,bl),bl.forEach(t),ul.forEach(t),zje=i(f),Ud=n(f,"H2",{class:!0});var YGe=s(Ud);w7=n(YGe,"A",{id:!0,class:!0,href:!0});var hMt=s(w7);T4e=n(hMt,"SPAN",{});var pMt=s(T4e);T(y8.$$.fragment,pMt),pMt.forEach(t),hMt.forEach(t),Bur=i(YGe),M4e=n(YGe,"SPAN",{});var _Mt=s(M4e);Iur=r(_Mt,"TFAutoModelForCausalLM"),_Mt.forEach(t),YGe.forEach(t),Wje=i(f),Zo=n(f,"DIV",{class:!0});var vl=s(Zo);T(L8.$$.fragment,vl),Nur=i(vl),Jd=n(vl,"P",{});var Pee=s(Jd);qur=r(Pee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),WQ=n(Pee,"A",{href:!0});var uMt=s(WQ);jur=r(uMt,"from_pretrained()"),uMt.forEach(t),Dur=r(Pee," class method or the "),QQ=n(Pee,"A",{href:!0});var bMt=s(QQ);Gur=r(bMt,"from_config()"),bMt.forEach(t),Our=r(Pee,` class
method.`),Pee.forEach(t),Vur=i(vl),x8=n(vl,"P",{});var KGe=s(x8);Xur=r(KGe,"This class cannot be instantiated directly using "),E4e=n(KGe,"CODE",{});var vMt=s(E4e);zur=r(vMt,"__init__()"),vMt.forEach(t),Wur=r(KGe," (throws an error)."),KGe.forEach(t),Qur=i(vl),xt=n(vl,"DIV",{class:!0});var N6=s(xt);T($8.$$.fragment,N6),Hur=i(N6),C4e=n(N6,"P",{});var FMt=s(C4e);Uur=r(FMt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),FMt.forEach(t),Jur=i(N6),Yd=n(N6,"P",{});var Bee=s(Yd);Yur=r(Bee,`Note:
Loading a model from its configuration file does `),w4e=n(Bee,"STRONG",{});var TMt=s(w4e);Kur=r(TMt,"not"),TMt.forEach(t),Zur=r(Bee,` load the model weights. It only affects the
model\u2019s configuration. Use `),HQ=n(Bee,"A",{href:!0});var MMt=s(HQ);e2r=r(MMt,"from_pretrained()"),MMt.forEach(t),o2r=r(Bee," to load the model weights."),Bee.forEach(t),r2r=i(N6),T(A7.$$.fragment,N6),N6.forEach(t),t2r=i(vl),yr=n(vl,"DIV",{class:!0});var Fl=s(yr);T(k8.$$.fragment,Fl),a2r=i(Fl),A4e=n(Fl,"P",{});var EMt=s(A4e);n2r=r(EMt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),EMt.forEach(t),s2r=i(Fl),en=n(Fl,"P",{});var q6=s(en);l2r=r(q6,"The model class to instantiate is selected based on the "),y4e=n(q6,"CODE",{});var CMt=s(y4e);i2r=r(CMt,"model_type"),CMt.forEach(t),d2r=r(q6,` property of the config object (either
passed as an argument or loaded from `),L4e=n(q6,"CODE",{});var wMt=s(L4e);c2r=r(wMt,"pretrained_model_name_or_path"),wMt.forEach(t),f2r=r(q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x4e=n(q6,"CODE",{});var AMt=s(x4e);m2r=r(AMt,"pretrained_model_name_or_path"),AMt.forEach(t),g2r=r(q6,":"),q6.forEach(t),h2r=i(Fl),Me=n(Fl,"UL",{});var Ce=s(Me);y7=n(Ce,"LI",{});var cPe=s(y7);$4e=n(cPe,"STRONG",{});var yMt=s($4e);p2r=r(yMt,"bert"),yMt.forEach(t),_2r=r(cPe," \u2014 "),UQ=n(cPe,"A",{href:!0});var LMt=s(UQ);u2r=r(LMt,"TFBertLMHeadModel"),LMt.forEach(t),b2r=r(cPe," (BERT model)"),cPe.forEach(t),v2r=i(Ce),L7=n(Ce,"LI",{});var fPe=s(L7);k4e=n(fPe,"STRONG",{});var xMt=s(k4e);F2r=r(xMt,"camembert"),xMt.forEach(t),T2r=r(fPe," \u2014 "),JQ=n(fPe,"A",{href:!0});var $Mt=s(JQ);M2r=r($Mt,"TFCamembertForCausalLM"),$Mt.forEach(t),E2r=r(fPe," (CamemBERT model)"),fPe.forEach(t),C2r=i(Ce),x7=n(Ce,"LI",{});var mPe=s(x7);S4e=n(mPe,"STRONG",{});var kMt=s(S4e);w2r=r(kMt,"ctrl"),kMt.forEach(t),A2r=r(mPe," \u2014 "),YQ=n(mPe,"A",{href:!0});var SMt=s(YQ);y2r=r(SMt,"TFCTRLLMHeadModel"),SMt.forEach(t),L2r=r(mPe," (CTRL model)"),mPe.forEach(t),x2r=i(Ce),$7=n(Ce,"LI",{});var gPe=s($7);R4e=n(gPe,"STRONG",{});var RMt=s(R4e);$2r=r(RMt,"gpt2"),RMt.forEach(t),k2r=r(gPe," \u2014 "),KQ=n(gPe,"A",{href:!0});var PMt=s(KQ);S2r=r(PMt,"TFGPT2LMHeadModel"),PMt.forEach(t),R2r=r(gPe," (OpenAI GPT-2 model)"),gPe.forEach(t),P2r=i(Ce),k7=n(Ce,"LI",{});var hPe=s(k7);P4e=n(hPe,"STRONG",{});var BMt=s(P4e);B2r=r(BMt,"gptj"),BMt.forEach(t),I2r=r(hPe," \u2014 "),ZQ=n(hPe,"A",{href:!0});var IMt=s(ZQ);N2r=r(IMt,"TFGPTJForCausalLM"),IMt.forEach(t),q2r=r(hPe," (GPT-J model)"),hPe.forEach(t),j2r=i(Ce),S7=n(Ce,"LI",{});var pPe=s(S7);B4e=n(pPe,"STRONG",{});var NMt=s(B4e);D2r=r(NMt,"openai-gpt"),NMt.forEach(t),G2r=r(pPe," \u2014 "),eH=n(pPe,"A",{href:!0});var qMt=s(eH);O2r=r(qMt,"TFOpenAIGPTLMHeadModel"),qMt.forEach(t),V2r=r(pPe," (OpenAI GPT model)"),pPe.forEach(t),X2r=i(Ce),R7=n(Ce,"LI",{});var _Pe=s(R7);I4e=n(_Pe,"STRONG",{});var jMt=s(I4e);z2r=r(jMt,"opt"),jMt.forEach(t),W2r=r(_Pe," \u2014 "),oH=n(_Pe,"A",{href:!0});var DMt=s(oH);Q2r=r(DMt,"TFOPTForCausalLM"),DMt.forEach(t),H2r=r(_Pe," (OPT model)"),_Pe.forEach(t),U2r=i(Ce),P7=n(Ce,"LI",{});var uPe=s(P7);N4e=n(uPe,"STRONG",{});var GMt=s(N4e);J2r=r(GMt,"rembert"),GMt.forEach(t),Y2r=r(uPe," \u2014 "),rH=n(uPe,"A",{href:!0});var OMt=s(rH);K2r=r(OMt,"TFRemBertForCausalLM"),OMt.forEach(t),Z2r=r(uPe," (RemBERT model)"),uPe.forEach(t),e1r=i(Ce),B7=n(Ce,"LI",{});var bPe=s(B7);q4e=n(bPe,"STRONG",{});var VMt=s(q4e);o1r=r(VMt,"roberta"),VMt.forEach(t),r1r=r(bPe," \u2014 "),tH=n(bPe,"A",{href:!0});var XMt=s(tH);t1r=r(XMt,"TFRobertaForCausalLM"),XMt.forEach(t),a1r=r(bPe," (RoBERTa model)"),bPe.forEach(t),n1r=i(Ce),I7=n(Ce,"LI",{});var vPe=s(I7);j4e=n(vPe,"STRONG",{});var zMt=s(j4e);s1r=r(zMt,"roformer"),zMt.forEach(t),l1r=r(vPe," \u2014 "),aH=n(vPe,"A",{href:!0});var WMt=s(aH);i1r=r(WMt,"TFRoFormerForCausalLM"),WMt.forEach(t),d1r=r(vPe," (RoFormer model)"),vPe.forEach(t),c1r=i(Ce),N7=n(Ce,"LI",{});var FPe=s(N7);D4e=n(FPe,"STRONG",{});var QMt=s(D4e);f1r=r(QMt,"transfo-xl"),QMt.forEach(t),m1r=r(FPe," \u2014 "),nH=n(FPe,"A",{href:!0});var HMt=s(nH);g1r=r(HMt,"TFTransfoXLLMHeadModel"),HMt.forEach(t),h1r=r(FPe," (Transformer-XL model)"),FPe.forEach(t),p1r=i(Ce),q7=n(Ce,"LI",{});var TPe=s(q7);G4e=n(TPe,"STRONG",{});var UMt=s(G4e);_1r=r(UMt,"xlm"),UMt.forEach(t),u1r=r(TPe," \u2014 "),sH=n(TPe,"A",{href:!0});var JMt=s(sH);b1r=r(JMt,"TFXLMWithLMHeadModel"),JMt.forEach(t),v1r=r(TPe," (XLM model)"),TPe.forEach(t),F1r=i(Ce),j7=n(Ce,"LI",{});var MPe=s(j7);O4e=n(MPe,"STRONG",{});var YMt=s(O4e);T1r=r(YMt,"xlnet"),YMt.forEach(t),M1r=r(MPe," \u2014 "),lH=n(MPe,"A",{href:!0});var KMt=s(lH);E1r=r(KMt,"TFXLNetLMHeadModel"),KMt.forEach(t),C1r=r(MPe," (XLNet model)"),MPe.forEach(t),Ce.forEach(t),w1r=i(Fl),T(D7.$$.fragment,Fl),Fl.forEach(t),vl.forEach(t),Qje=i(f),Kd=n(f,"H2",{class:!0});var ZGe=s(Kd);G7=n(ZGe,"A",{id:!0,class:!0,href:!0});var ZMt=s(G7);V4e=n(ZMt,"SPAN",{});var eEt=s(V4e);T(S8.$$.fragment,eEt),eEt.forEach(t),ZMt.forEach(t),A1r=i(ZGe),X4e=n(ZGe,"SPAN",{});var oEt=s(X4e);y1r=r(oEt,"TFAutoModelForImageClassification"),oEt.forEach(t),ZGe.forEach(t),Hje=i(f),er=n(f,"DIV",{class:!0});var Tl=s(er);T(R8.$$.fragment,Tl),L1r=i(Tl),Zd=n(Tl,"P",{});var Iee=s(Zd);x1r=r(Iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iH=n(Iee,"A",{href:!0});var rEt=s(iH);$1r=r(rEt,"from_pretrained()"),rEt.forEach(t),k1r=r(Iee," class method or the "),dH=n(Iee,"A",{href:!0});var tEt=s(dH);S1r=r(tEt,"from_config()"),tEt.forEach(t),R1r=r(Iee,` class
method.`),Iee.forEach(t),P1r=i(Tl),P8=n(Tl,"P",{});var eOe=s(P8);B1r=r(eOe,"This class cannot be instantiated directly using "),z4e=n(eOe,"CODE",{});var aEt=s(z4e);I1r=r(aEt,"__init__()"),aEt.forEach(t),N1r=r(eOe," (throws an error)."),eOe.forEach(t),q1r=i(Tl),$t=n(Tl,"DIV",{class:!0});var j6=s($t);T(B8.$$.fragment,j6),j1r=i(j6),W4e=n(j6,"P",{});var nEt=s(W4e);D1r=r(nEt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),nEt.forEach(t),G1r=i(j6),ec=n(j6,"P",{});var Nee=s(ec);O1r=r(Nee,`Note:
Loading a model from its configuration file does `),Q4e=n(Nee,"STRONG",{});var sEt=s(Q4e);V1r=r(sEt,"not"),sEt.forEach(t),X1r=r(Nee,` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=n(Nee,"A",{href:!0});var lEt=s(cH);z1r=r(lEt,"from_pretrained()"),lEt.forEach(t),W1r=r(Nee," to load the model weights."),Nee.forEach(t),Q1r=i(j6),T(O7.$$.fragment,j6),j6.forEach(t),H1r=i(Tl),Lr=n(Tl,"DIV",{class:!0});var Ml=s(Lr);T(I8.$$.fragment,Ml),U1r=i(Ml),H4e=n(Ml,"P",{});var iEt=s(H4e);J1r=r(iEt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),iEt.forEach(t),Y1r=i(Ml),on=n(Ml,"P",{});var D6=s(on);K1r=r(D6,"The model class to instantiate is selected based on the "),U4e=n(D6,"CODE",{});var dEt=s(U4e);Z1r=r(dEt,"model_type"),dEt.forEach(t),ebr=r(D6,` property of the config object (either
passed as an argument or loaded from `),J4e=n(D6,"CODE",{});var cEt=s(J4e);obr=r(cEt,"pretrained_model_name_or_path"),cEt.forEach(t),rbr=r(D6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y4e=n(D6,"CODE",{});var fEt=s(Y4e);tbr=r(fEt,"pretrained_model_name_or_path"),fEt.forEach(t),abr=r(D6,":"),D6.forEach(t),nbr=i(Ml),rn=n(Ml,"UL",{});var G6=s(rn);V7=n(G6,"LI",{});var EPe=s(V7);K4e=n(EPe,"STRONG",{});var mEt=s(K4e);sbr=r(mEt,"convnext"),mEt.forEach(t),lbr=r(EPe," \u2014 "),fH=n(EPe,"A",{href:!0});var gEt=s(fH);ibr=r(gEt,"TFConvNextForImageClassification"),gEt.forEach(t),dbr=r(EPe," (ConvNext model)"),EPe.forEach(t),cbr=i(G6),X7=n(G6,"LI",{});var CPe=s(X7);Z4e=n(CPe,"STRONG",{});var hEt=s(Z4e);fbr=r(hEt,"data2vec-vision"),hEt.forEach(t),mbr=r(CPe," \u2014 "),mH=n(CPe,"A",{href:!0});var pEt=s(mH);gbr=r(pEt,"TFData2VecVisionForImageClassification"),pEt.forEach(t),hbr=r(CPe," (Data2VecVision model)"),CPe.forEach(t),pbr=i(G6),z7=n(G6,"LI",{});var wPe=s(z7);eve=n(wPe,"STRONG",{});var _Et=s(eve);_br=r(_Et,"swin"),_Et.forEach(t),ubr=r(wPe," \u2014 "),gH=n(wPe,"A",{href:!0});var uEt=s(gH);bbr=r(uEt,"TFSwinForImageClassification"),uEt.forEach(t),vbr=r(wPe," (Swin model)"),wPe.forEach(t),Fbr=i(G6),W7=n(G6,"LI",{});var APe=s(W7);ove=n(APe,"STRONG",{});var bEt=s(ove);Tbr=r(bEt,"vit"),bEt.forEach(t),Mbr=r(APe," \u2014 "),hH=n(APe,"A",{href:!0});var vEt=s(hH);Ebr=r(vEt,"TFViTForImageClassification"),vEt.forEach(t),Cbr=r(APe," (ViT model)"),APe.forEach(t),G6.forEach(t),wbr=i(Ml),T(Q7.$$.fragment,Ml),Ml.forEach(t),Tl.forEach(t),Uje=i(f),oc=n(f,"H2",{class:!0});var oOe=s(oc);H7=n(oOe,"A",{id:!0,class:!0,href:!0});var FEt=s(H7);rve=n(FEt,"SPAN",{});var TEt=s(rve);T(N8.$$.fragment,TEt),TEt.forEach(t),FEt.forEach(t),Abr=i(oOe),tve=n(oOe,"SPAN",{});var MEt=s(tve);ybr=r(MEt,"TFAutoModelForMaskedLM"),MEt.forEach(t),oOe.forEach(t),Jje=i(f),or=n(f,"DIV",{class:!0});var El=s(or);T(q8.$$.fragment,El),Lbr=i(El),rc=n(El,"P",{});var qee=s(rc);xbr=r(qee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pH=n(qee,"A",{href:!0});var EEt=s(pH);$br=r(EEt,"from_pretrained()"),EEt.forEach(t),kbr=r(qee," class method or the "),_H=n(qee,"A",{href:!0});var CEt=s(_H);Sbr=r(CEt,"from_config()"),CEt.forEach(t),Rbr=r(qee,` class
method.`),qee.forEach(t),Pbr=i(El),j8=n(El,"P",{});var rOe=s(j8);Bbr=r(rOe,"This class cannot be instantiated directly using "),ave=n(rOe,"CODE",{});var wEt=s(ave);Ibr=r(wEt,"__init__()"),wEt.forEach(t),Nbr=r(rOe," (throws an error)."),rOe.forEach(t),qbr=i(El),kt=n(El,"DIV",{class:!0});var O6=s(kt);T(D8.$$.fragment,O6),jbr=i(O6),nve=n(O6,"P",{});var AEt=s(nve);Dbr=r(AEt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),AEt.forEach(t),Gbr=i(O6),tc=n(O6,"P",{});var jee=s(tc);Obr=r(jee,`Note:
Loading a model from its configuration file does `),sve=n(jee,"STRONG",{});var yEt=s(sve);Vbr=r(yEt,"not"),yEt.forEach(t),Xbr=r(jee,` load the model weights. It only affects the
model\u2019s configuration. Use `),uH=n(jee,"A",{href:!0});var LEt=s(uH);zbr=r(LEt,"from_pretrained()"),LEt.forEach(t),Wbr=r(jee," to load the model weights."),jee.forEach(t),Qbr=i(O6),T(U7.$$.fragment,O6),O6.forEach(t),Hbr=i(El),xr=n(El,"DIV",{class:!0});var Cl=s(xr);T(G8.$$.fragment,Cl),Ubr=i(Cl),lve=n(Cl,"P",{});var xEt=s(lve);Jbr=r(xEt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),xEt.forEach(t),Ybr=i(Cl),tn=n(Cl,"P",{});var V6=s(tn);Kbr=r(V6,"The model class to instantiate is selected based on the "),ive=n(V6,"CODE",{});var $Et=s(ive);Zbr=r($Et,"model_type"),$Et.forEach(t),e4r=r(V6,` property of the config object (either
passed as an argument or loaded from `),dve=n(V6,"CODE",{});var kEt=s(dve);o4r=r(kEt,"pretrained_model_name_or_path"),kEt.forEach(t),r4r=r(V6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cve=n(V6,"CODE",{});var SEt=s(cve);t4r=r(SEt,"pretrained_model_name_or_path"),SEt.forEach(t),a4r=r(V6,":"),V6.forEach(t),n4r=i(Cl),ie=n(Cl,"UL",{});var fe=s(ie);J7=n(fe,"LI",{});var yPe=s(J7);fve=n(yPe,"STRONG",{});var REt=s(fve);s4r=r(REt,"albert"),REt.forEach(t),l4r=r(yPe," \u2014 "),bH=n(yPe,"A",{href:!0});var PEt=s(bH);i4r=r(PEt,"TFAlbertForMaskedLM"),PEt.forEach(t),d4r=r(yPe," (ALBERT model)"),yPe.forEach(t),c4r=i(fe),Y7=n(fe,"LI",{});var LPe=s(Y7);mve=n(LPe,"STRONG",{});var BEt=s(mve);f4r=r(BEt,"bert"),BEt.forEach(t),m4r=r(LPe," \u2014 "),vH=n(LPe,"A",{href:!0});var IEt=s(vH);g4r=r(IEt,"TFBertForMaskedLM"),IEt.forEach(t),h4r=r(LPe," (BERT model)"),LPe.forEach(t),p4r=i(fe),K7=n(fe,"LI",{});var xPe=s(K7);gve=n(xPe,"STRONG",{});var NEt=s(gve);_4r=r(NEt,"camembert"),NEt.forEach(t),u4r=r(xPe," \u2014 "),FH=n(xPe,"A",{href:!0});var qEt=s(FH);b4r=r(qEt,"TFCamembertForMaskedLM"),qEt.forEach(t),v4r=r(xPe," (CamemBERT model)"),xPe.forEach(t),F4r=i(fe),Z7=n(fe,"LI",{});var $Pe=s(Z7);hve=n($Pe,"STRONG",{});var jEt=s(hve);T4r=r(jEt,"convbert"),jEt.forEach(t),M4r=r($Pe," \u2014 "),TH=n($Pe,"A",{href:!0});var DEt=s(TH);E4r=r(DEt,"TFConvBertForMaskedLM"),DEt.forEach(t),C4r=r($Pe," (ConvBERT model)"),$Pe.forEach(t),w4r=i(fe),eM=n(fe,"LI",{});var kPe=s(eM);pve=n(kPe,"STRONG",{});var GEt=s(pve);A4r=r(GEt,"deberta"),GEt.forEach(t),y4r=r(kPe," \u2014 "),MH=n(kPe,"A",{href:!0});var OEt=s(MH);L4r=r(OEt,"TFDebertaForMaskedLM"),OEt.forEach(t),x4r=r(kPe," (DeBERTa model)"),kPe.forEach(t),$4r=i(fe),oM=n(fe,"LI",{});var SPe=s(oM);_ve=n(SPe,"STRONG",{});var VEt=s(_ve);k4r=r(VEt,"deberta-v2"),VEt.forEach(t),S4r=r(SPe," \u2014 "),EH=n(SPe,"A",{href:!0});var XEt=s(EH);R4r=r(XEt,"TFDebertaV2ForMaskedLM"),XEt.forEach(t),P4r=r(SPe," (DeBERTa-v2 model)"),SPe.forEach(t),B4r=i(fe),rM=n(fe,"LI",{});var RPe=s(rM);uve=n(RPe,"STRONG",{});var zEt=s(uve);I4r=r(zEt,"distilbert"),zEt.forEach(t),N4r=r(RPe," \u2014 "),CH=n(RPe,"A",{href:!0});var WEt=s(CH);q4r=r(WEt,"TFDistilBertForMaskedLM"),WEt.forEach(t),j4r=r(RPe," (DistilBERT model)"),RPe.forEach(t),D4r=i(fe),tM=n(fe,"LI",{});var PPe=s(tM);bve=n(PPe,"STRONG",{});var QEt=s(bve);G4r=r(QEt,"electra"),QEt.forEach(t),O4r=r(PPe," \u2014 "),wH=n(PPe,"A",{href:!0});var HEt=s(wH);V4r=r(HEt,"TFElectraForMaskedLM"),HEt.forEach(t),X4r=r(PPe," (ELECTRA model)"),PPe.forEach(t),z4r=i(fe),aM=n(fe,"LI",{});var BPe=s(aM);vve=n(BPe,"STRONG",{});var UEt=s(vve);W4r=r(UEt,"flaubert"),UEt.forEach(t),Q4r=r(BPe," \u2014 "),AH=n(BPe,"A",{href:!0});var JEt=s(AH);H4r=r(JEt,"TFFlaubertWithLMHeadModel"),JEt.forEach(t),U4r=r(BPe," (FlauBERT model)"),BPe.forEach(t),J4r=i(fe),nM=n(fe,"LI",{});var IPe=s(nM);Fve=n(IPe,"STRONG",{});var YEt=s(Fve);Y4r=r(YEt,"funnel"),YEt.forEach(t),K4r=r(IPe," \u2014 "),yH=n(IPe,"A",{href:!0});var KEt=s(yH);Z4r=r(KEt,"TFFunnelForMaskedLM"),KEt.forEach(t),evr=r(IPe," (Funnel Transformer model)"),IPe.forEach(t),ovr=i(fe),sM=n(fe,"LI",{});var NPe=s(sM);Tve=n(NPe,"STRONG",{});var ZEt=s(Tve);rvr=r(ZEt,"layoutlm"),ZEt.forEach(t),tvr=r(NPe," \u2014 "),LH=n(NPe,"A",{href:!0});var eCt=s(LH);avr=r(eCt,"TFLayoutLMForMaskedLM"),eCt.forEach(t),nvr=r(NPe," (LayoutLM model)"),NPe.forEach(t),svr=i(fe),lM=n(fe,"LI",{});var qPe=s(lM);Mve=n(qPe,"STRONG",{});var oCt=s(Mve);lvr=r(oCt,"longformer"),oCt.forEach(t),ivr=r(qPe," \u2014 "),xH=n(qPe,"A",{href:!0});var rCt=s(xH);dvr=r(rCt,"TFLongformerForMaskedLM"),rCt.forEach(t),cvr=r(qPe," (Longformer model)"),qPe.forEach(t),fvr=i(fe),iM=n(fe,"LI",{});var jPe=s(iM);Eve=n(jPe,"STRONG",{});var tCt=s(Eve);mvr=r(tCt,"mobilebert"),tCt.forEach(t),gvr=r(jPe," \u2014 "),$H=n(jPe,"A",{href:!0});var aCt=s($H);hvr=r(aCt,"TFMobileBertForMaskedLM"),aCt.forEach(t),pvr=r(jPe," (MobileBERT model)"),jPe.forEach(t),_vr=i(fe),dM=n(fe,"LI",{});var DPe=s(dM);Cve=n(DPe,"STRONG",{});var nCt=s(Cve);uvr=r(nCt,"mpnet"),nCt.forEach(t),bvr=r(DPe," \u2014 "),kH=n(DPe,"A",{href:!0});var sCt=s(kH);vvr=r(sCt,"TFMPNetForMaskedLM"),sCt.forEach(t),Fvr=r(DPe," (MPNet model)"),DPe.forEach(t),Tvr=i(fe),cM=n(fe,"LI",{});var GPe=s(cM);wve=n(GPe,"STRONG",{});var lCt=s(wve);Mvr=r(lCt,"rembert"),lCt.forEach(t),Evr=r(GPe," \u2014 "),SH=n(GPe,"A",{href:!0});var iCt=s(SH);Cvr=r(iCt,"TFRemBertForMaskedLM"),iCt.forEach(t),wvr=r(GPe," (RemBERT model)"),GPe.forEach(t),Avr=i(fe),fM=n(fe,"LI",{});var OPe=s(fM);Ave=n(OPe,"STRONG",{});var dCt=s(Ave);yvr=r(dCt,"roberta"),dCt.forEach(t),Lvr=r(OPe," \u2014 "),RH=n(OPe,"A",{href:!0});var cCt=s(RH);xvr=r(cCt,"TFRobertaForMaskedLM"),cCt.forEach(t),$vr=r(OPe," (RoBERTa model)"),OPe.forEach(t),kvr=i(fe),mM=n(fe,"LI",{});var VPe=s(mM);yve=n(VPe,"STRONG",{});var fCt=s(yve);Svr=r(fCt,"roformer"),fCt.forEach(t),Rvr=r(VPe," \u2014 "),PH=n(VPe,"A",{href:!0});var mCt=s(PH);Pvr=r(mCt,"TFRoFormerForMaskedLM"),mCt.forEach(t),Bvr=r(VPe," (RoFormer model)"),VPe.forEach(t),Ivr=i(fe),gM=n(fe,"LI",{});var XPe=s(gM);Lve=n(XPe,"STRONG",{});var gCt=s(Lve);Nvr=r(gCt,"tapas"),gCt.forEach(t),qvr=r(XPe," \u2014 "),BH=n(XPe,"A",{href:!0});var hCt=s(BH);jvr=r(hCt,"TFTapasForMaskedLM"),hCt.forEach(t),Dvr=r(XPe," (TAPAS model)"),XPe.forEach(t),Gvr=i(fe),hM=n(fe,"LI",{});var zPe=s(hM);xve=n(zPe,"STRONG",{});var pCt=s(xve);Ovr=r(pCt,"xlm"),pCt.forEach(t),Vvr=r(zPe," \u2014 "),IH=n(zPe,"A",{href:!0});var _Ct=s(IH);Xvr=r(_Ct,"TFXLMWithLMHeadModel"),_Ct.forEach(t),zvr=r(zPe," (XLM model)"),zPe.forEach(t),Wvr=i(fe),pM=n(fe,"LI",{});var WPe=s(pM);$ve=n(WPe,"STRONG",{});var uCt=s($ve);Qvr=r(uCt,"xlm-roberta"),uCt.forEach(t),Hvr=r(WPe," \u2014 "),NH=n(WPe,"A",{href:!0});var bCt=s(NH);Uvr=r(bCt,"TFXLMRobertaForMaskedLM"),bCt.forEach(t),Jvr=r(WPe," (XLM-RoBERTa model)"),WPe.forEach(t),fe.forEach(t),Yvr=i(Cl),T(_M.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),Yje=i(f),ac=n(f,"H2",{class:!0});var tOe=s(ac);uM=n(tOe,"A",{id:!0,class:!0,href:!0});var vCt=s(uM);kve=n(vCt,"SPAN",{});var FCt=s(kve);T(O8.$$.fragment,FCt),FCt.forEach(t),vCt.forEach(t),Kvr=i(tOe),Sve=n(tOe,"SPAN",{});var TCt=s(Sve);Zvr=r(TCt,"TFAutoModelForSeq2SeqLM"),TCt.forEach(t),tOe.forEach(t),Kje=i(f),rr=n(f,"DIV",{class:!0});var wl=s(rr);T(V8.$$.fragment,wl),e5r=i(wl),nc=n(wl,"P",{});var Dee=s(nc);o5r=r(Dee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qH=n(Dee,"A",{href:!0});var MCt=s(qH);r5r=r(MCt,"from_pretrained()"),MCt.forEach(t),t5r=r(Dee," class method or the "),jH=n(Dee,"A",{href:!0});var ECt=s(jH);a5r=r(ECt,"from_config()"),ECt.forEach(t),n5r=r(Dee,` class
method.`),Dee.forEach(t),s5r=i(wl),X8=n(wl,"P",{});var aOe=s(X8);l5r=r(aOe,"This class cannot be instantiated directly using "),Rve=n(aOe,"CODE",{});var CCt=s(Rve);i5r=r(CCt,"__init__()"),CCt.forEach(t),d5r=r(aOe," (throws an error)."),aOe.forEach(t),c5r=i(wl),St=n(wl,"DIV",{class:!0});var X6=s(St);T(z8.$$.fragment,X6),f5r=i(X6),Pve=n(X6,"P",{});var wCt=s(Pve);m5r=r(wCt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),wCt.forEach(t),g5r=i(X6),sc=n(X6,"P",{});var Gee=s(sc);h5r=r(Gee,`Note:
Loading a model from its configuration file does `),Bve=n(Gee,"STRONG",{});var ACt=s(Bve);p5r=r(ACt,"not"),ACt.forEach(t),_5r=r(Gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),DH=n(Gee,"A",{href:!0});var yCt=s(DH);u5r=r(yCt,"from_pretrained()"),yCt.forEach(t),b5r=r(Gee," to load the model weights."),Gee.forEach(t),v5r=i(X6),T(bM.$$.fragment,X6),X6.forEach(t),F5r=i(wl),$r=n(wl,"DIV",{class:!0});var Al=s($r);T(W8.$$.fragment,Al),T5r=i(Al),Ive=n(Al,"P",{});var LCt=s(Ive);M5r=r(LCt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),LCt.forEach(t),E5r=i(Al),an=n(Al,"P",{});var z6=s(an);C5r=r(z6,"The model class to instantiate is selected based on the "),Nve=n(z6,"CODE",{});var xCt=s(Nve);w5r=r(xCt,"model_type"),xCt.forEach(t),A5r=r(z6,` property of the config object (either
passed as an argument or loaded from `),qve=n(z6,"CODE",{});var $Ct=s(qve);y5r=r($Ct,"pretrained_model_name_or_path"),$Ct.forEach(t),L5r=r(z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jve=n(z6,"CODE",{});var kCt=s(jve);x5r=r(kCt,"pretrained_model_name_or_path"),kCt.forEach(t),$5r=r(z6,":"),z6.forEach(t),k5r=i(Al),ye=n(Al,"UL",{});var Be=s(ye);vM=n(Be,"LI",{});var QPe=s(vM);Dve=n(QPe,"STRONG",{});var SCt=s(Dve);S5r=r(SCt,"bart"),SCt.forEach(t),R5r=r(QPe," \u2014 "),GH=n(QPe,"A",{href:!0});var RCt=s(GH);P5r=r(RCt,"TFBartForConditionalGeneration"),RCt.forEach(t),B5r=r(QPe," (BART model)"),QPe.forEach(t),I5r=i(Be),FM=n(Be,"LI",{});var HPe=s(FM);Gve=n(HPe,"STRONG",{});var PCt=s(Gve);N5r=r(PCt,"blenderbot"),PCt.forEach(t),q5r=r(HPe," \u2014 "),OH=n(HPe,"A",{href:!0});var BCt=s(OH);j5r=r(BCt,"TFBlenderbotForConditionalGeneration"),BCt.forEach(t),D5r=r(HPe," (Blenderbot model)"),HPe.forEach(t),G5r=i(Be),TM=n(Be,"LI",{});var UPe=s(TM);Ove=n(UPe,"STRONG",{});var ICt=s(Ove);O5r=r(ICt,"blenderbot-small"),ICt.forEach(t),V5r=r(UPe," \u2014 "),VH=n(UPe,"A",{href:!0});var NCt=s(VH);X5r=r(NCt,"TFBlenderbotSmallForConditionalGeneration"),NCt.forEach(t),z5r=r(UPe," (BlenderbotSmall model)"),UPe.forEach(t),W5r=i(Be),MM=n(Be,"LI",{});var JPe=s(MM);Vve=n(JPe,"STRONG",{});var qCt=s(Vve);Q5r=r(qCt,"encoder-decoder"),qCt.forEach(t),H5r=r(JPe," \u2014 "),XH=n(JPe,"A",{href:!0});var jCt=s(XH);U5r=r(jCt,"TFEncoderDecoderModel"),jCt.forEach(t),J5r=r(JPe," (Encoder decoder model)"),JPe.forEach(t),Y5r=i(Be),EM=n(Be,"LI",{});var YPe=s(EM);Xve=n(YPe,"STRONG",{});var DCt=s(Xve);K5r=r(DCt,"led"),DCt.forEach(t),Z5r=r(YPe," \u2014 "),zH=n(YPe,"A",{href:!0});var GCt=s(zH);eFr=r(GCt,"TFLEDForConditionalGeneration"),GCt.forEach(t),oFr=r(YPe," (LED model)"),YPe.forEach(t),rFr=i(Be),CM=n(Be,"LI",{});var KPe=s(CM);zve=n(KPe,"STRONG",{});var OCt=s(zve);tFr=r(OCt,"marian"),OCt.forEach(t),aFr=r(KPe," \u2014 "),WH=n(KPe,"A",{href:!0});var VCt=s(WH);nFr=r(VCt,"TFMarianMTModel"),VCt.forEach(t),sFr=r(KPe," (Marian model)"),KPe.forEach(t),lFr=i(Be),wM=n(Be,"LI",{});var ZPe=s(wM);Wve=n(ZPe,"STRONG",{});var XCt=s(Wve);iFr=r(XCt,"mbart"),XCt.forEach(t),dFr=r(ZPe," \u2014 "),QH=n(ZPe,"A",{href:!0});var zCt=s(QH);cFr=r(zCt,"TFMBartForConditionalGeneration"),zCt.forEach(t),fFr=r(ZPe," (mBART model)"),ZPe.forEach(t),mFr=i(Be),AM=n(Be,"LI",{});var eBe=s(AM);Qve=n(eBe,"STRONG",{});var WCt=s(Qve);gFr=r(WCt,"mt5"),WCt.forEach(t),hFr=r(eBe," \u2014 "),HH=n(eBe,"A",{href:!0});var QCt=s(HH);pFr=r(QCt,"TFMT5ForConditionalGeneration"),QCt.forEach(t),_Fr=r(eBe," (mT5 model)"),eBe.forEach(t),uFr=i(Be),yM=n(Be,"LI",{});var oBe=s(yM);Hve=n(oBe,"STRONG",{});var HCt=s(Hve);bFr=r(HCt,"pegasus"),HCt.forEach(t),vFr=r(oBe," \u2014 "),UH=n(oBe,"A",{href:!0});var UCt=s(UH);FFr=r(UCt,"TFPegasusForConditionalGeneration"),UCt.forEach(t),TFr=r(oBe," (Pegasus model)"),oBe.forEach(t),MFr=i(Be),LM=n(Be,"LI",{});var rBe=s(LM);Uve=n(rBe,"STRONG",{});var JCt=s(Uve);EFr=r(JCt,"t5"),JCt.forEach(t),CFr=r(rBe," \u2014 "),JH=n(rBe,"A",{href:!0});var YCt=s(JH);wFr=r(YCt,"TFT5ForConditionalGeneration"),YCt.forEach(t),AFr=r(rBe," (T5 model)"),rBe.forEach(t),Be.forEach(t),yFr=i(Al),T(xM.$$.fragment,Al),Al.forEach(t),wl.forEach(t),Zje=i(f),lc=n(f,"H2",{class:!0});var nOe=s(lc);$M=n(nOe,"A",{id:!0,class:!0,href:!0});var KCt=s($M);Jve=n(KCt,"SPAN",{});var ZCt=s(Jve);T(Q8.$$.fragment,ZCt),ZCt.forEach(t),KCt.forEach(t),LFr=i(nOe),Yve=n(nOe,"SPAN",{});var e3t=s(Yve);xFr=r(e3t,"TFAutoModelForSequenceClassification"),e3t.forEach(t),nOe.forEach(t),eDe=i(f),tr=n(f,"DIV",{class:!0});var yl=s(tr);T(H8.$$.fragment,yl),$Fr=i(yl),ic=n(yl,"P",{});var Oee=s(ic);kFr=r(Oee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),YH=n(Oee,"A",{href:!0});var o3t=s(YH);SFr=r(o3t,"from_pretrained()"),o3t.forEach(t),RFr=r(Oee," class method or the "),KH=n(Oee,"A",{href:!0});var r3t=s(KH);PFr=r(r3t,"from_config()"),r3t.forEach(t),BFr=r(Oee,` class
method.`),Oee.forEach(t),IFr=i(yl),U8=n(yl,"P",{});var sOe=s(U8);NFr=r(sOe,"This class cannot be instantiated directly using "),Kve=n(sOe,"CODE",{});var t3t=s(Kve);qFr=r(t3t,"__init__()"),t3t.forEach(t),jFr=r(sOe," (throws an error)."),sOe.forEach(t),DFr=i(yl),Rt=n(yl,"DIV",{class:!0});var W6=s(Rt);T(J8.$$.fragment,W6),GFr=i(W6),Zve=n(W6,"P",{});var a3t=s(Zve);OFr=r(a3t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),a3t.forEach(t),VFr=i(W6),dc=n(W6,"P",{});var Vee=s(dc);XFr=r(Vee,`Note:
Loading a model from its configuration file does `),e5e=n(Vee,"STRONG",{});var n3t=s(e5e);zFr=r(n3t,"not"),n3t.forEach(t),WFr=r(Vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=n(Vee,"A",{href:!0});var s3t=s(ZH);QFr=r(s3t,"from_pretrained()"),s3t.forEach(t),HFr=r(Vee," to load the model weights."),Vee.forEach(t),UFr=i(W6),T(kM.$$.fragment,W6),W6.forEach(t),JFr=i(yl),kr=n(yl,"DIV",{class:!0});var Ll=s(kr);T(Y8.$$.fragment,Ll),YFr=i(Ll),o5e=n(Ll,"P",{});var l3t=s(o5e);KFr=r(l3t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),l3t.forEach(t),ZFr=i(Ll),nn=n(Ll,"P",{});var Q6=s(nn);eTr=r(Q6,"The model class to instantiate is selected based on the "),r5e=n(Q6,"CODE",{});var i3t=s(r5e);oTr=r(i3t,"model_type"),i3t.forEach(t),rTr=r(Q6,` property of the config object (either
passed as an argument or loaded from `),t5e=n(Q6,"CODE",{});var d3t=s(t5e);tTr=r(d3t,"pretrained_model_name_or_path"),d3t.forEach(t),aTr=r(Q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a5e=n(Q6,"CODE",{});var c3t=s(a5e);nTr=r(c3t,"pretrained_model_name_or_path"),c3t.forEach(t),sTr=r(Q6,":"),Q6.forEach(t),lTr=i(Ll),oe=n(Ll,"UL",{});var ae=s(oe);SM=n(ae,"LI",{});var tBe=s(SM);n5e=n(tBe,"STRONG",{});var f3t=s(n5e);iTr=r(f3t,"albert"),f3t.forEach(t),dTr=r(tBe," \u2014 "),eU=n(tBe,"A",{href:!0});var m3t=s(eU);cTr=r(m3t,"TFAlbertForSequenceClassification"),m3t.forEach(t),fTr=r(tBe," (ALBERT model)"),tBe.forEach(t),mTr=i(ae),RM=n(ae,"LI",{});var aBe=s(RM);s5e=n(aBe,"STRONG",{});var g3t=s(s5e);gTr=r(g3t,"bert"),g3t.forEach(t),hTr=r(aBe," \u2014 "),oU=n(aBe,"A",{href:!0});var h3t=s(oU);pTr=r(h3t,"TFBertForSequenceClassification"),h3t.forEach(t),_Tr=r(aBe," (BERT model)"),aBe.forEach(t),uTr=i(ae),PM=n(ae,"LI",{});var nBe=s(PM);l5e=n(nBe,"STRONG",{});var p3t=s(l5e);bTr=r(p3t,"camembert"),p3t.forEach(t),vTr=r(nBe," \u2014 "),rU=n(nBe,"A",{href:!0});var _3t=s(rU);FTr=r(_3t,"TFCamembertForSequenceClassification"),_3t.forEach(t),TTr=r(nBe," (CamemBERT model)"),nBe.forEach(t),MTr=i(ae),BM=n(ae,"LI",{});var sBe=s(BM);i5e=n(sBe,"STRONG",{});var u3t=s(i5e);ETr=r(u3t,"convbert"),u3t.forEach(t),CTr=r(sBe," \u2014 "),tU=n(sBe,"A",{href:!0});var b3t=s(tU);wTr=r(b3t,"TFConvBertForSequenceClassification"),b3t.forEach(t),ATr=r(sBe," (ConvBERT model)"),sBe.forEach(t),yTr=i(ae),IM=n(ae,"LI",{});var lBe=s(IM);d5e=n(lBe,"STRONG",{});var v3t=s(d5e);LTr=r(v3t,"ctrl"),v3t.forEach(t),xTr=r(lBe," \u2014 "),aU=n(lBe,"A",{href:!0});var F3t=s(aU);$Tr=r(F3t,"TFCTRLForSequenceClassification"),F3t.forEach(t),kTr=r(lBe," (CTRL model)"),lBe.forEach(t),STr=i(ae),NM=n(ae,"LI",{});var iBe=s(NM);c5e=n(iBe,"STRONG",{});var T3t=s(c5e);RTr=r(T3t,"deberta"),T3t.forEach(t),PTr=r(iBe," \u2014 "),nU=n(iBe,"A",{href:!0});var M3t=s(nU);BTr=r(M3t,"TFDebertaForSequenceClassification"),M3t.forEach(t),ITr=r(iBe," (DeBERTa model)"),iBe.forEach(t),NTr=i(ae),qM=n(ae,"LI",{});var dBe=s(qM);f5e=n(dBe,"STRONG",{});var E3t=s(f5e);qTr=r(E3t,"deberta-v2"),E3t.forEach(t),jTr=r(dBe," \u2014 "),sU=n(dBe,"A",{href:!0});var C3t=s(sU);DTr=r(C3t,"TFDebertaV2ForSequenceClassification"),C3t.forEach(t),GTr=r(dBe," (DeBERTa-v2 model)"),dBe.forEach(t),OTr=i(ae),jM=n(ae,"LI",{});var cBe=s(jM);m5e=n(cBe,"STRONG",{});var w3t=s(m5e);VTr=r(w3t,"distilbert"),w3t.forEach(t),XTr=r(cBe," \u2014 "),lU=n(cBe,"A",{href:!0});var A3t=s(lU);zTr=r(A3t,"TFDistilBertForSequenceClassification"),A3t.forEach(t),WTr=r(cBe," (DistilBERT model)"),cBe.forEach(t),QTr=i(ae),DM=n(ae,"LI",{});var fBe=s(DM);g5e=n(fBe,"STRONG",{});var y3t=s(g5e);HTr=r(y3t,"electra"),y3t.forEach(t),UTr=r(fBe," \u2014 "),iU=n(fBe,"A",{href:!0});var L3t=s(iU);JTr=r(L3t,"TFElectraForSequenceClassification"),L3t.forEach(t),YTr=r(fBe," (ELECTRA model)"),fBe.forEach(t),KTr=i(ae),GM=n(ae,"LI",{});var mBe=s(GM);h5e=n(mBe,"STRONG",{});var x3t=s(h5e);ZTr=r(x3t,"flaubert"),x3t.forEach(t),e7r=r(mBe," \u2014 "),dU=n(mBe,"A",{href:!0});var $3t=s(dU);o7r=r($3t,"TFFlaubertForSequenceClassification"),$3t.forEach(t),r7r=r(mBe," (FlauBERT model)"),mBe.forEach(t),t7r=i(ae),OM=n(ae,"LI",{});var gBe=s(OM);p5e=n(gBe,"STRONG",{});var k3t=s(p5e);a7r=r(k3t,"funnel"),k3t.forEach(t),n7r=r(gBe," \u2014 "),cU=n(gBe,"A",{href:!0});var S3t=s(cU);s7r=r(S3t,"TFFunnelForSequenceClassification"),S3t.forEach(t),l7r=r(gBe," (Funnel Transformer model)"),gBe.forEach(t),i7r=i(ae),VM=n(ae,"LI",{});var hBe=s(VM);_5e=n(hBe,"STRONG",{});var R3t=s(_5e);d7r=r(R3t,"gpt2"),R3t.forEach(t),c7r=r(hBe," \u2014 "),fU=n(hBe,"A",{href:!0});var P3t=s(fU);f7r=r(P3t,"TFGPT2ForSequenceClassification"),P3t.forEach(t),m7r=r(hBe," (OpenAI GPT-2 model)"),hBe.forEach(t),g7r=i(ae),XM=n(ae,"LI",{});var pBe=s(XM);u5e=n(pBe,"STRONG",{});var B3t=s(u5e);h7r=r(B3t,"gptj"),B3t.forEach(t),p7r=r(pBe," \u2014 "),mU=n(pBe,"A",{href:!0});var I3t=s(mU);_7r=r(I3t,"TFGPTJForSequenceClassification"),I3t.forEach(t),u7r=r(pBe," (GPT-J model)"),pBe.forEach(t),b7r=i(ae),zM=n(ae,"LI",{});var _Be=s(zM);b5e=n(_Be,"STRONG",{});var N3t=s(b5e);v7r=r(N3t,"layoutlm"),N3t.forEach(t),F7r=r(_Be," \u2014 "),gU=n(_Be,"A",{href:!0});var q3t=s(gU);T7r=r(q3t,"TFLayoutLMForSequenceClassification"),q3t.forEach(t),M7r=r(_Be," (LayoutLM model)"),_Be.forEach(t),E7r=i(ae),WM=n(ae,"LI",{});var uBe=s(WM);v5e=n(uBe,"STRONG",{});var j3t=s(v5e);C7r=r(j3t,"longformer"),j3t.forEach(t),w7r=r(uBe," \u2014 "),hU=n(uBe,"A",{href:!0});var D3t=s(hU);A7r=r(D3t,"TFLongformerForSequenceClassification"),D3t.forEach(t),y7r=r(uBe," (Longformer model)"),uBe.forEach(t),L7r=i(ae),QM=n(ae,"LI",{});var bBe=s(QM);F5e=n(bBe,"STRONG",{});var G3t=s(F5e);x7r=r(G3t,"mobilebert"),G3t.forEach(t),$7r=r(bBe," \u2014 "),pU=n(bBe,"A",{href:!0});var O3t=s(pU);k7r=r(O3t,"TFMobileBertForSequenceClassification"),O3t.forEach(t),S7r=r(bBe," (MobileBERT model)"),bBe.forEach(t),R7r=i(ae),HM=n(ae,"LI",{});var vBe=s(HM);T5e=n(vBe,"STRONG",{});var V3t=s(T5e);P7r=r(V3t,"mpnet"),V3t.forEach(t),B7r=r(vBe," \u2014 "),_U=n(vBe,"A",{href:!0});var X3t=s(_U);I7r=r(X3t,"TFMPNetForSequenceClassification"),X3t.forEach(t),N7r=r(vBe," (MPNet model)"),vBe.forEach(t),q7r=i(ae),UM=n(ae,"LI",{});var FBe=s(UM);M5e=n(FBe,"STRONG",{});var z3t=s(M5e);j7r=r(z3t,"openai-gpt"),z3t.forEach(t),D7r=r(FBe," \u2014 "),uU=n(FBe,"A",{href:!0});var W3t=s(uU);G7r=r(W3t,"TFOpenAIGPTForSequenceClassification"),W3t.forEach(t),O7r=r(FBe," (OpenAI GPT model)"),FBe.forEach(t),V7r=i(ae),JM=n(ae,"LI",{});var TBe=s(JM);E5e=n(TBe,"STRONG",{});var Q3t=s(E5e);X7r=r(Q3t,"rembert"),Q3t.forEach(t),z7r=r(TBe," \u2014 "),bU=n(TBe,"A",{href:!0});var H3t=s(bU);W7r=r(H3t,"TFRemBertForSequenceClassification"),H3t.forEach(t),Q7r=r(TBe," (RemBERT model)"),TBe.forEach(t),H7r=i(ae),YM=n(ae,"LI",{});var MBe=s(YM);C5e=n(MBe,"STRONG",{});var U3t=s(C5e);U7r=r(U3t,"roberta"),U3t.forEach(t),J7r=r(MBe," \u2014 "),vU=n(MBe,"A",{href:!0});var J3t=s(vU);Y7r=r(J3t,"TFRobertaForSequenceClassification"),J3t.forEach(t),K7r=r(MBe," (RoBERTa model)"),MBe.forEach(t),Z7r=i(ae),KM=n(ae,"LI",{});var EBe=s(KM);w5e=n(EBe,"STRONG",{});var Y3t=s(w5e);eMr=r(Y3t,"roformer"),Y3t.forEach(t),oMr=r(EBe," \u2014 "),FU=n(EBe,"A",{href:!0});var K3t=s(FU);rMr=r(K3t,"TFRoFormerForSequenceClassification"),K3t.forEach(t),tMr=r(EBe," (RoFormer model)"),EBe.forEach(t),aMr=i(ae),ZM=n(ae,"LI",{});var CBe=s(ZM);A5e=n(CBe,"STRONG",{});var Z3t=s(A5e);nMr=r(Z3t,"tapas"),Z3t.forEach(t),sMr=r(CBe," \u2014 "),TU=n(CBe,"A",{href:!0});var e0t=s(TU);lMr=r(e0t,"TFTapasForSequenceClassification"),e0t.forEach(t),iMr=r(CBe," (TAPAS model)"),CBe.forEach(t),dMr=i(ae),eE=n(ae,"LI",{});var wBe=s(eE);y5e=n(wBe,"STRONG",{});var o0t=s(y5e);cMr=r(o0t,"transfo-xl"),o0t.forEach(t),fMr=r(wBe," \u2014 "),MU=n(wBe,"A",{href:!0});var r0t=s(MU);mMr=r(r0t,"TFTransfoXLForSequenceClassification"),r0t.forEach(t),gMr=r(wBe," (Transformer-XL model)"),wBe.forEach(t),hMr=i(ae),oE=n(ae,"LI",{});var ABe=s(oE);L5e=n(ABe,"STRONG",{});var t0t=s(L5e);pMr=r(t0t,"xlm"),t0t.forEach(t),_Mr=r(ABe," \u2014 "),EU=n(ABe,"A",{href:!0});var a0t=s(EU);uMr=r(a0t,"TFXLMForSequenceClassification"),a0t.forEach(t),bMr=r(ABe," (XLM model)"),ABe.forEach(t),vMr=i(ae),rE=n(ae,"LI",{});var yBe=s(rE);x5e=n(yBe,"STRONG",{});var n0t=s(x5e);FMr=r(n0t,"xlm-roberta"),n0t.forEach(t),TMr=r(yBe," \u2014 "),CU=n(yBe,"A",{href:!0});var s0t=s(CU);MMr=r(s0t,"TFXLMRobertaForSequenceClassification"),s0t.forEach(t),EMr=r(yBe," (XLM-RoBERTa model)"),yBe.forEach(t),CMr=i(ae),tE=n(ae,"LI",{});var LBe=s(tE);$5e=n(LBe,"STRONG",{});var l0t=s($5e);wMr=r(l0t,"xlnet"),l0t.forEach(t),AMr=r(LBe," \u2014 "),wU=n(LBe,"A",{href:!0});var i0t=s(wU);yMr=r(i0t,"TFXLNetForSequenceClassification"),i0t.forEach(t),LMr=r(LBe," (XLNet model)"),LBe.forEach(t),ae.forEach(t),xMr=i(Ll),T(aE.$$.fragment,Ll),Ll.forEach(t),yl.forEach(t),oDe=i(f),cc=n(f,"H2",{class:!0});var lOe=s(cc);nE=n(lOe,"A",{id:!0,class:!0,href:!0});var d0t=s(nE);k5e=n(d0t,"SPAN",{});var c0t=s(k5e);T(K8.$$.fragment,c0t),c0t.forEach(t),d0t.forEach(t),$Mr=i(lOe),S5e=n(lOe,"SPAN",{});var f0t=s(S5e);kMr=r(f0t,"TFAutoModelForMultipleChoice"),f0t.forEach(t),lOe.forEach(t),rDe=i(f),ar=n(f,"DIV",{class:!0});var xl=s(ar);T(Z8.$$.fragment,xl),SMr=i(xl),fc=n(xl,"P",{});var Xee=s(fc);RMr=r(Xee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),AU=n(Xee,"A",{href:!0});var m0t=s(AU);PMr=r(m0t,"from_pretrained()"),m0t.forEach(t),BMr=r(Xee," class method or the "),yU=n(Xee,"A",{href:!0});var g0t=s(yU);IMr=r(g0t,"from_config()"),g0t.forEach(t),NMr=r(Xee,` class
method.`),Xee.forEach(t),qMr=i(xl),e9=n(xl,"P",{});var iOe=s(e9);jMr=r(iOe,"This class cannot be instantiated directly using "),R5e=n(iOe,"CODE",{});var h0t=s(R5e);DMr=r(h0t,"__init__()"),h0t.forEach(t),GMr=r(iOe," (throws an error)."),iOe.forEach(t),OMr=i(xl),Pt=n(xl,"DIV",{class:!0});var H6=s(Pt);T(o9.$$.fragment,H6),VMr=i(H6),P5e=n(H6,"P",{});var p0t=s(P5e);XMr=r(p0t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),p0t.forEach(t),zMr=i(H6),mc=n(H6,"P",{});var zee=s(mc);WMr=r(zee,`Note:
Loading a model from its configuration file does `),B5e=n(zee,"STRONG",{});var _0t=s(B5e);QMr=r(_0t,"not"),_0t.forEach(t),HMr=r(zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(zee,"A",{href:!0});var u0t=s(LU);UMr=r(u0t,"from_pretrained()"),u0t.forEach(t),JMr=r(zee," to load the model weights."),zee.forEach(t),YMr=i(H6),T(sE.$$.fragment,H6),H6.forEach(t),KMr=i(xl),Sr=n(xl,"DIV",{class:!0});var $l=s(Sr);T(r9.$$.fragment,$l),ZMr=i($l),I5e=n($l,"P",{});var b0t=s(I5e);eEr=r(b0t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),b0t.forEach(t),oEr=i($l),sn=n($l,"P",{});var U6=s(sn);rEr=r(U6,"The model class to instantiate is selected based on the "),N5e=n(U6,"CODE",{});var v0t=s(N5e);tEr=r(v0t,"model_type"),v0t.forEach(t),aEr=r(U6,` property of the config object (either
passed as an argument or loaded from `),q5e=n(U6,"CODE",{});var F0t=s(q5e);nEr=r(F0t,"pretrained_model_name_or_path"),F0t.forEach(t),sEr=r(U6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j5e=n(U6,"CODE",{});var T0t=s(j5e);lEr=r(T0t,"pretrained_model_name_or_path"),T0t.forEach(t),iEr=r(U6,":"),U6.forEach(t),dEr=i($l),pe=n($l,"UL",{});var be=s(pe);lE=n(be,"LI",{});var xBe=s(lE);D5e=n(xBe,"STRONG",{});var M0t=s(D5e);cEr=r(M0t,"albert"),M0t.forEach(t),fEr=r(xBe," \u2014 "),xU=n(xBe,"A",{href:!0});var E0t=s(xU);mEr=r(E0t,"TFAlbertForMultipleChoice"),E0t.forEach(t),gEr=r(xBe," (ALBERT model)"),xBe.forEach(t),hEr=i(be),iE=n(be,"LI",{});var $Be=s(iE);G5e=n($Be,"STRONG",{});var C0t=s(G5e);pEr=r(C0t,"bert"),C0t.forEach(t),_Er=r($Be," \u2014 "),$U=n($Be,"A",{href:!0});var w0t=s($U);uEr=r(w0t,"TFBertForMultipleChoice"),w0t.forEach(t),bEr=r($Be," (BERT model)"),$Be.forEach(t),vEr=i(be),dE=n(be,"LI",{});var kBe=s(dE);O5e=n(kBe,"STRONG",{});var A0t=s(O5e);FEr=r(A0t,"camembert"),A0t.forEach(t),TEr=r(kBe," \u2014 "),kU=n(kBe,"A",{href:!0});var y0t=s(kU);MEr=r(y0t,"TFCamembertForMultipleChoice"),y0t.forEach(t),EEr=r(kBe," (CamemBERT model)"),kBe.forEach(t),CEr=i(be),cE=n(be,"LI",{});var SBe=s(cE);V5e=n(SBe,"STRONG",{});var L0t=s(V5e);wEr=r(L0t,"convbert"),L0t.forEach(t),AEr=r(SBe," \u2014 "),SU=n(SBe,"A",{href:!0});var x0t=s(SU);yEr=r(x0t,"TFConvBertForMultipleChoice"),x0t.forEach(t),LEr=r(SBe," (ConvBERT model)"),SBe.forEach(t),xEr=i(be),fE=n(be,"LI",{});var RBe=s(fE);X5e=n(RBe,"STRONG",{});var $0t=s(X5e);$Er=r($0t,"distilbert"),$0t.forEach(t),kEr=r(RBe," \u2014 "),RU=n(RBe,"A",{href:!0});var k0t=s(RU);SEr=r(k0t,"TFDistilBertForMultipleChoice"),k0t.forEach(t),REr=r(RBe," (DistilBERT model)"),RBe.forEach(t),PEr=i(be),mE=n(be,"LI",{});var PBe=s(mE);z5e=n(PBe,"STRONG",{});var S0t=s(z5e);BEr=r(S0t,"electra"),S0t.forEach(t),IEr=r(PBe," \u2014 "),PU=n(PBe,"A",{href:!0});var R0t=s(PU);NEr=r(R0t,"TFElectraForMultipleChoice"),R0t.forEach(t),qEr=r(PBe," (ELECTRA model)"),PBe.forEach(t),jEr=i(be),gE=n(be,"LI",{});var BBe=s(gE);W5e=n(BBe,"STRONG",{});var P0t=s(W5e);DEr=r(P0t,"flaubert"),P0t.forEach(t),GEr=r(BBe," \u2014 "),BU=n(BBe,"A",{href:!0});var B0t=s(BU);OEr=r(B0t,"TFFlaubertForMultipleChoice"),B0t.forEach(t),VEr=r(BBe," (FlauBERT model)"),BBe.forEach(t),XEr=i(be),hE=n(be,"LI",{});var IBe=s(hE);Q5e=n(IBe,"STRONG",{});var I0t=s(Q5e);zEr=r(I0t,"funnel"),I0t.forEach(t),WEr=r(IBe," \u2014 "),IU=n(IBe,"A",{href:!0});var N0t=s(IU);QEr=r(N0t,"TFFunnelForMultipleChoice"),N0t.forEach(t),HEr=r(IBe," (Funnel Transformer model)"),IBe.forEach(t),UEr=i(be),pE=n(be,"LI",{});var NBe=s(pE);H5e=n(NBe,"STRONG",{});var q0t=s(H5e);JEr=r(q0t,"longformer"),q0t.forEach(t),YEr=r(NBe," \u2014 "),NU=n(NBe,"A",{href:!0});var j0t=s(NU);KEr=r(j0t,"TFLongformerForMultipleChoice"),j0t.forEach(t),ZEr=r(NBe," (Longformer model)"),NBe.forEach(t),eCr=i(be),_E=n(be,"LI",{});var qBe=s(_E);U5e=n(qBe,"STRONG",{});var D0t=s(U5e);oCr=r(D0t,"mobilebert"),D0t.forEach(t),rCr=r(qBe," \u2014 "),qU=n(qBe,"A",{href:!0});var G0t=s(qU);tCr=r(G0t,"TFMobileBertForMultipleChoice"),G0t.forEach(t),aCr=r(qBe," (MobileBERT model)"),qBe.forEach(t),nCr=i(be),uE=n(be,"LI",{});var jBe=s(uE);J5e=n(jBe,"STRONG",{});var O0t=s(J5e);sCr=r(O0t,"mpnet"),O0t.forEach(t),lCr=r(jBe," \u2014 "),jU=n(jBe,"A",{href:!0});var V0t=s(jU);iCr=r(V0t,"TFMPNetForMultipleChoice"),V0t.forEach(t),dCr=r(jBe," (MPNet model)"),jBe.forEach(t),cCr=i(be),bE=n(be,"LI",{});var DBe=s(bE);Y5e=n(DBe,"STRONG",{});var X0t=s(Y5e);fCr=r(X0t,"rembert"),X0t.forEach(t),mCr=r(DBe," \u2014 "),DU=n(DBe,"A",{href:!0});var z0t=s(DU);gCr=r(z0t,"TFRemBertForMultipleChoice"),z0t.forEach(t),hCr=r(DBe," (RemBERT model)"),DBe.forEach(t),pCr=i(be),vE=n(be,"LI",{});var GBe=s(vE);K5e=n(GBe,"STRONG",{});var W0t=s(K5e);_Cr=r(W0t,"roberta"),W0t.forEach(t),uCr=r(GBe," \u2014 "),GU=n(GBe,"A",{href:!0});var Q0t=s(GU);bCr=r(Q0t,"TFRobertaForMultipleChoice"),Q0t.forEach(t),vCr=r(GBe," (RoBERTa model)"),GBe.forEach(t),FCr=i(be),FE=n(be,"LI",{});var OBe=s(FE);Z5e=n(OBe,"STRONG",{});var H0t=s(Z5e);TCr=r(H0t,"roformer"),H0t.forEach(t),MCr=r(OBe," \u2014 "),OU=n(OBe,"A",{href:!0});var U0t=s(OU);ECr=r(U0t,"TFRoFormerForMultipleChoice"),U0t.forEach(t),CCr=r(OBe," (RoFormer model)"),OBe.forEach(t),wCr=i(be),TE=n(be,"LI",{});var VBe=s(TE);eFe=n(VBe,"STRONG",{});var J0t=s(eFe);ACr=r(J0t,"xlm"),J0t.forEach(t),yCr=r(VBe," \u2014 "),VU=n(VBe,"A",{href:!0});var Y0t=s(VU);LCr=r(Y0t,"TFXLMForMultipleChoice"),Y0t.forEach(t),xCr=r(VBe," (XLM model)"),VBe.forEach(t),$Cr=i(be),ME=n(be,"LI",{});var XBe=s(ME);oFe=n(XBe,"STRONG",{});var K0t=s(oFe);kCr=r(K0t,"xlm-roberta"),K0t.forEach(t),SCr=r(XBe," \u2014 "),XU=n(XBe,"A",{href:!0});var Z0t=s(XU);RCr=r(Z0t,"TFXLMRobertaForMultipleChoice"),Z0t.forEach(t),PCr=r(XBe," (XLM-RoBERTa model)"),XBe.forEach(t),BCr=i(be),EE=n(be,"LI",{});var zBe=s(EE);rFe=n(zBe,"STRONG",{});var ewt=s(rFe);ICr=r(ewt,"xlnet"),ewt.forEach(t),NCr=r(zBe," \u2014 "),zU=n(zBe,"A",{href:!0});var owt=s(zU);qCr=r(owt,"TFXLNetForMultipleChoice"),owt.forEach(t),jCr=r(zBe," (XLNet model)"),zBe.forEach(t),be.forEach(t),DCr=i($l),T(CE.$$.fragment,$l),$l.forEach(t),xl.forEach(t),tDe=i(f),gc=n(f,"H2",{class:!0});var dOe=s(gc);wE=n(dOe,"A",{id:!0,class:!0,href:!0});var rwt=s(wE);tFe=n(rwt,"SPAN",{});var twt=s(tFe);T(t9.$$.fragment,twt),twt.forEach(t),rwt.forEach(t),GCr=i(dOe),aFe=n(dOe,"SPAN",{});var awt=s(aFe);OCr=r(awt,"TFAutoModelForNextSentencePrediction"),awt.forEach(t),dOe.forEach(t),aDe=i(f),nr=n(f,"DIV",{class:!0});var kl=s(nr);T(a9.$$.fragment,kl),VCr=i(kl),hc=n(kl,"P",{});var Wee=s(hc);XCr=r(Wee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),WU=n(Wee,"A",{href:!0});var nwt=s(WU);zCr=r(nwt,"from_pretrained()"),nwt.forEach(t),WCr=r(Wee," class method or the "),QU=n(Wee,"A",{href:!0});var swt=s(QU);QCr=r(swt,"from_config()"),swt.forEach(t),HCr=r(Wee,` class
method.`),Wee.forEach(t),UCr=i(kl),n9=n(kl,"P",{});var cOe=s(n9);JCr=r(cOe,"This class cannot be instantiated directly using "),nFe=n(cOe,"CODE",{});var lwt=s(nFe);YCr=r(lwt,"__init__()"),lwt.forEach(t),KCr=r(cOe," (throws an error)."),cOe.forEach(t),ZCr=i(kl),Bt=n(kl,"DIV",{class:!0});var J6=s(Bt);T(s9.$$.fragment,J6),e3r=i(J6),sFe=n(J6,"P",{});var iwt=s(sFe);o3r=r(iwt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),iwt.forEach(t),r3r=i(J6),pc=n(J6,"P",{});var Qee=s(pc);t3r=r(Qee,`Note:
Loading a model from its configuration file does `),lFe=n(Qee,"STRONG",{});var dwt=s(lFe);a3r=r(dwt,"not"),dwt.forEach(t),n3r=r(Qee,` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=n(Qee,"A",{href:!0});var cwt=s(HU);s3r=r(cwt,"from_pretrained()"),cwt.forEach(t),l3r=r(Qee," to load the model weights."),Qee.forEach(t),i3r=i(J6),T(AE.$$.fragment,J6),J6.forEach(t),d3r=i(kl),Rr=n(kl,"DIV",{class:!0});var Sl=s(Rr);T(l9.$$.fragment,Sl),c3r=i(Sl),iFe=n(Sl,"P",{});var fwt=s(iFe);f3r=r(fwt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),fwt.forEach(t),m3r=i(Sl),ln=n(Sl,"P",{});var Y6=s(ln);g3r=r(Y6,"The model class to instantiate is selected based on the "),dFe=n(Y6,"CODE",{});var mwt=s(dFe);h3r=r(mwt,"model_type"),mwt.forEach(t),p3r=r(Y6,` property of the config object (either
passed as an argument or loaded from `),cFe=n(Y6,"CODE",{});var gwt=s(cFe);_3r=r(gwt,"pretrained_model_name_or_path"),gwt.forEach(t),u3r=r(Y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fFe=n(Y6,"CODE",{});var hwt=s(fFe);b3r=r(hwt,"pretrained_model_name_or_path"),hwt.forEach(t),v3r=r(Y6,":"),Y6.forEach(t),F3r=i(Sl),i9=n(Sl,"UL",{});var fOe=s(i9);yE=n(fOe,"LI",{});var WBe=s(yE);mFe=n(WBe,"STRONG",{});var pwt=s(mFe);T3r=r(pwt,"bert"),pwt.forEach(t),M3r=r(WBe," \u2014 "),UU=n(WBe,"A",{href:!0});var _wt=s(UU);E3r=r(_wt,"TFBertForNextSentencePrediction"),_wt.forEach(t),C3r=r(WBe," (BERT model)"),WBe.forEach(t),w3r=i(fOe),LE=n(fOe,"LI",{});var QBe=s(LE);gFe=n(QBe,"STRONG",{});var uwt=s(gFe);A3r=r(uwt,"mobilebert"),uwt.forEach(t),y3r=r(QBe," \u2014 "),JU=n(QBe,"A",{href:!0});var bwt=s(JU);L3r=r(bwt,"TFMobileBertForNextSentencePrediction"),bwt.forEach(t),x3r=r(QBe," (MobileBERT model)"),QBe.forEach(t),fOe.forEach(t),$3r=i(Sl),T(xE.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),nDe=i(f),_c=n(f,"H2",{class:!0});var mOe=s(_c);$E=n(mOe,"A",{id:!0,class:!0,href:!0});var vwt=s($E);hFe=n(vwt,"SPAN",{});var Fwt=s(hFe);T(d9.$$.fragment,Fwt),Fwt.forEach(t),vwt.forEach(t),k3r=i(mOe),pFe=n(mOe,"SPAN",{});var Twt=s(pFe);S3r=r(Twt,"TFAutoModelForTableQuestionAnswering"),Twt.forEach(t),mOe.forEach(t),sDe=i(f),sr=n(f,"DIV",{class:!0});var Rl=s(sr);T(c9.$$.fragment,Rl),R3r=i(Rl),uc=n(Rl,"P",{});var Hee=s(uc);P3r=r(Hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),YU=n(Hee,"A",{href:!0});var Mwt=s(YU);B3r=r(Mwt,"from_pretrained()"),Mwt.forEach(t),I3r=r(Hee," class method or the "),KU=n(Hee,"A",{href:!0});var Ewt=s(KU);N3r=r(Ewt,"from_config()"),Ewt.forEach(t),q3r=r(Hee,` class
method.`),Hee.forEach(t),j3r=i(Rl),f9=n(Rl,"P",{});var gOe=s(f9);D3r=r(gOe,"This class cannot be instantiated directly using "),_Fe=n(gOe,"CODE",{});var Cwt=s(_Fe);G3r=r(Cwt,"__init__()"),Cwt.forEach(t),O3r=r(gOe," (throws an error)."),gOe.forEach(t),V3r=i(Rl),It=n(Rl,"DIV",{class:!0});var K6=s(It);T(m9.$$.fragment,K6),X3r=i(K6),uFe=n(K6,"P",{});var wwt=s(uFe);z3r=r(wwt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),wwt.forEach(t),W3r=i(K6),bc=n(K6,"P",{});var Uee=s(bc);Q3r=r(Uee,`Note:
Loading a model from its configuration file does `),bFe=n(Uee,"STRONG",{});var Awt=s(bFe);H3r=r(Awt,"not"),Awt.forEach(t),U3r=r(Uee,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZU=n(Uee,"A",{href:!0});var ywt=s(ZU);J3r=r(ywt,"from_pretrained()"),ywt.forEach(t),Y3r=r(Uee," to load the model weights."),Uee.forEach(t),K3r=i(K6),T(kE.$$.fragment,K6),K6.forEach(t),Z3r=i(Rl),Pr=n(Rl,"DIV",{class:!0});var Pl=s(Pr);T(g9.$$.fragment,Pl),e0r=i(Pl),vFe=n(Pl,"P",{});var Lwt=s(vFe);o0r=r(Lwt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Lwt.forEach(t),r0r=i(Pl),dn=n(Pl,"P",{});var Z6=s(dn);t0r=r(Z6,"The model class to instantiate is selected based on the "),FFe=n(Z6,"CODE",{});var xwt=s(FFe);a0r=r(xwt,"model_type"),xwt.forEach(t),n0r=r(Z6,` property of the config object (either
passed as an argument or loaded from `),TFe=n(Z6,"CODE",{});var $wt=s(TFe);s0r=r($wt,"pretrained_model_name_or_path"),$wt.forEach(t),l0r=r(Z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MFe=n(Z6,"CODE",{});var kwt=s(MFe);i0r=r(kwt,"pretrained_model_name_or_path"),kwt.forEach(t),d0r=r(Z6,":"),Z6.forEach(t),c0r=i(Pl),EFe=n(Pl,"UL",{});var Swt=s(EFe);SE=n(Swt,"LI",{});var HBe=s(SE);CFe=n(HBe,"STRONG",{});var Rwt=s(CFe);f0r=r(Rwt,"tapas"),Rwt.forEach(t),m0r=r(HBe," \u2014 "),eJ=n(HBe,"A",{href:!0});var Pwt=s(eJ);g0r=r(Pwt,"TFTapasForQuestionAnswering"),Pwt.forEach(t),h0r=r(HBe," (TAPAS model)"),HBe.forEach(t),Swt.forEach(t),p0r=i(Pl),T(RE.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),lDe=i(f),vc=n(f,"H2",{class:!0});var hOe=s(vc);PE=n(hOe,"A",{id:!0,class:!0,href:!0});var Bwt=s(PE);wFe=n(Bwt,"SPAN",{});var Iwt=s(wFe);T(h9.$$.fragment,Iwt),Iwt.forEach(t),Bwt.forEach(t),_0r=i(hOe),AFe=n(hOe,"SPAN",{});var Nwt=s(AFe);u0r=r(Nwt,"TFAutoModelForTokenClassification"),Nwt.forEach(t),hOe.forEach(t),iDe=i(f),lr=n(f,"DIV",{class:!0});var Bl=s(lr);T(p9.$$.fragment,Bl),b0r=i(Bl),Fc=n(Bl,"P",{});var Jee=s(Fc);v0r=r(Jee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),oJ=n(Jee,"A",{href:!0});var qwt=s(oJ);F0r=r(qwt,"from_pretrained()"),qwt.forEach(t),T0r=r(Jee," class method or the "),rJ=n(Jee,"A",{href:!0});var jwt=s(rJ);M0r=r(jwt,"from_config()"),jwt.forEach(t),E0r=r(Jee,` class
method.`),Jee.forEach(t),C0r=i(Bl),_9=n(Bl,"P",{});var pOe=s(_9);w0r=r(pOe,"This class cannot be instantiated directly using "),yFe=n(pOe,"CODE",{});var Dwt=s(yFe);A0r=r(Dwt,"__init__()"),Dwt.forEach(t),y0r=r(pOe," (throws an error)."),pOe.forEach(t),L0r=i(Bl),Nt=n(Bl,"DIV",{class:!0});var eA=s(Nt);T(u9.$$.fragment,eA),x0r=i(eA),LFe=n(eA,"P",{});var Gwt=s(LFe);$0r=r(Gwt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Gwt.forEach(t),k0r=i(eA),Tc=n(eA,"P",{});var Yee=s(Tc);S0r=r(Yee,`Note:
Loading a model from its configuration file does `),xFe=n(Yee,"STRONG",{});var Owt=s(xFe);R0r=r(Owt,"not"),Owt.forEach(t),P0r=r(Yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),tJ=n(Yee,"A",{href:!0});var Vwt=s(tJ);B0r=r(Vwt,"from_pretrained()"),Vwt.forEach(t),I0r=r(Yee," to load the model weights."),Yee.forEach(t),N0r=i(eA),T(BE.$$.fragment,eA),eA.forEach(t),q0r=i(Bl),Br=n(Bl,"DIV",{class:!0});var Il=s(Br);T(b9.$$.fragment,Il),j0r=i(Il),$Fe=n(Il,"P",{});var Xwt=s($Fe);D0r=r(Xwt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Xwt.forEach(t),G0r=i(Il),cn=n(Il,"P",{});var oA=s(cn);O0r=r(oA,"The model class to instantiate is selected based on the "),kFe=n(oA,"CODE",{});var zwt=s(kFe);V0r=r(zwt,"model_type"),zwt.forEach(t),X0r=r(oA,` property of the config object (either
passed as an argument or loaded from `),SFe=n(oA,"CODE",{});var Wwt=s(SFe);z0r=r(Wwt,"pretrained_model_name_or_path"),Wwt.forEach(t),W0r=r(oA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RFe=n(oA,"CODE",{});var Qwt=s(RFe);Q0r=r(Qwt,"pretrained_model_name_or_path"),Qwt.forEach(t),H0r=r(oA,":"),oA.forEach(t),U0r=i(Il),de=n(Il,"UL",{});var me=s(de);IE=n(me,"LI",{});var UBe=s(IE);PFe=n(UBe,"STRONG",{});var Hwt=s(PFe);J0r=r(Hwt,"albert"),Hwt.forEach(t),Y0r=r(UBe," \u2014 "),aJ=n(UBe,"A",{href:!0});var Uwt=s(aJ);K0r=r(Uwt,"TFAlbertForTokenClassification"),Uwt.forEach(t),Z0r=r(UBe," (ALBERT model)"),UBe.forEach(t),ewr=i(me),NE=n(me,"LI",{});var JBe=s(NE);BFe=n(JBe,"STRONG",{});var Jwt=s(BFe);owr=r(Jwt,"bert"),Jwt.forEach(t),rwr=r(JBe," \u2014 "),nJ=n(JBe,"A",{href:!0});var Ywt=s(nJ);twr=r(Ywt,"TFBertForTokenClassification"),Ywt.forEach(t),awr=r(JBe," (BERT model)"),JBe.forEach(t),nwr=i(me),qE=n(me,"LI",{});var YBe=s(qE);IFe=n(YBe,"STRONG",{});var Kwt=s(IFe);swr=r(Kwt,"camembert"),Kwt.forEach(t),lwr=r(YBe," \u2014 "),sJ=n(YBe,"A",{href:!0});var Zwt=s(sJ);iwr=r(Zwt,"TFCamembertForTokenClassification"),Zwt.forEach(t),dwr=r(YBe," (CamemBERT model)"),YBe.forEach(t),cwr=i(me),jE=n(me,"LI",{});var KBe=s(jE);NFe=n(KBe,"STRONG",{});var e6t=s(NFe);fwr=r(e6t,"convbert"),e6t.forEach(t),mwr=r(KBe," \u2014 "),lJ=n(KBe,"A",{href:!0});var o6t=s(lJ);gwr=r(o6t,"TFConvBertForTokenClassification"),o6t.forEach(t),hwr=r(KBe," (ConvBERT model)"),KBe.forEach(t),pwr=i(me),DE=n(me,"LI",{});var ZBe=s(DE);qFe=n(ZBe,"STRONG",{});var r6t=s(qFe);_wr=r(r6t,"deberta"),r6t.forEach(t),uwr=r(ZBe," \u2014 "),iJ=n(ZBe,"A",{href:!0});var t6t=s(iJ);bwr=r(t6t,"TFDebertaForTokenClassification"),t6t.forEach(t),vwr=r(ZBe," (DeBERTa model)"),ZBe.forEach(t),Fwr=i(me),GE=n(me,"LI",{});var eIe=s(GE);jFe=n(eIe,"STRONG",{});var a6t=s(jFe);Twr=r(a6t,"deberta-v2"),a6t.forEach(t),Mwr=r(eIe," \u2014 "),dJ=n(eIe,"A",{href:!0});var n6t=s(dJ);Ewr=r(n6t,"TFDebertaV2ForTokenClassification"),n6t.forEach(t),Cwr=r(eIe," (DeBERTa-v2 model)"),eIe.forEach(t),wwr=i(me),OE=n(me,"LI",{});var oIe=s(OE);DFe=n(oIe,"STRONG",{});var s6t=s(DFe);Awr=r(s6t,"distilbert"),s6t.forEach(t),ywr=r(oIe," \u2014 "),cJ=n(oIe,"A",{href:!0});var l6t=s(cJ);Lwr=r(l6t,"TFDistilBertForTokenClassification"),l6t.forEach(t),xwr=r(oIe," (DistilBERT model)"),oIe.forEach(t),$wr=i(me),VE=n(me,"LI",{});var rIe=s(VE);GFe=n(rIe,"STRONG",{});var i6t=s(GFe);kwr=r(i6t,"electra"),i6t.forEach(t),Swr=r(rIe," \u2014 "),fJ=n(rIe,"A",{href:!0});var d6t=s(fJ);Rwr=r(d6t,"TFElectraForTokenClassification"),d6t.forEach(t),Pwr=r(rIe," (ELECTRA model)"),rIe.forEach(t),Bwr=i(me),XE=n(me,"LI",{});var tIe=s(XE);OFe=n(tIe,"STRONG",{});var c6t=s(OFe);Iwr=r(c6t,"flaubert"),c6t.forEach(t),Nwr=r(tIe," \u2014 "),mJ=n(tIe,"A",{href:!0});var f6t=s(mJ);qwr=r(f6t,"TFFlaubertForTokenClassification"),f6t.forEach(t),jwr=r(tIe," (FlauBERT model)"),tIe.forEach(t),Dwr=i(me),zE=n(me,"LI",{});var aIe=s(zE);VFe=n(aIe,"STRONG",{});var m6t=s(VFe);Gwr=r(m6t,"funnel"),m6t.forEach(t),Owr=r(aIe," \u2014 "),gJ=n(aIe,"A",{href:!0});var g6t=s(gJ);Vwr=r(g6t,"TFFunnelForTokenClassification"),g6t.forEach(t),Xwr=r(aIe," (Funnel Transformer model)"),aIe.forEach(t),zwr=i(me),WE=n(me,"LI",{});var nIe=s(WE);XFe=n(nIe,"STRONG",{});var h6t=s(XFe);Wwr=r(h6t,"layoutlm"),h6t.forEach(t),Qwr=r(nIe," \u2014 "),hJ=n(nIe,"A",{href:!0});var p6t=s(hJ);Hwr=r(p6t,"TFLayoutLMForTokenClassification"),p6t.forEach(t),Uwr=r(nIe," (LayoutLM model)"),nIe.forEach(t),Jwr=i(me),QE=n(me,"LI",{});var sIe=s(QE);zFe=n(sIe,"STRONG",{});var _6t=s(zFe);Ywr=r(_6t,"longformer"),_6t.forEach(t),Kwr=r(sIe," \u2014 "),pJ=n(sIe,"A",{href:!0});var u6t=s(pJ);Zwr=r(u6t,"TFLongformerForTokenClassification"),u6t.forEach(t),e6r=r(sIe," (Longformer model)"),sIe.forEach(t),o6r=i(me),HE=n(me,"LI",{});var lIe=s(HE);WFe=n(lIe,"STRONG",{});var b6t=s(WFe);r6r=r(b6t,"mobilebert"),b6t.forEach(t),t6r=r(lIe," \u2014 "),_J=n(lIe,"A",{href:!0});var v6t=s(_J);a6r=r(v6t,"TFMobileBertForTokenClassification"),v6t.forEach(t),n6r=r(lIe," (MobileBERT model)"),lIe.forEach(t),s6r=i(me),UE=n(me,"LI",{});var iIe=s(UE);QFe=n(iIe,"STRONG",{});var F6t=s(QFe);l6r=r(F6t,"mpnet"),F6t.forEach(t),i6r=r(iIe," \u2014 "),uJ=n(iIe,"A",{href:!0});var T6t=s(uJ);d6r=r(T6t,"TFMPNetForTokenClassification"),T6t.forEach(t),c6r=r(iIe," (MPNet model)"),iIe.forEach(t),f6r=i(me),JE=n(me,"LI",{});var dIe=s(JE);HFe=n(dIe,"STRONG",{});var M6t=s(HFe);m6r=r(M6t,"rembert"),M6t.forEach(t),g6r=r(dIe," \u2014 "),bJ=n(dIe,"A",{href:!0});var E6t=s(bJ);h6r=r(E6t,"TFRemBertForTokenClassification"),E6t.forEach(t),p6r=r(dIe," (RemBERT model)"),dIe.forEach(t),_6r=i(me),YE=n(me,"LI",{});var cIe=s(YE);UFe=n(cIe,"STRONG",{});var C6t=s(UFe);u6r=r(C6t,"roberta"),C6t.forEach(t),b6r=r(cIe," \u2014 "),vJ=n(cIe,"A",{href:!0});var w6t=s(vJ);v6r=r(w6t,"TFRobertaForTokenClassification"),w6t.forEach(t),F6r=r(cIe," (RoBERTa model)"),cIe.forEach(t),T6r=i(me),KE=n(me,"LI",{});var fIe=s(KE);JFe=n(fIe,"STRONG",{});var A6t=s(JFe);M6r=r(A6t,"roformer"),A6t.forEach(t),E6r=r(fIe," \u2014 "),FJ=n(fIe,"A",{href:!0});var y6t=s(FJ);C6r=r(y6t,"TFRoFormerForTokenClassification"),y6t.forEach(t),w6r=r(fIe," (RoFormer model)"),fIe.forEach(t),A6r=i(me),ZE=n(me,"LI",{});var mIe=s(ZE);YFe=n(mIe,"STRONG",{});var L6t=s(YFe);y6r=r(L6t,"xlm"),L6t.forEach(t),L6r=r(mIe," \u2014 "),TJ=n(mIe,"A",{href:!0});var x6t=s(TJ);x6r=r(x6t,"TFXLMForTokenClassification"),x6t.forEach(t),$6r=r(mIe," (XLM model)"),mIe.forEach(t),k6r=i(me),eC=n(me,"LI",{});var gIe=s(eC);KFe=n(gIe,"STRONG",{});var $6t=s(KFe);S6r=r($6t,"xlm-roberta"),$6t.forEach(t),R6r=r(gIe," \u2014 "),MJ=n(gIe,"A",{href:!0});var k6t=s(MJ);P6r=r(k6t,"TFXLMRobertaForTokenClassification"),k6t.forEach(t),B6r=r(gIe," (XLM-RoBERTa model)"),gIe.forEach(t),I6r=i(me),oC=n(me,"LI",{});var hIe=s(oC);ZFe=n(hIe,"STRONG",{});var S6t=s(ZFe);N6r=r(S6t,"xlnet"),S6t.forEach(t),q6r=r(hIe," \u2014 "),EJ=n(hIe,"A",{href:!0});var R6t=s(EJ);j6r=r(R6t,"TFXLNetForTokenClassification"),R6t.forEach(t),D6r=r(hIe," (XLNet model)"),hIe.forEach(t),me.forEach(t),G6r=i(Il),T(rC.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),dDe=i(f),Mc=n(f,"H2",{class:!0});var _Oe=s(Mc);tC=n(_Oe,"A",{id:!0,class:!0,href:!0});var P6t=s(tC);eTe=n(P6t,"SPAN",{});var B6t=s(eTe);T(v9.$$.fragment,B6t),B6t.forEach(t),P6t.forEach(t),O6r=i(_Oe),oTe=n(_Oe,"SPAN",{});var I6t=s(oTe);V6r=r(I6t,"TFAutoModelForQuestionAnswering"),I6t.forEach(t),_Oe.forEach(t),cDe=i(f),ir=n(f,"DIV",{class:!0});var Nl=s(ir);T(F9.$$.fragment,Nl),X6r=i(Nl),Ec=n(Nl,"P",{});var Kee=s(Ec);z6r=r(Kee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),CJ=n(Kee,"A",{href:!0});var N6t=s(CJ);W6r=r(N6t,"from_pretrained()"),N6t.forEach(t),Q6r=r(Kee," class method or the "),wJ=n(Kee,"A",{href:!0});var q6t=s(wJ);H6r=r(q6t,"from_config()"),q6t.forEach(t),U6r=r(Kee,` class
method.`),Kee.forEach(t),J6r=i(Nl),T9=n(Nl,"P",{});var uOe=s(T9);Y6r=r(uOe,"This class cannot be instantiated directly using "),rTe=n(uOe,"CODE",{});var j6t=s(rTe);K6r=r(j6t,"__init__()"),j6t.forEach(t),Z6r=r(uOe," (throws an error)."),uOe.forEach(t),eAr=i(Nl),qt=n(Nl,"DIV",{class:!0});var rA=s(qt);T(M9.$$.fragment,rA),oAr=i(rA),tTe=n(rA,"P",{});var D6t=s(tTe);rAr=r(D6t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),D6t.forEach(t),tAr=i(rA),Cc=n(rA,"P",{});var Zee=s(Cc);aAr=r(Zee,`Note:
Loading a model from its configuration file does `),aTe=n(Zee,"STRONG",{});var G6t=s(aTe);nAr=r(G6t,"not"),G6t.forEach(t),sAr=r(Zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),AJ=n(Zee,"A",{href:!0});var O6t=s(AJ);lAr=r(O6t,"from_pretrained()"),O6t.forEach(t),iAr=r(Zee," to load the model weights."),Zee.forEach(t),dAr=i(rA),T(aC.$$.fragment,rA),rA.forEach(t),cAr=i(Nl),Ir=n(Nl,"DIV",{class:!0});var ql=s(Ir);T(E9.$$.fragment,ql),fAr=i(ql),nTe=n(ql,"P",{});var V6t=s(nTe);mAr=r(V6t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),V6t.forEach(t),gAr=i(ql),fn=n(ql,"P",{});var tA=s(fn);hAr=r(tA,"The model class to instantiate is selected based on the "),sTe=n(tA,"CODE",{});var X6t=s(sTe);pAr=r(X6t,"model_type"),X6t.forEach(t),_Ar=r(tA,` property of the config object (either
passed as an argument or loaded from `),lTe=n(tA,"CODE",{});var z6t=s(lTe);uAr=r(z6t,"pretrained_model_name_or_path"),z6t.forEach(t),bAr=r(tA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=n(tA,"CODE",{});var W6t=s(iTe);vAr=r(W6t,"pretrained_model_name_or_path"),W6t.forEach(t),FAr=r(tA,":"),tA.forEach(t),TAr=i(ql),ce=n(ql,"UL",{});var ge=s(ce);nC=n(ge,"LI",{});var pIe=s(nC);dTe=n(pIe,"STRONG",{});var Q6t=s(dTe);MAr=r(Q6t,"albert"),Q6t.forEach(t),EAr=r(pIe," \u2014 "),yJ=n(pIe,"A",{href:!0});var H6t=s(yJ);CAr=r(H6t,"TFAlbertForQuestionAnswering"),H6t.forEach(t),wAr=r(pIe," (ALBERT model)"),pIe.forEach(t),AAr=i(ge),sC=n(ge,"LI",{});var _Ie=s(sC);cTe=n(_Ie,"STRONG",{});var U6t=s(cTe);yAr=r(U6t,"bert"),U6t.forEach(t),LAr=r(_Ie," \u2014 "),LJ=n(_Ie,"A",{href:!0});var J6t=s(LJ);xAr=r(J6t,"TFBertForQuestionAnswering"),J6t.forEach(t),$Ar=r(_Ie," (BERT model)"),_Ie.forEach(t),kAr=i(ge),lC=n(ge,"LI",{});var uIe=s(lC);fTe=n(uIe,"STRONG",{});var Y6t=s(fTe);SAr=r(Y6t,"camembert"),Y6t.forEach(t),RAr=r(uIe," \u2014 "),xJ=n(uIe,"A",{href:!0});var K6t=s(xJ);PAr=r(K6t,"TFCamembertForQuestionAnswering"),K6t.forEach(t),BAr=r(uIe," (CamemBERT model)"),uIe.forEach(t),IAr=i(ge),iC=n(ge,"LI",{});var bIe=s(iC);mTe=n(bIe,"STRONG",{});var Z6t=s(mTe);NAr=r(Z6t,"convbert"),Z6t.forEach(t),qAr=r(bIe," \u2014 "),$J=n(bIe,"A",{href:!0});var eAt=s($J);jAr=r(eAt,"TFConvBertForQuestionAnswering"),eAt.forEach(t),DAr=r(bIe," (ConvBERT model)"),bIe.forEach(t),GAr=i(ge),dC=n(ge,"LI",{});var vIe=s(dC);gTe=n(vIe,"STRONG",{});var oAt=s(gTe);OAr=r(oAt,"deberta"),oAt.forEach(t),VAr=r(vIe," \u2014 "),kJ=n(vIe,"A",{href:!0});var rAt=s(kJ);XAr=r(rAt,"TFDebertaForQuestionAnswering"),rAt.forEach(t),zAr=r(vIe," (DeBERTa model)"),vIe.forEach(t),WAr=i(ge),cC=n(ge,"LI",{});var FIe=s(cC);hTe=n(FIe,"STRONG",{});var tAt=s(hTe);QAr=r(tAt,"deberta-v2"),tAt.forEach(t),HAr=r(FIe," \u2014 "),SJ=n(FIe,"A",{href:!0});var aAt=s(SJ);UAr=r(aAt,"TFDebertaV2ForQuestionAnswering"),aAt.forEach(t),JAr=r(FIe," (DeBERTa-v2 model)"),FIe.forEach(t),YAr=i(ge),fC=n(ge,"LI",{});var TIe=s(fC);pTe=n(TIe,"STRONG",{});var nAt=s(pTe);KAr=r(nAt,"distilbert"),nAt.forEach(t),ZAr=r(TIe," \u2014 "),RJ=n(TIe,"A",{href:!0});var sAt=s(RJ);eyr=r(sAt,"TFDistilBertForQuestionAnswering"),sAt.forEach(t),oyr=r(TIe," (DistilBERT model)"),TIe.forEach(t),ryr=i(ge),mC=n(ge,"LI",{});var MIe=s(mC);_Te=n(MIe,"STRONG",{});var lAt=s(_Te);tyr=r(lAt,"electra"),lAt.forEach(t),ayr=r(MIe," \u2014 "),PJ=n(MIe,"A",{href:!0});var iAt=s(PJ);nyr=r(iAt,"TFElectraForQuestionAnswering"),iAt.forEach(t),syr=r(MIe," (ELECTRA model)"),MIe.forEach(t),lyr=i(ge),gC=n(ge,"LI",{});var EIe=s(gC);uTe=n(EIe,"STRONG",{});var dAt=s(uTe);iyr=r(dAt,"flaubert"),dAt.forEach(t),dyr=r(EIe," \u2014 "),BJ=n(EIe,"A",{href:!0});var cAt=s(BJ);cyr=r(cAt,"TFFlaubertForQuestionAnsweringSimple"),cAt.forEach(t),fyr=r(EIe," (FlauBERT model)"),EIe.forEach(t),myr=i(ge),hC=n(ge,"LI",{});var CIe=s(hC);bTe=n(CIe,"STRONG",{});var fAt=s(bTe);gyr=r(fAt,"funnel"),fAt.forEach(t),hyr=r(CIe," \u2014 "),IJ=n(CIe,"A",{href:!0});var mAt=s(IJ);pyr=r(mAt,"TFFunnelForQuestionAnswering"),mAt.forEach(t),_yr=r(CIe," (Funnel Transformer model)"),CIe.forEach(t),uyr=i(ge),pC=n(ge,"LI",{});var wIe=s(pC);vTe=n(wIe,"STRONG",{});var gAt=s(vTe);byr=r(gAt,"gptj"),gAt.forEach(t),vyr=r(wIe," \u2014 "),NJ=n(wIe,"A",{href:!0});var hAt=s(NJ);Fyr=r(hAt,"TFGPTJForQuestionAnswering"),hAt.forEach(t),Tyr=r(wIe," (GPT-J model)"),wIe.forEach(t),Myr=i(ge),_C=n(ge,"LI",{});var AIe=s(_C);FTe=n(AIe,"STRONG",{});var pAt=s(FTe);Eyr=r(pAt,"longformer"),pAt.forEach(t),Cyr=r(AIe," \u2014 "),qJ=n(AIe,"A",{href:!0});var _At=s(qJ);wyr=r(_At,"TFLongformerForQuestionAnswering"),_At.forEach(t),Ayr=r(AIe," (Longformer model)"),AIe.forEach(t),yyr=i(ge),uC=n(ge,"LI",{});var yIe=s(uC);TTe=n(yIe,"STRONG",{});var uAt=s(TTe);Lyr=r(uAt,"mobilebert"),uAt.forEach(t),xyr=r(yIe," \u2014 "),jJ=n(yIe,"A",{href:!0});var bAt=s(jJ);$yr=r(bAt,"TFMobileBertForQuestionAnswering"),bAt.forEach(t),kyr=r(yIe," (MobileBERT model)"),yIe.forEach(t),Syr=i(ge),bC=n(ge,"LI",{});var LIe=s(bC);MTe=n(LIe,"STRONG",{});var vAt=s(MTe);Ryr=r(vAt,"mpnet"),vAt.forEach(t),Pyr=r(LIe," \u2014 "),DJ=n(LIe,"A",{href:!0});var FAt=s(DJ);Byr=r(FAt,"TFMPNetForQuestionAnswering"),FAt.forEach(t),Iyr=r(LIe," (MPNet model)"),LIe.forEach(t),Nyr=i(ge),vC=n(ge,"LI",{});var xIe=s(vC);ETe=n(xIe,"STRONG",{});var TAt=s(ETe);qyr=r(TAt,"rembert"),TAt.forEach(t),jyr=r(xIe," \u2014 "),GJ=n(xIe,"A",{href:!0});var MAt=s(GJ);Dyr=r(MAt,"TFRemBertForQuestionAnswering"),MAt.forEach(t),Gyr=r(xIe," (RemBERT model)"),xIe.forEach(t),Oyr=i(ge),FC=n(ge,"LI",{});var $Ie=s(FC);CTe=n($Ie,"STRONG",{});var EAt=s(CTe);Vyr=r(EAt,"roberta"),EAt.forEach(t),Xyr=r($Ie," \u2014 "),OJ=n($Ie,"A",{href:!0});var CAt=s(OJ);zyr=r(CAt,"TFRobertaForQuestionAnswering"),CAt.forEach(t),Wyr=r($Ie," (RoBERTa model)"),$Ie.forEach(t),Qyr=i(ge),TC=n(ge,"LI",{});var kIe=s(TC);wTe=n(kIe,"STRONG",{});var wAt=s(wTe);Hyr=r(wAt,"roformer"),wAt.forEach(t),Uyr=r(kIe," \u2014 "),VJ=n(kIe,"A",{href:!0});var AAt=s(VJ);Jyr=r(AAt,"TFRoFormerForQuestionAnswering"),AAt.forEach(t),Yyr=r(kIe," (RoFormer model)"),kIe.forEach(t),Kyr=i(ge),MC=n(ge,"LI",{});var SIe=s(MC);ATe=n(SIe,"STRONG",{});var yAt=s(ATe);Zyr=r(yAt,"xlm"),yAt.forEach(t),eLr=r(SIe," \u2014 "),XJ=n(SIe,"A",{href:!0});var LAt=s(XJ);oLr=r(LAt,"TFXLMForQuestionAnsweringSimple"),LAt.forEach(t),rLr=r(SIe," (XLM model)"),SIe.forEach(t),tLr=i(ge),EC=n(ge,"LI",{});var RIe=s(EC);yTe=n(RIe,"STRONG",{});var xAt=s(yTe);aLr=r(xAt,"xlm-roberta"),xAt.forEach(t),nLr=r(RIe," \u2014 "),zJ=n(RIe,"A",{href:!0});var $At=s(zJ);sLr=r($At,"TFXLMRobertaForQuestionAnswering"),$At.forEach(t),lLr=r(RIe," (XLM-RoBERTa model)"),RIe.forEach(t),iLr=i(ge),CC=n(ge,"LI",{});var PIe=s(CC);LTe=n(PIe,"STRONG",{});var kAt=s(LTe);dLr=r(kAt,"xlnet"),kAt.forEach(t),cLr=r(PIe," \u2014 "),WJ=n(PIe,"A",{href:!0});var SAt=s(WJ);fLr=r(SAt,"TFXLNetForQuestionAnsweringSimple"),SAt.forEach(t),mLr=r(PIe," (XLNet model)"),PIe.forEach(t),ge.forEach(t),gLr=i(ql),T(wC.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),fDe=i(f),wc=n(f,"H2",{class:!0});var bOe=s(wc);AC=n(bOe,"A",{id:!0,class:!0,href:!0});var RAt=s(AC);xTe=n(RAt,"SPAN",{});var PAt=s(xTe);T(C9.$$.fragment,PAt),PAt.forEach(t),RAt.forEach(t),hLr=i(bOe),$Te=n(bOe,"SPAN",{});var BAt=s($Te);pLr=r(BAt,"TFAutoModelForVision2Seq"),BAt.forEach(t),bOe.forEach(t),mDe=i(f),dr=n(f,"DIV",{class:!0});var jl=s(dr);T(w9.$$.fragment,jl),_Lr=i(jl),Ac=n(jl,"P",{});var eoe=s(Ac);uLr=r(eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),QJ=n(eoe,"A",{href:!0});var IAt=s(QJ);bLr=r(IAt,"from_pretrained()"),IAt.forEach(t),vLr=r(eoe," class method or the "),HJ=n(eoe,"A",{href:!0});var NAt=s(HJ);FLr=r(NAt,"from_config()"),NAt.forEach(t),TLr=r(eoe,` class
method.`),eoe.forEach(t),MLr=i(jl),A9=n(jl,"P",{});var vOe=s(A9);ELr=r(vOe,"This class cannot be instantiated directly using "),kTe=n(vOe,"CODE",{});var qAt=s(kTe);CLr=r(qAt,"__init__()"),qAt.forEach(t),wLr=r(vOe," (throws an error)."),vOe.forEach(t),ALr=i(jl),jt=n(jl,"DIV",{class:!0});var aA=s(jt);T(y9.$$.fragment,aA),yLr=i(aA),STe=n(aA,"P",{});var jAt=s(STe);LLr=r(jAt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),jAt.forEach(t),xLr=i(aA),yc=n(aA,"P",{});var ooe=s(yc);$Lr=r(ooe,`Note:
Loading a model from its configuration file does `),RTe=n(ooe,"STRONG",{});var DAt=s(RTe);kLr=r(DAt,"not"),DAt.forEach(t),SLr=r(ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),UJ=n(ooe,"A",{href:!0});var GAt=s(UJ);RLr=r(GAt,"from_pretrained()"),GAt.forEach(t),PLr=r(ooe," to load the model weights."),ooe.forEach(t),BLr=i(aA),T(yC.$$.fragment,aA),aA.forEach(t),ILr=i(jl),Nr=n(jl,"DIV",{class:!0});var Dl=s(Nr);T(L9.$$.fragment,Dl),NLr=i(Dl),PTe=n(Dl,"P",{});var OAt=s(PTe);qLr=r(OAt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),OAt.forEach(t),jLr=i(Dl),mn=n(Dl,"P",{});var nA=s(mn);DLr=r(nA,"The model class to instantiate is selected based on the "),BTe=n(nA,"CODE",{});var VAt=s(BTe);GLr=r(VAt,"model_type"),VAt.forEach(t),OLr=r(nA,` property of the config object (either
passed as an argument or loaded from `),ITe=n(nA,"CODE",{});var XAt=s(ITe);VLr=r(XAt,"pretrained_model_name_or_path"),XAt.forEach(t),XLr=r(nA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=n(nA,"CODE",{});var zAt=s(NTe);zLr=r(zAt,"pretrained_model_name_or_path"),zAt.forEach(t),WLr=r(nA,":"),nA.forEach(t),QLr=i(Dl),qTe=n(Dl,"UL",{});var WAt=s(qTe);LC=n(WAt,"LI",{});var BIe=s(LC);jTe=n(BIe,"STRONG",{});var QAt=s(jTe);HLr=r(QAt,"vision-encoder-decoder"),QAt.forEach(t),ULr=r(BIe," \u2014 "),JJ=n(BIe,"A",{href:!0});var HAt=s(JJ);JLr=r(HAt,"TFVisionEncoderDecoderModel"),HAt.forEach(t),YLr=r(BIe," (Vision Encoder decoder model)"),BIe.forEach(t),WAt.forEach(t),KLr=i(Dl),T(xC.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),gDe=i(f),Lc=n(f,"H2",{class:!0});var FOe=s(Lc);$C=n(FOe,"A",{id:!0,class:!0,href:!0});var UAt=s($C);DTe=n(UAt,"SPAN",{});var JAt=s(DTe);T(x9.$$.fragment,JAt),JAt.forEach(t),UAt.forEach(t),ZLr=i(FOe),GTe=n(FOe,"SPAN",{});var YAt=s(GTe);e8r=r(YAt,"TFAutoModelForSpeechSeq2Seq"),YAt.forEach(t),FOe.forEach(t),hDe=i(f),cr=n(f,"DIV",{class:!0});var Gl=s(cr);T($9.$$.fragment,Gl),o8r=i(Gl),xc=n(Gl,"P",{});var roe=s(xc);r8r=r(roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),YJ=n(roe,"A",{href:!0});var KAt=s(YJ);t8r=r(KAt,"from_pretrained()"),KAt.forEach(t),a8r=r(roe," class method or the "),KJ=n(roe,"A",{href:!0});var ZAt=s(KJ);n8r=r(ZAt,"from_config()"),ZAt.forEach(t),s8r=r(roe,` class
method.`),roe.forEach(t),l8r=i(Gl),k9=n(Gl,"P",{});var TOe=s(k9);i8r=r(TOe,"This class cannot be instantiated directly using "),OTe=n(TOe,"CODE",{});var eyt=s(OTe);d8r=r(eyt,"__init__()"),eyt.forEach(t),c8r=r(TOe," (throws an error)."),TOe.forEach(t),f8r=i(Gl),Dt=n(Gl,"DIV",{class:!0});var sA=s(Dt);T(S9.$$.fragment,sA),m8r=i(sA),VTe=n(sA,"P",{});var oyt=s(VTe);g8r=r(oyt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),oyt.forEach(t),h8r=i(sA),$c=n(sA,"P",{});var toe=s($c);p8r=r(toe,`Note:
Loading a model from its configuration file does `),XTe=n(toe,"STRONG",{});var ryt=s(XTe);_8r=r(ryt,"not"),ryt.forEach(t),u8r=r(toe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZJ=n(toe,"A",{href:!0});var tyt=s(ZJ);b8r=r(tyt,"from_pretrained()"),tyt.forEach(t),v8r=r(toe," to load the model weights."),toe.forEach(t),F8r=i(sA),T(kC.$$.fragment,sA),sA.forEach(t),T8r=i(Gl),qr=n(Gl,"DIV",{class:!0});var Ol=s(qr);T(R9.$$.fragment,Ol),M8r=i(Ol),zTe=n(Ol,"P",{});var ayt=s(zTe);E8r=r(ayt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),ayt.forEach(t),C8r=i(Ol),gn=n(Ol,"P",{});var lA=s(gn);w8r=r(lA,"The model class to instantiate is selected based on the "),WTe=n(lA,"CODE",{});var nyt=s(WTe);A8r=r(nyt,"model_type"),nyt.forEach(t),y8r=r(lA,` property of the config object (either
passed as an argument or loaded from `),QTe=n(lA,"CODE",{});var syt=s(QTe);L8r=r(syt,"pretrained_model_name_or_path"),syt.forEach(t),x8r=r(lA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HTe=n(lA,"CODE",{});var lyt=s(HTe);$8r=r(lyt,"pretrained_model_name_or_path"),lyt.forEach(t),k8r=r(lA,":"),lA.forEach(t),S8r=i(Ol),UTe=n(Ol,"UL",{});var iyt=s(UTe);SC=n(iyt,"LI",{});var IIe=s(SC);JTe=n(IIe,"STRONG",{});var dyt=s(JTe);R8r=r(dyt,"speech_to_text"),dyt.forEach(t),P8r=r(IIe," \u2014 "),eY=n(IIe,"A",{href:!0});var cyt=s(eY);B8r=r(cyt,"TFSpeech2TextForConditionalGeneration"),cyt.forEach(t),I8r=r(IIe," (Speech2Text model)"),IIe.forEach(t),iyt.forEach(t),N8r=i(Ol),T(RC.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),pDe=i(f),kc=n(f,"H2",{class:!0});var MOe=s(kc);PC=n(MOe,"A",{id:!0,class:!0,href:!0});var fyt=s(PC);YTe=n(fyt,"SPAN",{});var myt=s(YTe);T(P9.$$.fragment,myt),myt.forEach(t),fyt.forEach(t),q8r=i(MOe),KTe=n(MOe,"SPAN",{});var gyt=s(KTe);j8r=r(gyt,"FlaxAutoModel"),gyt.forEach(t),MOe.forEach(t),_De=i(f),fr=n(f,"DIV",{class:!0});var Vl=s(fr);T(B9.$$.fragment,Vl),D8r=i(Vl),Sc=n(Vl,"P",{});var aoe=s(Sc);G8r=r(aoe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oY=n(aoe,"A",{href:!0});var hyt=s(oY);O8r=r(hyt,"from_pretrained()"),hyt.forEach(t),V8r=r(aoe," class method or the "),rY=n(aoe,"A",{href:!0});var pyt=s(rY);X8r=r(pyt,"from_config()"),pyt.forEach(t),z8r=r(aoe,` class
method.`),aoe.forEach(t),W8r=i(Vl),I9=n(Vl,"P",{});var EOe=s(I9);Q8r=r(EOe,"This class cannot be instantiated directly using "),ZTe=n(EOe,"CODE",{});var _yt=s(ZTe);H8r=r(_yt,"__init__()"),_yt.forEach(t),U8r=r(EOe," (throws an error)."),EOe.forEach(t),J8r=i(Vl),Gt=n(Vl,"DIV",{class:!0});var iA=s(Gt);T(N9.$$.fragment,iA),Y8r=i(iA),e7e=n(iA,"P",{});var uyt=s(e7e);K8r=r(uyt,"Instantiates one of the base model classes of the library from a configuration."),uyt.forEach(t),Z8r=i(iA),Rc=n(iA,"P",{});var noe=s(Rc);e9r=r(noe,`Note:
Loading a model from its configuration file does `),o7e=n(noe,"STRONG",{});var byt=s(o7e);o9r=r(byt,"not"),byt.forEach(t),r9r=r(noe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=n(noe,"A",{href:!0});var vyt=s(tY);t9r=r(vyt,"from_pretrained()"),vyt.forEach(t),a9r=r(noe," to load the model weights."),noe.forEach(t),n9r=i(iA),T(BC.$$.fragment,iA),iA.forEach(t),s9r=i(Vl),jr=n(Vl,"DIV",{class:!0});var Xl=s(jr);T(q9.$$.fragment,Xl),l9r=i(Xl),r7e=n(Xl,"P",{});var Fyt=s(r7e);i9r=r(Fyt,"Instantiate one of the base model classes of the library from a pretrained model."),Fyt.forEach(t),d9r=i(Xl),hn=n(Xl,"P",{});var dA=s(hn);c9r=r(dA,"The model class to instantiate is selected based on the "),t7e=n(dA,"CODE",{});var Tyt=s(t7e);f9r=r(Tyt,"model_type"),Tyt.forEach(t),m9r=r(dA,` property of the config object (either
passed as an argument or loaded from `),a7e=n(dA,"CODE",{});var Myt=s(a7e);g9r=r(Myt,"pretrained_model_name_or_path"),Myt.forEach(t),h9r=r(dA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=n(dA,"CODE",{});var Eyt=s(n7e);p9r=r(Eyt,"pretrained_model_name_or_path"),Eyt.forEach(t),_9r=r(dA,":"),dA.forEach(t),u9r=i(Xl),re=n(Xl,"UL",{});var ne=s(re);IC=n(ne,"LI",{});var NIe=s(IC);s7e=n(NIe,"STRONG",{});var Cyt=s(s7e);b9r=r(Cyt,"albert"),Cyt.forEach(t),v9r=r(NIe," \u2014 "),aY=n(NIe,"A",{href:!0});var wyt=s(aY);F9r=r(wyt,"FlaxAlbertModel"),wyt.forEach(t),T9r=r(NIe," (ALBERT model)"),NIe.forEach(t),M9r=i(ne),NC=n(ne,"LI",{});var qIe=s(NC);l7e=n(qIe,"STRONG",{});var Ayt=s(l7e);E9r=r(Ayt,"bart"),Ayt.forEach(t),C9r=r(qIe," \u2014 "),nY=n(qIe,"A",{href:!0});var yyt=s(nY);w9r=r(yyt,"FlaxBartModel"),yyt.forEach(t),A9r=r(qIe," (BART model)"),qIe.forEach(t),y9r=i(ne),qC=n(ne,"LI",{});var jIe=s(qC);i7e=n(jIe,"STRONG",{});var Lyt=s(i7e);L9r=r(Lyt,"beit"),Lyt.forEach(t),x9r=r(jIe," \u2014 "),sY=n(jIe,"A",{href:!0});var xyt=s(sY);$9r=r(xyt,"FlaxBeitModel"),xyt.forEach(t),k9r=r(jIe," (BEiT model)"),jIe.forEach(t),S9r=i(ne),jC=n(ne,"LI",{});var DIe=s(jC);d7e=n(DIe,"STRONG",{});var $yt=s(d7e);R9r=r($yt,"bert"),$yt.forEach(t),P9r=r(DIe," \u2014 "),lY=n(DIe,"A",{href:!0});var kyt=s(lY);B9r=r(kyt,"FlaxBertModel"),kyt.forEach(t),I9r=r(DIe," (BERT model)"),DIe.forEach(t),N9r=i(ne),DC=n(ne,"LI",{});var GIe=s(DC);c7e=n(GIe,"STRONG",{});var Syt=s(c7e);q9r=r(Syt,"big_bird"),Syt.forEach(t),j9r=r(GIe," \u2014 "),iY=n(GIe,"A",{href:!0});var Ryt=s(iY);D9r=r(Ryt,"FlaxBigBirdModel"),Ryt.forEach(t),G9r=r(GIe," (BigBird model)"),GIe.forEach(t),O9r=i(ne),GC=n(ne,"LI",{});var OIe=s(GC);f7e=n(OIe,"STRONG",{});var Pyt=s(f7e);V9r=r(Pyt,"blenderbot"),Pyt.forEach(t),X9r=r(OIe," \u2014 "),dY=n(OIe,"A",{href:!0});var Byt=s(dY);z9r=r(Byt,"FlaxBlenderbotModel"),Byt.forEach(t),W9r=r(OIe," (Blenderbot model)"),OIe.forEach(t),Q9r=i(ne),OC=n(ne,"LI",{});var VIe=s(OC);m7e=n(VIe,"STRONG",{});var Iyt=s(m7e);H9r=r(Iyt,"blenderbot-small"),Iyt.forEach(t),U9r=r(VIe," \u2014 "),cY=n(VIe,"A",{href:!0});var Nyt=s(cY);J9r=r(Nyt,"FlaxBlenderbotSmallModel"),Nyt.forEach(t),Y9r=r(VIe," (BlenderbotSmall model)"),VIe.forEach(t),K9r=i(ne),VC=n(ne,"LI",{});var XIe=s(VC);g7e=n(XIe,"STRONG",{});var qyt=s(g7e);Z9r=r(qyt,"clip"),qyt.forEach(t),exr=r(XIe," \u2014 "),fY=n(XIe,"A",{href:!0});var jyt=s(fY);oxr=r(jyt,"FlaxCLIPModel"),jyt.forEach(t),rxr=r(XIe," (CLIP model)"),XIe.forEach(t),txr=i(ne),XC=n(ne,"LI",{});var zIe=s(XC);h7e=n(zIe,"STRONG",{});var Dyt=s(h7e);axr=r(Dyt,"distilbert"),Dyt.forEach(t),nxr=r(zIe," \u2014 "),mY=n(zIe,"A",{href:!0});var Gyt=s(mY);sxr=r(Gyt,"FlaxDistilBertModel"),Gyt.forEach(t),lxr=r(zIe," (DistilBERT model)"),zIe.forEach(t),ixr=i(ne),zC=n(ne,"LI",{});var WIe=s(zC);p7e=n(WIe,"STRONG",{});var Oyt=s(p7e);dxr=r(Oyt,"electra"),Oyt.forEach(t),cxr=r(WIe," \u2014 "),gY=n(WIe,"A",{href:!0});var Vyt=s(gY);fxr=r(Vyt,"FlaxElectraModel"),Vyt.forEach(t),mxr=r(WIe," (ELECTRA model)"),WIe.forEach(t),gxr=i(ne),WC=n(ne,"LI",{});var QIe=s(WC);_7e=n(QIe,"STRONG",{});var Xyt=s(_7e);hxr=r(Xyt,"gpt2"),Xyt.forEach(t),pxr=r(QIe," \u2014 "),hY=n(QIe,"A",{href:!0});var zyt=s(hY);_xr=r(zyt,"FlaxGPT2Model"),zyt.forEach(t),uxr=r(QIe," (OpenAI GPT-2 model)"),QIe.forEach(t),bxr=i(ne),QC=n(ne,"LI",{});var HIe=s(QC);u7e=n(HIe,"STRONG",{});var Wyt=s(u7e);vxr=r(Wyt,"gpt_neo"),Wyt.forEach(t),Fxr=r(HIe," \u2014 "),pY=n(HIe,"A",{href:!0});var Qyt=s(pY);Txr=r(Qyt,"FlaxGPTNeoModel"),Qyt.forEach(t),Mxr=r(HIe," (GPT Neo model)"),HIe.forEach(t),Exr=i(ne),HC=n(ne,"LI",{});var UIe=s(HC);b7e=n(UIe,"STRONG",{});var Hyt=s(b7e);Cxr=r(Hyt,"gptj"),Hyt.forEach(t),wxr=r(UIe," \u2014 "),_Y=n(UIe,"A",{href:!0});var Uyt=s(_Y);Axr=r(Uyt,"FlaxGPTJModel"),Uyt.forEach(t),yxr=r(UIe," (GPT-J model)"),UIe.forEach(t),Lxr=i(ne),UC=n(ne,"LI",{});var JIe=s(UC);v7e=n(JIe,"STRONG",{});var Jyt=s(v7e);xxr=r(Jyt,"marian"),Jyt.forEach(t),$xr=r(JIe," \u2014 "),uY=n(JIe,"A",{href:!0});var Yyt=s(uY);kxr=r(Yyt,"FlaxMarianModel"),Yyt.forEach(t),Sxr=r(JIe," (Marian model)"),JIe.forEach(t),Rxr=i(ne),JC=n(ne,"LI",{});var YIe=s(JC);F7e=n(YIe,"STRONG",{});var Kyt=s(F7e);Pxr=r(Kyt,"mbart"),Kyt.forEach(t),Bxr=r(YIe," \u2014 "),bY=n(YIe,"A",{href:!0});var Zyt=s(bY);Ixr=r(Zyt,"FlaxMBartModel"),Zyt.forEach(t),Nxr=r(YIe," (mBART model)"),YIe.forEach(t),qxr=i(ne),YC=n(ne,"LI",{});var KIe=s(YC);T7e=n(KIe,"STRONG",{});var eLt=s(T7e);jxr=r(eLt,"mt5"),eLt.forEach(t),Dxr=r(KIe," \u2014 "),vY=n(KIe,"A",{href:!0});var oLt=s(vY);Gxr=r(oLt,"FlaxMT5Model"),oLt.forEach(t),Oxr=r(KIe," (mT5 model)"),KIe.forEach(t),Vxr=i(ne),KC=n(ne,"LI",{});var ZIe=s(KC);M7e=n(ZIe,"STRONG",{});var rLt=s(M7e);Xxr=r(rLt,"opt"),rLt.forEach(t),zxr=r(ZIe," \u2014 "),FY=n(ZIe,"A",{href:!0});var tLt=s(FY);Wxr=r(tLt,"FlaxOPTModel"),tLt.forEach(t),Qxr=r(ZIe," (OPT model)"),ZIe.forEach(t),Hxr=i(ne),ZC=n(ne,"LI",{});var eNe=s(ZC);E7e=n(eNe,"STRONG",{});var aLt=s(E7e);Uxr=r(aLt,"pegasus"),aLt.forEach(t),Jxr=r(eNe," \u2014 "),TY=n(eNe,"A",{href:!0});var nLt=s(TY);Yxr=r(nLt,"FlaxPegasusModel"),nLt.forEach(t),Kxr=r(eNe," (Pegasus model)"),eNe.forEach(t),Zxr=i(ne),e3=n(ne,"LI",{});var oNe=s(e3);C7e=n(oNe,"STRONG",{});var sLt=s(C7e);e$r=r(sLt,"roberta"),sLt.forEach(t),o$r=r(oNe," \u2014 "),MY=n(oNe,"A",{href:!0});var lLt=s(MY);r$r=r(lLt,"FlaxRobertaModel"),lLt.forEach(t),t$r=r(oNe," (RoBERTa model)"),oNe.forEach(t),a$r=i(ne),o3=n(ne,"LI",{});var rNe=s(o3);w7e=n(rNe,"STRONG",{});var iLt=s(w7e);n$r=r(iLt,"roformer"),iLt.forEach(t),s$r=r(rNe," \u2014 "),EY=n(rNe,"A",{href:!0});var dLt=s(EY);l$r=r(dLt,"FlaxRoFormerModel"),dLt.forEach(t),i$r=r(rNe," (RoFormer model)"),rNe.forEach(t),d$r=i(ne),r3=n(ne,"LI",{});var tNe=s(r3);A7e=n(tNe,"STRONG",{});var cLt=s(A7e);c$r=r(cLt,"t5"),cLt.forEach(t),f$r=r(tNe," \u2014 "),CY=n(tNe,"A",{href:!0});var fLt=s(CY);m$r=r(fLt,"FlaxT5Model"),fLt.forEach(t),g$r=r(tNe," (T5 model)"),tNe.forEach(t),h$r=i(ne),t3=n(ne,"LI",{});var aNe=s(t3);y7e=n(aNe,"STRONG",{});var mLt=s(y7e);p$r=r(mLt,"vision-text-dual-encoder"),mLt.forEach(t),_$r=r(aNe," \u2014 "),wY=n(aNe,"A",{href:!0});var gLt=s(wY);u$r=r(gLt,"FlaxVisionTextDualEncoderModel"),gLt.forEach(t),b$r=r(aNe," (VisionTextDualEncoder model)"),aNe.forEach(t),v$r=i(ne),a3=n(ne,"LI",{});var nNe=s(a3);L7e=n(nNe,"STRONG",{});var hLt=s(L7e);F$r=r(hLt,"vit"),hLt.forEach(t),T$r=r(nNe," \u2014 "),AY=n(nNe,"A",{href:!0});var pLt=s(AY);M$r=r(pLt,"FlaxViTModel"),pLt.forEach(t),E$r=r(nNe," (ViT model)"),nNe.forEach(t),C$r=i(ne),n3=n(ne,"LI",{});var sNe=s(n3);x7e=n(sNe,"STRONG",{});var _Lt=s(x7e);w$r=r(_Lt,"wav2vec2"),_Lt.forEach(t),A$r=r(sNe," \u2014 "),yY=n(sNe,"A",{href:!0});var uLt=s(yY);y$r=r(uLt,"FlaxWav2Vec2Model"),uLt.forEach(t),L$r=r(sNe," (Wav2Vec2 model)"),sNe.forEach(t),x$r=i(ne),s3=n(ne,"LI",{});var lNe=s(s3);$7e=n(lNe,"STRONG",{});var bLt=s($7e);$$r=r(bLt,"xglm"),bLt.forEach(t),k$r=r(lNe," \u2014 "),LY=n(lNe,"A",{href:!0});var vLt=s(LY);S$r=r(vLt,"FlaxXGLMModel"),vLt.forEach(t),R$r=r(lNe," (XGLM model)"),lNe.forEach(t),P$r=i(ne),l3=n(ne,"LI",{});var iNe=s(l3);k7e=n(iNe,"STRONG",{});var FLt=s(k7e);B$r=r(FLt,"xlm-roberta"),FLt.forEach(t),I$r=r(iNe," \u2014 "),xY=n(iNe,"A",{href:!0});var TLt=s(xY);N$r=r(TLt,"FlaxXLMRobertaModel"),TLt.forEach(t),q$r=r(iNe," (XLM-RoBERTa model)"),iNe.forEach(t),ne.forEach(t),j$r=i(Xl),T(i3.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),uDe=i(f),Pc=n(f,"H2",{class:!0});var COe=s(Pc);d3=n(COe,"A",{id:!0,class:!0,href:!0});var MLt=s(d3);S7e=n(MLt,"SPAN",{});var ELt=s(S7e);T(j9.$$.fragment,ELt),ELt.forEach(t),MLt.forEach(t),D$r=i(COe),R7e=n(COe,"SPAN",{});var CLt=s(R7e);G$r=r(CLt,"FlaxAutoModelForCausalLM"),CLt.forEach(t),COe.forEach(t),bDe=i(f),mr=n(f,"DIV",{class:!0});var zl=s(mr);T(D9.$$.fragment,zl),O$r=i(zl),Bc=n(zl,"P",{});var soe=s(Bc);V$r=r(soe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),$Y=n(soe,"A",{href:!0});var wLt=s($Y);X$r=r(wLt,"from_pretrained()"),wLt.forEach(t),z$r=r(soe," class method or the "),kY=n(soe,"A",{href:!0});var ALt=s(kY);W$r=r(ALt,"from_config()"),ALt.forEach(t),Q$r=r(soe,` class
method.`),soe.forEach(t),H$r=i(zl),G9=n(zl,"P",{});var wOe=s(G9);U$r=r(wOe,"This class cannot be instantiated directly using "),P7e=n(wOe,"CODE",{});var yLt=s(P7e);J$r=r(yLt,"__init__()"),yLt.forEach(t),Y$r=r(wOe," (throws an error)."),wOe.forEach(t),K$r=i(zl),Ot=n(zl,"DIV",{class:!0});var cA=s(Ot);T(O9.$$.fragment,cA),Z$r=i(cA),B7e=n(cA,"P",{});var LLt=s(B7e);ekr=r(LLt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),LLt.forEach(t),okr=i(cA),Ic=n(cA,"P",{});var loe=s(Ic);rkr=r(loe,`Note:
Loading a model from its configuration file does `),I7e=n(loe,"STRONG",{});var xLt=s(I7e);tkr=r(xLt,"not"),xLt.forEach(t),akr=r(loe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=n(loe,"A",{href:!0});var $Lt=s(SY);nkr=r($Lt,"from_pretrained()"),$Lt.forEach(t),skr=r(loe," to load the model weights."),loe.forEach(t),lkr=i(cA),T(c3.$$.fragment,cA),cA.forEach(t),ikr=i(zl),Dr=n(zl,"DIV",{class:!0});var Wl=s(Dr);T(V9.$$.fragment,Wl),dkr=i(Wl),N7e=n(Wl,"P",{});var kLt=s(N7e);ckr=r(kLt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kLt.forEach(t),fkr=i(Wl),pn=n(Wl,"P",{});var fA=s(pn);mkr=r(fA,"The model class to instantiate is selected based on the "),q7e=n(fA,"CODE",{});var SLt=s(q7e);gkr=r(SLt,"model_type"),SLt.forEach(t),hkr=r(fA,` property of the config object (either
passed as an argument or loaded from `),j7e=n(fA,"CODE",{});var RLt=s(j7e);pkr=r(RLt,"pretrained_model_name_or_path"),RLt.forEach(t),_kr=r(fA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D7e=n(fA,"CODE",{});var PLt=s(D7e);ukr=r(PLt,"pretrained_model_name_or_path"),PLt.forEach(t),bkr=r(fA,":"),fA.forEach(t),vkr=i(Wl),Le=n(Wl,"UL",{});var Ie=s(Le);f3=n(Ie,"LI",{});var dNe=s(f3);G7e=n(dNe,"STRONG",{});var BLt=s(G7e);Fkr=r(BLt,"bart"),BLt.forEach(t),Tkr=r(dNe," \u2014 "),RY=n(dNe,"A",{href:!0});var ILt=s(RY);Mkr=r(ILt,"FlaxBartForCausalLM"),ILt.forEach(t),Ekr=r(dNe," (BART model)"),dNe.forEach(t),Ckr=i(Ie),m3=n(Ie,"LI",{});var cNe=s(m3);O7e=n(cNe,"STRONG",{});var NLt=s(O7e);wkr=r(NLt,"bert"),NLt.forEach(t),Akr=r(cNe," \u2014 "),PY=n(cNe,"A",{href:!0});var qLt=s(PY);ykr=r(qLt,"FlaxBertForCausalLM"),qLt.forEach(t),Lkr=r(cNe," (BERT model)"),cNe.forEach(t),xkr=i(Ie),g3=n(Ie,"LI",{});var fNe=s(g3);V7e=n(fNe,"STRONG",{});var jLt=s(V7e);$kr=r(jLt,"big_bird"),jLt.forEach(t),kkr=r(fNe," \u2014 "),BY=n(fNe,"A",{href:!0});var DLt=s(BY);Skr=r(DLt,"FlaxBigBirdForCausalLM"),DLt.forEach(t),Rkr=r(fNe," (BigBird model)"),fNe.forEach(t),Pkr=i(Ie),h3=n(Ie,"LI",{});var mNe=s(h3);X7e=n(mNe,"STRONG",{});var GLt=s(X7e);Bkr=r(GLt,"electra"),GLt.forEach(t),Ikr=r(mNe," \u2014 "),IY=n(mNe,"A",{href:!0});var OLt=s(IY);Nkr=r(OLt,"FlaxElectraForCausalLM"),OLt.forEach(t),qkr=r(mNe," (ELECTRA model)"),mNe.forEach(t),jkr=i(Ie),p3=n(Ie,"LI",{});var gNe=s(p3);z7e=n(gNe,"STRONG",{});var VLt=s(z7e);Dkr=r(VLt,"gpt2"),VLt.forEach(t),Gkr=r(gNe," \u2014 "),NY=n(gNe,"A",{href:!0});var XLt=s(NY);Okr=r(XLt,"FlaxGPT2LMHeadModel"),XLt.forEach(t),Vkr=r(gNe," (OpenAI GPT-2 model)"),gNe.forEach(t),Xkr=i(Ie),_3=n(Ie,"LI",{});var hNe=s(_3);W7e=n(hNe,"STRONG",{});var zLt=s(W7e);zkr=r(zLt,"gpt_neo"),zLt.forEach(t),Wkr=r(hNe," \u2014 "),qY=n(hNe,"A",{href:!0});var WLt=s(qY);Qkr=r(WLt,"FlaxGPTNeoForCausalLM"),WLt.forEach(t),Hkr=r(hNe," (GPT Neo model)"),hNe.forEach(t),Ukr=i(Ie),u3=n(Ie,"LI",{});var pNe=s(u3);Q7e=n(pNe,"STRONG",{});var QLt=s(Q7e);Jkr=r(QLt,"gptj"),QLt.forEach(t),Ykr=r(pNe," \u2014 "),jY=n(pNe,"A",{href:!0});var HLt=s(jY);Kkr=r(HLt,"FlaxGPTJForCausalLM"),HLt.forEach(t),Zkr=r(pNe," (GPT-J model)"),pNe.forEach(t),eSr=i(Ie),b3=n(Ie,"LI",{});var _Ne=s(b3);H7e=n(_Ne,"STRONG",{});var ULt=s(H7e);oSr=r(ULt,"opt"),ULt.forEach(t),rSr=r(_Ne," \u2014 "),DY=n(_Ne,"A",{href:!0});var JLt=s(DY);tSr=r(JLt,"FlaxOPTForCausalLM"),JLt.forEach(t),aSr=r(_Ne," (OPT model)"),_Ne.forEach(t),nSr=i(Ie),v3=n(Ie,"LI",{});var uNe=s(v3);U7e=n(uNe,"STRONG",{});var YLt=s(U7e);sSr=r(YLt,"roberta"),YLt.forEach(t),lSr=r(uNe," \u2014 "),GY=n(uNe,"A",{href:!0});var KLt=s(GY);iSr=r(KLt,"FlaxRobertaForCausalLM"),KLt.forEach(t),dSr=r(uNe," (RoBERTa model)"),uNe.forEach(t),cSr=i(Ie),F3=n(Ie,"LI",{});var bNe=s(F3);J7e=n(bNe,"STRONG",{});var ZLt=s(J7e);fSr=r(ZLt,"xglm"),ZLt.forEach(t),mSr=r(bNe," \u2014 "),OY=n(bNe,"A",{href:!0});var e8t=s(OY);gSr=r(e8t,"FlaxXGLMForCausalLM"),e8t.forEach(t),hSr=r(bNe," (XGLM model)"),bNe.forEach(t),Ie.forEach(t),pSr=i(Wl),T(T3.$$.fragment,Wl),Wl.forEach(t),zl.forEach(t),vDe=i(f),Nc=n(f,"H2",{class:!0});var AOe=s(Nc);M3=n(AOe,"A",{id:!0,class:!0,href:!0});var o8t=s(M3);Y7e=n(o8t,"SPAN",{});var r8t=s(Y7e);T(X9.$$.fragment,r8t),r8t.forEach(t),o8t.forEach(t),_Sr=i(AOe),K7e=n(AOe,"SPAN",{});var t8t=s(K7e);uSr=r(t8t,"FlaxAutoModelForPreTraining"),t8t.forEach(t),AOe.forEach(t),FDe=i(f),gr=n(f,"DIV",{class:!0});var Ql=s(gr);T(z9.$$.fragment,Ql),bSr=i(Ql),qc=n(Ql,"P",{});var ioe=s(qc);vSr=r(ioe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VY=n(ioe,"A",{href:!0});var a8t=s(VY);FSr=r(a8t,"from_pretrained()"),a8t.forEach(t),TSr=r(ioe," class method or the "),XY=n(ioe,"A",{href:!0});var n8t=s(XY);MSr=r(n8t,"from_config()"),n8t.forEach(t),ESr=r(ioe,` class
method.`),ioe.forEach(t),CSr=i(Ql),W9=n(Ql,"P",{});var yOe=s(W9);wSr=r(yOe,"This class cannot be instantiated directly using "),Z7e=n(yOe,"CODE",{});var s8t=s(Z7e);ASr=r(s8t,"__init__()"),s8t.forEach(t),ySr=r(yOe," (throws an error)."),yOe.forEach(t),LSr=i(Ql),Vt=n(Ql,"DIV",{class:!0});var mA=s(Vt);T(Q9.$$.fragment,mA),xSr=i(mA),eMe=n(mA,"P",{});var l8t=s(eMe);$Sr=r(l8t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),l8t.forEach(t),kSr=i(mA),jc=n(mA,"P",{});var doe=s(jc);SSr=r(doe,`Note:
Loading a model from its configuration file does `),oMe=n(doe,"STRONG",{});var i8t=s(oMe);RSr=r(i8t,"not"),i8t.forEach(t),PSr=r(doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zY=n(doe,"A",{href:!0});var d8t=s(zY);BSr=r(d8t,"from_pretrained()"),d8t.forEach(t),ISr=r(doe," to load the model weights."),doe.forEach(t),NSr=i(mA),T(E3.$$.fragment,mA),mA.forEach(t),qSr=i(Ql),Gr=n(Ql,"DIV",{class:!0});var Hl=s(Gr);T(H9.$$.fragment,Hl),jSr=i(Hl),rMe=n(Hl,"P",{});var c8t=s(rMe);DSr=r(c8t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),c8t.forEach(t),GSr=i(Hl),_n=n(Hl,"P",{});var gA=s(_n);OSr=r(gA,"The model class to instantiate is selected based on the "),tMe=n(gA,"CODE",{});var f8t=s(tMe);VSr=r(f8t,"model_type"),f8t.forEach(t),XSr=r(gA,` property of the config object (either
passed as an argument or loaded from `),aMe=n(gA,"CODE",{});var m8t=s(aMe);zSr=r(m8t,"pretrained_model_name_or_path"),m8t.forEach(t),WSr=r(gA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=n(gA,"CODE",{});var g8t=s(nMe);QSr=r(g8t,"pretrained_model_name_or_path"),g8t.forEach(t),HSr=r(gA,":"),gA.forEach(t),USr=i(Hl),Ee=n(Hl,"UL",{});var we=s(Ee);C3=n(we,"LI",{});var vNe=s(C3);sMe=n(vNe,"STRONG",{});var h8t=s(sMe);JSr=r(h8t,"albert"),h8t.forEach(t),YSr=r(vNe," \u2014 "),WY=n(vNe,"A",{href:!0});var p8t=s(WY);KSr=r(p8t,"FlaxAlbertForPreTraining"),p8t.forEach(t),ZSr=r(vNe," (ALBERT model)"),vNe.forEach(t),eRr=i(we),w3=n(we,"LI",{});var FNe=s(w3);lMe=n(FNe,"STRONG",{});var _8t=s(lMe);oRr=r(_8t,"bart"),_8t.forEach(t),rRr=r(FNe," \u2014 "),QY=n(FNe,"A",{href:!0});var u8t=s(QY);tRr=r(u8t,"FlaxBartForConditionalGeneration"),u8t.forEach(t),aRr=r(FNe," (BART model)"),FNe.forEach(t),nRr=i(we),A3=n(we,"LI",{});var TNe=s(A3);iMe=n(TNe,"STRONG",{});var b8t=s(iMe);sRr=r(b8t,"bert"),b8t.forEach(t),lRr=r(TNe," \u2014 "),HY=n(TNe,"A",{href:!0});var v8t=s(HY);iRr=r(v8t,"FlaxBertForPreTraining"),v8t.forEach(t),dRr=r(TNe," (BERT model)"),TNe.forEach(t),cRr=i(we),y3=n(we,"LI",{});var MNe=s(y3);dMe=n(MNe,"STRONG",{});var F8t=s(dMe);fRr=r(F8t,"big_bird"),F8t.forEach(t),mRr=r(MNe," \u2014 "),UY=n(MNe,"A",{href:!0});var T8t=s(UY);gRr=r(T8t,"FlaxBigBirdForPreTraining"),T8t.forEach(t),hRr=r(MNe," (BigBird model)"),MNe.forEach(t),pRr=i(we),L3=n(we,"LI",{});var ENe=s(L3);cMe=n(ENe,"STRONG",{});var M8t=s(cMe);_Rr=r(M8t,"electra"),M8t.forEach(t),uRr=r(ENe," \u2014 "),JY=n(ENe,"A",{href:!0});var E8t=s(JY);bRr=r(E8t,"FlaxElectraForPreTraining"),E8t.forEach(t),vRr=r(ENe," (ELECTRA model)"),ENe.forEach(t),FRr=i(we),x3=n(we,"LI",{});var CNe=s(x3);fMe=n(CNe,"STRONG",{});var C8t=s(fMe);TRr=r(C8t,"mbart"),C8t.forEach(t),MRr=r(CNe," \u2014 "),YY=n(CNe,"A",{href:!0});var w8t=s(YY);ERr=r(w8t,"FlaxMBartForConditionalGeneration"),w8t.forEach(t),CRr=r(CNe," (mBART model)"),CNe.forEach(t),wRr=i(we),$3=n(we,"LI",{});var wNe=s($3);mMe=n(wNe,"STRONG",{});var A8t=s(mMe);ARr=r(A8t,"mt5"),A8t.forEach(t),yRr=r(wNe," \u2014 "),KY=n(wNe,"A",{href:!0});var y8t=s(KY);LRr=r(y8t,"FlaxMT5ForConditionalGeneration"),y8t.forEach(t),xRr=r(wNe," (mT5 model)"),wNe.forEach(t),$Rr=i(we),k3=n(we,"LI",{});var ANe=s(k3);gMe=n(ANe,"STRONG",{});var L8t=s(gMe);kRr=r(L8t,"roberta"),L8t.forEach(t),SRr=r(ANe," \u2014 "),ZY=n(ANe,"A",{href:!0});var x8t=s(ZY);RRr=r(x8t,"FlaxRobertaForMaskedLM"),x8t.forEach(t),PRr=r(ANe," (RoBERTa model)"),ANe.forEach(t),BRr=i(we),S3=n(we,"LI",{});var yNe=s(S3);hMe=n(yNe,"STRONG",{});var $8t=s(hMe);IRr=r($8t,"roformer"),$8t.forEach(t),NRr=r(yNe," \u2014 "),eK=n(yNe,"A",{href:!0});var k8t=s(eK);qRr=r(k8t,"FlaxRoFormerForMaskedLM"),k8t.forEach(t),jRr=r(yNe," (RoFormer model)"),yNe.forEach(t),DRr=i(we),R3=n(we,"LI",{});var LNe=s(R3);pMe=n(LNe,"STRONG",{});var S8t=s(pMe);GRr=r(S8t,"t5"),S8t.forEach(t),ORr=r(LNe," \u2014 "),oK=n(LNe,"A",{href:!0});var R8t=s(oK);VRr=r(R8t,"FlaxT5ForConditionalGeneration"),R8t.forEach(t),XRr=r(LNe," (T5 model)"),LNe.forEach(t),zRr=i(we),P3=n(we,"LI",{});var xNe=s(P3);_Me=n(xNe,"STRONG",{});var P8t=s(_Me);WRr=r(P8t,"wav2vec2"),P8t.forEach(t),QRr=r(xNe," \u2014 "),rK=n(xNe,"A",{href:!0});var B8t=s(rK);HRr=r(B8t,"FlaxWav2Vec2ForPreTraining"),B8t.forEach(t),URr=r(xNe," (Wav2Vec2 model)"),xNe.forEach(t),JRr=i(we),B3=n(we,"LI",{});var $Ne=s(B3);uMe=n($Ne,"STRONG",{});var I8t=s(uMe);YRr=r(I8t,"xlm-roberta"),I8t.forEach(t),KRr=r($Ne," \u2014 "),tK=n($Ne,"A",{href:!0});var N8t=s(tK);ZRr=r(N8t,"FlaxXLMRobertaForMaskedLM"),N8t.forEach(t),ePr=r($Ne," (XLM-RoBERTa model)"),$Ne.forEach(t),we.forEach(t),oPr=i(Hl),T(I3.$$.fragment,Hl),Hl.forEach(t),Ql.forEach(t),TDe=i(f),Dc=n(f,"H2",{class:!0});var LOe=s(Dc);N3=n(LOe,"A",{id:!0,class:!0,href:!0});var q8t=s(N3);bMe=n(q8t,"SPAN",{});var j8t=s(bMe);T(U9.$$.fragment,j8t),j8t.forEach(t),q8t.forEach(t),rPr=i(LOe),vMe=n(LOe,"SPAN",{});var D8t=s(vMe);tPr=r(D8t,"FlaxAutoModelForMaskedLM"),D8t.forEach(t),LOe.forEach(t),MDe=i(f),hr=n(f,"DIV",{class:!0});var Ul=s(hr);T(J9.$$.fragment,Ul),aPr=i(Ul),Gc=n(Ul,"P",{});var coe=s(Gc);nPr=r(coe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aK=n(coe,"A",{href:!0});var G8t=s(aK);sPr=r(G8t,"from_pretrained()"),G8t.forEach(t),lPr=r(coe," class method or the "),nK=n(coe,"A",{href:!0});var O8t=s(nK);iPr=r(O8t,"from_config()"),O8t.forEach(t),dPr=r(coe,` class
method.`),coe.forEach(t),cPr=i(Ul),Y9=n(Ul,"P",{});var xOe=s(Y9);fPr=r(xOe,"This class cannot be instantiated directly using "),FMe=n(xOe,"CODE",{});var V8t=s(FMe);mPr=r(V8t,"__init__()"),V8t.forEach(t),gPr=r(xOe," (throws an error)."),xOe.forEach(t),hPr=i(Ul),Xt=n(Ul,"DIV",{class:!0});var hA=s(Xt);T(K9.$$.fragment,hA),pPr=i(hA),TMe=n(hA,"P",{});var X8t=s(TMe);_Pr=r(X8t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),X8t.forEach(t),uPr=i(hA),Oc=n(hA,"P",{});var foe=s(Oc);bPr=r(foe,`Note:
Loading a model from its configuration file does `),MMe=n(foe,"STRONG",{});var z8t=s(MMe);vPr=r(z8t,"not"),z8t.forEach(t),FPr=r(foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sK=n(foe,"A",{href:!0});var W8t=s(sK);TPr=r(W8t,"from_pretrained()"),W8t.forEach(t),MPr=r(foe," to load the model weights."),foe.forEach(t),EPr=i(hA),T(q3.$$.fragment,hA),hA.forEach(t),CPr=i(Ul),Or=n(Ul,"DIV",{class:!0});var Jl=s(Or);T(Z9.$$.fragment,Jl),wPr=i(Jl),EMe=n(Jl,"P",{});var Q8t=s(EMe);APr=r(Q8t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Q8t.forEach(t),yPr=i(Jl),un=n(Jl,"P",{});var pA=s(un);LPr=r(pA,"The model class to instantiate is selected based on the "),CMe=n(pA,"CODE",{});var H8t=s(CMe);xPr=r(H8t,"model_type"),H8t.forEach(t),$Pr=r(pA,` property of the config object (either
passed as an argument or loaded from `),wMe=n(pA,"CODE",{});var U8t=s(wMe);kPr=r(U8t,"pretrained_model_name_or_path"),U8t.forEach(t),SPr=r(pA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AMe=n(pA,"CODE",{});var J8t=s(AMe);RPr=r(J8t,"pretrained_model_name_or_path"),J8t.forEach(t),PPr=r(pA,":"),pA.forEach(t),BPr=i(Jl),xe=n(Jl,"UL",{});var Ne=s(xe);j3=n(Ne,"LI",{});var kNe=s(j3);yMe=n(kNe,"STRONG",{});var Y8t=s(yMe);IPr=r(Y8t,"albert"),Y8t.forEach(t),NPr=r(kNe," \u2014 "),lK=n(kNe,"A",{href:!0});var K8t=s(lK);qPr=r(K8t,"FlaxAlbertForMaskedLM"),K8t.forEach(t),jPr=r(kNe," (ALBERT model)"),kNe.forEach(t),DPr=i(Ne),D3=n(Ne,"LI",{});var SNe=s(D3);LMe=n(SNe,"STRONG",{});var Z8t=s(LMe);GPr=r(Z8t,"bart"),Z8t.forEach(t),OPr=r(SNe," \u2014 "),iK=n(SNe,"A",{href:!0});var e9t=s(iK);VPr=r(e9t,"FlaxBartForConditionalGeneration"),e9t.forEach(t),XPr=r(SNe," (BART model)"),SNe.forEach(t),zPr=i(Ne),G3=n(Ne,"LI",{});var RNe=s(G3);xMe=n(RNe,"STRONG",{});var o9t=s(xMe);WPr=r(o9t,"bert"),o9t.forEach(t),QPr=r(RNe," \u2014 "),dK=n(RNe,"A",{href:!0});var r9t=s(dK);HPr=r(r9t,"FlaxBertForMaskedLM"),r9t.forEach(t),UPr=r(RNe," (BERT model)"),RNe.forEach(t),JPr=i(Ne),O3=n(Ne,"LI",{});var PNe=s(O3);$Me=n(PNe,"STRONG",{});var t9t=s($Me);YPr=r(t9t,"big_bird"),t9t.forEach(t),KPr=r(PNe," \u2014 "),cK=n(PNe,"A",{href:!0});var a9t=s(cK);ZPr=r(a9t,"FlaxBigBirdForMaskedLM"),a9t.forEach(t),eBr=r(PNe," (BigBird model)"),PNe.forEach(t),oBr=i(Ne),V3=n(Ne,"LI",{});var BNe=s(V3);kMe=n(BNe,"STRONG",{});var n9t=s(kMe);rBr=r(n9t,"distilbert"),n9t.forEach(t),tBr=r(BNe," \u2014 "),fK=n(BNe,"A",{href:!0});var s9t=s(fK);aBr=r(s9t,"FlaxDistilBertForMaskedLM"),s9t.forEach(t),nBr=r(BNe," (DistilBERT model)"),BNe.forEach(t),sBr=i(Ne),X3=n(Ne,"LI",{});var INe=s(X3);SMe=n(INe,"STRONG",{});var l9t=s(SMe);lBr=r(l9t,"electra"),l9t.forEach(t),iBr=r(INe," \u2014 "),mK=n(INe,"A",{href:!0});var i9t=s(mK);dBr=r(i9t,"FlaxElectraForMaskedLM"),i9t.forEach(t),cBr=r(INe," (ELECTRA model)"),INe.forEach(t),fBr=i(Ne),z3=n(Ne,"LI",{});var NNe=s(z3);RMe=n(NNe,"STRONG",{});var d9t=s(RMe);mBr=r(d9t,"mbart"),d9t.forEach(t),gBr=r(NNe," \u2014 "),gK=n(NNe,"A",{href:!0});var c9t=s(gK);hBr=r(c9t,"FlaxMBartForConditionalGeneration"),c9t.forEach(t),pBr=r(NNe," (mBART model)"),NNe.forEach(t),_Br=i(Ne),W3=n(Ne,"LI",{});var qNe=s(W3);PMe=n(qNe,"STRONG",{});var f9t=s(PMe);uBr=r(f9t,"roberta"),f9t.forEach(t),bBr=r(qNe," \u2014 "),hK=n(qNe,"A",{href:!0});var m9t=s(hK);vBr=r(m9t,"FlaxRobertaForMaskedLM"),m9t.forEach(t),FBr=r(qNe," (RoBERTa model)"),qNe.forEach(t),TBr=i(Ne),Q3=n(Ne,"LI",{});var jNe=s(Q3);BMe=n(jNe,"STRONG",{});var g9t=s(BMe);MBr=r(g9t,"roformer"),g9t.forEach(t),EBr=r(jNe," \u2014 "),pK=n(jNe,"A",{href:!0});var h9t=s(pK);CBr=r(h9t,"FlaxRoFormerForMaskedLM"),h9t.forEach(t),wBr=r(jNe," (RoFormer model)"),jNe.forEach(t),ABr=i(Ne),H3=n(Ne,"LI",{});var DNe=s(H3);IMe=n(DNe,"STRONG",{});var p9t=s(IMe);yBr=r(p9t,"xlm-roberta"),p9t.forEach(t),LBr=r(DNe," \u2014 "),_K=n(DNe,"A",{href:!0});var _9t=s(_K);xBr=r(_9t,"FlaxXLMRobertaForMaskedLM"),_9t.forEach(t),$Br=r(DNe," (XLM-RoBERTa model)"),DNe.forEach(t),Ne.forEach(t),kBr=i(Jl),T(U3.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),EDe=i(f),Vc=n(f,"H2",{class:!0});var $Oe=s(Vc);J3=n($Oe,"A",{id:!0,class:!0,href:!0});var u9t=s(J3);NMe=n(u9t,"SPAN",{});var b9t=s(NMe);T(ex.$$.fragment,b9t),b9t.forEach(t),u9t.forEach(t),SBr=i($Oe),qMe=n($Oe,"SPAN",{});var v9t=s(qMe);RBr=r(v9t,"FlaxAutoModelForSeq2SeqLM"),v9t.forEach(t),$Oe.forEach(t),CDe=i(f),pr=n(f,"DIV",{class:!0});var Yl=s(pr);T(ox.$$.fragment,Yl),PBr=i(Yl),Xc=n(Yl,"P",{});var moe=s(Xc);BBr=r(moe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uK=n(moe,"A",{href:!0});var F9t=s(uK);IBr=r(F9t,"from_pretrained()"),F9t.forEach(t),NBr=r(moe," class method or the "),bK=n(moe,"A",{href:!0});var T9t=s(bK);qBr=r(T9t,"from_config()"),T9t.forEach(t),jBr=r(moe,` class
method.`),moe.forEach(t),DBr=i(Yl),rx=n(Yl,"P",{});var kOe=s(rx);GBr=r(kOe,"This class cannot be instantiated directly using "),jMe=n(kOe,"CODE",{});var M9t=s(jMe);OBr=r(M9t,"__init__()"),M9t.forEach(t),VBr=r(kOe," (throws an error)."),kOe.forEach(t),XBr=i(Yl),zt=n(Yl,"DIV",{class:!0});var _A=s(zt);T(tx.$$.fragment,_A),zBr=i(_A),DMe=n(_A,"P",{});var E9t=s(DMe);WBr=r(E9t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),E9t.forEach(t),QBr=i(_A),zc=n(_A,"P",{});var goe=s(zc);HBr=r(goe,`Note:
Loading a model from its configuration file does `),GMe=n(goe,"STRONG",{});var C9t=s(GMe);UBr=r(C9t,"not"),C9t.forEach(t),JBr=r(goe,` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=n(goe,"A",{href:!0});var w9t=s(vK);YBr=r(w9t,"from_pretrained()"),w9t.forEach(t),KBr=r(goe," to load the model weights."),goe.forEach(t),ZBr=i(_A),T(Y3.$$.fragment,_A),_A.forEach(t),eIr=i(Yl),Vr=n(Yl,"DIV",{class:!0});var Kl=s(Vr);T(ax.$$.fragment,Kl),oIr=i(Kl),OMe=n(Kl,"P",{});var A9t=s(OMe);rIr=r(A9t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),A9t.forEach(t),tIr=i(Kl),bn=n(Kl,"P",{});var uA=s(bn);aIr=r(uA,"The model class to instantiate is selected based on the "),VMe=n(uA,"CODE",{});var y9t=s(VMe);nIr=r(y9t,"model_type"),y9t.forEach(t),sIr=r(uA,` property of the config object (either
passed as an argument or loaded from `),XMe=n(uA,"CODE",{});var L9t=s(XMe);lIr=r(L9t,"pretrained_model_name_or_path"),L9t.forEach(t),iIr=r(uA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zMe=n(uA,"CODE",{});var x9t=s(zMe);dIr=r(x9t,"pretrained_model_name_or_path"),x9t.forEach(t),cIr=r(uA,":"),uA.forEach(t),fIr=i(Kl),Pe=n(Kl,"UL",{});var ze=s(Pe);K3=n(ze,"LI",{});var GNe=s(K3);WMe=n(GNe,"STRONG",{});var $9t=s(WMe);mIr=r($9t,"bart"),$9t.forEach(t),gIr=r(GNe," \u2014 "),FK=n(GNe,"A",{href:!0});var k9t=s(FK);hIr=r(k9t,"FlaxBartForConditionalGeneration"),k9t.forEach(t),pIr=r(GNe," (BART model)"),GNe.forEach(t),_Ir=i(ze),Z3=n(ze,"LI",{});var ONe=s(Z3);QMe=n(ONe,"STRONG",{});var S9t=s(QMe);uIr=r(S9t,"blenderbot"),S9t.forEach(t),bIr=r(ONe," \u2014 "),TK=n(ONe,"A",{href:!0});var R9t=s(TK);vIr=r(R9t,"FlaxBlenderbotForConditionalGeneration"),R9t.forEach(t),FIr=r(ONe," (Blenderbot model)"),ONe.forEach(t),TIr=i(ze),e0=n(ze,"LI",{});var VNe=s(e0);HMe=n(VNe,"STRONG",{});var P9t=s(HMe);MIr=r(P9t,"blenderbot-small"),P9t.forEach(t),EIr=r(VNe," \u2014 "),MK=n(VNe,"A",{href:!0});var B9t=s(MK);CIr=r(B9t,"FlaxBlenderbotSmallForConditionalGeneration"),B9t.forEach(t),wIr=r(VNe," (BlenderbotSmall model)"),VNe.forEach(t),AIr=i(ze),o0=n(ze,"LI",{});var XNe=s(o0);UMe=n(XNe,"STRONG",{});var I9t=s(UMe);yIr=r(I9t,"encoder-decoder"),I9t.forEach(t),LIr=r(XNe," \u2014 "),EK=n(XNe,"A",{href:!0});var N9t=s(EK);xIr=r(N9t,"FlaxEncoderDecoderModel"),N9t.forEach(t),$Ir=r(XNe," (Encoder decoder model)"),XNe.forEach(t),kIr=i(ze),r0=n(ze,"LI",{});var zNe=s(r0);JMe=n(zNe,"STRONG",{});var q9t=s(JMe);SIr=r(q9t,"marian"),q9t.forEach(t),RIr=r(zNe," \u2014 "),CK=n(zNe,"A",{href:!0});var j9t=s(CK);PIr=r(j9t,"FlaxMarianMTModel"),j9t.forEach(t),BIr=r(zNe," (Marian model)"),zNe.forEach(t),IIr=i(ze),t0=n(ze,"LI",{});var WNe=s(t0);YMe=n(WNe,"STRONG",{});var D9t=s(YMe);NIr=r(D9t,"mbart"),D9t.forEach(t),qIr=r(WNe," \u2014 "),wK=n(WNe,"A",{href:!0});var G9t=s(wK);jIr=r(G9t,"FlaxMBartForConditionalGeneration"),G9t.forEach(t),DIr=r(WNe," (mBART model)"),WNe.forEach(t),GIr=i(ze),a0=n(ze,"LI",{});var QNe=s(a0);KMe=n(QNe,"STRONG",{});var O9t=s(KMe);OIr=r(O9t,"mt5"),O9t.forEach(t),VIr=r(QNe," \u2014 "),AK=n(QNe,"A",{href:!0});var V9t=s(AK);XIr=r(V9t,"FlaxMT5ForConditionalGeneration"),V9t.forEach(t),zIr=r(QNe," (mT5 model)"),QNe.forEach(t),WIr=i(ze),n0=n(ze,"LI",{});var HNe=s(n0);ZMe=n(HNe,"STRONG",{});var X9t=s(ZMe);QIr=r(X9t,"pegasus"),X9t.forEach(t),HIr=r(HNe," \u2014 "),yK=n(HNe,"A",{href:!0});var z9t=s(yK);UIr=r(z9t,"FlaxPegasusForConditionalGeneration"),z9t.forEach(t),JIr=r(HNe," (Pegasus model)"),HNe.forEach(t),YIr=i(ze),s0=n(ze,"LI",{});var UNe=s(s0);eEe=n(UNe,"STRONG",{});var W9t=s(eEe);KIr=r(W9t,"t5"),W9t.forEach(t),ZIr=r(UNe," \u2014 "),LK=n(UNe,"A",{href:!0});var Q9t=s(LK);eNr=r(Q9t,"FlaxT5ForConditionalGeneration"),Q9t.forEach(t),oNr=r(UNe," (T5 model)"),UNe.forEach(t),ze.forEach(t),rNr=i(Kl),T(l0.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),wDe=i(f),Wc=n(f,"H2",{class:!0});var SOe=s(Wc);i0=n(SOe,"A",{id:!0,class:!0,href:!0});var H9t=s(i0);oEe=n(H9t,"SPAN",{});var U9t=s(oEe);T(nx.$$.fragment,U9t),U9t.forEach(t),H9t.forEach(t),tNr=i(SOe),rEe=n(SOe,"SPAN",{});var J9t=s(rEe);aNr=r(J9t,"FlaxAutoModelForSequenceClassification"),J9t.forEach(t),SOe.forEach(t),ADe=i(f),_r=n(f,"DIV",{class:!0});var Zl=s(_r);T(sx.$$.fragment,Zl),nNr=i(Zl),Qc=n(Zl,"P",{});var hoe=s(Qc);sNr=r(hoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),xK=n(hoe,"A",{href:!0});var Y9t=s(xK);lNr=r(Y9t,"from_pretrained()"),Y9t.forEach(t),iNr=r(hoe," class method or the "),$K=n(hoe,"A",{href:!0});var K9t=s($K);dNr=r(K9t,"from_config()"),K9t.forEach(t),cNr=r(hoe,` class
method.`),hoe.forEach(t),fNr=i(Zl),lx=n(Zl,"P",{});var ROe=s(lx);mNr=r(ROe,"This class cannot be instantiated directly using "),tEe=n(ROe,"CODE",{});var Z9t=s(tEe);gNr=r(Z9t,"__init__()"),Z9t.forEach(t),hNr=r(ROe," (throws an error)."),ROe.forEach(t),pNr=i(Zl),Wt=n(Zl,"DIV",{class:!0});var bA=s(Wt);T(ix.$$.fragment,bA),_Nr=i(bA),aEe=n(bA,"P",{});var ext=s(aEe);uNr=r(ext,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ext.forEach(t),bNr=i(bA),Hc=n(bA,"P",{});var poe=s(Hc);vNr=r(poe,`Note:
Loading a model from its configuration file does `),nEe=n(poe,"STRONG",{});var oxt=s(nEe);FNr=r(oxt,"not"),oxt.forEach(t),TNr=r(poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=n(poe,"A",{href:!0});var rxt=s(kK);MNr=r(rxt,"from_pretrained()"),rxt.forEach(t),ENr=r(poe," to load the model weights."),poe.forEach(t),CNr=i(bA),T(d0.$$.fragment,bA),bA.forEach(t),wNr=i(Zl),Xr=n(Zl,"DIV",{class:!0});var ei=s(Xr);T(dx.$$.fragment,ei),ANr=i(ei),sEe=n(ei,"P",{});var txt=s(sEe);yNr=r(txt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),txt.forEach(t),LNr=i(ei),vn=n(ei,"P",{});var vA=s(vn);xNr=r(vA,"The model class to instantiate is selected based on the "),lEe=n(vA,"CODE",{});var axt=s(lEe);$Nr=r(axt,"model_type"),axt.forEach(t),kNr=r(vA,` property of the config object (either
passed as an argument or loaded from `),iEe=n(vA,"CODE",{});var nxt=s(iEe);SNr=r(nxt,"pretrained_model_name_or_path"),nxt.forEach(t),RNr=r(vA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dEe=n(vA,"CODE",{});var sxt=s(dEe);PNr=r(sxt,"pretrained_model_name_or_path"),sxt.forEach(t),BNr=r(vA,":"),vA.forEach(t),INr=i(ei),$e=n(ei,"UL",{});var qe=s($e);c0=n(qe,"LI",{});var JNe=s(c0);cEe=n(JNe,"STRONG",{});var lxt=s(cEe);NNr=r(lxt,"albert"),lxt.forEach(t),qNr=r(JNe," \u2014 "),SK=n(JNe,"A",{href:!0});var ixt=s(SK);jNr=r(ixt,"FlaxAlbertForSequenceClassification"),ixt.forEach(t),DNr=r(JNe," (ALBERT model)"),JNe.forEach(t),GNr=i(qe),f0=n(qe,"LI",{});var YNe=s(f0);fEe=n(YNe,"STRONG",{});var dxt=s(fEe);ONr=r(dxt,"bart"),dxt.forEach(t),VNr=r(YNe," \u2014 "),RK=n(YNe,"A",{href:!0});var cxt=s(RK);XNr=r(cxt,"FlaxBartForSequenceClassification"),cxt.forEach(t),zNr=r(YNe," (BART model)"),YNe.forEach(t),WNr=i(qe),m0=n(qe,"LI",{});var KNe=s(m0);mEe=n(KNe,"STRONG",{});var fxt=s(mEe);QNr=r(fxt,"bert"),fxt.forEach(t),HNr=r(KNe," \u2014 "),PK=n(KNe,"A",{href:!0});var mxt=s(PK);UNr=r(mxt,"FlaxBertForSequenceClassification"),mxt.forEach(t),JNr=r(KNe," (BERT model)"),KNe.forEach(t),YNr=i(qe),g0=n(qe,"LI",{});var ZNe=s(g0);gEe=n(ZNe,"STRONG",{});var gxt=s(gEe);KNr=r(gxt,"big_bird"),gxt.forEach(t),ZNr=r(ZNe," \u2014 "),BK=n(ZNe,"A",{href:!0});var hxt=s(BK);eqr=r(hxt,"FlaxBigBirdForSequenceClassification"),hxt.forEach(t),oqr=r(ZNe," (BigBird model)"),ZNe.forEach(t),rqr=i(qe),h0=n(qe,"LI",{});var eqe=s(h0);hEe=n(eqe,"STRONG",{});var pxt=s(hEe);tqr=r(pxt,"distilbert"),pxt.forEach(t),aqr=r(eqe," \u2014 "),IK=n(eqe,"A",{href:!0});var _xt=s(IK);nqr=r(_xt,"FlaxDistilBertForSequenceClassification"),_xt.forEach(t),sqr=r(eqe," (DistilBERT model)"),eqe.forEach(t),lqr=i(qe),p0=n(qe,"LI",{});var oqe=s(p0);pEe=n(oqe,"STRONG",{});var uxt=s(pEe);iqr=r(uxt,"electra"),uxt.forEach(t),dqr=r(oqe," \u2014 "),NK=n(oqe,"A",{href:!0});var bxt=s(NK);cqr=r(bxt,"FlaxElectraForSequenceClassification"),bxt.forEach(t),fqr=r(oqe," (ELECTRA model)"),oqe.forEach(t),mqr=i(qe),_0=n(qe,"LI",{});var rqe=s(_0);_Ee=n(rqe,"STRONG",{});var vxt=s(_Ee);gqr=r(vxt,"mbart"),vxt.forEach(t),hqr=r(rqe," \u2014 "),qK=n(rqe,"A",{href:!0});var Fxt=s(qK);pqr=r(Fxt,"FlaxMBartForSequenceClassification"),Fxt.forEach(t),_qr=r(rqe," (mBART model)"),rqe.forEach(t),uqr=i(qe),u0=n(qe,"LI",{});var tqe=s(u0);uEe=n(tqe,"STRONG",{});var Txt=s(uEe);bqr=r(Txt,"roberta"),Txt.forEach(t),vqr=r(tqe," \u2014 "),jK=n(tqe,"A",{href:!0});var Mxt=s(jK);Fqr=r(Mxt,"FlaxRobertaForSequenceClassification"),Mxt.forEach(t),Tqr=r(tqe," (RoBERTa model)"),tqe.forEach(t),Mqr=i(qe),b0=n(qe,"LI",{});var aqe=s(b0);bEe=n(aqe,"STRONG",{});var Ext=s(bEe);Eqr=r(Ext,"roformer"),Ext.forEach(t),Cqr=r(aqe," \u2014 "),DK=n(aqe,"A",{href:!0});var Cxt=s(DK);wqr=r(Cxt,"FlaxRoFormerForSequenceClassification"),Cxt.forEach(t),Aqr=r(aqe," (RoFormer model)"),aqe.forEach(t),yqr=i(qe),v0=n(qe,"LI",{});var nqe=s(v0);vEe=n(nqe,"STRONG",{});var wxt=s(vEe);Lqr=r(wxt,"xlm-roberta"),wxt.forEach(t),xqr=r(nqe," \u2014 "),GK=n(nqe,"A",{href:!0});var Axt=s(GK);$qr=r(Axt,"FlaxXLMRobertaForSequenceClassification"),Axt.forEach(t),kqr=r(nqe," (XLM-RoBERTa model)"),nqe.forEach(t),qe.forEach(t),Sqr=i(ei),T(F0.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),yDe=i(f),Uc=n(f,"H2",{class:!0});var POe=s(Uc);T0=n(POe,"A",{id:!0,class:!0,href:!0});var yxt=s(T0);FEe=n(yxt,"SPAN",{});var Lxt=s(FEe);T(cx.$$.fragment,Lxt),Lxt.forEach(t),yxt.forEach(t),Rqr=i(POe),TEe=n(POe,"SPAN",{});var xxt=s(TEe);Pqr=r(xxt,"FlaxAutoModelForQuestionAnswering"),xxt.forEach(t),POe.forEach(t),LDe=i(f),ur=n(f,"DIV",{class:!0});var oi=s(ur);T(fx.$$.fragment,oi),Bqr=i(oi),Jc=n(oi,"P",{});var _oe=s(Jc);Iqr=r(_oe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),OK=n(_oe,"A",{href:!0});var $xt=s(OK);Nqr=r($xt,"from_pretrained()"),$xt.forEach(t),qqr=r(_oe," class method or the "),VK=n(_oe,"A",{href:!0});var kxt=s(VK);jqr=r(kxt,"from_config()"),kxt.forEach(t),Dqr=r(_oe,` class
method.`),_oe.forEach(t),Gqr=i(oi),mx=n(oi,"P",{});var BOe=s(mx);Oqr=r(BOe,"This class cannot be instantiated directly using "),MEe=n(BOe,"CODE",{});var Sxt=s(MEe);Vqr=r(Sxt,"__init__()"),Sxt.forEach(t),Xqr=r(BOe," (throws an error)."),BOe.forEach(t),zqr=i(oi),Qt=n(oi,"DIV",{class:!0});var FA=s(Qt);T(gx.$$.fragment,FA),Wqr=i(FA),EEe=n(FA,"P",{});var Rxt=s(EEe);Qqr=r(Rxt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Rxt.forEach(t),Hqr=i(FA),Yc=n(FA,"P",{});var uoe=s(Yc);Uqr=r(uoe,`Note:
Loading a model from its configuration file does `),CEe=n(uoe,"STRONG",{});var Pxt=s(CEe);Jqr=r(Pxt,"not"),Pxt.forEach(t),Yqr=r(uoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=n(uoe,"A",{href:!0});var Bxt=s(XK);Kqr=r(Bxt,"from_pretrained()"),Bxt.forEach(t),Zqr=r(uoe," to load the model weights."),uoe.forEach(t),ejr=i(FA),T(M0.$$.fragment,FA),FA.forEach(t),ojr=i(oi),zr=n(oi,"DIV",{class:!0});var ri=s(zr);T(hx.$$.fragment,ri),rjr=i(ri),wEe=n(ri,"P",{});var Ixt=s(wEe);tjr=r(Ixt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ixt.forEach(t),ajr=i(ri),Fn=n(ri,"P",{});var TA=s(Fn);njr=r(TA,"The model class to instantiate is selected based on the "),AEe=n(TA,"CODE",{});var Nxt=s(AEe);sjr=r(Nxt,"model_type"),Nxt.forEach(t),ljr=r(TA,` property of the config object (either
passed as an argument or loaded from `),yEe=n(TA,"CODE",{});var qxt=s(yEe);ijr=r(qxt,"pretrained_model_name_or_path"),qxt.forEach(t),djr=r(TA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=n(TA,"CODE",{});var jxt=s(LEe);cjr=r(jxt,"pretrained_model_name_or_path"),jxt.forEach(t),fjr=r(TA,":"),TA.forEach(t),mjr=i(ri),ke=n(ri,"UL",{});var je=s(ke);E0=n(je,"LI",{});var sqe=s(E0);xEe=n(sqe,"STRONG",{});var Dxt=s(xEe);gjr=r(Dxt,"albert"),Dxt.forEach(t),hjr=r(sqe," \u2014 "),zK=n(sqe,"A",{href:!0});var Gxt=s(zK);pjr=r(Gxt,"FlaxAlbertForQuestionAnswering"),Gxt.forEach(t),_jr=r(sqe," (ALBERT model)"),sqe.forEach(t),ujr=i(je),C0=n(je,"LI",{});var lqe=s(C0);$Ee=n(lqe,"STRONG",{});var Oxt=s($Ee);bjr=r(Oxt,"bart"),Oxt.forEach(t),vjr=r(lqe," \u2014 "),WK=n(lqe,"A",{href:!0});var Vxt=s(WK);Fjr=r(Vxt,"FlaxBartForQuestionAnswering"),Vxt.forEach(t),Tjr=r(lqe," (BART model)"),lqe.forEach(t),Mjr=i(je),w0=n(je,"LI",{});var iqe=s(w0);kEe=n(iqe,"STRONG",{});var Xxt=s(kEe);Ejr=r(Xxt,"bert"),Xxt.forEach(t),Cjr=r(iqe," \u2014 "),QK=n(iqe,"A",{href:!0});var zxt=s(QK);wjr=r(zxt,"FlaxBertForQuestionAnswering"),zxt.forEach(t),Ajr=r(iqe," (BERT model)"),iqe.forEach(t),yjr=i(je),A0=n(je,"LI",{});var dqe=s(A0);SEe=n(dqe,"STRONG",{});var Wxt=s(SEe);Ljr=r(Wxt,"big_bird"),Wxt.forEach(t),xjr=r(dqe," \u2014 "),HK=n(dqe,"A",{href:!0});var Qxt=s(HK);$jr=r(Qxt,"FlaxBigBirdForQuestionAnswering"),Qxt.forEach(t),kjr=r(dqe," (BigBird model)"),dqe.forEach(t),Sjr=i(je),y0=n(je,"LI",{});var cqe=s(y0);REe=n(cqe,"STRONG",{});var Hxt=s(REe);Rjr=r(Hxt,"distilbert"),Hxt.forEach(t),Pjr=r(cqe," \u2014 "),UK=n(cqe,"A",{href:!0});var Uxt=s(UK);Bjr=r(Uxt,"FlaxDistilBertForQuestionAnswering"),Uxt.forEach(t),Ijr=r(cqe," (DistilBERT model)"),cqe.forEach(t),Njr=i(je),L0=n(je,"LI",{});var fqe=s(L0);PEe=n(fqe,"STRONG",{});var Jxt=s(PEe);qjr=r(Jxt,"electra"),Jxt.forEach(t),jjr=r(fqe," \u2014 "),JK=n(fqe,"A",{href:!0});var Yxt=s(JK);Djr=r(Yxt,"FlaxElectraForQuestionAnswering"),Yxt.forEach(t),Gjr=r(fqe," (ELECTRA model)"),fqe.forEach(t),Ojr=i(je),x0=n(je,"LI",{});var mqe=s(x0);BEe=n(mqe,"STRONG",{});var Kxt=s(BEe);Vjr=r(Kxt,"mbart"),Kxt.forEach(t),Xjr=r(mqe," \u2014 "),YK=n(mqe,"A",{href:!0});var Zxt=s(YK);zjr=r(Zxt,"FlaxMBartForQuestionAnswering"),Zxt.forEach(t),Wjr=r(mqe," (mBART model)"),mqe.forEach(t),Qjr=i(je),$0=n(je,"LI",{});var gqe=s($0);IEe=n(gqe,"STRONG",{});var e$t=s(IEe);Hjr=r(e$t,"roberta"),e$t.forEach(t),Ujr=r(gqe," \u2014 "),KK=n(gqe,"A",{href:!0});var o$t=s(KK);Jjr=r(o$t,"FlaxRobertaForQuestionAnswering"),o$t.forEach(t),Yjr=r(gqe," (RoBERTa model)"),gqe.forEach(t),Kjr=i(je),k0=n(je,"LI",{});var hqe=s(k0);NEe=n(hqe,"STRONG",{});var r$t=s(NEe);Zjr=r(r$t,"roformer"),r$t.forEach(t),eDr=r(hqe," \u2014 "),ZK=n(hqe,"A",{href:!0});var t$t=s(ZK);oDr=r(t$t,"FlaxRoFormerForQuestionAnswering"),t$t.forEach(t),rDr=r(hqe," (RoFormer model)"),hqe.forEach(t),tDr=i(je),S0=n(je,"LI",{});var pqe=s(S0);qEe=n(pqe,"STRONG",{});var a$t=s(qEe);aDr=r(a$t,"xlm-roberta"),a$t.forEach(t),nDr=r(pqe," \u2014 "),eZ=n(pqe,"A",{href:!0});var n$t=s(eZ);sDr=r(n$t,"FlaxXLMRobertaForQuestionAnswering"),n$t.forEach(t),lDr=r(pqe," (XLM-RoBERTa model)"),pqe.forEach(t),je.forEach(t),iDr=i(ri),T(R0.$$.fragment,ri),ri.forEach(t),oi.forEach(t),xDe=i(f),Kc=n(f,"H2",{class:!0});var IOe=s(Kc);P0=n(IOe,"A",{id:!0,class:!0,href:!0});var s$t=s(P0);jEe=n(s$t,"SPAN",{});var l$t=s(jEe);T(px.$$.fragment,l$t),l$t.forEach(t),s$t.forEach(t),dDr=i(IOe),DEe=n(IOe,"SPAN",{});var i$t=s(DEe);cDr=r(i$t,"FlaxAutoModelForTokenClassification"),i$t.forEach(t),IOe.forEach(t),$De=i(f),br=n(f,"DIV",{class:!0});var ti=s(br);T(_x.$$.fragment,ti),fDr=i(ti),Zc=n(ti,"P",{});var boe=s(Zc);mDr=r(boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),oZ=n(boe,"A",{href:!0});var d$t=s(oZ);gDr=r(d$t,"from_pretrained()"),d$t.forEach(t),hDr=r(boe," class method or the "),rZ=n(boe,"A",{href:!0});var c$t=s(rZ);pDr=r(c$t,"from_config()"),c$t.forEach(t),_Dr=r(boe,` class
method.`),boe.forEach(t),uDr=i(ti),ux=n(ti,"P",{});var NOe=s(ux);bDr=r(NOe,"This class cannot be instantiated directly using "),GEe=n(NOe,"CODE",{});var f$t=s(GEe);vDr=r(f$t,"__init__()"),f$t.forEach(t),FDr=r(NOe," (throws an error)."),NOe.forEach(t),TDr=i(ti),Ht=n(ti,"DIV",{class:!0});var MA=s(Ht);T(bx.$$.fragment,MA),MDr=i(MA),OEe=n(MA,"P",{});var m$t=s(OEe);EDr=r(m$t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),m$t.forEach(t),CDr=i(MA),ef=n(MA,"P",{});var voe=s(ef);wDr=r(voe,`Note:
Loading a model from its configuration file does `),VEe=n(voe,"STRONG",{});var g$t=s(VEe);ADr=r(g$t,"not"),g$t.forEach(t),yDr=r(voe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tZ=n(voe,"A",{href:!0});var h$t=s(tZ);LDr=r(h$t,"from_pretrained()"),h$t.forEach(t),xDr=r(voe," to load the model weights."),voe.forEach(t),$Dr=i(MA),T(B0.$$.fragment,MA),MA.forEach(t),kDr=i(ti),Wr=n(ti,"DIV",{class:!0});var ai=s(Wr);T(vx.$$.fragment,ai),SDr=i(ai),XEe=n(ai,"P",{});var p$t=s(XEe);RDr=r(p$t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),p$t.forEach(t),PDr=i(ai),Tn=n(ai,"P",{});var EA=s(Tn);BDr=r(EA,"The model class to instantiate is selected based on the "),zEe=n(EA,"CODE",{});var _$t=s(zEe);IDr=r(_$t,"model_type"),_$t.forEach(t),NDr=r(EA,` property of the config object (either
passed as an argument or loaded from `),WEe=n(EA,"CODE",{});var u$t=s(WEe);qDr=r(u$t,"pretrained_model_name_or_path"),u$t.forEach(t),jDr=r(EA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=n(EA,"CODE",{});var b$t=s(QEe);DDr=r(b$t,"pretrained_model_name_or_path"),b$t.forEach(t),GDr=r(EA,":"),EA.forEach(t),ODr=i(ai),Ge=n(ai,"UL",{});var Fo=s(Ge);I0=n(Fo,"LI",{});var _qe=s(I0);HEe=n(_qe,"STRONG",{});var v$t=s(HEe);VDr=r(v$t,"albert"),v$t.forEach(t),XDr=r(_qe," \u2014 "),aZ=n(_qe,"A",{href:!0});var F$t=s(aZ);zDr=r(F$t,"FlaxAlbertForTokenClassification"),F$t.forEach(t),WDr=r(_qe," (ALBERT model)"),_qe.forEach(t),QDr=i(Fo),N0=n(Fo,"LI",{});var uqe=s(N0);UEe=n(uqe,"STRONG",{});var T$t=s(UEe);HDr=r(T$t,"bert"),T$t.forEach(t),UDr=r(uqe," \u2014 "),nZ=n(uqe,"A",{href:!0});var M$t=s(nZ);JDr=r(M$t,"FlaxBertForTokenClassification"),M$t.forEach(t),YDr=r(uqe," (BERT model)"),uqe.forEach(t),KDr=i(Fo),q0=n(Fo,"LI",{});var bqe=s(q0);JEe=n(bqe,"STRONG",{});var E$t=s(JEe);ZDr=r(E$t,"big_bird"),E$t.forEach(t),eGr=r(bqe," \u2014 "),sZ=n(bqe,"A",{href:!0});var C$t=s(sZ);oGr=r(C$t,"FlaxBigBirdForTokenClassification"),C$t.forEach(t),rGr=r(bqe," (BigBird model)"),bqe.forEach(t),tGr=i(Fo),j0=n(Fo,"LI",{});var vqe=s(j0);YEe=n(vqe,"STRONG",{});var w$t=s(YEe);aGr=r(w$t,"distilbert"),w$t.forEach(t),nGr=r(vqe," \u2014 "),lZ=n(vqe,"A",{href:!0});var A$t=s(lZ);sGr=r(A$t,"FlaxDistilBertForTokenClassification"),A$t.forEach(t),lGr=r(vqe," (DistilBERT model)"),vqe.forEach(t),iGr=i(Fo),D0=n(Fo,"LI",{});var Fqe=s(D0);KEe=n(Fqe,"STRONG",{});var y$t=s(KEe);dGr=r(y$t,"electra"),y$t.forEach(t),cGr=r(Fqe," \u2014 "),iZ=n(Fqe,"A",{href:!0});var L$t=s(iZ);fGr=r(L$t,"FlaxElectraForTokenClassification"),L$t.forEach(t),mGr=r(Fqe," (ELECTRA model)"),Fqe.forEach(t),gGr=i(Fo),G0=n(Fo,"LI",{});var Tqe=s(G0);ZEe=n(Tqe,"STRONG",{});var x$t=s(ZEe);hGr=r(x$t,"roberta"),x$t.forEach(t),pGr=r(Tqe," \u2014 "),dZ=n(Tqe,"A",{href:!0});var $$t=s(dZ);_Gr=r($$t,"FlaxRobertaForTokenClassification"),$$t.forEach(t),uGr=r(Tqe," (RoBERTa model)"),Tqe.forEach(t),bGr=i(Fo),O0=n(Fo,"LI",{});var Mqe=s(O0);eCe=n(Mqe,"STRONG",{});var k$t=s(eCe);vGr=r(k$t,"roformer"),k$t.forEach(t),FGr=r(Mqe," \u2014 "),cZ=n(Mqe,"A",{href:!0});var S$t=s(cZ);TGr=r(S$t,"FlaxRoFormerForTokenClassification"),S$t.forEach(t),MGr=r(Mqe," (RoFormer model)"),Mqe.forEach(t),EGr=i(Fo),V0=n(Fo,"LI",{});var Eqe=s(V0);oCe=n(Eqe,"STRONG",{});var R$t=s(oCe);CGr=r(R$t,"xlm-roberta"),R$t.forEach(t),wGr=r(Eqe," \u2014 "),fZ=n(Eqe,"A",{href:!0});var P$t=s(fZ);AGr=r(P$t,"FlaxXLMRobertaForTokenClassification"),P$t.forEach(t),yGr=r(Eqe," (XLM-RoBERTa model)"),Eqe.forEach(t),Fo.forEach(t),LGr=i(ai),T(X0.$$.fragment,ai),ai.forEach(t),ti.forEach(t),kDe=i(f),of=n(f,"H2",{class:!0});var qOe=s(of);z0=n(qOe,"A",{id:!0,class:!0,href:!0});var B$t=s(z0);rCe=n(B$t,"SPAN",{});var I$t=s(rCe);T(Fx.$$.fragment,I$t),I$t.forEach(t),B$t.forEach(t),xGr=i(qOe),tCe=n(qOe,"SPAN",{});var N$t=s(tCe);$Gr=r(N$t,"FlaxAutoModelForMultipleChoice"),N$t.forEach(t),qOe.forEach(t),SDe=i(f),vr=n(f,"DIV",{class:!0});var ni=s(vr);T(Tx.$$.fragment,ni),kGr=i(ni),rf=n(ni,"P",{});var Foe=s(rf);SGr=r(Foe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),mZ=n(Foe,"A",{href:!0});var q$t=s(mZ);RGr=r(q$t,"from_pretrained()"),q$t.forEach(t),PGr=r(Foe," class method or the "),gZ=n(Foe,"A",{href:!0});var j$t=s(gZ);BGr=r(j$t,"from_config()"),j$t.forEach(t),IGr=r(Foe,` class
method.`),Foe.forEach(t),NGr=i(ni),Mx=n(ni,"P",{});var jOe=s(Mx);qGr=r(jOe,"This class cannot be instantiated directly using "),aCe=n(jOe,"CODE",{});var D$t=s(aCe);jGr=r(D$t,"__init__()"),D$t.forEach(t),DGr=r(jOe," (throws an error)."),jOe.forEach(t),GGr=i(ni),Ut=n(ni,"DIV",{class:!0});var CA=s(Ut);T(Ex.$$.fragment,CA),OGr=i(CA),nCe=n(CA,"P",{});var G$t=s(nCe);VGr=r(G$t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),G$t.forEach(t),XGr=i(CA),tf=n(CA,"P",{});var Toe=s(tf);zGr=r(Toe,`Note:
Loading a model from its configuration file does `),sCe=n(Toe,"STRONG",{});var O$t=s(sCe);WGr=r(O$t,"not"),O$t.forEach(t),QGr=r(Toe,` load the model weights. It only affects the
model\u2019s configuration. Use `),hZ=n(Toe,"A",{href:!0});var V$t=s(hZ);HGr=r(V$t,"from_pretrained()"),V$t.forEach(t),UGr=r(Toe," to load the model weights."),Toe.forEach(t),JGr=i(CA),T(W0.$$.fragment,CA),CA.forEach(t),YGr=i(ni),Qr=n(ni,"DIV",{class:!0});var si=s(Qr);T(Cx.$$.fragment,si),KGr=i(si),lCe=n(si,"P",{});var X$t=s(lCe);ZGr=r(X$t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),X$t.forEach(t),eOr=i(si),Mn=n(si,"P",{});var wA=s(Mn);oOr=r(wA,"The model class to instantiate is selected based on the "),iCe=n(wA,"CODE",{});var z$t=s(iCe);rOr=r(z$t,"model_type"),z$t.forEach(t),tOr=r(wA,` property of the config object (either
passed as an argument or loaded from `),dCe=n(wA,"CODE",{});var W$t=s(dCe);aOr=r(W$t,"pretrained_model_name_or_path"),W$t.forEach(t),nOr=r(wA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=n(wA,"CODE",{});var Q$t=s(cCe);sOr=r(Q$t,"pretrained_model_name_or_path"),Q$t.forEach(t),lOr=r(wA,":"),wA.forEach(t),iOr=i(si),Oe=n(si,"UL",{});var To=s(Oe);Q0=n(To,"LI",{});var Cqe=s(Q0);fCe=n(Cqe,"STRONG",{});var H$t=s(fCe);dOr=r(H$t,"albert"),H$t.forEach(t),cOr=r(Cqe," \u2014 "),pZ=n(Cqe,"A",{href:!0});var U$t=s(pZ);fOr=r(U$t,"FlaxAlbertForMultipleChoice"),U$t.forEach(t),mOr=r(Cqe," (ALBERT model)"),Cqe.forEach(t),gOr=i(To),H0=n(To,"LI",{});var wqe=s(H0);mCe=n(wqe,"STRONG",{});var J$t=s(mCe);hOr=r(J$t,"bert"),J$t.forEach(t),pOr=r(wqe," \u2014 "),_Z=n(wqe,"A",{href:!0});var Y$t=s(_Z);_Or=r(Y$t,"FlaxBertForMultipleChoice"),Y$t.forEach(t),uOr=r(wqe," (BERT model)"),wqe.forEach(t),bOr=i(To),U0=n(To,"LI",{});var Aqe=s(U0);gCe=n(Aqe,"STRONG",{});var K$t=s(gCe);vOr=r(K$t,"big_bird"),K$t.forEach(t),FOr=r(Aqe," \u2014 "),uZ=n(Aqe,"A",{href:!0});var Z$t=s(uZ);TOr=r(Z$t,"FlaxBigBirdForMultipleChoice"),Z$t.forEach(t),MOr=r(Aqe," (BigBird model)"),Aqe.forEach(t),EOr=i(To),J0=n(To,"LI",{});var yqe=s(J0);hCe=n(yqe,"STRONG",{});var ekt=s(hCe);COr=r(ekt,"distilbert"),ekt.forEach(t),wOr=r(yqe," \u2014 "),bZ=n(yqe,"A",{href:!0});var okt=s(bZ);AOr=r(okt,"FlaxDistilBertForMultipleChoice"),okt.forEach(t),yOr=r(yqe," (DistilBERT model)"),yqe.forEach(t),LOr=i(To),Y0=n(To,"LI",{});var Lqe=s(Y0);pCe=n(Lqe,"STRONG",{});var rkt=s(pCe);xOr=r(rkt,"electra"),rkt.forEach(t),$Or=r(Lqe," \u2014 "),vZ=n(Lqe,"A",{href:!0});var tkt=s(vZ);kOr=r(tkt,"FlaxElectraForMultipleChoice"),tkt.forEach(t),SOr=r(Lqe," (ELECTRA model)"),Lqe.forEach(t),ROr=i(To),K0=n(To,"LI",{});var xqe=s(K0);_Ce=n(xqe,"STRONG",{});var akt=s(_Ce);POr=r(akt,"roberta"),akt.forEach(t),BOr=r(xqe," \u2014 "),FZ=n(xqe,"A",{href:!0});var nkt=s(FZ);IOr=r(nkt,"FlaxRobertaForMultipleChoice"),nkt.forEach(t),NOr=r(xqe," (RoBERTa model)"),xqe.forEach(t),qOr=i(To),Z0=n(To,"LI",{});var $qe=s(Z0);uCe=n($qe,"STRONG",{});var skt=s(uCe);jOr=r(skt,"roformer"),skt.forEach(t),DOr=r($qe," \u2014 "),TZ=n($qe,"A",{href:!0});var lkt=s(TZ);GOr=r(lkt,"FlaxRoFormerForMultipleChoice"),lkt.forEach(t),OOr=r($qe," (RoFormer model)"),$qe.forEach(t),VOr=i(To),ew=n(To,"LI",{});var kqe=s(ew);bCe=n(kqe,"STRONG",{});var ikt=s(bCe);XOr=r(ikt,"xlm-roberta"),ikt.forEach(t),zOr=r(kqe," \u2014 "),MZ=n(kqe,"A",{href:!0});var dkt=s(MZ);WOr=r(dkt,"FlaxXLMRobertaForMultipleChoice"),dkt.forEach(t),QOr=r(kqe," (XLM-RoBERTa model)"),kqe.forEach(t),To.forEach(t),HOr=i(si),T(ow.$$.fragment,si),si.forEach(t),ni.forEach(t),RDe=i(f),af=n(f,"H2",{class:!0});var DOe=s(af);rw=n(DOe,"A",{id:!0,class:!0,href:!0});var ckt=s(rw);vCe=n(ckt,"SPAN",{});var fkt=s(vCe);T(wx.$$.fragment,fkt),fkt.forEach(t),ckt.forEach(t),UOr=i(DOe),FCe=n(DOe,"SPAN",{});var mkt=s(FCe);JOr=r(mkt,"FlaxAutoModelForNextSentencePrediction"),mkt.forEach(t),DOe.forEach(t),PDe=i(f),Fr=n(f,"DIV",{class:!0});var li=s(Fr);T(Ax.$$.fragment,li),YOr=i(li),nf=n(li,"P",{});var Moe=s(nf);KOr=r(Moe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),EZ=n(Moe,"A",{href:!0});var gkt=s(EZ);ZOr=r(gkt,"from_pretrained()"),gkt.forEach(t),eVr=r(Moe," class method or the "),CZ=n(Moe,"A",{href:!0});var hkt=s(CZ);oVr=r(hkt,"from_config()"),hkt.forEach(t),rVr=r(Moe,` class
method.`),Moe.forEach(t),tVr=i(li),yx=n(li,"P",{});var GOe=s(yx);aVr=r(GOe,"This class cannot be instantiated directly using "),TCe=n(GOe,"CODE",{});var pkt=s(TCe);nVr=r(pkt,"__init__()"),pkt.forEach(t),sVr=r(GOe," (throws an error)."),GOe.forEach(t),lVr=i(li),Jt=n(li,"DIV",{class:!0});var AA=s(Jt);T(Lx.$$.fragment,AA),iVr=i(AA),MCe=n(AA,"P",{});var _kt=s(MCe);dVr=r(_kt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_kt.forEach(t),cVr=i(AA),sf=n(AA,"P",{});var Eoe=s(sf);fVr=r(Eoe,`Note:
Loading a model from its configuration file does `),ECe=n(Eoe,"STRONG",{});var ukt=s(ECe);mVr=r(ukt,"not"),ukt.forEach(t),gVr=r(Eoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=n(Eoe,"A",{href:!0});var bkt=s(wZ);hVr=r(bkt,"from_pretrained()"),bkt.forEach(t),pVr=r(Eoe," to load the model weights."),Eoe.forEach(t),_Vr=i(AA),T(tw.$$.fragment,AA),AA.forEach(t),uVr=i(li),Hr=n(li,"DIV",{class:!0});var ii=s(Hr);T(xx.$$.fragment,ii),bVr=i(ii),CCe=n(ii,"P",{});var vkt=s(CCe);vVr=r(vkt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),vkt.forEach(t),FVr=i(ii),En=n(ii,"P",{});var yA=s(En);TVr=r(yA,"The model class to instantiate is selected based on the "),wCe=n(yA,"CODE",{});var Fkt=s(wCe);MVr=r(Fkt,"model_type"),Fkt.forEach(t),EVr=r(yA,` property of the config object (either
passed as an argument or loaded from `),ACe=n(yA,"CODE",{});var Tkt=s(ACe);CVr=r(Tkt,"pretrained_model_name_or_path"),Tkt.forEach(t),wVr=r(yA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yCe=n(yA,"CODE",{});var Mkt=s(yCe);AVr=r(Mkt,"pretrained_model_name_or_path"),Mkt.forEach(t),yVr=r(yA,":"),yA.forEach(t),LVr=i(ii),LCe=n(ii,"UL",{});var Ekt=s(LCe);aw=n(Ekt,"LI",{});var Sqe=s(aw);xCe=n(Sqe,"STRONG",{});var Ckt=s(xCe);xVr=r(Ckt,"bert"),Ckt.forEach(t),$Vr=r(Sqe," \u2014 "),AZ=n(Sqe,"A",{href:!0});var wkt=s(AZ);kVr=r(wkt,"FlaxBertForNextSentencePrediction"),wkt.forEach(t),SVr=r(Sqe," (BERT model)"),Sqe.forEach(t),Ekt.forEach(t),RVr=i(ii),T(nw.$$.fragment,ii),ii.forEach(t),li.forEach(t),BDe=i(f),lf=n(f,"H2",{class:!0});var OOe=s(lf);sw=n(OOe,"A",{id:!0,class:!0,href:!0});var Akt=s(sw);$Ce=n(Akt,"SPAN",{});var ykt=s($Ce);T($x.$$.fragment,ykt),ykt.forEach(t),Akt.forEach(t),PVr=i(OOe),kCe=n(OOe,"SPAN",{});var Lkt=s(kCe);BVr=r(Lkt,"FlaxAutoModelForImageClassification"),Lkt.forEach(t),OOe.forEach(t),IDe=i(f),Tr=n(f,"DIV",{class:!0});var di=s(Tr);T(kx.$$.fragment,di),IVr=i(di),df=n(di,"P",{});var Coe=s(df);NVr=r(Coe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),yZ=n(Coe,"A",{href:!0});var xkt=s(yZ);qVr=r(xkt,"from_pretrained()"),xkt.forEach(t),jVr=r(Coe," class method or the "),LZ=n(Coe,"A",{href:!0});var $kt=s(LZ);DVr=r($kt,"from_config()"),$kt.forEach(t),GVr=r(Coe,` class
method.`),Coe.forEach(t),OVr=i(di),Sx=n(di,"P",{});var VOe=s(Sx);VVr=r(VOe,"This class cannot be instantiated directly using "),SCe=n(VOe,"CODE",{});var kkt=s(SCe);XVr=r(kkt,"__init__()"),kkt.forEach(t),zVr=r(VOe," (throws an error)."),VOe.forEach(t),WVr=i(di),Yt=n(di,"DIV",{class:!0});var LA=s(Yt);T(Rx.$$.fragment,LA),QVr=i(LA),RCe=n(LA,"P",{});var Skt=s(RCe);HVr=r(Skt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Skt.forEach(t),UVr=i(LA),cf=n(LA,"P",{});var woe=s(cf);JVr=r(woe,`Note:
Loading a model from its configuration file does `),PCe=n(woe,"STRONG",{});var Rkt=s(PCe);YVr=r(Rkt,"not"),Rkt.forEach(t),KVr=r(woe,` load the model weights. It only affects the
model\u2019s configuration. Use `),xZ=n(woe,"A",{href:!0});var Pkt=s(xZ);ZVr=r(Pkt,"from_pretrained()"),Pkt.forEach(t),eXr=r(woe," to load the model weights."),woe.forEach(t),oXr=i(LA),T(lw.$$.fragment,LA),LA.forEach(t),rXr=i(di),Ur=n(di,"DIV",{class:!0});var ci=s(Ur);T(Px.$$.fragment,ci),tXr=i(ci),BCe=n(ci,"P",{});var Bkt=s(BCe);aXr=r(Bkt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Bkt.forEach(t),nXr=i(ci),Cn=n(ci,"P",{});var xA=s(Cn);sXr=r(xA,"The model class to instantiate is selected based on the "),ICe=n(xA,"CODE",{});var Ikt=s(ICe);lXr=r(Ikt,"model_type"),Ikt.forEach(t),iXr=r(xA,` property of the config object (either
passed as an argument or loaded from `),NCe=n(xA,"CODE",{});var Nkt=s(NCe);dXr=r(Nkt,"pretrained_model_name_or_path"),Nkt.forEach(t),cXr=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qCe=n(xA,"CODE",{});var qkt=s(qCe);fXr=r(qkt,"pretrained_model_name_or_path"),qkt.forEach(t),mXr=r(xA,":"),xA.forEach(t),gXr=i(ci),Bx=n(ci,"UL",{});var XOe=s(Bx);iw=n(XOe,"LI",{});var Rqe=s(iw);jCe=n(Rqe,"STRONG",{});var jkt=s(jCe);hXr=r(jkt,"beit"),jkt.forEach(t),pXr=r(Rqe," \u2014 "),$Z=n(Rqe,"A",{href:!0});var Dkt=s($Z);_Xr=r(Dkt,"FlaxBeitForImageClassification"),Dkt.forEach(t),uXr=r(Rqe," (BEiT model)"),Rqe.forEach(t),bXr=i(XOe),dw=n(XOe,"LI",{});var Pqe=s(dw);DCe=n(Pqe,"STRONG",{});var Gkt=s(DCe);vXr=r(Gkt,"vit"),Gkt.forEach(t),FXr=r(Pqe," \u2014 "),kZ=n(Pqe,"A",{href:!0});var Okt=s(kZ);TXr=r(Okt,"FlaxViTForImageClassification"),Okt.forEach(t),MXr=r(Pqe," (ViT model)"),Pqe.forEach(t),XOe.forEach(t),EXr=i(ci),T(cw.$$.fragment,ci),ci.forEach(t),di.forEach(t),NDe=i(f),ff=n(f,"H2",{class:!0});var zOe=s(ff);fw=n(zOe,"A",{id:!0,class:!0,href:!0});var Vkt=s(fw);GCe=n(Vkt,"SPAN",{});var Xkt=s(GCe);T(Ix.$$.fragment,Xkt),Xkt.forEach(t),Vkt.forEach(t),CXr=i(zOe),OCe=n(zOe,"SPAN",{});var zkt=s(OCe);wXr=r(zkt,"FlaxAutoModelForVision2Seq"),zkt.forEach(t),zOe.forEach(t),qDe=i(f),Mr=n(f,"DIV",{class:!0});var fi=s(Mr);T(Nx.$$.fragment,fi),AXr=i(fi),mf=n(fi,"P",{});var Aoe=s(mf);yXr=r(Aoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),SZ=n(Aoe,"A",{href:!0});var Wkt=s(SZ);LXr=r(Wkt,"from_pretrained()"),Wkt.forEach(t),xXr=r(Aoe," class method or the "),RZ=n(Aoe,"A",{href:!0});var Qkt=s(RZ);$Xr=r(Qkt,"from_config()"),Qkt.forEach(t),kXr=r(Aoe,` class
method.`),Aoe.forEach(t),SXr=i(fi),qx=n(fi,"P",{});var WOe=s(qx);RXr=r(WOe,"This class cannot be instantiated directly using "),VCe=n(WOe,"CODE",{});var Hkt=s(VCe);PXr=r(Hkt,"__init__()"),Hkt.forEach(t),BXr=r(WOe," (throws an error)."),WOe.forEach(t),IXr=i(fi),Kt=n(fi,"DIV",{class:!0});var $A=s(Kt);T(jx.$$.fragment,$A),NXr=i($A),XCe=n($A,"P",{});var Ukt=s(XCe);qXr=r(Ukt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ukt.forEach(t),jXr=i($A),gf=n($A,"P",{});var yoe=s(gf);DXr=r(yoe,`Note:
Loading a model from its configuration file does `),zCe=n(yoe,"STRONG",{});var Jkt=s(zCe);GXr=r(Jkt,"not"),Jkt.forEach(t),OXr=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),PZ=n(yoe,"A",{href:!0});var Ykt=s(PZ);VXr=r(Ykt,"from_pretrained()"),Ykt.forEach(t),XXr=r(yoe," to load the model weights."),yoe.forEach(t),zXr=i($A),T(mw.$$.fragment,$A),$A.forEach(t),WXr=i(fi),Jr=n(fi,"DIV",{class:!0});var mi=s(Jr);T(Dx.$$.fragment,mi),QXr=i(mi),WCe=n(mi,"P",{});var Kkt=s(WCe);HXr=r(Kkt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Kkt.forEach(t),UXr=i(mi),wn=n(mi,"P",{});var kA=s(wn);JXr=r(kA,"The model class to instantiate is selected based on the "),QCe=n(kA,"CODE",{});var Zkt=s(QCe);YXr=r(Zkt,"model_type"),Zkt.forEach(t),KXr=r(kA,` property of the config object (either
passed as an argument or loaded from `),HCe=n(kA,"CODE",{});var eSt=s(HCe);ZXr=r(eSt,"pretrained_model_name_or_path"),eSt.forEach(t),ezr=r(kA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UCe=n(kA,"CODE",{});var oSt=s(UCe);ozr=r(oSt,"pretrained_model_name_or_path"),oSt.forEach(t),rzr=r(kA,":"),kA.forEach(t),tzr=i(mi),JCe=n(mi,"UL",{});var rSt=s(JCe);gw=n(rSt,"LI",{});var Bqe=s(gw);YCe=n(Bqe,"STRONG",{});var tSt=s(YCe);azr=r(tSt,"vision-encoder-decoder"),tSt.forEach(t),nzr=r(Bqe," \u2014 "),BZ=n(Bqe,"A",{href:!0});var aSt=s(BZ);szr=r(aSt,"FlaxVisionEncoderDecoderModel"),aSt.forEach(t),lzr=r(Bqe," (Vision Encoder decoder model)"),Bqe.forEach(t),rSt.forEach(t),izr=i(mi),T(hw.$$.fragment,mi),mi.forEach(t),fi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(iPt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(yn,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoConfig"),c(xn,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoModel"),c($n,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoTokenizer"),c(vi,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertModel"),c(Tf,"id","extending-the-auto-classes"),c(Tf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Tf,"href","#extending-the-auto-classes"),c(Fi,"class","relative group"),c(Ef,"id","transformers.AutoConfig"),c(Ef,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ef,"href","#transformers.AutoConfig"),c(Ti,"class","relative group"),c(ik,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(dk,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig"),c(ck,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig"),c(fk,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig"),c(mk,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig"),c(gk,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(hk,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig"),c(pk,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(_k,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(uk,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(bk,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig"),c(vk,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig"),c(Fk,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig"),c(Tk,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig"),c(Mk,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig"),c(Ek,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig"),c(Ck,"href","/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtConfig"),c(wk,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(Ak,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(yk,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(Lk,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig"),c(xk,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c($k,"href","/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(kk,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig"),c(Sk,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig"),c(Rk,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig"),c(Pk,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRConfig"),c(Bk,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTConfig"),c(Ik,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig"),c(Nk,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(qk,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig"),c(jk,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaConfig"),c(Dk,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig"),c(Gk,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig"),c(Ok,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig"),c(Vk,"href","/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNConfig"),c(Xk,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config"),c(zk,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(Wk,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(Qk,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig"),c(Hk,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig"),c(Uk,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig"),c(Jk,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(Yk,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Kk,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(Zk,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(eS,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig"),c(oS,"href","/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitConfig"),c(rS,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig"),c(tS,"href","/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeConfig"),c(aS,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig"),c(nS,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Config"),c(sS,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig"),c(lS,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(iS,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig"),c(dS,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(cS,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(fS,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig"),c(mS,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config"),c(gS,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(hS,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(pS,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig"),c(_S,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig"),c(uS,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig"),c(bS,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig"),c(vS,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(FS,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(TS,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(MS,"href","/docs/transformers/pr_17254/en/model_doc/rag#transformers.RagConfig"),c(ES,"href","/docs/transformers/pr_17254/en/model_doc/realm#transformers.RealmConfig"),c(CS,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig"),c(wS,"href","/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetConfig"),c(AS,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig"),c(yS,"href","/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetConfig"),c(LS,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertConfig"),c(xS,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig"),c($S,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig"),c(kS,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig"),c(SS,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig"),c(RS,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig"),c(PS,"href","/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(BS,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(IS,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(NS,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig"),c(qS,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(jS,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig"),c(DS,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config"),c(GS,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig"),c(OS,"href","/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(VS,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(XS,"href","/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRConfig"),c(zS,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(WS,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(QS,"href","/docs/transformers/pr_17254/en/model_doc/van#transformers.VanConfig"),c(HS,"href","/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltConfig"),c(US,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(JS,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(YS,"href","/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(KS,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig"),c(ZS,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(eR,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(oR,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(rR,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig"),c(tR,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig"),c(aR,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig"),c(nR,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(sR,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(lR,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(iR,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig"),c(dR,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosConfig"),c(cR,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lg,"id","transformers.AutoTokenizer"),c(Lg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lg,"href","#transformers.AutoTokenizer"),c(Ei,"class","relative group"),c(fR,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(mR,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizer"),c(gR,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(hR,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartTokenizer"),c(pR,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartTokenizerFast"),c(_R,"href","/docs/transformers/pr_17254/en/model_doc/barthez#transformers.BarthezTokenizer"),c(uR,"href","/docs/transformers/pr_17254/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(bR,"href","/docs/transformers/pr_17254/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(vR,"href","/docs/transformers/pr_17254/en/model_doc/bartpho#transformers.BartphoTokenizerFast"),c(FR,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(TR,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(MR,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(ER,"href","/docs/transformers/pr_17254/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(CR,"href","/docs/transformers/pr_17254/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(wR,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(AR,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(yR,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(LR,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(xR,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c($R,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(kR,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(SR,"href","/docs/transformers/pr_17254/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(RR,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertTokenizer"),c(PR,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(BR,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineTokenizer"),c(IR,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPTokenizer"),c(NR,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(qR,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(jR,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(DR,"href","/docs/transformers/pr_17254/en/model_doc/cpm#transformers.CpmTokenizer"),c(GR,"href","/docs/transformers/pr_17254/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(OR,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(VR,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(XR,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(zR,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaTokenizer"),c(WR,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(QR,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(HR,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(UR,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(JR,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(YR,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(KR,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(ZR,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraTokenizer"),c(eP,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(oP,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(rP,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetTokenizer"),c(tP,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(aP,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(nP,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelTokenizer"),c(sP,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(lP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(dP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(cP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(fP,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(mP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(gP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(hP,"href","/docs/transformers/pr_17254/en/model_doc/herbert#transformers.HerbertTokenizer"),c(pP,"href","/docs/transformers/pr_17254/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(_P,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(uP,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(bP,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(FP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(TP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(MP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(EP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(CP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(wP,"href","/docs/transformers/pr_17254/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(AP,"href","/docs/transformers/pr_17254/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(yP,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDTokenizer"),c(LP,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDTokenizerFast"),c(xP,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerTokenizer"),c($P,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(kP,"href","/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeTokenizer"),c(SP,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(RP,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(PP,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(BP,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianTokenizer"),c(IP,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartTokenizer"),c(NP,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(qP,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(jP,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(DP,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(GP,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(OP,"href","/docs/transformers/pr_17254/en/model_doc/mluke#transformers.MLukeTokenizer"),c(VP,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(XP,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(zP,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(WP,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(QP,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Tokenizer"),c(HP,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5TokenizerFast"),c(UP,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizer"),c(JP,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(YP,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(KP,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(ZP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(eB,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(oB,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(rB,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(tB,"href","/docs/transformers/pr_17254/en/model_doc/phobert#transformers.PhobertTokenizer"),c(aB,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartTokenizer"),c(nB,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(sB,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(lB,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(iB,"href","/docs/transformers/pr_17254/en/model_doc/rag#transformers.RagTokenizer"),c(dB,"href","/docs/transformers/pr_17254/en/model_doc/realm#transformers.RealmTokenizer"),c(cB,"href","/docs/transformers/pr_17254/en/model_doc/realm#transformers.RealmTokenizerFast"),c(fB,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerTokenizer"),c(mB,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(gB,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertTokenizer"),c(hB,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(pB,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(_B,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(uB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(bB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vB,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(FB,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(TB,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(MB,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(EB,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterTokenizer"),c(CB,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(wB,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(AB,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(yB,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Tokenizer"),c(LB,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5TokenizerFast"),c(xB,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasTokenizer"),c($B,"href","/docs/transformers/pr_17254/en/model_doc/tapex#transformers.TapexTokenizer"),c(kB,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(SB,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(RB,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(PB,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(BB,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(IB,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(NB,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMTokenizer"),c(qB,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(jB,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMTokenizer"),c(DB,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(GB,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(OB,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(VB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(XB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(zB,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(WB,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(QB,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizer"),c(HB,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ih,"id","transformers.AutoFeatureExtractor"),c(ih,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ih,"href","#transformers.AutoFeatureExtractor"),c(Ci,"class","relative group"),c(UB,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(JB,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(YB,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(KB,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(ZB,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(eI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(oI,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(rI,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(tI,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(aI,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(nI,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(sI,"href","/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(lI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(iI,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(dI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(cI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(fI,"href","/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(mI,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(gI,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(hI,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(pI,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(_I,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(uI,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(bI,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(vI,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(FI,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(TI,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(MI,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(EI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(CI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(wI,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oh,"id","transformers.AutoProcessor"),c(Oh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Oh,"href","#transformers.AutoProcessor"),c(wi,"class","relative group"),c(AI,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(yI,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPProcessor"),c(LI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(xI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c($I,"href","/docs/transformers/pr_17254/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(kI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(SI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(RI,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(PI,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(BI,"href","/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRProcessor"),c(II,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(NI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(qI,"href","/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltProcessor"),c(jI,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(DI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(GI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(OI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ip,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dp,"id","transformers.AutoModel"),c(dp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dp,"href","#transformers.AutoModel"),c(yi,"class","relative group"),c(VI,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XI,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zI,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WI,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertModel"),c(QI,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartModel"),c(HI,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitModel"),c(UI,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertModel"),c(JI,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(YI,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdModel"),c(KI,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(ZI,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(eN,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(oN,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertModel"),c(rN,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineModel"),c(tN,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPModel"),c(aN,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertModel"),c(nN,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextModel"),c(sN,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLModel"),c(lN,"href","/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtModel"),c(iN,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(dN,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(cN,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(fN,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaModel"),c(mN,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(gN,"href","/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(hN,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTModel"),c(pN,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrModel"),c(_N,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertModel"),c(uN,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(bN,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTModel"),c(vN,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraModel"),c(FN,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertModel"),c(TN,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaModel"),c(MN,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetModel"),c(EN,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTModel"),c(CN,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelModel"),c(wN,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelBaseModel"),c(AN,"href","/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNModel"),c(yN,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Model"),c(LN,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(xN,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c($N,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJModel"),c(kN,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertModel"),c(SN,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertModel"),c(RN,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(PN,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(BN,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(IN,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(NN,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDModel"),c(qN,"href","/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitModel"),c(jN,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerModel"),c(DN,"href","/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeModel"),c(GN,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertModel"),c(ON,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Model"),c(VN,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianModel"),c(XN,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerModel"),c(zN,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartModel"),c(WN,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(QN,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertModel"),c(HN,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetModel"),c(UN,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Model"),c(JN,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerModel"),c(YN,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(KN,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTModel"),c(ZN,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusModel"),c(eq,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverModel"),c(oq,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartModel"),c(rq,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerModel"),c(tq,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(aq,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertModel"),c(nq,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModel"),c(sq,"href","/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetModel"),c(lq,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertModel"),c(iq,"href","/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetModel"),c(dq,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel"),c(cq,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaModel"),c(fq,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerModel"),c(mq,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerModel"),c(gq,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWModel"),c(hq,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDModel"),c(pq,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(_q,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterModel"),c(uq,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(bq,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinModel"),c(vq,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Model"),c(Fq,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasModel"),c(Tq,"href","/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(Mq,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(Eq,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Cq,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(wq,"href","/docs/transformers/pr_17254/en/model_doc/van#transformers.VanModel"),c(Aq,"href","/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltModel"),c(yq,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Lq,"href","/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertModel"),c(xq,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTModel"),c($q,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(kq,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Sq,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Rq,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMModel"),c(Pq,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMModel"),c(Bq,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMModel"),c(Iq,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Nq,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(qq,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(jq,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetModel"),c(Dq,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosModel"),c(Gq,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lu,"id","transformers.AutoModelForPreTraining"),c(lu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lu,"href","#transformers.AutoModelForPreTraining"),c($i,"class","relative group"),c(Oq,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vq,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Xq,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zq,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForPreTraining"),c(Wq,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Qq,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForPreTraining"),c(Hq,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(Uq,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(Jq,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Yq,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(Kq,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Zq,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(ej,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(oj,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForPreTraining"),c(rj,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(tj,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaForPreTraining"),c(aj,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForPreTraining"),c(nj,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(sj,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(lj,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(ij,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(dj,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(cj,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(fj,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(mj,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(gj,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(hj,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(pj,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(_j,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel"),c(uj,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(bj,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(vj,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(Fj,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(Tj,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(Mj,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(Ej,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(Cj,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(wj,"href","/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(Aj,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(yj,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(Lj,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(xj,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c($j,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(kj,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(Sj,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zu,"id","transformers.AutoModelForCausalLM"),c(Zu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zu,"href","#transformers.AutoModelForCausalLM"),c(Ri,"class","relative group"),c(Rj,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pj,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bj,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ij,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForCausalLM"),c(Nj,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertLMHeadModel"),c(qj,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(jj,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(Dj,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Gj,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Oj,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(Vj,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(Xj,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(zj,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(Wj,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Qj,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Hj,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Uj,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(Jj,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(Yj,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianForCausalLM"),c(Kj,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Zj,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(eD,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(oD,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTForCausalLM"),c(rD,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(tD,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(aD,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(nD,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(sD,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(lD,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(iD,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(dD,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(cD,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(fD,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(mD,"href","/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(gD,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(hD,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(pD,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(_D,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(uD,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(bD,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D2,"id","transformers.AutoModelForMaskedLM"),c(D2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D2,"href","#transformers.AutoModelForMaskedLM"),c(Ii,"class","relative group"),c(vD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MD,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(ED,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(CD,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMaskedLM"),c(wD,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(AD,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(yD,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(LD,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(xD,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c($D,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(kD,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(SD,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(RD,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(PD,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(BD,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(ID,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(ND,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(qD,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(jD,"href","/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeForMaskedLM"),c(DD,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(GD,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(OD,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(VD,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(XD,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(zD,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(WD,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(QD,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(HD,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(UD,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(JD,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(YD,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(KD,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(ZD,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(eG,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(oG,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(rG,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A1,"id","transformers.AutoModelForSeq2SeqLM"),c(A1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A1,"href","#transformers.AutoModelForSeq2SeqLM"),c(ji,"class","relative group"),c(tG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sG,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(lG,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(iG,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(dG,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(cG,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(fG,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(mG,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(gG,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(hG,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianMTModel"),c(pG,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(_G,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(uG,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(bG,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(vG,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(FG,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(TG,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W1,"id","transformers.AutoModelForSequenceClassification"),c(W1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W1,"href","#transformers.AutoModelForSequenceClassification"),c(Oi,"class","relative group"),c(MG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wG,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(AG,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForSequenceClassification"),c(yG,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForSequenceClassification"),c(LG,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(xG,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c($G,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(kG,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(SG,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(RG,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(PG,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(BG,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(IG,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(NG,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(qG,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(jG,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(DG,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(GG,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(OG,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(VG,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(XG,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(zG,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(WG,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(QG,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(HG,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(UG,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForSequenceClassification"),c(JG,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(YG,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(KG,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(ZG,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(eO,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(oO,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(rO,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(tO,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(aO,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(nO,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(sO,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(lO,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(iO,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(dO,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(cO,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(fO,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(mO,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(gO,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(hO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(pO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(_O,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(uO,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vb,"id","transformers.AutoModelForMultipleChoice"),c(Vb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vb,"href","#transformers.AutoModelForMultipleChoice"),c(zi,"class","relative group"),c(bO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TO,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(MO,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMultipleChoice"),c(EO,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(CO,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(wO,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(AO,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(yO,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(LO,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(xO,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c($O,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(kO,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(SO,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(RO,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(PO,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(BO,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(IO,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(NO,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(qO,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(jO,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(DO,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(GO,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(OO,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(VO,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(XO,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(zO,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(WO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(QO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(HO,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(UO,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M4,"id","transformers.AutoModelForNextSentencePrediction"),c(M4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M4,"href","#transformers.AutoModelForNextSentencePrediction"),c(Hi,"class","relative group"),c(JO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZO,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(eV,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(oV,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(rV,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(tV,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k4,"id","transformers.AutoModelForTokenClassification"),c(k4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k4,"href","#transformers.AutoModelForTokenClassification"),c(Yi,"class","relative group"),c(aV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lV,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(iV,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForTokenClassification"),c(dV,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(cV,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(fV,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForTokenClassification"),c(mV,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(gV,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(hV,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(pV,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(_V,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(uV,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(bV,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(vV,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(FV,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(TV,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(MV,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(EV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(CV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(wV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(AV,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(yV,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(LV,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(xV,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c($V,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(kV,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(SV,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(RV,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(PV,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(BV,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(IV,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(NV,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(qV,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(jV,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(DV,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pv,"id","transformers.AutoModelForQuestionAnswering"),c(pv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pv,"href","#transformers.AutoModelForQuestionAnswering"),c(ed,"class","relative group"),c(GV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XV,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(zV,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(WV,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(QV,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(HV,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(UV,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(JV,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(YV,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(KV,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(ZV,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(eX,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(oX,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(rX,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(tX,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(aX,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(nX,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(sX,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(lX,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(iX,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(dX,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(cX,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(fX,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(mX,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(gX,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(hX,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(pX,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(_X,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(uX,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(bX,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(vX,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(FX,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(TX,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(MX,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(EX,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(CX,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(wX,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(AX,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(yX,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(LX,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(xX,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n5,"id","transformers.AutoModelForTableQuestionAnswering"),c(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n5,"href","#transformers.AutoModelForTableQuestionAnswering"),c(td,"class","relative group"),c($X,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RX,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c5,"id","transformers.AutoModelForImageClassification"),c(c5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c5,"href","#transformers.AutoModelForImageClassification"),c(sd,"class","relative group"),c(PX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NX,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForImageClassification"),c(qX,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(jX,"href","/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtForImageClassification"),c(DX,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(GX,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassification"),c(OX,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(VX,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(XX,"href","/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitForImageClassification"),c(zX,"href","/docs/transformers/pr_17254/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(WX,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(QX,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(HX,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(UX,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(JX,"href","/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(YX,"href","/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(KX,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(ZX,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForImageClassification"),c(ez,"href","/docs/transformers/pr_17254/en/model_doc/van#transformers.VanForImageClassification"),c(oz,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A5,"id","transformers.AutoModelForVision2Seq"),c(A5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A5,"href","#transformers.AutoModelForVision2Seq"),c(dd,"class","relative group"),c(rz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(az,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nz,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k5,"id","transformers.AutoModelForAudioClassification"),c(k5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k5,"href","#transformers.AutoModelForAudioClassification"),c(md,"class","relative group"),c(sz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dz,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(cz,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(fz,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(mz,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(gz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(hz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(pz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(_z,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(uz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X5,"id","transformers.AutoModelForAudioFrameClassification"),c(X5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X5,"href","#transformers.AutoModelForAudioFrameClassification"),c(pd,"class","relative group"),c(bz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(Mz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(Ez,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(Cz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(wz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z5,"id","transformers.AutoModelForCTC"),c(Z5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z5,"href","#transformers.AutoModelForCTC"),c(bd,"class","relative group"),c(Az,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Lz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xz,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c($z,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForCTC"),c(kz,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForCTC"),c(Sz,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForCTC"),c(Rz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(Pz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(Bz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(Iz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(Nz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForCTC"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(mF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Td,"class","relative group"),c(qz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gz,"href","/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(Oz,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bF,"id","transformers.AutoModelForAudioXVector"),c(bF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bF,"href","#transformers.AutoModelForAudioXVector"),c(Cd,"class","relative group"),c(Vz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wz,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(Qz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(Hz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(Uz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(Jz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForXVector"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yF,"id","transformers.AutoModelForMaskedImageModeling"),c(yF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yF,"href","#transformers.AutoModelForMaskedImageModeling"),c(yd,"class","relative group"),c(Yz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eW,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(oW,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(rW,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PF,"id","transformers.AutoModelForObjectDetection"),c(PF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PF,"href","#transformers.AutoModelForObjectDetection"),c(kd,"class","relative group"),c(tW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sW,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForObjectDetection"),c(lW,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DF,"id","transformers.AutoModelForImageSegmentation"),c(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DF,"href","#transformers.AutoModelForImageSegmentation"),c(Pd,"class","relative group"),c(iW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fW,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForSegmentation"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zF,"id","transformers.AutoModelForSemanticSegmentation"),c(zF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zF,"href","#transformers.AutoModelForSemanticSegmentation"),c(Nd,"class","relative group"),c(mW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pW,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(_W,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(uW,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(bW,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZF,"id","transformers.AutoModelForInstanceSegmentation"),c(ZF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZF,"href","#transformers.AutoModelForInstanceSegmentation"),c(Dd,"class","relative group"),c(vW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MW,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aT,"id","transformers.TFAutoModel"),c(aT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aT,"href","#transformers.TFAutoModel"),c(Vd,"class","relative group"),c(EW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AW,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertModel"),c(yW,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartModel"),c(LW,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertModel"),c(xW,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c($W,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(kW,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertModel"),c(SW,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.TFCLIPModel"),c(RW,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertModel"),c(PW,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextModel"),c(BW,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLModel"),c(IW,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(NW,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaModel"),c(qW,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(jW,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(DW,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(GW,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraModel"),c(OW,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(VW,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelModel"),c(XW,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(zW,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2Model"),c(WW,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJModel"),c(QW,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.TFHubertModel"),c(HW,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(UW,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDModel"),c(JW,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerModel"),c(YW,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertModel"),c(KW,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianModel"),c(ZW,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartModel"),c(eQ,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(oQ,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetModel"),c(rQ,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5Model"),c(tQ,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(aQ,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.TFOPTModel"),c(nQ,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusModel"),c(sQ,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertModel"),c(lQ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaModel"),c(iQ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerModel"),c(dQ,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(cQ,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinModel"),c(fQ,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5Model"),c(mQ,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasModel"),c(gQ,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(hQ,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTModel"),c(pQ,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(_Q,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(uQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMModel"),c(bQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(vQ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZT,"id","transformers.TFAutoModelForPreTraining"),c(ZT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZT,"href","#transformers.TFAutoModelForPreTraining"),c(Wd,"class","relative group"),c(FQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EQ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(CQ,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(wQ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForPreTraining"),c(AQ,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(yQ,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(LQ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(xQ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForPreTraining"),c($Q,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(kQ,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(SQ,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(RQ,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(PQ,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(BQ,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(IQ,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(NQ,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(qQ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(jQ,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(DQ,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(GQ,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(OQ,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(VQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(XQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(zQ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w7,"id","transformers.TFAutoModelForCausalLM"),c(w7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w7,"href","#transformers.TFAutoModelForCausalLM"),c(Ud,"class","relative group"),c(WQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UQ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(JQ,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(YQ,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(KQ,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(ZQ,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(eH,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(oH,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(rH,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(tH,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(aH,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(nH,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(sH,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(lH,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G7,"id","transformers.TFAutoModelForImageClassification"),c(G7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G7,"href","#transformers.TFAutoModelForImageClassification"),c(Kd,"class","relative group"),c(iH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fH,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(mH,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(gH,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(hH,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H7,"id","transformers.TFAutoModelForMaskedLM"),c(H7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H7,"href","#transformers.TFAutoModelForMaskedLM"),c(oc,"class","relative group"),c(pH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_H,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bH,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(vH,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(FH,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(TH,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(MH,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(EH,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(CH,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(wH,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(AH,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(yH,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(LH,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(xH,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c($H,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(kH,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(SH,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(RH,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(PH,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(BH,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(IH,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(NH,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uM,"id","transformers.TFAutoModelForSeq2SeqLM"),c(uM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uM,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(ac,"class","relative group"),c(qH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GH,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(OH,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(VH,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(XH,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(zH,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(WH,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianMTModel"),c(QH,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(HH,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(UH,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(JH,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($M,"id","transformers.TFAutoModelForSequenceClassification"),c($M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($M,"href","#transformers.TFAutoModelForSequenceClassification"),c(lc,"class","relative group"),c(YH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eU,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(oU,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(rU,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(tU,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(aU,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(nU,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(sU,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(lU,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(iU,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(dU,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(cU,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(fU,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(mU,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(gU,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(hU,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(pU,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(_U,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(uU,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(bU,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(vU,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(FU,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(TU,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(MU,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(EU,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(CU,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(wU,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nE,"id","transformers.TFAutoModelForMultipleChoice"),c(nE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nE,"href","#transformers.TFAutoModelForMultipleChoice"),c(cc,"class","relative group"),c(AU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xU,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c($U,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(kU,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(SU,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(RU,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(PU,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(BU,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(IU,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(NU,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(qU,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(jU,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(DU,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(GU,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(OU,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(VU,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(XU,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(zU,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wE,"id","transformers.TFAutoModelForNextSentencePrediction"),c(wE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wE,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(gc,"class","relative group"),c(WU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UU,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(JU,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($E,"id","transformers.TFAutoModelForTableQuestionAnswering"),c($E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($E,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(_c,"class","relative group"),c(YU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eJ,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PE,"id","transformers.TFAutoModelForTokenClassification"),c(PE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PE,"href","#transformers.TFAutoModelForTokenClassification"),c(vc,"class","relative group"),c(oJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aJ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(nJ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(sJ,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(lJ,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(iJ,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(dJ,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(cJ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(fJ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(mJ,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(gJ,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(hJ,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(pJ,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(_J,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(uJ,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(bJ,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(vJ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(FJ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(TJ,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(MJ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(EJ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tC,"id","transformers.TFAutoModelForQuestionAnswering"),c(tC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tC,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Mc,"class","relative group"),c(CJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yJ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(LJ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(xJ,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c($J,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(kJ,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(SJ,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(RJ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(PJ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(BJ,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(IJ,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(NJ,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(qJ,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(jJ,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(DJ,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(GJ,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(OJ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(VJ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(XJ,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(zJ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(WJ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AC,"id","transformers.TFAutoModelForVision2Seq"),c(AC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AC,"href","#transformers.TFAutoModelForVision2Seq"),c(wc,"class","relative group"),c(QJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JJ,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($C,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c($C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($C,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Lc,"class","relative group"),c(YJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eY,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PC,"id","transformers.FlaxAutoModel"),c(PC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PC,"href","#transformers.FlaxAutoModel"),c(kc,"class","relative group"),c(oY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aY,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertModel"),c(nY,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartModel"),c(sY,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitModel"),c(lY,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertModel"),c(iY,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(dY,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(cY,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(fY,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.FlaxCLIPModel"),c(mY,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(gY,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraModel"),c(hY,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(pY,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(_Y,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(uY,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianModel"),c(bY,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartModel"),c(vY,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5Model"),c(FY,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.FlaxOPTModel"),c(TY,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(MY,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(EY,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(CY,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5Model"),c(wY,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(AY,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTModel"),c(yY,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(LY,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(xY,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d3,"id","transformers.FlaxAutoModelForCausalLM"),c(d3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d3,"href","#transformers.FlaxAutoModelForCausalLM"),c(Pc,"class","relative group"),c($Y,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RY,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(PY,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(BY,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(IY,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(NY,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(qY,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(jY,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(DY,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(GY,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(OY,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M3,"id","transformers.FlaxAutoModelForPreTraining"),c(M3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M3,"href","#transformers.FlaxAutoModelForPreTraining"),c(Nc,"class","relative group"),c(VY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WY,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(QY,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(HY,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(UY,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(JY,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(YY,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(KY,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ZY,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(eK,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(oK,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(rK,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(tK,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N3,"id","transformers.FlaxAutoModelForMaskedLM"),c(N3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N3,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Dc,"class","relative group"),c(aK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lK,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(iK,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(dK,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(cK,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(fK,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(mK,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(gK,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(hK,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(pK,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(_K,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J3,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(J3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J3,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Vc,"class","relative group"),c(uK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FK,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(TK,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(MK,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(EK,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(CK,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(wK,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(AK,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(yK,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(LK,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i0,"id","transformers.FlaxAutoModelForSequenceClassification"),c(i0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i0,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Wc,"class","relative group"),c(xK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($K,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SK,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(RK,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(PK,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(BK,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(IK,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(NK,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(qK,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(jK,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(DK,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(GK,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T0,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(T0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T0,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Uc,"class","relative group"),c(OK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zK,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(WK,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(QK,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(HK,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(UK,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(JK,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(YK,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(KK,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(ZK,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(eZ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P0,"id","transformers.FlaxAutoModelForTokenClassification"),c(P0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P0,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Kc,"class","relative group"),c(oZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aZ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(nZ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(sZ,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(lZ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(iZ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(dZ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(cZ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(fZ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z0,"id","transformers.FlaxAutoModelForMultipleChoice"),c(z0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z0,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(of,"class","relative group"),c(mZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pZ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(_Z,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(uZ,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(bZ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(vZ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(FZ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(TZ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(MZ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(rw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(af,"class","relative group"),c(EZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AZ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sw,"id","transformers.FlaxAutoModelForImageClassification"),c(sw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sw,"href","#transformers.FlaxAutoModelForImageClassification"),c(lf,"class","relative group"),c(yZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($Z,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(kZ,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fw,"id","transformers.FlaxAutoModelForVision2Seq"),c(fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fw,"href","#transformers.FlaxAutoModelForVision2Seq"),c(ff,"class","relative group"),c(SZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BZ,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Mo),e(Mo,gi),b(f,uf,u),b(f,rt,u),e(rt,hi),e(rt,pi),e(pi,SA),e(rt,bf),b(f,De,u),b(f,We,u),e(We,_i),e(We,yn),e(yn,RA),e(We,Ln),e(We,xn),e(xn,PA),e(We,ui),e(We,$n),e($n,BA),e(We,bi),b(f,vf,u),M(Ca,f,u),b(f,Qe,u),b(f,Ae,u),e(Ae,rk),e(Ae,vi),e(vi,tk),e(Ae,ak),b(f,Eo,u),b(f,wa,u),e(wa,nk),e(wa,Ff),e(Ff,sk),e(wa,QOe),b(f,Iqe,u),b(f,Fi,u),e(Fi,Tf),e(Tf,Loe),M(IA,Loe,null),e(Fi,HOe),e(Fi,xoe),e(xoe,UOe),b(f,Nqe,u),b(f,kn,u),e(kn,JOe),e(kn,$oe),e($oe,YOe),e(kn,KOe),e(kn,koe),e(koe,ZOe),e(kn,eVe),b(f,qqe,u),M(NA,f,u),b(f,jqe,u),b(f,lk,u),e(lk,oVe),b(f,Dqe,u),M(Mf,f,u),b(f,Gqe,u),b(f,Ti,u),e(Ti,Ef),e(Ef,Soe),M(qA,Soe,null),e(Ti,rVe),e(Ti,Roe),e(Roe,tVe),b(f,Oqe,u),b(f,Co,u),M(jA,Co,null),e(Co,aVe),e(Co,DA),e(DA,nVe),e(DA,ik),e(ik,sVe),e(DA,lVe),e(Co,iVe),e(Co,GA),e(GA,dVe),e(GA,Poe),e(Poe,cVe),e(GA,fVe),e(Co,mVe),e(Co,Er),M(OA,Er,null),e(Er,gVe),e(Er,Boe),e(Boe,hVe),e(Er,pVe),e(Er,Mi),e(Mi,_Ve),e(Mi,Ioe),e(Ioe,uVe),e(Mi,bVe),e(Mi,Noe),e(Noe,vVe),e(Mi,FVe),e(Er,TVe),e(Er,A),e(A,Cf),e(Cf,qoe),e(qoe,MVe),e(Cf,EVe),e(Cf,dk),e(dk,CVe),e(Cf,wVe),e(A,AVe),e(A,wf),e(wf,joe),e(joe,yVe),e(wf,LVe),e(wf,ck),e(ck,xVe),e(wf,$Ve),e(A,kVe),e(A,Af),e(Af,Doe),e(Doe,SVe),e(Af,RVe),e(Af,fk),e(fk,PVe),e(Af,BVe),e(A,IVe),e(A,yf),e(yf,Goe),e(Goe,NVe),e(yf,qVe),e(yf,mk),e(mk,jVe),e(yf,DVe),e(A,GVe),e(A,Lf),e(Lf,Ooe),e(Ooe,OVe),e(Lf,VVe),e(Lf,gk),e(gk,XVe),e(Lf,zVe),e(A,WVe),e(A,xf),e(xf,Voe),e(Voe,QVe),e(xf,HVe),e(xf,hk),e(hk,UVe),e(xf,JVe),e(A,YVe),e(A,$f),e($f,Xoe),e(Xoe,KVe),e($f,ZVe),e($f,pk),e(pk,eXe),e($f,oXe),e(A,rXe),e(A,kf),e(kf,zoe),e(zoe,tXe),e(kf,aXe),e(kf,_k),e(_k,nXe),e(kf,sXe),e(A,lXe),e(A,Sf),e(Sf,Woe),e(Woe,iXe),e(Sf,dXe),e(Sf,uk),e(uk,cXe),e(Sf,fXe),e(A,mXe),e(A,Rf),e(Rf,Qoe),e(Qoe,gXe),e(Rf,hXe),e(Rf,bk),e(bk,pXe),e(Rf,_Xe),e(A,uXe),e(A,Pf),e(Pf,Hoe),e(Hoe,bXe),e(Pf,vXe),e(Pf,vk),e(vk,FXe),e(Pf,TXe),e(A,MXe),e(A,Bf),e(Bf,Uoe),e(Uoe,EXe),e(Bf,CXe),e(Bf,Fk),e(Fk,wXe),e(Bf,AXe),e(A,yXe),e(A,If),e(If,Joe),e(Joe,LXe),e(If,xXe),e(If,Tk),e(Tk,$Xe),e(If,kXe),e(A,SXe),e(A,Nf),e(Nf,Yoe),e(Yoe,RXe),e(Nf,PXe),e(Nf,Mk),e(Mk,BXe),e(Nf,IXe),e(A,NXe),e(A,qf),e(qf,Koe),e(Koe,qXe),e(qf,jXe),e(qf,Ek),e(Ek,DXe),e(qf,GXe),e(A,OXe),e(A,jf),e(jf,Zoe),e(Zoe,VXe),e(jf,XXe),e(jf,Ck),e(Ck,zXe),e(jf,WXe),e(A,QXe),e(A,Df),e(Df,ere),e(ere,HXe),e(Df,UXe),e(Df,wk),e(wk,JXe),e(Df,YXe),e(A,KXe),e(A,Gf),e(Gf,ore),e(ore,ZXe),e(Gf,eze),e(Gf,Ak),e(Ak,oze),e(Gf,rze),e(A,tze),e(A,Of),e(Of,rre),e(rre,aze),e(Of,nze),e(Of,yk),e(yk,sze),e(Of,lze),e(A,ize),e(A,Vf),e(Vf,tre),e(tre,dze),e(Vf,cze),e(Vf,Lk),e(Lk,fze),e(Vf,mze),e(A,gze),e(A,Xf),e(Xf,are),e(are,hze),e(Xf,pze),e(Xf,xk),e(xk,_ze),e(Xf,uze),e(A,bze),e(A,zf),e(zf,nre),e(nre,vze),e(zf,Fze),e(zf,$k),e($k,Tze),e(zf,Mze),e(A,Eze),e(A,Wf),e(Wf,sre),e(sre,Cze),e(Wf,wze),e(Wf,kk),e(kk,Aze),e(Wf,yze),e(A,Lze),e(A,Qf),e(Qf,lre),e(lre,xze),e(Qf,$ze),e(Qf,Sk),e(Sk,kze),e(Qf,Sze),e(A,Rze),e(A,Hf),e(Hf,ire),e(ire,Pze),e(Hf,Bze),e(Hf,Rk),e(Rk,Ize),e(Hf,Nze),e(A,qze),e(A,Uf),e(Uf,dre),e(dre,jze),e(Uf,Dze),e(Uf,Pk),e(Pk,Gze),e(Uf,Oze),e(A,Vze),e(A,Jf),e(Jf,cre),e(cre,Xze),e(Jf,zze),e(Jf,Bk),e(Bk,Wze),e(Jf,Qze),e(A,Hze),e(A,Yf),e(Yf,fre),e(fre,Uze),e(Yf,Jze),e(Yf,Ik),e(Ik,Yze),e(Yf,Kze),e(A,Zze),e(A,Kf),e(Kf,mre),e(mre,eWe),e(Kf,oWe),e(Kf,Nk),e(Nk,rWe),e(Kf,tWe),e(A,aWe),e(A,Zf),e(Zf,gre),e(gre,nWe),e(Zf,sWe),e(Zf,qk),e(qk,lWe),e(Zf,iWe),e(A,dWe),e(A,em),e(em,hre),e(hre,cWe),e(em,fWe),e(em,jk),e(jk,mWe),e(em,gWe),e(A,hWe),e(A,om),e(om,pre),e(pre,pWe),e(om,_We),e(om,Dk),e(Dk,uWe),e(om,bWe),e(A,vWe),e(A,rm),e(rm,_re),e(_re,FWe),e(rm,TWe),e(rm,Gk),e(Gk,MWe),e(rm,EWe),e(A,CWe),e(A,tm),e(tm,ure),e(ure,wWe),e(tm,AWe),e(tm,Ok),e(Ok,yWe),e(tm,LWe),e(A,xWe),e(A,am),e(am,bre),e(bre,$We),e(am,kWe),e(am,Vk),e(Vk,SWe),e(am,RWe),e(A,PWe),e(A,nm),e(nm,vre),e(vre,BWe),e(nm,IWe),e(nm,Xk),e(Xk,NWe),e(nm,qWe),e(A,jWe),e(A,sm),e(sm,Fre),e(Fre,DWe),e(sm,GWe),e(sm,zk),e(zk,OWe),e(sm,VWe),e(A,XWe),e(A,lm),e(lm,Tre),e(Tre,zWe),e(lm,WWe),e(lm,Wk),e(Wk,QWe),e(lm,HWe),e(A,UWe),e(A,im),e(im,Mre),e(Mre,JWe),e(im,YWe),e(im,Qk),e(Qk,KWe),e(im,ZWe),e(A,eQe),e(A,dm),e(dm,Ere),e(Ere,oQe),e(dm,rQe),e(dm,Hk),e(Hk,tQe),e(dm,aQe),e(A,nQe),e(A,cm),e(cm,Cre),e(Cre,sQe),e(cm,lQe),e(cm,Uk),e(Uk,iQe),e(cm,dQe),e(A,cQe),e(A,fm),e(fm,wre),e(wre,fQe),e(fm,mQe),e(fm,Jk),e(Jk,gQe),e(fm,hQe),e(A,pQe),e(A,mm),e(mm,Are),e(Are,_Qe),e(mm,uQe),e(mm,Yk),e(Yk,bQe),e(mm,vQe),e(A,FQe),e(A,gm),e(gm,yre),e(yre,TQe),e(gm,MQe),e(gm,Kk),e(Kk,EQe),e(gm,CQe),e(A,wQe),e(A,hm),e(hm,Lre),e(Lre,AQe),e(hm,yQe),e(hm,Zk),e(Zk,LQe),e(hm,xQe),e(A,$Qe),e(A,pm),e(pm,xre),e(xre,kQe),e(pm,SQe),e(pm,eS),e(eS,RQe),e(pm,PQe),e(A,BQe),e(A,_m),e(_m,$re),e($re,IQe),e(_m,NQe),e(_m,oS),e(oS,qQe),e(_m,jQe),e(A,DQe),e(A,um),e(um,kre),e(kre,GQe),e(um,OQe),e(um,rS),e(rS,VQe),e(um,XQe),e(A,zQe),e(A,bm),e(bm,Sre),e(Sre,WQe),e(bm,QQe),e(bm,tS),e(tS,HQe),e(bm,UQe),e(A,JQe),e(A,vm),e(vm,Rre),e(Rre,YQe),e(vm,KQe),e(vm,aS),e(aS,ZQe),e(vm,eHe),e(A,oHe),e(A,Fm),e(Fm,Pre),e(Pre,rHe),e(Fm,tHe),e(Fm,nS),e(nS,aHe),e(Fm,nHe),e(A,sHe),e(A,Tm),e(Tm,Bre),e(Bre,lHe),e(Tm,iHe),e(Tm,sS),e(sS,dHe),e(Tm,cHe),e(A,fHe),e(A,Mm),e(Mm,Ire),e(Ire,mHe),e(Mm,gHe),e(Mm,lS),e(lS,hHe),e(Mm,pHe),e(A,_He),e(A,Em),e(Em,Nre),e(Nre,uHe),e(Em,bHe),e(Em,iS),e(iS,vHe),e(Em,FHe),e(A,THe),e(A,Cm),e(Cm,qre),e(qre,MHe),e(Cm,EHe),e(Cm,dS),e(dS,CHe),e(Cm,wHe),e(A,AHe),e(A,wm),e(wm,jre),e(jre,yHe),e(wm,LHe),e(wm,cS),e(cS,xHe),e(wm,$He),e(A,kHe),e(A,Am),e(Am,Dre),e(Dre,SHe),e(Am,RHe),e(Am,fS),e(fS,PHe),e(Am,BHe),e(A,IHe),e(A,ym),e(ym,Gre),e(Gre,NHe),e(ym,qHe),e(ym,mS),e(mS,jHe),e(ym,DHe),e(A,GHe),e(A,Lm),e(Lm,Ore),e(Ore,OHe),e(Lm,VHe),e(Lm,gS),e(gS,XHe),e(Lm,zHe),e(A,WHe),e(A,xm),e(xm,Vre),e(Vre,QHe),e(xm,HHe),e(xm,hS),e(hS,UHe),e(xm,JHe),e(A,YHe),e(A,$m),e($m,Xre),e(Xre,KHe),e($m,ZHe),e($m,pS),e(pS,eUe),e($m,oUe),e(A,rUe),e(A,km),e(km,zre),e(zre,tUe),e(km,aUe),e(km,_S),e(_S,nUe),e(km,sUe),e(A,lUe),e(A,Sm),e(Sm,Wre),e(Wre,iUe),e(Sm,dUe),e(Sm,uS),e(uS,cUe),e(Sm,fUe),e(A,mUe),e(A,Rm),e(Rm,Qre),e(Qre,gUe),e(Rm,hUe),e(Rm,bS),e(bS,pUe),e(Rm,_Ue),e(A,uUe),e(A,Pm),e(Pm,Hre),e(Hre,bUe),e(Pm,vUe),e(Pm,vS),e(vS,FUe),e(Pm,TUe),e(A,MUe),e(A,Bm),e(Bm,Ure),e(Ure,EUe),e(Bm,CUe),e(Bm,FS),e(FS,wUe),e(Bm,AUe),e(A,yUe),e(A,Im),e(Im,Jre),e(Jre,LUe),e(Im,xUe),e(Im,TS),e(TS,$Ue),e(Im,kUe),e(A,SUe),e(A,Nm),e(Nm,Yre),e(Yre,RUe),e(Nm,PUe),e(Nm,MS),e(MS,BUe),e(Nm,IUe),e(A,NUe),e(A,qm),e(qm,Kre),e(Kre,qUe),e(qm,jUe),e(qm,ES),e(ES,DUe),e(qm,GUe),e(A,OUe),e(A,jm),e(jm,Zre),e(Zre,VUe),e(jm,XUe),e(jm,CS),e(CS,zUe),e(jm,WUe),e(A,QUe),e(A,Dm),e(Dm,ete),e(ete,HUe),e(Dm,UUe),e(Dm,wS),e(wS,JUe),e(Dm,YUe),e(A,KUe),e(A,Gm),e(Gm,ote),e(ote,ZUe),e(Gm,eJe),e(Gm,AS),e(AS,oJe),e(Gm,rJe),e(A,tJe),e(A,Om),e(Om,rte),e(rte,aJe),e(Om,nJe),e(Om,yS),e(yS,sJe),e(Om,lJe),e(A,iJe),e(A,Vm),e(Vm,tte),e(tte,dJe),e(Vm,cJe),e(Vm,LS),e(LS,fJe),e(Vm,mJe),e(A,gJe),e(A,Xm),e(Xm,ate),e(ate,hJe),e(Xm,pJe),e(Xm,xS),e(xS,_Je),e(Xm,uJe),e(A,bJe),e(A,zm),e(zm,nte),e(nte,vJe),e(zm,FJe),e(zm,$S),e($S,TJe),e(zm,MJe),e(A,EJe),e(A,Wm),e(Wm,ste),e(ste,CJe),e(Wm,wJe),e(Wm,kS),e(kS,AJe),e(Wm,yJe),e(A,LJe),e(A,Qm),e(Qm,lte),e(lte,xJe),e(Qm,$Je),e(Qm,SS),e(SS,kJe),e(Qm,SJe),e(A,RJe),e(A,Hm),e(Hm,ite),e(ite,PJe),e(Hm,BJe),e(Hm,RS),e(RS,IJe),e(Hm,NJe),e(A,qJe),e(A,Um),e(Um,dte),e(dte,jJe),e(Um,DJe),e(Um,PS),e(PS,GJe),e(Um,OJe),e(A,VJe),e(A,Jm),e(Jm,cte),e(cte,XJe),e(Jm,zJe),e(Jm,BS),e(BS,WJe),e(Jm,QJe),e(A,HJe),e(A,Ym),e(Ym,fte),e(fte,UJe),e(Ym,JJe),e(Ym,IS),e(IS,YJe),e(Ym,KJe),e(A,ZJe),e(A,Km),e(Km,mte),e(mte,eYe),e(Km,oYe),e(Km,NS),e(NS,rYe),e(Km,tYe),e(A,aYe),e(A,Zm),e(Zm,gte),e(gte,nYe),e(Zm,sYe),e(Zm,qS),e(qS,lYe),e(Zm,iYe),e(A,dYe),e(A,eg),e(eg,hte),e(hte,cYe),e(eg,fYe),e(eg,jS),e(jS,mYe),e(eg,gYe),e(A,hYe),e(A,og),e(og,pte),e(pte,pYe),e(og,_Ye),e(og,DS),e(DS,uYe),e(og,bYe),e(A,vYe),e(A,rg),e(rg,_te),e(_te,FYe),e(rg,TYe),e(rg,GS),e(GS,MYe),e(rg,EYe),e(A,CYe),e(A,tg),e(tg,ute),e(ute,wYe),e(tg,AYe),e(tg,OS),e(OS,yYe),e(tg,LYe),e(A,xYe),e(A,ag),e(ag,bte),e(bte,$Ye),e(ag,kYe),e(ag,VS),e(VS,SYe),e(ag,RYe),e(A,PYe),e(A,ng),e(ng,vte),e(vte,BYe),e(ng,IYe),e(ng,XS),e(XS,NYe),e(ng,qYe),e(A,jYe),e(A,sg),e(sg,Fte),e(Fte,DYe),e(sg,GYe),e(sg,zS),e(zS,OYe),e(sg,VYe),e(A,XYe),e(A,lg),e(lg,Tte),e(Tte,zYe),e(lg,WYe),e(lg,WS),e(WS,QYe),e(lg,HYe),e(A,UYe),e(A,ig),e(ig,Mte),e(Mte,JYe),e(ig,YYe),e(ig,QS),e(QS,KYe),e(ig,ZYe),e(A,eKe),e(A,dg),e(dg,Ete),e(Ete,oKe),e(dg,rKe),e(dg,HS),e(HS,tKe),e(dg,aKe),e(A,nKe),e(A,cg),e(cg,Cte),e(Cte,sKe),e(cg,lKe),e(cg,US),e(US,iKe),e(cg,dKe),e(A,cKe),e(A,fg),e(fg,wte),e(wte,fKe),e(fg,mKe),e(fg,JS),e(JS,gKe),e(fg,hKe),e(A,pKe),e(A,mg),e(mg,Ate),e(Ate,_Ke),e(mg,uKe),e(mg,YS),e(YS,bKe),e(mg,vKe),e(A,FKe),e(A,gg),e(gg,yte),e(yte,TKe),e(gg,MKe),e(gg,KS),e(KS,EKe),e(gg,CKe),e(A,wKe),e(A,hg),e(hg,Lte),e(Lte,AKe),e(hg,yKe),e(hg,ZS),e(ZS,LKe),e(hg,xKe),e(A,$Ke),e(A,pg),e(pg,xte),e(xte,kKe),e(pg,SKe),e(pg,eR),e(eR,RKe),e(pg,PKe),e(A,BKe),e(A,_g),e(_g,$te),e($te,IKe),e(_g,NKe),e(_g,oR),e(oR,qKe),e(_g,jKe),e(A,DKe),e(A,ug),e(ug,kte),e(kte,GKe),e(ug,OKe),e(ug,rR),e(rR,VKe),e(ug,XKe),e(A,zKe),e(A,bg),e(bg,Ste),e(Ste,WKe),e(bg,QKe),e(bg,tR),e(tR,HKe),e(bg,UKe),e(A,JKe),e(A,vg),e(vg,Rte),e(Rte,YKe),e(vg,KKe),e(vg,aR),e(aR,ZKe),e(vg,eZe),e(A,oZe),e(A,Fg),e(Fg,Pte),e(Pte,rZe),e(Fg,tZe),e(Fg,nR),e(nR,aZe),e(Fg,nZe),e(A,sZe),e(A,Tg),e(Tg,Bte),e(Bte,lZe),e(Tg,iZe),e(Tg,sR),e(sR,dZe),e(Tg,cZe),e(A,fZe),e(A,Mg),e(Mg,Ite),e(Ite,mZe),e(Mg,gZe),e(Mg,lR),e(lR,hZe),e(Mg,pZe),e(A,_Ze),e(A,Eg),e(Eg,Nte),e(Nte,uZe),e(Eg,bZe),e(Eg,iR),e(iR,vZe),e(Eg,FZe),e(A,TZe),e(A,Cg),e(Cg,qte),e(qte,MZe),e(Cg,EZe),e(Cg,dR),e(dR,CZe),e(Cg,wZe),e(A,AZe),e(A,wg),e(wg,jte),e(jte,yZe),e(wg,LZe),e(wg,cR),e(cR,xZe),e(wg,$Ze),e(Er,kZe),M(Ag,Er,null),e(Co,SZe),e(Co,yg),M(VA,yg,null),e(yg,RZe),e(yg,Dte),e(Dte,PZe),b(f,Vqe,u),b(f,Ei,u),e(Ei,Lg),e(Lg,Gte),M(XA,Gte,null),e(Ei,BZe),e(Ei,Ote),e(Ote,IZe),b(f,Xqe,u),b(f,wo,u),M(zA,wo,null),e(wo,NZe),e(wo,WA),e(WA,qZe),e(WA,fR),e(fR,jZe),e(WA,DZe),e(wo,GZe),e(wo,QA),e(QA,OZe),e(QA,Vte),e(Vte,VZe),e(QA,XZe),e(wo,zZe),e(wo,Cr),M(HA,Cr,null),e(Cr,WZe),e(Cr,Xte),e(Xte,QZe),e(Cr,HZe),e(Cr,Aa),e(Aa,UZe),e(Aa,zte),e(zte,JZe),e(Aa,YZe),e(Aa,Wte),e(Wte,KZe),e(Aa,ZZe),e(Aa,Qte),e(Qte,eeo),e(Aa,oeo),e(Cr,reo),e(Cr,k),e(k,Sn),e(Sn,Hte),e(Hte,teo),e(Sn,aeo),e(Sn,mR),e(mR,neo),e(Sn,seo),e(Sn,gR),e(gR,leo),e(Sn,ieo),e(k,deo),e(k,Rn),e(Rn,Ute),e(Ute,ceo),e(Rn,feo),e(Rn,hR),e(hR,meo),e(Rn,geo),e(Rn,pR),e(pR,heo),e(Rn,peo),e(k,_eo),e(k,Pn),e(Pn,Jte),e(Jte,ueo),e(Pn,beo),e(Pn,_R),e(_R,veo),e(Pn,Feo),e(Pn,uR),e(uR,Teo),e(Pn,Meo),e(k,Eeo),e(k,Bn),e(Bn,Yte),e(Yte,Ceo),e(Bn,weo),e(Bn,bR),e(bR,Aeo),e(Bn,yeo),e(Bn,vR),e(vR,Leo),e(Bn,xeo),e(k,$eo),e(k,In),e(In,Kte),e(Kte,keo),e(In,Seo),e(In,FR),e(FR,Reo),e(In,Peo),e(In,TR),e(TR,Beo),e(In,Ieo),e(k,Neo),e(k,xg),e(xg,Zte),e(Zte,qeo),e(xg,jeo),e(xg,MR),e(MR,Deo),e(xg,Geo),e(k,Oeo),e(k,$g),e($g,eae),e(eae,Veo),e($g,Xeo),e($g,ER),e(ER,zeo),e($g,Weo),e(k,Qeo),e(k,kg),e(kg,oae),e(oae,Heo),e(kg,Ueo),e(kg,CR),e(CR,Jeo),e(kg,Yeo),e(k,Keo),e(k,Nn),e(Nn,rae),e(rae,Zeo),e(Nn,eoo),e(Nn,wR),e(wR,ooo),e(Nn,roo),e(Nn,AR),e(AR,too),e(Nn,aoo),e(k,noo),e(k,qn),e(qn,tae),e(tae,soo),e(qn,loo),e(qn,yR),e(yR,ioo),e(qn,doo),e(qn,LR),e(LR,coo),e(qn,foo),e(k,moo),e(k,jn),e(jn,aae),e(aae,goo),e(jn,hoo),e(jn,xR),e(xR,poo),e(jn,_oo),e(jn,$R),e($R,uoo),e(jn,boo),e(k,voo),e(k,Sg),e(Sg,nae),e(nae,Foo),e(Sg,Too),e(Sg,kR),e(kR,Moo),e(Sg,Eoo),e(k,Coo),e(k,Rg),e(Rg,sae),e(sae,woo),e(Rg,Aoo),e(Rg,SR),e(SR,yoo),e(Rg,Loo),e(k,xoo),e(k,Dn),e(Dn,lae),e(lae,$oo),e(Dn,koo),e(Dn,RR),e(RR,Soo),e(Dn,Roo),e(Dn,PR),e(PR,Poo),e(Dn,Boo),e(k,Ioo),e(k,Pg),e(Pg,iae),e(iae,Noo),e(Pg,qoo),e(Pg,BR),e(BR,joo),e(Pg,Doo),e(k,Goo),e(k,Gn),e(Gn,dae),e(dae,Ooo),e(Gn,Voo),e(Gn,IR),e(IR,Xoo),e(Gn,zoo),e(Gn,NR),e(NR,Woo),e(Gn,Qoo),e(k,Hoo),e(k,On),e(On,cae),e(cae,Uoo),e(On,Joo),e(On,qR),e(qR,Yoo),e(On,Koo),e(On,jR),e(jR,Zoo),e(On,ero),e(k,oro),e(k,Vn),e(Vn,fae),e(fae,rro),e(Vn,tro),e(Vn,DR),e(DR,aro),e(Vn,nro),e(Vn,GR),e(GR,sro),e(Vn,lro),e(k,iro),e(k,Bg),e(Bg,mae),e(mae,dro),e(Bg,cro),e(Bg,OR),e(OR,fro),e(Bg,mro),e(k,gro),e(k,Xn),e(Xn,gae),e(gae,hro),e(Xn,pro),e(Xn,VR),e(VR,_ro),e(Xn,uro),e(Xn,XR),e(XR,bro),e(Xn,vro),e(k,Fro),e(k,zn),e(zn,hae),e(hae,Tro),e(zn,Mro),e(zn,zR),e(zR,Ero),e(zn,Cro),e(zn,WR),e(WR,wro),e(zn,Aro),e(k,yro),e(k,Wn),e(Wn,pae),e(pae,Lro),e(Wn,xro),e(Wn,QR),e(QR,$ro),e(Wn,kro),e(Wn,HR),e(HR,Sro),e(Wn,Rro),e(k,Pro),e(k,Qn),e(Qn,_ae),e(_ae,Bro),e(Qn,Iro),e(Qn,UR),e(UR,Nro),e(Qn,qro),e(Qn,JR),e(JR,jro),e(Qn,Dro),e(k,Gro),e(k,Hn),e(Hn,uae),e(uae,Oro),e(Hn,Vro),e(Hn,YR),e(YR,Xro),e(Hn,zro),e(Hn,KR),e(KR,Wro),e(Hn,Qro),e(k,Hro),e(k,Un),e(Un,bae),e(bae,Uro),e(Un,Jro),e(Un,ZR),e(ZR,Yro),e(Un,Kro),e(Un,eP),e(eP,Zro),e(Un,eto),e(k,oto),e(k,Ig),e(Ig,vae),e(vae,rto),e(Ig,tto),e(Ig,oP),e(oP,ato),e(Ig,nto),e(k,sto),e(k,Jn),e(Jn,Fae),e(Fae,lto),e(Jn,ito),e(Jn,rP),e(rP,dto),e(Jn,cto),e(Jn,tP),e(tP,fto),e(Jn,mto),e(k,gto),e(k,Ng),e(Ng,Tae),e(Tae,hto),e(Ng,pto),e(Ng,aP),e(aP,_to),e(Ng,uto),e(k,bto),e(k,Yn),e(Yn,Mae),e(Mae,vto),e(Yn,Fto),e(Yn,nP),e(nP,Tto),e(Yn,Mto),e(Yn,sP),e(sP,Eto),e(Yn,Cto),e(k,wto),e(k,Kn),e(Kn,Eae),e(Eae,Ato),e(Kn,yto),e(Kn,lP),e(lP,Lto),e(Kn,xto),e(Kn,iP),e(iP,$to),e(Kn,kto),e(k,Sto),e(k,Zn),e(Zn,Cae),e(Cae,Rto),e(Zn,Pto),e(Zn,dP),e(dP,Bto),e(Zn,Ito),e(Zn,cP),e(cP,Nto),e(Zn,qto),e(k,jto),e(k,qg),e(qg,wae),e(wae,Dto),e(qg,Gto),e(qg,fP),e(fP,Oto),e(qg,Vto),e(k,Xto),e(k,es),e(es,Aae),e(Aae,zto),e(es,Wto),e(es,mP),e(mP,Qto),e(es,Hto),e(es,gP),e(gP,Uto),e(es,Jto),e(k,Yto),e(k,os),e(os,yae),e(yae,Kto),e(os,Zto),e(os,hP),e(hP,eao),e(os,oao),e(os,pP),e(pP,rao),e(os,tao),e(k,aao),e(k,jg),e(jg,Lae),e(Lae,nao),e(jg,sao),e(jg,_P),e(_P,lao),e(jg,iao),e(k,dao),e(k,rs),e(rs,xae),e(xae,cao),e(rs,fao),e(rs,uP),e(uP,mao),e(rs,gao),e(rs,bP),e(bP,hao),e(rs,pao),e(k,_ao),e(k,ts),e(ts,$ae),e($ae,uao),e(ts,bao),e(ts,vP),e(vP,vao),e(ts,Fao),e(ts,FP),e(FP,Tao),e(ts,Mao),e(k,Eao),e(k,as),e(as,kae),e(kae,Cao),e(as,wao),e(as,TP),e(TP,Aao),e(as,yao),e(as,MP),e(MP,Lao),e(as,xao),e(k,$ao),e(k,ns),e(ns,Sae),e(Sae,kao),e(ns,Sao),e(ns,EP),e(EP,Rao),e(ns,Pao),e(ns,CP),e(CP,Bao),e(ns,Iao),e(k,Nao),e(k,ss),e(ss,Rae),e(Rae,qao),e(ss,jao),e(ss,wP),e(wP,Dao),e(ss,Gao),e(ss,AP),e(AP,Oao),e(ss,Vao),e(k,Xao),e(k,ls),e(ls,Pae),e(Pae,zao),e(ls,Wao),e(ls,yP),e(yP,Qao),e(ls,Hao),e(ls,LP),e(LP,Uao),e(ls,Jao),e(k,Yao),e(k,is),e(is,Bae),e(Bae,Kao),e(is,Zao),e(is,xP),e(xP,eno),e(is,ono),e(is,$P),e($P,rno),e(is,tno),e(k,ano),e(k,Dg),e(Dg,Iae),e(Iae,nno),e(Dg,sno),e(Dg,kP),e(kP,lno),e(Dg,ino),e(k,dno),e(k,ds),e(ds,Nae),e(Nae,cno),e(ds,fno),e(ds,SP),e(SP,mno),e(ds,gno),e(ds,RP),e(RP,hno),e(ds,pno),e(k,_no),e(k,Gg),e(Gg,qae),e(qae,uno),e(Gg,bno),e(Gg,PP),e(PP,vno),e(Gg,Fno),e(k,Tno),e(k,Og),e(Og,jae),e(jae,Mno),e(Og,Eno),e(Og,BP),e(BP,Cno),e(Og,wno),e(k,Ano),e(k,cs),e(cs,Dae),e(Dae,yno),e(cs,Lno),e(cs,IP),e(IP,xno),e(cs,$no),e(cs,NP),e(NP,kno),e(cs,Sno),e(k,Rno),e(k,fs),e(fs,Gae),e(Gae,Pno),e(fs,Bno),e(fs,qP),e(qP,Ino),e(fs,Nno),e(fs,jP),e(jP,qno),e(fs,jno),e(k,Dno),e(k,ms),e(ms,Oae),e(Oae,Gno),e(ms,Ono),e(ms,DP),e(DP,Vno),e(ms,Xno),e(ms,GP),e(GP,zno),e(ms,Wno),e(k,Qno),e(k,Vg),e(Vg,Vae),e(Vae,Hno),e(Vg,Uno),e(Vg,OP),e(OP,Jno),e(Vg,Yno),e(k,Kno),e(k,gs),e(gs,Xae),e(Xae,Zno),e(gs,eso),e(gs,VP),e(VP,oso),e(gs,rso),e(gs,XP),e(XP,tso),e(gs,aso),e(k,nso),e(k,hs),e(hs,zae),e(zae,sso),e(hs,lso),e(hs,zP),e(zP,iso),e(hs,dso),e(hs,WP),e(WP,cso),e(hs,fso),e(k,mso),e(k,ps),e(ps,Wae),e(Wae,gso),e(ps,hso),e(ps,QP),e(QP,pso),e(ps,_so),e(ps,HP),e(HP,uso),e(ps,bso),e(k,vso),e(k,_s),e(_s,Qae),e(Qae,Fso),e(_s,Tso),e(_s,UP),e(UP,Mso),e(_s,Eso),e(_s,JP),e(JP,Cso),e(_s,wso),e(k,Aso),e(k,us),e(us,Hae),e(Hae,yso),e(us,Lso),e(us,YP),e(YP,xso),e(us,$so),e(us,KP),e(KP,kso),e(us,Sso),e(k,Rso),e(k,Xg),e(Xg,Uae),e(Uae,Pso),e(Xg,Bso),e(Xg,ZP),e(ZP,Iso),e(Xg,Nso),e(k,qso),e(k,bs),e(bs,Jae),e(Jae,jso),e(bs,Dso),e(bs,eB),e(eB,Gso),e(bs,Oso),e(bs,oB),e(oB,Vso),e(bs,Xso),e(k,zso),e(k,zg),e(zg,Yae),e(Yae,Wso),e(zg,Qso),e(zg,rB),e(rB,Hso),e(zg,Uso),e(k,Jso),e(k,Wg),e(Wg,Kae),e(Kae,Yso),e(Wg,Kso),e(Wg,tB),e(tB,Zso),e(Wg,elo),e(k,olo),e(k,Qg),e(Qg,Zae),e(Zae,rlo),e(Qg,tlo),e(Qg,aB),e(aB,alo),e(Qg,nlo),e(k,slo),e(k,Hg),e(Hg,ene),e(ene,llo),e(Hg,ilo),e(Hg,nB),e(nB,dlo),e(Hg,clo),e(k,flo),e(k,vs),e(vs,one),e(one,mlo),e(vs,glo),e(vs,sB),e(sB,hlo),e(vs,plo),e(vs,lB),e(lB,_lo),e(vs,ulo),e(k,blo),e(k,Ug),e(Ug,rne),e(rne,vlo),e(Ug,Flo),e(Ug,iB),e(iB,Tlo),e(Ug,Mlo),e(k,Elo),e(k,Fs),e(Fs,tne),e(tne,Clo),e(Fs,wlo),e(Fs,dB),e(dB,Alo),e(Fs,ylo),e(Fs,cB),e(cB,Llo),e(Fs,xlo),e(k,$lo),e(k,Ts),e(Ts,ane),e(ane,klo),e(Ts,Slo),e(Ts,fB),e(fB,Rlo),e(Ts,Plo),e(Ts,mB),e(mB,Blo),e(Ts,Ilo),e(k,Nlo),e(k,Ms),e(Ms,nne),e(nne,qlo),e(Ms,jlo),e(Ms,gB),e(gB,Dlo),e(Ms,Glo),e(Ms,hB),e(hB,Olo),e(Ms,Vlo),e(k,Xlo),e(k,Es),e(Es,sne),e(sne,zlo),e(Es,Wlo),e(Es,pB),e(pB,Qlo),e(Es,Hlo),e(Es,_B),e(_B,Ulo),e(Es,Jlo),e(k,Ylo),e(k,Cs),e(Cs,lne),e(lne,Klo),e(Cs,Zlo),e(Cs,uB),e(uB,eio),e(Cs,oio),e(Cs,bB),e(bB,rio),e(Cs,tio),e(k,aio),e(k,ws),e(ws,ine),e(ine,nio),e(ws,sio),e(ws,vB),e(vB,lio),e(ws,iio),e(ws,FB),e(FB,dio),e(ws,cio),e(k,fio),e(k,Jg),e(Jg,dne),e(dne,mio),e(Jg,gio),e(Jg,TB),e(TB,hio),e(Jg,pio),e(k,_io),e(k,Yg),e(Yg,cne),e(cne,uio),e(Yg,bio),e(Yg,MB),e(MB,vio),e(Yg,Fio),e(k,Tio),e(k,As),e(As,fne),e(fne,Mio),e(As,Eio),e(As,EB),e(EB,Cio),e(As,wio),e(As,CB),e(CB,Aio),e(As,yio),e(k,Lio),e(k,ys),e(ys,mne),e(mne,xio),e(ys,$io),e(ys,wB),e(wB,kio),e(ys,Sio),e(ys,AB),e(AB,Rio),e(ys,Pio),e(k,Bio),e(k,Ls),e(Ls,gne),e(gne,Iio),e(Ls,Nio),e(Ls,yB),e(yB,qio),e(Ls,jio),e(Ls,LB),e(LB,Dio),e(Ls,Gio),e(k,Oio),e(k,Kg),e(Kg,hne),e(hne,Vio),e(Kg,Xio),e(Kg,xB),e(xB,zio),e(Kg,Wio),e(k,Qio),e(k,Zg),e(Zg,pne),e(pne,Hio),e(Zg,Uio),e(Zg,$B),e($B,Jio),e(Zg,Yio),e(k,Kio),e(k,eh),e(eh,_ne),e(_ne,Zio),e(eh,edo),e(eh,kB),e(kB,odo),e(eh,rdo),e(k,tdo),e(k,xs),e(xs,une),e(une,ado),e(xs,ndo),e(xs,SB),e(SB,sdo),e(xs,ldo),e(xs,RB),e(RB,ido),e(xs,ddo),e(k,cdo),e(k,oh),e(oh,bne),e(bne,fdo),e(oh,mdo),e(oh,PB),e(PB,gdo),e(oh,hdo),e(k,pdo),e(k,rh),e(rh,vne),e(vne,_do),e(rh,udo),e(rh,BB),e(BB,bdo),e(rh,vdo),e(k,Fdo),e(k,th),e(th,Fne),e(Fne,Tdo),e(th,Mdo),e(th,IB),e(IB,Edo),e(th,Cdo),e(k,wdo),e(k,$s),e($s,Tne),e(Tne,Ado),e($s,ydo),e($s,NB),e(NB,Ldo),e($s,xdo),e($s,qB),e(qB,$do),e($s,kdo),e(k,Sdo),e(k,ah),e(ah,Mne),e(Mne,Rdo),e(ah,Pdo),e(ah,jB),e(jB,Bdo),e(ah,Ido),e(k,Ndo),e(k,nh),e(nh,Ene),e(Ene,qdo),e(nh,jdo),e(nh,DB),e(DB,Ddo),e(nh,Gdo),e(k,Odo),e(k,ks),e(ks,Cne),e(Cne,Vdo),e(ks,Xdo),e(ks,GB),e(GB,zdo),e(ks,Wdo),e(ks,OB),e(OB,Qdo),e(ks,Hdo),e(k,Udo),e(k,Ss),e(Ss,wne),e(wne,Jdo),e(Ss,Ydo),e(Ss,VB),e(VB,Kdo),e(Ss,Zdo),e(Ss,XB),e(XB,eco),e(Ss,oco),e(k,rco),e(k,Rs),e(Rs,Ane),e(Ane,tco),e(Rs,aco),e(Rs,zB),e(zB,nco),e(Rs,sco),e(Rs,WB),e(WB,lco),e(Rs,ico),e(k,dco),e(k,Ps),e(Ps,yne),e(yne,cco),e(Ps,fco),e(Ps,QB),e(QB,mco),e(Ps,gco),e(Ps,HB),e(HB,hco),e(Ps,pco),e(Cr,_co),M(sh,Cr,null),e(wo,uco),e(wo,lh),M(UA,lh,null),e(lh,bco),e(lh,Lne),e(Lne,vco),b(f,zqe,u),b(f,Ci,u),e(Ci,ih),e(ih,xne),M(JA,xne,null),e(Ci,Fco),e(Ci,$ne),e($ne,Tco),b(f,Wqe,u),b(f,Ao,u),M(YA,Ao,null),e(Ao,Mco),e(Ao,KA),e(KA,Eco),e(KA,UB),e(UB,Cco),e(KA,wco),e(Ao,Aco),e(Ao,ZA),e(ZA,yco),e(ZA,kne),e(kne,Lco),e(ZA,xco),e(Ao,$co),e(Ao,He),M(ey,He,null),e(He,kco),e(He,Sne),e(Sne,Sco),e(He,Rco),e(He,ya),e(ya,Pco),e(ya,Rne),e(Rne,Bco),e(ya,Ico),e(ya,Pne),e(Pne,Nco),e(ya,qco),e(ya,Bne),e(Bne,jco),e(ya,Dco),e(He,Gco),e(He,Y),e(Y,dh),e(dh,Ine),e(Ine,Oco),e(dh,Vco),e(dh,JB),e(JB,Xco),e(dh,zco),e(Y,Wco),e(Y,ch),e(ch,Nne),e(Nne,Qco),e(ch,Hco),e(ch,YB),e(YB,Uco),e(ch,Jco),e(Y,Yco),e(Y,fh),e(fh,qne),e(qne,Kco),e(fh,Zco),e(fh,KB),e(KB,efo),e(fh,ofo),e(Y,rfo),e(Y,mh),e(mh,jne),e(jne,tfo),e(mh,afo),e(mh,ZB),e(ZB,nfo),e(mh,sfo),e(Y,lfo),e(Y,gh),e(gh,Dne),e(Dne,ifo),e(gh,dfo),e(gh,eI),e(eI,cfo),e(gh,ffo),e(Y,mfo),e(Y,hh),e(hh,Gne),e(Gne,gfo),e(hh,hfo),e(hh,oI),e(oI,pfo),e(hh,_fo),e(Y,ufo),e(Y,ph),e(ph,One),e(One,bfo),e(ph,vfo),e(ph,rI),e(rI,Ffo),e(ph,Tfo),e(Y,Mfo),e(Y,_h),e(_h,Vne),e(Vne,Efo),e(_h,Cfo),e(_h,tI),e(tI,wfo),e(_h,Afo),e(Y,yfo),e(Y,uh),e(uh,Xne),e(Xne,Lfo),e(uh,xfo),e(uh,aI),e(aI,$fo),e(uh,kfo),e(Y,Sfo),e(Y,bh),e(bh,zne),e(zne,Rfo),e(bh,Pfo),e(bh,nI),e(nI,Bfo),e(bh,Ifo),e(Y,Nfo),e(Y,vh),e(vh,Wne),e(Wne,qfo),e(vh,jfo),e(vh,sI),e(sI,Dfo),e(vh,Gfo),e(Y,Ofo),e(Y,Fh),e(Fh,Qne),e(Qne,Vfo),e(Fh,Xfo),e(Fh,lI),e(lI,zfo),e(Fh,Wfo),e(Y,Qfo),e(Y,Th),e(Th,Hne),e(Hne,Hfo),e(Th,Ufo),e(Th,iI),e(iI,Jfo),e(Th,Yfo),e(Y,Kfo),e(Y,Mh),e(Mh,Une),e(Une,Zfo),e(Mh,emo),e(Mh,dI),e(dI,omo),e(Mh,rmo),e(Y,tmo),e(Y,Eh),e(Eh,Jne),e(Jne,amo),e(Eh,nmo),e(Eh,cI),e(cI,smo),e(Eh,lmo),e(Y,imo),e(Y,Ch),e(Ch,Yne),e(Yne,dmo),e(Ch,cmo),e(Ch,fI),e(fI,fmo),e(Ch,mmo),e(Y,gmo),e(Y,wh),e(wh,Kne),e(Kne,hmo),e(wh,pmo),e(wh,mI),e(mI,_mo),e(wh,umo),e(Y,bmo),e(Y,Ah),e(Ah,Zne),e(Zne,vmo),e(Ah,Fmo),e(Ah,gI),e(gI,Tmo),e(Ah,Mmo),e(Y,Emo),e(Y,yh),e(yh,ese),e(ese,Cmo),e(yh,wmo),e(yh,hI),e(hI,Amo),e(yh,ymo),e(Y,Lmo),e(Y,Lh),e(Lh,ose),e(ose,xmo),e(Lh,$mo),e(Lh,pI),e(pI,kmo),e(Lh,Smo),e(Y,Rmo),e(Y,xh),e(xh,rse),e(rse,Pmo),e(xh,Bmo),e(xh,_I),e(_I,Imo),e(xh,Nmo),e(Y,qmo),e(Y,$h),e($h,tse),e(tse,jmo),e($h,Dmo),e($h,uI),e(uI,Gmo),e($h,Omo),e(Y,Vmo),e(Y,kh),e(kh,ase),e(ase,Xmo),e(kh,zmo),e(kh,bI),e(bI,Wmo),e(kh,Qmo),e(Y,Hmo),e(Y,Sh),e(Sh,nse),e(nse,Umo),e(Sh,Jmo),e(Sh,vI),e(vI,Ymo),e(Sh,Kmo),e(Y,Zmo),e(Y,Rh),e(Rh,sse),e(sse,ego),e(Rh,ogo),e(Rh,FI),e(FI,rgo),e(Rh,tgo),e(Y,ago),e(Y,Ph),e(Ph,lse),e(lse,ngo),e(Ph,sgo),e(Ph,TI),e(TI,lgo),e(Ph,igo),e(Y,dgo),e(Y,Bh),e(Bh,ise),e(ise,cgo),e(Bh,fgo),e(Bh,MI),e(MI,mgo),e(Bh,ggo),e(Y,hgo),e(Y,Ih),e(Ih,dse),e(dse,pgo),e(Ih,_go),e(Ih,EI),e(EI,ugo),e(Ih,bgo),e(Y,vgo),e(Y,Nh),e(Nh,cse),e(cse,Fgo),e(Nh,Tgo),e(Nh,CI),e(CI,Mgo),e(Nh,Ego),e(Y,Cgo),e(Y,qh),e(qh,fse),e(fse,wgo),e(qh,Ago),e(qh,wI),e(wI,ygo),e(qh,Lgo),e(He,xgo),M(jh,He,null),e(He,$go),M(Dh,He,null),e(Ao,kgo),e(Ao,Gh),M(oy,Gh,null),e(Gh,Sgo),e(Gh,mse),e(mse,Rgo),b(f,Qqe,u),b(f,wi,u),e(wi,Oh),e(Oh,gse),M(ry,gse,null),e(wi,Pgo),e(wi,hse),e(hse,Bgo),b(f,Hqe,u),b(f,yo,u),M(ty,yo,null),e(yo,Igo),e(yo,ay),e(ay,Ngo),e(ay,AI),e(AI,qgo),e(ay,jgo),e(yo,Dgo),e(yo,ny),e(ny,Ggo),e(ny,pse),e(pse,Ogo),e(ny,Vgo),e(yo,Xgo),e(yo,Ue),M(sy,Ue,null),e(Ue,zgo),e(Ue,_se),e(_se,Wgo),e(Ue,Qgo),e(Ue,Ai),e(Ai,Hgo),e(Ai,use),e(use,Ugo),e(Ai,Jgo),e(Ai,bse),e(bse,Ygo),e(Ai,Kgo),e(Ue,Zgo),e(Ue,he),e(he,Vh),e(Vh,vse),e(vse,eho),e(Vh,oho),e(Vh,yI),e(yI,rho),e(Vh,tho),e(he,aho),e(he,Xh),e(Xh,Fse),e(Fse,nho),e(Xh,sho),e(Xh,Tse),e(Tse,lho),e(Xh,iho),e(he,dho),e(he,zh),e(zh,Mse),e(Mse,cho),e(zh,fho),e(zh,LI),e(LI,mho),e(zh,gho),e(he,hho),e(he,Wh),e(Wh,Ese),e(Ese,pho),e(Wh,_ho),e(Wh,xI),e(xI,uho),e(Wh,bho),e(he,vho),e(he,Qh),e(Qh,Cse),e(Cse,Fho),e(Qh,Tho),e(Qh,$I),e($I,Mho),e(Qh,Eho),e(he,Cho),e(he,Hh),e(Hh,wse),e(wse,who),e(Hh,Aho),e(Hh,kI),e(kI,yho),e(Hh,Lho),e(he,xho),e(he,Uh),e(Uh,Ase),e(Ase,$ho),e(Uh,kho),e(Uh,SI),e(SI,Sho),e(Uh,Rho),e(he,Pho),e(he,Jh),e(Jh,yse),e(yse,Bho),e(Jh,Iho),e(Jh,RI),e(RI,Nho),e(Jh,qho),e(he,jho),e(he,Yh),e(Yh,Lse),e(Lse,Dho),e(Yh,Gho),e(Yh,PI),e(PI,Oho),e(Yh,Vho),e(he,Xho),e(he,Kh),e(Kh,xse),e(xse,zho),e(Kh,Who),e(Kh,BI),e(BI,Qho),e(Kh,Hho),e(he,Uho),e(he,Zh),e(Zh,$se),e($se,Jho),e(Zh,Yho),e(Zh,II),e(II,Kho),e(Zh,Zho),e(he,epo),e(he,ep),e(ep,kse),e(kse,opo),e(ep,rpo),e(ep,NI),e(NI,tpo),e(ep,apo),e(he,npo),e(he,op),e(op,Sse),e(Sse,spo),e(op,lpo),e(op,qI),e(qI,ipo),e(op,dpo),e(he,cpo),e(he,rp),e(rp,Rse),e(Rse,fpo),e(rp,mpo),e(rp,jI),e(jI,gpo),e(rp,hpo),e(he,ppo),e(he,tp),e(tp,Pse),e(Pse,_po),e(tp,upo),e(tp,DI),e(DI,bpo),e(tp,vpo),e(he,Fpo),e(he,ap),e(ap,Bse),e(Bse,Tpo),e(ap,Mpo),e(ap,GI),e(GI,Epo),e(ap,Cpo),e(he,wpo),e(he,np),e(np,Ise),e(Ise,Apo),e(np,ypo),e(np,OI),e(OI,Lpo),e(np,xpo),e(Ue,$po),M(sp,Ue,null),e(Ue,kpo),M(lp,Ue,null),e(yo,Spo),e(yo,ip),M(ly,ip,null),e(ip,Rpo),e(ip,Nse),e(Nse,Ppo),b(f,Uqe,u),b(f,yi,u),e(yi,dp),e(dp,qse),M(iy,qse,null),e(yi,Bpo),e(yi,jse),e(jse,Ipo),b(f,Jqe,u),b(f,Lo,u),M(dy,Lo,null),e(Lo,Npo),e(Lo,Li),e(Li,qpo),e(Li,VI),e(VI,jpo),e(Li,Dpo),e(Li,XI),e(XI,Gpo),e(Li,Opo),e(Lo,Vpo),e(Lo,cy),e(cy,Xpo),e(cy,Dse),e(Dse,zpo),e(cy,Wpo),e(Lo,Qpo),e(Lo,tt),M(fy,tt,null),e(tt,Hpo),e(tt,Gse),e(Gse,Upo),e(tt,Jpo),e(tt,xi),e(xi,Ypo),e(xi,Ose),e(Ose,Kpo),e(xi,Zpo),e(xi,zI),e(zI,e_o),e(xi,o_o),e(tt,r_o),M(cp,tt,null),e(Lo,t_o),e(Lo,Je),M(my,Je,null),e(Je,a_o),e(Je,Vse),e(Vse,n_o),e(Je,s_o),e(Je,La),e(La,l_o),e(La,Xse),e(Xse,i_o),e(La,d_o),e(La,zse),e(zse,c_o),e(La,f_o),e(La,Wse),e(Wse,m_o),e(La,g_o),e(Je,h_o),e(Je,x),e(x,fp),e(fp,Qse),e(Qse,p_o),e(fp,__o),e(fp,WI),e(WI,u_o),e(fp,b_o),e(x,v_o),e(x,mp),e(mp,Hse),e(Hse,F_o),e(mp,T_o),e(mp,QI),e(QI,M_o),e(mp,E_o),e(x,C_o),e(x,gp),e(gp,Use),e(Use,w_o),e(gp,A_o),e(gp,HI),e(HI,y_o),e(gp,L_o),e(x,x_o),e(x,hp),e(hp,Jse),e(Jse,$_o),e(hp,k_o),e(hp,UI),e(UI,S_o),e(hp,R_o),e(x,P_o),e(x,pp),e(pp,Yse),e(Yse,B_o),e(pp,I_o),e(pp,JI),e(JI,N_o),e(pp,q_o),e(x,j_o),e(x,_p),e(_p,Kse),e(Kse,D_o),e(_p,G_o),e(_p,YI),e(YI,O_o),e(_p,V_o),e(x,X_o),e(x,up),e(up,Zse),e(Zse,z_o),e(up,W_o),e(up,KI),e(KI,Q_o),e(up,H_o),e(x,U_o),e(x,bp),e(bp,ele),e(ele,J_o),e(bp,Y_o),e(bp,ZI),e(ZI,K_o),e(bp,Z_o),e(x,euo),e(x,vp),e(vp,ole),e(ole,ouo),e(vp,ruo),e(vp,eN),e(eN,tuo),e(vp,auo),e(x,nuo),e(x,Fp),e(Fp,rle),e(rle,suo),e(Fp,luo),e(Fp,oN),e(oN,iuo),e(Fp,duo),e(x,cuo),e(x,Tp),e(Tp,tle),e(tle,fuo),e(Tp,muo),e(Tp,rN),e(rN,guo),e(Tp,huo),e(x,puo),e(x,Mp),e(Mp,ale),e(ale,_uo),e(Mp,uuo),e(Mp,tN),e(tN,buo),e(Mp,vuo),e(x,Fuo),e(x,Ep),e(Ep,nle),e(nle,Tuo),e(Ep,Muo),e(Ep,aN),e(aN,Euo),e(Ep,Cuo),e(x,wuo),e(x,Cp),e(Cp,sle),e(sle,Auo),e(Cp,yuo),e(Cp,nN),e(nN,Luo),e(Cp,xuo),e(x,$uo),e(x,wp),e(wp,lle),e(lle,kuo),e(wp,Suo),e(wp,sN),e(sN,Ruo),e(wp,Puo),e(x,Buo),e(x,Ap),e(Ap,ile),e(ile,Iuo),e(Ap,Nuo),e(Ap,lN),e(lN,quo),e(Ap,juo),e(x,Duo),e(x,yp),e(yp,dle),e(dle,Guo),e(yp,Ouo),e(yp,iN),e(iN,Vuo),e(yp,Xuo),e(x,zuo),e(x,Lp),e(Lp,cle),e(cle,Wuo),e(Lp,Quo),e(Lp,dN),e(dN,Huo),e(Lp,Uuo),e(x,Juo),e(x,xp),e(xp,fle),e(fle,Yuo),e(xp,Kuo),e(xp,cN),e(cN,Zuo),e(xp,e2o),e(x,o2o),e(x,$p),e($p,mle),e(mle,r2o),e($p,t2o),e($p,fN),e(fN,a2o),e($p,n2o),e(x,s2o),e(x,kp),e(kp,gle),e(gle,l2o),e(kp,i2o),e(kp,mN),e(mN,d2o),e(kp,c2o),e(x,f2o),e(x,Sp),e(Sp,hle),e(hle,m2o),e(Sp,g2o),e(Sp,gN),e(gN,h2o),e(Sp,p2o),e(x,_2o),e(x,Rp),e(Rp,ple),e(ple,u2o),e(Rp,b2o),e(Rp,hN),e(hN,v2o),e(Rp,F2o),e(x,T2o),e(x,Pp),e(Pp,_le),e(_le,M2o),e(Pp,E2o),e(Pp,pN),e(pN,C2o),e(Pp,w2o),e(x,A2o),e(x,Bp),e(Bp,ule),e(ule,y2o),e(Bp,L2o),e(Bp,_N),e(_N,x2o),e(Bp,$2o),e(x,k2o),e(x,Ip),e(Ip,ble),e(ble,S2o),e(Ip,R2o),e(Ip,uN),e(uN,P2o),e(Ip,B2o),e(x,I2o),e(x,Np),e(Np,vle),e(vle,N2o),e(Np,q2o),e(Np,bN),e(bN,j2o),e(Np,D2o),e(x,G2o),e(x,qp),e(qp,Fle),e(Fle,O2o),e(qp,V2o),e(qp,vN),e(vN,X2o),e(qp,z2o),e(x,W2o),e(x,jp),e(jp,Tle),e(Tle,Q2o),e(jp,H2o),e(jp,FN),e(FN,U2o),e(jp,J2o),e(x,Y2o),e(x,Dp),e(Dp,Mle),e(Mle,K2o),e(Dp,Z2o),e(Dp,TN),e(TN,e1o),e(Dp,o1o),e(x,r1o),e(x,Gp),e(Gp,Ele),e(Ele,t1o),e(Gp,a1o),e(Gp,MN),e(MN,n1o),e(Gp,s1o),e(x,l1o),e(x,Op),e(Op,Cle),e(Cle,i1o),e(Op,d1o),e(Op,EN),e(EN,c1o),e(Op,f1o),e(x,m1o),e(x,Bs),e(Bs,wle),e(wle,g1o),e(Bs,h1o),e(Bs,CN),e(CN,p1o),e(Bs,_1o),e(Bs,wN),e(wN,u1o),e(Bs,b1o),e(x,v1o),e(x,Vp),e(Vp,Ale),e(Ale,F1o),e(Vp,T1o),e(Vp,AN),e(AN,M1o),e(Vp,E1o),e(x,C1o),e(x,Xp),e(Xp,yle),e(yle,w1o),e(Xp,A1o),e(Xp,yN),e(yN,y1o),e(Xp,L1o),e(x,x1o),e(x,zp),e(zp,Lle),e(Lle,$1o),e(zp,k1o),e(zp,LN),e(LN,S1o),e(zp,R1o),e(x,P1o),e(x,Wp),e(Wp,xle),e(xle,B1o),e(Wp,I1o),e(Wp,xN),e(xN,N1o),e(Wp,q1o),e(x,j1o),e(x,Qp),e(Qp,$le),e($le,D1o),e(Qp,G1o),e(Qp,$N),e($N,O1o),e(Qp,V1o),e(x,X1o),e(x,Hp),e(Hp,kle),e(kle,z1o),e(Hp,W1o),e(Hp,kN),e(kN,Q1o),e(Hp,H1o),e(x,U1o),e(x,Up),e(Up,Sle),e(Sle,J1o),e(Up,Y1o),e(Up,SN),e(SN,K1o),e(Up,Z1o),e(x,ebo),e(x,Jp),e(Jp,Rle),e(Rle,obo),e(Jp,rbo),e(Jp,RN),e(RN,tbo),e(Jp,abo),e(x,nbo),e(x,Yp),e(Yp,Ple),e(Ple,sbo),e(Yp,lbo),e(Yp,PN),e(PN,ibo),e(Yp,dbo),e(x,cbo),e(x,Kp),e(Kp,Ble),e(Ble,fbo),e(Kp,mbo),e(Kp,BN),e(BN,gbo),e(Kp,hbo),e(x,pbo),e(x,Zp),e(Zp,Ile),e(Ile,_bo),e(Zp,ubo),e(Zp,IN),e(IN,bbo),e(Zp,vbo),e(x,Fbo),e(x,e_),e(e_,Nle),e(Nle,Tbo),e(e_,Mbo),e(e_,NN),e(NN,Ebo),e(e_,Cbo),e(x,wbo),e(x,o_),e(o_,qle),e(qle,Abo),e(o_,ybo),e(o_,qN),e(qN,Lbo),e(o_,xbo),e(x,$bo),e(x,r_),e(r_,jle),e(jle,kbo),e(r_,Sbo),e(r_,jN),e(jN,Rbo),e(r_,Pbo),e(x,Bbo),e(x,t_),e(t_,Dle),e(Dle,Ibo),e(t_,Nbo),e(t_,DN),e(DN,qbo),e(t_,jbo),e(x,Dbo),e(x,a_),e(a_,Gle),e(Gle,Gbo),e(a_,Obo),e(a_,GN),e(GN,Vbo),e(a_,Xbo),e(x,zbo),e(x,n_),e(n_,Ole),e(Ole,Wbo),e(n_,Qbo),e(n_,ON),e(ON,Hbo),e(n_,Ubo),e(x,Jbo),e(x,s_),e(s_,Vle),e(Vle,Ybo),e(s_,Kbo),e(s_,VN),e(VN,Zbo),e(s_,e4o),e(x,o4o),e(x,l_),e(l_,Xle),e(Xle,r4o),e(l_,t4o),e(l_,XN),e(XN,a4o),e(l_,n4o),e(x,s4o),e(x,i_),e(i_,zle),e(zle,l4o),e(i_,i4o),e(i_,zN),e(zN,d4o),e(i_,c4o),e(x,f4o),e(x,d_),e(d_,Wle),e(Wle,m4o),e(d_,g4o),e(d_,WN),e(WN,h4o),e(d_,p4o),e(x,_4o),e(x,c_),e(c_,Qle),e(Qle,u4o),e(c_,b4o),e(c_,QN),e(QN,v4o),e(c_,F4o),e(x,T4o),e(x,f_),e(f_,Hle),e(Hle,M4o),e(f_,E4o),e(f_,HN),e(HN,C4o),e(f_,w4o),e(x,A4o),e(x,m_),e(m_,Ule),e(Ule,y4o),e(m_,L4o),e(m_,UN),e(UN,x4o),e(m_,$4o),e(x,k4o),e(x,g_),e(g_,Jle),e(Jle,S4o),e(g_,R4o),e(g_,JN),e(JN,P4o),e(g_,B4o),e(x,I4o),e(x,h_),e(h_,Yle),e(Yle,N4o),e(h_,q4o),e(h_,YN),e(YN,j4o),e(h_,D4o),e(x,G4o),e(x,p_),e(p_,Kle),e(Kle,O4o),e(p_,V4o),e(p_,KN),e(KN,X4o),e(p_,z4o),e(x,W4o),e(x,__),e(__,Zle),e(Zle,Q4o),e(__,H4o),e(__,ZN),e(ZN,U4o),e(__,J4o),e(x,Y4o),e(x,u_),e(u_,eie),e(eie,K4o),e(u_,Z4o),e(u_,eq),e(eq,evo),e(u_,ovo),e(x,rvo),e(x,b_),e(b_,oie),e(oie,tvo),e(b_,avo),e(b_,oq),e(oq,nvo),e(b_,svo),e(x,lvo),e(x,v_),e(v_,rie),e(rie,ivo),e(v_,dvo),e(v_,rq),e(rq,cvo),e(v_,fvo),e(x,mvo),e(x,F_),e(F_,tie),e(tie,gvo),e(F_,hvo),e(F_,tq),e(tq,pvo),e(F_,_vo),e(x,uvo),e(x,T_),e(T_,aie),e(aie,bvo),e(T_,vvo),e(T_,aq),e(aq,Fvo),e(T_,Tvo),e(x,Mvo),e(x,M_),e(M_,nie),e(nie,Evo),e(M_,Cvo),e(M_,nq),e(nq,wvo),e(M_,Avo),e(x,yvo),e(x,E_),e(E_,sie),e(sie,Lvo),e(E_,xvo),e(E_,sq),e(sq,$vo),e(E_,kvo),e(x,Svo),e(x,C_),e(C_,lie),e(lie,Rvo),e(C_,Pvo),e(C_,lq),e(lq,Bvo),e(C_,Ivo),e(x,Nvo),e(x,w_),e(w_,iie),e(iie,qvo),e(w_,jvo),e(w_,iq),e(iq,Dvo),e(w_,Gvo),e(x,Ovo),e(x,A_),e(A_,die),e(die,Vvo),e(A_,Xvo),e(A_,dq),e(dq,zvo),e(A_,Wvo),e(x,Qvo),e(x,y_),e(y_,cie),e(cie,Hvo),e(y_,Uvo),e(y_,cq),e(cq,Jvo),e(y_,Yvo),e(x,Kvo),e(x,L_),e(L_,fie),e(fie,Zvo),e(L_,e5o),e(L_,fq),e(fq,o5o),e(L_,r5o),e(x,t5o),e(x,x_),e(x_,mie),e(mie,a5o),e(x_,n5o),e(x_,mq),e(mq,s5o),e(x_,l5o),e(x,i5o),e(x,$_),e($_,gie),e(gie,d5o),e($_,c5o),e($_,gq),e(gq,f5o),e($_,m5o),e(x,g5o),e(x,k_),e(k_,hie),e(hie,h5o),e(k_,p5o),e(k_,hq),e(hq,_5o),e(k_,u5o),e(x,b5o),e(x,S_),e(S_,pie),e(pie,v5o),e(S_,F5o),e(S_,pq),e(pq,T5o),e(S_,M5o),e(x,E5o),e(x,R_),e(R_,_ie),e(_ie,C5o),e(R_,w5o),e(R_,_q),e(_q,A5o),e(R_,y5o),e(x,L5o),e(x,P_),e(P_,uie),e(uie,x5o),e(P_,$5o),e(P_,uq),e(uq,k5o),e(P_,S5o),e(x,R5o),e(x,B_),e(B_,bie),e(bie,P5o),e(B_,B5o),e(B_,bq),e(bq,I5o),e(B_,N5o),e(x,q5o),e(x,I_),e(I_,vie),e(vie,j5o),e(I_,D5o),e(I_,vq),e(vq,G5o),e(I_,O5o),e(x,V5o),e(x,N_),e(N_,Fie),e(Fie,X5o),e(N_,z5o),e(N_,Fq),e(Fq,W5o),e(N_,Q5o),e(x,H5o),e(x,q_),e(q_,Tie),e(Tie,U5o),e(q_,J5o),e(q_,Tq),e(Tq,Y5o),e(q_,K5o),e(x,Z5o),e(x,j_),e(j_,Mie),e(Mie,eFo),e(j_,oFo),e(j_,Mq),e(Mq,rFo),e(j_,tFo),e(x,aFo),e(x,D_),e(D_,Eie),e(Eie,nFo),e(D_,sFo),e(D_,Eq),e(Eq,lFo),e(D_,iFo),e(x,dFo),e(x,G_),e(G_,Cie),e(Cie,cFo),e(G_,fFo),e(G_,Cq),e(Cq,mFo),e(G_,gFo),e(x,hFo),e(x,O_),e(O_,wie),e(wie,pFo),e(O_,_Fo),e(O_,wq),e(wq,uFo),e(O_,bFo),e(x,vFo),e(x,V_),e(V_,Aie),e(Aie,FFo),e(V_,TFo),e(V_,Aq),e(Aq,MFo),e(V_,EFo),e(x,CFo),e(x,X_),e(X_,yie),e(yie,wFo),e(X_,AFo),e(X_,yq),e(yq,yFo),e(X_,LFo),e(x,xFo),e(x,z_),e(z_,Lie),e(Lie,$Fo),e(z_,kFo),e(z_,Lq),e(Lq,SFo),e(z_,RFo),e(x,PFo),e(x,W_),e(W_,xie),e(xie,BFo),e(W_,IFo),e(W_,xq),e(xq,NFo),e(W_,qFo),e(x,jFo),e(x,Q_),e(Q_,$ie),e($ie,DFo),e(Q_,GFo),e(Q_,$q),e($q,OFo),e(Q_,VFo),e(x,XFo),e(x,H_),e(H_,kie),e(kie,zFo),e(H_,WFo),e(H_,kq),e(kq,QFo),e(H_,HFo),e(x,UFo),e(x,U_),e(U_,Sie),e(Sie,JFo),e(U_,YFo),e(U_,Sq),e(Sq,KFo),e(U_,ZFo),e(x,eTo),e(x,J_),e(J_,Rie),e(Rie,oTo),e(J_,rTo),e(J_,Rq),e(Rq,tTo),e(J_,aTo),e(x,nTo),e(x,Y_),e(Y_,Pie),e(Pie,sTo),e(Y_,lTo),e(Y_,Pq),e(Pq,iTo),e(Y_,dTo),e(x,cTo),e(x,K_),e(K_,Bie),e(Bie,fTo),e(K_,mTo),e(K_,Bq),e(Bq,gTo),e(K_,hTo),e(x,pTo),e(x,Z_),e(Z_,Iie),e(Iie,_To),e(Z_,uTo),e(Z_,Iq),e(Iq,bTo),e(Z_,vTo),e(x,FTo),e(x,eu),e(eu,Nie),e(Nie,TTo),e(eu,MTo),e(eu,Nq),e(Nq,ETo),e(eu,CTo),e(x,wTo),e(x,ou),e(ou,qie),e(qie,ATo),e(ou,yTo),e(ou,qq),e(qq,LTo),e(ou,xTo),e(x,$To),e(x,ru),e(ru,jie),e(jie,kTo),e(ru,STo),e(ru,jq),e(jq,RTo),e(ru,PTo),e(x,BTo),e(x,tu),e(tu,Die),e(Die,ITo),e(tu,NTo),e(tu,Dq),e(Dq,qTo),e(tu,jTo),e(x,DTo),e(x,au),e(au,Gie),e(Gie,GTo),e(au,OTo),e(au,Gq),e(Gq,VTo),e(au,XTo),e(Je,zTo),e(Je,nu),e(nu,WTo),e(nu,Oie),e(Oie,QTo),e(nu,HTo),e(nu,Vie),e(Vie,UTo),e(Je,JTo),M(su,Je,null),b(f,Yqe,u),b(f,$i,u),e($i,lu),e(lu,Xie),M(gy,Xie,null),e($i,YTo),e($i,zie),e(zie,KTo),b(f,Kqe,u),b(f,xo,u),M(hy,xo,null),e(xo,ZTo),e(xo,ki),e(ki,e7o),e(ki,Oq),e(Oq,o7o),e(ki,r7o),e(ki,Vq),e(Vq,t7o),e(ki,a7o),e(xo,n7o),e(xo,py),e(py,s7o),e(py,Wie),e(Wie,l7o),e(py,i7o),e(xo,d7o),e(xo,at),M(_y,at,null),e(at,c7o),e(at,Qie),e(Qie,f7o),e(at,m7o),e(at,Si),e(Si,g7o),e(Si,Hie),e(Hie,h7o),e(Si,p7o),e(Si,Xq),e(Xq,_7o),e(Si,u7o),e(at,b7o),M(iu,at,null),e(xo,v7o),e(xo,Ye),M(uy,Ye,null),e(Ye,F7o),e(Ye,Uie),e(Uie,T7o),e(Ye,M7o),e(Ye,xa),e(xa,E7o),e(xa,Jie),e(Jie,C7o),e(xa,w7o),e(xa,Yie),e(Yie,A7o),e(xa,y7o),e(xa,Kie),e(Kie,L7o),e(xa,x7o),e(Ye,$7o),e(Ye,G),e(G,du),e(du,Zie),e(Zie,k7o),e(du,S7o),e(du,zq),e(zq,R7o),e(du,P7o),e(G,B7o),e(G,cu),e(cu,ede),e(ede,I7o),e(cu,N7o),e(cu,Wq),e(Wq,q7o),e(cu,j7o),e(G,D7o),e(G,fu),e(fu,ode),e(ode,G7o),e(fu,O7o),e(fu,Qq),e(Qq,V7o),e(fu,X7o),e(G,z7o),e(G,mu),e(mu,rde),e(rde,W7o),e(mu,Q7o),e(mu,Hq),e(Hq,H7o),e(mu,U7o),e(G,J7o),e(G,gu),e(gu,tde),e(tde,Y7o),e(gu,K7o),e(gu,Uq),e(Uq,Z7o),e(gu,eMo),e(G,oMo),e(G,hu),e(hu,ade),e(ade,rMo),e(hu,tMo),e(hu,Jq),e(Jq,aMo),e(hu,nMo),e(G,sMo),e(G,pu),e(pu,nde),e(nde,lMo),e(pu,iMo),e(pu,Yq),e(Yq,dMo),e(pu,cMo),e(G,fMo),e(G,_u),e(_u,sde),e(sde,mMo),e(_u,gMo),e(_u,Kq),e(Kq,hMo),e(_u,pMo),e(G,_Mo),e(G,uu),e(uu,lde),e(lde,uMo),e(uu,bMo),e(uu,Zq),e(Zq,vMo),e(uu,FMo),e(G,TMo),e(G,bu),e(bu,ide),e(ide,MMo),e(bu,EMo),e(bu,ej),e(ej,CMo),e(bu,wMo),e(G,AMo),e(G,vu),e(vu,dde),e(dde,yMo),e(vu,LMo),e(vu,oj),e(oj,xMo),e(vu,$Mo),e(G,kMo),e(G,Fu),e(Fu,cde),e(cde,SMo),e(Fu,RMo),e(Fu,rj),e(rj,PMo),e(Fu,BMo),e(G,IMo),e(G,Tu),e(Tu,fde),e(fde,NMo),e(Tu,qMo),e(Tu,tj),e(tj,jMo),e(Tu,DMo),e(G,GMo),e(G,Mu),e(Mu,mde),e(mde,OMo),e(Mu,VMo),e(Mu,aj),e(aj,XMo),e(Mu,zMo),e(G,WMo),e(G,Eu),e(Eu,gde),e(gde,QMo),e(Eu,HMo),e(Eu,nj),e(nj,UMo),e(Eu,JMo),e(G,YMo),e(G,Cu),e(Cu,hde),e(hde,KMo),e(Cu,ZMo),e(Cu,sj),e(sj,eEo),e(Cu,oEo),e(G,rEo),e(G,wu),e(wu,pde),e(pde,tEo),e(wu,aEo),e(wu,lj),e(lj,nEo),e(wu,sEo),e(G,lEo),e(G,Au),e(Au,_de),e(_de,iEo),e(Au,dEo),e(Au,ij),e(ij,cEo),e(Au,fEo),e(G,mEo),e(G,yu),e(yu,ude),e(ude,gEo),e(yu,hEo),e(yu,dj),e(dj,pEo),e(yu,_Eo),e(G,uEo),e(G,Lu),e(Lu,bde),e(bde,bEo),e(Lu,vEo),e(Lu,cj),e(cj,FEo),e(Lu,TEo),e(G,MEo),e(G,xu),e(xu,vde),e(vde,EEo),e(xu,CEo),e(xu,fj),e(fj,wEo),e(xu,AEo),e(G,yEo),e(G,$u),e($u,Fde),e(Fde,LEo),e($u,xEo),e($u,mj),e(mj,$Eo),e($u,kEo),e(G,SEo),e(G,ku),e(ku,Tde),e(Tde,REo),e(ku,PEo),e(ku,gj),e(gj,BEo),e(ku,IEo),e(G,NEo),e(G,Su),e(Su,Mde),e(Mde,qEo),e(Su,jEo),e(Su,hj),e(hj,DEo),e(Su,GEo),e(G,OEo),e(G,Ru),e(Ru,Ede),e(Ede,VEo),e(Ru,XEo),e(Ru,pj),e(pj,zEo),e(Ru,WEo),e(G,QEo),e(G,Pu),e(Pu,Cde),e(Cde,HEo),e(Pu,UEo),e(Pu,_j),e(_j,JEo),e(Pu,YEo),e(G,KEo),e(G,Bu),e(Bu,wde),e(wde,ZEo),e(Bu,eCo),e(Bu,uj),e(uj,oCo),e(Bu,rCo),e(G,tCo),e(G,Iu),e(Iu,Ade),e(Ade,aCo),e(Iu,nCo),e(Iu,bj),e(bj,sCo),e(Iu,lCo),e(G,iCo),e(G,Nu),e(Nu,yde),e(yde,dCo),e(Nu,cCo),e(Nu,vj),e(vj,fCo),e(Nu,mCo),e(G,gCo),e(G,qu),e(qu,Lde),e(Lde,hCo),e(qu,pCo),e(qu,Fj),e(Fj,_Co),e(qu,uCo),e(G,bCo),e(G,ju),e(ju,xde),e(xde,vCo),e(ju,FCo),e(ju,Tj),e(Tj,TCo),e(ju,MCo),e(G,ECo),e(G,Du),e(Du,$de),e($de,CCo),e(Du,wCo),e(Du,Mj),e(Mj,ACo),e(Du,yCo),e(G,LCo),e(G,Gu),e(Gu,kde),e(kde,xCo),e(Gu,$Co),e(Gu,Ej),e(Ej,kCo),e(Gu,SCo),e(G,RCo),e(G,Ou),e(Ou,Sde),e(Sde,PCo),e(Ou,BCo),e(Ou,Cj),e(Cj,ICo),e(Ou,NCo),e(G,qCo),e(G,Vu),e(Vu,Rde),e(Rde,jCo),e(Vu,DCo),e(Vu,wj),e(wj,GCo),e(Vu,OCo),e(G,VCo),e(G,Xu),e(Xu,Pde),e(Pde,XCo),e(Xu,zCo),e(Xu,Aj),e(Aj,WCo),e(Xu,QCo),e(G,HCo),e(G,zu),e(zu,Bde),e(Bde,UCo),e(zu,JCo),e(zu,yj),e(yj,YCo),e(zu,KCo),e(G,ZCo),e(G,Wu),e(Wu,Ide),e(Ide,e3o),e(Wu,o3o),e(Wu,Lj),e(Lj,r3o),e(Wu,t3o),e(G,a3o),e(G,Qu),e(Qu,Nde),e(Nde,n3o),e(Qu,s3o),e(Qu,xj),e(xj,l3o),e(Qu,i3o),e(G,d3o),e(G,Hu),e(Hu,qde),e(qde,c3o),e(Hu,f3o),e(Hu,$j),e($j,m3o),e(Hu,g3o),e(G,h3o),e(G,Uu),e(Uu,jde),e(jde,p3o),e(Uu,_3o),e(Uu,kj),e(kj,u3o),e(Uu,b3o),e(G,v3o),e(G,Ju),e(Ju,Dde),e(Dde,F3o),e(Ju,T3o),e(Ju,Sj),e(Sj,M3o),e(Ju,E3o),e(Ye,C3o),e(Ye,Yu),e(Yu,w3o),e(Yu,Gde),e(Gde,A3o),e(Yu,y3o),e(Yu,Ode),e(Ode,L3o),e(Ye,x3o),M(Ku,Ye,null),b(f,Zqe,u),b(f,Ri,u),e(Ri,Zu),e(Zu,Vde),M(by,Vde,null),e(Ri,$3o),e(Ri,Xde),e(Xde,k3o),b(f,eje,u),b(f,$o,u),M(vy,$o,null),e($o,S3o),e($o,Pi),e(Pi,R3o),e(Pi,Rj),e(Rj,P3o),e(Pi,B3o),e(Pi,Pj),e(Pj,I3o),e(Pi,N3o),e($o,q3o),e($o,Fy),e(Fy,j3o),e(Fy,zde),e(zde,D3o),e(Fy,G3o),e($o,O3o),e($o,nt),M(Ty,nt,null),e(nt,V3o),e(nt,Wde),e(Wde,X3o),e(nt,z3o),e(nt,Bi),e(Bi,W3o),e(Bi,Qde),e(Qde,Q3o),e(Bi,H3o),e(Bi,Bj),e(Bj,U3o),e(Bi,J3o),e(nt,Y3o),M(e2,nt,null),e($o,K3o),e($o,Ke),M(My,Ke,null),e(Ke,Z3o),e(Ke,Hde),e(Hde,e0o),e(Ke,o0o),e(Ke,$a),e($a,r0o),e($a,Ude),e(Ude,t0o),e($a,a0o),e($a,Jde),e(Jde,n0o),e($a,s0o),e($a,Yde),e(Yde,l0o),e($a,i0o),e(Ke,d0o),e(Ke,z),e(z,o2),e(o2,Kde),e(Kde,c0o),e(o2,f0o),e(o2,Ij),e(Ij,m0o),e(o2,g0o),e(z,h0o),e(z,r2),e(r2,Zde),e(Zde,p0o),e(r2,_0o),e(r2,Nj),e(Nj,u0o),e(r2,b0o),e(z,v0o),e(z,t2),e(t2,ece),e(ece,F0o),e(t2,T0o),e(t2,qj),e(qj,M0o),e(t2,E0o),e(z,C0o),e(z,a2),e(a2,oce),e(oce,w0o),e(a2,A0o),e(a2,jj),e(jj,y0o),e(a2,L0o),e(z,x0o),e(z,n2),e(n2,rce),e(rce,$0o),e(n2,k0o),e(n2,Dj),e(Dj,S0o),e(n2,R0o),e(z,P0o),e(z,s2),e(s2,tce),e(tce,B0o),e(s2,I0o),e(s2,Gj),e(Gj,N0o),e(s2,q0o),e(z,j0o),e(z,l2),e(l2,ace),e(ace,D0o),e(l2,G0o),e(l2,Oj),e(Oj,O0o),e(l2,V0o),e(z,X0o),e(z,i2),e(i2,nce),e(nce,z0o),e(i2,W0o),e(i2,Vj),e(Vj,Q0o),e(i2,H0o),e(z,U0o),e(z,d2),e(d2,sce),e(sce,J0o),e(d2,Y0o),e(d2,Xj),e(Xj,K0o),e(d2,Z0o),e(z,ewo),e(z,c2),e(c2,lce),e(lce,owo),e(c2,rwo),e(c2,zj),e(zj,two),e(c2,awo),e(z,nwo),e(z,f2),e(f2,ice),e(ice,swo),e(f2,lwo),e(f2,Wj),e(Wj,iwo),e(f2,dwo),e(z,cwo),e(z,m2),e(m2,dce),e(dce,fwo),e(m2,mwo),e(m2,Qj),e(Qj,gwo),e(m2,hwo),e(z,pwo),e(z,g2),e(g2,cce),e(cce,_wo),e(g2,uwo),e(g2,Hj),e(Hj,bwo),e(g2,vwo),e(z,Fwo),e(z,h2),e(h2,fce),e(fce,Two),e(h2,Mwo),e(h2,Uj),e(Uj,Ewo),e(h2,Cwo),e(z,wwo),e(z,p2),e(p2,mce),e(mce,Awo),e(p2,ywo),e(p2,Jj),e(Jj,Lwo),e(p2,xwo),e(z,$wo),e(z,_2),e(_2,gce),e(gce,kwo),e(_2,Swo),e(_2,Yj),e(Yj,Rwo),e(_2,Pwo),e(z,Bwo),e(z,u2),e(u2,hce),e(hce,Iwo),e(u2,Nwo),e(u2,Kj),e(Kj,qwo),e(u2,jwo),e(z,Dwo),e(z,b2),e(b2,pce),e(pce,Gwo),e(b2,Owo),e(b2,Zj),e(Zj,Vwo),e(b2,Xwo),e(z,zwo),e(z,v2),e(v2,_ce),e(_ce,Wwo),e(v2,Qwo),e(v2,eD),e(eD,Hwo),e(v2,Uwo),e(z,Jwo),e(z,F2),e(F2,uce),e(uce,Ywo),e(F2,Kwo),e(F2,oD),e(oD,Zwo),e(F2,e6o),e(z,o6o),e(z,T2),e(T2,bce),e(bce,r6o),e(T2,t6o),e(T2,rD),e(rD,a6o),e(T2,n6o),e(z,s6o),e(z,M2),e(M2,vce),e(vce,l6o),e(M2,i6o),e(M2,tD),e(tD,d6o),e(M2,c6o),e(z,f6o),e(z,E2),e(E2,Fce),e(Fce,m6o),e(E2,g6o),e(E2,aD),e(aD,h6o),e(E2,p6o),e(z,_6o),e(z,C2),e(C2,Tce),e(Tce,u6o),e(C2,b6o),e(C2,nD),e(nD,v6o),e(C2,F6o),e(z,T6o),e(z,w2),e(w2,Mce),e(Mce,M6o),e(w2,E6o),e(w2,sD),e(sD,C6o),e(w2,w6o),e(z,A6o),e(z,A2),e(A2,Ece),e(Ece,y6o),e(A2,L6o),e(A2,lD),e(lD,x6o),e(A2,$6o),e(z,k6o),e(z,y2),e(y2,Cce),e(Cce,S6o),e(y2,R6o),e(y2,iD),e(iD,P6o),e(y2,B6o),e(z,I6o),e(z,L2),e(L2,wce),e(wce,N6o),e(L2,q6o),e(L2,dD),e(dD,j6o),e(L2,D6o),e(z,G6o),e(z,x2),e(x2,Ace),e(Ace,O6o),e(x2,V6o),e(x2,cD),e(cD,X6o),e(x2,z6o),e(z,W6o),e(z,$2),e($2,yce),e(yce,Q6o),e($2,H6o),e($2,fD),e(fD,U6o),e($2,J6o),e(z,Y6o),e(z,k2),e(k2,Lce),e(Lce,K6o),e(k2,Z6o),e(k2,mD),e(mD,eAo),e(k2,oAo),e(z,rAo),e(z,S2),e(S2,xce),e(xce,tAo),e(S2,aAo),e(S2,gD),e(gD,nAo),e(S2,sAo),e(z,lAo),e(z,R2),e(R2,$ce),e($ce,iAo),e(R2,dAo),e(R2,hD),e(hD,cAo),e(R2,fAo),e(z,mAo),e(z,P2),e(P2,kce),e(kce,gAo),e(P2,hAo),e(P2,pD),e(pD,pAo),e(P2,_Ao),e(z,uAo),e(z,B2),e(B2,Sce),e(Sce,bAo),e(B2,vAo),e(B2,_D),e(_D,FAo),e(B2,TAo),e(z,MAo),e(z,I2),e(I2,Rce),e(Rce,EAo),e(I2,CAo),e(I2,uD),e(uD,wAo),e(I2,AAo),e(z,yAo),e(z,N2),e(N2,Pce),e(Pce,LAo),e(N2,xAo),e(N2,bD),e(bD,$Ao),e(N2,kAo),e(Ke,SAo),e(Ke,q2),e(q2,RAo),e(q2,Bce),e(Bce,PAo),e(q2,BAo),e(q2,Ice),e(Ice,IAo),e(Ke,NAo),M(j2,Ke,null),b(f,oje,u),b(f,Ii,u),e(Ii,D2),e(D2,Nce),M(Ey,Nce,null),e(Ii,qAo),e(Ii,qce),e(qce,jAo),b(f,rje,u),b(f,ko,u),M(Cy,ko,null),e(ko,DAo),e(ko,Ni),e(Ni,GAo),e(Ni,vD),e(vD,OAo),e(Ni,VAo),e(Ni,FD),e(FD,XAo),e(Ni,zAo),e(ko,WAo),e(ko,wy),e(wy,QAo),e(wy,jce),e(jce,HAo),e(wy,UAo),e(ko,JAo),e(ko,st),M(Ay,st,null),e(st,YAo),e(st,Dce),e(Dce,KAo),e(st,ZAo),e(st,qi),e(qi,eyo),e(qi,Gce),e(Gce,oyo),e(qi,ryo),e(qi,TD),e(TD,tyo),e(qi,ayo),e(st,nyo),M(G2,st,null),e(ko,syo),e(ko,Ze),M(yy,Ze,null),e(Ze,lyo),e(Ze,Oce),e(Oce,iyo),e(Ze,dyo),e(Ze,ka),e(ka,cyo),e(ka,Vce),e(Vce,fyo),e(ka,myo),e(ka,Xce),e(Xce,gyo),e(ka,hyo),e(ka,zce),e(zce,pyo),e(ka,_yo),e(Ze,uyo),e(Ze,W),e(W,O2),e(O2,Wce),e(Wce,byo),e(O2,vyo),e(O2,MD),e(MD,Fyo),e(O2,Tyo),e(W,Myo),e(W,V2),e(V2,Qce),e(Qce,Eyo),e(V2,Cyo),e(V2,ED),e(ED,wyo),e(V2,Ayo),e(W,yyo),e(W,X2),e(X2,Hce),e(Hce,Lyo),e(X2,xyo),e(X2,CD),e(CD,$yo),e(X2,kyo),e(W,Syo),e(W,z2),e(z2,Uce),e(Uce,Ryo),e(z2,Pyo),e(z2,wD),e(wD,Byo),e(z2,Iyo),e(W,Nyo),e(W,W2),e(W2,Jce),e(Jce,qyo),e(W2,jyo),e(W2,AD),e(AD,Dyo),e(W2,Gyo),e(W,Oyo),e(W,Q2),e(Q2,Yce),e(Yce,Vyo),e(Q2,Xyo),e(Q2,yD),e(yD,zyo),e(Q2,Wyo),e(W,Qyo),e(W,H2),e(H2,Kce),e(Kce,Hyo),e(H2,Uyo),e(H2,LD),e(LD,Jyo),e(H2,Yyo),e(W,Kyo),e(W,U2),e(U2,Zce),e(Zce,Zyo),e(U2,eLo),e(U2,xD),e(xD,oLo),e(U2,rLo),e(W,tLo),e(W,J2),e(J2,efe),e(efe,aLo),e(J2,nLo),e(J2,$D),e($D,sLo),e(J2,lLo),e(W,iLo),e(W,Y2),e(Y2,ofe),e(ofe,dLo),e(Y2,cLo),e(Y2,kD),e(kD,fLo),e(Y2,mLo),e(W,gLo),e(W,K2),e(K2,rfe),e(rfe,hLo),e(K2,pLo),e(K2,SD),e(SD,_Lo),e(K2,uLo),e(W,bLo),e(W,Z2),e(Z2,tfe),e(tfe,vLo),e(Z2,FLo),e(Z2,RD),e(RD,TLo),e(Z2,MLo),e(W,ELo),e(W,e1),e(e1,afe),e(afe,CLo),e(e1,wLo),e(e1,PD),e(PD,ALo),e(e1,yLo),e(W,LLo),e(W,o1),e(o1,nfe),e(nfe,xLo),e(o1,$Lo),e(o1,BD),e(BD,kLo),e(o1,SLo),e(W,RLo),e(W,r1),e(r1,sfe),e(sfe,PLo),e(r1,BLo),e(r1,ID),e(ID,ILo),e(r1,NLo),e(W,qLo),e(W,t1),e(t1,lfe),e(lfe,jLo),e(t1,DLo),e(t1,ND),e(ND,GLo),e(t1,OLo),e(W,VLo),e(W,a1),e(a1,ife),e(ife,XLo),e(a1,zLo),e(a1,qD),e(qD,WLo),e(a1,QLo),e(W,HLo),e(W,n1),e(n1,dfe),e(dfe,ULo),e(n1,JLo),e(n1,jD),e(jD,YLo),e(n1,KLo),e(W,ZLo),e(W,s1),e(s1,cfe),e(cfe,e8o),e(s1,o8o),e(s1,DD),e(DD,r8o),e(s1,t8o),e(W,a8o),e(W,l1),e(l1,ffe),e(ffe,n8o),e(l1,s8o),e(l1,GD),e(GD,l8o),e(l1,i8o),e(W,d8o),e(W,i1),e(i1,mfe),e(mfe,c8o),e(i1,f8o),e(i1,OD),e(OD,m8o),e(i1,g8o),e(W,h8o),e(W,d1),e(d1,gfe),e(gfe,p8o),e(d1,_8o),e(d1,VD),e(VD,u8o),e(d1,b8o),e(W,v8o),e(W,c1),e(c1,hfe),e(hfe,F8o),e(c1,T8o),e(c1,XD),e(XD,M8o),e(c1,E8o),e(W,C8o),e(W,f1),e(f1,pfe),e(pfe,w8o),e(f1,A8o),e(f1,zD),e(zD,y8o),e(f1,L8o),e(W,x8o),e(W,m1),e(m1,_fe),e(_fe,$8o),e(m1,k8o),e(m1,WD),e(WD,S8o),e(m1,R8o),e(W,P8o),e(W,g1),e(g1,ufe),e(ufe,B8o),e(g1,I8o),e(g1,QD),e(QD,N8o),e(g1,q8o),e(W,j8o),e(W,h1),e(h1,bfe),e(bfe,D8o),e(h1,G8o),e(h1,HD),e(HD,O8o),e(h1,V8o),e(W,X8o),e(W,p1),e(p1,vfe),e(vfe,z8o),e(p1,W8o),e(p1,UD),e(UD,Q8o),e(p1,H8o),e(W,U8o),e(W,_1),e(_1,Ffe),e(Ffe,J8o),e(_1,Y8o),e(_1,JD),e(JD,K8o),e(_1,Z8o),e(W,e9o),e(W,u1),e(u1,Tfe),e(Tfe,o9o),e(u1,r9o),e(u1,YD),e(YD,t9o),e(u1,a9o),e(W,n9o),e(W,b1),e(b1,Mfe),e(Mfe,s9o),e(b1,l9o),e(b1,KD),e(KD,i9o),e(b1,d9o),e(W,c9o),e(W,v1),e(v1,Efe),e(Efe,f9o),e(v1,m9o),e(v1,Cfe),e(Cfe,g9o),e(v1,h9o),e(W,p9o),e(W,F1),e(F1,wfe),e(wfe,_9o),e(F1,u9o),e(F1,ZD),e(ZD,b9o),e(F1,v9o),e(W,F9o),e(W,T1),e(T1,Afe),e(Afe,T9o),e(T1,M9o),e(T1,eG),e(eG,E9o),e(T1,C9o),e(W,w9o),e(W,M1),e(M1,yfe),e(yfe,A9o),e(M1,y9o),e(M1,oG),e(oG,L9o),e(M1,x9o),e(W,$9o),e(W,E1),e(E1,Lfe),e(Lfe,k9o),e(E1,S9o),e(E1,rG),e(rG,R9o),e(E1,P9o),e(Ze,B9o),e(Ze,C1),e(C1,I9o),e(C1,xfe),e(xfe,N9o),e(C1,q9o),e(C1,$fe),e($fe,j9o),e(Ze,D9o),M(w1,Ze,null),b(f,tje,u),b(f,ji,u),e(ji,A1),e(A1,kfe),M(Ly,kfe,null),e(ji,G9o),e(ji,Sfe),e(Sfe,O9o),b(f,aje,u),b(f,So,u),M(xy,So,null),e(So,V9o),e(So,Di),e(Di,X9o),e(Di,tG),e(tG,z9o),e(Di,W9o),e(Di,aG),e(aG,Q9o),e(Di,H9o),e(So,U9o),e(So,$y),e($y,J9o),e($y,Rfe),e(Rfe,Y9o),e($y,K9o),e(So,Z9o),e(So,lt),M(ky,lt,null),e(lt,exo),e(lt,Pfe),e(Pfe,oxo),e(lt,rxo),e(lt,Gi),e(Gi,txo),e(Gi,Bfe),e(Bfe,axo),e(Gi,nxo),e(Gi,nG),e(nG,sxo),e(Gi,lxo),e(lt,ixo),M(y1,lt,null),e(So,dxo),e(So,eo),M(Sy,eo,null),e(eo,cxo),e(eo,Ife),e(Ife,fxo),e(eo,mxo),e(eo,Sa),e(Sa,gxo),e(Sa,Nfe),e(Nfe,hxo),e(Sa,pxo),e(Sa,qfe),e(qfe,_xo),e(Sa,uxo),e(Sa,jfe),e(jfe,bxo),e(Sa,vxo),e(eo,Fxo),e(eo,_e),e(_e,L1),e(L1,Dfe),e(Dfe,Txo),e(L1,Mxo),e(L1,sG),e(sG,Exo),e(L1,Cxo),e(_e,wxo),e(_e,x1),e(x1,Gfe),e(Gfe,Axo),e(x1,yxo),e(x1,lG),e(lG,Lxo),e(x1,xxo),e(_e,$xo),e(_e,$1),e($1,Ofe),e(Ofe,kxo),e($1,Sxo),e($1,iG),e(iG,Rxo),e($1,Pxo),e(_e,Bxo),e(_e,k1),e(k1,Vfe),e(Vfe,Ixo),e(k1,Nxo),e(k1,dG),e(dG,qxo),e(k1,jxo),e(_e,Dxo),e(_e,S1),e(S1,Xfe),e(Xfe,Gxo),e(S1,Oxo),e(S1,cG),e(cG,Vxo),e(S1,Xxo),e(_e,zxo),e(_e,R1),e(R1,zfe),e(zfe,Wxo),e(R1,Qxo),e(R1,fG),e(fG,Hxo),e(R1,Uxo),e(_e,Jxo),e(_e,P1),e(P1,Wfe),e(Wfe,Yxo),e(P1,Kxo),e(P1,mG),e(mG,Zxo),e(P1,e$o),e(_e,o$o),e(_e,B1),e(B1,Qfe),e(Qfe,r$o),e(B1,t$o),e(B1,gG),e(gG,a$o),e(B1,n$o),e(_e,s$o),e(_e,I1),e(I1,Hfe),e(Hfe,l$o),e(I1,i$o),e(I1,hG),e(hG,d$o),e(I1,c$o),e(_e,f$o),e(_e,N1),e(N1,Ufe),e(Ufe,m$o),e(N1,g$o),e(N1,pG),e(pG,h$o),e(N1,p$o),e(_e,_$o),e(_e,q1),e(q1,Jfe),e(Jfe,u$o),e(q1,b$o),e(q1,_G),e(_G,v$o),e(q1,F$o),e(_e,T$o),e(_e,j1),e(j1,Yfe),e(Yfe,M$o),e(j1,E$o),e(j1,uG),e(uG,C$o),e(j1,w$o),e(_e,A$o),e(_e,D1),e(D1,Kfe),e(Kfe,y$o),e(D1,L$o),e(D1,bG),e(bG,x$o),e(D1,$$o),e(_e,k$o),e(_e,G1),e(G1,Zfe),e(Zfe,S$o),e(G1,R$o),e(G1,vG),e(vG,P$o),e(G1,B$o),e(_e,I$o),e(_e,O1),e(O1,eme),e(eme,N$o),e(O1,q$o),e(O1,FG),e(FG,j$o),e(O1,D$o),e(_e,G$o),e(_e,V1),e(V1,ome),e(ome,O$o),e(V1,V$o),e(V1,TG),e(TG,X$o),e(V1,z$o),e(eo,W$o),e(eo,X1),e(X1,Q$o),e(X1,rme),e(rme,H$o),e(X1,U$o),e(X1,tme),e(tme,J$o),e(eo,Y$o),M(z1,eo,null),b(f,nje,u),b(f,Oi,u),e(Oi,W1),e(W1,ame),M(Ry,ame,null),e(Oi,K$o),e(Oi,nme),e(nme,Z$o),b(f,sje,u),b(f,Ro,u),M(Py,Ro,null),e(Ro,eko),e(Ro,Vi),e(Vi,oko),e(Vi,MG),e(MG,rko),e(Vi,tko),e(Vi,EG),e(EG,ako),e(Vi,nko),e(Ro,sko),e(Ro,By),e(By,lko),e(By,sme),e(sme,iko),e(By,dko),e(Ro,cko),e(Ro,it),M(Iy,it,null),e(it,fko),e(it,lme),e(lme,mko),e(it,gko),e(it,Xi),e(Xi,hko),e(Xi,ime),e(ime,pko),e(Xi,_ko),e(Xi,CG),e(CG,uko),e(Xi,bko),e(it,vko),M(Q1,it,null),e(Ro,Fko),e(Ro,oo),M(Ny,oo,null),e(oo,Tko),e(oo,dme),e(dme,Mko),e(oo,Eko),e(oo,Ra),e(Ra,Cko),e(Ra,cme),e(cme,wko),e(Ra,Ako),e(Ra,fme),e(fme,yko),e(Ra,Lko),e(Ra,mme),e(mme,xko),e(Ra,$ko),e(oo,kko),e(oo,N),e(N,H1),e(H1,gme),e(gme,Sko),e(H1,Rko),e(H1,wG),e(wG,Pko),e(H1,Bko),e(N,Iko),e(N,U1),e(U1,hme),e(hme,Nko),e(U1,qko),e(U1,AG),e(AG,jko),e(U1,Dko),e(N,Gko),e(N,J1),e(J1,pme),e(pme,Oko),e(J1,Vko),e(J1,yG),e(yG,Xko),e(J1,zko),e(N,Wko),e(N,Y1),e(Y1,_me),e(_me,Qko),e(Y1,Hko),e(Y1,LG),e(LG,Uko),e(Y1,Jko),e(N,Yko),e(N,K1),e(K1,ume),e(ume,Kko),e(K1,Zko),e(K1,xG),e(xG,eSo),e(K1,oSo),e(N,rSo),e(N,Z1),e(Z1,bme),e(bme,tSo),e(Z1,aSo),e(Z1,$G),e($G,nSo),e(Z1,sSo),e(N,lSo),e(N,eb),e(eb,vme),e(vme,iSo),e(eb,dSo),e(eb,kG),e(kG,cSo),e(eb,fSo),e(N,mSo),e(N,ob),e(ob,Fme),e(Fme,gSo),e(ob,hSo),e(ob,SG),e(SG,pSo),e(ob,_So),e(N,uSo),e(N,rb),e(rb,Tme),e(Tme,bSo),e(rb,vSo),e(rb,RG),e(RG,FSo),e(rb,TSo),e(N,MSo),e(N,tb),e(tb,Mme),e(Mme,ESo),e(tb,CSo),e(tb,PG),e(PG,wSo),e(tb,ASo),e(N,ySo),e(N,ab),e(ab,Eme),e(Eme,LSo),e(ab,xSo),e(ab,BG),e(BG,$So),e(ab,kSo),e(N,SSo),e(N,nb),e(nb,Cme),e(Cme,RSo),e(nb,PSo),e(nb,IG),e(IG,BSo),e(nb,ISo),e(N,NSo),e(N,sb),e(sb,wme),e(wme,qSo),e(sb,jSo),e(sb,NG),e(NG,DSo),e(sb,GSo),e(N,OSo),e(N,lb),e(lb,Ame),e(Ame,VSo),e(lb,XSo),e(lb,qG),e(qG,zSo),e(lb,WSo),e(N,QSo),e(N,ib),e(ib,yme),e(yme,HSo),e(ib,USo),e(ib,jG),e(jG,JSo),e(ib,YSo),e(N,KSo),e(N,db),e(db,Lme),e(Lme,ZSo),e(db,eRo),e(db,DG),e(DG,oRo),e(db,rRo),e(N,tRo),e(N,cb),e(cb,xme),e(xme,aRo),e(cb,nRo),e(cb,GG),e(GG,sRo),e(cb,lRo),e(N,iRo),e(N,fb),e(fb,$me),e($me,dRo),e(fb,cRo),e(fb,OG),e(OG,fRo),e(fb,mRo),e(N,gRo),e(N,mb),e(mb,kme),e(kme,hRo),e(mb,pRo),e(mb,VG),e(VG,_Ro),e(mb,uRo),e(N,bRo),e(N,gb),e(gb,Sme),e(Sme,vRo),e(gb,FRo),e(gb,XG),e(XG,TRo),e(gb,MRo),e(N,ERo),e(N,hb),e(hb,Rme),e(Rme,CRo),e(hb,wRo),e(hb,zG),e(zG,ARo),e(hb,yRo),e(N,LRo),e(N,pb),e(pb,Pme),e(Pme,xRo),e(pb,$Ro),e(pb,WG),e(WG,kRo),e(pb,SRo),e(N,RRo),e(N,_b),e(_b,Bme),e(Bme,PRo),e(_b,BRo),e(_b,QG),e(QG,IRo),e(_b,NRo),e(N,qRo),e(N,ub),e(ub,Ime),e(Ime,jRo),e(ub,DRo),e(ub,HG),e(HG,GRo),e(ub,ORo),e(N,VRo),e(N,bb),e(bb,Nme),e(Nme,XRo),e(bb,zRo),e(bb,UG),e(UG,WRo),e(bb,QRo),e(N,HRo),e(N,vb),e(vb,qme),e(qme,URo),e(vb,JRo),e(vb,JG),e(JG,YRo),e(vb,KRo),e(N,ZRo),e(N,Fb),e(Fb,jme),e(jme,ePo),e(Fb,oPo),e(Fb,YG),e(YG,rPo),e(Fb,tPo),e(N,aPo),e(N,Tb),e(Tb,Dme),e(Dme,nPo),e(Tb,sPo),e(Tb,KG),e(KG,lPo),e(Tb,iPo),e(N,dPo),e(N,Mb),e(Mb,Gme),e(Gme,cPo),e(Mb,fPo),e(Mb,ZG),e(ZG,mPo),e(Mb,gPo),e(N,hPo),e(N,Eb),e(Eb,Ome),e(Ome,pPo),e(Eb,_Po),e(Eb,eO),e(eO,uPo),e(Eb,bPo),e(N,vPo),e(N,Cb),e(Cb,Vme),e(Vme,FPo),e(Cb,TPo),e(Cb,oO),e(oO,MPo),e(Cb,EPo),e(N,CPo),e(N,wb),e(wb,Xme),e(Xme,wPo),e(wb,APo),e(wb,rO),e(rO,yPo),e(wb,LPo),e(N,xPo),e(N,Ab),e(Ab,zme),e(zme,$Po),e(Ab,kPo),e(Ab,tO),e(tO,SPo),e(Ab,RPo),e(N,PPo),e(N,yb),e(yb,Wme),e(Wme,BPo),e(yb,IPo),e(yb,aO),e(aO,NPo),e(yb,qPo),e(N,jPo),e(N,Lb),e(Lb,Qme),e(Qme,DPo),e(Lb,GPo),e(Lb,nO),e(nO,OPo),e(Lb,VPo),e(N,XPo),e(N,xb),e(xb,Hme),e(Hme,zPo),e(xb,WPo),e(xb,sO),e(sO,QPo),e(xb,HPo),e(N,UPo),e(N,$b),e($b,Ume),e(Ume,JPo),e($b,YPo),e($b,lO),e(lO,KPo),e($b,ZPo),e(N,eBo),e(N,kb),e(kb,Jme),e(Jme,oBo),e(kb,rBo),e(kb,iO),e(iO,tBo),e(kb,aBo),e(N,nBo),e(N,Sb),e(Sb,Yme),e(Yme,sBo),e(Sb,lBo),e(Sb,dO),e(dO,iBo),e(Sb,dBo),e(N,cBo),e(N,Rb),e(Rb,Kme),e(Kme,fBo),e(Rb,mBo),e(Rb,cO),e(cO,gBo),e(Rb,hBo),e(N,pBo),e(N,Pb),e(Pb,Zme),e(Zme,_Bo),e(Pb,uBo),e(Pb,fO),e(fO,bBo),e(Pb,vBo),e(N,FBo),e(N,Bb),e(Bb,ege),e(ege,TBo),e(Bb,MBo),e(Bb,mO),e(mO,EBo),e(Bb,CBo),e(N,wBo),e(N,Ib),e(Ib,oge),e(oge,ABo),e(Ib,yBo),e(Ib,gO),e(gO,LBo),e(Ib,xBo),e(N,$Bo),e(N,Nb),e(Nb,rge),e(rge,kBo),e(Nb,SBo),e(Nb,hO),e(hO,RBo),e(Nb,PBo),e(N,BBo),e(N,qb),e(qb,tge),e(tge,IBo),e(qb,NBo),e(qb,pO),e(pO,qBo),e(qb,jBo),e(N,DBo),e(N,jb),e(jb,age),e(age,GBo),e(jb,OBo),e(jb,_O),e(_O,VBo),e(jb,XBo),e(N,zBo),e(N,Db),e(Db,nge),e(nge,WBo),e(Db,QBo),e(Db,uO),e(uO,HBo),e(Db,UBo),e(oo,JBo),e(oo,Gb),e(Gb,YBo),e(Gb,sge),e(sge,KBo),e(Gb,ZBo),e(Gb,lge),e(lge,eIo),e(oo,oIo),M(Ob,oo,null),b(f,lje,u),b(f,zi,u),e(zi,Vb),e(Vb,ige),M(qy,ige,null),e(zi,rIo),e(zi,dge),e(dge,tIo),b(f,ije,u),b(f,Po,u),M(jy,Po,null),e(Po,aIo),e(Po,Wi),e(Wi,nIo),e(Wi,bO),e(bO,sIo),e(Wi,lIo),e(Wi,vO),e(vO,iIo),e(Wi,dIo),e(Po,cIo),e(Po,Dy),e(Dy,fIo),e(Dy,cge),e(cge,mIo),e(Dy,gIo),e(Po,hIo),e(Po,dt),M(Gy,dt,null),e(dt,pIo),e(dt,fge),e(fge,_Io),e(dt,uIo),e(dt,Qi),e(Qi,bIo),e(Qi,mge),e(mge,vIo),e(Qi,FIo),e(Qi,FO),e(FO,TIo),e(Qi,MIo),e(dt,EIo),M(Xb,dt,null),e(Po,CIo),e(Po,ro),M(Oy,ro,null),e(ro,wIo),e(ro,gge),e(gge,AIo),e(ro,yIo),e(ro,Pa),e(Pa,LIo),e(Pa,hge),e(hge,xIo),e(Pa,$Io),e(Pa,pge),e(pge,kIo),e(Pa,SIo),e(Pa,_ge),e(_ge,RIo),e(Pa,PIo),e(ro,BIo),e(ro,K),e(K,zb),e(zb,uge),e(uge,IIo),e(zb,NIo),e(zb,TO),e(TO,qIo),e(zb,jIo),e(K,DIo),e(K,Wb),e(Wb,bge),e(bge,GIo),e(Wb,OIo),e(Wb,MO),e(MO,VIo),e(Wb,XIo),e(K,zIo),e(K,Qb),e(Qb,vge),e(vge,WIo),e(Qb,QIo),e(Qb,EO),e(EO,HIo),e(Qb,UIo),e(K,JIo),e(K,Hb),e(Hb,Fge),e(Fge,YIo),e(Hb,KIo),e(Hb,CO),e(CO,ZIo),e(Hb,eNo),e(K,oNo),e(K,Ub),e(Ub,Tge),e(Tge,rNo),e(Ub,tNo),e(Ub,wO),e(wO,aNo),e(Ub,nNo),e(K,sNo),e(K,Jb),e(Jb,Mge),e(Mge,lNo),e(Jb,iNo),e(Jb,AO),e(AO,dNo),e(Jb,cNo),e(K,fNo),e(K,Yb),e(Yb,Ege),e(Ege,mNo),e(Yb,gNo),e(Yb,yO),e(yO,hNo),e(Yb,pNo),e(K,_No),e(K,Kb),e(Kb,Cge),e(Cge,uNo),e(Kb,bNo),e(Kb,LO),e(LO,vNo),e(Kb,FNo),e(K,TNo),e(K,Zb),e(Zb,wge),e(wge,MNo),e(Zb,ENo),e(Zb,xO),e(xO,CNo),e(Zb,wNo),e(K,ANo),e(K,e4),e(e4,Age),e(Age,yNo),e(e4,LNo),e(e4,$O),e($O,xNo),e(e4,$No),e(K,kNo),e(K,o4),e(o4,yge),e(yge,SNo),e(o4,RNo),e(o4,kO),e(kO,PNo),e(o4,BNo),e(K,INo),e(K,r4),e(r4,Lge),e(Lge,NNo),e(r4,qNo),e(r4,SO),e(SO,jNo),e(r4,DNo),e(K,GNo),e(K,t4),e(t4,xge),e(xge,ONo),e(t4,VNo),e(t4,RO),e(RO,XNo),e(t4,zNo),e(K,WNo),e(K,a4),e(a4,$ge),e($ge,QNo),e(a4,HNo),e(a4,PO),e(PO,UNo),e(a4,JNo),e(K,YNo),e(K,n4),e(n4,kge),e(kge,KNo),e(n4,ZNo),e(n4,BO),e(BO,eqo),e(n4,oqo),e(K,rqo),e(K,s4),e(s4,Sge),e(Sge,tqo),e(s4,aqo),e(s4,IO),e(IO,nqo),e(s4,sqo),e(K,lqo),e(K,l4),e(l4,Rge),e(Rge,iqo),e(l4,dqo),e(l4,NO),e(NO,cqo),e(l4,fqo),e(K,mqo),e(K,i4),e(i4,Pge),e(Pge,gqo),e(i4,hqo),e(i4,qO),e(qO,pqo),e(i4,_qo),e(K,uqo),e(K,d4),e(d4,Bge),e(Bge,bqo),e(d4,vqo),e(d4,jO),e(jO,Fqo),e(d4,Tqo),e(K,Mqo),e(K,c4),e(c4,Ige),e(Ige,Eqo),e(c4,Cqo),e(c4,DO),e(DO,wqo),e(c4,Aqo),e(K,yqo),e(K,f4),e(f4,Nge),e(Nge,Lqo),e(f4,xqo),e(f4,GO),e(GO,$qo),e(f4,kqo),e(K,Sqo),e(K,m4),e(m4,qge),e(qge,Rqo),e(m4,Pqo),e(m4,OO),e(OO,Bqo),e(m4,Iqo),e(K,Nqo),e(K,g4),e(g4,jge),e(jge,qqo),e(g4,jqo),e(g4,VO),e(VO,Dqo),e(g4,Gqo),e(K,Oqo),e(K,h4),e(h4,Dge),e(Dge,Vqo),e(h4,Xqo),e(h4,XO),e(XO,zqo),e(h4,Wqo),e(K,Qqo),e(K,p4),e(p4,Gge),e(Gge,Hqo),e(p4,Uqo),e(p4,zO),e(zO,Jqo),e(p4,Yqo),e(K,Kqo),e(K,_4),e(_4,Oge),e(Oge,Zqo),e(_4,ejo),e(_4,WO),e(WO,ojo),e(_4,rjo),e(K,tjo),e(K,u4),e(u4,Vge),e(Vge,ajo),e(u4,njo),e(u4,QO),e(QO,sjo),e(u4,ljo),e(K,ijo),e(K,b4),e(b4,Xge),e(Xge,djo),e(b4,cjo),e(b4,HO),e(HO,fjo),e(b4,mjo),e(K,gjo),e(K,v4),e(v4,zge),e(zge,hjo),e(v4,pjo),e(v4,UO),e(UO,_jo),e(v4,ujo),e(ro,bjo),e(ro,F4),e(F4,vjo),e(F4,Wge),e(Wge,Fjo),e(F4,Tjo),e(F4,Qge),e(Qge,Mjo),e(ro,Ejo),M(T4,ro,null),b(f,dje,u),b(f,Hi,u),e(Hi,M4),e(M4,Hge),M(Vy,Hge,null),e(Hi,Cjo),e(Hi,Uge),e(Uge,wjo),b(f,cje,u),b(f,Bo,u),M(Xy,Bo,null),e(Bo,Ajo),e(Bo,Ui),e(Ui,yjo),e(Ui,JO),e(JO,Ljo),e(Ui,xjo),e(Ui,YO),e(YO,$jo),e(Ui,kjo),e(Bo,Sjo),e(Bo,zy),e(zy,Rjo),e(zy,Jge),e(Jge,Pjo),e(zy,Bjo),e(Bo,Ijo),e(Bo,ct),M(Wy,ct,null),e(ct,Njo),e(ct,Yge),e(Yge,qjo),e(ct,jjo),e(ct,Ji),e(Ji,Djo),e(Ji,Kge),e(Kge,Gjo),e(Ji,Ojo),e(Ji,KO),e(KO,Vjo),e(Ji,Xjo),e(ct,zjo),M(E4,ct,null),e(Bo,Wjo),e(Bo,to),M(Qy,to,null),e(to,Qjo),e(to,Zge),e(Zge,Hjo),e(to,Ujo),e(to,Ba),e(Ba,Jjo),e(Ba,ehe),e(ehe,Yjo),e(Ba,Kjo),e(Ba,ohe),e(ohe,Zjo),e(Ba,eDo),e(Ba,rhe),e(rhe,oDo),e(Ba,rDo),e(to,tDo),e(to,Yr),e(Yr,C4),e(C4,the),e(the,aDo),e(C4,nDo),e(C4,ZO),e(ZO,sDo),e(C4,lDo),e(Yr,iDo),e(Yr,w4),e(w4,ahe),e(ahe,dDo),e(w4,cDo),e(w4,eV),e(eV,fDo),e(w4,mDo),e(Yr,gDo),e(Yr,A4),e(A4,nhe),e(nhe,hDo),e(A4,pDo),e(A4,oV),e(oV,_Do),e(A4,uDo),e(Yr,bDo),e(Yr,y4),e(y4,she),e(she,vDo),e(y4,FDo),e(y4,rV),e(rV,TDo),e(y4,MDo),e(Yr,EDo),e(Yr,L4),e(L4,lhe),e(lhe,CDo),e(L4,wDo),e(L4,tV),e(tV,ADo),e(L4,yDo),e(to,LDo),e(to,x4),e(x4,xDo),e(x4,ihe),e(ihe,$Do),e(x4,kDo),e(x4,dhe),e(dhe,SDo),e(to,RDo),M($4,to,null),b(f,fje,u),b(f,Yi,u),e(Yi,k4),e(k4,che),M(Hy,che,null),e(Yi,PDo),e(Yi,fhe),e(fhe,BDo),b(f,mje,u),b(f,Io,u),M(Uy,Io,null),e(Io,IDo),e(Io,Ki),e(Ki,NDo),e(Ki,aV),e(aV,qDo),e(Ki,jDo),e(Ki,nV),e(nV,DDo),e(Ki,GDo),e(Io,ODo),e(Io,Jy),e(Jy,VDo),e(Jy,mhe),e(mhe,XDo),e(Jy,zDo),e(Io,WDo),e(Io,ft),M(Yy,ft,null),e(ft,QDo),e(ft,ghe),e(ghe,HDo),e(ft,UDo),e(ft,Zi),e(Zi,JDo),e(Zi,hhe),e(hhe,YDo),e(Zi,KDo),e(Zi,sV),e(sV,ZDo),e(Zi,eGo),e(ft,oGo),M(S4,ft,null),e(Io,rGo),e(Io,ao),M(Ky,ao,null),e(ao,tGo),e(ao,phe),e(phe,aGo),e(ao,nGo),e(ao,Ia),e(Ia,sGo),e(Ia,_he),e(_he,lGo),e(Ia,iGo),e(Ia,uhe),e(uhe,dGo),e(Ia,cGo),e(Ia,bhe),e(bhe,fGo),e(Ia,mGo),e(ao,gGo),e(ao,U),e(U,R4),e(R4,vhe),e(vhe,hGo),e(R4,pGo),e(R4,lV),e(lV,_Go),e(R4,uGo),e(U,bGo),e(U,P4),e(P4,Fhe),e(Fhe,vGo),e(P4,FGo),e(P4,iV),e(iV,TGo),e(P4,MGo),e(U,EGo),e(U,B4),e(B4,The),e(The,CGo),e(B4,wGo),e(B4,dV),e(dV,AGo),e(B4,yGo),e(U,LGo),e(U,I4),e(I4,Mhe),e(Mhe,xGo),e(I4,$Go),e(I4,cV),e(cV,kGo),e(I4,SGo),e(U,RGo),e(U,N4),e(N4,Ehe),e(Ehe,PGo),e(N4,BGo),e(N4,fV),e(fV,IGo),e(N4,NGo),e(U,qGo),e(U,q4),e(q4,Che),e(Che,jGo),e(q4,DGo),e(q4,mV),e(mV,GGo),e(q4,OGo),e(U,VGo),e(U,j4),e(j4,whe),e(whe,XGo),e(j4,zGo),e(j4,gV),e(gV,WGo),e(j4,QGo),e(U,HGo),e(U,D4),e(D4,Ahe),e(Ahe,UGo),e(D4,JGo),e(D4,hV),e(hV,YGo),e(D4,KGo),e(U,ZGo),e(U,G4),e(G4,yhe),e(yhe,eOo),e(G4,oOo),e(G4,pV),e(pV,rOo),e(G4,tOo),e(U,aOo),e(U,O4),e(O4,Lhe),e(Lhe,nOo),e(O4,sOo),e(O4,_V),e(_V,lOo),e(O4,iOo),e(U,dOo),e(U,V4),e(V4,xhe),e(xhe,cOo),e(V4,fOo),e(V4,uV),e(uV,mOo),e(V4,gOo),e(U,hOo),e(U,X4),e(X4,$he),e($he,pOo),e(X4,_Oo),e(X4,bV),e(bV,uOo),e(X4,bOo),e(U,vOo),e(U,z4),e(z4,khe),e(khe,FOo),e(z4,TOo),e(z4,vV),e(vV,MOo),e(z4,EOo),e(U,COo),e(U,W4),e(W4,She),e(She,wOo),e(W4,AOo),e(W4,FV),e(FV,yOo),e(W4,LOo),e(U,xOo),e(U,Q4),e(Q4,Rhe),e(Rhe,$Oo),e(Q4,kOo),e(Q4,TV),e(TV,SOo),e(Q4,ROo),e(U,POo),e(U,H4),e(H4,Phe),e(Phe,BOo),e(H4,IOo),e(H4,MV),e(MV,NOo),e(H4,qOo),e(U,jOo),e(U,U4),e(U4,Bhe),e(Bhe,DOo),e(U4,GOo),e(U4,EV),e(EV,OOo),e(U4,VOo),e(U,XOo),e(U,J4),e(J4,Ihe),e(Ihe,zOo),e(J4,WOo),e(J4,CV),e(CV,QOo),e(J4,HOo),e(U,UOo),e(U,Y4),e(Y4,Nhe),e(Nhe,JOo),e(Y4,YOo),e(Y4,wV),e(wV,KOo),e(Y4,ZOo),e(U,eVo),e(U,K4),e(K4,qhe),e(qhe,oVo),e(K4,rVo),e(K4,AV),e(AV,tVo),e(K4,aVo),e(U,nVo),e(U,Z4),e(Z4,jhe),e(jhe,sVo),e(Z4,lVo),e(Z4,yV),e(yV,iVo),e(Z4,dVo),e(U,cVo),e(U,ev),e(ev,Dhe),e(Dhe,fVo),e(ev,mVo),e(ev,LV),e(LV,gVo),e(ev,hVo),e(U,pVo),e(U,ov),e(ov,Ghe),e(Ghe,_Vo),e(ov,uVo),e(ov,xV),e(xV,bVo),e(ov,vVo),e(U,FVo),e(U,rv),e(rv,Ohe),e(Ohe,TVo),e(rv,MVo),e(rv,$V),e($V,EVo),e(rv,CVo),e(U,wVo),e(U,tv),e(tv,Vhe),e(Vhe,AVo),e(tv,yVo),e(tv,kV),e(kV,LVo),e(tv,xVo),e(U,$Vo),e(U,av),e(av,Xhe),e(Xhe,kVo),e(av,SVo),e(av,SV),e(SV,RVo),e(av,PVo),e(U,BVo),e(U,nv),e(nv,zhe),e(zhe,IVo),e(nv,NVo),e(nv,RV),e(RV,qVo),e(nv,jVo),e(U,DVo),e(U,sv),e(sv,Whe),e(Whe,GVo),e(sv,OVo),e(sv,PV),e(PV,VVo),e(sv,XVo),e(U,zVo),e(U,lv),e(lv,Qhe),e(Qhe,WVo),e(lv,QVo),e(lv,BV),e(BV,HVo),e(lv,UVo),e(U,JVo),e(U,iv),e(iv,Hhe),e(Hhe,YVo),e(iv,KVo),e(iv,IV),e(IV,ZVo),e(iv,eXo),e(U,oXo),e(U,dv),e(dv,Uhe),e(Uhe,rXo),e(dv,tXo),e(dv,NV),e(NV,aXo),e(dv,nXo),e(U,sXo),e(U,cv),e(cv,Jhe),e(Jhe,lXo),e(cv,iXo),e(cv,qV),e(qV,dXo),e(cv,cXo),e(U,fXo),e(U,fv),e(fv,Yhe),e(Yhe,mXo),e(fv,gXo),e(fv,jV),e(jV,hXo),e(fv,pXo),e(U,_Xo),e(U,mv),e(mv,Khe),e(Khe,uXo),e(mv,bXo),e(mv,DV),e(DV,vXo),e(mv,FXo),e(ao,TXo),e(ao,gv),e(gv,MXo),e(gv,Zhe),e(Zhe,EXo),e(gv,CXo),e(gv,epe),e(epe,wXo),e(ao,AXo),M(hv,ao,null),b(f,gje,u),b(f,ed,u),e(ed,pv),e(pv,ope),M(Zy,ope,null),e(ed,yXo),e(ed,rpe),e(rpe,LXo),b(f,hje,u),b(f,No,u),M(eL,No,null),e(No,xXo),e(No,od),e(od,$Xo),e(od,GV),e(GV,kXo),e(od,SXo),e(od,OV),e(OV,RXo),e(od,PXo),e(No,BXo),e(No,oL),e(oL,IXo),e(oL,tpe),e(tpe,NXo),e(oL,qXo),e(No,jXo),e(No,mt),M(rL,mt,null),e(mt,DXo),e(mt,ape),e(ape,GXo),e(mt,OXo),e(mt,rd),e(rd,VXo),e(rd,npe),e(npe,XXo),e(rd,zXo),e(rd,VV),e(VV,WXo),e(rd,QXo),e(mt,HXo),M(_v,mt,null),e(No,UXo),e(No,no),M(tL,no,null),e(no,JXo),e(no,spe),e(spe,YXo),e(no,KXo),e(no,Na),e(Na,ZXo),e(Na,lpe),e(lpe,ezo),e(Na,ozo),e(Na,ipe),e(ipe,rzo),e(Na,tzo),e(Na,dpe),e(dpe,azo),e(Na,nzo),e(no,szo),e(no,V),e(V,uv),e(uv,cpe),e(cpe,lzo),e(uv,izo),e(uv,XV),e(XV,dzo),e(uv,czo),e(V,fzo),e(V,bv),e(bv,fpe),e(fpe,mzo),e(bv,gzo),e(bv,zV),e(zV,hzo),e(bv,pzo),e(V,_zo),e(V,vv),e(vv,mpe),e(mpe,uzo),e(vv,bzo),e(vv,WV),e(WV,vzo),e(vv,Fzo),e(V,Tzo),e(V,Fv),e(Fv,gpe),e(gpe,Mzo),e(Fv,Ezo),e(Fv,QV),e(QV,Czo),e(Fv,wzo),e(V,Azo),e(V,Tv),e(Tv,hpe),e(hpe,yzo),e(Tv,Lzo),e(Tv,HV),e(HV,xzo),e(Tv,$zo),e(V,kzo),e(V,Mv),e(Mv,ppe),e(ppe,Szo),e(Mv,Rzo),e(Mv,UV),e(UV,Pzo),e(Mv,Bzo),e(V,Izo),e(V,Ev),e(Ev,_pe),e(_pe,Nzo),e(Ev,qzo),e(Ev,JV),e(JV,jzo),e(Ev,Dzo),e(V,Gzo),e(V,Cv),e(Cv,upe),e(upe,Ozo),e(Cv,Vzo),e(Cv,YV),e(YV,Xzo),e(Cv,zzo),e(V,Wzo),e(V,wv),e(wv,bpe),e(bpe,Qzo),e(wv,Hzo),e(wv,KV),e(KV,Uzo),e(wv,Jzo),e(V,Yzo),e(V,Av),e(Av,vpe),e(vpe,Kzo),e(Av,Zzo),e(Av,ZV),e(ZV,eWo),e(Av,oWo),e(V,rWo),e(V,yv),e(yv,Fpe),e(Fpe,tWo),e(yv,aWo),e(yv,eX),e(eX,nWo),e(yv,sWo),e(V,lWo),e(V,Lv),e(Lv,Tpe),e(Tpe,iWo),e(Lv,dWo),e(Lv,oX),e(oX,cWo),e(Lv,fWo),e(V,mWo),e(V,xv),e(xv,Mpe),e(Mpe,gWo),e(xv,hWo),e(xv,rX),e(rX,pWo),e(xv,_Wo),e(V,uWo),e(V,$v),e($v,Epe),e(Epe,bWo),e($v,vWo),e($v,tX),e(tX,FWo),e($v,TWo),e(V,MWo),e(V,kv),e(kv,Cpe),e(Cpe,EWo),e(kv,CWo),e(kv,aX),e(aX,wWo),e(kv,AWo),e(V,yWo),e(V,Sv),e(Sv,wpe),e(wpe,LWo),e(Sv,xWo),e(Sv,nX),e(nX,$Wo),e(Sv,kWo),e(V,SWo),e(V,Rv),e(Rv,Ape),e(Ape,RWo),e(Rv,PWo),e(Rv,sX),e(sX,BWo),e(Rv,IWo),e(V,NWo),e(V,Pv),e(Pv,ype),e(ype,qWo),e(Pv,jWo),e(Pv,lX),e(lX,DWo),e(Pv,GWo),e(V,OWo),e(V,Bv),e(Bv,Lpe),e(Lpe,VWo),e(Bv,XWo),e(Bv,iX),e(iX,zWo),e(Bv,WWo),e(V,QWo),e(V,Iv),e(Iv,xpe),e(xpe,HWo),e(Iv,UWo),e(Iv,dX),e(dX,JWo),e(Iv,YWo),e(V,KWo),e(V,Nv),e(Nv,$pe),e($pe,ZWo),e(Nv,eQo),e(Nv,cX),e(cX,oQo),e(Nv,rQo),e(V,tQo),e(V,qv),e(qv,kpe),e(kpe,aQo),e(qv,nQo),e(qv,fX),e(fX,sQo),e(qv,lQo),e(V,iQo),e(V,jv),e(jv,Spe),e(Spe,dQo),e(jv,cQo),e(jv,mX),e(mX,fQo),e(jv,mQo),e(V,gQo),e(V,Dv),e(Dv,Rpe),e(Rpe,hQo),e(Dv,pQo),e(Dv,gX),e(gX,_Qo),e(Dv,uQo),e(V,bQo),e(V,Gv),e(Gv,Ppe),e(Ppe,vQo),e(Gv,FQo),e(Gv,hX),e(hX,TQo),e(Gv,MQo),e(V,EQo),e(V,Ov),e(Ov,Bpe),e(Bpe,CQo),e(Ov,wQo),e(Ov,pX),e(pX,AQo),e(Ov,yQo),e(V,LQo),e(V,Vv),e(Vv,Ipe),e(Ipe,xQo),e(Vv,$Qo),e(Vv,_X),e(_X,kQo),e(Vv,SQo),e(V,RQo),e(V,Xv),e(Xv,Npe),e(Npe,PQo),e(Xv,BQo),e(Xv,uX),e(uX,IQo),e(Xv,NQo),e(V,qQo),e(V,zv),e(zv,qpe),e(qpe,jQo),e(zv,DQo),e(zv,bX),e(bX,GQo),e(zv,OQo),e(V,VQo),e(V,Wv),e(Wv,jpe),e(jpe,XQo),e(Wv,zQo),e(Wv,vX),e(vX,WQo),e(Wv,QQo),e(V,HQo),e(V,Qv),e(Qv,Dpe),e(Dpe,UQo),e(Qv,JQo),e(Qv,FX),e(FX,YQo),e(Qv,KQo),e(V,ZQo),e(V,Hv),e(Hv,Gpe),e(Gpe,eHo),e(Hv,oHo),e(Hv,TX),e(TX,rHo),e(Hv,tHo),e(V,aHo),e(V,Uv),e(Uv,Ope),e(Ope,nHo),e(Uv,sHo),e(Uv,MX),e(MX,lHo),e(Uv,iHo),e(V,dHo),e(V,Jv),e(Jv,Vpe),e(Vpe,cHo),e(Jv,fHo),e(Jv,EX),e(EX,mHo),e(Jv,gHo),e(V,hHo),e(V,Yv),e(Yv,Xpe),e(Xpe,pHo),e(Yv,_Ho),e(Yv,CX),e(CX,uHo),e(Yv,bHo),e(V,vHo),e(V,Kv),e(Kv,zpe),e(zpe,FHo),e(Kv,THo),e(Kv,wX),e(wX,MHo),e(Kv,EHo),e(V,CHo),e(V,Zv),e(Zv,Wpe),e(Wpe,wHo),e(Zv,AHo),e(Zv,AX),e(AX,yHo),e(Zv,LHo),e(V,xHo),e(V,e5),e(e5,Qpe),e(Qpe,$Ho),e(e5,kHo),e(e5,yX),e(yX,SHo),e(e5,RHo),e(V,PHo),e(V,o5),e(o5,Hpe),e(Hpe,BHo),e(o5,IHo),e(o5,LX),e(LX,NHo),e(o5,qHo),e(V,jHo),e(V,r5),e(r5,Upe),e(Upe,DHo),e(r5,GHo),e(r5,xX),e(xX,OHo),e(r5,VHo),e(no,XHo),e(no,t5),e(t5,zHo),e(t5,Jpe),e(Jpe,WHo),e(t5,QHo),e(t5,Ype),e(Ype,HHo),e(no,UHo),M(a5,no,null),b(f,pje,u),b(f,td,u),e(td,n5),e(n5,Kpe),M(aL,Kpe,null),e(td,JHo),e(td,Zpe),e(Zpe,YHo),b(f,_je,u),b(f,qo,u),M(nL,qo,null),e(qo,KHo),e(qo,ad),e(ad,ZHo),e(ad,$X),e($X,eUo),e(ad,oUo),e(ad,kX),e(kX,rUo),e(ad,tUo),e(qo,aUo),e(qo,sL),e(sL,nUo),e(sL,e_e),e(e_e,sUo),e(sL,lUo),e(qo,iUo),e(qo,gt),M(lL,gt,null),e(gt,dUo),e(gt,o_e),e(o_e,cUo),e(gt,fUo),e(gt,nd),e(nd,mUo),e(nd,r_e),e(r_e,gUo),e(nd,hUo),e(nd,SX),e(SX,pUo),e(nd,_Uo),e(gt,uUo),M(s5,gt,null),e(qo,bUo),e(qo,so),M(iL,so,null),e(so,vUo),e(so,t_e),e(t_e,FUo),e(so,TUo),e(so,qa),e(qa,MUo),e(qa,a_e),e(a_e,EUo),e(qa,CUo),e(qa,n_e),e(n_e,wUo),e(qa,AUo),e(qa,s_e),e(s_e,yUo),e(qa,LUo),e(so,xUo),e(so,l_e),e(l_e,l5),e(l5,i_e),e(i_e,$Uo),e(l5,kUo),e(l5,RX),e(RX,SUo),e(l5,RUo),e(so,PUo),e(so,i5),e(i5,BUo),e(i5,d_e),e(d_e,IUo),e(i5,NUo),e(i5,c_e),e(c_e,qUo),e(so,jUo),M(d5,so,null),b(f,uje,u),b(f,sd,u),e(sd,c5),e(c5,f_e),M(dL,f_e,null),e(sd,DUo),e(sd,m_e),e(m_e,GUo),b(f,bje,u),b(f,jo,u),M(cL,jo,null),e(jo,OUo),e(jo,ld),e(ld,VUo),e(ld,PX),e(PX,XUo),e(ld,zUo),e(ld,BX),e(BX,WUo),e(ld,QUo),e(jo,HUo),e(jo,fL),e(fL,UUo),e(fL,g_e),e(g_e,JUo),e(fL,YUo),e(jo,KUo),e(jo,ht),M(mL,ht,null),e(ht,ZUo),e(ht,h_e),e(h_e,eJo),e(ht,oJo),e(ht,id),e(id,rJo),e(id,p_e),e(p_e,tJo),e(id,aJo),e(id,IX),e(IX,nJo),e(id,sJo),e(ht,lJo),M(f5,ht,null),e(jo,iJo),e(jo,lo),M(gL,lo,null),e(lo,dJo),e(lo,__e),e(__e,cJo),e(lo,fJo),e(lo,ja),e(ja,mJo),e(ja,u_e),e(u_e,gJo),e(ja,hJo),e(ja,b_e),e(b_e,pJo),e(ja,_Jo),e(ja,v_e),e(v_e,uJo),e(ja,bJo),e(lo,vJo),e(lo,ve),e(ve,m5),e(m5,F_e),e(F_e,FJo),e(m5,TJo),e(m5,NX),e(NX,MJo),e(m5,EJo),e(ve,CJo),e(ve,g5),e(g5,T_e),e(T_e,wJo),e(g5,AJo),e(g5,qX),e(qX,yJo),e(g5,LJo),e(ve,xJo),e(ve,h5),e(h5,M_e),e(M_e,$Jo),e(h5,kJo),e(h5,jX),e(jX,SJo),e(h5,RJo),e(ve,PJo),e(ve,p5),e(p5,E_e),e(E_e,BJo),e(p5,IJo),e(p5,DX),e(DX,NJo),e(p5,qJo),e(ve,jJo),e(ve,Is),e(Is,C_e),e(C_e,DJo),e(Is,GJo),e(Is,GX),e(GX,OJo),e(Is,VJo),e(Is,OX),e(OX,XJo),e(Is,zJo),e(ve,WJo),e(ve,_5),e(_5,w_e),e(w_e,QJo),e(_5,HJo),e(_5,VX),e(VX,UJo),e(_5,JJo),e(ve,YJo),e(ve,Ns),e(Ns,A_e),e(A_e,KJo),e(Ns,ZJo),e(Ns,XX),e(XX,eYo),e(Ns,oYo),e(Ns,zX),e(zX,rYo),e(Ns,tYo),e(ve,aYo),e(ve,pt),e(pt,y_e),e(y_e,nYo),e(pt,sYo),e(pt,WX),e(WX,lYo),e(pt,iYo),e(pt,QX),e(QX,dYo),e(pt,cYo),e(pt,HX),e(HX,fYo),e(pt,mYo),e(ve,gYo),e(ve,u5),e(u5,L_e),e(L_e,hYo),e(u5,pYo),e(u5,UX),e(UX,_Yo),e(u5,uYo),e(ve,bYo),e(ve,b5),e(b5,x_e),e(x_e,vYo),e(b5,FYo),e(b5,JX),e(JX,TYo),e(b5,MYo),e(ve,EYo),e(ve,v5),e(v5,$_e),e($_e,CYo),e(v5,wYo),e(v5,YX),e(YX,AYo),e(v5,yYo),e(ve,LYo),e(ve,F5),e(F5,k_e),e(k_e,xYo),e(F5,$Yo),e(F5,KX),e(KX,kYo),e(F5,SYo),e(ve,RYo),e(ve,T5),e(T5,S_e),e(S_e,PYo),e(T5,BYo),e(T5,ZX),e(ZX,IYo),e(T5,NYo),e(ve,qYo),e(ve,M5),e(M5,R_e),e(R_e,jYo),e(M5,DYo),e(M5,ez),e(ez,GYo),e(M5,OYo),e(ve,VYo),e(ve,E5),e(E5,P_e),e(P_e,XYo),e(E5,zYo),e(E5,oz),e(oz,WYo),e(E5,QYo),e(lo,HYo),e(lo,C5),e(C5,UYo),e(C5,B_e),e(B_e,JYo),e(C5,YYo),e(C5,I_e),e(I_e,KYo),e(lo,ZYo),M(w5,lo,null),b(f,vje,u),b(f,dd,u),e(dd,A5),e(A5,N_e),M(hL,N_e,null),e(dd,eKo),e(dd,q_e),e(q_e,oKo),b(f,Fje,u),b(f,Do,u),M(pL,Do,null),e(Do,rKo),e(Do,cd),e(cd,tKo),e(cd,rz),e(rz,aKo),e(cd,nKo),e(cd,tz),e(tz,sKo),e(cd,lKo),e(Do,iKo),e(Do,_L),e(_L,dKo),e(_L,j_e),e(j_e,cKo),e(_L,fKo),e(Do,mKo),e(Do,_t),M(uL,_t,null),e(_t,gKo),e(_t,D_e),e(D_e,hKo),e(_t,pKo),e(_t,fd),e(fd,_Ko),e(fd,G_e),e(G_e,uKo),e(fd,bKo),e(fd,az),e(az,vKo),e(fd,FKo),e(_t,TKo),M(y5,_t,null),e(Do,MKo),e(Do,io),M(bL,io,null),e(io,EKo),e(io,O_e),e(O_e,CKo),e(io,wKo),e(io,Da),e(Da,AKo),e(Da,V_e),e(V_e,yKo),e(Da,LKo),e(Da,X_e),e(X_e,xKo),e(Da,$Ko),e(Da,z_e),e(z_e,kKo),e(Da,SKo),e(io,RKo),e(io,W_e),e(W_e,L5),e(L5,Q_e),e(Q_e,PKo),e(L5,BKo),e(L5,nz),e(nz,IKo),e(L5,NKo),e(io,qKo),e(io,x5),e(x5,jKo),e(x5,H_e),e(H_e,DKo),e(x5,GKo),e(x5,U_e),e(U_e,OKo),e(io,VKo),M($5,io,null),b(f,Tje,u),b(f,md,u),e(md,k5),e(k5,J_e),M(vL,J_e,null),e(md,XKo),e(md,Y_e),e(Y_e,zKo),b(f,Mje,u),b(f,Go,u),M(FL,Go,null),e(Go,WKo),e(Go,gd),e(gd,QKo),e(gd,sz),e(sz,HKo),e(gd,UKo),e(gd,lz),e(lz,JKo),e(gd,YKo),e(Go,KKo),e(Go,TL),e(TL,ZKo),e(TL,K_e),e(K_e,eZo),e(TL,oZo),e(Go,rZo),e(Go,ut),M(ML,ut,null),e(ut,tZo),e(ut,Z_e),e(Z_e,aZo),e(ut,nZo),e(ut,hd),e(hd,sZo),e(hd,eue),e(eue,lZo),e(hd,iZo),e(hd,iz),e(iz,dZo),e(hd,cZo),e(ut,fZo),M(S5,ut,null),e(Go,mZo),e(Go,co),M(EL,co,null),e(co,gZo),e(co,oue),e(oue,hZo),e(co,pZo),e(co,Ga),e(Ga,_Zo),e(Ga,rue),e(rue,uZo),e(Ga,bZo),e(Ga,tue),e(tue,vZo),e(Ga,FZo),e(Ga,aue),e(aue,TZo),e(Ga,MZo),e(co,EZo),e(co,Se),e(Se,R5),e(R5,nue),e(nue,CZo),e(R5,wZo),e(R5,dz),e(dz,AZo),e(R5,yZo),e(Se,LZo),e(Se,P5),e(P5,sue),e(sue,xZo),e(P5,$Zo),e(P5,cz),e(cz,kZo),e(P5,SZo),e(Se,RZo),e(Se,B5),e(B5,lue),e(lue,PZo),e(B5,BZo),e(B5,fz),e(fz,IZo),e(B5,NZo),e(Se,qZo),e(Se,I5),e(I5,iue),e(iue,jZo),e(I5,DZo),e(I5,mz),e(mz,GZo),e(I5,OZo),e(Se,VZo),e(Se,N5),e(N5,due),e(due,XZo),e(N5,zZo),e(N5,gz),e(gz,WZo),e(N5,QZo),e(Se,HZo),e(Se,q5),e(q5,cue),e(cue,UZo),e(q5,JZo),e(q5,hz),e(hz,YZo),e(q5,KZo),e(Se,ZZo),e(Se,j5),e(j5,fue),e(fue,eer),e(j5,oer),e(j5,pz),e(pz,rer),e(j5,ter),e(Se,aer),e(Se,D5),e(D5,mue),e(mue,ner),e(D5,ser),e(D5,_z),e(_z,ler),e(D5,ier),e(Se,der),e(Se,G5),e(G5,gue),e(gue,cer),e(G5,fer),e(G5,uz),e(uz,mer),e(G5,ger),e(co,her),e(co,O5),e(O5,per),e(O5,hue),e(hue,_er),e(O5,uer),e(O5,pue),e(pue,ber),e(co,ver),M(V5,co,null),b(f,Eje,u),b(f,pd,u),e(pd,X5),e(X5,_ue),M(CL,_ue,null),e(pd,Fer),e(pd,uue),e(uue,Ter),b(f,Cje,u),b(f,Oo,u),M(wL,Oo,null),e(Oo,Mer),e(Oo,_d),e(_d,Eer),e(_d,bz),e(bz,Cer),e(_d,wer),e(_d,vz),e(vz,Aer),e(_d,yer),e(Oo,Ler),e(Oo,AL),e(AL,xer),e(AL,bue),e(bue,$er),e(AL,ker),e(Oo,Ser),e(Oo,bt),M(yL,bt,null),e(bt,Rer),e(bt,vue),e(vue,Per),e(bt,Ber),e(bt,ud),e(ud,Ier),e(ud,Fue),e(Fue,Ner),e(ud,qer),e(ud,Fz),e(Fz,jer),e(ud,Der),e(bt,Ger),M(z5,bt,null),e(Oo,Oer),e(Oo,fo),M(LL,fo,null),e(fo,Ver),e(fo,Tue),e(Tue,Xer),e(fo,zer),e(fo,Oa),e(Oa,Wer),e(Oa,Mue),e(Mue,Qer),e(Oa,Her),e(Oa,Eue),e(Eue,Uer),e(Oa,Jer),e(Oa,Cue),e(Cue,Yer),e(Oa,Ker),e(fo,Zer),e(fo,Kr),e(Kr,W5),e(W5,wue),e(wue,eor),e(W5,oor),e(W5,Tz),e(Tz,ror),e(W5,tor),e(Kr,aor),e(Kr,Q5),e(Q5,Aue),e(Aue,nor),e(Q5,sor),e(Q5,Mz),e(Mz,lor),e(Q5,ior),e(Kr,dor),e(Kr,H5),e(H5,yue),e(yue,cor),e(H5,mor),e(H5,Ez),e(Ez,gor),e(H5,hor),e(Kr,por),e(Kr,U5),e(U5,Lue),e(Lue,_or),e(U5,uor),e(U5,Cz),e(Cz,bor),e(U5,vor),e(Kr,For),e(Kr,J5),e(J5,xue),e(xue,Tor),e(J5,Mor),e(J5,wz),e(wz,Eor),e(J5,Cor),e(fo,wor),e(fo,Y5),e(Y5,Aor),e(Y5,$ue),e($ue,yor),e(Y5,Lor),e(Y5,kue),e(kue,xor),e(fo,$or),M(K5,fo,null),b(f,wje,u),b(f,bd,u),e(bd,Z5),e(Z5,Sue),M(xL,Sue,null),e(bd,kor),e(bd,Rue),e(Rue,Sor),b(f,Aje,u),b(f,Vo,u),M($L,Vo,null),e(Vo,Ror),e(Vo,vd),e(vd,Por),e(vd,Az),e(Az,Bor),e(vd,Ior),e(vd,yz),e(yz,Nor),e(vd,qor),e(Vo,jor),e(Vo,kL),e(kL,Dor),e(kL,Pue),e(Pue,Gor),e(kL,Oor),e(Vo,Vor),e(Vo,vt),M(SL,vt,null),e(vt,Xor),e(vt,Bue),e(Bue,zor),e(vt,Wor),e(vt,Fd),e(Fd,Qor),e(Fd,Iue),e(Iue,Hor),e(Fd,Uor),e(Fd,Lz),e(Lz,Jor),e(Fd,Yor),e(vt,Kor),M(eF,vt,null),e(Vo,Zor),e(Vo,mo),M(RL,mo,null),e(mo,err),e(mo,Nue),e(Nue,orr),e(mo,rrr),e(mo,Va),e(Va,trr),e(Va,que),e(que,arr),e(Va,nrr),e(Va,jue),e(jue,srr),e(Va,lrr),e(Va,Due),e(Due,irr),e(Va,drr),e(mo,crr),e(mo,Re),e(Re,oF),e(oF,Gue),e(Gue,frr),e(oF,mrr),e(oF,xz),e(xz,grr),e(oF,hrr),e(Re,prr),e(Re,rF),e(rF,Oue),e(Oue,_rr),e(rF,urr),e(rF,$z),e($z,brr),e(rF,vrr),e(Re,Frr),e(Re,tF),e(tF,Vue),e(Vue,Trr),e(tF,Mrr),e(tF,kz),e(kz,Err),e(tF,Crr),e(Re,wrr),e(Re,aF),e(aF,Xue),e(Xue,Arr),e(aF,yrr),e(aF,Sz),e(Sz,Lrr),e(aF,xrr),e(Re,$rr),e(Re,nF),e(nF,zue),e(zue,krr),e(nF,Srr),e(nF,Rz),e(Rz,Rrr),e(nF,Prr),e(Re,Brr),e(Re,sF),e(sF,Wue),e(Wue,Irr),e(sF,Nrr),e(sF,Pz),e(Pz,qrr),e(sF,jrr),e(Re,Drr),e(Re,lF),e(lF,Que),e(Que,Grr),e(lF,Orr),e(lF,Bz),e(Bz,Vrr),e(lF,Xrr),e(Re,zrr),e(Re,iF),e(iF,Hue),e(Hue,Wrr),e(iF,Qrr),e(iF,Iz),e(Iz,Hrr),e(iF,Urr),e(Re,Jrr),e(Re,dF),e(dF,Uue),e(Uue,Yrr),e(dF,Krr),e(dF,Nz),e(Nz,Zrr),e(dF,etr),e(mo,otr),e(mo,cF),e(cF,rtr),e(cF,Jue),e(Jue,ttr),e(cF,atr),e(cF,Yue),e(Yue,ntr),e(mo,str),M(fF,mo,null),b(f,yje,u),b(f,Td,u),e(Td,mF),e(mF,Kue),M(PL,Kue,null),e(Td,ltr),e(Td,Zue),e(Zue,itr),b(f,Lje,u),b(f,Xo,u),M(BL,Xo,null),e(Xo,dtr),e(Xo,Md),e(Md,ctr),e(Md,qz),e(qz,ftr),e(Md,mtr),e(Md,jz),e(jz,gtr),e(Md,htr),e(Xo,ptr),e(Xo,IL),e(IL,_tr),e(IL,e2e),e(e2e,utr),e(IL,btr),e(Xo,vtr),e(Xo,Ft),M(NL,Ft,null),e(Ft,Ftr),e(Ft,o2e),e(o2e,Ttr),e(Ft,Mtr),e(Ft,Ed),e(Ed,Etr),e(Ed,r2e),e(r2e,Ctr),e(Ed,wtr),e(Ed,Dz),e(Dz,Atr),e(Ed,ytr),e(Ft,Ltr),M(gF,Ft,null),e(Xo,xtr),e(Xo,go),M(qL,go,null),e(go,$tr),e(go,t2e),e(t2e,ktr),e(go,Str),e(go,Xa),e(Xa,Rtr),e(Xa,a2e),e(a2e,Ptr),e(Xa,Btr),e(Xa,n2e),e(n2e,Itr),e(Xa,Ntr),e(Xa,s2e),e(s2e,qtr),e(Xa,jtr),e(go,Dtr),e(go,jL),e(jL,hF),e(hF,l2e),e(l2e,Gtr),e(hF,Otr),e(hF,Gz),e(Gz,Vtr),e(hF,Xtr),e(jL,ztr),e(jL,pF),e(pF,i2e),e(i2e,Wtr),e(pF,Qtr),e(pF,Oz),e(Oz,Htr),e(pF,Utr),e(go,Jtr),e(go,_F),e(_F,Ytr),e(_F,d2e),e(d2e,Ktr),e(_F,Ztr),e(_F,c2e),e(c2e,ear),e(go,oar),M(uF,go,null),b(f,xje,u),b(f,Cd,u),e(Cd,bF),e(bF,f2e),M(DL,f2e,null),e(Cd,rar),e(Cd,m2e),e(m2e,tar),b(f,$je,u),b(f,zo,u),M(GL,zo,null),e(zo,aar),e(zo,wd),e(wd,nar),e(wd,Vz),e(Vz,sar),e(wd,lar),e(wd,Xz),e(Xz,iar),e(wd,dar),e(zo,car),e(zo,OL),e(OL,far),e(OL,g2e),e(g2e,mar),e(OL,gar),e(zo,har),e(zo,Tt),M(VL,Tt,null),e(Tt,par),e(Tt,h2e),e(h2e,_ar),e(Tt,uar),e(Tt,Ad),e(Ad,bar),e(Ad,p2e),e(p2e,Far),e(Ad,Tar),e(Ad,zz),e(zz,Mar),e(Ad,Ear),e(Tt,Car),M(vF,Tt,null),e(zo,war),e(zo,ho),M(XL,ho,null),e(ho,Aar),e(ho,_2e),e(_2e,yar),e(ho,Lar),e(ho,za),e(za,xar),e(za,u2e),e(u2e,$ar),e(za,kar),e(za,b2e),e(b2e,Sar),e(za,Rar),e(za,v2e),e(v2e,Par),e(za,Bar),e(ho,Iar),e(ho,Zr),e(Zr,FF),e(FF,F2e),e(F2e,Nar),e(FF,qar),e(FF,Wz),e(Wz,jar),e(FF,Dar),e(Zr,Gar),e(Zr,TF),e(TF,T2e),e(T2e,Oar),e(TF,Var),e(TF,Qz),e(Qz,Xar),e(TF,zar),e(Zr,War),e(Zr,MF),e(MF,M2e),e(M2e,Qar),e(MF,Har),e(MF,Hz),e(Hz,Uar),e(MF,Jar),e(Zr,Yar),e(Zr,EF),e(EF,E2e),e(E2e,Kar),e(EF,Zar),e(EF,Uz),e(Uz,enr),e(EF,onr),e(Zr,rnr),e(Zr,CF),e(CF,C2e),e(C2e,tnr),e(CF,anr),e(CF,Jz),e(Jz,nnr),e(CF,snr),e(ho,lnr),e(ho,wF),e(wF,inr),e(wF,w2e),e(w2e,dnr),e(wF,cnr),e(wF,A2e),e(A2e,fnr),e(ho,mnr),M(AF,ho,null),b(f,kje,u),b(f,yd,u),e(yd,yF),e(yF,y2e),M(zL,y2e,null),e(yd,gnr),e(yd,L2e),e(L2e,hnr),b(f,Sje,u),b(f,Wo,u),M(WL,Wo,null),e(Wo,pnr),e(Wo,Ld),e(Ld,_nr),e(Ld,Yz),e(Yz,unr),e(Ld,bnr),e(Ld,Kz),e(Kz,vnr),e(Ld,Fnr),e(Wo,Tnr),e(Wo,QL),e(QL,Mnr),e(QL,x2e),e(x2e,Enr),e(QL,Cnr),e(Wo,wnr),e(Wo,Mt),M(HL,Mt,null),e(Mt,Anr),e(Mt,$2e),e($2e,ynr),e(Mt,Lnr),e(Mt,xd),e(xd,xnr),e(xd,k2e),e(k2e,$nr),e(xd,knr),e(xd,Zz),e(Zz,Snr),e(xd,Rnr),e(Mt,Pnr),M(LF,Mt,null),e(Wo,Bnr),e(Wo,po),M(UL,po,null),e(po,Inr),e(po,S2e),e(S2e,Nnr),e(po,qnr),e(po,Wa),e(Wa,jnr),e(Wa,R2e),e(R2e,Dnr),e(Wa,Gnr),e(Wa,P2e),e(P2e,Onr),e(Wa,Vnr),e(Wa,B2e),e(B2e,Xnr),e(Wa,znr),e(po,Wnr),e(po,$d),e($d,xF),e(xF,I2e),e(I2e,Qnr),e(xF,Hnr),e(xF,eW),e(eW,Unr),e(xF,Jnr),e($d,Ynr),e($d,$F),e($F,N2e),e(N2e,Knr),e($F,Znr),e($F,oW),e(oW,esr),e($F,osr),e($d,rsr),e($d,kF),e(kF,q2e),e(q2e,tsr),e(kF,asr),e(kF,rW),e(rW,nsr),e(kF,ssr),e(po,lsr),e(po,SF),e(SF,isr),e(SF,j2e),e(j2e,dsr),e(SF,csr),e(SF,D2e),e(D2e,fsr),e(po,msr),M(RF,po,null),b(f,Rje,u),b(f,kd,u),e(kd,PF),e(PF,G2e),M(JL,G2e,null),e(kd,gsr),e(kd,O2e),e(O2e,hsr),b(f,Pje,u),b(f,Qo,u),M(YL,Qo,null),e(Qo,psr),e(Qo,Sd),e(Sd,_sr),e(Sd,tW),e(tW,usr),e(Sd,bsr),e(Sd,aW),e(aW,vsr),e(Sd,Fsr),e(Qo,Tsr),e(Qo,KL),e(KL,Msr),e(KL,V2e),e(V2e,Esr),e(KL,Csr),e(Qo,wsr),e(Qo,Et),M(ZL,Et,null),e(Et,Asr),e(Et,X2e),e(X2e,ysr),e(Et,Lsr),e(Et,Rd),e(Rd,xsr),e(Rd,z2e),e(z2e,$sr),e(Rd,ksr),e(Rd,nW),e(nW,Ssr),e(Rd,Rsr),e(Et,Psr),M(BF,Et,null),e(Qo,Bsr),e(Qo,_o),M(e8,_o,null),e(_o,Isr),e(_o,W2e),e(W2e,Nsr),e(_o,qsr),e(_o,Qa),e(Qa,jsr),e(Qa,Q2e),e(Q2e,Dsr),e(Qa,Gsr),e(Qa,H2e),e(H2e,Osr),e(Qa,Vsr),e(Qa,U2e),e(U2e,Xsr),e(Qa,zsr),e(_o,Wsr),e(_o,o8),e(o8,IF),e(IF,J2e),e(J2e,Qsr),e(IF,Hsr),e(IF,sW),e(sW,Usr),e(IF,Jsr),e(o8,Ysr),e(o8,NF),e(NF,Y2e),e(Y2e,Ksr),e(NF,Zsr),e(NF,lW),e(lW,elr),e(NF,olr),e(_o,rlr),e(_o,qF),e(qF,tlr),e(qF,K2e),e(K2e,alr),e(qF,nlr),e(qF,Z2e),e(Z2e,slr),e(_o,llr),M(jF,_o,null),b(f,Bje,u),b(f,Pd,u),e(Pd,DF),e(DF,e1e),M(r8,e1e,null),e(Pd,ilr),e(Pd,o1e),e(o1e,dlr),b(f,Ije,u),b(f,Ho,u),M(t8,Ho,null),e(Ho,clr),e(Ho,Bd),e(Bd,flr),e(Bd,iW),e(iW,mlr),e(Bd,glr),e(Bd,dW),e(dW,hlr),e(Bd,plr),e(Ho,_lr),e(Ho,a8),e(a8,ulr),e(a8,r1e),e(r1e,blr),e(a8,vlr),e(Ho,Flr),e(Ho,Ct),M(n8,Ct,null),e(Ct,Tlr),e(Ct,t1e),e(t1e,Mlr),e(Ct,Elr),e(Ct,Id),e(Id,Clr),e(Id,a1e),e(a1e,wlr),e(Id,Alr),e(Id,cW),e(cW,ylr),e(Id,Llr),e(Ct,xlr),M(GF,Ct,null),e(Ho,$lr),e(Ho,uo),M(s8,uo,null),e(uo,klr),e(uo,n1e),e(n1e,Slr),e(uo,Rlr),e(uo,Ha),e(Ha,Plr),e(Ha,s1e),e(s1e,Blr),e(Ha,Ilr),e(Ha,l1e),e(l1e,Nlr),e(Ha,qlr),e(Ha,i1e),e(i1e,jlr),e(Ha,Dlr),e(uo,Glr),e(uo,d1e),e(d1e,OF),e(OF,c1e),e(c1e,Olr),e(OF,Vlr),e(OF,fW),e(fW,Xlr),e(OF,zlr),e(uo,Wlr),e(uo,VF),e(VF,Qlr),e(VF,f1e),e(f1e,Hlr),e(VF,Ulr),e(VF,m1e),e(m1e,Jlr),e(uo,Ylr),M(XF,uo,null),b(f,Nje,u),b(f,Nd,u),e(Nd,zF),e(zF,g1e),M(l8,g1e,null),e(Nd,Klr),e(Nd,h1e),e(h1e,Zlr),b(f,qje,u),b(f,Uo,u),M(i8,Uo,null),e(Uo,eir),e(Uo,qd),e(qd,oir),e(qd,mW),e(mW,rir),e(qd,tir),e(qd,gW),e(gW,air),e(qd,nir),e(Uo,sir),e(Uo,d8),e(d8,lir),e(d8,p1e),e(p1e,iir),e(d8,dir),e(Uo,cir),e(Uo,wt),M(c8,wt,null),e(wt,fir),e(wt,_1e),e(_1e,mir),e(wt,gir),e(wt,jd),e(jd,hir),e(jd,u1e),e(u1e,pir),e(jd,_ir),e(jd,hW),e(hW,uir),e(jd,bir),e(wt,vir),M(WF,wt,null),e(Uo,Fir),e(Uo,bo),M(f8,bo,null),e(bo,Tir),e(bo,b1e),e(b1e,Mir),e(bo,Eir),e(bo,Ua),e(Ua,Cir),e(Ua,v1e),e(v1e,wir),e(Ua,Air),e(Ua,F1e),e(F1e,yir),e(Ua,Lir),e(Ua,T1e),e(T1e,xir),e(Ua,$ir),e(bo,kir),e(bo,Ja),e(Ja,QF),e(QF,M1e),e(M1e,Sir),e(QF,Rir),e(QF,pW),e(pW,Pir),e(QF,Bir),e(Ja,Iir),e(Ja,HF),e(HF,E1e),e(E1e,Nir),e(HF,qir),e(HF,_W),e(_W,jir),e(HF,Dir),e(Ja,Gir),e(Ja,UF),e(UF,C1e),e(C1e,Oir),e(UF,Vir),e(UF,uW),e(uW,Xir),e(UF,zir),e(Ja,Wir),e(Ja,JF),e(JF,w1e),e(w1e,Qir),e(JF,Hir),e(JF,bW),e(bW,Uir),e(JF,Jir),e(bo,Yir),e(bo,YF),e(YF,Kir),e(YF,A1e),e(A1e,Zir),e(YF,edr),e(YF,y1e),e(y1e,odr),e(bo,rdr),M(KF,bo,null),b(f,jje,u),b(f,Dd,u),e(Dd,ZF),e(ZF,L1e),M(m8,L1e,null),e(Dd,tdr),e(Dd,x1e),e(x1e,adr),b(f,Dje,u),b(f,Jo,u),M(g8,Jo,null),e(Jo,ndr),e(Jo,Gd),e(Gd,sdr),e(Gd,vW),e(vW,ldr),e(Gd,idr),e(Gd,FW),e(FW,ddr),e(Gd,cdr),e(Jo,fdr),e(Jo,h8),e(h8,mdr),e(h8,$1e),e($1e,gdr),e(h8,hdr),e(Jo,pdr),e(Jo,At),M(p8,At,null),e(At,_dr),e(At,k1e),e(k1e,udr),e(At,bdr),e(At,Od),e(Od,vdr),e(Od,S1e),e(S1e,Fdr),e(Od,Tdr),e(Od,TW),e(TW,Mdr),e(Od,Edr),e(At,Cdr),M(eT,At,null),e(Jo,wdr),e(Jo,vo),M(_8,vo,null),e(vo,Adr),e(vo,R1e),e(R1e,ydr),e(vo,Ldr),e(vo,Ya),e(Ya,xdr),e(Ya,P1e),e(P1e,$dr),e(Ya,kdr),e(Ya,B1e),e(B1e,Sdr),e(Ya,Rdr),e(Ya,I1e),e(I1e,Pdr),e(Ya,Bdr),e(vo,Idr),e(vo,N1e),e(N1e,oT),e(oT,q1e),e(q1e,Ndr),e(oT,qdr),e(oT,MW),e(MW,jdr),e(oT,Ddr),e(vo,Gdr),e(vo,rT),e(rT,Odr),e(rT,j1e),e(j1e,Vdr),e(rT,Xdr),e(rT,D1e),e(D1e,zdr),e(vo,Wdr),M(tT,vo,null),b(f,Gje,u),b(f,Vd,u),e(Vd,aT),e(aT,G1e),M(u8,G1e,null),e(Vd,Qdr),e(Vd,O1e),e(O1e,Hdr),b(f,Oje,u),b(f,Yo,u),M(b8,Yo,null),e(Yo,Udr),e(Yo,Xd),e(Xd,Jdr),e(Xd,EW),e(EW,Ydr),e(Xd,Kdr),e(Xd,CW),e(CW,Zdr),e(Xd,ecr),e(Yo,ocr),e(Yo,v8),e(v8,rcr),e(v8,V1e),e(V1e,tcr),e(v8,acr),e(Yo,ncr),e(Yo,yt),M(F8,yt,null),e(yt,scr),e(yt,X1e),e(X1e,lcr),e(yt,icr),e(yt,zd),e(zd,dcr),e(zd,z1e),e(z1e,ccr),e(zd,fcr),e(zd,wW),e(wW,mcr),e(zd,gcr),e(yt,hcr),M(nT,yt,null),e(Yo,pcr),e(Yo,wr),M(T8,wr,null),e(wr,_cr),e(wr,W1e),e(W1e,ucr),e(wr,bcr),e(wr,Ka),e(Ka,vcr),e(Ka,Q1e),e(Q1e,Fcr),e(Ka,Tcr),e(Ka,H1e),e(H1e,Mcr),e(Ka,Ecr),e(Ka,U1e),e(U1e,Ccr),e(Ka,wcr),e(wr,Acr),e(wr,q),e(q,sT),e(sT,J1e),e(J1e,ycr),e(sT,Lcr),e(sT,AW),e(AW,xcr),e(sT,$cr),e(q,kcr),e(q,lT),e(lT,Y1e),e(Y1e,Scr),e(lT,Rcr),e(lT,yW),e(yW,Pcr),e(lT,Bcr),e(q,Icr),e(q,iT),e(iT,K1e),e(K1e,Ncr),e(iT,qcr),e(iT,LW),e(LW,jcr),e(iT,Dcr),e(q,Gcr),e(q,dT),e(dT,Z1e),e(Z1e,Ocr),e(dT,Vcr),e(dT,xW),e(xW,Xcr),e(dT,zcr),e(q,Wcr),e(q,cT),e(cT,ebe),e(ebe,Qcr),e(cT,Hcr),e(cT,$W),e($W,Ucr),e(cT,Jcr),e(q,Ycr),e(q,fT),e(fT,obe),e(obe,Kcr),e(fT,Zcr),e(fT,kW),e(kW,efr),e(fT,ofr),e(q,rfr),e(q,mT),e(mT,rbe),e(rbe,tfr),e(mT,afr),e(mT,SW),e(SW,nfr),e(mT,sfr),e(q,lfr),e(q,gT),e(gT,tbe),e(tbe,ifr),e(gT,dfr),e(gT,RW),e(RW,cfr),e(gT,ffr),e(q,mfr),e(q,hT),e(hT,abe),e(abe,gfr),e(hT,hfr),e(hT,PW),e(PW,pfr),e(hT,_fr),e(q,ufr),e(q,pT),e(pT,nbe),e(nbe,bfr),e(pT,vfr),e(pT,BW),e(BW,Ffr),e(pT,Tfr),e(q,Mfr),e(q,_T),e(_T,sbe),e(sbe,Efr),e(_T,Cfr),e(_T,IW),e(IW,wfr),e(_T,Afr),e(q,yfr),e(q,uT),e(uT,lbe),e(lbe,Lfr),e(uT,xfr),e(uT,NW),e(NW,$fr),e(uT,kfr),e(q,Sfr),e(q,bT),e(bT,ibe),e(ibe,Rfr),e(bT,Pfr),e(bT,qW),e(qW,Bfr),e(bT,Ifr),e(q,Nfr),e(q,vT),e(vT,dbe),e(dbe,qfr),e(vT,jfr),e(vT,jW),e(jW,Dfr),e(vT,Gfr),e(q,Ofr),e(q,FT),e(FT,cbe),e(cbe,Vfr),e(FT,Xfr),e(FT,DW),e(DW,zfr),e(FT,Wfr),e(q,Qfr),e(q,TT),e(TT,fbe),e(fbe,Hfr),e(TT,Ufr),e(TT,GW),e(GW,Jfr),e(TT,Yfr),e(q,Kfr),e(q,MT),e(MT,mbe),e(mbe,Zfr),e(MT,emr),e(MT,OW),e(OW,omr),e(MT,rmr),e(q,tmr),e(q,qs),e(qs,gbe),e(gbe,amr),e(qs,nmr),e(qs,VW),e(VW,smr),e(qs,lmr),e(qs,XW),e(XW,imr),e(qs,dmr),e(q,cmr),e(q,ET),e(ET,hbe),e(hbe,fmr),e(ET,mmr),e(ET,zW),e(zW,gmr),e(ET,hmr),e(q,pmr),e(q,CT),e(CT,pbe),e(pbe,_mr),e(CT,umr),e(CT,WW),e(WW,bmr),e(CT,vmr),e(q,Fmr),e(q,wT),e(wT,_be),e(_be,Tmr),e(wT,Mmr),e(wT,QW),e(QW,Emr),e(wT,Cmr),e(q,wmr),e(q,AT),e(AT,ube),e(ube,Amr),e(AT,ymr),e(AT,HW),e(HW,Lmr),e(AT,xmr),e(q,$mr),e(q,yT),e(yT,bbe),e(bbe,kmr),e(yT,Smr),e(yT,UW),e(UW,Rmr),e(yT,Pmr),e(q,Bmr),e(q,LT),e(LT,vbe),e(vbe,Imr),e(LT,Nmr),e(LT,JW),e(JW,qmr),e(LT,jmr),e(q,Dmr),e(q,xT),e(xT,Fbe),e(Fbe,Gmr),e(xT,Omr),e(xT,YW),e(YW,Vmr),e(xT,Xmr),e(q,zmr),e(q,$T),e($T,Tbe),e(Tbe,Wmr),e($T,Qmr),e($T,KW),e(KW,Hmr),e($T,Umr),e(q,Jmr),e(q,kT),e(kT,Mbe),e(Mbe,Ymr),e(kT,Kmr),e(kT,ZW),e(ZW,Zmr),e(kT,egr),e(q,ogr),e(q,ST),e(ST,Ebe),e(Ebe,rgr),e(ST,tgr),e(ST,eQ),e(eQ,agr),e(ST,ngr),e(q,sgr),e(q,RT),e(RT,Cbe),e(Cbe,lgr),e(RT,igr),e(RT,oQ),e(oQ,dgr),e(RT,cgr),e(q,fgr),e(q,PT),e(PT,wbe),e(wbe,mgr),e(PT,ggr),e(PT,rQ),e(rQ,hgr),e(PT,pgr),e(q,_gr),e(q,BT),e(BT,Abe),e(Abe,ugr),e(BT,bgr),e(BT,tQ),e(tQ,vgr),e(BT,Fgr),e(q,Tgr),e(q,IT),e(IT,ybe),e(ybe,Mgr),e(IT,Egr),e(IT,aQ),e(aQ,Cgr),e(IT,wgr),e(q,Agr),e(q,NT),e(NT,Lbe),e(Lbe,ygr),e(NT,Lgr),e(NT,nQ),e(nQ,xgr),e(NT,$gr),e(q,kgr),e(q,qT),e(qT,xbe),e(xbe,Sgr),e(qT,Rgr),e(qT,sQ),e(sQ,Pgr),e(qT,Bgr),e(q,Igr),e(q,jT),e(jT,$be),e($be,Ngr),e(jT,qgr),e(jT,lQ),e(lQ,jgr),e(jT,Dgr),e(q,Ggr),e(q,DT),e(DT,kbe),e(kbe,Ogr),e(DT,Vgr),e(DT,iQ),e(iQ,Xgr),e(DT,zgr),e(q,Wgr),e(q,GT),e(GT,Sbe),e(Sbe,Qgr),e(GT,Hgr),e(GT,dQ),e(dQ,Ugr),e(GT,Jgr),e(q,Ygr),e(q,OT),e(OT,Rbe),e(Rbe,Kgr),e(OT,Zgr),e(OT,cQ),e(cQ,ehr),e(OT,ohr),e(q,rhr),e(q,VT),e(VT,Pbe),e(Pbe,thr),e(VT,ahr),e(VT,fQ),e(fQ,nhr),e(VT,shr),e(q,lhr),e(q,XT),e(XT,Bbe),e(Bbe,ihr),e(XT,dhr),e(XT,mQ),e(mQ,chr),e(XT,fhr),e(q,mhr),e(q,zT),e(zT,Ibe),e(Ibe,ghr),e(zT,hhr),e(zT,gQ),e(gQ,phr),e(zT,_hr),e(q,uhr),e(q,WT),e(WT,Nbe),e(Nbe,bhr),e(WT,vhr),e(WT,hQ),e(hQ,Fhr),e(WT,Thr),e(q,Mhr),e(q,QT),e(QT,qbe),e(qbe,Ehr),e(QT,Chr),e(QT,pQ),e(pQ,whr),e(QT,Ahr),e(q,yhr),e(q,HT),e(HT,jbe),e(jbe,Lhr),e(HT,xhr),e(HT,_Q),e(_Q,$hr),e(HT,khr),e(q,Shr),e(q,UT),e(UT,Dbe),e(Dbe,Rhr),e(UT,Phr),e(UT,uQ),e(uQ,Bhr),e(UT,Ihr),e(q,Nhr),e(q,JT),e(JT,Gbe),e(Gbe,qhr),e(JT,jhr),e(JT,bQ),e(bQ,Dhr),e(JT,Ghr),e(q,Ohr),e(q,YT),e(YT,Obe),e(Obe,Vhr),e(YT,Xhr),e(YT,vQ),e(vQ,zhr),e(YT,Whr),e(wr,Qhr),M(KT,wr,null),b(f,Vje,u),b(f,Wd,u),e(Wd,ZT),e(ZT,Vbe),M(M8,Vbe,null),e(Wd,Hhr),e(Wd,Xbe),e(Xbe,Uhr),b(f,Xje,u),b(f,Ko,u),M(E8,Ko,null),e(Ko,Jhr),e(Ko,Qd),e(Qd,Yhr),e(Qd,FQ),e(FQ,Khr),e(Qd,Zhr),e(Qd,TQ),e(TQ,epr),e(Qd,opr),e(Ko,rpr),e(Ko,C8),e(C8,tpr),e(C8,zbe),e(zbe,apr),e(C8,npr),e(Ko,spr),e(Ko,Lt),M(w8,Lt,null),e(Lt,lpr),e(Lt,Wbe),e(Wbe,ipr),e(Lt,dpr),e(Lt,Hd),e(Hd,cpr),e(Hd,Qbe),e(Qbe,fpr),e(Hd,mpr),e(Hd,MQ),e(MQ,gpr),e(Hd,hpr),e(Lt,ppr),M(e7,Lt,null),e(Ko,_pr),e(Ko,Ar),M(A8,Ar,null),e(Ar,upr),e(Ar,Hbe),e(Hbe,bpr),e(Ar,vpr),e(Ar,Za),e(Za,Fpr),e(Za,Ube),e(Ube,Tpr),e(Za,Mpr),e(Za,Jbe),e(Jbe,Epr),e(Za,Cpr),e(Za,Ybe),e(Ybe,wpr),e(Za,Apr),e(Ar,ypr),e(Ar,se),e(se,o7),e(o7,Kbe),e(Kbe,Lpr),e(o7,xpr),e(o7,EQ),e(EQ,$pr),e(o7,kpr),e(se,Spr),e(se,r7),e(r7,Zbe),e(Zbe,Rpr),e(r7,Ppr),e(r7,CQ),e(CQ,Bpr),e(r7,Ipr),e(se,Npr),e(se,t7),e(t7,e4e),e(e4e,qpr),e(t7,jpr),e(t7,wQ),e(wQ,Dpr),e(t7,Gpr),e(se,Opr),e(se,a7),e(a7,o4e),e(o4e,Vpr),e(a7,Xpr),e(a7,AQ),e(AQ,zpr),e(a7,Wpr),e(se,Qpr),e(se,n7),e(n7,r4e),e(r4e,Hpr),e(n7,Upr),e(n7,yQ),e(yQ,Jpr),e(n7,Ypr),e(se,Kpr),e(se,s7),e(s7,t4e),e(t4e,Zpr),e(s7,e_r),e(s7,LQ),e(LQ,o_r),e(s7,r_r),e(se,t_r),e(se,l7),e(l7,a4e),e(a4e,a_r),e(l7,n_r),e(l7,xQ),e(xQ,s_r),e(l7,l_r),e(se,i_r),e(se,i7),e(i7,n4e),e(n4e,d_r),e(i7,c_r),e(i7,$Q),e($Q,f_r),e(i7,m_r),e(se,g_r),e(se,d7),e(d7,s4e),e(s4e,h_r),e(d7,p_r),e(d7,kQ),e(kQ,__r),e(d7,u_r),e(se,b_r),e(se,c7),e(c7,l4e),e(l4e,v_r),e(c7,F_r),e(c7,SQ),e(SQ,T_r),e(c7,M_r),e(se,E_r),e(se,f7),e(f7,i4e),e(i4e,C_r),e(f7,w_r),e(f7,RQ),e(RQ,A_r),e(f7,y_r),e(se,L_r),e(se,m7),e(m7,d4e),e(d4e,x_r),e(m7,$_r),e(m7,PQ),e(PQ,k_r),e(m7,S_r),e(se,R_r),e(se,g7),e(g7,c4e),e(c4e,P_r),e(g7,B_r),e(g7,BQ),e(BQ,I_r),e(g7,N_r),e(se,q_r),e(se,h7),e(h7,f4e),e(f4e,j_r),e(h7,D_r),e(h7,IQ),e(IQ,G_r),e(h7,O_r),e(se,V_r),e(se,p7),e(p7,m4e),e(m4e,X_r),e(p7,z_r),e(p7,NQ),e(NQ,W_r),e(p7,Q_r),e(se,H_r),e(se,_7),e(_7,g4e),e(g4e,U_r),e(_7,J_r),e(_7,qQ),e(qQ,Y_r),e(_7,K_r),e(se,Z_r),e(se,u7),e(u7,h4e),e(h4e,eur),e(u7,our),e(u7,jQ),e(jQ,rur),e(u7,tur),e(se,aur),e(se,b7),e(b7,p4e),e(p4e,nur),e(b7,sur),e(b7,DQ),e(DQ,lur),e(b7,iur),e(se,dur),e(se,v7),e(v7,_4e),e(_4e,cur),e(v7,fur),e(v7,GQ),e(GQ,mur),e(v7,gur),e(se,hur),e(se,F7),e(F7,u4e),e(u4e,pur),e(F7,_ur),e(F7,OQ),e(OQ,uur),e(F7,bur),e(se,vur),e(se,T7),e(T7,b4e),e(b4e,Fur),e(T7,Tur),e(T7,VQ),e(VQ,Mur),e(T7,Eur),e(se,Cur),e(se,M7),e(M7,v4e),e(v4e,wur),e(M7,Aur),e(M7,XQ),e(XQ,yur),e(M7,Lur),e(se,xur),e(se,E7),e(E7,F4e),e(F4e,$ur),e(E7,kur),e(E7,zQ),e(zQ,Sur),e(E7,Rur),e(Ar,Pur),M(C7,Ar,null),b(f,zje,u),b(f,Ud,u),e(Ud,w7),e(w7,T4e),M(y8,T4e,null),e(Ud,Bur),e(Ud,M4e),e(M4e,Iur),b(f,Wje,u),b(f,Zo,u),M(L8,Zo,null),e(Zo,Nur),e(Zo,Jd),e(Jd,qur),e(Jd,WQ),e(WQ,jur),e(Jd,Dur),e(Jd,QQ),e(QQ,Gur),e(Jd,Our),e(Zo,Vur),e(Zo,x8),e(x8,Xur),e(x8,E4e),e(E4e,zur),e(x8,Wur),e(Zo,Qur),e(Zo,xt),M($8,xt,null),e(xt,Hur),e(xt,C4e),e(C4e,Uur),e(xt,Jur),e(xt,Yd),e(Yd,Yur),e(Yd,w4e),e(w4e,Kur),e(Yd,Zur),e(Yd,HQ),e(HQ,e2r),e(Yd,o2r),e(xt,r2r),M(A7,xt,null),e(Zo,t2r),e(Zo,yr),M(k8,yr,null),e(yr,a2r),e(yr,A4e),e(A4e,n2r),e(yr,s2r),e(yr,en),e(en,l2r),e(en,y4e),e(y4e,i2r),e(en,d2r),e(en,L4e),e(L4e,c2r),e(en,f2r),e(en,x4e),e(x4e,m2r),e(en,g2r),e(yr,h2r),e(yr,Me),e(Me,y7),e(y7,$4e),e($4e,p2r),e(y7,_2r),e(y7,UQ),e(UQ,u2r),e(y7,b2r),e(Me,v2r),e(Me,L7),e(L7,k4e),e(k4e,F2r),e(L7,T2r),e(L7,JQ),e(JQ,M2r),e(L7,E2r),e(Me,C2r),e(Me,x7),e(x7,S4e),e(S4e,w2r),e(x7,A2r),e(x7,YQ),e(YQ,y2r),e(x7,L2r),e(Me,x2r),e(Me,$7),e($7,R4e),e(R4e,$2r),e($7,k2r),e($7,KQ),e(KQ,S2r),e($7,R2r),e(Me,P2r),e(Me,k7),e(k7,P4e),e(P4e,B2r),e(k7,I2r),e(k7,ZQ),e(ZQ,N2r),e(k7,q2r),e(Me,j2r),e(Me,S7),e(S7,B4e),e(B4e,D2r),e(S7,G2r),e(S7,eH),e(eH,O2r),e(S7,V2r),e(Me,X2r),e(Me,R7),e(R7,I4e),e(I4e,z2r),e(R7,W2r),e(R7,oH),e(oH,Q2r),e(R7,H2r),e(Me,U2r),e(Me,P7),e(P7,N4e),e(N4e,J2r),e(P7,Y2r),e(P7,rH),e(rH,K2r),e(P7,Z2r),e(Me,e1r),e(Me,B7),e(B7,q4e),e(q4e,o1r),e(B7,r1r),e(B7,tH),e(tH,t1r),e(B7,a1r),e(Me,n1r),e(Me,I7),e(I7,j4e),e(j4e,s1r),e(I7,l1r),e(I7,aH),e(aH,i1r),e(I7,d1r),e(Me,c1r),e(Me,N7),e(N7,D4e),e(D4e,f1r),e(N7,m1r),e(N7,nH),e(nH,g1r),e(N7,h1r),e(Me,p1r),e(Me,q7),e(q7,G4e),e(G4e,_1r),e(q7,u1r),e(q7,sH),e(sH,b1r),e(q7,v1r),e(Me,F1r),e(Me,j7),e(j7,O4e),e(O4e,T1r),e(j7,M1r),e(j7,lH),e(lH,E1r),e(j7,C1r),e(yr,w1r),M(D7,yr,null),b(f,Qje,u),b(f,Kd,u),e(Kd,G7),e(G7,V4e),M(S8,V4e,null),e(Kd,A1r),e(Kd,X4e),e(X4e,y1r),b(f,Hje,u),b(f,er,u),M(R8,er,null),e(er,L1r),e(er,Zd),e(Zd,x1r),e(Zd,iH),e(iH,$1r),e(Zd,k1r),e(Zd,dH),e(dH,S1r),e(Zd,R1r),e(er,P1r),e(er,P8),e(P8,B1r),e(P8,z4e),e(z4e,I1r),e(P8,N1r),e(er,q1r),e(er,$t),M(B8,$t,null),e($t,j1r),e($t,W4e),e(W4e,D1r),e($t,G1r),e($t,ec),e(ec,O1r),e(ec,Q4e),e(Q4e,V1r),e(ec,X1r),e(ec,cH),e(cH,z1r),e(ec,W1r),e($t,Q1r),M(O7,$t,null),e(er,H1r),e(er,Lr),M(I8,Lr,null),e(Lr,U1r),e(Lr,H4e),e(H4e,J1r),e(Lr,Y1r),e(Lr,on),e(on,K1r),e(on,U4e),e(U4e,Z1r),e(on,ebr),e(on,J4e),e(J4e,obr),e(on,rbr),e(on,Y4e),e(Y4e,tbr),e(on,abr),e(Lr,nbr),e(Lr,rn),e(rn,V7),e(V7,K4e),e(K4e,sbr),e(V7,lbr),e(V7,fH),e(fH,ibr),e(V7,dbr),e(rn,cbr),e(rn,X7),e(X7,Z4e),e(Z4e,fbr),e(X7,mbr),e(X7,mH),e(mH,gbr),e(X7,hbr),e(rn,pbr),e(rn,z7),e(z7,eve),e(eve,_br),e(z7,ubr),e(z7,gH),e(gH,bbr),e(z7,vbr),e(rn,Fbr),e(rn,W7),e(W7,ove),e(ove,Tbr),e(W7,Mbr),e(W7,hH),e(hH,Ebr),e(W7,Cbr),e(Lr,wbr),M(Q7,Lr,null),b(f,Uje,u),b(f,oc,u),e(oc,H7),e(H7,rve),M(N8,rve,null),e(oc,Abr),e(oc,tve),e(tve,ybr),b(f,Jje,u),b(f,or,u),M(q8,or,null),e(or,Lbr),e(or,rc),e(rc,xbr),e(rc,pH),e(pH,$br),e(rc,kbr),e(rc,_H),e(_H,Sbr),e(rc,Rbr),e(or,Pbr),e(or,j8),e(j8,Bbr),e(j8,ave),e(ave,Ibr),e(j8,Nbr),e(or,qbr),e(or,kt),M(D8,kt,null),e(kt,jbr),e(kt,nve),e(nve,Dbr),e(kt,Gbr),e(kt,tc),e(tc,Obr),e(tc,sve),e(sve,Vbr),e(tc,Xbr),e(tc,uH),e(uH,zbr),e(tc,Wbr),e(kt,Qbr),M(U7,kt,null),e(or,Hbr),e(or,xr),M(G8,xr,null),e(xr,Ubr),e(xr,lve),e(lve,Jbr),e(xr,Ybr),e(xr,tn),e(tn,Kbr),e(tn,ive),e(ive,Zbr),e(tn,e4r),e(tn,dve),e(dve,o4r),e(tn,r4r),e(tn,cve),e(cve,t4r),e(tn,a4r),e(xr,n4r),e(xr,ie),e(ie,J7),e(J7,fve),e(fve,s4r),e(J7,l4r),e(J7,bH),e(bH,i4r),e(J7,d4r),e(ie,c4r),e(ie,Y7),e(Y7,mve),e(mve,f4r),e(Y7,m4r),e(Y7,vH),e(vH,g4r),e(Y7,h4r),e(ie,p4r),e(ie,K7),e(K7,gve),e(gve,_4r),e(K7,u4r),e(K7,FH),e(FH,b4r),e(K7,v4r),e(ie,F4r),e(ie,Z7),e(Z7,hve),e(hve,T4r),e(Z7,M4r),e(Z7,TH),e(TH,E4r),e(Z7,C4r),e(ie,w4r),e(ie,eM),e(eM,pve),e(pve,A4r),e(eM,y4r),e(eM,MH),e(MH,L4r),e(eM,x4r),e(ie,$4r),e(ie,oM),e(oM,_ve),e(_ve,k4r),e(oM,S4r),e(oM,EH),e(EH,R4r),e(oM,P4r),e(ie,B4r),e(ie,rM),e(rM,uve),e(uve,I4r),e(rM,N4r),e(rM,CH),e(CH,q4r),e(rM,j4r),e(ie,D4r),e(ie,tM),e(tM,bve),e(bve,G4r),e(tM,O4r),e(tM,wH),e(wH,V4r),e(tM,X4r),e(ie,z4r),e(ie,aM),e(aM,vve),e(vve,W4r),e(aM,Q4r),e(aM,AH),e(AH,H4r),e(aM,U4r),e(ie,J4r),e(ie,nM),e(nM,Fve),e(Fve,Y4r),e(nM,K4r),e(nM,yH),e(yH,Z4r),e(nM,evr),e(ie,ovr),e(ie,sM),e(sM,Tve),e(Tve,rvr),e(sM,tvr),e(sM,LH),e(LH,avr),e(sM,nvr),e(ie,svr),e(ie,lM),e(lM,Mve),e(Mve,lvr),e(lM,ivr),e(lM,xH),e(xH,dvr),e(lM,cvr),e(ie,fvr),e(ie,iM),e(iM,Eve),e(Eve,mvr),e(iM,gvr),e(iM,$H),e($H,hvr),e(iM,pvr),e(ie,_vr),e(ie,dM),e(dM,Cve),e(Cve,uvr),e(dM,bvr),e(dM,kH),e(kH,vvr),e(dM,Fvr),e(ie,Tvr),e(ie,cM),e(cM,wve),e(wve,Mvr),e(cM,Evr),e(cM,SH),e(SH,Cvr),e(cM,wvr),e(ie,Avr),e(ie,fM),e(fM,Ave),e(Ave,yvr),e(fM,Lvr),e(fM,RH),e(RH,xvr),e(fM,$vr),e(ie,kvr),e(ie,mM),e(mM,yve),e(yve,Svr),e(mM,Rvr),e(mM,PH),e(PH,Pvr),e(mM,Bvr),e(ie,Ivr),e(ie,gM),e(gM,Lve),e(Lve,Nvr),e(gM,qvr),e(gM,BH),e(BH,jvr),e(gM,Dvr),e(ie,Gvr),e(ie,hM),e(hM,xve),e(xve,Ovr),e(hM,Vvr),e(hM,IH),e(IH,Xvr),e(hM,zvr),e(ie,Wvr),e(ie,pM),e(pM,$ve),e($ve,Qvr),e(pM,Hvr),e(pM,NH),e(NH,Uvr),e(pM,Jvr),e(xr,Yvr),M(_M,xr,null),b(f,Yje,u),b(f,ac,u),e(ac,uM),e(uM,kve),M(O8,kve,null),e(ac,Kvr),e(ac,Sve),e(Sve,Zvr),b(f,Kje,u),b(f,rr,u),M(V8,rr,null),e(rr,e5r),e(rr,nc),e(nc,o5r),e(nc,qH),e(qH,r5r),e(nc,t5r),e(nc,jH),e(jH,a5r),e(nc,n5r),e(rr,s5r),e(rr,X8),e(X8,l5r),e(X8,Rve),e(Rve,i5r),e(X8,d5r),e(rr,c5r),e(rr,St),M(z8,St,null),e(St,f5r),e(St,Pve),e(Pve,m5r),e(St,g5r),e(St,sc),e(sc,h5r),e(sc,Bve),e(Bve,p5r),e(sc,_5r),e(sc,DH),e(DH,u5r),e(sc,b5r),e(St,v5r),M(bM,St,null),e(rr,F5r),e(rr,$r),M(W8,$r,null),e($r,T5r),e($r,Ive),e(Ive,M5r),e($r,E5r),e($r,an),e(an,C5r),e(an,Nve),e(Nve,w5r),e(an,A5r),e(an,qve),e(qve,y5r),e(an,L5r),e(an,jve),e(jve,x5r),e(an,$5r),e($r,k5r),e($r,ye),e(ye,vM),e(vM,Dve),e(Dve,S5r),e(vM,R5r),e(vM,GH),e(GH,P5r),e(vM,B5r),e(ye,I5r),e(ye,FM),e(FM,Gve),e(Gve,N5r),e(FM,q5r),e(FM,OH),e(OH,j5r),e(FM,D5r),e(ye,G5r),e(ye,TM),e(TM,Ove),e(Ove,O5r),e(TM,V5r),e(TM,VH),e(VH,X5r),e(TM,z5r),e(ye,W5r),e(ye,MM),e(MM,Vve),e(Vve,Q5r),e(MM,H5r),e(MM,XH),e(XH,U5r),e(MM,J5r),e(ye,Y5r),e(ye,EM),e(EM,Xve),e(Xve,K5r),e(EM,Z5r),e(EM,zH),e(zH,eFr),e(EM,oFr),e(ye,rFr),e(ye,CM),e(CM,zve),e(zve,tFr),e(CM,aFr),e(CM,WH),e(WH,nFr),e(CM,sFr),e(ye,lFr),e(ye,wM),e(wM,Wve),e(Wve,iFr),e(wM,dFr),e(wM,QH),e(QH,cFr),e(wM,fFr),e(ye,mFr),e(ye,AM),e(AM,Qve),e(Qve,gFr),e(AM,hFr),e(AM,HH),e(HH,pFr),e(AM,_Fr),e(ye,uFr),e(ye,yM),e(yM,Hve),e(Hve,bFr),e(yM,vFr),e(yM,UH),e(UH,FFr),e(yM,TFr),e(ye,MFr),e(ye,LM),e(LM,Uve),e(Uve,EFr),e(LM,CFr),e(LM,JH),e(JH,wFr),e(LM,AFr),e($r,yFr),M(xM,$r,null),b(f,Zje,u),b(f,lc,u),e(lc,$M),e($M,Jve),M(Q8,Jve,null),e(lc,LFr),e(lc,Yve),e(Yve,xFr),b(f,eDe,u),b(f,tr,u),M(H8,tr,null),e(tr,$Fr),e(tr,ic),e(ic,kFr),e(ic,YH),e(YH,SFr),e(ic,RFr),e(ic,KH),e(KH,PFr),e(ic,BFr),e(tr,IFr),e(tr,U8),e(U8,NFr),e(U8,Kve),e(Kve,qFr),e(U8,jFr),e(tr,DFr),e(tr,Rt),M(J8,Rt,null),e(Rt,GFr),e(Rt,Zve),e(Zve,OFr),e(Rt,VFr),e(Rt,dc),e(dc,XFr),e(dc,e5e),e(e5e,zFr),e(dc,WFr),e(dc,ZH),e(ZH,QFr),e(dc,HFr),e(Rt,UFr),M(kM,Rt,null),e(tr,JFr),e(tr,kr),M(Y8,kr,null),e(kr,YFr),e(kr,o5e),e(o5e,KFr),e(kr,ZFr),e(kr,nn),e(nn,eTr),e(nn,r5e),e(r5e,oTr),e(nn,rTr),e(nn,t5e),e(t5e,tTr),e(nn,aTr),e(nn,a5e),e(a5e,nTr),e(nn,sTr),e(kr,lTr),e(kr,oe),e(oe,SM),e(SM,n5e),e(n5e,iTr),e(SM,dTr),e(SM,eU),e(eU,cTr),e(SM,fTr),e(oe,mTr),e(oe,RM),e(RM,s5e),e(s5e,gTr),e(RM,hTr),e(RM,oU),e(oU,pTr),e(RM,_Tr),e(oe,uTr),e(oe,PM),e(PM,l5e),e(l5e,bTr),e(PM,vTr),e(PM,rU),e(rU,FTr),e(PM,TTr),e(oe,MTr),e(oe,BM),e(BM,i5e),e(i5e,ETr),e(BM,CTr),e(BM,tU),e(tU,wTr),e(BM,ATr),e(oe,yTr),e(oe,IM),e(IM,d5e),e(d5e,LTr),e(IM,xTr),e(IM,aU),e(aU,$Tr),e(IM,kTr),e(oe,STr),e(oe,NM),e(NM,c5e),e(c5e,RTr),e(NM,PTr),e(NM,nU),e(nU,BTr),e(NM,ITr),e(oe,NTr),e(oe,qM),e(qM,f5e),e(f5e,qTr),e(qM,jTr),e(qM,sU),e(sU,DTr),e(qM,GTr),e(oe,OTr),e(oe,jM),e(jM,m5e),e(m5e,VTr),e(jM,XTr),e(jM,lU),e(lU,zTr),e(jM,WTr),e(oe,QTr),e(oe,DM),e(DM,g5e),e(g5e,HTr),e(DM,UTr),e(DM,iU),e(iU,JTr),e(DM,YTr),e(oe,KTr),e(oe,GM),e(GM,h5e),e(h5e,ZTr),e(GM,e7r),e(GM,dU),e(dU,o7r),e(GM,r7r),e(oe,t7r),e(oe,OM),e(OM,p5e),e(p5e,a7r),e(OM,n7r),e(OM,cU),e(cU,s7r),e(OM,l7r),e(oe,i7r),e(oe,VM),e(VM,_5e),e(_5e,d7r),e(VM,c7r),e(VM,fU),e(fU,f7r),e(VM,m7r),e(oe,g7r),e(oe,XM),e(XM,u5e),e(u5e,h7r),e(XM,p7r),e(XM,mU),e(mU,_7r),e(XM,u7r),e(oe,b7r),e(oe,zM),e(zM,b5e),e(b5e,v7r),e(zM,F7r),e(zM,gU),e(gU,T7r),e(zM,M7r),e(oe,E7r),e(oe,WM),e(WM,v5e),e(v5e,C7r),e(WM,w7r),e(WM,hU),e(hU,A7r),e(WM,y7r),e(oe,L7r),e(oe,QM),e(QM,F5e),e(F5e,x7r),e(QM,$7r),e(QM,pU),e(pU,k7r),e(QM,S7r),e(oe,R7r),e(oe,HM),e(HM,T5e),e(T5e,P7r),e(HM,B7r),e(HM,_U),e(_U,I7r),e(HM,N7r),e(oe,q7r),e(oe,UM),e(UM,M5e),e(M5e,j7r),e(UM,D7r),e(UM,uU),e(uU,G7r),e(UM,O7r),e(oe,V7r),e(oe,JM),e(JM,E5e),e(E5e,X7r),e(JM,z7r),e(JM,bU),e(bU,W7r),e(JM,Q7r),e(oe,H7r),e(oe,YM),e(YM,C5e),e(C5e,U7r),e(YM,J7r),e(YM,vU),e(vU,Y7r),e(YM,K7r),e(oe,Z7r),e(oe,KM),e(KM,w5e),e(w5e,eMr),e(KM,oMr),e(KM,FU),e(FU,rMr),e(KM,tMr),e(oe,aMr),e(oe,ZM),e(ZM,A5e),e(A5e,nMr),e(ZM,sMr),e(ZM,TU),e(TU,lMr),e(ZM,iMr),e(oe,dMr),e(oe,eE),e(eE,y5e),e(y5e,cMr),e(eE,fMr),e(eE,MU),e(MU,mMr),e(eE,gMr),e(oe,hMr),e(oe,oE),e(oE,L5e),e(L5e,pMr),e(oE,_Mr),e(oE,EU),e(EU,uMr),e(oE,bMr),e(oe,vMr),e(oe,rE),e(rE,x5e),e(x5e,FMr),e(rE,TMr),e(rE,CU),e(CU,MMr),e(rE,EMr),e(oe,CMr),e(oe,tE),e(tE,$5e),e($5e,wMr),e(tE,AMr),e(tE,wU),e(wU,yMr),e(tE,LMr),e(kr,xMr),M(aE,kr,null),b(f,oDe,u),b(f,cc,u),e(cc,nE),e(nE,k5e),M(K8,k5e,null),e(cc,$Mr),e(cc,S5e),e(S5e,kMr),b(f,rDe,u),b(f,ar,u),M(Z8,ar,null),e(ar,SMr),e(ar,fc),e(fc,RMr),e(fc,AU),e(AU,PMr),e(fc,BMr),e(fc,yU),e(yU,IMr),e(fc,NMr),e(ar,qMr),e(ar,e9),e(e9,jMr),e(e9,R5e),e(R5e,DMr),e(e9,GMr),e(ar,OMr),e(ar,Pt),M(o9,Pt,null),e(Pt,VMr),e(Pt,P5e),e(P5e,XMr),e(Pt,zMr),e(Pt,mc),e(mc,WMr),e(mc,B5e),e(B5e,QMr),e(mc,HMr),e(mc,LU),e(LU,UMr),e(mc,JMr),e(Pt,YMr),M(sE,Pt,null),e(ar,KMr),e(ar,Sr),M(r9,Sr,null),e(Sr,ZMr),e(Sr,I5e),e(I5e,eEr),e(Sr,oEr),e(Sr,sn),e(sn,rEr),e(sn,N5e),e(N5e,tEr),e(sn,aEr),e(sn,q5e),e(q5e,nEr),e(sn,sEr),e(sn,j5e),e(j5e,lEr),e(sn,iEr),e(Sr,dEr),e(Sr,pe),e(pe,lE),e(lE,D5e),e(D5e,cEr),e(lE,fEr),e(lE,xU),e(xU,mEr),e(lE,gEr),e(pe,hEr),e(pe,iE),e(iE,G5e),e(G5e,pEr),e(iE,_Er),e(iE,$U),e($U,uEr),e(iE,bEr),e(pe,vEr),e(pe,dE),e(dE,O5e),e(O5e,FEr),e(dE,TEr),e(dE,kU),e(kU,MEr),e(dE,EEr),e(pe,CEr),e(pe,cE),e(cE,V5e),e(V5e,wEr),e(cE,AEr),e(cE,SU),e(SU,yEr),e(cE,LEr),e(pe,xEr),e(pe,fE),e(fE,X5e),e(X5e,$Er),e(fE,kEr),e(fE,RU),e(RU,SEr),e(fE,REr),e(pe,PEr),e(pe,mE),e(mE,z5e),e(z5e,BEr),e(mE,IEr),e(mE,PU),e(PU,NEr),e(mE,qEr),e(pe,jEr),e(pe,gE),e(gE,W5e),e(W5e,DEr),e(gE,GEr),e(gE,BU),e(BU,OEr),e(gE,VEr),e(pe,XEr),e(pe,hE),e(hE,Q5e),e(Q5e,zEr),e(hE,WEr),e(hE,IU),e(IU,QEr),e(hE,HEr),e(pe,UEr),e(pe,pE),e(pE,H5e),e(H5e,JEr),e(pE,YEr),e(pE,NU),e(NU,KEr),e(pE,ZEr),e(pe,eCr),e(pe,_E),e(_E,U5e),e(U5e,oCr),e(_E,rCr),e(_E,qU),e(qU,tCr),e(_E,aCr),e(pe,nCr),e(pe,uE),e(uE,J5e),e(J5e,sCr),e(uE,lCr),e(uE,jU),e(jU,iCr),e(uE,dCr),e(pe,cCr),e(pe,bE),e(bE,Y5e),e(Y5e,fCr),e(bE,mCr),e(bE,DU),e(DU,gCr),e(bE,hCr),e(pe,pCr),e(pe,vE),e(vE,K5e),e(K5e,_Cr),e(vE,uCr),e(vE,GU),e(GU,bCr),e(vE,vCr),e(pe,FCr),e(pe,FE),e(FE,Z5e),e(Z5e,TCr),e(FE,MCr),e(FE,OU),e(OU,ECr),e(FE,CCr),e(pe,wCr),e(pe,TE),e(TE,eFe),e(eFe,ACr),e(TE,yCr),e(TE,VU),e(VU,LCr),e(TE,xCr),e(pe,$Cr),e(pe,ME),e(ME,oFe),e(oFe,kCr),e(ME,SCr),e(ME,XU),e(XU,RCr),e(ME,PCr),e(pe,BCr),e(pe,EE),e(EE,rFe),e(rFe,ICr),e(EE,NCr),e(EE,zU),e(zU,qCr),e(EE,jCr),e(Sr,DCr),M(CE,Sr,null),b(f,tDe,u),b(f,gc,u),e(gc,wE),e(wE,tFe),M(t9,tFe,null),e(gc,GCr),e(gc,aFe),e(aFe,OCr),b(f,aDe,u),b(f,nr,u),M(a9,nr,null),e(nr,VCr),e(nr,hc),e(hc,XCr),e(hc,WU),e(WU,zCr),e(hc,WCr),e(hc,QU),e(QU,QCr),e(hc,HCr),e(nr,UCr),e(nr,n9),e(n9,JCr),e(n9,nFe),e(nFe,YCr),e(n9,KCr),e(nr,ZCr),e(nr,Bt),M(s9,Bt,null),e(Bt,e3r),e(Bt,sFe),e(sFe,o3r),e(Bt,r3r),e(Bt,pc),e(pc,t3r),e(pc,lFe),e(lFe,a3r),e(pc,n3r),e(pc,HU),e(HU,s3r),e(pc,l3r),e(Bt,i3r),M(AE,Bt,null),e(nr,d3r),e(nr,Rr),M(l9,Rr,null),e(Rr,c3r),e(Rr,iFe),e(iFe,f3r),e(Rr,m3r),e(Rr,ln),e(ln,g3r),e(ln,dFe),e(dFe,h3r),e(ln,p3r),e(ln,cFe),e(cFe,_3r),e(ln,u3r),e(ln,fFe),e(fFe,b3r),e(ln,v3r),e(Rr,F3r),e(Rr,i9),e(i9,yE),e(yE,mFe),e(mFe,T3r),e(yE,M3r),e(yE,UU),e(UU,E3r),e(yE,C3r),e(i9,w3r),e(i9,LE),e(LE,gFe),e(gFe,A3r),e(LE,y3r),e(LE,JU),e(JU,L3r),e(LE,x3r),e(Rr,$3r),M(xE,Rr,null),b(f,nDe,u),b(f,_c,u),e(_c,$E),e($E,hFe),M(d9,hFe,null),e(_c,k3r),e(_c,pFe),e(pFe,S3r),b(f,sDe,u),b(f,sr,u),M(c9,sr,null),e(sr,R3r),e(sr,uc),e(uc,P3r),e(uc,YU),e(YU,B3r),e(uc,I3r),e(uc,KU),e(KU,N3r),e(uc,q3r),e(sr,j3r),e(sr,f9),e(f9,D3r),e(f9,_Fe),e(_Fe,G3r),e(f9,O3r),e(sr,V3r),e(sr,It),M(m9,It,null),e(It,X3r),e(It,uFe),e(uFe,z3r),e(It,W3r),e(It,bc),e(bc,Q3r),e(bc,bFe),e(bFe,H3r),e(bc,U3r),e(bc,ZU),e(ZU,J3r),e(bc,Y3r),e(It,K3r),M(kE,It,null),e(sr,Z3r),e(sr,Pr),M(g9,Pr,null),e(Pr,e0r),e(Pr,vFe),e(vFe,o0r),e(Pr,r0r),e(Pr,dn),e(dn,t0r),e(dn,FFe),e(FFe,a0r),e(dn,n0r),e(dn,TFe),e(TFe,s0r),e(dn,l0r),e(dn,MFe),e(MFe,i0r),e(dn,d0r),e(Pr,c0r),e(Pr,EFe),e(EFe,SE),e(SE,CFe),e(CFe,f0r),e(SE,m0r),e(SE,eJ),e(eJ,g0r),e(SE,h0r),e(Pr,p0r),M(RE,Pr,null),b(f,lDe,u),b(f,vc,u),e(vc,PE),e(PE,wFe),M(h9,wFe,null),e(vc,_0r),e(vc,AFe),e(AFe,u0r),b(f,iDe,u),b(f,lr,u),M(p9,lr,null),e(lr,b0r),e(lr,Fc),e(Fc,v0r),e(Fc,oJ),e(oJ,F0r),e(Fc,T0r),e(Fc,rJ),e(rJ,M0r),e(Fc,E0r),e(lr,C0r),e(lr,_9),e(_9,w0r),e(_9,yFe),e(yFe,A0r),e(_9,y0r),e(lr,L0r),e(lr,Nt),M(u9,Nt,null),e(Nt,x0r),e(Nt,LFe),e(LFe,$0r),e(Nt,k0r),e(Nt,Tc),e(Tc,S0r),e(Tc,xFe),e(xFe,R0r),e(Tc,P0r),e(Tc,tJ),e(tJ,B0r),e(Tc,I0r),e(Nt,N0r),M(BE,Nt,null),e(lr,q0r),e(lr,Br),M(b9,Br,null),e(Br,j0r),e(Br,$Fe),e($Fe,D0r),e(Br,G0r),e(Br,cn),e(cn,O0r),e(cn,kFe),e(kFe,V0r),e(cn,X0r),e(cn,SFe),e(SFe,z0r),e(cn,W0r),e(cn,RFe),e(RFe,Q0r),e(cn,H0r),e(Br,U0r),e(Br,de),e(de,IE),e(IE,PFe),e(PFe,J0r),e(IE,Y0r),e(IE,aJ),e(aJ,K0r),e(IE,Z0r),e(de,ewr),e(de,NE),e(NE,BFe),e(BFe,owr),e(NE,rwr),e(NE,nJ),e(nJ,twr),e(NE,awr),e(de,nwr),e(de,qE),e(qE,IFe),e(IFe,swr),e(qE,lwr),e(qE,sJ),e(sJ,iwr),e(qE,dwr),e(de,cwr),e(de,jE),e(jE,NFe),e(NFe,fwr),e(jE,mwr),e(jE,lJ),e(lJ,gwr),e(jE,hwr),e(de,pwr),e(de,DE),e(DE,qFe),e(qFe,_wr),e(DE,uwr),e(DE,iJ),e(iJ,bwr),e(DE,vwr),e(de,Fwr),e(de,GE),e(GE,jFe),e(jFe,Twr),e(GE,Mwr),e(GE,dJ),e(dJ,Ewr),e(GE,Cwr),e(de,wwr),e(de,OE),e(OE,DFe),e(DFe,Awr),e(OE,ywr),e(OE,cJ),e(cJ,Lwr),e(OE,xwr),e(de,$wr),e(de,VE),e(VE,GFe),e(GFe,kwr),e(VE,Swr),e(VE,fJ),e(fJ,Rwr),e(VE,Pwr),e(de,Bwr),e(de,XE),e(XE,OFe),e(OFe,Iwr),e(XE,Nwr),e(XE,mJ),e(mJ,qwr),e(XE,jwr),e(de,Dwr),e(de,zE),e(zE,VFe),e(VFe,Gwr),e(zE,Owr),e(zE,gJ),e(gJ,Vwr),e(zE,Xwr),e(de,zwr),e(de,WE),e(WE,XFe),e(XFe,Wwr),e(WE,Qwr),e(WE,hJ),e(hJ,Hwr),e(WE,Uwr),e(de,Jwr),e(de,QE),e(QE,zFe),e(zFe,Ywr),e(QE,Kwr),e(QE,pJ),e(pJ,Zwr),e(QE,e6r),e(de,o6r),e(de,HE),e(HE,WFe),e(WFe,r6r),e(HE,t6r),e(HE,_J),e(_J,a6r),e(HE,n6r),e(de,s6r),e(de,UE),e(UE,QFe),e(QFe,l6r),e(UE,i6r),e(UE,uJ),e(uJ,d6r),e(UE,c6r),e(de,f6r),e(de,JE),e(JE,HFe),e(HFe,m6r),e(JE,g6r),e(JE,bJ),e(bJ,h6r),e(JE,p6r),e(de,_6r),e(de,YE),e(YE,UFe),e(UFe,u6r),e(YE,b6r),e(YE,vJ),e(vJ,v6r),e(YE,F6r),e(de,T6r),e(de,KE),e(KE,JFe),e(JFe,M6r),e(KE,E6r),e(KE,FJ),e(FJ,C6r),e(KE,w6r),e(de,A6r),e(de,ZE),e(ZE,YFe),e(YFe,y6r),e(ZE,L6r),e(ZE,TJ),e(TJ,x6r),e(ZE,$6r),e(de,k6r),e(de,eC),e(eC,KFe),e(KFe,S6r),e(eC,R6r),e(eC,MJ),e(MJ,P6r),e(eC,B6r),e(de,I6r),e(de,oC),e(oC,ZFe),e(ZFe,N6r),e(oC,q6r),e(oC,EJ),e(EJ,j6r),e(oC,D6r),e(Br,G6r),M(rC,Br,null),b(f,dDe,u),b(f,Mc,u),e(Mc,tC),e(tC,eTe),M(v9,eTe,null),e(Mc,O6r),e(Mc,oTe),e(oTe,V6r),b(f,cDe,u),b(f,ir,u),M(F9,ir,null),e(ir,X6r),e(ir,Ec),e(Ec,z6r),e(Ec,CJ),e(CJ,W6r),e(Ec,Q6r),e(Ec,wJ),e(wJ,H6r),e(Ec,U6r),e(ir,J6r),e(ir,T9),e(T9,Y6r),e(T9,rTe),e(rTe,K6r),e(T9,Z6r),e(ir,eAr),e(ir,qt),M(M9,qt,null),e(qt,oAr),e(qt,tTe),e(tTe,rAr),e(qt,tAr),e(qt,Cc),e(Cc,aAr),e(Cc,aTe),e(aTe,nAr),e(Cc,sAr),e(Cc,AJ),e(AJ,lAr),e(Cc,iAr),e(qt,dAr),M(aC,qt,null),e(ir,cAr),e(ir,Ir),M(E9,Ir,null),e(Ir,fAr),e(Ir,nTe),e(nTe,mAr),e(Ir,gAr),e(Ir,fn),e(fn,hAr),e(fn,sTe),e(sTe,pAr),e(fn,_Ar),e(fn,lTe),e(lTe,uAr),e(fn,bAr),e(fn,iTe),e(iTe,vAr),e(fn,FAr),e(Ir,TAr),e(Ir,ce),e(ce,nC),e(nC,dTe),e(dTe,MAr),e(nC,EAr),e(nC,yJ),e(yJ,CAr),e(nC,wAr),e(ce,AAr),e(ce,sC),e(sC,cTe),e(cTe,yAr),e(sC,LAr),e(sC,LJ),e(LJ,xAr),e(sC,$Ar),e(ce,kAr),e(ce,lC),e(lC,fTe),e(fTe,SAr),e(lC,RAr),e(lC,xJ),e(xJ,PAr),e(lC,BAr),e(ce,IAr),e(ce,iC),e(iC,mTe),e(mTe,NAr),e(iC,qAr),e(iC,$J),e($J,jAr),e(iC,DAr),e(ce,GAr),e(ce,dC),e(dC,gTe),e(gTe,OAr),e(dC,VAr),e(dC,kJ),e(kJ,XAr),e(dC,zAr),e(ce,WAr),e(ce,cC),e(cC,hTe),e(hTe,QAr),e(cC,HAr),e(cC,SJ),e(SJ,UAr),e(cC,JAr),e(ce,YAr),e(ce,fC),e(fC,pTe),e(pTe,KAr),e(fC,ZAr),e(fC,RJ),e(RJ,eyr),e(fC,oyr),e(ce,ryr),e(ce,mC),e(mC,_Te),e(_Te,tyr),e(mC,ayr),e(mC,PJ),e(PJ,nyr),e(mC,syr),e(ce,lyr),e(ce,gC),e(gC,uTe),e(uTe,iyr),e(gC,dyr),e(gC,BJ),e(BJ,cyr),e(gC,fyr),e(ce,myr),e(ce,hC),e(hC,bTe),e(bTe,gyr),e(hC,hyr),e(hC,IJ),e(IJ,pyr),e(hC,_yr),e(ce,uyr),e(ce,pC),e(pC,vTe),e(vTe,byr),e(pC,vyr),e(pC,NJ),e(NJ,Fyr),e(pC,Tyr),e(ce,Myr),e(ce,_C),e(_C,FTe),e(FTe,Eyr),e(_C,Cyr),e(_C,qJ),e(qJ,wyr),e(_C,Ayr),e(ce,yyr),e(ce,uC),e(uC,TTe),e(TTe,Lyr),e(uC,xyr),e(uC,jJ),e(jJ,$yr),e(uC,kyr),e(ce,Syr),e(ce,bC),e(bC,MTe),e(MTe,Ryr),e(bC,Pyr),e(bC,DJ),e(DJ,Byr),e(bC,Iyr),e(ce,Nyr),e(ce,vC),e(vC,ETe),e(ETe,qyr),e(vC,jyr),e(vC,GJ),e(GJ,Dyr),e(vC,Gyr),e(ce,Oyr),e(ce,FC),e(FC,CTe),e(CTe,Vyr),e(FC,Xyr),e(FC,OJ),e(OJ,zyr),e(FC,Wyr),e(ce,Qyr),e(ce,TC),e(TC,wTe),e(wTe,Hyr),e(TC,Uyr),e(TC,VJ),e(VJ,Jyr),e(TC,Yyr),e(ce,Kyr),e(ce,MC),e(MC,ATe),e(ATe,Zyr),e(MC,eLr),e(MC,XJ),e(XJ,oLr),e(MC,rLr),e(ce,tLr),e(ce,EC),e(EC,yTe),e(yTe,aLr),e(EC,nLr),e(EC,zJ),e(zJ,sLr),e(EC,lLr),e(ce,iLr),e(ce,CC),e(CC,LTe),e(LTe,dLr),e(CC,cLr),e(CC,WJ),e(WJ,fLr),e(CC,mLr),e(Ir,gLr),M(wC,Ir,null),b(f,fDe,u),b(f,wc,u),e(wc,AC),e(AC,xTe),M(C9,xTe,null),e(wc,hLr),e(wc,$Te),e($Te,pLr),b(f,mDe,u),b(f,dr,u),M(w9,dr,null),e(dr,_Lr),e(dr,Ac),e(Ac,uLr),e(Ac,QJ),e(QJ,bLr),e(Ac,vLr),e(Ac,HJ),e(HJ,FLr),e(Ac,TLr),e(dr,MLr),e(dr,A9),e(A9,ELr),e(A9,kTe),e(kTe,CLr),e(A9,wLr),e(dr,ALr),e(dr,jt),M(y9,jt,null),e(jt,yLr),e(jt,STe),e(STe,LLr),e(jt,xLr),e(jt,yc),e(yc,$Lr),e(yc,RTe),e(RTe,kLr),e(yc,SLr),e(yc,UJ),e(UJ,RLr),e(yc,PLr),e(jt,BLr),M(yC,jt,null),e(dr,ILr),e(dr,Nr),M(L9,Nr,null),e(Nr,NLr),e(Nr,PTe),e(PTe,qLr),e(Nr,jLr),e(Nr,mn),e(mn,DLr),e(mn,BTe),e(BTe,GLr),e(mn,OLr),e(mn,ITe),e(ITe,VLr),e(mn,XLr),e(mn,NTe),e(NTe,zLr),e(mn,WLr),e(Nr,QLr),e(Nr,qTe),e(qTe,LC),e(LC,jTe),e(jTe,HLr),e(LC,ULr),e(LC,JJ),e(JJ,JLr),e(LC,YLr),e(Nr,KLr),M(xC,Nr,null),b(f,gDe,u),b(f,Lc,u),e(Lc,$C),e($C,DTe),M(x9,DTe,null),e(Lc,ZLr),e(Lc,GTe),e(GTe,e8r),b(f,hDe,u),b(f,cr,u),M($9,cr,null),e(cr,o8r),e(cr,xc),e(xc,r8r),e(xc,YJ),e(YJ,t8r),e(xc,a8r),e(xc,KJ),e(KJ,n8r),e(xc,s8r),e(cr,l8r),e(cr,k9),e(k9,i8r),e(k9,OTe),e(OTe,d8r),e(k9,c8r),e(cr,f8r),e(cr,Dt),M(S9,Dt,null),e(Dt,m8r),e(Dt,VTe),e(VTe,g8r),e(Dt,h8r),e(Dt,$c),e($c,p8r),e($c,XTe),e(XTe,_8r),e($c,u8r),e($c,ZJ),e(ZJ,b8r),e($c,v8r),e(Dt,F8r),M(kC,Dt,null),e(cr,T8r),e(cr,qr),M(R9,qr,null),e(qr,M8r),e(qr,zTe),e(zTe,E8r),e(qr,C8r),e(qr,gn),e(gn,w8r),e(gn,WTe),e(WTe,A8r),e(gn,y8r),e(gn,QTe),e(QTe,L8r),e(gn,x8r),e(gn,HTe),e(HTe,$8r),e(gn,k8r),e(qr,S8r),e(qr,UTe),e(UTe,SC),e(SC,JTe),e(JTe,R8r),e(SC,P8r),e(SC,eY),e(eY,B8r),e(SC,I8r),e(qr,N8r),M(RC,qr,null),b(f,pDe,u),b(f,kc,u),e(kc,PC),e(PC,YTe),M(P9,YTe,null),e(kc,q8r),e(kc,KTe),e(KTe,j8r),b(f,_De,u),b(f,fr,u),M(B9,fr,null),e(fr,D8r),e(fr,Sc),e(Sc,G8r),e(Sc,oY),e(oY,O8r),e(Sc,V8r),e(Sc,rY),e(rY,X8r),e(Sc,z8r),e(fr,W8r),e(fr,I9),e(I9,Q8r),e(I9,ZTe),e(ZTe,H8r),e(I9,U8r),e(fr,J8r),e(fr,Gt),M(N9,Gt,null),e(Gt,Y8r),e(Gt,e7e),e(e7e,K8r),e(Gt,Z8r),e(Gt,Rc),e(Rc,e9r),e(Rc,o7e),e(o7e,o9r),e(Rc,r9r),e(Rc,tY),e(tY,t9r),e(Rc,a9r),e(Gt,n9r),M(BC,Gt,null),e(fr,s9r),e(fr,jr),M(q9,jr,null),e(jr,l9r),e(jr,r7e),e(r7e,i9r),e(jr,d9r),e(jr,hn),e(hn,c9r),e(hn,t7e),e(t7e,f9r),e(hn,m9r),e(hn,a7e),e(a7e,g9r),e(hn,h9r),e(hn,n7e),e(n7e,p9r),e(hn,_9r),e(jr,u9r),e(jr,re),e(re,IC),e(IC,s7e),e(s7e,b9r),e(IC,v9r),e(IC,aY),e(aY,F9r),e(IC,T9r),e(re,M9r),e(re,NC),e(NC,l7e),e(l7e,E9r),e(NC,C9r),e(NC,nY),e(nY,w9r),e(NC,A9r),e(re,y9r),e(re,qC),e(qC,i7e),e(i7e,L9r),e(qC,x9r),e(qC,sY),e(sY,$9r),e(qC,k9r),e(re,S9r),e(re,jC),e(jC,d7e),e(d7e,R9r),e(jC,P9r),e(jC,lY),e(lY,B9r),e(jC,I9r),e(re,N9r),e(re,DC),e(DC,c7e),e(c7e,q9r),e(DC,j9r),e(DC,iY),e(iY,D9r),e(DC,G9r),e(re,O9r),e(re,GC),e(GC,f7e),e(f7e,V9r),e(GC,X9r),e(GC,dY),e(dY,z9r),e(GC,W9r),e(re,Q9r),e(re,OC),e(OC,m7e),e(m7e,H9r),e(OC,U9r),e(OC,cY),e(cY,J9r),e(OC,Y9r),e(re,K9r),e(re,VC),e(VC,g7e),e(g7e,Z9r),e(VC,exr),e(VC,fY),e(fY,oxr),e(VC,rxr),e(re,txr),e(re,XC),e(XC,h7e),e(h7e,axr),e(XC,nxr),e(XC,mY),e(mY,sxr),e(XC,lxr),e(re,ixr),e(re,zC),e(zC,p7e),e(p7e,dxr),e(zC,cxr),e(zC,gY),e(gY,fxr),e(zC,mxr),e(re,gxr),e(re,WC),e(WC,_7e),e(_7e,hxr),e(WC,pxr),e(WC,hY),e(hY,_xr),e(WC,uxr),e(re,bxr),e(re,QC),e(QC,u7e),e(u7e,vxr),e(QC,Fxr),e(QC,pY),e(pY,Txr),e(QC,Mxr),e(re,Exr),e(re,HC),e(HC,b7e),e(b7e,Cxr),e(HC,wxr),e(HC,_Y),e(_Y,Axr),e(HC,yxr),e(re,Lxr),e(re,UC),e(UC,v7e),e(v7e,xxr),e(UC,$xr),e(UC,uY),e(uY,kxr),e(UC,Sxr),e(re,Rxr),e(re,JC),e(JC,F7e),e(F7e,Pxr),e(JC,Bxr),e(JC,bY),e(bY,Ixr),e(JC,Nxr),e(re,qxr),e(re,YC),e(YC,T7e),e(T7e,jxr),e(YC,Dxr),e(YC,vY),e(vY,Gxr),e(YC,Oxr),e(re,Vxr),e(re,KC),e(KC,M7e),e(M7e,Xxr),e(KC,zxr),e(KC,FY),e(FY,Wxr),e(KC,Qxr),e(re,Hxr),e(re,ZC),e(ZC,E7e),e(E7e,Uxr),e(ZC,Jxr),e(ZC,TY),e(TY,Yxr),e(ZC,Kxr),e(re,Zxr),e(re,e3),e(e3,C7e),e(C7e,e$r),e(e3,o$r),e(e3,MY),e(MY,r$r),e(e3,t$r),e(re,a$r),e(re,o3),e(o3,w7e),e(w7e,n$r),e(o3,s$r),e(o3,EY),e(EY,l$r),e(o3,i$r),e(re,d$r),e(re,r3),e(r3,A7e),e(A7e,c$r),e(r3,f$r),e(r3,CY),e(CY,m$r),e(r3,g$r),e(re,h$r),e(re,t3),e(t3,y7e),e(y7e,p$r),e(t3,_$r),e(t3,wY),e(wY,u$r),e(t3,b$r),e(re,v$r),e(re,a3),e(a3,L7e),e(L7e,F$r),e(a3,T$r),e(a3,AY),e(AY,M$r),e(a3,E$r),e(re,C$r),e(re,n3),e(n3,x7e),e(x7e,w$r),e(n3,A$r),e(n3,yY),e(yY,y$r),e(n3,L$r),e(re,x$r),e(re,s3),e(s3,$7e),e($7e,$$r),e(s3,k$r),e(s3,LY),e(LY,S$r),e(s3,R$r),e(re,P$r),e(re,l3),e(l3,k7e),e(k7e,B$r),e(l3,I$r),e(l3,xY),e(xY,N$r),e(l3,q$r),e(jr,j$r),M(i3,jr,null),b(f,uDe,u),b(f,Pc,u),e(Pc,d3),e(d3,S7e),M(j9,S7e,null),e(Pc,D$r),e(Pc,R7e),e(R7e,G$r),b(f,bDe,u),b(f,mr,u),M(D9,mr,null),e(mr,O$r),e(mr,Bc),e(Bc,V$r),e(Bc,$Y),e($Y,X$r),e(Bc,z$r),e(Bc,kY),e(kY,W$r),e(Bc,Q$r),e(mr,H$r),e(mr,G9),e(G9,U$r),e(G9,P7e),e(P7e,J$r),e(G9,Y$r),e(mr,K$r),e(mr,Ot),M(O9,Ot,null),e(Ot,Z$r),e(Ot,B7e),e(B7e,ekr),e(Ot,okr),e(Ot,Ic),e(Ic,rkr),e(Ic,I7e),e(I7e,tkr),e(Ic,akr),e(Ic,SY),e(SY,nkr),e(Ic,skr),e(Ot,lkr),M(c3,Ot,null),e(mr,ikr),e(mr,Dr),M(V9,Dr,null),e(Dr,dkr),e(Dr,N7e),e(N7e,ckr),e(Dr,fkr),e(Dr,pn),e(pn,mkr),e(pn,q7e),e(q7e,gkr),e(pn,hkr),e(pn,j7e),e(j7e,pkr),e(pn,_kr),e(pn,D7e),e(D7e,ukr),e(pn,bkr),e(Dr,vkr),e(Dr,Le),e(Le,f3),e(f3,G7e),e(G7e,Fkr),e(f3,Tkr),e(f3,RY),e(RY,Mkr),e(f3,Ekr),e(Le,Ckr),e(Le,m3),e(m3,O7e),e(O7e,wkr),e(m3,Akr),e(m3,PY),e(PY,ykr),e(m3,Lkr),e(Le,xkr),e(Le,g3),e(g3,V7e),e(V7e,$kr),e(g3,kkr),e(g3,BY),e(BY,Skr),e(g3,Rkr),e(Le,Pkr),e(Le,h3),e(h3,X7e),e(X7e,Bkr),e(h3,Ikr),e(h3,IY),e(IY,Nkr),e(h3,qkr),e(Le,jkr),e(Le,p3),e(p3,z7e),e(z7e,Dkr),e(p3,Gkr),e(p3,NY),e(NY,Okr),e(p3,Vkr),e(Le,Xkr),e(Le,_3),e(_3,W7e),e(W7e,zkr),e(_3,Wkr),e(_3,qY),e(qY,Qkr),e(_3,Hkr),e(Le,Ukr),e(Le,u3),e(u3,Q7e),e(Q7e,Jkr),e(u3,Ykr),e(u3,jY),e(jY,Kkr),e(u3,Zkr),e(Le,eSr),e(Le,b3),e(b3,H7e),e(H7e,oSr),e(b3,rSr),e(b3,DY),e(DY,tSr),e(b3,aSr),e(Le,nSr),e(Le,v3),e(v3,U7e),e(U7e,sSr),e(v3,lSr),e(v3,GY),e(GY,iSr),e(v3,dSr),e(Le,cSr),e(Le,F3),e(F3,J7e),e(J7e,fSr),e(F3,mSr),e(F3,OY),e(OY,gSr),e(F3,hSr),e(Dr,pSr),M(T3,Dr,null),b(f,vDe,u),b(f,Nc,u),e(Nc,M3),e(M3,Y7e),M(X9,Y7e,null),e(Nc,_Sr),e(Nc,K7e),e(K7e,uSr),b(f,FDe,u),b(f,gr,u),M(z9,gr,null),e(gr,bSr),e(gr,qc),e(qc,vSr),e(qc,VY),e(VY,FSr),e(qc,TSr),e(qc,XY),e(XY,MSr),e(qc,ESr),e(gr,CSr),e(gr,W9),e(W9,wSr),e(W9,Z7e),e(Z7e,ASr),e(W9,ySr),e(gr,LSr),e(gr,Vt),M(Q9,Vt,null),e(Vt,xSr),e(Vt,eMe),e(eMe,$Sr),e(Vt,kSr),e(Vt,jc),e(jc,SSr),e(jc,oMe),e(oMe,RSr),e(jc,PSr),e(jc,zY),e(zY,BSr),e(jc,ISr),e(Vt,NSr),M(E3,Vt,null),e(gr,qSr),e(gr,Gr),M(H9,Gr,null),e(Gr,jSr),e(Gr,rMe),e(rMe,DSr),e(Gr,GSr),e(Gr,_n),e(_n,OSr),e(_n,tMe),e(tMe,VSr),e(_n,XSr),e(_n,aMe),e(aMe,zSr),e(_n,WSr),e(_n,nMe),e(nMe,QSr),e(_n,HSr),e(Gr,USr),e(Gr,Ee),e(Ee,C3),e(C3,sMe),e(sMe,JSr),e(C3,YSr),e(C3,WY),e(WY,KSr),e(C3,ZSr),e(Ee,eRr),e(Ee,w3),e(w3,lMe),e(lMe,oRr),e(w3,rRr),e(w3,QY),e(QY,tRr),e(w3,aRr),e(Ee,nRr),e(Ee,A3),e(A3,iMe),e(iMe,sRr),e(A3,lRr),e(A3,HY),e(HY,iRr),e(A3,dRr),e(Ee,cRr),e(Ee,y3),e(y3,dMe),e(dMe,fRr),e(y3,mRr),e(y3,UY),e(UY,gRr),e(y3,hRr),e(Ee,pRr),e(Ee,L3),e(L3,cMe),e(cMe,_Rr),e(L3,uRr),e(L3,JY),e(JY,bRr),e(L3,vRr),e(Ee,FRr),e(Ee,x3),e(x3,fMe),e(fMe,TRr),e(x3,MRr),e(x3,YY),e(YY,ERr),e(x3,CRr),e(Ee,wRr),e(Ee,$3),e($3,mMe),e(mMe,ARr),e($3,yRr),e($3,KY),e(KY,LRr),e($3,xRr),e(Ee,$Rr),e(Ee,k3),e(k3,gMe),e(gMe,kRr),e(k3,SRr),e(k3,ZY),e(ZY,RRr),e(k3,PRr),e(Ee,BRr),e(Ee,S3),e(S3,hMe),e(hMe,IRr),e(S3,NRr),e(S3,eK),e(eK,qRr),e(S3,jRr),e(Ee,DRr),e(Ee,R3),e(R3,pMe),e(pMe,GRr),e(R3,ORr),e(R3,oK),e(oK,VRr),e(R3,XRr),e(Ee,zRr),e(Ee,P3),e(P3,_Me),e(_Me,WRr),e(P3,QRr),e(P3,rK),e(rK,HRr),e(P3,URr),e(Ee,JRr),e(Ee,B3),e(B3,uMe),e(uMe,YRr),e(B3,KRr),e(B3,tK),e(tK,ZRr),e(B3,ePr),e(Gr,oPr),M(I3,Gr,null),b(f,TDe,u),b(f,Dc,u),e(Dc,N3),e(N3,bMe),M(U9,bMe,null),e(Dc,rPr),e(Dc,vMe),e(vMe,tPr),b(f,MDe,u),b(f,hr,u),M(J9,hr,null),e(hr,aPr),e(hr,Gc),e(Gc,nPr),e(Gc,aK),e(aK,sPr),e(Gc,lPr),e(Gc,nK),e(nK,iPr),e(Gc,dPr),e(hr,cPr),e(hr,Y9),e(Y9,fPr),e(Y9,FMe),e(FMe,mPr),e(Y9,gPr),e(hr,hPr),e(hr,Xt),M(K9,Xt,null),e(Xt,pPr),e(Xt,TMe),e(TMe,_Pr),e(Xt,uPr),e(Xt,Oc),e(Oc,bPr),e(Oc,MMe),e(MMe,vPr),e(Oc,FPr),e(Oc,sK),e(sK,TPr),e(Oc,MPr),e(Xt,EPr),M(q3,Xt,null),e(hr,CPr),e(hr,Or),M(Z9,Or,null),e(Or,wPr),e(Or,EMe),e(EMe,APr),e(Or,yPr),e(Or,un),e(un,LPr),e(un,CMe),e(CMe,xPr),e(un,$Pr),e(un,wMe),e(wMe,kPr),e(un,SPr),e(un,AMe),e(AMe,RPr),e(un,PPr),e(Or,BPr),e(Or,xe),e(xe,j3),e(j3,yMe),e(yMe,IPr),e(j3,NPr),e(j3,lK),e(lK,qPr),e(j3,jPr),e(xe,DPr),e(xe,D3),e(D3,LMe),e(LMe,GPr),e(D3,OPr),e(D3,iK),e(iK,VPr),e(D3,XPr),e(xe,zPr),e(xe,G3),e(G3,xMe),e(xMe,WPr),e(G3,QPr),e(G3,dK),e(dK,HPr),e(G3,UPr),e(xe,JPr),e(xe,O3),e(O3,$Me),e($Me,YPr),e(O3,KPr),e(O3,cK),e(cK,ZPr),e(O3,eBr),e(xe,oBr),e(xe,V3),e(V3,kMe),e(kMe,rBr),e(V3,tBr),e(V3,fK),e(fK,aBr),e(V3,nBr),e(xe,sBr),e(xe,X3),e(X3,SMe),e(SMe,lBr),e(X3,iBr),e(X3,mK),e(mK,dBr),e(X3,cBr),e(xe,fBr),e(xe,z3),e(z3,RMe),e(RMe,mBr),e(z3,gBr),e(z3,gK),e(gK,hBr),e(z3,pBr),e(xe,_Br),e(xe,W3),e(W3,PMe),e(PMe,uBr),e(W3,bBr),e(W3,hK),e(hK,vBr),e(W3,FBr),e(xe,TBr),e(xe,Q3),e(Q3,BMe),e(BMe,MBr),e(Q3,EBr),e(Q3,pK),e(pK,CBr),e(Q3,wBr),e(xe,ABr),e(xe,H3),e(H3,IMe),e(IMe,yBr),e(H3,LBr),e(H3,_K),e(_K,xBr),e(H3,$Br),e(Or,kBr),M(U3,Or,null),b(f,EDe,u),b(f,Vc,u),e(Vc,J3),e(J3,NMe),M(ex,NMe,null),e(Vc,SBr),e(Vc,qMe),e(qMe,RBr),b(f,CDe,u),b(f,pr,u),M(ox,pr,null),e(pr,PBr),e(pr,Xc),e(Xc,BBr),e(Xc,uK),e(uK,IBr),e(Xc,NBr),e(Xc,bK),e(bK,qBr),e(Xc,jBr),e(pr,DBr),e(pr,rx),e(rx,GBr),e(rx,jMe),e(jMe,OBr),e(rx,VBr),e(pr,XBr),e(pr,zt),M(tx,zt,null),e(zt,zBr),e(zt,DMe),e(DMe,WBr),e(zt,QBr),e(zt,zc),e(zc,HBr),e(zc,GMe),e(GMe,UBr),e(zc,JBr),e(zc,vK),e(vK,YBr),e(zc,KBr),e(zt,ZBr),M(Y3,zt,null),e(pr,eIr),e(pr,Vr),M(ax,Vr,null),e(Vr,oIr),e(Vr,OMe),e(OMe,rIr),e(Vr,tIr),e(Vr,bn),e(bn,aIr),e(bn,VMe),e(VMe,nIr),e(bn,sIr),e(bn,XMe),e(XMe,lIr),e(bn,iIr),e(bn,zMe),e(zMe,dIr),e(bn,cIr),e(Vr,fIr),e(Vr,Pe),e(Pe,K3),e(K3,WMe),e(WMe,mIr),e(K3,gIr),e(K3,FK),e(FK,hIr),e(K3,pIr),e(Pe,_Ir),e(Pe,Z3),e(Z3,QMe),e(QMe,uIr),e(Z3,bIr),e(Z3,TK),e(TK,vIr),e(Z3,FIr),e(Pe,TIr),e(Pe,e0),e(e0,HMe),e(HMe,MIr),e(e0,EIr),e(e0,MK),e(MK,CIr),e(e0,wIr),e(Pe,AIr),e(Pe,o0),e(o0,UMe),e(UMe,yIr),e(o0,LIr),e(o0,EK),e(EK,xIr),e(o0,$Ir),e(Pe,kIr),e(Pe,r0),e(r0,JMe),e(JMe,SIr),e(r0,RIr),e(r0,CK),e(CK,PIr),e(r0,BIr),e(Pe,IIr),e(Pe,t0),e(t0,YMe),e(YMe,NIr),e(t0,qIr),e(t0,wK),e(wK,jIr),e(t0,DIr),e(Pe,GIr),e(Pe,a0),e(a0,KMe),e(KMe,OIr),e(a0,VIr),e(a0,AK),e(AK,XIr),e(a0,zIr),e(Pe,WIr),e(Pe,n0),e(n0,ZMe),e(ZMe,QIr),e(n0,HIr),e(n0,yK),e(yK,UIr),e(n0,JIr),e(Pe,YIr),e(Pe,s0),e(s0,eEe),e(eEe,KIr),e(s0,ZIr),e(s0,LK),e(LK,eNr),e(s0,oNr),e(Vr,rNr),M(l0,Vr,null),b(f,wDe,u),b(f,Wc,u),e(Wc,i0),e(i0,oEe),M(nx,oEe,null),e(Wc,tNr),e(Wc,rEe),e(rEe,aNr),b(f,ADe,u),b(f,_r,u),M(sx,_r,null),e(_r,nNr),e(_r,Qc),e(Qc,sNr),e(Qc,xK),e(xK,lNr),e(Qc,iNr),e(Qc,$K),e($K,dNr),e(Qc,cNr),e(_r,fNr),e(_r,lx),e(lx,mNr),e(lx,tEe),e(tEe,gNr),e(lx,hNr),e(_r,pNr),e(_r,Wt),M(ix,Wt,null),e(Wt,_Nr),e(Wt,aEe),e(aEe,uNr),e(Wt,bNr),e(Wt,Hc),e(Hc,vNr),e(Hc,nEe),e(nEe,FNr),e(Hc,TNr),e(Hc,kK),e(kK,MNr),e(Hc,ENr),e(Wt,CNr),M(d0,Wt,null),e(_r,wNr),e(_r,Xr),M(dx,Xr,null),e(Xr,ANr),e(Xr,sEe),e(sEe,yNr),e(Xr,LNr),e(Xr,vn),e(vn,xNr),e(vn,lEe),e(lEe,$Nr),e(vn,kNr),e(vn,iEe),e(iEe,SNr),e(vn,RNr),e(vn,dEe),e(dEe,PNr),e(vn,BNr),e(Xr,INr),e(Xr,$e),e($e,c0),e(c0,cEe),e(cEe,NNr),e(c0,qNr),e(c0,SK),e(SK,jNr),e(c0,DNr),e($e,GNr),e($e,f0),e(f0,fEe),e(fEe,ONr),e(f0,VNr),e(f0,RK),e(RK,XNr),e(f0,zNr),e($e,WNr),e($e,m0),e(m0,mEe),e(mEe,QNr),e(m0,HNr),e(m0,PK),e(PK,UNr),e(m0,JNr),e($e,YNr),e($e,g0),e(g0,gEe),e(gEe,KNr),e(g0,ZNr),e(g0,BK),e(BK,eqr),e(g0,oqr),e($e,rqr),e($e,h0),e(h0,hEe),e(hEe,tqr),e(h0,aqr),e(h0,IK),e(IK,nqr),e(h0,sqr),e($e,lqr),e($e,p0),e(p0,pEe),e(pEe,iqr),e(p0,dqr),e(p0,NK),e(NK,cqr),e(p0,fqr),e($e,mqr),e($e,_0),e(_0,_Ee),e(_Ee,gqr),e(_0,hqr),e(_0,qK),e(qK,pqr),e(_0,_qr),e($e,uqr),e($e,u0),e(u0,uEe),e(uEe,bqr),e(u0,vqr),e(u0,jK),e(jK,Fqr),e(u0,Tqr),e($e,Mqr),e($e,b0),e(b0,bEe),e(bEe,Eqr),e(b0,Cqr),e(b0,DK),e(DK,wqr),e(b0,Aqr),e($e,yqr),e($e,v0),e(v0,vEe),e(vEe,Lqr),e(v0,xqr),e(v0,GK),e(GK,$qr),e(v0,kqr),e(Xr,Sqr),M(F0,Xr,null),b(f,yDe,u),b(f,Uc,u),e(Uc,T0),e(T0,FEe),M(cx,FEe,null),e(Uc,Rqr),e(Uc,TEe),e(TEe,Pqr),b(f,LDe,u),b(f,ur,u),M(fx,ur,null),e(ur,Bqr),e(ur,Jc),e(Jc,Iqr),e(Jc,OK),e(OK,Nqr),e(Jc,qqr),e(Jc,VK),e(VK,jqr),e(Jc,Dqr),e(ur,Gqr),e(ur,mx),e(mx,Oqr),e(mx,MEe),e(MEe,Vqr),e(mx,Xqr),e(ur,zqr),e(ur,Qt),M(gx,Qt,null),e(Qt,Wqr),e(Qt,EEe),e(EEe,Qqr),e(Qt,Hqr),e(Qt,Yc),e(Yc,Uqr),e(Yc,CEe),e(CEe,Jqr),e(Yc,Yqr),e(Yc,XK),e(XK,Kqr),e(Yc,Zqr),e(Qt,ejr),M(M0,Qt,null),e(ur,ojr),e(ur,zr),M(hx,zr,null),e(zr,rjr),e(zr,wEe),e(wEe,tjr),e(zr,ajr),e(zr,Fn),e(Fn,njr),e(Fn,AEe),e(AEe,sjr),e(Fn,ljr),e(Fn,yEe),e(yEe,ijr),e(Fn,djr),e(Fn,LEe),e(LEe,cjr),e(Fn,fjr),e(zr,mjr),e(zr,ke),e(ke,E0),e(E0,xEe),e(xEe,gjr),e(E0,hjr),e(E0,zK),e(zK,pjr),e(E0,_jr),e(ke,ujr),e(ke,C0),e(C0,$Ee),e($Ee,bjr),e(C0,vjr),e(C0,WK),e(WK,Fjr),e(C0,Tjr),e(ke,Mjr),e(ke,w0),e(w0,kEe),e(kEe,Ejr),e(w0,Cjr),e(w0,QK),e(QK,wjr),e(w0,Ajr),e(ke,yjr),e(ke,A0),e(A0,SEe),e(SEe,Ljr),e(A0,xjr),e(A0,HK),e(HK,$jr),e(A0,kjr),e(ke,Sjr),e(ke,y0),e(y0,REe),e(REe,Rjr),e(y0,Pjr),e(y0,UK),e(UK,Bjr),e(y0,Ijr),e(ke,Njr),e(ke,L0),e(L0,PEe),e(PEe,qjr),e(L0,jjr),e(L0,JK),e(JK,Djr),e(L0,Gjr),e(ke,Ojr),e(ke,x0),e(x0,BEe),e(BEe,Vjr),e(x0,Xjr),e(x0,YK),e(YK,zjr),e(x0,Wjr),e(ke,Qjr),e(ke,$0),e($0,IEe),e(IEe,Hjr),e($0,Ujr),e($0,KK),e(KK,Jjr),e($0,Yjr),e(ke,Kjr),e(ke,k0),e(k0,NEe),e(NEe,Zjr),e(k0,eDr),e(k0,ZK),e(ZK,oDr),e(k0,rDr),e(ke,tDr),e(ke,S0),e(S0,qEe),e(qEe,aDr),e(S0,nDr),e(S0,eZ),e(eZ,sDr),e(S0,lDr),e(zr,iDr),M(R0,zr,null),b(f,xDe,u),b(f,Kc,u),e(Kc,P0),e(P0,jEe),M(px,jEe,null),e(Kc,dDr),e(Kc,DEe),e(DEe,cDr),b(f,$De,u),b(f,br,u),M(_x,br,null),e(br,fDr),e(br,Zc),e(Zc,mDr),e(Zc,oZ),e(oZ,gDr),e(Zc,hDr),e(Zc,rZ),e(rZ,pDr),e(Zc,_Dr),e(br,uDr),e(br,ux),e(ux,bDr),e(ux,GEe),e(GEe,vDr),e(ux,FDr),e(br,TDr),e(br,Ht),M(bx,Ht,null),e(Ht,MDr),e(Ht,OEe),e(OEe,EDr),e(Ht,CDr),e(Ht,ef),e(ef,wDr),e(ef,VEe),e(VEe,ADr),e(ef,yDr),e(ef,tZ),e(tZ,LDr),e(ef,xDr),e(Ht,$Dr),M(B0,Ht,null),e(br,kDr),e(br,Wr),M(vx,Wr,null),e(Wr,SDr),e(Wr,XEe),e(XEe,RDr),e(Wr,PDr),e(Wr,Tn),e(Tn,BDr),e(Tn,zEe),e(zEe,IDr),e(Tn,NDr),e(Tn,WEe),e(WEe,qDr),e(Tn,jDr),e(Tn,QEe),e(QEe,DDr),e(Tn,GDr),e(Wr,ODr),e(Wr,Ge),e(Ge,I0),e(I0,HEe),e(HEe,VDr),e(I0,XDr),e(I0,aZ),e(aZ,zDr),e(I0,WDr),e(Ge,QDr),e(Ge,N0),e(N0,UEe),e(UEe,HDr),e(N0,UDr),e(N0,nZ),e(nZ,JDr),e(N0,YDr),e(Ge,KDr),e(Ge,q0),e(q0,JEe),e(JEe,ZDr),e(q0,eGr),e(q0,sZ),e(sZ,oGr),e(q0,rGr),e(Ge,tGr),e(Ge,j0),e(j0,YEe),e(YEe,aGr),e(j0,nGr),e(j0,lZ),e(lZ,sGr),e(j0,lGr),e(Ge,iGr),e(Ge,D0),e(D0,KEe),e(KEe,dGr),e(D0,cGr),e(D0,iZ),e(iZ,fGr),e(D0,mGr),e(Ge,gGr),e(Ge,G0),e(G0,ZEe),e(ZEe,hGr),e(G0,pGr),e(G0,dZ),e(dZ,_Gr),e(G0,uGr),e(Ge,bGr),e(Ge,O0),e(O0,eCe),e(eCe,vGr),e(O0,FGr),e(O0,cZ),e(cZ,TGr),e(O0,MGr),e(Ge,EGr),e(Ge,V0),e(V0,oCe),e(oCe,CGr),e(V0,wGr),e(V0,fZ),e(fZ,AGr),e(V0,yGr),e(Wr,LGr),M(X0,Wr,null),b(f,kDe,u),b(f,of,u),e(of,z0),e(z0,rCe),M(Fx,rCe,null),e(of,xGr),e(of,tCe),e(tCe,$Gr),b(f,SDe,u),b(f,vr,u),M(Tx,vr,null),e(vr,kGr),e(vr,rf),e(rf,SGr),e(rf,mZ),e(mZ,RGr),e(rf,PGr),e(rf,gZ),e(gZ,BGr),e(rf,IGr),e(vr,NGr),e(vr,Mx),e(Mx,qGr),e(Mx,aCe),e(aCe,jGr),e(Mx,DGr),e(vr,GGr),e(vr,Ut),M(Ex,Ut,null),e(Ut,OGr),e(Ut,nCe),e(nCe,VGr),e(Ut,XGr),e(Ut,tf),e(tf,zGr),e(tf,sCe),e(sCe,WGr),e(tf,QGr),e(tf,hZ),e(hZ,HGr),e(tf,UGr),e(Ut,JGr),M(W0,Ut,null),e(vr,YGr),e(vr,Qr),M(Cx,Qr,null),e(Qr,KGr),e(Qr,lCe),e(lCe,ZGr),e(Qr,eOr),e(Qr,Mn),e(Mn,oOr),e(Mn,iCe),e(iCe,rOr),e(Mn,tOr),e(Mn,dCe),e(dCe,aOr),e(Mn,nOr),e(Mn,cCe),e(cCe,sOr),e(Mn,lOr),e(Qr,iOr),e(Qr,Oe),e(Oe,Q0),e(Q0,fCe),e(fCe,dOr),e(Q0,cOr),e(Q0,pZ),e(pZ,fOr),e(Q0,mOr),e(Oe,gOr),e(Oe,H0),e(H0,mCe),e(mCe,hOr),e(H0,pOr),e(H0,_Z),e(_Z,_Or),e(H0,uOr),e(Oe,bOr),e(Oe,U0),e(U0,gCe),e(gCe,vOr),e(U0,FOr),e(U0,uZ),e(uZ,TOr),e(U0,MOr),e(Oe,EOr),e(Oe,J0),e(J0,hCe),e(hCe,COr),e(J0,wOr),e(J0,bZ),e(bZ,AOr),e(J0,yOr),e(Oe,LOr),e(Oe,Y0),e(Y0,pCe),e(pCe,xOr),e(Y0,$Or),e(Y0,vZ),e(vZ,kOr),e(Y0,SOr),e(Oe,ROr),e(Oe,K0),e(K0,_Ce),e(_Ce,POr),e(K0,BOr),e(K0,FZ),e(FZ,IOr),e(K0,NOr),e(Oe,qOr),e(Oe,Z0),e(Z0,uCe),e(uCe,jOr),e(Z0,DOr),e(Z0,TZ),e(TZ,GOr),e(Z0,OOr),e(Oe,VOr),e(Oe,ew),e(ew,bCe),e(bCe,XOr),e(ew,zOr),e(ew,MZ),e(MZ,WOr),e(ew,QOr),e(Qr,HOr),M(ow,Qr,null),b(f,RDe,u),b(f,af,u),e(af,rw),e(rw,vCe),M(wx,vCe,null),e(af,UOr),e(af,FCe),e(FCe,JOr),b(f,PDe,u),b(f,Fr,u),M(Ax,Fr,null),e(Fr,YOr),e(Fr,nf),e(nf,KOr),e(nf,EZ),e(EZ,ZOr),e(nf,eVr),e(nf,CZ),e(CZ,oVr),e(nf,rVr),e(Fr,tVr),e(Fr,yx),e(yx,aVr),e(yx,TCe),e(TCe,nVr),e(yx,sVr),e(Fr,lVr),e(Fr,Jt),M(Lx,Jt,null),e(Jt,iVr),e(Jt,MCe),e(MCe,dVr),e(Jt,cVr),e(Jt,sf),e(sf,fVr),e(sf,ECe),e(ECe,mVr),e(sf,gVr),e(sf,wZ),e(wZ,hVr),e(sf,pVr),e(Jt,_Vr),M(tw,Jt,null),e(Fr,uVr),e(Fr,Hr),M(xx,Hr,null),e(Hr,bVr),e(Hr,CCe),e(CCe,vVr),e(Hr,FVr),e(Hr,En),e(En,TVr),e(En,wCe),e(wCe,MVr),e(En,EVr),e(En,ACe),e(ACe,CVr),e(En,wVr),e(En,yCe),e(yCe,AVr),e(En,yVr),e(Hr,LVr),e(Hr,LCe),e(LCe,aw),e(aw,xCe),e(xCe,xVr),e(aw,$Vr),e(aw,AZ),e(AZ,kVr),e(aw,SVr),e(Hr,RVr),M(nw,Hr,null),b(f,BDe,u),b(f,lf,u),e(lf,sw),e(sw,$Ce),M($x,$Ce,null),e(lf,PVr),e(lf,kCe),e(kCe,BVr),b(f,IDe,u),b(f,Tr,u),M(kx,Tr,null),e(Tr,IVr),e(Tr,df),e(df,NVr),e(df,yZ),e(yZ,qVr),e(df,jVr),e(df,LZ),e(LZ,DVr),e(df,GVr),e(Tr,OVr),e(Tr,Sx),e(Sx,VVr),e(Sx,SCe),e(SCe,XVr),e(Sx,zVr),e(Tr,WVr),e(Tr,Yt),M(Rx,Yt,null),e(Yt,QVr),e(Yt,RCe),e(RCe,HVr),e(Yt,UVr),e(Yt,cf),e(cf,JVr),e(cf,PCe),e(PCe,YVr),e(cf,KVr),e(cf,xZ),e(xZ,ZVr),e(cf,eXr),e(Yt,oXr),M(lw,Yt,null),e(Tr,rXr),e(Tr,Ur),M(Px,Ur,null),e(Ur,tXr),e(Ur,BCe),e(BCe,aXr),e(Ur,nXr),e(Ur,Cn),e(Cn,sXr),e(Cn,ICe),e(ICe,lXr),e(Cn,iXr),e(Cn,NCe),e(NCe,dXr),e(Cn,cXr),e(Cn,qCe),e(qCe,fXr),e(Cn,mXr),e(Ur,gXr),e(Ur,Bx),e(Bx,iw),e(iw,jCe),e(jCe,hXr),e(iw,pXr),e(iw,$Z),e($Z,_Xr),e(iw,uXr),e(Bx,bXr),e(Bx,dw),e(dw,DCe),e(DCe,vXr),e(dw,FXr),e(dw,kZ),e(kZ,TXr),e(dw,MXr),e(Ur,EXr),M(cw,Ur,null),b(f,NDe,u),b(f,ff,u),e(ff,fw),e(fw,GCe),M(Ix,GCe,null),e(ff,CXr),e(ff,OCe),e(OCe,wXr),b(f,qDe,u),b(f,Mr,u),M(Nx,Mr,null),e(Mr,AXr),e(Mr,mf),e(mf,yXr),e(mf,SZ),e(SZ,LXr),e(mf,xXr),e(mf,RZ),e(RZ,$Xr),e(mf,kXr),e(Mr,SXr),e(Mr,qx),e(qx,RXr),e(qx,VCe),e(VCe,PXr),e(qx,BXr),e(Mr,IXr),e(Mr,Kt),M(jx,Kt,null),e(Kt,NXr),e(Kt,XCe),e(XCe,qXr),e(Kt,jXr),e(Kt,gf),e(gf,DXr),e(gf,zCe),e(zCe,GXr),e(gf,OXr),e(gf,PZ),e(PZ,VXr),e(gf,XXr),e(Kt,zXr),M(mw,Kt,null),e(Mr,WXr),e(Mr,Jr),M(Dx,Jr,null),e(Jr,QXr),e(Jr,WCe),e(WCe,HXr),e(Jr,UXr),e(Jr,wn),e(wn,JXr),e(wn,QCe),e(QCe,YXr),e(wn,KXr),e(wn,HCe),e(HCe,ZXr),e(wn,ezr),e(wn,UCe),e(UCe,ozr),e(wn,rzr),e(Jr,tzr),e(Jr,JCe),e(JCe,gw),e(gw,YCe),e(YCe,azr),e(gw,nzr),e(gw,BZ),e(BZ,szr),e(gw,lzr),e(Jr,izr),M(hw,Jr,null),jDe=!0},p(f,[u]){const Gx={};u&2&&(Gx.$$scope={dirty:u,ctx:f}),Mf.$set(Gx);const KCe={};u&2&&(KCe.$$scope={dirty:u,ctx:f}),Ag.$set(KCe);const ZCe={};u&2&&(ZCe.$$scope={dirty:u,ctx:f}),sh.$set(ZCe);const e3e={};u&2&&(e3e.$$scope={dirty:u,ctx:f}),jh.$set(e3e);const Ox={};u&2&&(Ox.$$scope={dirty:u,ctx:f}),Dh.$set(Ox);const o3e={};u&2&&(o3e.$$scope={dirty:u,ctx:f}),sp.$set(o3e);const An={};u&2&&(An.$$scope={dirty:u,ctx:f}),lp.$set(An);const r3e={};u&2&&(r3e.$$scope={dirty:u,ctx:f}),cp.$set(r3e);const t3e={};u&2&&(t3e.$$scope={dirty:u,ctx:f}),su.$set(t3e);const a3e={};u&2&&(a3e.$$scope={dirty:u,ctx:f}),iu.$set(a3e);const Vx={};u&2&&(Vx.$$scope={dirty:u,ctx:f}),Ku.$set(Vx);const n3e={};u&2&&(n3e.$$scope={dirty:u,ctx:f}),e2.$set(n3e);const Xx={};u&2&&(Xx.$$scope={dirty:u,ctx:f}),j2.$set(Xx);const s3e={};u&2&&(s3e.$$scope={dirty:u,ctx:f}),G2.$set(s3e);const zx={};u&2&&(zx.$$scope={dirty:u,ctx:f}),w1.$set(zx);const l3e={};u&2&&(l3e.$$scope={dirty:u,ctx:f}),y1.$set(l3e);const i3e={};u&2&&(i3e.$$scope={dirty:u,ctx:f}),z1.$set(i3e);const d3e={};u&2&&(d3e.$$scope={dirty:u,ctx:f}),Q1.$set(d3e);const hf={};u&2&&(hf.$$scope={dirty:u,ctx:f}),Ob.$set(hf);const c3e={};u&2&&(c3e.$$scope={dirty:u,ctx:f}),Xb.$set(c3e);const f3e={};u&2&&(f3e.$$scope={dirty:u,ctx:f}),T4.$set(f3e);const m3e={};u&2&&(m3e.$$scope={dirty:u,ctx:f}),E4.$set(m3e);const Wx={};u&2&&(Wx.$$scope={dirty:u,ctx:f}),$4.$set(Wx);const g3e={};u&2&&(g3e.$$scope={dirty:u,ctx:f}),S4.$set(g3e);const h3e={};u&2&&(h3e.$$scope={dirty:u,ctx:f}),hv.$set(h3e);const p3e={};u&2&&(p3e.$$scope={dirty:u,ctx:f}),_v.$set(p3e);const et={};u&2&&(et.$$scope={dirty:u,ctx:f}),a5.$set(et);const Qx={};u&2&&(Qx.$$scope={dirty:u,ctx:f}),s5.$set(Qx);const _3e={};u&2&&(_3e.$$scope={dirty:u,ctx:f}),d5.$set(_3e);const Hx={};u&2&&(Hx.$$scope={dirty:u,ctx:f}),f5.$set(Hx);const u3e={};u&2&&(u3e.$$scope={dirty:u,ctx:f}),w5.$set(u3e);const ot={};u&2&&(ot.$$scope={dirty:u,ctx:f}),y5.$set(ot);const b3e={};u&2&&(b3e.$$scope={dirty:u,ctx:f}),$5.$set(b3e);const pf={};u&2&&(pf.$$scope={dirty:u,ctx:f}),S5.$set(pf);const v3e={};u&2&&(v3e.$$scope={dirty:u,ctx:f}),V5.$set(v3e);const F3e={};u&2&&(F3e.$$scope={dirty:u,ctx:f}),z5.$set(F3e);const y={};u&2&&(y.$$scope={dirty:u,ctx:f}),K5.$set(y);const pw={};u&2&&(pw.$$scope={dirty:u,ctx:f}),eF.$set(pw);const T3e={};u&2&&(T3e.$$scope={dirty:u,ctx:f}),fF.$set(T3e);const M3e={};u&2&&(M3e.$$scope={dirty:u,ctx:f}),gF.$set(M3e);const _w={};u&2&&(_w.$$scope={dirty:u,ctx:f}),uF.$set(_w);const E3e={};u&2&&(E3e.$$scope={dirty:u,ctx:f}),vF.$set(E3e);const C3e={};u&2&&(C3e.$$scope={dirty:u,ctx:f}),AF.$set(C3e);const uw={};u&2&&(uw.$$scope={dirty:u,ctx:f}),LF.$set(uw);const w3e={};u&2&&(w3e.$$scope={dirty:u,ctx:f}),RF.$set(w3e);const A3e={};u&2&&(A3e.$$scope={dirty:u,ctx:f}),BF.$set(A3e);const bw={};u&2&&(bw.$$scope={dirty:u,ctx:f}),jF.$set(bw);const y3e={};u&2&&(y3e.$$scope={dirty:u,ctx:f}),GF.$set(y3e);const L3e={};u&2&&(L3e.$$scope={dirty:u,ctx:f}),XF.$set(L3e);const vw={};u&2&&(vw.$$scope={dirty:u,ctx:f}),WF.$set(vw);const x3e={};u&2&&(x3e.$$scope={dirty:u,ctx:f}),KF.$set(x3e);const $3e={};u&2&&($3e.$$scope={dirty:u,ctx:f}),eT.$set($3e);const Fw={};u&2&&(Fw.$$scope={dirty:u,ctx:f}),tT.$set(Fw);const k3e={};u&2&&(k3e.$$scope={dirty:u,ctx:f}),nT.$set(k3e);const S3e={};u&2&&(S3e.$$scope={dirty:u,ctx:f}),KT.$set(S3e);const Tw={};u&2&&(Tw.$$scope={dirty:u,ctx:f}),e7.$set(Tw);const R3e={};u&2&&(R3e.$$scope={dirty:u,ctx:f}),C7.$set(R3e);const P3e={};u&2&&(P3e.$$scope={dirty:u,ctx:f}),A7.$set(P3e);const Mw={};u&2&&(Mw.$$scope={dirty:u,ctx:f}),D7.$set(Mw);const B3e={};u&2&&(B3e.$$scope={dirty:u,ctx:f}),O7.$set(B3e);const I3e={};u&2&&(I3e.$$scope={dirty:u,ctx:f}),Q7.$set(I3e);const Ew={};u&2&&(Ew.$$scope={dirty:u,ctx:f}),U7.$set(Ew);const N3e={};u&2&&(N3e.$$scope={dirty:u,ctx:f}),_M.$set(N3e);const q3e={};u&2&&(q3e.$$scope={dirty:u,ctx:f}),bM.$set(q3e);const Cw={};u&2&&(Cw.$$scope={dirty:u,ctx:f}),xM.$set(Cw);const j3e={};u&2&&(j3e.$$scope={dirty:u,ctx:f}),kM.$set(j3e);const D3e={};u&2&&(D3e.$$scope={dirty:u,ctx:f}),aE.$set(D3e);const ww={};u&2&&(ww.$$scope={dirty:u,ctx:f}),sE.$set(ww);const G3e={};u&2&&(G3e.$$scope={dirty:u,ctx:f}),CE.$set(G3e);const O3e={};u&2&&(O3e.$$scope={dirty:u,ctx:f}),AE.$set(O3e);const Aw={};u&2&&(Aw.$$scope={dirty:u,ctx:f}),xE.$set(Aw);const V3e={};u&2&&(V3e.$$scope={dirty:u,ctx:f}),kE.$set(V3e);const X3e={};u&2&&(X3e.$$scope={dirty:u,ctx:f}),RE.$set(X3e);const yw={};u&2&&(yw.$$scope={dirty:u,ctx:f}),BE.$set(yw);const z3e={};u&2&&(z3e.$$scope={dirty:u,ctx:f}),rC.$set(z3e);const W3e={};u&2&&(W3e.$$scope={dirty:u,ctx:f}),aC.$set(W3e);const Lw={};u&2&&(Lw.$$scope={dirty:u,ctx:f}),wC.$set(Lw);const Q3e={};u&2&&(Q3e.$$scope={dirty:u,ctx:f}),yC.$set(Q3e);const H3e={};u&2&&(H3e.$$scope={dirty:u,ctx:f}),xC.$set(H3e);const xw={};u&2&&(xw.$$scope={dirty:u,ctx:f}),kC.$set(xw);const U3e={};u&2&&(U3e.$$scope={dirty:u,ctx:f}),RC.$set(U3e);const J3e={};u&2&&(J3e.$$scope={dirty:u,ctx:f}),BC.$set(J3e);const $w={};u&2&&($w.$$scope={dirty:u,ctx:f}),i3.$set($w);const Y3e={};u&2&&(Y3e.$$scope={dirty:u,ctx:f}),c3.$set(Y3e);const K3e={};u&2&&(K3e.$$scope={dirty:u,ctx:f}),T3.$set(K3e);const kw={};u&2&&(kw.$$scope={dirty:u,ctx:f}),E3.$set(kw);const Z3e={};u&2&&(Z3e.$$scope={dirty:u,ctx:f}),I3.$set(Z3e);const e0e={};u&2&&(e0e.$$scope={dirty:u,ctx:f}),q3.$set(e0e);const Sw={};u&2&&(Sw.$$scope={dirty:u,ctx:f}),U3.$set(Sw);const o0e={};u&2&&(o0e.$$scope={dirty:u,ctx:f}),Y3.$set(o0e);const r0e={};u&2&&(r0e.$$scope={dirty:u,ctx:f}),l0.$set(r0e);const Rw={};u&2&&(Rw.$$scope={dirty:u,ctx:f}),d0.$set(Rw);const t0e={};u&2&&(t0e.$$scope={dirty:u,ctx:f}),F0.$set(t0e);const a0e={};u&2&&(a0e.$$scope={dirty:u,ctx:f}),M0.$set(a0e);const Pw={};u&2&&(Pw.$$scope={dirty:u,ctx:f}),R0.$set(Pw);const n0e={};u&2&&(n0e.$$scope={dirty:u,ctx:f}),B0.$set(n0e);const s0e={};u&2&&(s0e.$$scope={dirty:u,ctx:f}),X0.$set(s0e);const Bw={};u&2&&(Bw.$$scope={dirty:u,ctx:f}),W0.$set(Bw);const l0e={};u&2&&(l0e.$$scope={dirty:u,ctx:f}),ow.$set(l0e);const i0e={};u&2&&(i0e.$$scope={dirty:u,ctx:f}),tw.$set(i0e);const Iw={};u&2&&(Iw.$$scope={dirty:u,ctx:f}),nw.$set(Iw);const d0e={};u&2&&(d0e.$$scope={dirty:u,ctx:f}),lw.$set(d0e);const c0e={};u&2&&(c0e.$$scope={dirty:u,ctx:f}),cw.$set(c0e);const Nw={};u&2&&(Nw.$$scope={dirty:u,ctx:f}),mw.$set(Nw);const f0e={};u&2&&(f0e.$$scope={dirty:u,ctx:f}),hw.$set(f0e)},i(f){jDe||(E(d.$$.fragment,f),E(Ca.$$.fragment,f),E(IA.$$.fragment,f),E(NA.$$.fragment,f),E(Mf.$$.fragment,f),E(qA.$$.fragment,f),E(jA.$$.fragment,f),E(OA.$$.fragment,f),E(Ag.$$.fragment,f),E(VA.$$.fragment,f),E(XA.$$.fragment,f),E(zA.$$.fragment,f),E(HA.$$.fragment,f),E(sh.$$.fragment,f),E(UA.$$.fragment,f),E(JA.$$.fragment,f),E(YA.$$.fragment,f),E(ey.$$.fragment,f),E(jh.$$.fragment,f),E(Dh.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(sy.$$.fragment,f),E(sp.$$.fragment,f),E(lp.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(dy.$$.fragment,f),E(fy.$$.fragment,f),E(cp.$$.fragment,f),E(my.$$.fragment,f),E(su.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(_y.$$.fragment,f),E(iu.$$.fragment,f),E(uy.$$.fragment,f),E(Ku.$$.fragment,f),E(by.$$.fragment,f),E(vy.$$.fragment,f),E(Ty.$$.fragment,f),E(e2.$$.fragment,f),E(My.$$.fragment,f),E(j2.$$.fragment,f),E(Ey.$$.fragment,f),E(Cy.$$.fragment,f),E(Ay.$$.fragment,f),E(G2.$$.fragment,f),E(yy.$$.fragment,f),E(w1.$$.fragment,f),E(Ly.$$.fragment,f),E(xy.$$.fragment,f),E(ky.$$.fragment,f),E(y1.$$.fragment,f),E(Sy.$$.fragment,f),E(z1.$$.fragment,f),E(Ry.$$.fragment,f),E(Py.$$.fragment,f),E(Iy.$$.fragment,f),E(Q1.$$.fragment,f),E(Ny.$$.fragment,f),E(Ob.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(Gy.$$.fragment,f),E(Xb.$$.fragment,f),E(Oy.$$.fragment,f),E(T4.$$.fragment,f),E(Vy.$$.fragment,f),E(Xy.$$.fragment,f),E(Wy.$$.fragment,f),E(E4.$$.fragment,f),E(Qy.$$.fragment,f),E($4.$$.fragment,f),E(Hy.$$.fragment,f),E(Uy.$$.fragment,f),E(Yy.$$.fragment,f),E(S4.$$.fragment,f),E(Ky.$$.fragment,f),E(hv.$$.fragment,f),E(Zy.$$.fragment,f),E(eL.$$.fragment,f),E(rL.$$.fragment,f),E(_v.$$.fragment,f),E(tL.$$.fragment,f),E(a5.$$.fragment,f),E(aL.$$.fragment,f),E(nL.$$.fragment,f),E(lL.$$.fragment,f),E(s5.$$.fragment,f),E(iL.$$.fragment,f),E(d5.$$.fragment,f),E(dL.$$.fragment,f),E(cL.$$.fragment,f),E(mL.$$.fragment,f),E(f5.$$.fragment,f),E(gL.$$.fragment,f),E(w5.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(uL.$$.fragment,f),E(y5.$$.fragment,f),E(bL.$$.fragment,f),E($5.$$.fragment,f),E(vL.$$.fragment,f),E(FL.$$.fragment,f),E(ML.$$.fragment,f),E(S5.$$.fragment,f),E(EL.$$.fragment,f),E(V5.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(yL.$$.fragment,f),E(z5.$$.fragment,f),E(LL.$$.fragment,f),E(K5.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(SL.$$.fragment,f),E(eF.$$.fragment,f),E(RL.$$.fragment,f),E(fF.$$.fragment,f),E(PL.$$.fragment,f),E(BL.$$.fragment,f),E(NL.$$.fragment,f),E(gF.$$.fragment,f),E(qL.$$.fragment,f),E(uF.$$.fragment,f),E(DL.$$.fragment,f),E(GL.$$.fragment,f),E(VL.$$.fragment,f),E(vF.$$.fragment,f),E(XL.$$.fragment,f),E(AF.$$.fragment,f),E(zL.$$.fragment,f),E(WL.$$.fragment,f),E(HL.$$.fragment,f),E(LF.$$.fragment,f),E(UL.$$.fragment,f),E(RF.$$.fragment,f),E(JL.$$.fragment,f),E(YL.$$.fragment,f),E(ZL.$$.fragment,f),E(BF.$$.fragment,f),E(e8.$$.fragment,f),E(jF.$$.fragment,f),E(r8.$$.fragment,f),E(t8.$$.fragment,f),E(n8.$$.fragment,f),E(GF.$$.fragment,f),E(s8.$$.fragment,f),E(XF.$$.fragment,f),E(l8.$$.fragment,f),E(i8.$$.fragment,f),E(c8.$$.fragment,f),E(WF.$$.fragment,f),E(f8.$$.fragment,f),E(KF.$$.fragment,f),E(m8.$$.fragment,f),E(g8.$$.fragment,f),E(p8.$$.fragment,f),E(eT.$$.fragment,f),E(_8.$$.fragment,f),E(tT.$$.fragment,f),E(u8.$$.fragment,f),E(b8.$$.fragment,f),E(F8.$$.fragment,f),E(nT.$$.fragment,f),E(T8.$$.fragment,f),E(KT.$$.fragment,f),E(M8.$$.fragment,f),E(E8.$$.fragment,f),E(w8.$$.fragment,f),E(e7.$$.fragment,f),E(A8.$$.fragment,f),E(C7.$$.fragment,f),E(y8.$$.fragment,f),E(L8.$$.fragment,f),E($8.$$.fragment,f),E(A7.$$.fragment,f),E(k8.$$.fragment,f),E(D7.$$.fragment,f),E(S8.$$.fragment,f),E(R8.$$.fragment,f),E(B8.$$.fragment,f),E(O7.$$.fragment,f),E(I8.$$.fragment,f),E(Q7.$$.fragment,f),E(N8.$$.fragment,f),E(q8.$$.fragment,f),E(D8.$$.fragment,f),E(U7.$$.fragment,f),E(G8.$$.fragment,f),E(_M.$$.fragment,f),E(O8.$$.fragment,f),E(V8.$$.fragment,f),E(z8.$$.fragment,f),E(bM.$$.fragment,f),E(W8.$$.fragment,f),E(xM.$$.fragment,f),E(Q8.$$.fragment,f),E(H8.$$.fragment,f),E(J8.$$.fragment,f),E(kM.$$.fragment,f),E(Y8.$$.fragment,f),E(aE.$$.fragment,f),E(K8.$$.fragment,f),E(Z8.$$.fragment,f),E(o9.$$.fragment,f),E(sE.$$.fragment,f),E(r9.$$.fragment,f),E(CE.$$.fragment,f),E(t9.$$.fragment,f),E(a9.$$.fragment,f),E(s9.$$.fragment,f),E(AE.$$.fragment,f),E(l9.$$.fragment,f),E(xE.$$.fragment,f),E(d9.$$.fragment,f),E(c9.$$.fragment,f),E(m9.$$.fragment,f),E(kE.$$.fragment,f),E(g9.$$.fragment,f),E(RE.$$.fragment,f),E(h9.$$.fragment,f),E(p9.$$.fragment,f),E(u9.$$.fragment,f),E(BE.$$.fragment,f),E(b9.$$.fragment,f),E(rC.$$.fragment,f),E(v9.$$.fragment,f),E(F9.$$.fragment,f),E(M9.$$.fragment,f),E(aC.$$.fragment,f),E(E9.$$.fragment,f),E(wC.$$.fragment,f),E(C9.$$.fragment,f),E(w9.$$.fragment,f),E(y9.$$.fragment,f),E(yC.$$.fragment,f),E(L9.$$.fragment,f),E(xC.$$.fragment,f),E(x9.$$.fragment,f),E($9.$$.fragment,f),E(S9.$$.fragment,f),E(kC.$$.fragment,f),E(R9.$$.fragment,f),E(RC.$$.fragment,f),E(P9.$$.fragment,f),E(B9.$$.fragment,f),E(N9.$$.fragment,f),E(BC.$$.fragment,f),E(q9.$$.fragment,f),E(i3.$$.fragment,f),E(j9.$$.fragment,f),E(D9.$$.fragment,f),E(O9.$$.fragment,f),E(c3.$$.fragment,f),E(V9.$$.fragment,f),E(T3.$$.fragment,f),E(X9.$$.fragment,f),E(z9.$$.fragment,f),E(Q9.$$.fragment,f),E(E3.$$.fragment,f),E(H9.$$.fragment,f),E(I3.$$.fragment,f),E(U9.$$.fragment,f),E(J9.$$.fragment,f),E(K9.$$.fragment,f),E(q3.$$.fragment,f),E(Z9.$$.fragment,f),E(U3.$$.fragment,f),E(ex.$$.fragment,f),E(ox.$$.fragment,f),E(tx.$$.fragment,f),E(Y3.$$.fragment,f),E(ax.$$.fragment,f),E(l0.$$.fragment,f),E(nx.$$.fragment,f),E(sx.$$.fragment,f),E(ix.$$.fragment,f),E(d0.$$.fragment,f),E(dx.$$.fragment,f),E(F0.$$.fragment,f),E(cx.$$.fragment,f),E(fx.$$.fragment,f),E(gx.$$.fragment,f),E(M0.$$.fragment,f),E(hx.$$.fragment,f),E(R0.$$.fragment,f),E(px.$$.fragment,f),E(_x.$$.fragment,f),E(bx.$$.fragment,f),E(B0.$$.fragment,f),E(vx.$$.fragment,f),E(X0.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(W0.$$.fragment,f),E(Cx.$$.fragment,f),E(ow.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(Lx.$$.fragment,f),E(tw.$$.fragment,f),E(xx.$$.fragment,f),E(nw.$$.fragment,f),E($x.$$.fragment,f),E(kx.$$.fragment,f),E(Rx.$$.fragment,f),E(lw.$$.fragment,f),E(Px.$$.fragment,f),E(cw.$$.fragment,f),E(Ix.$$.fragment,f),E(Nx.$$.fragment,f),E(jx.$$.fragment,f),E(mw.$$.fragment,f),E(Dx.$$.fragment,f),E(hw.$$.fragment,f),jDe=!0)},o(f){C(d.$$.fragment,f),C(Ca.$$.fragment,f),C(IA.$$.fragment,f),C(NA.$$.fragment,f),C(Mf.$$.fragment,f),C(qA.$$.fragment,f),C(jA.$$.fragment,f),C(OA.$$.fragment,f),C(Ag.$$.fragment,f),C(VA.$$.fragment,f),C(XA.$$.fragment,f),C(zA.$$.fragment,f),C(HA.$$.fragment,f),C(sh.$$.fragment,f),C(UA.$$.fragment,f),C(JA.$$.fragment,f),C(YA.$$.fragment,f),C(ey.$$.fragment,f),C(jh.$$.fragment,f),C(Dh.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(sy.$$.fragment,f),C(sp.$$.fragment,f),C(lp.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(dy.$$.fragment,f),C(fy.$$.fragment,f),C(cp.$$.fragment,f),C(my.$$.fragment,f),C(su.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(_y.$$.fragment,f),C(iu.$$.fragment,f),C(uy.$$.fragment,f),C(Ku.$$.fragment,f),C(by.$$.fragment,f),C(vy.$$.fragment,f),C(Ty.$$.fragment,f),C(e2.$$.fragment,f),C(My.$$.fragment,f),C(j2.$$.fragment,f),C(Ey.$$.fragment,f),C(Cy.$$.fragment,f),C(Ay.$$.fragment,f),C(G2.$$.fragment,f),C(yy.$$.fragment,f),C(w1.$$.fragment,f),C(Ly.$$.fragment,f),C(xy.$$.fragment,f),C(ky.$$.fragment,f),C(y1.$$.fragment,f),C(Sy.$$.fragment,f),C(z1.$$.fragment,f),C(Ry.$$.fragment,f),C(Py.$$.fragment,f),C(Iy.$$.fragment,f),C(Q1.$$.fragment,f),C(Ny.$$.fragment,f),C(Ob.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(Gy.$$.fragment,f),C(Xb.$$.fragment,f),C(Oy.$$.fragment,f),C(T4.$$.fragment,f),C(Vy.$$.fragment,f),C(Xy.$$.fragment,f),C(Wy.$$.fragment,f),C(E4.$$.fragment,f),C(Qy.$$.fragment,f),C($4.$$.fragment,f),C(Hy.$$.fragment,f),C(Uy.$$.fragment,f),C(Yy.$$.fragment,f),C(S4.$$.fragment,f),C(Ky.$$.fragment,f),C(hv.$$.fragment,f),C(Zy.$$.fragment,f),C(eL.$$.fragment,f),C(rL.$$.fragment,f),C(_v.$$.fragment,f),C(tL.$$.fragment,f),C(a5.$$.fragment,f),C(aL.$$.fragment,f),C(nL.$$.fragment,f),C(lL.$$.fragment,f),C(s5.$$.fragment,f),C(iL.$$.fragment,f),C(d5.$$.fragment,f),C(dL.$$.fragment,f),C(cL.$$.fragment,f),C(mL.$$.fragment,f),C(f5.$$.fragment,f),C(gL.$$.fragment,f),C(w5.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(uL.$$.fragment,f),C(y5.$$.fragment,f),C(bL.$$.fragment,f),C($5.$$.fragment,f),C(vL.$$.fragment,f),C(FL.$$.fragment,f),C(ML.$$.fragment,f),C(S5.$$.fragment,f),C(EL.$$.fragment,f),C(V5.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(yL.$$.fragment,f),C(z5.$$.fragment,f),C(LL.$$.fragment,f),C(K5.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(SL.$$.fragment,f),C(eF.$$.fragment,f),C(RL.$$.fragment,f),C(fF.$$.fragment,f),C(PL.$$.fragment,f),C(BL.$$.fragment,f),C(NL.$$.fragment,f),C(gF.$$.fragment,f),C(qL.$$.fragment,f),C(uF.$$.fragment,f),C(DL.$$.fragment,f),C(GL.$$.fragment,f),C(VL.$$.fragment,f),C(vF.$$.fragment,f),C(XL.$$.fragment,f),C(AF.$$.fragment,f),C(zL.$$.fragment,f),C(WL.$$.fragment,f),C(HL.$$.fragment,f),C(LF.$$.fragment,f),C(UL.$$.fragment,f),C(RF.$$.fragment,f),C(JL.$$.fragment,f),C(YL.$$.fragment,f),C(ZL.$$.fragment,f),C(BF.$$.fragment,f),C(e8.$$.fragment,f),C(jF.$$.fragment,f),C(r8.$$.fragment,f),C(t8.$$.fragment,f),C(n8.$$.fragment,f),C(GF.$$.fragment,f),C(s8.$$.fragment,f),C(XF.$$.fragment,f),C(l8.$$.fragment,f),C(i8.$$.fragment,f),C(c8.$$.fragment,f),C(WF.$$.fragment,f),C(f8.$$.fragment,f),C(KF.$$.fragment,f),C(m8.$$.fragment,f),C(g8.$$.fragment,f),C(p8.$$.fragment,f),C(eT.$$.fragment,f),C(_8.$$.fragment,f),C(tT.$$.fragment,f),C(u8.$$.fragment,f),C(b8.$$.fragment,f),C(F8.$$.fragment,f),C(nT.$$.fragment,f),C(T8.$$.fragment,f),C(KT.$$.fragment,f),C(M8.$$.fragment,f),C(E8.$$.fragment,f),C(w8.$$.fragment,f),C(e7.$$.fragment,f),C(A8.$$.fragment,f),C(C7.$$.fragment,f),C(y8.$$.fragment,f),C(L8.$$.fragment,f),C($8.$$.fragment,f),C(A7.$$.fragment,f),C(k8.$$.fragment,f),C(D7.$$.fragment,f),C(S8.$$.fragment,f),C(R8.$$.fragment,f),C(B8.$$.fragment,f),C(O7.$$.fragment,f),C(I8.$$.fragment,f),C(Q7.$$.fragment,f),C(N8.$$.fragment,f),C(q8.$$.fragment,f),C(D8.$$.fragment,f),C(U7.$$.fragment,f),C(G8.$$.fragment,f),C(_M.$$.fragment,f),C(O8.$$.fragment,f),C(V8.$$.fragment,f),C(z8.$$.fragment,f),C(bM.$$.fragment,f),C(W8.$$.fragment,f),C(xM.$$.fragment,f),C(Q8.$$.fragment,f),C(H8.$$.fragment,f),C(J8.$$.fragment,f),C(kM.$$.fragment,f),C(Y8.$$.fragment,f),C(aE.$$.fragment,f),C(K8.$$.fragment,f),C(Z8.$$.fragment,f),C(o9.$$.fragment,f),C(sE.$$.fragment,f),C(r9.$$.fragment,f),C(CE.$$.fragment,f),C(t9.$$.fragment,f),C(a9.$$.fragment,f),C(s9.$$.fragment,f),C(AE.$$.fragment,f),C(l9.$$.fragment,f),C(xE.$$.fragment,f),C(d9.$$.fragment,f),C(c9.$$.fragment,f),C(m9.$$.fragment,f),C(kE.$$.fragment,f),C(g9.$$.fragment,f),C(RE.$$.fragment,f),C(h9.$$.fragment,f),C(p9.$$.fragment,f),C(u9.$$.fragment,f),C(BE.$$.fragment,f),C(b9.$$.fragment,f),C(rC.$$.fragment,f),C(v9.$$.fragment,f),C(F9.$$.fragment,f),C(M9.$$.fragment,f),C(aC.$$.fragment,f),C(E9.$$.fragment,f),C(wC.$$.fragment,f),C(C9.$$.fragment,f),C(w9.$$.fragment,f),C(y9.$$.fragment,f),C(yC.$$.fragment,f),C(L9.$$.fragment,f),C(xC.$$.fragment,f),C(x9.$$.fragment,f),C($9.$$.fragment,f),C(S9.$$.fragment,f),C(kC.$$.fragment,f),C(R9.$$.fragment,f),C(RC.$$.fragment,f),C(P9.$$.fragment,f),C(B9.$$.fragment,f),C(N9.$$.fragment,f),C(BC.$$.fragment,f),C(q9.$$.fragment,f),C(i3.$$.fragment,f),C(j9.$$.fragment,f),C(D9.$$.fragment,f),C(O9.$$.fragment,f),C(c3.$$.fragment,f),C(V9.$$.fragment,f),C(T3.$$.fragment,f),C(X9.$$.fragment,f),C(z9.$$.fragment,f),C(Q9.$$.fragment,f),C(E3.$$.fragment,f),C(H9.$$.fragment,f),C(I3.$$.fragment,f),C(U9.$$.fragment,f),C(J9.$$.fragment,f),C(K9.$$.fragment,f),C(q3.$$.fragment,f),C(Z9.$$.fragment,f),C(U3.$$.fragment,f),C(ex.$$.fragment,f),C(ox.$$.fragment,f),C(tx.$$.fragment,f),C(Y3.$$.fragment,f),C(ax.$$.fragment,f),C(l0.$$.fragment,f),C(nx.$$.fragment,f),C(sx.$$.fragment,f),C(ix.$$.fragment,f),C(d0.$$.fragment,f),C(dx.$$.fragment,f),C(F0.$$.fragment,f),C(cx.$$.fragment,f),C(fx.$$.fragment,f),C(gx.$$.fragment,f),C(M0.$$.fragment,f),C(hx.$$.fragment,f),C(R0.$$.fragment,f),C(px.$$.fragment,f),C(_x.$$.fragment,f),C(bx.$$.fragment,f),C(B0.$$.fragment,f),C(vx.$$.fragment,f),C(X0.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(W0.$$.fragment,f),C(Cx.$$.fragment,f),C(ow.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(Lx.$$.fragment,f),C(tw.$$.fragment,f),C(xx.$$.fragment,f),C(nw.$$.fragment,f),C($x.$$.fragment,f),C(kx.$$.fragment,f),C(Rx.$$.fragment,f),C(lw.$$.fragment,f),C(Px.$$.fragment,f),C(cw.$$.fragment,f),C(Ix.$$.fragment,f),C(Nx.$$.fragment,f),C(jx.$$.fragment,f),C(mw.$$.fragment,f),C(Dx.$$.fragment,f),C(hw.$$.fragment,f),jDe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(uf),f&&t(rt),f&&t(De),f&&t(We),f&&t(vf),w(Ca,f),f&&t(Qe),f&&t(Ae),f&&t(Eo),f&&t(wa),f&&t(Iqe),f&&t(Fi),w(IA),f&&t(Nqe),f&&t(kn),f&&t(qqe),w(NA,f),f&&t(jqe),f&&t(lk),f&&t(Dqe),w(Mf,f),f&&t(Gqe),f&&t(Ti),w(qA),f&&t(Oqe),f&&t(Co),w(jA),w(OA),w(Ag),w(VA),f&&t(Vqe),f&&t(Ei),w(XA),f&&t(Xqe),f&&t(wo),w(zA),w(HA),w(sh),w(UA),f&&t(zqe),f&&t(Ci),w(JA),f&&t(Wqe),f&&t(Ao),w(YA),w(ey),w(jh),w(Dh),w(oy),f&&t(Qqe),f&&t(wi),w(ry),f&&t(Hqe),f&&t(yo),w(ty),w(sy),w(sp),w(lp),w(ly),f&&t(Uqe),f&&t(yi),w(iy),f&&t(Jqe),f&&t(Lo),w(dy),w(fy),w(cp),w(my),w(su),f&&t(Yqe),f&&t($i),w(gy),f&&t(Kqe),f&&t(xo),w(hy),w(_y),w(iu),w(uy),w(Ku),f&&t(Zqe),f&&t(Ri),w(by),f&&t(eje),f&&t($o),w(vy),w(Ty),w(e2),w(My),w(j2),f&&t(oje),f&&t(Ii),w(Ey),f&&t(rje),f&&t(ko),w(Cy),w(Ay),w(G2),w(yy),w(w1),f&&t(tje),f&&t(ji),w(Ly),f&&t(aje),f&&t(So),w(xy),w(ky),w(y1),w(Sy),w(z1),f&&t(nje),f&&t(Oi),w(Ry),f&&t(sje),f&&t(Ro),w(Py),w(Iy),w(Q1),w(Ny),w(Ob),f&&t(lje),f&&t(zi),w(qy),f&&t(ije),f&&t(Po),w(jy),w(Gy),w(Xb),w(Oy),w(T4),f&&t(dje),f&&t(Hi),w(Vy),f&&t(cje),f&&t(Bo),w(Xy),w(Wy),w(E4),w(Qy),w($4),f&&t(fje),f&&t(Yi),w(Hy),f&&t(mje),f&&t(Io),w(Uy),w(Yy),w(S4),w(Ky),w(hv),f&&t(gje),f&&t(ed),w(Zy),f&&t(hje),f&&t(No),w(eL),w(rL),w(_v),w(tL),w(a5),f&&t(pje),f&&t(td),w(aL),f&&t(_je),f&&t(qo),w(nL),w(lL),w(s5),w(iL),w(d5),f&&t(uje),f&&t(sd),w(dL),f&&t(bje),f&&t(jo),w(cL),w(mL),w(f5),w(gL),w(w5),f&&t(vje),f&&t(dd),w(hL),f&&t(Fje),f&&t(Do),w(pL),w(uL),w(y5),w(bL),w($5),f&&t(Tje),f&&t(md),w(vL),f&&t(Mje),f&&t(Go),w(FL),w(ML),w(S5),w(EL),w(V5),f&&t(Eje),f&&t(pd),w(CL),f&&t(Cje),f&&t(Oo),w(wL),w(yL),w(z5),w(LL),w(K5),f&&t(wje),f&&t(bd),w(xL),f&&t(Aje),f&&t(Vo),w($L),w(SL),w(eF),w(RL),w(fF),f&&t(yje),f&&t(Td),w(PL),f&&t(Lje),f&&t(Xo),w(BL),w(NL),w(gF),w(qL),w(uF),f&&t(xje),f&&t(Cd),w(DL),f&&t($je),f&&t(zo),w(GL),w(VL),w(vF),w(XL),w(AF),f&&t(kje),f&&t(yd),w(zL),f&&t(Sje),f&&t(Wo),w(WL),w(HL),w(LF),w(UL),w(RF),f&&t(Rje),f&&t(kd),w(JL),f&&t(Pje),f&&t(Qo),w(YL),w(ZL),w(BF),w(e8),w(jF),f&&t(Bje),f&&t(Pd),w(r8),f&&t(Ije),f&&t(Ho),w(t8),w(n8),w(GF),w(s8),w(XF),f&&t(Nje),f&&t(Nd),w(l8),f&&t(qje),f&&t(Uo),w(i8),w(c8),w(WF),w(f8),w(KF),f&&t(jje),f&&t(Dd),w(m8),f&&t(Dje),f&&t(Jo),w(g8),w(p8),w(eT),w(_8),w(tT),f&&t(Gje),f&&t(Vd),w(u8),f&&t(Oje),f&&t(Yo),w(b8),w(F8),w(nT),w(T8),w(KT),f&&t(Vje),f&&t(Wd),w(M8),f&&t(Xje),f&&t(Ko),w(E8),w(w8),w(e7),w(A8),w(C7),f&&t(zje),f&&t(Ud),w(y8),f&&t(Wje),f&&t(Zo),w(L8),w($8),w(A7),w(k8),w(D7),f&&t(Qje),f&&t(Kd),w(S8),f&&t(Hje),f&&t(er),w(R8),w(B8),w(O7),w(I8),w(Q7),f&&t(Uje),f&&t(oc),w(N8),f&&t(Jje),f&&t(or),w(q8),w(D8),w(U7),w(G8),w(_M),f&&t(Yje),f&&t(ac),w(O8),f&&t(Kje),f&&t(rr),w(V8),w(z8),w(bM),w(W8),w(xM),f&&t(Zje),f&&t(lc),w(Q8),f&&t(eDe),f&&t(tr),w(H8),w(J8),w(kM),w(Y8),w(aE),f&&t(oDe),f&&t(cc),w(K8),f&&t(rDe),f&&t(ar),w(Z8),w(o9),w(sE),w(r9),w(CE),f&&t(tDe),f&&t(gc),w(t9),f&&t(aDe),f&&t(nr),w(a9),w(s9),w(AE),w(l9),w(xE),f&&t(nDe),f&&t(_c),w(d9),f&&t(sDe),f&&t(sr),w(c9),w(m9),w(kE),w(g9),w(RE),f&&t(lDe),f&&t(vc),w(h9),f&&t(iDe),f&&t(lr),w(p9),w(u9),w(BE),w(b9),w(rC),f&&t(dDe),f&&t(Mc),w(v9),f&&t(cDe),f&&t(ir),w(F9),w(M9),w(aC),w(E9),w(wC),f&&t(fDe),f&&t(wc),w(C9),f&&t(mDe),f&&t(dr),w(w9),w(y9),w(yC),w(L9),w(xC),f&&t(gDe),f&&t(Lc),w(x9),f&&t(hDe),f&&t(cr),w($9),w(S9),w(kC),w(R9),w(RC),f&&t(pDe),f&&t(kc),w(P9),f&&t(_De),f&&t(fr),w(B9),w(N9),w(BC),w(q9),w(i3),f&&t(uDe),f&&t(Pc),w(j9),f&&t(bDe),f&&t(mr),w(D9),w(O9),w(c3),w(V9),w(T3),f&&t(vDe),f&&t(Nc),w(X9),f&&t(FDe),f&&t(gr),w(z9),w(Q9),w(E3),w(H9),w(I3),f&&t(TDe),f&&t(Dc),w(U9),f&&t(MDe),f&&t(hr),w(J9),w(K9),w(q3),w(Z9),w(U3),f&&t(EDe),f&&t(Vc),w(ex),f&&t(CDe),f&&t(pr),w(ox),w(tx),w(Y3),w(ax),w(l0),f&&t(wDe),f&&t(Wc),w(nx),f&&t(ADe),f&&t(_r),w(sx),w(ix),w(d0),w(dx),w(F0),f&&t(yDe),f&&t(Uc),w(cx),f&&t(LDe),f&&t(ur),w(fx),w(gx),w(M0),w(hx),w(R0),f&&t(xDe),f&&t(Kc),w(px),f&&t($De),f&&t(br),w(_x),w(bx),w(B0),w(vx),w(X0),f&&t(kDe),f&&t(of),w(Fx),f&&t(SDe),f&&t(vr),w(Tx),w(Ex),w(W0),w(Cx),w(ow),f&&t(RDe),f&&t(af),w(wx),f&&t(PDe),f&&t(Fr),w(Ax),w(Lx),w(tw),w(xx),w(nw),f&&t(BDe),f&&t(lf),w($x),f&&t(IDe),f&&t(Tr),w(kx),w(Rx),w(lw),w(Px),w(cw),f&&t(NDe),f&&t(ff),w(Ix),f&&t(qDe),f&&t(Mr),w(Nx),w(jx),w(mw),w(Dx),w(hw)}}}const iPt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function dPt(L){return dSt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _Pt extends nSt{constructor(g){super();sSt(this,g,dPt,lPt,lSt,{})}}export{_Pt as default,iPt as metadata};
