import{S as b$t,i as v$t,s as F$t,e as a,k as l,w as F,t as o,M as T$t,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as M$t,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as jVr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function E$t(L){let g,v,p,m,u,d,h,Mo,hi,bf,rt,pi,ui,EA,vf,je,We,_i,yn,CA,Ln,xn,wA,bi,$n,AA,vi,Ff,Ca;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),hi=a("code"),bf=o("model_type"),rt=o(" attribute is set to the same key you use when registering the config (here "),pi=a("code"),ui=o('"new-model"'),EA=o(")."),vf=l(),je=a("p"),We=o("Likewise, if your "),_i=a("code"),yn=o("NewModel"),CA=o(" is a subclass of "),Ln=a("a"),xn=o("PreTrainedModel"),wA=o(`, make sure its
`),bi=a("code"),$n=o("config_class"),AA=o(` attribute is set to the same class you use when registering the model (here
`),vi=a("code"),Ff=o("NewModelConfig"),Ca=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var H$=s(p);m=r(H$,"NewModelConfig"),H$.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Fi=s(d);h=r(Fi,"PretrainedConfig"),Fi.forEach(t),Mo=r(Ae,`, make sure its
`),hi=n(Ae,"CODE",{});var U$=s(hi);bf=r(U$,"model_type"),U$.forEach(t),rt=r(Ae," attribute is set to the same key you use when registering the config (here "),pi=n(Ae,"CODE",{});var J$=s(pi);ui=r(J$,'"new-model"'),J$.forEach(t),EA=r(Ae,")."),Ae.forEach(t),vf=i(Qe),je=n(Qe,"P",{});var Eo=s(je);We=r(Eo,"Likewise, if your "),_i=n(Eo,"CODE",{});var wa=s(_i);yn=r(wa,"NewModel"),wa.forEach(t),CA=r(Eo," is a subclass of "),Ln=n(Eo,"A",{href:!0});var Y$=s(Ln);xn=r(Y$,"PreTrainedModel"),Y$.forEach(t),wA=r(Eo,`, make sure its
`),bi=n(Eo,"CODE",{});var Tf=s(bi);$n=r(Tf,"config_class"),Tf.forEach(t),AA=r(Eo,` attribute is set to the same class you use when registering the model (here
`),vi=n(Eo,"CODE",{});var K$=s(vi);Ff=r(K$,"NewModelConfig"),K$.forEach(t),Ca=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(Ln,"href","/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Mo),e(g,hi),e(hi,bf),e(g,rt),e(g,pi),e(pi,ui),e(g,EA),b(Qe,vf,Ae),b(Qe,je,Ae),e(je,We),e(je,_i),e(_i,yn),e(je,CA),e(je,Ln),e(Ln,xn),e(je,wA),e(je,bi),e(bi,$n),e(je,AA),e(je,vi),e(vi,Ff),e(je,Ca)},d(Qe){Qe&&t(g),Qe&&t(vf),Qe&&t(je)}}}function C$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function w$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function A$t(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function y$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function L$t(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function x$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function k$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function S$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function R$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function P$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function B$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function I$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function q$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function N$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function j$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function D$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function G$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function O$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function V$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function X$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function z$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function W$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Q$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function H$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function U$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function J$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Y$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function K$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Z$t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ekt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function okt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function akt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function skt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ikt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ckt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ukt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _kt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ekt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ckt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Akt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ykt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $kt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Skt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ikt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Okt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ukt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ykt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zkt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _St(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vSt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FSt(L){let g,v,p,m,u,d,h,Mo,hi,bf,rt,pi,ui,EA,vf,je,We,_i,yn,CA,Ln,xn,wA,bi,$n,AA,vi,Ff,Ca,Qe,Ae,H$,Fi,U$,J$,Eo,wa,Y$,Tf,K$,mOe,oNe,Ti,Mf,moe,yA,gOe,goe,hOe,rNe,kn,pOe,hoe,uOe,_Oe,poe,bOe,vOe,tNe,LA,aNe,Z$,FOe,nNe,Ef,sNe,Mi,Cf,uoe,xA,TOe,_oe,MOe,lNe,Co,$A,EOe,kA,COe,ek,wOe,AOe,yOe,SA,LOe,boe,xOe,$Oe,kOe,Er,RA,SOe,voe,ROe,POe,Ei,BOe,Foe,IOe,qOe,Toe,NOe,jOe,DOe,A,wf,Moe,GOe,OOe,ok,VOe,XOe,zOe,Af,Eoe,WOe,QOe,rk,HOe,UOe,JOe,yf,Coe,YOe,KOe,tk,ZOe,eVe,oVe,Lf,woe,rVe,tVe,ak,aVe,nVe,sVe,xf,Aoe,lVe,iVe,nk,dVe,cVe,fVe,$f,yoe,mVe,gVe,sk,hVe,pVe,uVe,kf,Loe,_Ve,bVe,lk,vVe,FVe,TVe,Sf,xoe,MVe,EVe,ik,CVe,wVe,AVe,Rf,$oe,yVe,LVe,dk,xVe,$Ve,kVe,Pf,koe,SVe,RVe,ck,PVe,BVe,IVe,Bf,Soe,qVe,NVe,fk,jVe,DVe,GVe,If,Roe,OVe,VVe,mk,XVe,zVe,WVe,qf,Poe,QVe,HVe,gk,UVe,JVe,YVe,Nf,Boe,KVe,ZVe,hk,eXe,oXe,rXe,jf,Ioe,tXe,aXe,pk,nXe,sXe,lXe,Df,qoe,iXe,dXe,uk,cXe,fXe,mXe,Gf,Noe,gXe,hXe,_k,pXe,uXe,_Xe,Of,joe,bXe,vXe,bk,FXe,TXe,MXe,Vf,Doe,EXe,CXe,vk,wXe,AXe,yXe,Xf,Goe,LXe,xXe,Fk,$Xe,kXe,SXe,zf,Ooe,RXe,PXe,Tk,BXe,IXe,qXe,Wf,Voe,NXe,jXe,Mk,DXe,GXe,OXe,Qf,Xoe,VXe,XXe,Ek,zXe,WXe,QXe,Hf,zoe,HXe,UXe,Ck,JXe,YXe,KXe,Uf,Woe,ZXe,eze,wk,oze,rze,tze,Jf,Qoe,aze,nze,Ak,sze,lze,ize,Yf,Hoe,dze,cze,yk,fze,mze,gze,Kf,Uoe,hze,pze,Lk,uze,_ze,bze,Zf,Joe,vze,Fze,xk,Tze,Mze,Eze,em,Yoe,Cze,wze,$k,Aze,yze,Lze,om,Koe,xze,$ze,kk,kze,Sze,Rze,rm,Zoe,Pze,Bze,Sk,Ize,qze,Nze,tm,ere,jze,Dze,Rk,Gze,Oze,Vze,am,ore,Xze,zze,Pk,Wze,Qze,Hze,nm,rre,Uze,Jze,Bk,Yze,Kze,Zze,sm,tre,eWe,oWe,Ik,rWe,tWe,aWe,lm,are,nWe,sWe,qk,lWe,iWe,dWe,im,nre,cWe,fWe,Nk,mWe,gWe,hWe,dm,sre,pWe,uWe,jk,_We,bWe,vWe,cm,lre,FWe,TWe,Dk,MWe,EWe,CWe,fm,ire,wWe,AWe,Gk,yWe,LWe,xWe,mm,dre,$We,kWe,Ok,SWe,RWe,PWe,gm,cre,BWe,IWe,Vk,qWe,NWe,jWe,hm,fre,DWe,GWe,Xk,OWe,VWe,XWe,pm,mre,zWe,WWe,zk,QWe,HWe,UWe,um,gre,JWe,YWe,Wk,KWe,ZWe,eQe,_m,hre,oQe,rQe,Qk,tQe,aQe,nQe,bm,pre,sQe,lQe,Hk,iQe,dQe,cQe,vm,ure,fQe,mQe,Uk,gQe,hQe,pQe,Fm,_re,uQe,_Qe,Jk,bQe,vQe,FQe,Tm,bre,TQe,MQe,Yk,EQe,CQe,wQe,Mm,vre,AQe,yQe,Kk,LQe,xQe,$Qe,Em,Fre,kQe,SQe,Zk,RQe,PQe,BQe,Cm,Tre,IQe,qQe,eS,NQe,jQe,DQe,wm,Mre,GQe,OQe,oS,VQe,XQe,zQe,Am,Ere,WQe,QQe,rS,HQe,UQe,JQe,ym,Cre,YQe,KQe,tS,ZQe,eHe,oHe,Lm,wre,rHe,tHe,aS,aHe,nHe,sHe,xm,Are,lHe,iHe,nS,dHe,cHe,fHe,$m,yre,mHe,gHe,sS,hHe,pHe,uHe,km,Lre,_He,bHe,lS,vHe,FHe,THe,Sm,xre,MHe,EHe,iS,CHe,wHe,AHe,Rm,$re,yHe,LHe,dS,xHe,$He,kHe,Pm,kre,SHe,RHe,cS,PHe,BHe,IHe,Bm,Sre,qHe,NHe,fS,jHe,DHe,GHe,Im,Rre,OHe,VHe,mS,XHe,zHe,WHe,qm,Pre,QHe,HHe,gS,UHe,JHe,YHe,Nm,Bre,KHe,ZHe,hS,eUe,oUe,rUe,jm,Ire,tUe,aUe,pS,nUe,sUe,lUe,Dm,qre,iUe,dUe,uS,cUe,fUe,mUe,Gm,Nre,gUe,hUe,_S,pUe,uUe,_Ue,Om,jre,bUe,vUe,bS,FUe,TUe,MUe,Vm,Dre,EUe,CUe,vS,wUe,AUe,yUe,Xm,Gre,LUe,xUe,FS,$Ue,kUe,SUe,zm,Ore,RUe,PUe,TS,BUe,IUe,qUe,Wm,Vre,NUe,jUe,MS,DUe,GUe,OUe,Qm,Xre,VUe,XUe,ES,zUe,WUe,QUe,Hm,zre,HUe,UUe,CS,JUe,YUe,KUe,Um,Wre,ZUe,eJe,wS,oJe,rJe,tJe,Jm,Qre,aJe,nJe,AS,sJe,lJe,iJe,Ym,Hre,dJe,cJe,yS,fJe,mJe,gJe,Km,Ure,hJe,pJe,LS,uJe,_Je,bJe,Zm,Jre,vJe,FJe,xS,TJe,MJe,EJe,eg,Yre,CJe,wJe,$S,AJe,yJe,LJe,og,Kre,xJe,$Je,kS,kJe,SJe,RJe,rg,Zre,PJe,BJe,SS,IJe,qJe,NJe,tg,ete,jJe,DJe,RS,GJe,OJe,VJe,ag,ote,XJe,zJe,PS,WJe,QJe,HJe,ng,rte,UJe,JJe,BS,YJe,KJe,ZJe,sg,tte,eYe,oYe,IS,rYe,tYe,aYe,lg,ate,nYe,sYe,qS,lYe,iYe,dYe,ig,nte,cYe,fYe,NS,mYe,gYe,hYe,dg,ste,pYe,uYe,jS,_Ye,bYe,vYe,cg,lte,FYe,TYe,DS,MYe,EYe,CYe,fg,ite,wYe,AYe,GS,yYe,LYe,xYe,mg,dte,$Ye,kYe,OS,SYe,RYe,PYe,gg,cte,BYe,IYe,VS,qYe,NYe,jYe,hg,fte,DYe,GYe,XS,OYe,VYe,XYe,pg,mte,zYe,WYe,zS,QYe,HYe,UYe,ug,gte,JYe,YYe,WS,KYe,ZYe,eKe,_g,hte,oKe,rKe,QS,tKe,aKe,nKe,bg,pte,sKe,lKe,HS,iKe,dKe,cKe,vg,ute,fKe,mKe,US,gKe,hKe,pKe,Fg,_te,uKe,_Ke,JS,bKe,vKe,FKe,Tg,bte,TKe,MKe,YS,EKe,CKe,wKe,Mg,vte,AKe,yKe,KS,LKe,xKe,$Ke,Eg,Fte,kKe,SKe,ZS,RKe,PKe,BKe,Cg,Tte,IKe,qKe,eR,NKe,jKe,DKe,wg,Mte,GKe,OKe,oR,VKe,XKe,zKe,Ag,WKe,yg,PA,QKe,Ete,HKe,iNe,Ci,Lg,Cte,BA,UKe,wte,JKe,dNe,wo,IA,YKe,qA,KKe,rR,ZKe,eZe,oZe,NA,rZe,Ate,tZe,aZe,nZe,Cr,jA,sZe,yte,lZe,iZe,Aa,dZe,Lte,cZe,fZe,xte,mZe,gZe,$te,hZe,pZe,uZe,k,Sn,kte,_Ze,bZe,tR,vZe,FZe,aR,TZe,MZe,EZe,Rn,Ste,CZe,wZe,nR,AZe,yZe,sR,LZe,xZe,$Ze,Pn,Rte,kZe,SZe,lR,RZe,PZe,iR,BZe,IZe,qZe,Bn,Pte,NZe,jZe,dR,DZe,GZe,cR,OZe,VZe,XZe,In,Bte,zZe,WZe,fR,QZe,HZe,mR,UZe,JZe,YZe,xg,Ite,KZe,ZZe,gR,eeo,oeo,reo,$g,qte,teo,aeo,hR,neo,seo,leo,qn,Nte,ieo,deo,pR,ceo,feo,uR,meo,geo,heo,Nn,jte,peo,ueo,_R,_eo,beo,bR,veo,Feo,Teo,jn,Dte,Meo,Eeo,vR,Ceo,weo,FR,Aeo,yeo,Leo,Dn,Gte,xeo,$eo,TR,keo,Seo,MR,Reo,Peo,Beo,kg,Ote,Ieo,qeo,ER,Neo,jeo,Deo,Sg,Vte,Geo,Oeo,CR,Veo,Xeo,zeo,Gn,Xte,Weo,Qeo,wR,Heo,Ueo,AR,Jeo,Yeo,Keo,Rg,zte,Zeo,eoo,yR,ooo,roo,too,On,Wte,aoo,noo,LR,soo,loo,xR,ioo,doo,coo,Vn,Qte,foo,moo,$R,goo,hoo,kR,poo,uoo,_oo,Xn,Hte,boo,voo,SR,Foo,Too,RR,Moo,Eoo,Coo,Pg,Ute,woo,Aoo,PR,yoo,Loo,xoo,zn,Jte,$oo,koo,BR,Soo,Roo,IR,Poo,Boo,Ioo,Wn,Yte,qoo,Noo,qR,joo,Doo,NR,Goo,Ooo,Voo,Qn,Kte,Xoo,zoo,jR,Woo,Qoo,DR,Hoo,Uoo,Joo,Hn,Zte,Yoo,Koo,GR,Zoo,ero,OR,oro,rro,tro,Un,eae,aro,nro,VR,sro,lro,XR,iro,dro,cro,Jn,oae,fro,mro,zR,gro,hro,WR,pro,uro,_ro,Bg,rae,bro,vro,QR,Fro,Tro,Mro,Yn,tae,Ero,Cro,HR,wro,Aro,UR,yro,Lro,xro,Ig,aae,$ro,kro,JR,Sro,Rro,Pro,Kn,nae,Bro,Iro,YR,qro,Nro,KR,jro,Dro,Gro,Zn,sae,Oro,Vro,ZR,Xro,zro,eP,Wro,Qro,Hro,es,lae,Uro,Jro,oP,Yro,Kro,rP,Zro,eto,oto,qg,iae,rto,tto,tP,ato,nto,sto,os,dae,lto,ito,aP,dto,cto,nP,fto,mto,gto,rs,cae,hto,pto,sP,uto,_to,lP,bto,vto,Fto,Ng,fae,Tto,Mto,iP,Eto,Cto,wto,ts,mae,Ato,yto,dP,Lto,xto,cP,$to,kto,Sto,as,gae,Rto,Pto,fP,Bto,Ito,mP,qto,Nto,jto,ns,hae,Dto,Gto,gP,Oto,Vto,hP,Xto,zto,Wto,ss,pae,Qto,Hto,pP,Uto,Jto,uP,Yto,Kto,Zto,ls,uae,eao,oao,_P,rao,tao,bP,aao,nao,sao,is,_ae,lao,iao,vP,dao,cao,FP,fao,mao,gao,ds,bae,hao,pao,TP,uao,_ao,MP,bao,vao,Fao,jg,vae,Tao,Mao,EP,Eao,Cao,wao,cs,Fae,Aao,yao,CP,Lao,xao,wP,$ao,kao,Sao,Dg,Tae,Rao,Pao,AP,Bao,Iao,qao,Gg,Mae,Nao,jao,yP,Dao,Gao,Oao,fs,Eae,Vao,Xao,LP,zao,Wao,xP,Qao,Hao,Uao,ms,Cae,Jao,Yao,$P,Kao,Zao,kP,eno,ono,rno,gs,wae,tno,ano,SP,nno,sno,RP,lno,ino,dno,Og,Aae,cno,fno,PP,mno,gno,hno,hs,yae,pno,uno,BP,_no,bno,IP,vno,Fno,Tno,ps,Lae,Mno,Eno,qP,Cno,wno,NP,Ano,yno,Lno,us,xae,xno,$no,jP,kno,Sno,DP,Rno,Pno,Bno,_s,$ae,Ino,qno,GP,Nno,jno,OP,Dno,Gno,Ono,bs,kae,Vno,Xno,VP,zno,Wno,XP,Qno,Hno,Uno,Vg,Sae,Jno,Yno,zP,Kno,Zno,eso,vs,Rae,oso,rso,WP,tso,aso,QP,nso,sso,lso,Xg,Pae,iso,dso,HP,cso,fso,mso,Fs,Bae,gso,hso,UP,pso,uso,JP,_so,bso,vso,zg,Iae,Fso,Tso,YP,Mso,Eso,Cso,Wg,qae,wso,Aso,KP,yso,Lso,xso,Ts,Nae,$so,kso,ZP,Sso,Rso,eB,Pso,Bso,Iso,Qg,jae,qso,Nso,oB,jso,Dso,Gso,Ms,Dae,Oso,Vso,rB,Xso,zso,tB,Wso,Qso,Hso,Es,Gae,Uso,Jso,aB,Yso,Kso,nB,Zso,elo,olo,Cs,Oae,rlo,tlo,sB,alo,nlo,lB,slo,llo,ilo,ws,Vae,dlo,clo,iB,flo,mlo,dB,glo,hlo,plo,As,Xae,ulo,_lo,cB,blo,vlo,fB,Flo,Tlo,Mlo,ys,zae,Elo,Clo,mB,wlo,Alo,gB,ylo,Llo,xlo,Hg,Wae,$lo,klo,hB,Slo,Rlo,Plo,Ug,Qae,Blo,Ilo,pB,qlo,Nlo,jlo,Ls,Hae,Dlo,Glo,uB,Olo,Vlo,_B,Xlo,zlo,Wlo,xs,Uae,Qlo,Hlo,bB,Ulo,Jlo,vB,Ylo,Klo,Zlo,$s,Jae,eio,oio,FB,rio,tio,TB,aio,nio,sio,Jg,Yae,lio,iio,MB,dio,cio,fio,Yg,Kae,mio,gio,EB,hio,pio,uio,Kg,Zae,_io,bio,CB,vio,Fio,Tio,ks,ene,Mio,Eio,wB,Cio,wio,AB,Aio,yio,Lio,Zg,one,xio,$io,yB,kio,Sio,Rio,eh,rne,Pio,Bio,LB,Iio,qio,Nio,oh,tne,jio,Dio,xB,Gio,Oio,Vio,Ss,ane,Xio,zio,$B,Wio,Qio,kB,Hio,Uio,Jio,rh,nne,Yio,Kio,SB,Zio,edo,odo,th,sne,rdo,tdo,RB,ado,ndo,sdo,Rs,lne,ldo,ido,PB,ddo,cdo,BB,fdo,mdo,gdo,Ps,ine,hdo,pdo,IB,udo,_do,qB,bdo,vdo,Fdo,Bs,dne,Tdo,Mdo,NB,Edo,Cdo,jB,wdo,Ado,ydo,Is,cne,Ldo,xdo,DB,$do,kdo,GB,Sdo,Rdo,Pdo,ah,Bdo,nh,DA,Ido,fne,qdo,cNe,wi,sh,mne,GA,Ndo,gne,jdo,fNe,Ao,OA,Ddo,VA,Gdo,OB,Odo,Vdo,Xdo,XA,zdo,hne,Wdo,Qdo,Hdo,He,zA,Udo,pne,Jdo,Ydo,ya,Kdo,une,Zdo,eco,_ne,oco,rco,bne,tco,aco,nco,Y,lh,vne,sco,lco,VB,ico,dco,cco,ih,Fne,fco,mco,XB,gco,hco,pco,dh,Tne,uco,_co,zB,bco,vco,Fco,ch,Mne,Tco,Mco,WB,Eco,Cco,wco,fh,Ene,Aco,yco,QB,Lco,xco,$co,mh,Cne,kco,Sco,HB,Rco,Pco,Bco,gh,wne,Ico,qco,UB,Nco,jco,Dco,hh,Ane,Gco,Oco,JB,Vco,Xco,zco,ph,yne,Wco,Qco,YB,Hco,Uco,Jco,uh,Lne,Yco,Kco,KB,Zco,efo,ofo,_h,xne,rfo,tfo,ZB,afo,nfo,sfo,bh,$ne,lfo,ifo,eI,dfo,cfo,ffo,vh,kne,mfo,gfo,oI,hfo,pfo,ufo,Fh,Sne,_fo,bfo,rI,vfo,Ffo,Tfo,Th,Rne,Mfo,Efo,tI,Cfo,wfo,Afo,Mh,Pne,yfo,Lfo,aI,xfo,$fo,kfo,Eh,Bne,Sfo,Rfo,nI,Pfo,Bfo,Ifo,Ch,Ine,qfo,Nfo,sI,jfo,Dfo,Gfo,wh,qne,Ofo,Vfo,lI,Xfo,zfo,Wfo,Ah,Nne,Qfo,Hfo,iI,Ufo,Jfo,Yfo,yh,jne,Kfo,Zfo,dI,emo,omo,rmo,Lh,Dne,tmo,amo,cI,nmo,smo,lmo,xh,Gne,imo,dmo,fI,cmo,fmo,mmo,$h,One,gmo,hmo,mI,pmo,umo,_mo,kh,Vne,bmo,vmo,gI,Fmo,Tmo,Mmo,Sh,Xne,Emo,Cmo,hI,wmo,Amo,ymo,Rh,zne,Lmo,xmo,pI,$mo,kmo,Smo,Ph,Wne,Rmo,Pmo,uI,Bmo,Imo,qmo,Bh,Qne,Nmo,jmo,_I,Dmo,Gmo,Omo,Ih,Vmo,qh,Xmo,Nh,WA,zmo,Hne,Wmo,mNe,Ai,jh,Une,QA,Qmo,Jne,Hmo,gNe,yo,HA,Umo,UA,Jmo,bI,Ymo,Kmo,Zmo,JA,ego,Yne,ogo,rgo,tgo,Ue,YA,ago,Kne,ngo,sgo,yi,lgo,Zne,igo,dgo,ese,cgo,fgo,mgo,he,Dh,ose,ggo,hgo,vI,pgo,ugo,_go,Gh,rse,bgo,vgo,tse,Fgo,Tgo,Mgo,Oh,ase,Ego,Cgo,FI,wgo,Ago,ygo,Vh,nse,Lgo,xgo,TI,$go,kgo,Sgo,Xh,sse,Rgo,Pgo,MI,Bgo,Igo,qgo,zh,lse,Ngo,jgo,EI,Dgo,Ggo,Ogo,Wh,ise,Vgo,Xgo,CI,zgo,Wgo,Qgo,Qh,dse,Hgo,Ugo,wI,Jgo,Ygo,Kgo,Hh,cse,Zgo,eho,AI,oho,rho,tho,Uh,fse,aho,nho,yI,sho,lho,iho,Jh,mse,dho,cho,LI,fho,mho,gho,Yh,gse,hho,pho,xI,uho,_ho,bho,Kh,hse,vho,Fho,$I,Tho,Mho,Eho,Zh,pse,Cho,who,kI,Aho,yho,Lho,ep,use,xho,$ho,SI,kho,Sho,Rho,op,_se,Pho,Bho,RI,Iho,qho,Nho,rp,bse,jho,Dho,PI,Gho,Oho,Vho,tp,Xho,ap,zho,np,KA,Who,vse,Qho,hNe,Li,sp,Fse,ZA,Hho,Tse,Uho,pNe,Lo,ey,Jho,xi,Yho,BI,Kho,Zho,II,epo,opo,rpo,oy,tpo,Mse,apo,npo,spo,tt,ry,lpo,Ese,ipo,dpo,$i,cpo,Cse,fpo,mpo,qI,gpo,hpo,ppo,lp,upo,Je,ty,_po,wse,bpo,vpo,La,Fpo,Ase,Tpo,Mpo,yse,Epo,Cpo,Lse,wpo,Apo,ypo,x,ip,xse,Lpo,xpo,NI,$po,kpo,Spo,dp,$se,Rpo,Ppo,jI,Bpo,Ipo,qpo,cp,kse,Npo,jpo,DI,Dpo,Gpo,Opo,fp,Sse,Vpo,Xpo,GI,zpo,Wpo,Qpo,mp,Rse,Hpo,Upo,OI,Jpo,Ypo,Kpo,gp,Pse,Zpo,euo,VI,ouo,ruo,tuo,hp,Bse,auo,nuo,XI,suo,luo,iuo,pp,Ise,duo,cuo,zI,fuo,muo,guo,up,qse,huo,puo,WI,uuo,_uo,buo,_p,Nse,vuo,Fuo,QI,Tuo,Muo,Euo,bp,jse,Cuo,wuo,HI,Auo,yuo,Luo,vp,Dse,xuo,$uo,UI,kuo,Suo,Ruo,Fp,Gse,Puo,Buo,JI,Iuo,quo,Nuo,Tp,Ose,juo,Duo,YI,Guo,Ouo,Vuo,Mp,Vse,Xuo,zuo,KI,Wuo,Quo,Huo,Ep,Xse,Uuo,Juo,ZI,Yuo,Kuo,Zuo,Cp,zse,e_o,o_o,eq,r_o,t_o,a_o,wp,Wse,n_o,s_o,oq,l_o,i_o,d_o,Ap,Qse,c_o,f_o,rq,m_o,g_o,h_o,yp,Hse,p_o,u_o,tq,__o,b_o,v_o,Lp,Use,F_o,T_o,aq,M_o,E_o,C_o,xp,Jse,w_o,A_o,nq,y_o,L_o,x_o,$p,Yse,$_o,k_o,sq,S_o,R_o,P_o,kp,Kse,B_o,I_o,lq,q_o,N_o,j_o,Sp,Zse,D_o,G_o,iq,O_o,V_o,X_o,Rp,ele,z_o,W_o,dq,Q_o,H_o,U_o,Pp,ole,J_o,Y_o,cq,K_o,Z_o,e2o,Bp,rle,o2o,r2o,fq,t2o,a2o,n2o,Ip,tle,s2o,l2o,mq,i2o,d2o,c2o,qp,ale,f2o,m2o,gq,g2o,h2o,p2o,Np,nle,u2o,_2o,hq,b2o,v2o,F2o,jp,sle,T2o,M2o,pq,E2o,C2o,w2o,qs,lle,A2o,y2o,uq,L2o,x2o,_q,$2o,k2o,S2o,Dp,ile,R2o,P2o,bq,B2o,I2o,q2o,Gp,dle,N2o,j2o,vq,D2o,G2o,O2o,Op,cle,V2o,X2o,Fq,z2o,W2o,Q2o,Vp,fle,H2o,U2o,Tq,J2o,Y2o,K2o,Xp,mle,Z2o,e1o,Mq,o1o,r1o,t1o,zp,gle,a1o,n1o,Eq,s1o,l1o,i1o,Wp,hle,d1o,c1o,Cq,f1o,m1o,g1o,Qp,ple,h1o,p1o,wq,u1o,_1o,b1o,Hp,ule,v1o,F1o,Aq,T1o,M1o,E1o,Up,_le,C1o,w1o,yq,A1o,y1o,L1o,Jp,ble,x1o,$1o,Lq,k1o,S1o,R1o,Yp,vle,P1o,B1o,xq,I1o,q1o,N1o,Kp,Fle,j1o,D1o,$q,G1o,O1o,V1o,Zp,Tle,X1o,z1o,kq,W1o,Q1o,H1o,eu,Mle,U1o,J1o,Sq,Y1o,K1o,Z1o,ou,Ele,ebo,obo,Rq,rbo,tbo,abo,ru,Cle,nbo,sbo,Pq,lbo,ibo,dbo,tu,wle,cbo,fbo,Bq,mbo,gbo,hbo,au,Ale,pbo,ubo,Iq,_bo,bbo,vbo,nu,yle,Fbo,Tbo,qq,Mbo,Ebo,Cbo,su,Lle,wbo,Abo,Nq,ybo,Lbo,xbo,lu,xle,$bo,kbo,jq,Sbo,Rbo,Pbo,iu,$le,Bbo,Ibo,Dq,qbo,Nbo,jbo,du,kle,Dbo,Gbo,Gq,Obo,Vbo,Xbo,cu,Sle,zbo,Wbo,Oq,Qbo,Hbo,Ubo,fu,Rle,Jbo,Ybo,Vq,Kbo,Zbo,e4o,mu,Ple,o4o,r4o,Xq,t4o,a4o,n4o,gu,Ble,s4o,l4o,zq,i4o,d4o,c4o,hu,Ile,f4o,m4o,Wq,g4o,h4o,p4o,pu,qle,u4o,_4o,Qq,b4o,v4o,F4o,uu,Nle,T4o,M4o,Hq,E4o,C4o,w4o,_u,jle,A4o,y4o,Uq,L4o,x4o,$4o,bu,Dle,k4o,S4o,Jq,R4o,P4o,B4o,vu,Gle,I4o,q4o,Yq,N4o,j4o,D4o,Fu,Ole,G4o,O4o,Kq,V4o,X4o,z4o,Tu,Vle,W4o,Q4o,Zq,H4o,U4o,J4o,Mu,Xle,Y4o,K4o,eN,Z4o,evo,ovo,Eu,zle,rvo,tvo,oN,avo,nvo,svo,Cu,Wle,lvo,ivo,rN,dvo,cvo,fvo,wu,Qle,mvo,gvo,tN,hvo,pvo,uvo,Au,Hle,_vo,bvo,aN,vvo,Fvo,Tvo,yu,Ule,Mvo,Evo,nN,Cvo,wvo,Avo,Lu,Jle,yvo,Lvo,sN,xvo,$vo,kvo,xu,Yle,Svo,Rvo,lN,Pvo,Bvo,Ivo,$u,Kle,qvo,Nvo,iN,jvo,Dvo,Gvo,ku,Zle,Ovo,Vvo,dN,Xvo,zvo,Wvo,Su,eie,Qvo,Hvo,cN,Uvo,Jvo,Yvo,Ru,oie,Kvo,Zvo,fN,e5o,o5o,r5o,Pu,rie,t5o,a5o,mN,n5o,s5o,l5o,Bu,tie,i5o,d5o,gN,c5o,f5o,m5o,Iu,aie,g5o,h5o,hN,p5o,u5o,_5o,qu,nie,b5o,v5o,pN,F5o,T5o,M5o,Nu,sie,E5o,C5o,uN,w5o,A5o,y5o,ju,lie,L5o,x5o,_N,$5o,k5o,S5o,Du,iie,R5o,P5o,bN,B5o,I5o,q5o,Gu,die,N5o,j5o,vN,D5o,G5o,O5o,Ou,cie,V5o,X5o,FN,z5o,W5o,Q5o,Vu,fie,H5o,U5o,TN,J5o,Y5o,K5o,Xu,mie,Z5o,eFo,MN,oFo,rFo,tFo,zu,gie,aFo,nFo,EN,sFo,lFo,iFo,Wu,hie,dFo,cFo,CN,fFo,mFo,gFo,Qu,pie,hFo,pFo,wN,uFo,_Fo,bFo,Hu,uie,vFo,FFo,AN,TFo,MFo,EFo,Uu,_ie,CFo,wFo,yN,AFo,yFo,LFo,Ju,bie,xFo,$Fo,LN,kFo,SFo,RFo,Yu,vie,PFo,BFo,xN,IFo,qFo,NFo,Ku,Fie,jFo,DFo,$N,GFo,OFo,VFo,Zu,Tie,XFo,zFo,kN,WFo,QFo,HFo,e_,Mie,UFo,JFo,SN,YFo,KFo,ZFo,o_,eTo,Eie,oTo,rTo,Cie,tTo,aTo,r_,uNe,ki,t_,wie,ay,nTo,Aie,sTo,_Ne,xo,ny,lTo,Si,iTo,RN,dTo,cTo,PN,fTo,mTo,gTo,sy,hTo,yie,pTo,uTo,_To,at,ly,bTo,Lie,vTo,FTo,Ri,TTo,xie,MTo,ETo,BN,CTo,wTo,ATo,a_,yTo,Ye,iy,LTo,$ie,xTo,$To,xa,kTo,kie,STo,RTo,Sie,PTo,BTo,Rie,ITo,qTo,NTo,G,n_,Pie,jTo,DTo,IN,GTo,OTo,VTo,s_,Bie,XTo,zTo,qN,WTo,QTo,HTo,l_,Iie,UTo,JTo,NN,YTo,KTo,ZTo,i_,qie,e7o,o7o,jN,r7o,t7o,a7o,d_,Nie,n7o,s7o,DN,l7o,i7o,d7o,c_,jie,c7o,f7o,GN,m7o,g7o,h7o,f_,Die,p7o,u7o,ON,_7o,b7o,v7o,m_,Gie,F7o,T7o,VN,M7o,E7o,C7o,g_,Oie,w7o,A7o,XN,y7o,L7o,x7o,h_,Vie,$7o,k7o,zN,S7o,R7o,P7o,p_,Xie,B7o,I7o,WN,q7o,N7o,j7o,u_,zie,D7o,G7o,QN,O7o,V7o,X7o,__,Wie,z7o,W7o,HN,Q7o,H7o,U7o,b_,Qie,J7o,Y7o,UN,K7o,Z7o,eMo,v_,Hie,oMo,rMo,JN,tMo,aMo,nMo,F_,Uie,sMo,lMo,YN,iMo,dMo,cMo,T_,Jie,fMo,mMo,KN,gMo,hMo,pMo,M_,Yie,uMo,_Mo,ZN,bMo,vMo,FMo,E_,Kie,TMo,MMo,ej,EMo,CMo,wMo,C_,Zie,AMo,yMo,oj,LMo,xMo,$Mo,w_,ede,kMo,SMo,rj,RMo,PMo,BMo,A_,ode,IMo,qMo,tj,NMo,jMo,DMo,y_,rde,GMo,OMo,aj,VMo,XMo,zMo,L_,tde,WMo,QMo,nj,HMo,UMo,JMo,x_,ade,YMo,KMo,sj,ZMo,eEo,oEo,$_,nde,rEo,tEo,lj,aEo,nEo,sEo,k_,sde,lEo,iEo,ij,dEo,cEo,fEo,S_,lde,mEo,gEo,dj,hEo,pEo,uEo,R_,ide,_Eo,bEo,cj,vEo,FEo,TEo,P_,dde,MEo,EEo,fj,CEo,wEo,AEo,B_,cde,yEo,LEo,mj,xEo,$Eo,kEo,I_,fde,SEo,REo,gj,PEo,BEo,IEo,q_,mde,qEo,NEo,hj,jEo,DEo,GEo,N_,gde,OEo,VEo,pj,XEo,zEo,WEo,j_,hde,QEo,HEo,uj,UEo,JEo,YEo,D_,pde,KEo,ZEo,_j,eCo,oCo,rCo,G_,ude,tCo,aCo,bj,nCo,sCo,lCo,O_,_de,iCo,dCo,vj,cCo,fCo,mCo,V_,bde,gCo,hCo,Fj,pCo,uCo,_Co,X_,vde,bCo,vCo,Tj,FCo,TCo,MCo,z_,Fde,ECo,CCo,Mj,wCo,ACo,yCo,W_,Tde,LCo,xCo,Ej,$Co,kCo,SCo,Q_,RCo,Mde,PCo,BCo,Ede,ICo,qCo,H_,bNe,Pi,U_,Cde,dy,NCo,wde,jCo,vNe,$o,cy,DCo,Bi,GCo,Cj,OCo,VCo,wj,XCo,zCo,WCo,fy,QCo,Ade,HCo,UCo,JCo,nt,my,YCo,yde,KCo,ZCo,Ii,e3o,Lde,o3o,r3o,Aj,t3o,a3o,n3o,J_,s3o,Ke,gy,l3o,xde,i3o,d3o,$a,c3o,$de,f3o,m3o,kde,g3o,h3o,Sde,p3o,u3o,_3o,z,Y_,Rde,b3o,v3o,yj,F3o,T3o,M3o,K_,Pde,E3o,C3o,Lj,w3o,A3o,y3o,Z_,Bde,L3o,x3o,xj,$3o,k3o,S3o,e2,Ide,R3o,P3o,$j,B3o,I3o,q3o,o2,qde,N3o,j3o,kj,D3o,G3o,O3o,r2,Nde,V3o,X3o,Sj,z3o,W3o,Q3o,t2,jde,H3o,U3o,Rj,J3o,Y3o,K3o,a2,Dde,Z3o,ewo,Pj,owo,rwo,two,n2,Gde,awo,nwo,Bj,swo,lwo,iwo,s2,Ode,dwo,cwo,Ij,fwo,mwo,gwo,l2,Vde,hwo,pwo,qj,uwo,_wo,bwo,i2,Xde,vwo,Fwo,Nj,Two,Mwo,Ewo,d2,zde,Cwo,wwo,jj,Awo,ywo,Lwo,c2,Wde,xwo,$wo,Dj,kwo,Swo,Rwo,f2,Qde,Pwo,Bwo,Gj,Iwo,qwo,Nwo,m2,Hde,jwo,Dwo,Oj,Gwo,Owo,Vwo,g2,Ude,Xwo,zwo,Vj,Wwo,Qwo,Hwo,h2,Jde,Uwo,Jwo,Xj,Ywo,Kwo,Zwo,p2,Yde,e0o,o0o,zj,r0o,t0o,a0o,u2,Kde,n0o,s0o,Wj,l0o,i0o,d0o,_2,Zde,c0o,f0o,Qj,m0o,g0o,h0o,b2,ece,p0o,u0o,Hj,_0o,b0o,v0o,v2,oce,F0o,T0o,Uj,M0o,E0o,C0o,F2,rce,w0o,A0o,Jj,y0o,L0o,x0o,T2,tce,$0o,k0o,Yj,S0o,R0o,P0o,M2,ace,B0o,I0o,Kj,q0o,N0o,j0o,E2,nce,D0o,G0o,Zj,O0o,V0o,X0o,C2,sce,z0o,W0o,eD,Q0o,H0o,U0o,w2,lce,J0o,Y0o,oD,K0o,Z0o,e6o,A2,ice,o6o,r6o,rD,t6o,a6o,n6o,y2,dce,s6o,l6o,tD,i6o,d6o,c6o,L2,cce,f6o,m6o,aD,g6o,h6o,p6o,x2,fce,u6o,_6o,nD,b6o,v6o,F6o,$2,mce,T6o,M6o,sD,E6o,C6o,w6o,k2,gce,A6o,y6o,lD,L6o,x6o,$6o,S2,hce,k6o,S6o,iD,R6o,P6o,B6o,R2,pce,I6o,q6o,dD,N6o,j6o,D6o,P2,G6o,uce,O6o,V6o,_ce,X6o,z6o,B2,FNe,qi,I2,bce,hy,W6o,vce,Q6o,TNe,ko,py,H6o,Ni,U6o,cD,J6o,Y6o,fD,K6o,Z6o,eAo,uy,oAo,Fce,rAo,tAo,aAo,st,_y,nAo,Tce,sAo,lAo,ji,iAo,Mce,dAo,cAo,mD,fAo,mAo,gAo,q2,hAo,Ze,by,pAo,Ece,uAo,_Ao,ka,bAo,Cce,vAo,FAo,wce,TAo,MAo,Ace,EAo,CAo,wAo,Q,N2,yce,AAo,yAo,gD,LAo,xAo,$Ao,j2,Lce,kAo,SAo,hD,RAo,PAo,BAo,D2,xce,IAo,qAo,pD,NAo,jAo,DAo,G2,$ce,GAo,OAo,uD,VAo,XAo,zAo,O2,kce,WAo,QAo,_D,HAo,UAo,JAo,V2,Sce,YAo,KAo,bD,ZAo,eyo,oyo,X2,Rce,ryo,tyo,vD,ayo,nyo,syo,z2,Pce,lyo,iyo,FD,dyo,cyo,fyo,W2,Bce,myo,gyo,TD,hyo,pyo,uyo,Q2,Ice,_yo,byo,MD,vyo,Fyo,Tyo,H2,qce,Myo,Eyo,ED,Cyo,wyo,Ayo,U2,Nce,yyo,Lyo,CD,xyo,$yo,kyo,J2,jce,Syo,Ryo,wD,Pyo,Byo,Iyo,Y2,Dce,qyo,Nyo,AD,jyo,Dyo,Gyo,K2,Gce,Oyo,Vyo,yD,Xyo,zyo,Wyo,Z2,Oce,Qyo,Hyo,LD,Uyo,Jyo,Yyo,e1,Vce,Kyo,Zyo,xD,eLo,oLo,rLo,o1,Xce,tLo,aLo,$D,nLo,sLo,lLo,r1,zce,iLo,dLo,kD,cLo,fLo,mLo,t1,Wce,gLo,hLo,SD,pLo,uLo,_Lo,a1,Qce,bLo,vLo,RD,FLo,TLo,MLo,n1,Hce,ELo,CLo,PD,wLo,ALo,yLo,s1,Uce,LLo,xLo,BD,$Lo,kLo,SLo,l1,Jce,RLo,PLo,ID,BLo,ILo,qLo,i1,Yce,NLo,jLo,qD,DLo,GLo,OLo,d1,Kce,VLo,XLo,ND,zLo,WLo,QLo,c1,Zce,HLo,ULo,jD,JLo,YLo,KLo,f1,efe,ZLo,e8o,DD,o8o,r8o,t8o,m1,ofe,a8o,n8o,GD,s8o,l8o,i8o,g1,rfe,d8o,c8o,OD,f8o,m8o,g8o,h1,tfe,h8o,p8o,afe,u8o,_8o,b8o,p1,nfe,v8o,F8o,VD,T8o,M8o,E8o,u1,sfe,C8o,w8o,XD,A8o,y8o,L8o,_1,lfe,x8o,$8o,zD,k8o,S8o,R8o,b1,ife,P8o,B8o,WD,I8o,q8o,N8o,v1,j8o,dfe,D8o,G8o,cfe,O8o,V8o,F1,MNe,Di,T1,ffe,vy,X8o,mfe,z8o,ENe,So,Fy,W8o,Gi,Q8o,QD,H8o,U8o,HD,J8o,Y8o,K8o,Ty,Z8o,gfe,e9o,o9o,r9o,lt,My,t9o,hfe,a9o,n9o,Oi,s9o,pfe,l9o,i9o,UD,d9o,c9o,f9o,M1,m9o,eo,Ey,g9o,ufe,h9o,p9o,Sa,u9o,_fe,_9o,b9o,bfe,v9o,F9o,vfe,T9o,M9o,E9o,ue,E1,Ffe,C9o,w9o,JD,A9o,y9o,L9o,C1,Tfe,x9o,$9o,YD,k9o,S9o,R9o,w1,Mfe,P9o,B9o,KD,I9o,q9o,N9o,A1,Efe,j9o,D9o,ZD,G9o,O9o,V9o,y1,Cfe,X9o,z9o,eG,W9o,Q9o,H9o,L1,wfe,U9o,J9o,oG,Y9o,K9o,Z9o,x1,Afe,exo,oxo,rG,rxo,txo,axo,$1,yfe,nxo,sxo,tG,lxo,ixo,dxo,k1,Lfe,cxo,fxo,aG,mxo,gxo,hxo,S1,xfe,pxo,uxo,nG,_xo,bxo,vxo,R1,$fe,Fxo,Txo,sG,Mxo,Exo,Cxo,P1,kfe,wxo,Axo,lG,yxo,Lxo,xxo,B1,Sfe,$xo,kxo,iG,Sxo,Rxo,Pxo,I1,Rfe,Bxo,Ixo,dG,qxo,Nxo,jxo,q1,Pfe,Dxo,Gxo,cG,Oxo,Vxo,Xxo,N1,Bfe,zxo,Wxo,fG,Qxo,Hxo,Uxo,j1,Jxo,Ife,Yxo,Kxo,qfe,Zxo,e$o,D1,CNe,Vi,G1,Nfe,Cy,o$o,jfe,r$o,wNe,Ro,wy,t$o,Xi,a$o,mG,n$o,s$o,gG,l$o,i$o,d$o,Ay,c$o,Dfe,f$o,m$o,g$o,it,yy,h$o,Gfe,p$o,u$o,zi,_$o,Ofe,b$o,v$o,hG,F$o,T$o,M$o,O1,E$o,oo,Ly,C$o,Vfe,w$o,A$o,Ra,y$o,Xfe,L$o,x$o,zfe,$$o,k$o,Wfe,S$o,R$o,P$o,q,V1,Qfe,B$o,I$o,pG,q$o,N$o,j$o,X1,Hfe,D$o,G$o,uG,O$o,V$o,X$o,z1,Ufe,z$o,W$o,_G,Q$o,H$o,U$o,W1,Jfe,J$o,Y$o,bG,K$o,Z$o,eko,Q1,Yfe,oko,rko,vG,tko,ako,nko,H1,Kfe,sko,lko,FG,iko,dko,cko,U1,Zfe,fko,mko,TG,gko,hko,pko,J1,eme,uko,_ko,MG,bko,vko,Fko,Y1,ome,Tko,Mko,EG,Eko,Cko,wko,K1,rme,Ako,yko,CG,Lko,xko,$ko,Z1,tme,kko,Sko,wG,Rko,Pko,Bko,eb,ame,Iko,qko,AG,Nko,jko,Dko,ob,nme,Gko,Oko,yG,Vko,Xko,zko,rb,sme,Wko,Qko,LG,Hko,Uko,Jko,tb,lme,Yko,Kko,xG,Zko,eSo,oSo,ab,ime,rSo,tSo,$G,aSo,nSo,sSo,nb,dme,lSo,iSo,kG,dSo,cSo,fSo,sb,cme,mSo,gSo,SG,hSo,pSo,uSo,lb,fme,_So,bSo,RG,vSo,FSo,TSo,ib,mme,MSo,ESo,PG,CSo,wSo,ASo,db,gme,ySo,LSo,BG,xSo,$So,kSo,cb,hme,SSo,RSo,IG,PSo,BSo,ISo,fb,pme,qSo,NSo,qG,jSo,DSo,GSo,mb,ume,OSo,VSo,NG,XSo,zSo,WSo,gb,_me,QSo,HSo,jG,USo,JSo,YSo,hb,bme,KSo,ZSo,DG,eRo,oRo,rRo,pb,vme,tRo,aRo,GG,nRo,sRo,lRo,ub,Fme,iRo,dRo,OG,cRo,fRo,mRo,_b,Tme,gRo,hRo,VG,pRo,uRo,_Ro,bb,Mme,bRo,vRo,XG,FRo,TRo,MRo,vb,Eme,ERo,CRo,zG,wRo,ARo,yRo,Fb,Cme,LRo,xRo,WG,$Ro,kRo,SRo,Tb,wme,RRo,PRo,QG,BRo,IRo,qRo,Mb,Ame,NRo,jRo,HG,DRo,GRo,ORo,Eb,yme,VRo,XRo,UG,zRo,WRo,QRo,Cb,Lme,HRo,URo,JG,JRo,YRo,KRo,wb,xme,ZRo,ePo,YG,oPo,rPo,tPo,Ab,$me,aPo,nPo,KG,sPo,lPo,iPo,yb,kme,dPo,cPo,ZG,fPo,mPo,gPo,Lb,Sme,hPo,pPo,eO,uPo,_Po,bPo,xb,Rme,vPo,FPo,oO,TPo,MPo,EPo,$b,Pme,CPo,wPo,rO,APo,yPo,LPo,kb,Bme,xPo,$Po,tO,kPo,SPo,RPo,Sb,Ime,PPo,BPo,aO,IPo,qPo,NPo,Rb,qme,jPo,DPo,nO,GPo,OPo,VPo,Pb,Nme,XPo,zPo,sO,WPo,QPo,HPo,Bb,jme,UPo,JPo,lO,YPo,KPo,ZPo,Ib,eBo,Dme,oBo,rBo,Gme,tBo,aBo,qb,ANe,Wi,Nb,Ome,xy,nBo,Vme,sBo,yNe,Po,$y,lBo,Qi,iBo,iO,dBo,cBo,dO,fBo,mBo,gBo,ky,hBo,Xme,pBo,uBo,_Bo,dt,Sy,bBo,zme,vBo,FBo,Hi,TBo,Wme,MBo,EBo,cO,CBo,wBo,ABo,jb,yBo,ro,Ry,LBo,Qme,xBo,$Bo,Pa,kBo,Hme,SBo,RBo,Ume,PBo,BBo,Jme,IBo,qBo,NBo,K,Db,Yme,jBo,DBo,fO,GBo,OBo,VBo,Gb,Kme,XBo,zBo,mO,WBo,QBo,HBo,Ob,Zme,UBo,JBo,gO,YBo,KBo,ZBo,Vb,ege,eIo,oIo,hO,rIo,tIo,aIo,Xb,oge,nIo,sIo,pO,lIo,iIo,dIo,zb,rge,cIo,fIo,uO,mIo,gIo,hIo,Wb,tge,pIo,uIo,_O,_Io,bIo,vIo,Qb,age,FIo,TIo,bO,MIo,EIo,CIo,Hb,nge,wIo,AIo,vO,yIo,LIo,xIo,Ub,sge,$Io,kIo,FO,SIo,RIo,PIo,Jb,lge,BIo,IIo,TO,qIo,NIo,jIo,Yb,ige,DIo,GIo,MO,OIo,VIo,XIo,Kb,dge,zIo,WIo,EO,QIo,HIo,UIo,Zb,cge,JIo,YIo,CO,KIo,ZIo,eqo,e4,fge,oqo,rqo,wO,tqo,aqo,nqo,o4,mge,sqo,lqo,AO,iqo,dqo,cqo,r4,gge,fqo,mqo,yO,gqo,hqo,pqo,t4,hge,uqo,_qo,LO,bqo,vqo,Fqo,a4,pge,Tqo,Mqo,xO,Eqo,Cqo,wqo,n4,uge,Aqo,yqo,$O,Lqo,xqo,$qo,s4,_ge,kqo,Sqo,kO,Rqo,Pqo,Bqo,l4,bge,Iqo,qqo,SO,Nqo,jqo,Dqo,i4,vge,Gqo,Oqo,RO,Vqo,Xqo,zqo,d4,Fge,Wqo,Qqo,PO,Hqo,Uqo,Jqo,c4,Tge,Yqo,Kqo,BO,Zqo,eNo,oNo,f4,Mge,rNo,tNo,IO,aNo,nNo,sNo,m4,Ege,lNo,iNo,qO,dNo,cNo,fNo,g4,Cge,mNo,gNo,NO,hNo,pNo,uNo,h4,wge,_No,bNo,jO,vNo,FNo,TNo,p4,MNo,Age,ENo,CNo,yge,wNo,ANo,u4,LNe,Ui,_4,Lge,Py,yNo,xge,LNo,xNe,Bo,By,xNo,Ji,$No,DO,kNo,SNo,GO,RNo,PNo,BNo,Iy,INo,$ge,qNo,NNo,jNo,ct,qy,DNo,kge,GNo,ONo,Yi,VNo,Sge,XNo,zNo,OO,WNo,QNo,HNo,b4,UNo,to,Ny,JNo,Rge,YNo,KNo,Ba,ZNo,Pge,ejo,ojo,Bge,rjo,tjo,Ige,ajo,njo,sjo,Yr,v4,qge,ljo,ijo,VO,djo,cjo,fjo,F4,Nge,mjo,gjo,XO,hjo,pjo,ujo,T4,jge,_jo,bjo,zO,vjo,Fjo,Tjo,M4,Dge,Mjo,Ejo,WO,Cjo,wjo,Ajo,E4,Gge,yjo,Ljo,QO,xjo,$jo,kjo,C4,Sjo,Oge,Rjo,Pjo,Vge,Bjo,Ijo,w4,$Ne,Ki,A4,Xge,jy,qjo,zge,Njo,kNe,Io,Dy,jjo,Zi,Djo,HO,Gjo,Ojo,UO,Vjo,Xjo,zjo,Gy,Wjo,Wge,Qjo,Hjo,Ujo,ft,Oy,Jjo,Qge,Yjo,Kjo,ed,Zjo,Hge,eDo,oDo,JO,rDo,tDo,aDo,y4,nDo,ao,Vy,sDo,Uge,lDo,iDo,Ia,dDo,Jge,cDo,fDo,Yge,mDo,gDo,Kge,hDo,pDo,uDo,H,L4,Zge,_Do,bDo,YO,vDo,FDo,TDo,x4,ehe,MDo,EDo,KO,CDo,wDo,ADo,$4,ohe,yDo,LDo,ZO,xDo,$Do,kDo,k4,rhe,SDo,RDo,eV,PDo,BDo,IDo,S4,the,qDo,NDo,oV,jDo,DDo,GDo,R4,ahe,ODo,VDo,rV,XDo,zDo,WDo,P4,nhe,QDo,HDo,tV,UDo,JDo,YDo,B4,she,KDo,ZDo,aV,eGo,oGo,rGo,I4,lhe,tGo,aGo,nV,nGo,sGo,lGo,q4,ihe,iGo,dGo,sV,cGo,fGo,mGo,N4,dhe,gGo,hGo,lV,pGo,uGo,_Go,j4,che,bGo,vGo,iV,FGo,TGo,MGo,D4,fhe,EGo,CGo,dV,wGo,AGo,yGo,G4,mhe,LGo,xGo,cV,$Go,kGo,SGo,O4,ghe,RGo,PGo,fV,BGo,IGo,qGo,V4,hhe,NGo,jGo,mV,DGo,GGo,OGo,X4,phe,VGo,XGo,gV,zGo,WGo,QGo,z4,uhe,HGo,UGo,hV,JGo,YGo,KGo,W4,_he,ZGo,eOo,pV,oOo,rOo,tOo,Q4,bhe,aOo,nOo,uV,sOo,lOo,iOo,H4,vhe,dOo,cOo,_V,fOo,mOo,gOo,U4,Fhe,hOo,pOo,bV,uOo,_Oo,bOo,J4,The,vOo,FOo,vV,TOo,MOo,EOo,Y4,Mhe,COo,wOo,FV,AOo,yOo,LOo,K4,Ehe,xOo,$Oo,TV,kOo,SOo,ROo,Z4,Che,POo,BOo,MV,IOo,qOo,NOo,ev,whe,jOo,DOo,EV,GOo,OOo,VOo,ov,Ahe,XOo,zOo,CV,WOo,QOo,HOo,rv,yhe,UOo,JOo,wV,YOo,KOo,ZOo,tv,Lhe,eVo,oVo,AV,rVo,tVo,aVo,av,xhe,nVo,sVo,yV,lVo,iVo,dVo,nv,$he,cVo,fVo,LV,mVo,gVo,hVo,sv,khe,pVo,uVo,xV,_Vo,bVo,vVo,lv,She,FVo,TVo,$V,MVo,EVo,CVo,iv,wVo,Rhe,AVo,yVo,Phe,LVo,xVo,dv,SNe,od,cv,Bhe,Xy,$Vo,Ihe,kVo,RNe,qo,zy,SVo,rd,RVo,kV,PVo,BVo,SV,IVo,qVo,NVo,Wy,jVo,qhe,DVo,GVo,OVo,mt,Qy,VVo,Nhe,XVo,zVo,td,WVo,jhe,QVo,HVo,RV,UVo,JVo,YVo,fv,KVo,no,Hy,ZVo,Dhe,eXo,oXo,qa,rXo,Ghe,tXo,aXo,Ohe,nXo,sXo,Vhe,lXo,iXo,dXo,V,mv,Xhe,cXo,fXo,PV,mXo,gXo,hXo,gv,zhe,pXo,uXo,BV,_Xo,bXo,vXo,hv,Whe,FXo,TXo,IV,MXo,EXo,CXo,pv,Qhe,wXo,AXo,qV,yXo,LXo,xXo,uv,Hhe,$Xo,kXo,NV,SXo,RXo,PXo,_v,Uhe,BXo,IXo,jV,qXo,NXo,jXo,bv,Jhe,DXo,GXo,DV,OXo,VXo,XXo,vv,Yhe,zXo,WXo,GV,QXo,HXo,UXo,Fv,Khe,JXo,YXo,OV,KXo,ZXo,ezo,Tv,Zhe,ozo,rzo,VV,tzo,azo,nzo,Mv,epe,szo,lzo,XV,izo,dzo,czo,Ev,ope,fzo,mzo,zV,gzo,hzo,pzo,Cv,rpe,uzo,_zo,WV,bzo,vzo,Fzo,wv,tpe,Tzo,Mzo,QV,Ezo,Czo,wzo,Av,ape,Azo,yzo,HV,Lzo,xzo,$zo,yv,npe,kzo,Szo,UV,Rzo,Pzo,Bzo,Lv,spe,Izo,qzo,JV,Nzo,jzo,Dzo,xv,lpe,Gzo,Ozo,YV,Vzo,Xzo,zzo,$v,ipe,Wzo,Qzo,KV,Hzo,Uzo,Jzo,kv,dpe,Yzo,Kzo,ZV,Zzo,eWo,oWo,Sv,cpe,rWo,tWo,eX,aWo,nWo,sWo,Rv,fpe,lWo,iWo,oX,dWo,cWo,fWo,Pv,mpe,mWo,gWo,rX,hWo,pWo,uWo,Bv,gpe,_Wo,bWo,tX,vWo,FWo,TWo,Iv,hpe,MWo,EWo,aX,CWo,wWo,AWo,qv,ppe,yWo,LWo,nX,xWo,$Wo,kWo,Nv,upe,SWo,RWo,sX,PWo,BWo,IWo,jv,_pe,qWo,NWo,lX,jWo,DWo,GWo,Dv,bpe,OWo,VWo,iX,XWo,zWo,WWo,Gv,vpe,QWo,HWo,dX,UWo,JWo,YWo,Ov,Fpe,KWo,ZWo,cX,eQo,oQo,rQo,Vv,Tpe,tQo,aQo,fX,nQo,sQo,lQo,Xv,Mpe,iQo,dQo,mX,cQo,fQo,mQo,zv,Epe,gQo,hQo,gX,pQo,uQo,_Qo,Wv,Cpe,bQo,vQo,hX,FQo,TQo,MQo,Qv,wpe,EQo,CQo,pX,wQo,AQo,yQo,Hv,Ape,LQo,xQo,uX,$Qo,kQo,SQo,Uv,ype,RQo,PQo,_X,BQo,IQo,qQo,Jv,Lpe,NQo,jQo,bX,DQo,GQo,OQo,Yv,xpe,VQo,XQo,vX,zQo,WQo,QQo,Kv,HQo,$pe,UQo,JQo,kpe,YQo,KQo,Zv,PNe,ad,e5,Spe,Uy,ZQo,Rpe,eHo,BNe,No,Jy,oHo,nd,rHo,FX,tHo,aHo,TX,nHo,sHo,lHo,Yy,iHo,Ppe,dHo,cHo,fHo,gt,Ky,mHo,Bpe,gHo,hHo,sd,pHo,Ipe,uHo,_Ho,MX,bHo,vHo,FHo,o5,THo,so,Zy,MHo,qpe,EHo,CHo,Na,wHo,Npe,AHo,yHo,jpe,LHo,xHo,Dpe,$Ho,kHo,SHo,Gpe,r5,Ope,RHo,PHo,EX,BHo,IHo,qHo,t5,NHo,Vpe,jHo,DHo,Xpe,GHo,OHo,a5,INe,ld,n5,zpe,eL,VHo,Wpe,XHo,qNe,jo,oL,zHo,id,WHo,CX,QHo,HHo,wX,UHo,JHo,YHo,rL,KHo,Qpe,ZHo,eUo,oUo,ht,tL,rUo,Hpe,tUo,aUo,dd,nUo,Upe,sUo,lUo,AX,iUo,dUo,cUo,s5,fUo,lo,aL,mUo,Jpe,gUo,hUo,ja,pUo,Ype,uUo,_Uo,Kpe,bUo,vUo,Zpe,FUo,TUo,MUo,Fe,l5,eue,EUo,CUo,yX,wUo,AUo,yUo,i5,oue,LUo,xUo,LX,$Uo,kUo,SUo,d5,rue,RUo,PUo,xX,BUo,IUo,qUo,c5,tue,NUo,jUo,$X,DUo,GUo,OUo,Ns,aue,VUo,XUo,kX,zUo,WUo,SX,QUo,HUo,UUo,f5,nue,JUo,YUo,RX,KUo,ZUo,eJo,pt,sue,oJo,rJo,PX,tJo,aJo,BX,nJo,sJo,IX,lJo,iJo,dJo,m5,lue,cJo,fJo,qX,mJo,gJo,hJo,g5,iue,pJo,uJo,NX,_Jo,bJo,vJo,h5,due,FJo,TJo,jX,MJo,EJo,CJo,p5,cue,wJo,AJo,DX,yJo,LJo,xJo,u5,fue,$Jo,kJo,GX,SJo,RJo,PJo,_5,mue,BJo,IJo,OX,qJo,NJo,jJo,b5,gue,DJo,GJo,VX,OJo,VJo,XJo,v5,zJo,hue,WJo,QJo,pue,HJo,UJo,F5,NNe,cd,T5,uue,nL,JJo,_ue,YJo,jNe,Do,sL,KJo,fd,ZJo,XX,eYo,oYo,zX,rYo,tYo,aYo,lL,nYo,bue,sYo,lYo,iYo,ut,iL,dYo,vue,cYo,fYo,md,mYo,Fue,gYo,hYo,WX,pYo,uYo,_Yo,M5,bYo,io,dL,vYo,Tue,FYo,TYo,Da,MYo,Mue,EYo,CYo,Eue,wYo,AYo,Cue,yYo,LYo,xYo,wue,E5,Aue,$Yo,kYo,QX,SYo,RYo,PYo,C5,BYo,yue,IYo,qYo,Lue,NYo,jYo,w5,DNe,gd,A5,xue,cL,DYo,$ue,GYo,GNe,Go,fL,OYo,hd,VYo,HX,XYo,zYo,UX,WYo,QYo,HYo,mL,UYo,kue,JYo,YYo,KYo,_t,gL,ZYo,Sue,eKo,oKo,pd,rKo,Rue,tKo,aKo,JX,nKo,sKo,lKo,y5,iKo,co,hL,dKo,Pue,cKo,fKo,Ga,mKo,Bue,gKo,hKo,Iue,pKo,uKo,que,_Ko,bKo,vKo,ke,L5,Nue,FKo,TKo,YX,MKo,EKo,CKo,x5,jue,wKo,AKo,KX,yKo,LKo,xKo,$5,Due,$Ko,kKo,ZX,SKo,RKo,PKo,k5,Gue,BKo,IKo,ez,qKo,NKo,jKo,S5,Oue,DKo,GKo,oz,OKo,VKo,XKo,R5,Vue,zKo,WKo,rz,QKo,HKo,UKo,P5,Xue,JKo,YKo,tz,KKo,ZKo,eZo,B5,zue,oZo,rZo,az,tZo,aZo,nZo,I5,Wue,sZo,lZo,nz,iZo,dZo,cZo,q5,fZo,Que,mZo,gZo,Hue,hZo,pZo,N5,ONe,ud,j5,Uue,pL,uZo,Jue,_Zo,VNe,Oo,uL,bZo,_d,vZo,sz,FZo,TZo,lz,MZo,EZo,CZo,_L,wZo,Yue,AZo,yZo,LZo,bt,bL,xZo,Kue,$Zo,kZo,bd,SZo,Zue,RZo,PZo,iz,BZo,IZo,qZo,D5,NZo,fo,vL,jZo,e_e,DZo,GZo,Oa,OZo,o_e,VZo,XZo,r_e,zZo,WZo,t_e,QZo,HZo,UZo,Kr,G5,a_e,JZo,YZo,dz,KZo,ZZo,eer,O5,n_e,oer,rer,cz,ter,aer,ner,V5,s_e,ser,ler,fz,ier,der,cer,X5,l_e,fer,mer,mz,ger,her,per,z5,i_e,uer,_er,gz,ber,ver,Fer,W5,Ter,d_e,Mer,Eer,c_e,Cer,wer,Q5,XNe,vd,H5,f_e,FL,Aer,m_e,yer,zNe,Vo,TL,Ler,Fd,xer,hz,$er,ker,pz,Ser,Rer,Per,ML,Ber,g_e,Ier,qer,Ner,vt,EL,jer,h_e,Der,Ger,Td,Oer,p_e,Ver,Xer,uz,zer,Wer,Qer,U5,Her,mo,CL,Uer,u_e,Jer,Yer,Va,Ker,__e,Zer,eor,b_e,oor,ror,v_e,tor,aor,nor,Se,J5,F_e,sor,lor,_z,ior,dor,cor,Y5,T_e,mor,gor,bz,hor,por,uor,K5,M_e,_or,bor,vz,vor,For,Tor,Z5,E_e,Mor,Eor,Fz,Cor,wor,Aor,eF,C_e,yor,Lor,Tz,xor,$or,kor,oF,w_e,Sor,Ror,Mz,Por,Bor,Ior,rF,A_e,qor,Nor,Ez,jor,Dor,Gor,tF,y_e,Oor,Vor,Cz,Xor,zor,Wor,aF,L_e,Qor,Hor,wz,Uor,Jor,Yor,nF,Kor,x_e,Zor,err,$_e,orr,rrr,sF,WNe,Md,lF,k_e,wL,trr,S_e,arr,QNe,Xo,AL,nrr,Ed,srr,Az,lrr,irr,yz,drr,crr,frr,yL,mrr,R_e,grr,hrr,prr,Ft,LL,urr,P_e,_rr,brr,Cd,vrr,B_e,Frr,Trr,Lz,Mrr,Err,Crr,iF,wrr,go,xL,Arr,I_e,yrr,Lrr,Xa,xrr,q_e,$rr,krr,N_e,Srr,Rrr,j_e,Prr,Brr,Irr,$L,dF,D_e,qrr,Nrr,xz,jrr,Drr,Grr,cF,G_e,Orr,Vrr,$z,Xrr,zrr,Wrr,fF,Qrr,O_e,Hrr,Urr,V_e,Jrr,Yrr,mF,HNe,wd,gF,X_e,kL,Krr,z_e,Zrr,UNe,zo,SL,etr,Ad,otr,kz,rtr,ttr,Sz,atr,ntr,str,RL,ltr,W_e,itr,dtr,ctr,Tt,PL,ftr,Q_e,mtr,gtr,yd,htr,H_e,ptr,utr,Rz,_tr,btr,vtr,hF,Ftr,ho,BL,Ttr,U_e,Mtr,Etr,za,Ctr,J_e,wtr,Atr,Y_e,ytr,Ltr,K_e,xtr,$tr,ktr,Zr,pF,Z_e,Str,Rtr,Pz,Ptr,Btr,Itr,uF,e2e,qtr,Ntr,Bz,jtr,Dtr,Gtr,_F,o2e,Otr,Vtr,Iz,Xtr,ztr,Wtr,bF,r2e,Qtr,Htr,qz,Utr,Jtr,Ytr,vF,t2e,Ktr,Ztr,Nz,ear,oar,rar,FF,tar,a2e,aar,nar,n2e,sar,lar,TF,JNe,Ld,MF,s2e,IL,iar,l2e,dar,YNe,Wo,qL,car,xd,far,jz,mar,gar,Dz,har,par,uar,NL,_ar,i2e,bar,Far,Tar,Mt,jL,Mar,d2e,Ear,Car,$d,war,c2e,Aar,yar,Gz,Lar,xar,$ar,EF,kar,po,DL,Sar,f2e,Rar,Par,Wa,Bar,m2e,Iar,qar,g2e,Nar,jar,h2e,Dar,Gar,Oar,kd,CF,p2e,Var,Xar,Oz,zar,War,Qar,wF,u2e,Har,Uar,Vz,Jar,Yar,Kar,AF,_2e,Zar,enr,Xz,onr,rnr,tnr,yF,anr,b2e,nnr,snr,v2e,lnr,inr,LF,KNe,Sd,xF,F2e,GL,dnr,T2e,cnr,ZNe,Qo,OL,fnr,Rd,mnr,zz,gnr,hnr,Wz,pnr,unr,_nr,VL,bnr,M2e,vnr,Fnr,Tnr,Et,XL,Mnr,E2e,Enr,Cnr,Pd,wnr,C2e,Anr,ynr,Qz,Lnr,xnr,$nr,$F,knr,uo,zL,Snr,w2e,Rnr,Pnr,Qa,Bnr,A2e,Inr,qnr,y2e,Nnr,jnr,L2e,Dnr,Gnr,Onr,WL,kF,x2e,Vnr,Xnr,Hz,znr,Wnr,Qnr,SF,$2e,Hnr,Unr,Uz,Jnr,Ynr,Knr,RF,Znr,k2e,esr,osr,S2e,rsr,tsr,PF,eje,Bd,BF,R2e,QL,asr,P2e,nsr,oje,Ho,HL,ssr,Id,lsr,Jz,isr,dsr,Yz,csr,fsr,msr,UL,gsr,B2e,hsr,psr,usr,Ct,JL,_sr,I2e,bsr,vsr,qd,Fsr,q2e,Tsr,Msr,Kz,Esr,Csr,wsr,IF,Asr,_o,YL,ysr,N2e,Lsr,xsr,Ha,$sr,j2e,ksr,Ssr,D2e,Rsr,Psr,G2e,Bsr,Isr,qsr,O2e,qF,V2e,Nsr,jsr,Zz,Dsr,Gsr,Osr,NF,Vsr,X2e,Xsr,zsr,z2e,Wsr,Qsr,jF,rje,Nd,DF,W2e,KL,Hsr,Q2e,Usr,tje,Uo,ZL,Jsr,jd,Ysr,eW,Ksr,Zsr,oW,elr,olr,rlr,e8,tlr,H2e,alr,nlr,slr,wt,o8,llr,U2e,ilr,dlr,Dd,clr,J2e,flr,mlr,rW,glr,hlr,plr,GF,ulr,bo,r8,_lr,Y2e,blr,vlr,Ua,Flr,K2e,Tlr,Mlr,Z2e,Elr,Clr,e1e,wlr,Alr,ylr,Ja,OF,o1e,Llr,xlr,tW,$lr,klr,Slr,VF,r1e,Rlr,Plr,aW,Blr,Ilr,qlr,XF,t1e,Nlr,jlr,nW,Dlr,Glr,Olr,zF,a1e,Vlr,Xlr,sW,zlr,Wlr,Qlr,WF,Hlr,n1e,Ulr,Jlr,s1e,Ylr,Klr,QF,aje,Gd,HF,l1e,t8,Zlr,i1e,eir,nje,Jo,a8,oir,Od,rir,lW,tir,air,iW,nir,sir,lir,n8,iir,d1e,dir,cir,fir,At,s8,mir,c1e,gir,hir,Vd,pir,f1e,uir,_ir,dW,bir,vir,Fir,UF,Tir,vo,l8,Mir,m1e,Eir,Cir,Ya,wir,g1e,Air,yir,h1e,Lir,xir,p1e,$ir,kir,Sir,u1e,JF,_1e,Rir,Pir,cW,Bir,Iir,qir,YF,Nir,b1e,jir,Dir,v1e,Gir,Oir,KF,sje,Xd,ZF,F1e,i8,Vir,T1e,Xir,lje,Yo,d8,zir,zd,Wir,fW,Qir,Hir,mW,Uir,Jir,Yir,c8,Kir,M1e,Zir,edr,odr,yt,f8,rdr,E1e,tdr,adr,Wd,ndr,C1e,sdr,ldr,gW,idr,ddr,cdr,eT,fdr,wr,m8,mdr,w1e,gdr,hdr,Ka,pdr,A1e,udr,_dr,y1e,bdr,vdr,L1e,Fdr,Tdr,Mdr,N,oT,x1e,Edr,Cdr,hW,wdr,Adr,ydr,rT,$1e,Ldr,xdr,pW,$dr,kdr,Sdr,tT,k1e,Rdr,Pdr,uW,Bdr,Idr,qdr,aT,S1e,Ndr,jdr,_W,Ddr,Gdr,Odr,nT,R1e,Vdr,Xdr,bW,zdr,Wdr,Qdr,sT,P1e,Hdr,Udr,vW,Jdr,Ydr,Kdr,lT,B1e,Zdr,ecr,FW,ocr,rcr,tcr,iT,I1e,acr,ncr,TW,scr,lcr,icr,dT,q1e,dcr,ccr,MW,fcr,mcr,gcr,cT,N1e,hcr,pcr,EW,ucr,_cr,bcr,fT,j1e,vcr,Fcr,CW,Tcr,Mcr,Ecr,mT,D1e,Ccr,wcr,wW,Acr,ycr,Lcr,gT,G1e,xcr,$cr,AW,kcr,Scr,Rcr,hT,O1e,Pcr,Bcr,yW,Icr,qcr,Ncr,pT,V1e,jcr,Dcr,LW,Gcr,Ocr,Vcr,uT,X1e,Xcr,zcr,xW,Wcr,Qcr,Hcr,_T,z1e,Ucr,Jcr,$W,Ycr,Kcr,Zcr,js,W1e,efr,ofr,kW,rfr,tfr,SW,afr,nfr,sfr,bT,Q1e,lfr,ifr,RW,dfr,cfr,ffr,vT,H1e,mfr,gfr,PW,hfr,pfr,ufr,FT,U1e,_fr,bfr,BW,vfr,Ffr,Tfr,TT,J1e,Mfr,Efr,IW,Cfr,wfr,Afr,MT,Y1e,yfr,Lfr,qW,xfr,$fr,kfr,ET,K1e,Sfr,Rfr,NW,Pfr,Bfr,Ifr,CT,Z1e,qfr,Nfr,jW,jfr,Dfr,Gfr,wT,ebe,Ofr,Vfr,DW,Xfr,zfr,Wfr,AT,obe,Qfr,Hfr,GW,Ufr,Jfr,Yfr,yT,rbe,Kfr,Zfr,OW,emr,omr,rmr,LT,tbe,tmr,amr,VW,nmr,smr,lmr,xT,abe,imr,dmr,XW,cmr,fmr,mmr,$T,nbe,gmr,hmr,zW,pmr,umr,_mr,kT,sbe,bmr,vmr,WW,Fmr,Tmr,Mmr,ST,lbe,Emr,Cmr,QW,wmr,Amr,ymr,RT,ibe,Lmr,xmr,HW,$mr,kmr,Smr,PT,dbe,Rmr,Pmr,UW,Bmr,Imr,qmr,BT,cbe,Nmr,jmr,JW,Dmr,Gmr,Omr,IT,fbe,Vmr,Xmr,YW,zmr,Wmr,Qmr,qT,mbe,Hmr,Umr,KW,Jmr,Ymr,Kmr,NT,gbe,Zmr,egr,ZW,ogr,rgr,tgr,jT,hbe,agr,ngr,eQ,sgr,lgr,igr,DT,pbe,dgr,cgr,oQ,fgr,mgr,ggr,GT,ube,hgr,pgr,rQ,ugr,_gr,bgr,OT,_be,vgr,Fgr,tQ,Tgr,Mgr,Egr,VT,bbe,Cgr,wgr,aQ,Agr,ygr,Lgr,XT,vbe,xgr,$gr,nQ,kgr,Sgr,Rgr,zT,Fbe,Pgr,Bgr,sQ,Igr,qgr,Ngr,WT,ije,Qd,QT,Tbe,g8,jgr,Mbe,Dgr,dje,Ko,h8,Ggr,Hd,Ogr,lQ,Vgr,Xgr,iQ,zgr,Wgr,Qgr,p8,Hgr,Ebe,Ugr,Jgr,Ygr,Lt,u8,Kgr,Cbe,Zgr,ehr,Ud,ohr,wbe,rhr,thr,dQ,ahr,nhr,shr,HT,lhr,Ar,_8,ihr,Abe,dhr,chr,Za,fhr,ybe,mhr,ghr,Lbe,hhr,phr,xbe,uhr,_hr,bhr,se,UT,$be,vhr,Fhr,cQ,Thr,Mhr,Ehr,JT,kbe,Chr,whr,fQ,Ahr,yhr,Lhr,YT,Sbe,xhr,$hr,mQ,khr,Shr,Rhr,KT,Rbe,Phr,Bhr,gQ,Ihr,qhr,Nhr,ZT,Pbe,jhr,Dhr,hQ,Ghr,Ohr,Vhr,e7,Bbe,Xhr,zhr,pQ,Whr,Qhr,Hhr,o7,Ibe,Uhr,Jhr,uQ,Yhr,Khr,Zhr,r7,qbe,epr,opr,_Q,rpr,tpr,apr,t7,Nbe,npr,spr,bQ,lpr,ipr,dpr,a7,jbe,cpr,fpr,vQ,mpr,gpr,hpr,n7,Dbe,ppr,upr,FQ,_pr,bpr,vpr,s7,Gbe,Fpr,Tpr,TQ,Mpr,Epr,Cpr,l7,Obe,wpr,Apr,MQ,ypr,Lpr,xpr,i7,Vbe,$pr,kpr,EQ,Spr,Rpr,Ppr,d7,Xbe,Bpr,Ipr,CQ,qpr,Npr,jpr,c7,zbe,Dpr,Gpr,wQ,Opr,Vpr,Xpr,f7,Wbe,zpr,Wpr,AQ,Qpr,Hpr,Upr,m7,Qbe,Jpr,Ypr,yQ,Kpr,Zpr,eur,g7,Hbe,our,rur,LQ,tur,aur,nur,h7,Ube,sur,lur,xQ,iur,dur,cur,p7,Jbe,fur,mur,$Q,gur,hur,pur,u7,Ybe,uur,_ur,kQ,bur,vur,Fur,_7,Kbe,Tur,Mur,SQ,Eur,Cur,wur,b7,cje,Jd,v7,Zbe,b8,Aur,e4e,yur,fje,Zo,v8,Lur,Yd,xur,RQ,$ur,kur,PQ,Sur,Rur,Pur,F8,Bur,o4e,Iur,qur,Nur,xt,T8,jur,r4e,Dur,Gur,Kd,Our,t4e,Vur,Xur,BQ,zur,Wur,Qur,F7,Hur,yr,M8,Uur,a4e,Jur,Yur,en,Kur,n4e,Zur,e_r,s4e,o_r,r_r,l4e,t_r,a_r,n_r,Me,T7,i4e,s_r,l_r,IQ,i_r,d_r,c_r,M7,d4e,f_r,m_r,qQ,g_r,h_r,p_r,E7,c4e,u_r,__r,NQ,b_r,v_r,F_r,C7,f4e,T_r,M_r,jQ,E_r,C_r,w_r,w7,m4e,A_r,y_r,DQ,L_r,x_r,$_r,A7,g4e,k_r,S_r,GQ,R_r,P_r,B_r,y7,h4e,I_r,q_r,OQ,N_r,j_r,D_r,L7,p4e,G_r,O_r,VQ,V_r,X_r,z_r,x7,u4e,W_r,Q_r,XQ,H_r,U_r,J_r,$7,_4e,Y_r,K_r,zQ,Z_r,e2r,o2r,k7,b4e,r2r,t2r,WQ,a2r,n2r,s2r,S7,v4e,l2r,i2r,QQ,d2r,c2r,f2r,R7,mje,Zd,P7,F4e,E8,m2r,T4e,g2r,gje,er,C8,h2r,ec,p2r,HQ,u2r,_2r,UQ,b2r,v2r,F2r,w8,T2r,M4e,M2r,E2r,C2r,$t,A8,w2r,E4e,A2r,y2r,oc,L2r,C4e,x2r,$2r,JQ,k2r,S2r,R2r,B7,P2r,Lr,y8,B2r,w4e,I2r,q2r,on,N2r,A4e,j2r,D2r,y4e,G2r,O2r,L4e,V2r,X2r,z2r,rn,I7,x4e,W2r,Q2r,YQ,H2r,U2r,J2r,q7,$4e,Y2r,K2r,KQ,Z2r,e1r,o1r,N7,k4e,r1r,t1r,ZQ,a1r,n1r,s1r,j7,S4e,l1r,i1r,eH,d1r,c1r,f1r,D7,hje,rc,G7,R4e,L8,m1r,P4e,g1r,pje,or,x8,h1r,tc,p1r,oH,u1r,_1r,rH,b1r,v1r,F1r,$8,T1r,B4e,M1r,E1r,C1r,kt,k8,w1r,I4e,A1r,y1r,ac,L1r,q4e,x1r,$1r,tH,k1r,S1r,R1r,O7,P1r,xr,S8,B1r,N4e,I1r,q1r,tn,N1r,j4e,j1r,D1r,D4e,G1r,O1r,G4e,V1r,X1r,z1r,ie,V7,O4e,W1r,Q1r,aH,H1r,U1r,J1r,X7,V4e,Y1r,K1r,nH,Z1r,ebr,obr,z7,X4e,rbr,tbr,sH,abr,nbr,sbr,W7,z4e,lbr,ibr,lH,dbr,cbr,fbr,Q7,W4e,mbr,gbr,iH,hbr,pbr,ubr,H7,Q4e,_br,bbr,dH,vbr,Fbr,Tbr,U7,H4e,Mbr,Ebr,cH,Cbr,wbr,Abr,J7,U4e,ybr,Lbr,fH,xbr,$br,kbr,Y7,J4e,Sbr,Rbr,mH,Pbr,Bbr,Ibr,K7,Y4e,qbr,Nbr,gH,jbr,Dbr,Gbr,Z7,K4e,Obr,Vbr,hH,Xbr,zbr,Wbr,eM,Z4e,Qbr,Hbr,pH,Ubr,Jbr,Ybr,oM,eve,Kbr,Zbr,uH,e4r,o4r,r4r,rM,ove,t4r,a4r,_H,n4r,s4r,l4r,tM,rve,i4r,d4r,bH,c4r,f4r,m4r,aM,tve,g4r,h4r,vH,p4r,u4r,_4r,nM,ave,b4r,v4r,FH,F4r,T4r,M4r,sM,nve,E4r,C4r,TH,w4r,A4r,y4r,lM,sve,L4r,x4r,MH,$4r,k4r,S4r,iM,lve,R4r,P4r,EH,B4r,I4r,q4r,dM,uje,nc,cM,ive,R8,N4r,dve,j4r,_je,rr,P8,D4r,sc,G4r,CH,O4r,V4r,wH,X4r,z4r,W4r,B8,Q4r,cve,H4r,U4r,J4r,St,I8,Y4r,fve,K4r,Z4r,lc,evr,mve,ovr,rvr,AH,tvr,avr,nvr,fM,svr,$r,q8,lvr,gve,ivr,dvr,an,cvr,hve,fvr,mvr,pve,gvr,hvr,uve,pvr,uvr,_vr,ye,mM,_ve,bvr,vvr,yH,Fvr,Tvr,Mvr,gM,bve,Evr,Cvr,LH,wvr,Avr,yvr,hM,vve,Lvr,xvr,xH,$vr,kvr,Svr,pM,Fve,Rvr,Pvr,$H,Bvr,Ivr,qvr,uM,Tve,Nvr,jvr,kH,Dvr,Gvr,Ovr,_M,Mve,Vvr,Xvr,SH,zvr,Wvr,Qvr,bM,Eve,Hvr,Uvr,RH,Jvr,Yvr,Kvr,vM,Cve,Zvr,e5r,PH,o5r,r5r,t5r,FM,wve,a5r,n5r,BH,s5r,l5r,i5r,TM,Ave,d5r,c5r,IH,f5r,m5r,g5r,MM,bje,ic,EM,yve,N8,h5r,Lve,p5r,vje,tr,j8,u5r,dc,_5r,qH,b5r,v5r,NH,F5r,T5r,M5r,D8,E5r,xve,C5r,w5r,A5r,Rt,G8,y5r,$ve,L5r,x5r,cc,$5r,kve,k5r,S5r,jH,R5r,P5r,B5r,CM,I5r,kr,O8,q5r,Sve,N5r,j5r,nn,D5r,Rve,G5r,O5r,Pve,V5r,X5r,Bve,z5r,W5r,Q5r,oe,wM,Ive,H5r,U5r,DH,J5r,Y5r,K5r,AM,qve,Z5r,eFr,GH,oFr,rFr,tFr,yM,Nve,aFr,nFr,OH,sFr,lFr,iFr,LM,jve,dFr,cFr,VH,fFr,mFr,gFr,xM,Dve,hFr,pFr,XH,uFr,_Fr,bFr,$M,Gve,vFr,FFr,zH,TFr,MFr,EFr,kM,Ove,CFr,wFr,WH,AFr,yFr,LFr,SM,Vve,xFr,$Fr,QH,kFr,SFr,RFr,RM,Xve,PFr,BFr,HH,IFr,qFr,NFr,PM,zve,jFr,DFr,UH,GFr,OFr,VFr,BM,Wve,XFr,zFr,JH,WFr,QFr,HFr,IM,Qve,UFr,JFr,YH,YFr,KFr,ZFr,qM,Hve,eTr,oTr,KH,rTr,tTr,aTr,NM,Uve,nTr,sTr,ZH,lTr,iTr,dTr,jM,Jve,cTr,fTr,eU,mTr,gTr,hTr,DM,Yve,pTr,uTr,oU,_Tr,bTr,vTr,GM,Kve,FTr,TTr,rU,MTr,ETr,CTr,OM,Zve,wTr,ATr,tU,yTr,LTr,xTr,VM,e5e,$Tr,kTr,aU,STr,RTr,PTr,XM,o5e,BTr,ITr,nU,qTr,NTr,jTr,zM,r5e,DTr,GTr,sU,OTr,VTr,XTr,WM,t5e,zTr,WTr,lU,QTr,HTr,UTr,QM,a5e,JTr,YTr,iU,KTr,ZTr,e7r,HM,n5e,o7r,r7r,dU,t7r,a7r,n7r,UM,s5e,s7r,l7r,cU,i7r,d7r,c7r,JM,l5e,f7r,m7r,fU,g7r,h7r,p7r,YM,Fje,fc,KM,i5e,V8,u7r,d5e,_7r,Tje,ar,X8,b7r,mc,v7r,mU,F7r,T7r,gU,M7r,E7r,C7r,z8,w7r,c5e,A7r,y7r,L7r,Pt,W8,x7r,f5e,$7r,k7r,gc,S7r,m5e,R7r,P7r,hU,B7r,I7r,q7r,ZM,N7r,Sr,Q8,j7r,g5e,D7r,G7r,sn,O7r,h5e,V7r,X7r,p5e,z7r,W7r,u5e,Q7r,H7r,U7r,pe,eE,_5e,J7r,Y7r,pU,K7r,Z7r,eMr,oE,b5e,oMr,rMr,uU,tMr,aMr,nMr,rE,v5e,sMr,lMr,_U,iMr,dMr,cMr,tE,F5e,fMr,mMr,bU,gMr,hMr,pMr,aE,T5e,uMr,_Mr,vU,bMr,vMr,FMr,nE,M5e,TMr,MMr,FU,EMr,CMr,wMr,sE,E5e,AMr,yMr,TU,LMr,xMr,$Mr,lE,C5e,kMr,SMr,MU,RMr,PMr,BMr,iE,w5e,IMr,qMr,EU,NMr,jMr,DMr,dE,A5e,GMr,OMr,CU,VMr,XMr,zMr,cE,y5e,WMr,QMr,wU,HMr,UMr,JMr,fE,L5e,YMr,KMr,AU,ZMr,eEr,oEr,mE,x5e,rEr,tEr,yU,aEr,nEr,sEr,gE,$5e,lEr,iEr,LU,dEr,cEr,fEr,hE,k5e,mEr,gEr,xU,hEr,pEr,uEr,pE,S5e,_Er,bEr,$U,vEr,FEr,TEr,uE,R5e,MEr,EEr,kU,CEr,wEr,AEr,_E,Mje,hc,bE,P5e,H8,yEr,B5e,LEr,Eje,nr,U8,xEr,pc,$Er,SU,kEr,SEr,RU,REr,PEr,BEr,J8,IEr,I5e,qEr,NEr,jEr,Bt,Y8,DEr,q5e,GEr,OEr,uc,VEr,N5e,XEr,zEr,PU,WEr,QEr,HEr,vE,UEr,Rr,K8,JEr,j5e,YEr,KEr,ln,ZEr,D5e,eCr,oCr,G5e,rCr,tCr,O5e,aCr,nCr,sCr,Z8,FE,V5e,lCr,iCr,BU,dCr,cCr,fCr,TE,X5e,mCr,gCr,IU,hCr,pCr,uCr,ME,Cje,_c,EE,z5e,e9,_Cr,W5e,bCr,wje,sr,o9,vCr,bc,FCr,qU,TCr,MCr,NU,ECr,CCr,wCr,r9,ACr,Q5e,yCr,LCr,xCr,It,t9,$Cr,H5e,kCr,SCr,vc,RCr,U5e,PCr,BCr,jU,ICr,qCr,NCr,CE,jCr,Pr,a9,DCr,J5e,GCr,OCr,dn,VCr,Y5e,XCr,zCr,K5e,WCr,QCr,Z5e,HCr,UCr,JCr,eFe,wE,oFe,YCr,KCr,DU,ZCr,e3r,o3r,AE,Aje,Fc,yE,rFe,n9,r3r,tFe,t3r,yje,lr,s9,a3r,Tc,n3r,GU,s3r,l3r,OU,i3r,d3r,c3r,l9,f3r,aFe,m3r,g3r,h3r,qt,i9,p3r,nFe,u3r,_3r,Mc,b3r,sFe,v3r,F3r,VU,T3r,M3r,E3r,LE,C3r,Br,d9,w3r,lFe,A3r,y3r,cn,L3r,iFe,x3r,$3r,dFe,k3r,S3r,cFe,R3r,P3r,B3r,de,xE,fFe,I3r,q3r,XU,N3r,j3r,D3r,$E,mFe,G3r,O3r,zU,V3r,X3r,z3r,kE,gFe,W3r,Q3r,WU,H3r,U3r,J3r,SE,hFe,Y3r,K3r,QU,Z3r,ewr,owr,RE,pFe,rwr,twr,HU,awr,nwr,swr,PE,uFe,lwr,iwr,UU,dwr,cwr,fwr,BE,_Fe,mwr,gwr,JU,hwr,pwr,uwr,IE,bFe,_wr,bwr,YU,vwr,Fwr,Twr,qE,vFe,Mwr,Ewr,KU,Cwr,wwr,Awr,NE,FFe,ywr,Lwr,ZU,xwr,$wr,kwr,jE,TFe,Swr,Rwr,eJ,Pwr,Bwr,Iwr,DE,MFe,qwr,Nwr,oJ,jwr,Dwr,Gwr,GE,EFe,Owr,Vwr,rJ,Xwr,zwr,Wwr,OE,CFe,Qwr,Hwr,tJ,Uwr,Jwr,Ywr,VE,wFe,Kwr,Zwr,aJ,e0r,o0r,r0r,XE,AFe,t0r,a0r,nJ,n0r,s0r,l0r,zE,yFe,i0r,d0r,sJ,c0r,f0r,m0r,WE,LFe,g0r,h0r,lJ,p0r,u0r,_0r,QE,xFe,b0r,v0r,iJ,F0r,T0r,M0r,HE,$Fe,E0r,C0r,dJ,w0r,A0r,y0r,UE,Lje,Ec,JE,kFe,c9,L0r,SFe,x0r,xje,ir,f9,$0r,Cc,k0r,cJ,S0r,R0r,fJ,P0r,B0r,I0r,m9,q0r,RFe,N0r,j0r,D0r,Nt,g9,G0r,PFe,O0r,V0r,wc,X0r,BFe,z0r,W0r,mJ,Q0r,H0r,U0r,YE,J0r,Ir,h9,Y0r,IFe,K0r,Z0r,fn,e6r,qFe,o6r,r6r,NFe,t6r,a6r,jFe,n6r,s6r,l6r,ce,KE,DFe,i6r,d6r,gJ,c6r,f6r,m6r,ZE,GFe,g6r,h6r,hJ,p6r,u6r,_6r,eC,OFe,b6r,v6r,pJ,F6r,T6r,M6r,oC,VFe,E6r,C6r,uJ,w6r,A6r,y6r,rC,XFe,L6r,x6r,_J,$6r,k6r,S6r,tC,zFe,R6r,P6r,bJ,B6r,I6r,q6r,aC,WFe,N6r,j6r,vJ,D6r,G6r,O6r,nC,QFe,V6r,X6r,FJ,z6r,W6r,Q6r,sC,HFe,H6r,U6r,TJ,J6r,Y6r,K6r,lC,UFe,Z6r,eAr,MJ,oAr,rAr,tAr,iC,JFe,aAr,nAr,EJ,sAr,lAr,iAr,dC,YFe,dAr,cAr,CJ,fAr,mAr,gAr,cC,KFe,hAr,pAr,wJ,uAr,_Ar,bAr,fC,ZFe,vAr,FAr,AJ,TAr,MAr,EAr,mC,eTe,CAr,wAr,yJ,AAr,yAr,LAr,gC,oTe,xAr,$Ar,LJ,kAr,SAr,RAr,hC,rTe,PAr,BAr,xJ,IAr,qAr,NAr,pC,tTe,jAr,DAr,$J,GAr,OAr,VAr,uC,aTe,XAr,zAr,kJ,WAr,QAr,HAr,_C,nTe,UAr,JAr,SJ,YAr,KAr,ZAr,bC,$je,Ac,vC,sTe,p9,eyr,lTe,oyr,kje,dr,u9,ryr,yc,tyr,RJ,ayr,nyr,PJ,syr,lyr,iyr,_9,dyr,iTe,cyr,fyr,myr,jt,b9,gyr,dTe,hyr,pyr,Lc,uyr,cTe,_yr,byr,BJ,vyr,Fyr,Tyr,FC,Myr,qr,v9,Eyr,fTe,Cyr,wyr,mn,Ayr,mTe,yyr,Lyr,gTe,xyr,$yr,hTe,kyr,Syr,Ryr,pTe,TC,uTe,Pyr,Byr,IJ,Iyr,qyr,Nyr,MC,Sje,xc,EC,_Te,F9,jyr,bTe,Dyr,Rje,cr,T9,Gyr,$c,Oyr,qJ,Vyr,Xyr,NJ,zyr,Wyr,Qyr,M9,Hyr,vTe,Uyr,Jyr,Yyr,Dt,E9,Kyr,FTe,Zyr,eLr,kc,oLr,TTe,rLr,tLr,jJ,aLr,nLr,sLr,CC,lLr,Nr,C9,iLr,MTe,dLr,cLr,gn,fLr,ETe,mLr,gLr,CTe,hLr,pLr,wTe,uLr,_Lr,bLr,ATe,wC,yTe,vLr,FLr,DJ,TLr,MLr,ELr,AC,Pje,Sc,yC,LTe,w9,CLr,xTe,wLr,Bje,fr,A9,ALr,Rc,yLr,GJ,LLr,xLr,OJ,$Lr,kLr,SLr,y9,RLr,$Te,PLr,BLr,ILr,Gt,L9,qLr,kTe,NLr,jLr,Pc,DLr,STe,GLr,OLr,VJ,VLr,XLr,zLr,LC,WLr,jr,x9,QLr,RTe,HLr,ULr,hn,JLr,PTe,YLr,KLr,BTe,ZLr,e8r,ITe,o8r,r8r,t8r,te,xC,qTe,a8r,n8r,XJ,s8r,l8r,i8r,$C,NTe,d8r,c8r,zJ,f8r,m8r,g8r,kC,jTe,h8r,p8r,WJ,u8r,_8r,b8r,SC,DTe,v8r,F8r,QJ,T8r,M8r,E8r,RC,GTe,C8r,w8r,HJ,A8r,y8r,L8r,PC,OTe,x8r,$8r,UJ,k8r,S8r,R8r,BC,VTe,P8r,B8r,JJ,I8r,q8r,N8r,IC,XTe,j8r,D8r,YJ,G8r,O8r,V8r,qC,zTe,X8r,z8r,KJ,W8r,Q8r,H8r,NC,WTe,U8r,J8r,ZJ,Y8r,K8r,Z8r,jC,QTe,e9r,o9r,eY,r9r,t9r,a9r,DC,HTe,n9r,s9r,oY,l9r,i9r,d9r,GC,UTe,c9r,f9r,rY,m9r,g9r,h9r,OC,JTe,p9r,u9r,tY,_9r,b9r,v9r,VC,YTe,F9r,T9r,aY,M9r,E9r,C9r,XC,KTe,w9r,A9r,nY,y9r,L9r,x9r,zC,ZTe,$9r,k9r,sY,S9r,R9r,P9r,WC,e7e,B9r,I9r,lY,q9r,N9r,j9r,QC,o7e,D9r,G9r,iY,O9r,V9r,X9r,HC,r7e,z9r,W9r,dY,Q9r,H9r,U9r,UC,t7e,J9r,Y9r,cY,K9r,Z9r,exr,JC,a7e,oxr,rxr,fY,txr,axr,nxr,YC,n7e,sxr,lxr,mY,ixr,dxr,cxr,KC,s7e,fxr,mxr,gY,gxr,hxr,pxr,ZC,l7e,uxr,_xr,hY,bxr,vxr,Fxr,e3,Ije,Bc,o3,i7e,$9,Txr,d7e,Mxr,qje,mr,k9,Exr,Ic,Cxr,pY,wxr,Axr,uY,yxr,Lxr,xxr,S9,$xr,c7e,kxr,Sxr,Rxr,Ot,R9,Pxr,f7e,Bxr,Ixr,qc,qxr,m7e,Nxr,jxr,_Y,Dxr,Gxr,Oxr,r3,Vxr,Dr,P9,Xxr,g7e,zxr,Wxr,pn,Qxr,h7e,Hxr,Uxr,p7e,Jxr,Yxr,u7e,Kxr,Zxr,e$r,Re,t3,_7e,o$r,r$r,bY,t$r,a$r,n$r,a3,b7e,s$r,l$r,vY,i$r,d$r,c$r,n3,v7e,f$r,m$r,FY,g$r,h$r,p$r,s3,F7e,u$r,_$r,TY,b$r,v$r,F$r,l3,T7e,T$r,M$r,MY,E$r,C$r,w$r,i3,M7e,A$r,y$r,EY,L$r,x$r,$$r,d3,E7e,k$r,S$r,CY,R$r,P$r,B$r,c3,C7e,I$r,q$r,wY,N$r,j$r,D$r,f3,w7e,G$r,O$r,AY,V$r,X$r,z$r,m3,Nje,Nc,g3,A7e,B9,W$r,y7e,Q$r,jje,gr,I9,H$r,jc,U$r,yY,J$r,Y$r,LY,K$r,Z$r,ekr,q9,okr,L7e,rkr,tkr,akr,Vt,N9,nkr,x7e,skr,lkr,Dc,ikr,$7e,dkr,ckr,xY,fkr,mkr,gkr,h3,hkr,Gr,j9,pkr,k7e,ukr,_kr,un,bkr,S7e,vkr,Fkr,R7e,Tkr,Mkr,P7e,Ekr,Ckr,wkr,Ee,p3,B7e,Akr,ykr,$Y,Lkr,xkr,$kr,u3,I7e,kkr,Skr,kY,Rkr,Pkr,Bkr,_3,q7e,Ikr,qkr,SY,Nkr,jkr,Dkr,b3,N7e,Gkr,Okr,RY,Vkr,Xkr,zkr,v3,j7e,Wkr,Qkr,PY,Hkr,Ukr,Jkr,F3,D7e,Ykr,Kkr,BY,Zkr,eSr,oSr,T3,G7e,rSr,tSr,IY,aSr,nSr,sSr,M3,O7e,lSr,iSr,qY,dSr,cSr,fSr,E3,V7e,mSr,gSr,NY,hSr,pSr,uSr,C3,X7e,_Sr,bSr,jY,vSr,FSr,TSr,w3,z7e,MSr,ESr,DY,CSr,wSr,ASr,A3,W7e,ySr,LSr,GY,xSr,$Sr,kSr,y3,Dje,Gc,L3,Q7e,D9,SSr,H7e,RSr,Gje,hr,G9,PSr,Oc,BSr,OY,ISr,qSr,VY,NSr,jSr,DSr,O9,GSr,U7e,OSr,VSr,XSr,Xt,V9,zSr,J7e,WSr,QSr,Vc,HSr,Y7e,USr,JSr,XY,YSr,KSr,ZSr,x3,eRr,Or,X9,oRr,K7e,rRr,tRr,_n,aRr,Z7e,nRr,sRr,eMe,lRr,iRr,oMe,dRr,cRr,fRr,Le,$3,rMe,mRr,gRr,zY,hRr,pRr,uRr,k3,tMe,_Rr,bRr,WY,vRr,FRr,TRr,S3,aMe,MRr,ERr,QY,CRr,wRr,ARr,R3,nMe,yRr,LRr,HY,xRr,$Rr,kRr,P3,sMe,SRr,RRr,UY,PRr,BRr,IRr,B3,lMe,qRr,NRr,JY,jRr,DRr,GRr,I3,iMe,ORr,VRr,YY,XRr,zRr,WRr,q3,dMe,QRr,HRr,KY,URr,JRr,YRr,N3,cMe,KRr,ZRr,ZY,ePr,oPr,rPr,j3,fMe,tPr,aPr,eK,nPr,sPr,lPr,D3,Oje,Xc,G3,mMe,z9,iPr,gMe,dPr,Vje,pr,W9,cPr,zc,fPr,oK,mPr,gPr,rK,hPr,pPr,uPr,Q9,_Pr,hMe,bPr,vPr,FPr,zt,H9,TPr,pMe,MPr,EPr,Wc,CPr,uMe,wPr,APr,tK,yPr,LPr,xPr,O3,$Pr,Vr,U9,kPr,_Me,SPr,RPr,bn,PPr,bMe,BPr,IPr,vMe,qPr,NPr,FMe,jPr,DPr,GPr,Pe,V3,TMe,OPr,VPr,aK,XPr,zPr,WPr,X3,MMe,QPr,HPr,nK,UPr,JPr,YPr,z3,EMe,KPr,ZPr,sK,eBr,oBr,rBr,W3,CMe,tBr,aBr,lK,nBr,sBr,lBr,Q3,wMe,iBr,dBr,iK,cBr,fBr,mBr,H3,AMe,gBr,hBr,dK,pBr,uBr,_Br,U3,yMe,bBr,vBr,cK,FBr,TBr,MBr,J3,LMe,EBr,CBr,fK,wBr,ABr,yBr,Y3,xMe,LBr,xBr,mK,$Br,kBr,SBr,K3,Xje,Qc,Z3,$Me,J9,RBr,kMe,PBr,zje,ur,Y9,BBr,Hc,IBr,gK,qBr,NBr,hK,jBr,DBr,GBr,K9,OBr,SMe,VBr,XBr,zBr,Wt,Z9,WBr,RMe,QBr,HBr,Uc,UBr,PMe,JBr,YBr,pK,KBr,ZBr,eIr,ew,oIr,Xr,ex,rIr,BMe,tIr,aIr,vn,nIr,IMe,sIr,lIr,qMe,iIr,dIr,NMe,cIr,fIr,mIr,xe,ow,jMe,gIr,hIr,uK,pIr,uIr,_Ir,rw,DMe,bIr,vIr,_K,FIr,TIr,MIr,tw,GMe,EIr,CIr,bK,wIr,AIr,yIr,aw,OMe,LIr,xIr,vK,$Ir,kIr,SIr,nw,VMe,RIr,PIr,FK,BIr,IIr,qIr,sw,XMe,NIr,jIr,TK,DIr,GIr,OIr,lw,zMe,VIr,XIr,MK,zIr,WIr,QIr,iw,WMe,HIr,UIr,EK,JIr,YIr,KIr,dw,QMe,ZIr,eqr,CK,oqr,rqr,tqr,cw,HMe,aqr,nqr,wK,sqr,lqr,iqr,fw,Wje,Jc,mw,UMe,ox,dqr,JMe,cqr,Qje,_r,rx,fqr,Yc,mqr,AK,gqr,hqr,yK,pqr,uqr,_qr,tx,bqr,YMe,vqr,Fqr,Tqr,Qt,ax,Mqr,KMe,Eqr,Cqr,Kc,wqr,ZMe,Aqr,yqr,LK,Lqr,xqr,$qr,gw,kqr,zr,nx,Sqr,eEe,Rqr,Pqr,Fn,Bqr,oEe,Iqr,qqr,rEe,Nqr,jqr,tEe,Dqr,Gqr,Oqr,$e,hw,aEe,Vqr,Xqr,xK,zqr,Wqr,Qqr,pw,nEe,Hqr,Uqr,$K,Jqr,Yqr,Kqr,uw,sEe,Zqr,eNr,kK,oNr,rNr,tNr,_w,lEe,aNr,nNr,SK,sNr,lNr,iNr,bw,iEe,dNr,cNr,RK,fNr,mNr,gNr,vw,dEe,hNr,pNr,PK,uNr,_Nr,bNr,Fw,cEe,vNr,FNr,BK,TNr,MNr,ENr,Tw,fEe,CNr,wNr,IK,ANr,yNr,LNr,Mw,mEe,xNr,$Nr,qK,kNr,SNr,RNr,Ew,gEe,PNr,BNr,NK,INr,qNr,NNr,Cw,Hje,Zc,ww,hEe,sx,jNr,pEe,DNr,Uje,br,lx,GNr,ef,ONr,jK,VNr,XNr,DK,zNr,WNr,QNr,ix,HNr,uEe,UNr,JNr,YNr,Ht,dx,KNr,_Ee,ZNr,ejr,of,ojr,bEe,rjr,tjr,GK,ajr,njr,sjr,Aw,ljr,Wr,cx,ijr,vEe,djr,cjr,Tn,fjr,FEe,mjr,gjr,TEe,hjr,pjr,MEe,ujr,_jr,bjr,De,yw,EEe,vjr,Fjr,OK,Tjr,Mjr,Ejr,Lw,CEe,Cjr,wjr,VK,Ajr,yjr,Ljr,xw,wEe,xjr,$jr,XK,kjr,Sjr,Rjr,$w,AEe,Pjr,Bjr,zK,Ijr,qjr,Njr,kw,yEe,jjr,Djr,WK,Gjr,Ojr,Vjr,Sw,LEe,Xjr,zjr,QK,Wjr,Qjr,Hjr,Rw,xEe,Ujr,Jjr,HK,Yjr,Kjr,Zjr,Pw,$Ee,eDr,oDr,UK,rDr,tDr,aDr,Bw,Jje,rf,Iw,kEe,fx,nDr,SEe,sDr,Yje,vr,mx,lDr,tf,iDr,JK,dDr,cDr,YK,fDr,mDr,gDr,gx,hDr,REe,pDr,uDr,_Dr,Ut,hx,bDr,PEe,vDr,FDr,af,TDr,BEe,MDr,EDr,KK,CDr,wDr,ADr,qw,yDr,Qr,px,LDr,IEe,xDr,$Dr,Mn,kDr,qEe,SDr,RDr,NEe,PDr,BDr,jEe,IDr,qDr,NDr,Ge,Nw,DEe,jDr,DDr,ZK,GDr,ODr,VDr,jw,GEe,XDr,zDr,eZ,WDr,QDr,HDr,Dw,OEe,UDr,JDr,oZ,YDr,KDr,ZDr,Gw,VEe,eGr,oGr,rZ,rGr,tGr,aGr,Ow,XEe,nGr,sGr,tZ,lGr,iGr,dGr,Vw,zEe,cGr,fGr,aZ,mGr,gGr,hGr,Xw,WEe,pGr,uGr,nZ,_Gr,bGr,vGr,zw,QEe,FGr,TGr,sZ,MGr,EGr,CGr,Ww,Kje,nf,Qw,HEe,ux,wGr,UEe,AGr,Zje,Fr,_x,yGr,sf,LGr,lZ,xGr,$Gr,iZ,kGr,SGr,RGr,bx,PGr,JEe,BGr,IGr,qGr,Jt,vx,NGr,YEe,jGr,DGr,lf,GGr,KEe,OGr,VGr,dZ,XGr,zGr,WGr,Hw,QGr,Hr,Fx,HGr,ZEe,UGr,JGr,En,YGr,eCe,KGr,ZGr,oCe,eOr,oOr,rCe,rOr,tOr,aOr,tCe,Uw,aCe,nOr,sOr,cZ,lOr,iOr,dOr,Jw,eDe,df,Yw,nCe,Tx,cOr,sCe,fOr,oDe,Tr,Mx,mOr,cf,gOr,fZ,hOr,pOr,mZ,uOr,_Or,bOr,Ex,vOr,lCe,FOr,TOr,MOr,Yt,Cx,EOr,iCe,COr,wOr,ff,AOr,dCe,yOr,LOr,gZ,xOr,$Or,kOr,Kw,SOr,Ur,wx,ROr,cCe,POr,BOr,Cn,IOr,fCe,qOr,NOr,mCe,jOr,DOr,gCe,GOr,OOr,VOr,Ax,Zw,hCe,XOr,zOr,hZ,WOr,QOr,HOr,e0,pCe,UOr,JOr,pZ,YOr,KOr,ZOr,o0,rDe,mf,r0,uCe,yx,eVr,_Ce,oVr,tDe,Mr,Lx,rVr,gf,tVr,uZ,aVr,nVr,_Z,sVr,lVr,iVr,xx,dVr,bCe,cVr,fVr,mVr,Kt,$x,gVr,vCe,hVr,pVr,hf,uVr,FCe,_Vr,bVr,bZ,vVr,FVr,TVr,t0,MVr,Jr,kx,EVr,TCe,CVr,wVr,wn,AVr,MCe,yVr,LVr,ECe,xVr,$Vr,CCe,kVr,SVr,RVr,wCe,a0,ACe,PVr,BVr,vZ,IVr,qVr,NVr,n0,aDe;return d=new re({}),Ca=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),yA=new re({}),LA=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Ef=new jVr({props:{warning:!0,$$slots:{default:[E$t]},$$scope:{ctx:L}}}),xA=new re({}),$A=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/configuration_auto.py#L584"}}),RA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/configuration_auto.py#L607"}}),Ag=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[C$t]},$$scope:{ctx:L}}}),PA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/configuration_auto.py#L730"}}),BA=new re({}),IA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/tokenization_auto.py#L396"}}),jA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17254/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/tokenization_auto.py#L410"}}),ah=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[w$t]},$$scope:{ctx:L}}}),DA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/tokenization_auto.py#L609"}}),GA=new re({}),OA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/feature_extraction_auto.py#L190"}}),zA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17254/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/feature_extraction_auto.py#L204"}}),Ih=new jVr({props:{$$slots:{default:[A$t]},$$scope:{ctx:L}}}),qh=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[y$t]},$$scope:{ctx:L}}}),WA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/feature_extraction_auto.py#L331"}}),QA=new re({}),HA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/processing_auto.py#L88"}}),YA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/processing_auto.py#L102"}}),tp=new jVr({props:{$$slots:{default:[L$t]},$$scope:{ctx:L}}}),ap=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[x$t]},$$scope:{ctx:L}}}),KA=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/processing_auto.py#L255"}}),ZA=new re({}),ey=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L736"}}),ry=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),lp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[$$t]},$$scope:{ctx:L}}}),ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),r_=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[k$t]},$$scope:{ctx:L}}}),ay=new re({}),ny=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L743"}}),ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),a_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[S$t]},$$scope:{ctx:L}}}),iy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),H_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[R$t]},$$scope:{ctx:L}}}),dy=new re({}),cy=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L758"}}),my=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),J_=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[P$t]},$$scope:{ctx:L}}}),gy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),B2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[B$t]},$$scope:{ctx:L}}}),hy=new re({}),py=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L765"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),q2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[I$t]},$$scope:{ctx:L}}}),by=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),F1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[q$t]},$$scope:{ctx:L}}}),vy=new re({}),Fy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L772"}}),My=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),M1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[N$t]},$$scope:{ctx:L}}}),Ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),D1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[j$t]},$$scope:{ctx:L}}}),Cy=new re({}),wy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L781"}}),yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),O1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[D$t]},$$scope:{ctx:L}}}),Ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),qb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[G$t]},$$scope:{ctx:L}}}),xy=new re({}),$y=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L815"}}),Sy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),jb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[O$t]},$$scope:{ctx:L}}}),Ry=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),u4=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[V$t]},$$scope:{ctx:L}}}),Py=new re({}),By=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L822"}}),qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),b4=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[X$t]},$$scope:{ctx:L}}}),Ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),w4=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[z$t]},$$scope:{ctx:L}}}),jy=new re({}),Dy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L808"}}),Oy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),y4=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[W$t]},$$scope:{ctx:L}}}),Vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),dv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Q$t]},$$scope:{ctx:L}}}),Xy=new re({}),zy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L790"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),fv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[H$t]},$$scope:{ctx:L}}}),Hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Zv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[U$t]},$$scope:{ctx:L}}}),Uy=new re({}),Jy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L797"}}),Ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),o5=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[J$t]},$$scope:{ctx:L}}}),Zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Y$t]},$$scope:{ctx:L}}}),eL=new re({}),oL=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L831"}}),tL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[K$t]},$$scope:{ctx:L}}}),aL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),F5=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Z$t]},$$scope:{ctx:L}}}),nL=new re({}),sL=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L870"}}),iL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),M5=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[ekt]},$$scope:{ctx:L}}}),dL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),w5=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[okt]},$$scope:{ctx:L}}}),cL=new re({}),fL=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L877"}}),gL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),y5=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[rkt]},$$scope:{ctx:L}}}),hL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),N5=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[tkt]},$$scope:{ctx:L}}}),pL=new re({}),uL=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L900"}}),bL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),D5=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[akt]},$$scope:{ctx:L}}}),vL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Q5=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[nkt]},$$scope:{ctx:L}}}),FL=new re({}),TL=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L884"}}),EL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),U5=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[skt]},$$scope:{ctx:L}}}),CL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),sF=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[lkt]},$$scope:{ctx:L}}}),wL=new re({}),AL=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L891"}}),LL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),iF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[ikt]},$$scope:{ctx:L}}}),xL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),mF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[dkt]},$$scope:{ctx:L}}}),kL=new re({}),SL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L909"}}),PL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),hF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[ckt]},$$scope:{ctx:L}}}),BL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),TF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[fkt]},$$scope:{ctx:L}}}),IL=new re({}),qL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L916"}}),jL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),EF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[mkt]},$$scope:{ctx:L}}}),DL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),LF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[gkt]},$$scope:{ctx:L}}}),GL=new re({}),OL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L863"}}),XL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),$F=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[hkt]},$$scope:{ctx:L}}}),zL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),PF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[pkt]},$$scope:{ctx:L}}}),QL=new re({}),HL=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L838"}}),JL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),IF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[ukt]},$$scope:{ctx:L}}}),YL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[_kt]},$$scope:{ctx:L}}}),KL=new re({}),ZL=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L845"}}),o8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),GF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[bkt]},$$scope:{ctx:L}}}),r8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),QF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[vkt]},$$scope:{ctx:L}}}),t8=new re({}),a8=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_auto.py#L854"}}),s8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),UF=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Fkt]},$$scope:{ctx:L}}}),l8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),KF=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[Tkt]},$$scope:{ctx:L}}}),i8=new re({}),d8=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L394"}}),f8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),eT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Mkt]},$$scope:{ctx:L}}}),m8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),WT=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Ekt]},$$scope:{ctx:L}}}),g8=new re({}),h8=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L401"}}),u8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),HT=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Ckt]},$$scope:{ctx:L}}}),_8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),b7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[wkt]},$$scope:{ctx:L}}}),b8=new re({}),v8=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),T8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),F7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Akt]},$$scope:{ctx:L}}}),M8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),R7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[ykt]},$$scope:{ctx:L}}}),E8=new re({}),C8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),A8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),B7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Lkt]},$$scope:{ctx:L}}}),y8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),D7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[xkt]},$$scope:{ctx:L}}}),L8=new re({}),x8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L448"}}),k8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),O7=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[$kt]},$$scope:{ctx:L}}}),S8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),dM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[kkt]},$$scope:{ctx:L}}}),R8=new re({}),P8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),I8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),fM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Skt]},$$scope:{ctx:L}}}),q8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),MM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Rkt]},$$scope:{ctx:L}}}),N8=new re({}),j8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L464"}}),G8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),CM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Pkt]},$$scope:{ctx:L}}}),O8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),YM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Bkt]},$$scope:{ctx:L}}}),V8=new re({}),X8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),W8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),ZM=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Ikt]},$$scope:{ctx:L}}}),Q8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),_E=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[qkt]},$$scope:{ctx:L}}}),H8=new re({}),U8=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),Y8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),vE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Nkt]},$$scope:{ctx:L}}}),K8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),ME=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[jkt]},$$scope:{ctx:L}}}),e9=new re({}),o9=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),t9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),CE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Dkt]},$$scope:{ctx:L}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),AE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Gkt]},$$scope:{ctx:L}}}),n9=new re({}),s9=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),i9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),LE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[Okt]},$$scope:{ctx:L}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),UE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Vkt]},$$scope:{ctx:L}}}),c9=new re({}),f9=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L473"}}),g9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),YE=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Xkt]},$$scope:{ctx:L}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),bC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[zkt]},$$scope:{ctx:L}}}),p9=new re({}),u9=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),b9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),FC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Wkt]},$$scope:{ctx:L}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),MC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Qkt]},$$scope:{ctx:L}}}),F9=new re({}),T9=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_tf_auto.py#L516"}}),E9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),CC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Hkt]},$$scope:{ctx:L}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),AC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Ukt]},$$scope:{ctx:L}}}),w9=new re({}),A9=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L241"}}),L9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),LC=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Jkt]},$$scope:{ctx:L}}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),e3=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Ykt]},$$scope:{ctx:L}}}),$9=new re({}),k9=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),R9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),r3=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Kkt]},$$scope:{ctx:L}}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),m3=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Zkt]},$$scope:{ctx:L}}}),B9=new re({}),I9=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),N9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),h3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[eSt]},$$scope:{ctx:L}}}),j9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),y3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[oSt]},$$scope:{ctx:L}}}),D9=new re({}),G9=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L262"}}),V9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),x3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[rSt]},$$scope:{ctx:L}}}),X9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),D3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[tSt]},$$scope:{ctx:L}}}),z9=new re({}),W9=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L269"}}),H9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),O3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[aSt]},$$scope:{ctx:L}}}),U9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),K3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[nSt]},$$scope:{ctx:L}}}),J9=new re({}),Y9=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L278"}}),Z9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),ew=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[sSt]},$$scope:{ctx:L}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),fw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[lSt]},$$scope:{ctx:L}}}),ox=new re({}),rx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L287"}}),ax=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),gw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[iSt]},$$scope:{ctx:L}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[dSt]},$$scope:{ctx:L}}}),sx=new re({}),lx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L294"}}),dx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[cSt]},$$scope:{ctx:L}}}),cx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Bw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[fSt]},$$scope:{ctx:L}}}),fx=new re({}),mx=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L303"}}),hx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),qw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[mSt]},$$scope:{ctx:L}}}),px=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Ww=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[gSt]},$$scope:{ctx:L}}}),ux=new re({}),_x=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),vx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),Hw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[hSt]},$$scope:{ctx:L}}}),Fx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),Jw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[pSt]},$$scope:{ctx:L}}}),Tx=new re({}),Mx=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L319"}}),Cx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),Kw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[uSt]},$$scope:{ctx:L}}}),wx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),o0=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[_St]},$$scope:{ctx:L}}}),yx=new re({}),Lx=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/modeling_flax_auto.py#L328"}}),$x=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L389"}}),t0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[bSt]},$$scope:{ctx:L}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17254/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17254/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17254/src/transformers/models/auto/auto_factory.py#L417"}}),n0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[vSt]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),hi=o("Auto Classes"),bf=l(),rt=a("p"),pi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ui=a("code"),EA=o("from_pretrained()"),vf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),je=l(),We=a("p"),_i=o("Instantiating one of "),yn=a("a"),CA=o("AutoConfig"),Ln=o(", "),xn=a("a"),wA=o("AutoModel"),bi=o(`, and
`),$n=a("a"),AA=o("AutoTokenizer"),vi=o(" will directly create a class of the relevant architecture. For instance"),Ff=l(),F(Ca.$$.fragment),Qe=l(),Ae=a("p"),H$=o("will create a model that is an instance of "),Fi=a("a"),U$=o("BertModel"),J$=o("."),Eo=l(),wa=a("p"),Y$=o("There is one class of "),Tf=a("code"),K$=o("AutoModel"),mOe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),oNe=l(),Ti=a("h2"),Mf=a("a"),moe=a("span"),F(yA.$$.fragment),gOe=l(),goe=a("span"),hOe=o("Extending the Auto Classes"),rNe=l(),kn=a("p"),pOe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hoe=a("code"),uOe=o("NewModel"),_Oe=o(", make sure you have a "),poe=a("code"),bOe=o("NewModelConfig"),vOe=o(` then you can add those to the auto
classes like this:`),tNe=l(),F(LA.$$.fragment),aNe=l(),Z$=a("p"),FOe=o("You will then be able to use the auto classes like you would usually do!"),nNe=l(),F(Ef.$$.fragment),sNe=l(),Mi=a("h2"),Cf=a("a"),uoe=a("span"),F(xA.$$.fragment),TOe=l(),_oe=a("span"),MOe=o("AutoConfig"),lNe=l(),Co=a("div"),F($A.$$.fragment),EOe=l(),kA=a("p"),COe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),ek=a("a"),wOe=o("from_pretrained()"),AOe=o(" class method."),yOe=l(),SA=a("p"),LOe=o("This class cannot be instantiated directly using "),boe=a("code"),xOe=o("__init__()"),$Oe=o(" (throws an error)."),kOe=l(),Er=a("div"),F(RA.$$.fragment),SOe=l(),voe=a("p"),ROe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),POe=l(),Ei=a("p"),BOe=o("The configuration class to instantiate is selected based on the "),Foe=a("code"),IOe=o("model_type"),qOe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Toe=a("code"),NOe=o("pretrained_model_name_or_path"),jOe=o(":"),DOe=l(),A=a("ul"),wf=a("li"),Moe=a("strong"),GOe=o("albert"),OOe=o(" \u2014 "),ok=a("a"),VOe=o("AlbertConfig"),XOe=o(" (ALBERT model)"),zOe=l(),Af=a("li"),Eoe=a("strong"),WOe=o("bart"),QOe=o(" \u2014 "),rk=a("a"),HOe=o("BartConfig"),UOe=o(" (BART model)"),JOe=l(),yf=a("li"),Coe=a("strong"),YOe=o("beit"),KOe=o(" \u2014 "),tk=a("a"),ZOe=o("BeitConfig"),eVe=o(" (BEiT model)"),oVe=l(),Lf=a("li"),woe=a("strong"),rVe=o("bert"),tVe=o(" \u2014 "),ak=a("a"),aVe=o("BertConfig"),nVe=o(" (BERT model)"),sVe=l(),xf=a("li"),Aoe=a("strong"),lVe=o("bert-generation"),iVe=o(" \u2014 "),nk=a("a"),dVe=o("BertGenerationConfig"),cVe=o(" (Bert Generation model)"),fVe=l(),$f=a("li"),yoe=a("strong"),mVe=o("big_bird"),gVe=o(" \u2014 "),sk=a("a"),hVe=o("BigBirdConfig"),pVe=o(" (BigBird model)"),uVe=l(),kf=a("li"),Loe=a("strong"),_Ve=o("bigbird_pegasus"),bVe=o(" \u2014 "),lk=a("a"),vVe=o("BigBirdPegasusConfig"),FVe=o(" (BigBirdPegasus model)"),TVe=l(),Sf=a("li"),xoe=a("strong"),MVe=o("blenderbot"),EVe=o(" \u2014 "),ik=a("a"),CVe=o("BlenderbotConfig"),wVe=o(" (Blenderbot model)"),AVe=l(),Rf=a("li"),$oe=a("strong"),yVe=o("blenderbot-small"),LVe=o(" \u2014 "),dk=a("a"),xVe=o("BlenderbotSmallConfig"),$Ve=o(" (BlenderbotSmall model)"),kVe=l(),Pf=a("li"),koe=a("strong"),SVe=o("camembert"),RVe=o(" \u2014 "),ck=a("a"),PVe=o("CamembertConfig"),BVe=o(" (CamemBERT model)"),IVe=l(),Bf=a("li"),Soe=a("strong"),qVe=o("canine"),NVe=o(" \u2014 "),fk=a("a"),jVe=o("CanineConfig"),DVe=o(" (Canine model)"),GVe=l(),If=a("li"),Roe=a("strong"),OVe=o("clip"),VVe=o(" \u2014 "),mk=a("a"),XVe=o("CLIPConfig"),zVe=o(" (CLIP model)"),WVe=l(),qf=a("li"),Poe=a("strong"),QVe=o("convbert"),HVe=o(" \u2014 "),gk=a("a"),UVe=o("ConvBertConfig"),JVe=o(" (ConvBERT model)"),YVe=l(),Nf=a("li"),Boe=a("strong"),KVe=o("convnext"),ZVe=o(" \u2014 "),hk=a("a"),eXe=o("ConvNextConfig"),oXe=o(" (ConvNext model)"),rXe=l(),jf=a("li"),Ioe=a("strong"),tXe=o("ctrl"),aXe=o(" \u2014 "),pk=a("a"),nXe=o("CTRLConfig"),sXe=o(" (CTRL model)"),lXe=l(),Df=a("li"),qoe=a("strong"),iXe=o("cvt"),dXe=o(" \u2014 "),uk=a("a"),cXe=o("CvtConfig"),fXe=o(" (CvT model)"),mXe=l(),Gf=a("li"),Noe=a("strong"),gXe=o("data2vec-audio"),hXe=o(" \u2014 "),_k=a("a"),pXe=o("Data2VecAudioConfig"),uXe=o(" (Data2VecAudio model)"),_Xe=l(),Of=a("li"),joe=a("strong"),bXe=o("data2vec-text"),vXe=o(" \u2014 "),bk=a("a"),FXe=o("Data2VecTextConfig"),TXe=o(" (Data2VecText model)"),MXe=l(),Vf=a("li"),Doe=a("strong"),EXe=o("data2vec-vision"),CXe=o(" \u2014 "),vk=a("a"),wXe=o("Data2VecVisionConfig"),AXe=o(" (Data2VecVision model)"),yXe=l(),Xf=a("li"),Goe=a("strong"),LXe=o("deberta"),xXe=o(" \u2014 "),Fk=a("a"),$Xe=o("DebertaConfig"),kXe=o(" (DeBERTa model)"),SXe=l(),zf=a("li"),Ooe=a("strong"),RXe=o("deberta-v2"),PXe=o(" \u2014 "),Tk=a("a"),BXe=o("DebertaV2Config"),IXe=o(" (DeBERTa-v2 model)"),qXe=l(),Wf=a("li"),Voe=a("strong"),NXe=o("decision_transformer"),jXe=o(" \u2014 "),Mk=a("a"),DXe=o("DecisionTransformerConfig"),GXe=o(" (Decision Transformer model)"),OXe=l(),Qf=a("li"),Xoe=a("strong"),VXe=o("deit"),XXe=o(" \u2014 "),Ek=a("a"),zXe=o("DeiTConfig"),WXe=o(" (DeiT model)"),QXe=l(),Hf=a("li"),zoe=a("strong"),HXe=o("detr"),UXe=o(" \u2014 "),Ck=a("a"),JXe=o("DetrConfig"),YXe=o(" (DETR model)"),KXe=l(),Uf=a("li"),Woe=a("strong"),ZXe=o("distilbert"),eze=o(" \u2014 "),wk=a("a"),oze=o("DistilBertConfig"),rze=o(" (DistilBERT model)"),tze=l(),Jf=a("li"),Qoe=a("strong"),aze=o("dpr"),nze=o(" \u2014 "),Ak=a("a"),sze=o("DPRConfig"),lze=o(" (DPR model)"),ize=l(),Yf=a("li"),Hoe=a("strong"),dze=o("dpt"),cze=o(" \u2014 "),yk=a("a"),fze=o("DPTConfig"),mze=o(" (DPT model)"),gze=l(),Kf=a("li"),Uoe=a("strong"),hze=o("electra"),pze=o(" \u2014 "),Lk=a("a"),uze=o("ElectraConfig"),_ze=o(" (ELECTRA model)"),bze=l(),Zf=a("li"),Joe=a("strong"),vze=o("encoder-decoder"),Fze=o(" \u2014 "),xk=a("a"),Tze=o("EncoderDecoderConfig"),Mze=o(" (Encoder decoder model)"),Eze=l(),em=a("li"),Yoe=a("strong"),Cze=o("flaubert"),wze=o(" \u2014 "),$k=a("a"),Aze=o("FlaubertConfig"),yze=o(" (FlauBERT model)"),Lze=l(),om=a("li"),Koe=a("strong"),xze=o("flava"),$ze=o(" \u2014 "),kk=a("a"),kze=o("FlavaConfig"),Sze=o(" (Flava model)"),Rze=l(),rm=a("li"),Zoe=a("strong"),Pze=o("fnet"),Bze=o(" \u2014 "),Sk=a("a"),Ize=o("FNetConfig"),qze=o(" (FNet model)"),Nze=l(),tm=a("li"),ere=a("strong"),jze=o("fsmt"),Dze=o(" \u2014 "),Rk=a("a"),Gze=o("FSMTConfig"),Oze=o(" (FairSeq Machine-Translation model)"),Vze=l(),am=a("li"),ore=a("strong"),Xze=o("funnel"),zze=o(" \u2014 "),Pk=a("a"),Wze=o("FunnelConfig"),Qze=o(" (Funnel Transformer model)"),Hze=l(),nm=a("li"),rre=a("strong"),Uze=o("glpn"),Jze=o(" \u2014 "),Bk=a("a"),Yze=o("GLPNConfig"),Kze=o(" (GLPN model)"),Zze=l(),sm=a("li"),tre=a("strong"),eWe=o("gpt2"),oWe=o(" \u2014 "),Ik=a("a"),rWe=o("GPT2Config"),tWe=o(" (OpenAI GPT-2 model)"),aWe=l(),lm=a("li"),are=a("strong"),nWe=o("gpt_neo"),sWe=o(" \u2014 "),qk=a("a"),lWe=o("GPTNeoConfig"),iWe=o(" (GPT Neo model)"),dWe=l(),im=a("li"),nre=a("strong"),cWe=o("gpt_neox"),fWe=o(" \u2014 "),Nk=a("a"),mWe=o("GPTNeoXConfig"),gWe=o(" (GPT NeoX model)"),hWe=l(),dm=a("li"),sre=a("strong"),pWe=o("gptj"),uWe=o(" \u2014 "),jk=a("a"),_We=o("GPTJConfig"),bWe=o(" (GPT-J model)"),vWe=l(),cm=a("li"),lre=a("strong"),FWe=o("hubert"),TWe=o(" \u2014 "),Dk=a("a"),MWe=o("HubertConfig"),EWe=o(" (Hubert model)"),CWe=l(),fm=a("li"),ire=a("strong"),wWe=o("ibert"),AWe=o(" \u2014 "),Gk=a("a"),yWe=o("IBertConfig"),LWe=o(" (I-BERT model)"),xWe=l(),mm=a("li"),dre=a("strong"),$We=o("imagegpt"),kWe=o(" \u2014 "),Ok=a("a"),SWe=o("ImageGPTConfig"),RWe=o(" (ImageGPT model)"),PWe=l(),gm=a("li"),cre=a("strong"),BWe=o("layoutlm"),IWe=o(" \u2014 "),Vk=a("a"),qWe=o("LayoutLMConfig"),NWe=o(" (LayoutLM model)"),jWe=l(),hm=a("li"),fre=a("strong"),DWe=o("layoutlmv2"),GWe=o(" \u2014 "),Xk=a("a"),OWe=o("LayoutLMv2Config"),VWe=o(" (LayoutLMv2 model)"),XWe=l(),pm=a("li"),mre=a("strong"),zWe=o("layoutlmv3"),WWe=o(" \u2014 "),zk=a("a"),QWe=o("LayoutLMv3Config"),HWe=o(" (LayoutLMv3 model)"),UWe=l(),um=a("li"),gre=a("strong"),JWe=o("led"),YWe=o(" \u2014 "),Wk=a("a"),KWe=o("LEDConfig"),ZWe=o(" (LED model)"),eQe=l(),_m=a("li"),hre=a("strong"),oQe=o("longformer"),rQe=o(" \u2014 "),Qk=a("a"),tQe=o("LongformerConfig"),aQe=o(" (Longformer model)"),nQe=l(),bm=a("li"),pre=a("strong"),sQe=o("luke"),lQe=o(" \u2014 "),Hk=a("a"),iQe=o("LukeConfig"),dQe=o(" (LUKE model)"),cQe=l(),vm=a("li"),ure=a("strong"),fQe=o("lxmert"),mQe=o(" \u2014 "),Uk=a("a"),gQe=o("LxmertConfig"),hQe=o(" (LXMERT model)"),pQe=l(),Fm=a("li"),_re=a("strong"),uQe=o("m2m_100"),_Qe=o(" \u2014 "),Jk=a("a"),bQe=o("M2M100Config"),vQe=o(" (M2M100 model)"),FQe=l(),Tm=a("li"),bre=a("strong"),TQe=o("marian"),MQe=o(" \u2014 "),Yk=a("a"),EQe=o("MarianConfig"),CQe=o(" (Marian model)"),wQe=l(),Mm=a("li"),vre=a("strong"),AQe=o("maskformer"),yQe=o(" \u2014 "),Kk=a("a"),LQe=o("MaskFormerConfig"),xQe=o(" (MaskFormer model)"),$Qe=l(),Em=a("li"),Fre=a("strong"),kQe=o("mbart"),SQe=o(" \u2014 "),Zk=a("a"),RQe=o("MBartConfig"),PQe=o(" (mBART model)"),BQe=l(),Cm=a("li"),Tre=a("strong"),IQe=o("megatron-bert"),qQe=o(" \u2014 "),eS=a("a"),NQe=o("MegatronBertConfig"),jQe=o(" (MegatronBert model)"),DQe=l(),wm=a("li"),Mre=a("strong"),GQe=o("mobilebert"),OQe=o(" \u2014 "),oS=a("a"),VQe=o("MobileBertConfig"),XQe=o(" (MobileBERT model)"),zQe=l(),Am=a("li"),Ere=a("strong"),WQe=o("mpnet"),QQe=o(" \u2014 "),rS=a("a"),HQe=o("MPNetConfig"),UQe=o(" (MPNet model)"),JQe=l(),ym=a("li"),Cre=a("strong"),YQe=o("mt5"),KQe=o(" \u2014 "),tS=a("a"),ZQe=o("MT5Config"),eHe=o(" (mT5 model)"),oHe=l(),Lm=a("li"),wre=a("strong"),rHe=o("nystromformer"),tHe=o(" \u2014 "),aS=a("a"),aHe=o("NystromformerConfig"),nHe=o(" (Nystromformer model)"),sHe=l(),xm=a("li"),Are=a("strong"),lHe=o("openai-gpt"),iHe=o(" \u2014 "),nS=a("a"),dHe=o("OpenAIGPTConfig"),cHe=o(" (OpenAI GPT model)"),fHe=l(),$m=a("li"),yre=a("strong"),mHe=o("opt"),gHe=o(" \u2014 "),sS=a("a"),hHe=o("OPTConfig"),pHe=o(" (OPT model)"),uHe=l(),km=a("li"),Lre=a("strong"),_He=o("pegasus"),bHe=o(" \u2014 "),lS=a("a"),vHe=o("PegasusConfig"),FHe=o(" (Pegasus model)"),THe=l(),Sm=a("li"),xre=a("strong"),MHe=o("perceiver"),EHe=o(" \u2014 "),iS=a("a"),CHe=o("PerceiverConfig"),wHe=o(" (Perceiver model)"),AHe=l(),Rm=a("li"),$re=a("strong"),yHe=o("plbart"),LHe=o(" \u2014 "),dS=a("a"),xHe=o("PLBartConfig"),$He=o(" (PLBart model)"),kHe=l(),Pm=a("li"),kre=a("strong"),SHe=o("poolformer"),RHe=o(" \u2014 "),cS=a("a"),PHe=o("PoolFormerConfig"),BHe=o(" (PoolFormer model)"),IHe=l(),Bm=a("li"),Sre=a("strong"),qHe=o("prophetnet"),NHe=o(" \u2014 "),fS=a("a"),jHe=o("ProphetNetConfig"),DHe=o(" (ProphetNet model)"),GHe=l(),Im=a("li"),Rre=a("strong"),OHe=o("qdqbert"),VHe=o(" \u2014 "),mS=a("a"),XHe=o("QDQBertConfig"),zHe=o(" (QDQBert model)"),WHe=l(),qm=a("li"),Pre=a("strong"),QHe=o("rag"),HHe=o(" \u2014 "),gS=a("a"),UHe=o("RagConfig"),JHe=o(" (RAG model)"),YHe=l(),Nm=a("li"),Bre=a("strong"),KHe=o("realm"),ZHe=o(" \u2014 "),hS=a("a"),eUe=o("RealmConfig"),oUe=o(" (Realm model)"),rUe=l(),jm=a("li"),Ire=a("strong"),tUe=o("reformer"),aUe=o(" \u2014 "),pS=a("a"),nUe=o("ReformerConfig"),sUe=o(" (Reformer model)"),lUe=l(),Dm=a("li"),qre=a("strong"),iUe=o("regnet"),dUe=o(" \u2014 "),uS=a("a"),cUe=o("RegNetConfig"),fUe=o(" (RegNet model)"),mUe=l(),Gm=a("li"),Nre=a("strong"),gUe=o("rembert"),hUe=o(" \u2014 "),_S=a("a"),pUe=o("RemBertConfig"),uUe=o(" (RemBERT model)"),_Ue=l(),Om=a("li"),jre=a("strong"),bUe=o("resnet"),vUe=o(" \u2014 "),bS=a("a"),FUe=o("ResNetConfig"),TUe=o(" (ResNet model)"),MUe=l(),Vm=a("li"),Dre=a("strong"),EUe=o("retribert"),CUe=o(" \u2014 "),vS=a("a"),wUe=o("RetriBertConfig"),AUe=o(" (RetriBERT model)"),yUe=l(),Xm=a("li"),Gre=a("strong"),LUe=o("roberta"),xUe=o(" \u2014 "),FS=a("a"),$Ue=o("RobertaConfig"),kUe=o(" (RoBERTa model)"),SUe=l(),zm=a("li"),Ore=a("strong"),RUe=o("roformer"),PUe=o(" \u2014 "),TS=a("a"),BUe=o("RoFormerConfig"),IUe=o(" (RoFormer model)"),qUe=l(),Wm=a("li"),Vre=a("strong"),NUe=o("segformer"),jUe=o(" \u2014 "),MS=a("a"),DUe=o("SegformerConfig"),GUe=o(" (SegFormer model)"),OUe=l(),Qm=a("li"),Xre=a("strong"),VUe=o("sew"),XUe=o(" \u2014 "),ES=a("a"),zUe=o("SEWConfig"),WUe=o(" (SEW model)"),QUe=l(),Hm=a("li"),zre=a("strong"),HUe=o("sew-d"),UUe=o(" \u2014 "),CS=a("a"),JUe=o("SEWDConfig"),YUe=o(" (SEW-D model)"),KUe=l(),Um=a("li"),Wre=a("strong"),ZUe=o("speech-encoder-decoder"),eJe=o(" \u2014 "),wS=a("a"),oJe=o("SpeechEncoderDecoderConfig"),rJe=o(" (Speech Encoder decoder model)"),tJe=l(),Jm=a("li"),Qre=a("strong"),aJe=o("speech_to_text"),nJe=o(" \u2014 "),AS=a("a"),sJe=o("Speech2TextConfig"),lJe=o(" (Speech2Text model)"),iJe=l(),Ym=a("li"),Hre=a("strong"),dJe=o("speech_to_text_2"),cJe=o(" \u2014 "),yS=a("a"),fJe=o("Speech2Text2Config"),mJe=o(" (Speech2Text2 model)"),gJe=l(),Km=a("li"),Ure=a("strong"),hJe=o("splinter"),pJe=o(" \u2014 "),LS=a("a"),uJe=o("SplinterConfig"),_Je=o(" (Splinter model)"),bJe=l(),Zm=a("li"),Jre=a("strong"),vJe=o("squeezebert"),FJe=o(" \u2014 "),xS=a("a"),TJe=o("SqueezeBertConfig"),MJe=o(" (SqueezeBERT model)"),EJe=l(),eg=a("li"),Yre=a("strong"),CJe=o("swin"),wJe=o(" \u2014 "),$S=a("a"),AJe=o("SwinConfig"),yJe=o(" (Swin model)"),LJe=l(),og=a("li"),Kre=a("strong"),xJe=o("t5"),$Je=o(" \u2014 "),kS=a("a"),kJe=o("T5Config"),SJe=o(" (T5 model)"),RJe=l(),rg=a("li"),Zre=a("strong"),PJe=o("tapas"),BJe=o(" \u2014 "),SS=a("a"),IJe=o("TapasConfig"),qJe=o(" (TAPAS model)"),NJe=l(),tg=a("li"),ete=a("strong"),jJe=o("trajectory_transformer"),DJe=o(" \u2014 "),RS=a("a"),GJe=o("TrajectoryTransformerConfig"),OJe=o(" (Trajectory Transformer model)"),VJe=l(),ag=a("li"),ote=a("strong"),XJe=o("transfo-xl"),zJe=o(" \u2014 "),PS=a("a"),WJe=o("TransfoXLConfig"),QJe=o(" (Transformer-XL model)"),HJe=l(),ng=a("li"),rte=a("strong"),UJe=o("trocr"),JJe=o(" \u2014 "),BS=a("a"),YJe=o("TrOCRConfig"),KJe=o(" (TrOCR model)"),ZJe=l(),sg=a("li"),tte=a("strong"),eYe=o("unispeech"),oYe=o(" \u2014 "),IS=a("a"),rYe=o("UniSpeechConfig"),tYe=o(" (UniSpeech model)"),aYe=l(),lg=a("li"),ate=a("strong"),nYe=o("unispeech-sat"),sYe=o(" \u2014 "),qS=a("a"),lYe=o("UniSpeechSatConfig"),iYe=o(" (UniSpeechSat model)"),dYe=l(),ig=a("li"),nte=a("strong"),cYe=o("van"),fYe=o(" \u2014 "),NS=a("a"),mYe=o("VanConfig"),gYe=o(" (VAN model)"),hYe=l(),dg=a("li"),ste=a("strong"),pYe=o("vilt"),uYe=o(" \u2014 "),jS=a("a"),_Ye=o("ViltConfig"),bYe=o(" (ViLT model)"),vYe=l(),cg=a("li"),lte=a("strong"),FYe=o("vision-encoder-decoder"),TYe=o(" \u2014 "),DS=a("a"),MYe=o("VisionEncoderDecoderConfig"),EYe=o(" (Vision Encoder decoder model)"),CYe=l(),fg=a("li"),ite=a("strong"),wYe=o("vision-text-dual-encoder"),AYe=o(" \u2014 "),GS=a("a"),yYe=o("VisionTextDualEncoderConfig"),LYe=o(" (VisionTextDualEncoder model)"),xYe=l(),mg=a("li"),dte=a("strong"),$Ye=o("visual_bert"),kYe=o(" \u2014 "),OS=a("a"),SYe=o("VisualBertConfig"),RYe=o(" (VisualBert model)"),PYe=l(),gg=a("li"),cte=a("strong"),BYe=o("vit"),IYe=o(" \u2014 "),VS=a("a"),qYe=o("ViTConfig"),NYe=o(" (ViT model)"),jYe=l(),hg=a("li"),fte=a("strong"),DYe=o("vit_mae"),GYe=o(" \u2014 "),XS=a("a"),OYe=o("ViTMAEConfig"),VYe=o(" (ViTMAE model)"),XYe=l(),pg=a("li"),mte=a("strong"),zYe=o("wav2vec2"),WYe=o(" \u2014 "),zS=a("a"),QYe=o("Wav2Vec2Config"),HYe=o(" (Wav2Vec2 model)"),UYe=l(),ug=a("li"),gte=a("strong"),JYe=o("wav2vec2-conformer"),YYe=o(" \u2014 "),WS=a("a"),KYe=o("Wav2Vec2ConformerConfig"),ZYe=o(" (Wav2Vec2-Conformer model)"),eKe=l(),_g=a("li"),hte=a("strong"),oKe=o("wavlm"),rKe=o(" \u2014 "),QS=a("a"),tKe=o("WavLMConfig"),aKe=o(" (WavLM model)"),nKe=l(),bg=a("li"),pte=a("strong"),sKe=o("xglm"),lKe=o(" \u2014 "),HS=a("a"),iKe=o("XGLMConfig"),dKe=o(" (XGLM model)"),cKe=l(),vg=a("li"),ute=a("strong"),fKe=o("xlm"),mKe=o(" \u2014 "),US=a("a"),gKe=o("XLMConfig"),hKe=o(" (XLM model)"),pKe=l(),Fg=a("li"),_te=a("strong"),uKe=o("xlm-prophetnet"),_Ke=o(" \u2014 "),JS=a("a"),bKe=o("XLMProphetNetConfig"),vKe=o(" (XLMProphetNet model)"),FKe=l(),Tg=a("li"),bte=a("strong"),TKe=o("xlm-roberta"),MKe=o(" \u2014 "),YS=a("a"),EKe=o("XLMRobertaConfig"),CKe=o(" (XLM-RoBERTa model)"),wKe=l(),Mg=a("li"),vte=a("strong"),AKe=o("xlm-roberta-xl"),yKe=o(" \u2014 "),KS=a("a"),LKe=o("XLMRobertaXLConfig"),xKe=o(" (XLM-RoBERTa-XL model)"),$Ke=l(),Eg=a("li"),Fte=a("strong"),kKe=o("xlnet"),SKe=o(" \u2014 "),ZS=a("a"),RKe=o("XLNetConfig"),PKe=o(" (XLNet model)"),BKe=l(),Cg=a("li"),Tte=a("strong"),IKe=o("yolos"),qKe=o(" \u2014 "),eR=a("a"),NKe=o("YolosConfig"),jKe=o(" (YOLOS model)"),DKe=l(),wg=a("li"),Mte=a("strong"),GKe=o("yoso"),OKe=o(" \u2014 "),oR=a("a"),VKe=o("YosoConfig"),XKe=o(" (YOSO model)"),zKe=l(),F(Ag.$$.fragment),WKe=l(),yg=a("div"),F(PA.$$.fragment),QKe=l(),Ete=a("p"),HKe=o("Register a new configuration for this class."),iNe=l(),Ci=a("h2"),Lg=a("a"),Cte=a("span"),F(BA.$$.fragment),UKe=l(),wte=a("span"),JKe=o("AutoTokenizer"),dNe=l(),wo=a("div"),F(IA.$$.fragment),YKe=l(),qA=a("p"),KKe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rR=a("a"),ZKe=o("AutoTokenizer.from_pretrained()"),eZe=o(" class method."),oZe=l(),NA=a("p"),rZe=o("This class cannot be instantiated directly using "),Ate=a("code"),tZe=o("__init__()"),aZe=o(" (throws an error)."),nZe=l(),Cr=a("div"),F(jA.$$.fragment),sZe=l(),yte=a("p"),lZe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),iZe=l(),Aa=a("p"),dZe=o("The tokenizer class to instantiate is selected based on the "),Lte=a("code"),cZe=o("model_type"),fZe=o(` property of the config object (either
passed as an argument or loaded from `),xte=a("code"),mZe=o("pretrained_model_name_or_path"),gZe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$te=a("code"),hZe=o("pretrained_model_name_or_path"),pZe=o(":"),uZe=l(),k=a("ul"),Sn=a("li"),kte=a("strong"),_Ze=o("albert"),bZe=o(" \u2014 "),tR=a("a"),vZe=o("AlbertTokenizer"),FZe=o(" or "),aR=a("a"),TZe=o("AlbertTokenizerFast"),MZe=o(" (ALBERT model)"),EZe=l(),Rn=a("li"),Ste=a("strong"),CZe=o("bart"),wZe=o(" \u2014 "),nR=a("a"),AZe=o("BartTokenizer"),yZe=o(" or "),sR=a("a"),LZe=o("BartTokenizerFast"),xZe=o(" (BART model)"),$Ze=l(),Pn=a("li"),Rte=a("strong"),kZe=o("barthez"),SZe=o(" \u2014 "),lR=a("a"),RZe=o("BarthezTokenizer"),PZe=o(" or "),iR=a("a"),BZe=o("BarthezTokenizerFast"),IZe=o(" (BARThez model)"),qZe=l(),Bn=a("li"),Pte=a("strong"),NZe=o("bartpho"),jZe=o(" \u2014 "),dR=a("a"),DZe=o("BartphoTokenizer"),GZe=o(" or "),cR=a("a"),OZe=o("BartphoTokenizerFast"),VZe=o(" (BARTpho model)"),XZe=l(),In=a("li"),Bte=a("strong"),zZe=o("bert"),WZe=o(" \u2014 "),fR=a("a"),QZe=o("BertTokenizer"),HZe=o(" or "),mR=a("a"),UZe=o("BertTokenizerFast"),JZe=o(" (BERT model)"),YZe=l(),xg=a("li"),Ite=a("strong"),KZe=o("bert-generation"),ZZe=o(" \u2014 "),gR=a("a"),eeo=o("BertGenerationTokenizer"),oeo=o(" (Bert Generation model)"),reo=l(),$g=a("li"),qte=a("strong"),teo=o("bert-japanese"),aeo=o(" \u2014 "),hR=a("a"),neo=o("BertJapaneseTokenizer"),seo=o(" (BertJapanese model)"),leo=l(),qn=a("li"),Nte=a("strong"),ieo=o("bertweet"),deo=o(" \u2014 "),pR=a("a"),ceo=o("BertweetTokenizer"),feo=o(" or "),uR=a("a"),meo=o("BertweetTokenizerFast"),geo=o(" (Bertweet model)"),heo=l(),Nn=a("li"),jte=a("strong"),peo=o("big_bird"),ueo=o(" \u2014 "),_R=a("a"),_eo=o("BigBirdTokenizer"),beo=o(" or "),bR=a("a"),veo=o("BigBirdTokenizerFast"),Feo=o(" (BigBird model)"),Teo=l(),jn=a("li"),Dte=a("strong"),Meo=o("bigbird_pegasus"),Eeo=o(" \u2014 "),vR=a("a"),Ceo=o("PegasusTokenizer"),weo=o(" or "),FR=a("a"),Aeo=o("PegasusTokenizerFast"),yeo=o(" (BigBirdPegasus model)"),Leo=l(),Dn=a("li"),Gte=a("strong"),xeo=o("blenderbot"),$eo=o(" \u2014 "),TR=a("a"),keo=o("BlenderbotTokenizer"),Seo=o(" or "),MR=a("a"),Reo=o("BlenderbotTokenizerFast"),Peo=o(" (Blenderbot model)"),Beo=l(),kg=a("li"),Ote=a("strong"),Ieo=o("blenderbot-small"),qeo=o(" \u2014 "),ER=a("a"),Neo=o("BlenderbotSmallTokenizer"),jeo=o(" (BlenderbotSmall model)"),Deo=l(),Sg=a("li"),Vte=a("strong"),Geo=o("byt5"),Oeo=o(" \u2014 "),CR=a("a"),Veo=o("ByT5Tokenizer"),Xeo=o(" (ByT5 model)"),zeo=l(),Gn=a("li"),Xte=a("strong"),Weo=o("camembert"),Qeo=o(" \u2014 "),wR=a("a"),Heo=o("CamembertTokenizer"),Ueo=o(" or "),AR=a("a"),Jeo=o("CamembertTokenizerFast"),Yeo=o(" (CamemBERT model)"),Keo=l(),Rg=a("li"),zte=a("strong"),Zeo=o("canine"),eoo=o(" \u2014 "),yR=a("a"),ooo=o("CanineTokenizer"),roo=o(" (Canine model)"),too=l(),On=a("li"),Wte=a("strong"),aoo=o("clip"),noo=o(" \u2014 "),LR=a("a"),soo=o("CLIPTokenizer"),loo=o(" or "),xR=a("a"),ioo=o("CLIPTokenizerFast"),doo=o(" (CLIP model)"),coo=l(),Vn=a("li"),Qte=a("strong"),foo=o("convbert"),moo=o(" \u2014 "),$R=a("a"),goo=o("ConvBertTokenizer"),hoo=o(" or "),kR=a("a"),poo=o("ConvBertTokenizerFast"),uoo=o(" (ConvBERT model)"),_oo=l(),Xn=a("li"),Hte=a("strong"),boo=o("cpm"),voo=o(" \u2014 "),SR=a("a"),Foo=o("CpmTokenizer"),Too=o(" or "),RR=a("a"),Moo=o("CpmTokenizerFast"),Eoo=o(" (CPM model)"),Coo=l(),Pg=a("li"),Ute=a("strong"),woo=o("ctrl"),Aoo=o(" \u2014 "),PR=a("a"),yoo=o("CTRLTokenizer"),Loo=o(" (CTRL model)"),xoo=l(),zn=a("li"),Jte=a("strong"),$oo=o("data2vec-text"),koo=o(" \u2014 "),BR=a("a"),Soo=o("RobertaTokenizer"),Roo=o(" or "),IR=a("a"),Poo=o("RobertaTokenizerFast"),Boo=o(" (Data2VecText model)"),Ioo=l(),Wn=a("li"),Yte=a("strong"),qoo=o("deberta"),Noo=o(" \u2014 "),qR=a("a"),joo=o("DebertaTokenizer"),Doo=o(" or "),NR=a("a"),Goo=o("DebertaTokenizerFast"),Ooo=o(" (DeBERTa model)"),Voo=l(),Qn=a("li"),Kte=a("strong"),Xoo=o("deberta-v2"),zoo=o(" \u2014 "),jR=a("a"),Woo=o("DebertaV2Tokenizer"),Qoo=o(" or "),DR=a("a"),Hoo=o("DebertaV2TokenizerFast"),Uoo=o(" (DeBERTa-v2 model)"),Joo=l(),Hn=a("li"),Zte=a("strong"),Yoo=o("distilbert"),Koo=o(" \u2014 "),GR=a("a"),Zoo=o("DistilBertTokenizer"),ero=o(" or "),OR=a("a"),oro=o("DistilBertTokenizerFast"),rro=o(" (DistilBERT model)"),tro=l(),Un=a("li"),eae=a("strong"),aro=o("dpr"),nro=o(" \u2014 "),VR=a("a"),sro=o("DPRQuestionEncoderTokenizer"),lro=o(" or "),XR=a("a"),iro=o("DPRQuestionEncoderTokenizerFast"),dro=o(" (DPR model)"),cro=l(),Jn=a("li"),oae=a("strong"),fro=o("electra"),mro=o(" \u2014 "),zR=a("a"),gro=o("ElectraTokenizer"),hro=o(" or "),WR=a("a"),pro=o("ElectraTokenizerFast"),uro=o(" (ELECTRA model)"),_ro=l(),Bg=a("li"),rae=a("strong"),bro=o("flaubert"),vro=o(" \u2014 "),QR=a("a"),Fro=o("FlaubertTokenizer"),Tro=o(" (FlauBERT model)"),Mro=l(),Yn=a("li"),tae=a("strong"),Ero=o("fnet"),Cro=o(" \u2014 "),HR=a("a"),wro=o("FNetTokenizer"),Aro=o(" or "),UR=a("a"),yro=o("FNetTokenizerFast"),Lro=o(" (FNet model)"),xro=l(),Ig=a("li"),aae=a("strong"),$ro=o("fsmt"),kro=o(" \u2014 "),JR=a("a"),Sro=o("FSMTTokenizer"),Rro=o(" (FairSeq Machine-Translation model)"),Pro=l(),Kn=a("li"),nae=a("strong"),Bro=o("funnel"),Iro=o(" \u2014 "),YR=a("a"),qro=o("FunnelTokenizer"),Nro=o(" or "),KR=a("a"),jro=o("FunnelTokenizerFast"),Dro=o(" (Funnel Transformer model)"),Gro=l(),Zn=a("li"),sae=a("strong"),Oro=o("gpt2"),Vro=o(" \u2014 "),ZR=a("a"),Xro=o("GPT2Tokenizer"),zro=o(" or "),eP=a("a"),Wro=o("GPT2TokenizerFast"),Qro=o(" (OpenAI GPT-2 model)"),Hro=l(),es=a("li"),lae=a("strong"),Uro=o("gpt_neo"),Jro=o(" \u2014 "),oP=a("a"),Yro=o("GPT2Tokenizer"),Kro=o(" or "),rP=a("a"),Zro=o("GPT2TokenizerFast"),eto=o(" (GPT Neo model)"),oto=l(),qg=a("li"),iae=a("strong"),rto=o("gpt_neox"),tto=o(" \u2014 "),tP=a("a"),ato=o("GPTNeoXTokenizerFast"),nto=o(" (GPT NeoX model)"),sto=l(),os=a("li"),dae=a("strong"),lto=o("gptj"),ito=o(" \u2014 "),aP=a("a"),dto=o("GPT2Tokenizer"),cto=o(" or "),nP=a("a"),fto=o("GPT2TokenizerFast"),mto=o(" (GPT-J model)"),gto=l(),rs=a("li"),cae=a("strong"),hto=o("herbert"),pto=o(" \u2014 "),sP=a("a"),uto=o("HerbertTokenizer"),_to=o(" or "),lP=a("a"),bto=o("HerbertTokenizerFast"),vto=o(" (HerBERT model)"),Fto=l(),Ng=a("li"),fae=a("strong"),Tto=o("hubert"),Mto=o(" \u2014 "),iP=a("a"),Eto=o("Wav2Vec2CTCTokenizer"),Cto=o(" (Hubert model)"),wto=l(),ts=a("li"),mae=a("strong"),Ato=o("ibert"),yto=o(" \u2014 "),dP=a("a"),Lto=o("RobertaTokenizer"),xto=o(" or "),cP=a("a"),$to=o("RobertaTokenizerFast"),kto=o(" (I-BERT model)"),Sto=l(),as=a("li"),gae=a("strong"),Rto=o("layoutlm"),Pto=o(" \u2014 "),fP=a("a"),Bto=o("LayoutLMTokenizer"),Ito=o(" or "),mP=a("a"),qto=o("LayoutLMTokenizerFast"),Nto=o(" (LayoutLM model)"),jto=l(),ns=a("li"),hae=a("strong"),Dto=o("layoutlmv2"),Gto=o(" \u2014 "),gP=a("a"),Oto=o("LayoutLMv2Tokenizer"),Vto=o(" or "),hP=a("a"),Xto=o("LayoutLMv2TokenizerFast"),zto=o(" (LayoutLMv2 model)"),Wto=l(),ss=a("li"),pae=a("strong"),Qto=o("layoutlmv3"),Hto=o(" \u2014 "),pP=a("a"),Uto=o("LayoutLMv3Tokenizer"),Jto=o(" or "),uP=a("a"),Yto=o("LayoutLMv3TokenizerFast"),Kto=o(" (LayoutLMv3 model)"),Zto=l(),ls=a("li"),uae=a("strong"),eao=o("layoutxlm"),oao=o(" \u2014 "),_P=a("a"),rao=o("LayoutXLMTokenizer"),tao=o(" or "),bP=a("a"),aao=o("LayoutXLMTokenizerFast"),nao=o(" (LayoutXLM model)"),sao=l(),is=a("li"),_ae=a("strong"),lao=o("led"),iao=o(" \u2014 "),vP=a("a"),dao=o("LEDTokenizer"),cao=o(" or "),FP=a("a"),fao=o("LEDTokenizerFast"),mao=o(" (LED model)"),gao=l(),ds=a("li"),bae=a("strong"),hao=o("longformer"),pao=o(" \u2014 "),TP=a("a"),uao=o("LongformerTokenizer"),_ao=o(" or "),MP=a("a"),bao=o("LongformerTokenizerFast"),vao=o(" (Longformer model)"),Fao=l(),jg=a("li"),vae=a("strong"),Tao=o("luke"),Mao=o(" \u2014 "),EP=a("a"),Eao=o("LukeTokenizer"),Cao=o(" (LUKE model)"),wao=l(),cs=a("li"),Fae=a("strong"),Aao=o("lxmert"),yao=o(" \u2014 "),CP=a("a"),Lao=o("LxmertTokenizer"),xao=o(" or "),wP=a("a"),$ao=o("LxmertTokenizerFast"),kao=o(" (LXMERT model)"),Sao=l(),Dg=a("li"),Tae=a("strong"),Rao=o("m2m_100"),Pao=o(" \u2014 "),AP=a("a"),Bao=o("M2M100Tokenizer"),Iao=o(" (M2M100 model)"),qao=l(),Gg=a("li"),Mae=a("strong"),Nao=o("marian"),jao=o(" \u2014 "),yP=a("a"),Dao=o("MarianTokenizer"),Gao=o(" (Marian model)"),Oao=l(),fs=a("li"),Eae=a("strong"),Vao=o("mbart"),Xao=o(" \u2014 "),LP=a("a"),zao=o("MBartTokenizer"),Wao=o(" or "),xP=a("a"),Qao=o("MBartTokenizerFast"),Hao=o(" (mBART model)"),Uao=l(),ms=a("li"),Cae=a("strong"),Jao=o("mbart50"),Yao=o(" \u2014 "),$P=a("a"),Kao=o("MBart50Tokenizer"),Zao=o(" or "),kP=a("a"),eno=o("MBart50TokenizerFast"),ono=o(" (mBART-50 model)"),rno=l(),gs=a("li"),wae=a("strong"),tno=o("megatron-bert"),ano=o(" \u2014 "),SP=a("a"),nno=o("BertTokenizer"),sno=o(" or "),RP=a("a"),lno=o("BertTokenizerFast"),ino=o(" (MegatronBert model)"),dno=l(),Og=a("li"),Aae=a("strong"),cno=o("mluke"),fno=o(" \u2014 "),PP=a("a"),mno=o("MLukeTokenizer"),gno=o(" (mLUKE model)"),hno=l(),hs=a("li"),yae=a("strong"),pno=o("mobilebert"),uno=o(" \u2014 "),BP=a("a"),_no=o("MobileBertTokenizer"),bno=o(" or "),IP=a("a"),vno=o("MobileBertTokenizerFast"),Fno=o(" (MobileBERT model)"),Tno=l(),ps=a("li"),Lae=a("strong"),Mno=o("mpnet"),Eno=o(" \u2014 "),qP=a("a"),Cno=o("MPNetTokenizer"),wno=o(" or "),NP=a("a"),Ano=o("MPNetTokenizerFast"),yno=o(" (MPNet model)"),Lno=l(),us=a("li"),xae=a("strong"),xno=o("mt5"),$no=o(" \u2014 "),jP=a("a"),kno=o("MT5Tokenizer"),Sno=o(" or "),DP=a("a"),Rno=o("MT5TokenizerFast"),Pno=o(" (mT5 model)"),Bno=l(),_s=a("li"),$ae=a("strong"),Ino=o("nystromformer"),qno=o(" \u2014 "),GP=a("a"),Nno=o("AlbertTokenizer"),jno=o(" or "),OP=a("a"),Dno=o("AlbertTokenizerFast"),Gno=o(" (Nystromformer model)"),Ono=l(),bs=a("li"),kae=a("strong"),Vno=o("openai-gpt"),Xno=o(" \u2014 "),VP=a("a"),zno=o("OpenAIGPTTokenizer"),Wno=o(" or "),XP=a("a"),Qno=o("OpenAIGPTTokenizerFast"),Hno=o(" (OpenAI GPT model)"),Uno=l(),Vg=a("li"),Sae=a("strong"),Jno=o("opt"),Yno=o(" \u2014 "),zP=a("a"),Kno=o("GPT2Tokenizer"),Zno=o(" (OPT model)"),eso=l(),vs=a("li"),Rae=a("strong"),oso=o("pegasus"),rso=o(" \u2014 "),WP=a("a"),tso=o("PegasusTokenizer"),aso=o(" or "),QP=a("a"),nso=o("PegasusTokenizerFast"),sso=o(" (Pegasus model)"),lso=l(),Xg=a("li"),Pae=a("strong"),iso=o("perceiver"),dso=o(" \u2014 "),HP=a("a"),cso=o("PerceiverTokenizer"),fso=o(" (Perceiver model)"),mso=l(),Fs=a("li"),Bae=a("strong"),gso=o("phobert"),hso=o(" \u2014 "),UP=a("a"),pso=o("PhobertTokenizer"),uso=o(" or "),JP=a("a"),_so=o("PhobertTokenizerFast"),bso=o(" (PhoBERT model)"),vso=l(),zg=a("li"),Iae=a("strong"),Fso=o("plbart"),Tso=o(" \u2014 "),YP=a("a"),Mso=o("PLBartTokenizer"),Eso=o(" (PLBart model)"),Cso=l(),Wg=a("li"),qae=a("strong"),wso=o("prophetnet"),Aso=o(" \u2014 "),KP=a("a"),yso=o("ProphetNetTokenizer"),Lso=o(" (ProphetNet model)"),xso=l(),Ts=a("li"),Nae=a("strong"),$so=o("qdqbert"),kso=o(" \u2014 "),ZP=a("a"),Sso=o("BertTokenizer"),Rso=o(" or "),eB=a("a"),Pso=o("BertTokenizerFast"),Bso=o(" (QDQBert model)"),Iso=l(),Qg=a("li"),jae=a("strong"),qso=o("rag"),Nso=o(" \u2014 "),oB=a("a"),jso=o("RagTokenizer"),Dso=o(" (RAG model)"),Gso=l(),Ms=a("li"),Dae=a("strong"),Oso=o("realm"),Vso=o(" \u2014 "),rB=a("a"),Xso=o("RealmTokenizer"),zso=o(" or "),tB=a("a"),Wso=o("RealmTokenizerFast"),Qso=o(" (Realm model)"),Hso=l(),Es=a("li"),Gae=a("strong"),Uso=o("reformer"),Jso=o(" \u2014 "),aB=a("a"),Yso=o("ReformerTokenizer"),Kso=o(" or "),nB=a("a"),Zso=o("ReformerTokenizerFast"),elo=o(" (Reformer model)"),olo=l(),Cs=a("li"),Oae=a("strong"),rlo=o("rembert"),tlo=o(" \u2014 "),sB=a("a"),alo=o("RemBertTokenizer"),nlo=o(" or "),lB=a("a"),slo=o("RemBertTokenizerFast"),llo=o(" (RemBERT model)"),ilo=l(),ws=a("li"),Vae=a("strong"),dlo=o("retribert"),clo=o(" \u2014 "),iB=a("a"),flo=o("RetriBertTokenizer"),mlo=o(" or "),dB=a("a"),glo=o("RetriBertTokenizerFast"),hlo=o(" (RetriBERT model)"),plo=l(),As=a("li"),Xae=a("strong"),ulo=o("roberta"),_lo=o(" \u2014 "),cB=a("a"),blo=o("RobertaTokenizer"),vlo=o(" or "),fB=a("a"),Flo=o("RobertaTokenizerFast"),Tlo=o(" (RoBERTa model)"),Mlo=l(),ys=a("li"),zae=a("strong"),Elo=o("roformer"),Clo=o(" \u2014 "),mB=a("a"),wlo=o("RoFormerTokenizer"),Alo=o(" or "),gB=a("a"),ylo=o("RoFormerTokenizerFast"),Llo=o(" (RoFormer model)"),xlo=l(),Hg=a("li"),Wae=a("strong"),$lo=o("speech_to_text"),klo=o(" \u2014 "),hB=a("a"),Slo=o("Speech2TextTokenizer"),Rlo=o(" (Speech2Text model)"),Plo=l(),Ug=a("li"),Qae=a("strong"),Blo=o("speech_to_text_2"),Ilo=o(" \u2014 "),pB=a("a"),qlo=o("Speech2Text2Tokenizer"),Nlo=o(" (Speech2Text2 model)"),jlo=l(),Ls=a("li"),Hae=a("strong"),Dlo=o("splinter"),Glo=o(" \u2014 "),uB=a("a"),Olo=o("SplinterTokenizer"),Vlo=o(" or "),_B=a("a"),Xlo=o("SplinterTokenizerFast"),zlo=o(" (Splinter model)"),Wlo=l(),xs=a("li"),Uae=a("strong"),Qlo=o("squeezebert"),Hlo=o(" \u2014 "),bB=a("a"),Ulo=o("SqueezeBertTokenizer"),Jlo=o(" or "),vB=a("a"),Ylo=o("SqueezeBertTokenizerFast"),Klo=o(" (SqueezeBERT model)"),Zlo=l(),$s=a("li"),Jae=a("strong"),eio=o("t5"),oio=o(" \u2014 "),FB=a("a"),rio=o("T5Tokenizer"),tio=o(" or "),TB=a("a"),aio=o("T5TokenizerFast"),nio=o(" (T5 model)"),sio=l(),Jg=a("li"),Yae=a("strong"),lio=o("tapas"),iio=o(" \u2014 "),MB=a("a"),dio=o("TapasTokenizer"),cio=o(" (TAPAS model)"),fio=l(),Yg=a("li"),Kae=a("strong"),mio=o("tapex"),gio=o(" \u2014 "),EB=a("a"),hio=o("TapexTokenizer"),pio=o(" (TAPEX model)"),uio=l(),Kg=a("li"),Zae=a("strong"),_io=o("transfo-xl"),bio=o(" \u2014 "),CB=a("a"),vio=o("TransfoXLTokenizer"),Fio=o(" (Transformer-XL model)"),Tio=l(),ks=a("li"),ene=a("strong"),Mio=o("visual_bert"),Eio=o(" \u2014 "),wB=a("a"),Cio=o("BertTokenizer"),wio=o(" or "),AB=a("a"),Aio=o("BertTokenizerFast"),yio=o(" (VisualBert model)"),Lio=l(),Zg=a("li"),one=a("strong"),xio=o("wav2vec2"),$io=o(" \u2014 "),yB=a("a"),kio=o("Wav2Vec2CTCTokenizer"),Sio=o(" (Wav2Vec2 model)"),Rio=l(),eh=a("li"),rne=a("strong"),Pio=o("wav2vec2-conformer"),Bio=o(" \u2014 "),LB=a("a"),Iio=o("Wav2Vec2CTCTokenizer"),qio=o(" (Wav2Vec2-Conformer model)"),Nio=l(),oh=a("li"),tne=a("strong"),jio=o("wav2vec2_phoneme"),Dio=o(" \u2014 "),xB=a("a"),Gio=o("Wav2Vec2PhonemeCTCTokenizer"),Oio=o(" (Wav2Vec2Phoneme model)"),Vio=l(),Ss=a("li"),ane=a("strong"),Xio=o("xglm"),zio=o(" \u2014 "),$B=a("a"),Wio=o("XGLMTokenizer"),Qio=o(" or "),kB=a("a"),Hio=o("XGLMTokenizerFast"),Uio=o(" (XGLM model)"),Jio=l(),rh=a("li"),nne=a("strong"),Yio=o("xlm"),Kio=o(" \u2014 "),SB=a("a"),Zio=o("XLMTokenizer"),edo=o(" (XLM model)"),odo=l(),th=a("li"),sne=a("strong"),rdo=o("xlm-prophetnet"),tdo=o(" \u2014 "),RB=a("a"),ado=o("XLMProphetNetTokenizer"),ndo=o(" (XLMProphetNet model)"),sdo=l(),Rs=a("li"),lne=a("strong"),ldo=o("xlm-roberta"),ido=o(" \u2014 "),PB=a("a"),ddo=o("XLMRobertaTokenizer"),cdo=o(" or "),BB=a("a"),fdo=o("XLMRobertaTokenizerFast"),mdo=o(" (XLM-RoBERTa model)"),gdo=l(),Ps=a("li"),ine=a("strong"),hdo=o("xlm-roberta-xl"),pdo=o(" \u2014 "),IB=a("a"),udo=o("RobertaTokenizer"),_do=o(" or "),qB=a("a"),bdo=o("RobertaTokenizerFast"),vdo=o(" (XLM-RoBERTa-XL model)"),Fdo=l(),Bs=a("li"),dne=a("strong"),Tdo=o("xlnet"),Mdo=o(" \u2014 "),NB=a("a"),Edo=o("XLNetTokenizer"),Cdo=o(" or "),jB=a("a"),wdo=o("XLNetTokenizerFast"),Ado=o(" (XLNet model)"),ydo=l(),Is=a("li"),cne=a("strong"),Ldo=o("yoso"),xdo=o(" \u2014 "),DB=a("a"),$do=o("AlbertTokenizer"),kdo=o(" or "),GB=a("a"),Sdo=o("AlbertTokenizerFast"),Rdo=o(" (YOSO model)"),Pdo=l(),F(ah.$$.fragment),Bdo=l(),nh=a("div"),F(DA.$$.fragment),Ido=l(),fne=a("p"),qdo=o("Register a new tokenizer in this mapping."),cNe=l(),wi=a("h2"),sh=a("a"),mne=a("span"),F(GA.$$.fragment),Ndo=l(),gne=a("span"),jdo=o("AutoFeatureExtractor"),fNe=l(),Ao=a("div"),F(OA.$$.fragment),Ddo=l(),VA=a("p"),Gdo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),OB=a("a"),Odo=o("AutoFeatureExtractor.from_pretrained()"),Vdo=o(" class method."),Xdo=l(),XA=a("p"),zdo=o("This class cannot be instantiated directly using "),hne=a("code"),Wdo=o("__init__()"),Qdo=o(" (throws an error)."),Hdo=l(),He=a("div"),F(zA.$$.fragment),Udo=l(),pne=a("p"),Jdo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Ydo=l(),ya=a("p"),Kdo=o("The feature extractor class to instantiate is selected based on the "),une=a("code"),Zdo=o("model_type"),eco=o(` property of the config object
(either passed as an argument or loaded from `),_ne=a("code"),oco=o("pretrained_model_name_or_path"),rco=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),bne=a("code"),tco=o("pretrained_model_name_or_path"),aco=o(":"),nco=l(),Y=a("ul"),lh=a("li"),vne=a("strong"),sco=o("beit"),lco=o(" \u2014 "),VB=a("a"),ico=o("BeitFeatureExtractor"),dco=o(" (BEiT model)"),cco=l(),ih=a("li"),Fne=a("strong"),fco=o("clip"),mco=o(" \u2014 "),XB=a("a"),gco=o("CLIPFeatureExtractor"),hco=o(" (CLIP model)"),pco=l(),dh=a("li"),Tne=a("strong"),uco=o("convnext"),_co=o(" \u2014 "),zB=a("a"),bco=o("ConvNextFeatureExtractor"),vco=o(" (ConvNext model)"),Fco=l(),ch=a("li"),Mne=a("strong"),Tco=o("cvt"),Mco=o(" \u2014 "),WB=a("a"),Eco=o("ConvNextFeatureExtractor"),Cco=o(" (CvT model)"),wco=l(),fh=a("li"),Ene=a("strong"),Aco=o("data2vec-audio"),yco=o(" \u2014 "),QB=a("a"),Lco=o("Wav2Vec2FeatureExtractor"),xco=o(" (Data2VecAudio model)"),$co=l(),mh=a("li"),Cne=a("strong"),kco=o("data2vec-vision"),Sco=o(" \u2014 "),HB=a("a"),Rco=o("BeitFeatureExtractor"),Pco=o(" (Data2VecVision model)"),Bco=l(),gh=a("li"),wne=a("strong"),Ico=o("deit"),qco=o(" \u2014 "),UB=a("a"),Nco=o("DeiTFeatureExtractor"),jco=o(" (DeiT model)"),Dco=l(),hh=a("li"),Ane=a("strong"),Gco=o("detr"),Oco=o(" \u2014 "),JB=a("a"),Vco=o("DetrFeatureExtractor"),Xco=o(" (DETR model)"),zco=l(),ph=a("li"),yne=a("strong"),Wco=o("dpt"),Qco=o(" \u2014 "),YB=a("a"),Hco=o("DPTFeatureExtractor"),Uco=o(" (DPT model)"),Jco=l(),uh=a("li"),Lne=a("strong"),Yco=o("flava"),Kco=o(" \u2014 "),KB=a("a"),Zco=o("FlavaFeatureExtractor"),efo=o(" (Flava model)"),ofo=l(),_h=a("li"),xne=a("strong"),rfo=o("glpn"),tfo=o(" \u2014 "),ZB=a("a"),afo=o("GLPNFeatureExtractor"),nfo=o(" (GLPN model)"),sfo=l(),bh=a("li"),$ne=a("strong"),lfo=o("hubert"),ifo=o(" \u2014 "),eI=a("a"),dfo=o("Wav2Vec2FeatureExtractor"),cfo=o(" (Hubert model)"),ffo=l(),vh=a("li"),kne=a("strong"),mfo=o("imagegpt"),gfo=o(" \u2014 "),oI=a("a"),hfo=o("ImageGPTFeatureExtractor"),pfo=o(" (ImageGPT model)"),ufo=l(),Fh=a("li"),Sne=a("strong"),_fo=o("layoutlmv2"),bfo=o(" \u2014 "),rI=a("a"),vfo=o("LayoutLMv2FeatureExtractor"),Ffo=o(" (LayoutLMv2 model)"),Tfo=l(),Th=a("li"),Rne=a("strong"),Mfo=o("layoutlmv3"),Efo=o(" \u2014 "),tI=a("a"),Cfo=o("LayoutLMv3FeatureExtractor"),wfo=o(" (LayoutLMv3 model)"),Afo=l(),Mh=a("li"),Pne=a("strong"),yfo=o("maskformer"),Lfo=o(" \u2014 "),aI=a("a"),xfo=o("MaskFormerFeatureExtractor"),$fo=o(" (MaskFormer model)"),kfo=l(),Eh=a("li"),Bne=a("strong"),Sfo=o("perceiver"),Rfo=o(" \u2014 "),nI=a("a"),Pfo=o("PerceiverFeatureExtractor"),Bfo=o(" (Perceiver model)"),Ifo=l(),Ch=a("li"),Ine=a("strong"),qfo=o("poolformer"),Nfo=o(" \u2014 "),sI=a("a"),jfo=o("PoolFormerFeatureExtractor"),Dfo=o(" (PoolFormer model)"),Gfo=l(),wh=a("li"),qne=a("strong"),Ofo=o("regnet"),Vfo=o(" \u2014 "),lI=a("a"),Xfo=o("ConvNextFeatureExtractor"),zfo=o(" (RegNet model)"),Wfo=l(),Ah=a("li"),Nne=a("strong"),Qfo=o("resnet"),Hfo=o(" \u2014 "),iI=a("a"),Ufo=o("ConvNextFeatureExtractor"),Jfo=o(" (ResNet model)"),Yfo=l(),yh=a("li"),jne=a("strong"),Kfo=o("segformer"),Zfo=o(" \u2014 "),dI=a("a"),emo=o("SegformerFeatureExtractor"),omo=o(" (SegFormer model)"),rmo=l(),Lh=a("li"),Dne=a("strong"),tmo=o("speech_to_text"),amo=o(" \u2014 "),cI=a("a"),nmo=o("Speech2TextFeatureExtractor"),smo=o(" (Speech2Text model)"),lmo=l(),xh=a("li"),Gne=a("strong"),imo=o("swin"),dmo=o(" \u2014 "),fI=a("a"),cmo=o("ViTFeatureExtractor"),fmo=o(" (Swin model)"),mmo=l(),$h=a("li"),One=a("strong"),gmo=o("van"),hmo=o(" \u2014 "),mI=a("a"),pmo=o("ConvNextFeatureExtractor"),umo=o(" (VAN model)"),_mo=l(),kh=a("li"),Vne=a("strong"),bmo=o("vit"),vmo=o(" \u2014 "),gI=a("a"),Fmo=o("ViTFeatureExtractor"),Tmo=o(" (ViT model)"),Mmo=l(),Sh=a("li"),Xne=a("strong"),Emo=o("vit_mae"),Cmo=o(" \u2014 "),hI=a("a"),wmo=o("ViTFeatureExtractor"),Amo=o(" (ViTMAE model)"),ymo=l(),Rh=a("li"),zne=a("strong"),Lmo=o("wav2vec2"),xmo=o(" \u2014 "),pI=a("a"),$mo=o("Wav2Vec2FeatureExtractor"),kmo=o(" (Wav2Vec2 model)"),Smo=l(),Ph=a("li"),Wne=a("strong"),Rmo=o("wav2vec2-conformer"),Pmo=o(" \u2014 "),uI=a("a"),Bmo=o("Wav2Vec2FeatureExtractor"),Imo=o(" (Wav2Vec2-Conformer model)"),qmo=l(),Bh=a("li"),Qne=a("strong"),Nmo=o("yolos"),jmo=o(" \u2014 "),_I=a("a"),Dmo=o("YolosFeatureExtractor"),Gmo=o(" (YOLOS model)"),Omo=l(),F(Ih.$$.fragment),Vmo=l(),F(qh.$$.fragment),Xmo=l(),Nh=a("div"),F(WA.$$.fragment),zmo=l(),Hne=a("p"),Wmo=o("Register a new feature extractor for this class."),mNe=l(),Ai=a("h2"),jh=a("a"),Une=a("span"),F(QA.$$.fragment),Qmo=l(),Jne=a("span"),Hmo=o("AutoProcessor"),gNe=l(),yo=a("div"),F(HA.$$.fragment),Umo=l(),UA=a("p"),Jmo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),bI=a("a"),Ymo=o("AutoProcessor.from_pretrained()"),Kmo=o(" class method."),Zmo=l(),JA=a("p"),ego=o("This class cannot be instantiated directly using "),Yne=a("code"),ogo=o("__init__()"),rgo=o(" (throws an error)."),tgo=l(),Ue=a("div"),F(YA.$$.fragment),ago=l(),Kne=a("p"),ngo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),sgo=l(),yi=a("p"),lgo=o("The processor class to instantiate is selected based on the "),Zne=a("code"),igo=o("model_type"),dgo=o(` property of the config object (either
passed as an argument or loaded from `),ese=a("code"),cgo=o("pretrained_model_name_or_path"),fgo=o(" if possible):"),mgo=l(),he=a("ul"),Dh=a("li"),ose=a("strong"),ggo=o("clip"),hgo=o(" \u2014 "),vI=a("a"),pgo=o("CLIPProcessor"),ugo=o(" (CLIP model)"),_go=l(),Gh=a("li"),rse=a("strong"),bgo=o("flava"),vgo=o(" \u2014 "),tse=a("code"),Fgo=o("FLAVAProcessor"),Tgo=o(" (Flava model)"),Mgo=l(),Oh=a("li"),ase=a("strong"),Ego=o("layoutlmv2"),Cgo=o(" \u2014 "),FI=a("a"),wgo=o("LayoutLMv2Processor"),Ago=o(" (LayoutLMv2 model)"),ygo=l(),Vh=a("li"),nse=a("strong"),Lgo=o("layoutlmv3"),xgo=o(" \u2014 "),TI=a("a"),$go=o("LayoutLMv3Processor"),kgo=o(" (LayoutLMv3 model)"),Sgo=l(),Xh=a("li"),sse=a("strong"),Rgo=o("layoutxlm"),Pgo=o(" \u2014 "),MI=a("a"),Bgo=o("LayoutXLMProcessor"),Igo=o(" (LayoutXLM model)"),qgo=l(),zh=a("li"),lse=a("strong"),Ngo=o("sew"),jgo=o(" \u2014 "),EI=a("a"),Dgo=o("Wav2Vec2Processor"),Ggo=o(" (SEW model)"),Ogo=l(),Wh=a("li"),ise=a("strong"),Vgo=o("sew-d"),Xgo=o(" \u2014 "),CI=a("a"),zgo=o("Wav2Vec2Processor"),Wgo=o(" (SEW-D model)"),Qgo=l(),Qh=a("li"),dse=a("strong"),Hgo=o("speech_to_text"),Ugo=o(" \u2014 "),wI=a("a"),Jgo=o("Speech2TextProcessor"),Ygo=o(" (Speech2Text model)"),Kgo=l(),Hh=a("li"),cse=a("strong"),Zgo=o("speech_to_text_2"),eho=o(" \u2014 "),AI=a("a"),oho=o("Speech2Text2Processor"),rho=o(" (Speech2Text2 model)"),tho=l(),Uh=a("li"),fse=a("strong"),aho=o("trocr"),nho=o(" \u2014 "),yI=a("a"),sho=o("TrOCRProcessor"),lho=o(" (TrOCR model)"),iho=l(),Jh=a("li"),mse=a("strong"),dho=o("unispeech"),cho=o(" \u2014 "),LI=a("a"),fho=o("Wav2Vec2Processor"),mho=o(" (UniSpeech model)"),gho=l(),Yh=a("li"),gse=a("strong"),hho=o("unispeech-sat"),pho=o(" \u2014 "),xI=a("a"),uho=o("Wav2Vec2Processor"),_ho=o(" (UniSpeechSat model)"),bho=l(),Kh=a("li"),hse=a("strong"),vho=o("vilt"),Fho=o(" \u2014 "),$I=a("a"),Tho=o("ViltProcessor"),Mho=o(" (ViLT model)"),Eho=l(),Zh=a("li"),pse=a("strong"),Cho=o("vision-text-dual-encoder"),who=o(" \u2014 "),kI=a("a"),Aho=o("VisionTextDualEncoderProcessor"),yho=o(" (VisionTextDualEncoder model)"),Lho=l(),ep=a("li"),use=a("strong"),xho=o("wav2vec2"),$ho=o(" \u2014 "),SI=a("a"),kho=o("Wav2Vec2Processor"),Sho=o(" (Wav2Vec2 model)"),Rho=l(),op=a("li"),_se=a("strong"),Pho=o("wav2vec2-conformer"),Bho=o(" \u2014 "),RI=a("a"),Iho=o("Wav2Vec2Processor"),qho=o(" (Wav2Vec2-Conformer model)"),Nho=l(),rp=a("li"),bse=a("strong"),jho=o("wavlm"),Dho=o(" \u2014 "),PI=a("a"),Gho=o("Wav2Vec2Processor"),Oho=o(" (WavLM model)"),Vho=l(),F(tp.$$.fragment),Xho=l(),F(ap.$$.fragment),zho=l(),np=a("div"),F(KA.$$.fragment),Who=l(),vse=a("p"),Qho=o("Register a new processor for this class."),hNe=l(),Li=a("h2"),sp=a("a"),Fse=a("span"),F(ZA.$$.fragment),Hho=l(),Tse=a("span"),Uho=o("AutoModel"),pNe=l(),Lo=a("div"),F(ey.$$.fragment),Jho=l(),xi=a("p"),Yho=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),BI=a("a"),Kho=o("from_pretrained()"),Zho=o(" class method or the "),II=a("a"),epo=o("from_config()"),opo=o(` class
method.`),rpo=l(),oy=a("p"),tpo=o("This class cannot be instantiated directly using "),Mse=a("code"),apo=o("__init__()"),npo=o(" (throws an error)."),spo=l(),tt=a("div"),F(ry.$$.fragment),lpo=l(),Ese=a("p"),ipo=o("Instantiates one of the base model classes of the library from a configuration."),dpo=l(),$i=a("p"),cpo=o(`Note:
Loading a model from its configuration file does `),Cse=a("strong"),fpo=o("not"),mpo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qI=a("a"),gpo=o("from_pretrained()"),hpo=o(" to load the model weights."),ppo=l(),F(lp.$$.fragment),upo=l(),Je=a("div"),F(ty.$$.fragment),_po=l(),wse=a("p"),bpo=o("Instantiate one of the base model classes of the library from a pretrained model."),vpo=l(),La=a("p"),Fpo=o("The model class to instantiate is selected based on the "),Ase=a("code"),Tpo=o("model_type"),Mpo=o(` property of the config object (either
passed as an argument or loaded from `),yse=a("code"),Epo=o("pretrained_model_name_or_path"),Cpo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lse=a("code"),wpo=o("pretrained_model_name_or_path"),Apo=o(":"),ypo=l(),x=a("ul"),ip=a("li"),xse=a("strong"),Lpo=o("albert"),xpo=o(" \u2014 "),NI=a("a"),$po=o("AlbertModel"),kpo=o(" (ALBERT model)"),Spo=l(),dp=a("li"),$se=a("strong"),Rpo=o("bart"),Ppo=o(" \u2014 "),jI=a("a"),Bpo=o("BartModel"),Ipo=o(" (BART model)"),qpo=l(),cp=a("li"),kse=a("strong"),Npo=o("beit"),jpo=o(" \u2014 "),DI=a("a"),Dpo=o("BeitModel"),Gpo=o(" (BEiT model)"),Opo=l(),fp=a("li"),Sse=a("strong"),Vpo=o("bert"),Xpo=o(" \u2014 "),GI=a("a"),zpo=o("BertModel"),Wpo=o(" (BERT model)"),Qpo=l(),mp=a("li"),Rse=a("strong"),Hpo=o("bert-generation"),Upo=o(" \u2014 "),OI=a("a"),Jpo=o("BertGenerationEncoder"),Ypo=o(" (Bert Generation model)"),Kpo=l(),gp=a("li"),Pse=a("strong"),Zpo=o("big_bird"),euo=o(" \u2014 "),VI=a("a"),ouo=o("BigBirdModel"),ruo=o(" (BigBird model)"),tuo=l(),hp=a("li"),Bse=a("strong"),auo=o("bigbird_pegasus"),nuo=o(" \u2014 "),XI=a("a"),suo=o("BigBirdPegasusModel"),luo=o(" (BigBirdPegasus model)"),iuo=l(),pp=a("li"),Ise=a("strong"),duo=o("blenderbot"),cuo=o(" \u2014 "),zI=a("a"),fuo=o("BlenderbotModel"),muo=o(" (Blenderbot model)"),guo=l(),up=a("li"),qse=a("strong"),huo=o("blenderbot-small"),puo=o(" \u2014 "),WI=a("a"),uuo=o("BlenderbotSmallModel"),_uo=o(" (BlenderbotSmall model)"),buo=l(),_p=a("li"),Nse=a("strong"),vuo=o("camembert"),Fuo=o(" \u2014 "),QI=a("a"),Tuo=o("CamembertModel"),Muo=o(" (CamemBERT model)"),Euo=l(),bp=a("li"),jse=a("strong"),Cuo=o("canine"),wuo=o(" \u2014 "),HI=a("a"),Auo=o("CanineModel"),yuo=o(" (Canine model)"),Luo=l(),vp=a("li"),Dse=a("strong"),xuo=o("clip"),$uo=o(" \u2014 "),UI=a("a"),kuo=o("CLIPModel"),Suo=o(" (CLIP model)"),Ruo=l(),Fp=a("li"),Gse=a("strong"),Puo=o("convbert"),Buo=o(" \u2014 "),JI=a("a"),Iuo=o("ConvBertModel"),quo=o(" (ConvBERT model)"),Nuo=l(),Tp=a("li"),Ose=a("strong"),juo=o("convnext"),Duo=o(" \u2014 "),YI=a("a"),Guo=o("ConvNextModel"),Ouo=o(" (ConvNext model)"),Vuo=l(),Mp=a("li"),Vse=a("strong"),Xuo=o("ctrl"),zuo=o(" \u2014 "),KI=a("a"),Wuo=o("CTRLModel"),Quo=o(" (CTRL model)"),Huo=l(),Ep=a("li"),Xse=a("strong"),Uuo=o("cvt"),Juo=o(" \u2014 "),ZI=a("a"),Yuo=o("CvtModel"),Kuo=o(" (CvT model)"),Zuo=l(),Cp=a("li"),zse=a("strong"),e_o=o("data2vec-audio"),o_o=o(" \u2014 "),eq=a("a"),r_o=o("Data2VecAudioModel"),t_o=o(" (Data2VecAudio model)"),a_o=l(),wp=a("li"),Wse=a("strong"),n_o=o("data2vec-text"),s_o=o(" \u2014 "),oq=a("a"),l_o=o("Data2VecTextModel"),i_o=o(" (Data2VecText model)"),d_o=l(),Ap=a("li"),Qse=a("strong"),c_o=o("data2vec-vision"),f_o=o(" \u2014 "),rq=a("a"),m_o=o("Data2VecVisionModel"),g_o=o(" (Data2VecVision model)"),h_o=l(),yp=a("li"),Hse=a("strong"),p_o=o("deberta"),u_o=o(" \u2014 "),tq=a("a"),__o=o("DebertaModel"),b_o=o(" (DeBERTa model)"),v_o=l(),Lp=a("li"),Use=a("strong"),F_o=o("deberta-v2"),T_o=o(" \u2014 "),aq=a("a"),M_o=o("DebertaV2Model"),E_o=o(" (DeBERTa-v2 model)"),C_o=l(),xp=a("li"),Jse=a("strong"),w_o=o("decision_transformer"),A_o=o(" \u2014 "),nq=a("a"),y_o=o("DecisionTransformerModel"),L_o=o(" (Decision Transformer model)"),x_o=l(),$p=a("li"),Yse=a("strong"),$_o=o("deit"),k_o=o(" \u2014 "),sq=a("a"),S_o=o("DeiTModel"),R_o=o(" (DeiT model)"),P_o=l(),kp=a("li"),Kse=a("strong"),B_o=o("detr"),I_o=o(" \u2014 "),lq=a("a"),q_o=o("DetrModel"),N_o=o(" (DETR model)"),j_o=l(),Sp=a("li"),Zse=a("strong"),D_o=o("distilbert"),G_o=o(" \u2014 "),iq=a("a"),O_o=o("DistilBertModel"),V_o=o(" (DistilBERT model)"),X_o=l(),Rp=a("li"),ele=a("strong"),z_o=o("dpr"),W_o=o(" \u2014 "),dq=a("a"),Q_o=o("DPRQuestionEncoder"),H_o=o(" (DPR model)"),U_o=l(),Pp=a("li"),ole=a("strong"),J_o=o("dpt"),Y_o=o(" \u2014 "),cq=a("a"),K_o=o("DPTModel"),Z_o=o(" (DPT model)"),e2o=l(),Bp=a("li"),rle=a("strong"),o2o=o("electra"),r2o=o(" \u2014 "),fq=a("a"),t2o=o("ElectraModel"),a2o=o(" (ELECTRA model)"),n2o=l(),Ip=a("li"),tle=a("strong"),s2o=o("flaubert"),l2o=o(" \u2014 "),mq=a("a"),i2o=o("FlaubertModel"),d2o=o(" (FlauBERT model)"),c2o=l(),qp=a("li"),ale=a("strong"),f2o=o("flava"),m2o=o(" \u2014 "),gq=a("a"),g2o=o("FlavaModel"),h2o=o(" (Flava model)"),p2o=l(),Np=a("li"),nle=a("strong"),u2o=o("fnet"),_2o=o(" \u2014 "),hq=a("a"),b2o=o("FNetModel"),v2o=o(" (FNet model)"),F2o=l(),jp=a("li"),sle=a("strong"),T2o=o("fsmt"),M2o=o(" \u2014 "),pq=a("a"),E2o=o("FSMTModel"),C2o=o(" (FairSeq Machine-Translation model)"),w2o=l(),qs=a("li"),lle=a("strong"),A2o=o("funnel"),y2o=o(" \u2014 "),uq=a("a"),L2o=o("FunnelModel"),x2o=o(" or "),_q=a("a"),$2o=o("FunnelBaseModel"),k2o=o(" (Funnel Transformer model)"),S2o=l(),Dp=a("li"),ile=a("strong"),R2o=o("glpn"),P2o=o(" \u2014 "),bq=a("a"),B2o=o("GLPNModel"),I2o=o(" (GLPN model)"),q2o=l(),Gp=a("li"),dle=a("strong"),N2o=o("gpt2"),j2o=o(" \u2014 "),vq=a("a"),D2o=o("GPT2Model"),G2o=o(" (OpenAI GPT-2 model)"),O2o=l(),Op=a("li"),cle=a("strong"),V2o=o("gpt_neo"),X2o=o(" \u2014 "),Fq=a("a"),z2o=o("GPTNeoModel"),W2o=o(" (GPT Neo model)"),Q2o=l(),Vp=a("li"),fle=a("strong"),H2o=o("gpt_neox"),U2o=o(" \u2014 "),Tq=a("a"),J2o=o("GPTNeoXModel"),Y2o=o(" (GPT NeoX model)"),K2o=l(),Xp=a("li"),mle=a("strong"),Z2o=o("gptj"),e1o=o(" \u2014 "),Mq=a("a"),o1o=o("GPTJModel"),r1o=o(" (GPT-J model)"),t1o=l(),zp=a("li"),gle=a("strong"),a1o=o("hubert"),n1o=o(" \u2014 "),Eq=a("a"),s1o=o("HubertModel"),l1o=o(" (Hubert model)"),i1o=l(),Wp=a("li"),hle=a("strong"),d1o=o("ibert"),c1o=o(" \u2014 "),Cq=a("a"),f1o=o("IBertModel"),m1o=o(" (I-BERT model)"),g1o=l(),Qp=a("li"),ple=a("strong"),h1o=o("imagegpt"),p1o=o(" \u2014 "),wq=a("a"),u1o=o("ImageGPTModel"),_1o=o(" (ImageGPT model)"),b1o=l(),Hp=a("li"),ule=a("strong"),v1o=o("layoutlm"),F1o=o(" \u2014 "),Aq=a("a"),T1o=o("LayoutLMModel"),M1o=o(" (LayoutLM model)"),E1o=l(),Up=a("li"),_le=a("strong"),C1o=o("layoutlmv2"),w1o=o(" \u2014 "),yq=a("a"),A1o=o("LayoutLMv2Model"),y1o=o(" (LayoutLMv2 model)"),L1o=l(),Jp=a("li"),ble=a("strong"),x1o=o("layoutlmv3"),$1o=o(" \u2014 "),Lq=a("a"),k1o=o("LayoutLMv3Model"),S1o=o(" (LayoutLMv3 model)"),R1o=l(),Yp=a("li"),vle=a("strong"),P1o=o("led"),B1o=o(" \u2014 "),xq=a("a"),I1o=o("LEDModel"),q1o=o(" (LED model)"),N1o=l(),Kp=a("li"),Fle=a("strong"),j1o=o("longformer"),D1o=o(" \u2014 "),$q=a("a"),G1o=o("LongformerModel"),O1o=o(" (Longformer model)"),V1o=l(),Zp=a("li"),Tle=a("strong"),X1o=o("luke"),z1o=o(" \u2014 "),kq=a("a"),W1o=o("LukeModel"),Q1o=o(" (LUKE model)"),H1o=l(),eu=a("li"),Mle=a("strong"),U1o=o("lxmert"),J1o=o(" \u2014 "),Sq=a("a"),Y1o=o("LxmertModel"),K1o=o(" (LXMERT model)"),Z1o=l(),ou=a("li"),Ele=a("strong"),ebo=o("m2m_100"),obo=o(" \u2014 "),Rq=a("a"),rbo=o("M2M100Model"),tbo=o(" (M2M100 model)"),abo=l(),ru=a("li"),Cle=a("strong"),nbo=o("marian"),sbo=o(" \u2014 "),Pq=a("a"),lbo=o("MarianModel"),ibo=o(" (Marian model)"),dbo=l(),tu=a("li"),wle=a("strong"),cbo=o("maskformer"),fbo=o(" \u2014 "),Bq=a("a"),mbo=o("MaskFormerModel"),gbo=o(" (MaskFormer model)"),hbo=l(),au=a("li"),Ale=a("strong"),pbo=o("mbart"),ubo=o(" \u2014 "),Iq=a("a"),_bo=o("MBartModel"),bbo=o(" (mBART model)"),vbo=l(),nu=a("li"),yle=a("strong"),Fbo=o("megatron-bert"),Tbo=o(" \u2014 "),qq=a("a"),Mbo=o("MegatronBertModel"),Ebo=o(" (MegatronBert model)"),Cbo=l(),su=a("li"),Lle=a("strong"),wbo=o("mobilebert"),Abo=o(" \u2014 "),Nq=a("a"),ybo=o("MobileBertModel"),Lbo=o(" (MobileBERT model)"),xbo=l(),lu=a("li"),xle=a("strong"),$bo=o("mpnet"),kbo=o(" \u2014 "),jq=a("a"),Sbo=o("MPNetModel"),Rbo=o(" (MPNet model)"),Pbo=l(),iu=a("li"),$le=a("strong"),Bbo=o("mt5"),Ibo=o(" \u2014 "),Dq=a("a"),qbo=o("MT5Model"),Nbo=o(" (mT5 model)"),jbo=l(),du=a("li"),kle=a("strong"),Dbo=o("nystromformer"),Gbo=o(" \u2014 "),Gq=a("a"),Obo=o("NystromformerModel"),Vbo=o(" (Nystromformer model)"),Xbo=l(),cu=a("li"),Sle=a("strong"),zbo=o("openai-gpt"),Wbo=o(" \u2014 "),Oq=a("a"),Qbo=o("OpenAIGPTModel"),Hbo=o(" (OpenAI GPT model)"),Ubo=l(),fu=a("li"),Rle=a("strong"),Jbo=o("opt"),Ybo=o(" \u2014 "),Vq=a("a"),Kbo=o("OPTModel"),Zbo=o(" (OPT model)"),e4o=l(),mu=a("li"),Ple=a("strong"),o4o=o("pegasus"),r4o=o(" \u2014 "),Xq=a("a"),t4o=o("PegasusModel"),a4o=o(" (Pegasus model)"),n4o=l(),gu=a("li"),Ble=a("strong"),s4o=o("perceiver"),l4o=o(" \u2014 "),zq=a("a"),i4o=o("PerceiverModel"),d4o=o(" (Perceiver model)"),c4o=l(),hu=a("li"),Ile=a("strong"),f4o=o("plbart"),m4o=o(" \u2014 "),Wq=a("a"),g4o=o("PLBartModel"),h4o=o(" (PLBart model)"),p4o=l(),pu=a("li"),qle=a("strong"),u4o=o("poolformer"),_4o=o(" \u2014 "),Qq=a("a"),b4o=o("PoolFormerModel"),v4o=o(" (PoolFormer model)"),F4o=l(),uu=a("li"),Nle=a("strong"),T4o=o("prophetnet"),M4o=o(" \u2014 "),Hq=a("a"),E4o=o("ProphetNetModel"),C4o=o(" (ProphetNet model)"),w4o=l(),_u=a("li"),jle=a("strong"),A4o=o("qdqbert"),y4o=o(" \u2014 "),Uq=a("a"),L4o=o("QDQBertModel"),x4o=o(" (QDQBert model)"),$4o=l(),bu=a("li"),Dle=a("strong"),k4o=o("reformer"),S4o=o(" \u2014 "),Jq=a("a"),R4o=o("ReformerModel"),P4o=o(" (Reformer model)"),B4o=l(),vu=a("li"),Gle=a("strong"),I4o=o("regnet"),q4o=o(" \u2014 "),Yq=a("a"),N4o=o("RegNetModel"),j4o=o(" (RegNet model)"),D4o=l(),Fu=a("li"),Ole=a("strong"),G4o=o("rembert"),O4o=o(" \u2014 "),Kq=a("a"),V4o=o("RemBertModel"),X4o=o(" (RemBERT model)"),z4o=l(),Tu=a("li"),Vle=a("strong"),W4o=o("resnet"),Q4o=o(" \u2014 "),Zq=a("a"),H4o=o("ResNetModel"),U4o=o(" (ResNet model)"),J4o=l(),Mu=a("li"),Xle=a("strong"),Y4o=o("retribert"),K4o=o(" \u2014 "),eN=a("a"),Z4o=o("RetriBertModel"),evo=o(" (RetriBERT model)"),ovo=l(),Eu=a("li"),zle=a("strong"),rvo=o("roberta"),tvo=o(" \u2014 "),oN=a("a"),avo=o("RobertaModel"),nvo=o(" (RoBERTa model)"),svo=l(),Cu=a("li"),Wle=a("strong"),lvo=o("roformer"),ivo=o(" \u2014 "),rN=a("a"),dvo=o("RoFormerModel"),cvo=o(" (RoFormer model)"),fvo=l(),wu=a("li"),Qle=a("strong"),mvo=o("segformer"),gvo=o(" \u2014 "),tN=a("a"),hvo=o("SegformerModel"),pvo=o(" (SegFormer model)"),uvo=l(),Au=a("li"),Hle=a("strong"),_vo=o("sew"),bvo=o(" \u2014 "),aN=a("a"),vvo=o("SEWModel"),Fvo=o(" (SEW model)"),Tvo=l(),yu=a("li"),Ule=a("strong"),Mvo=o("sew-d"),Evo=o(" \u2014 "),nN=a("a"),Cvo=o("SEWDModel"),wvo=o(" (SEW-D model)"),Avo=l(),Lu=a("li"),Jle=a("strong"),yvo=o("speech_to_text"),Lvo=o(" \u2014 "),sN=a("a"),xvo=o("Speech2TextModel"),$vo=o(" (Speech2Text model)"),kvo=l(),xu=a("li"),Yle=a("strong"),Svo=o("splinter"),Rvo=o(" \u2014 "),lN=a("a"),Pvo=o("SplinterModel"),Bvo=o(" (Splinter model)"),Ivo=l(),$u=a("li"),Kle=a("strong"),qvo=o("squeezebert"),Nvo=o(" \u2014 "),iN=a("a"),jvo=o("SqueezeBertModel"),Dvo=o(" (SqueezeBERT model)"),Gvo=l(),ku=a("li"),Zle=a("strong"),Ovo=o("swin"),Vvo=o(" \u2014 "),dN=a("a"),Xvo=o("SwinModel"),zvo=o(" (Swin model)"),Wvo=l(),Su=a("li"),eie=a("strong"),Qvo=o("t5"),Hvo=o(" \u2014 "),cN=a("a"),Uvo=o("T5Model"),Jvo=o(" (T5 model)"),Yvo=l(),Ru=a("li"),oie=a("strong"),Kvo=o("tapas"),Zvo=o(" \u2014 "),fN=a("a"),e5o=o("TapasModel"),o5o=o(" (TAPAS model)"),r5o=l(),Pu=a("li"),rie=a("strong"),t5o=o("trajectory_transformer"),a5o=o(" \u2014 "),mN=a("a"),n5o=o("TrajectoryTransformerModel"),s5o=o(" (Trajectory Transformer model)"),l5o=l(),Bu=a("li"),tie=a("strong"),i5o=o("transfo-xl"),d5o=o(" \u2014 "),gN=a("a"),c5o=o("TransfoXLModel"),f5o=o(" (Transformer-XL model)"),m5o=l(),Iu=a("li"),aie=a("strong"),g5o=o("unispeech"),h5o=o(" \u2014 "),hN=a("a"),p5o=o("UniSpeechModel"),u5o=o(" (UniSpeech model)"),_5o=l(),qu=a("li"),nie=a("strong"),b5o=o("unispeech-sat"),v5o=o(" \u2014 "),pN=a("a"),F5o=o("UniSpeechSatModel"),T5o=o(" (UniSpeechSat model)"),M5o=l(),Nu=a("li"),sie=a("strong"),E5o=o("van"),C5o=o(" \u2014 "),uN=a("a"),w5o=o("VanModel"),A5o=o(" (VAN model)"),y5o=l(),ju=a("li"),lie=a("strong"),L5o=o("vilt"),x5o=o(" \u2014 "),_N=a("a"),$5o=o("ViltModel"),k5o=o(" (ViLT model)"),S5o=l(),Du=a("li"),iie=a("strong"),R5o=o("vision-text-dual-encoder"),P5o=o(" \u2014 "),bN=a("a"),B5o=o("VisionTextDualEncoderModel"),I5o=o(" (VisionTextDualEncoder model)"),q5o=l(),Gu=a("li"),die=a("strong"),N5o=o("visual_bert"),j5o=o(" \u2014 "),vN=a("a"),D5o=o("VisualBertModel"),G5o=o(" (VisualBert model)"),O5o=l(),Ou=a("li"),cie=a("strong"),V5o=o("vit"),X5o=o(" \u2014 "),FN=a("a"),z5o=o("ViTModel"),W5o=o(" (ViT model)"),Q5o=l(),Vu=a("li"),fie=a("strong"),H5o=o("vit_mae"),U5o=o(" \u2014 "),TN=a("a"),J5o=o("ViTMAEModel"),Y5o=o(" (ViTMAE model)"),K5o=l(),Xu=a("li"),mie=a("strong"),Z5o=o("wav2vec2"),eFo=o(" \u2014 "),MN=a("a"),oFo=o("Wav2Vec2Model"),rFo=o(" (Wav2Vec2 model)"),tFo=l(),zu=a("li"),gie=a("strong"),aFo=o("wav2vec2-conformer"),nFo=o(" \u2014 "),EN=a("a"),sFo=o("Wav2Vec2ConformerModel"),lFo=o(" (Wav2Vec2-Conformer model)"),iFo=l(),Wu=a("li"),hie=a("strong"),dFo=o("wavlm"),cFo=o(" \u2014 "),CN=a("a"),fFo=o("WavLMModel"),mFo=o(" (WavLM model)"),gFo=l(),Qu=a("li"),pie=a("strong"),hFo=o("xglm"),pFo=o(" \u2014 "),wN=a("a"),uFo=o("XGLMModel"),_Fo=o(" (XGLM model)"),bFo=l(),Hu=a("li"),uie=a("strong"),vFo=o("xlm"),FFo=o(" \u2014 "),AN=a("a"),TFo=o("XLMModel"),MFo=o(" (XLM model)"),EFo=l(),Uu=a("li"),_ie=a("strong"),CFo=o("xlm-prophetnet"),wFo=o(" \u2014 "),yN=a("a"),AFo=o("XLMProphetNetModel"),yFo=o(" (XLMProphetNet model)"),LFo=l(),Ju=a("li"),bie=a("strong"),xFo=o("xlm-roberta"),$Fo=o(" \u2014 "),LN=a("a"),kFo=o("XLMRobertaModel"),SFo=o(" (XLM-RoBERTa model)"),RFo=l(),Yu=a("li"),vie=a("strong"),PFo=o("xlm-roberta-xl"),BFo=o(" \u2014 "),xN=a("a"),IFo=o("XLMRobertaXLModel"),qFo=o(" (XLM-RoBERTa-XL model)"),NFo=l(),Ku=a("li"),Fie=a("strong"),jFo=o("xlnet"),DFo=o(" \u2014 "),$N=a("a"),GFo=o("XLNetModel"),OFo=o(" (XLNet model)"),VFo=l(),Zu=a("li"),Tie=a("strong"),XFo=o("yolos"),zFo=o(" \u2014 "),kN=a("a"),WFo=o("YolosModel"),QFo=o(" (YOLOS model)"),HFo=l(),e_=a("li"),Mie=a("strong"),UFo=o("yoso"),JFo=o(" \u2014 "),SN=a("a"),YFo=o("YosoModel"),KFo=o(" (YOSO model)"),ZFo=l(),o_=a("p"),eTo=o("The model is set in evaluation mode by default using "),Eie=a("code"),oTo=o("model.eval()"),rTo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cie=a("code"),tTo=o("model.train()"),aTo=l(),F(r_.$$.fragment),uNe=l(),ki=a("h2"),t_=a("a"),wie=a("span"),F(ay.$$.fragment),nTo=l(),Aie=a("span"),sTo=o("AutoModelForPreTraining"),_Ne=l(),xo=a("div"),F(ny.$$.fragment),lTo=l(),Si=a("p"),iTo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),RN=a("a"),dTo=o("from_pretrained()"),cTo=o(" class method or the "),PN=a("a"),fTo=o("from_config()"),mTo=o(` class
method.`),gTo=l(),sy=a("p"),hTo=o("This class cannot be instantiated directly using "),yie=a("code"),pTo=o("__init__()"),uTo=o(" (throws an error)."),_To=l(),at=a("div"),F(ly.$$.fragment),bTo=l(),Lie=a("p"),vTo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),FTo=l(),Ri=a("p"),TTo=o(`Note:
Loading a model from its configuration file does `),xie=a("strong"),MTo=o("not"),ETo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BN=a("a"),CTo=o("from_pretrained()"),wTo=o(" to load the model weights."),ATo=l(),F(a_.$$.fragment),yTo=l(),Ye=a("div"),F(iy.$$.fragment),LTo=l(),$ie=a("p"),xTo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),$To=l(),xa=a("p"),kTo=o("The model class to instantiate is selected based on the "),kie=a("code"),STo=o("model_type"),RTo=o(` property of the config object (either
passed as an argument or loaded from `),Sie=a("code"),PTo=o("pretrained_model_name_or_path"),BTo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rie=a("code"),ITo=o("pretrained_model_name_or_path"),qTo=o(":"),NTo=l(),G=a("ul"),n_=a("li"),Pie=a("strong"),jTo=o("albert"),DTo=o(" \u2014 "),IN=a("a"),GTo=o("AlbertForPreTraining"),OTo=o(" (ALBERT model)"),VTo=l(),s_=a("li"),Bie=a("strong"),XTo=o("bart"),zTo=o(" \u2014 "),qN=a("a"),WTo=o("BartForConditionalGeneration"),QTo=o(" (BART model)"),HTo=l(),l_=a("li"),Iie=a("strong"),UTo=o("bert"),JTo=o(" \u2014 "),NN=a("a"),YTo=o("BertForPreTraining"),KTo=o(" (BERT model)"),ZTo=l(),i_=a("li"),qie=a("strong"),e7o=o("big_bird"),o7o=o(" \u2014 "),jN=a("a"),r7o=o("BigBirdForPreTraining"),t7o=o(" (BigBird model)"),a7o=l(),d_=a("li"),Nie=a("strong"),n7o=o("camembert"),s7o=o(" \u2014 "),DN=a("a"),l7o=o("CamembertForMaskedLM"),i7o=o(" (CamemBERT model)"),d7o=l(),c_=a("li"),jie=a("strong"),c7o=o("ctrl"),f7o=o(" \u2014 "),GN=a("a"),m7o=o("CTRLLMHeadModel"),g7o=o(" (CTRL model)"),h7o=l(),f_=a("li"),Die=a("strong"),p7o=o("data2vec-text"),u7o=o(" \u2014 "),ON=a("a"),_7o=o("Data2VecTextForMaskedLM"),b7o=o(" (Data2VecText model)"),v7o=l(),m_=a("li"),Gie=a("strong"),F7o=o("deberta"),T7o=o(" \u2014 "),VN=a("a"),M7o=o("DebertaForMaskedLM"),E7o=o(" (DeBERTa model)"),C7o=l(),g_=a("li"),Oie=a("strong"),w7o=o("deberta-v2"),A7o=o(" \u2014 "),XN=a("a"),y7o=o("DebertaV2ForMaskedLM"),L7o=o(" (DeBERTa-v2 model)"),x7o=l(),h_=a("li"),Vie=a("strong"),$7o=o("distilbert"),k7o=o(" \u2014 "),zN=a("a"),S7o=o("DistilBertForMaskedLM"),R7o=o(" (DistilBERT model)"),P7o=l(),p_=a("li"),Xie=a("strong"),B7o=o("electra"),I7o=o(" \u2014 "),WN=a("a"),q7o=o("ElectraForPreTraining"),N7o=o(" (ELECTRA model)"),j7o=l(),u_=a("li"),zie=a("strong"),D7o=o("flaubert"),G7o=o(" \u2014 "),QN=a("a"),O7o=o("FlaubertWithLMHeadModel"),V7o=o(" (FlauBERT model)"),X7o=l(),__=a("li"),Wie=a("strong"),z7o=o("flava"),W7o=o(" \u2014 "),HN=a("a"),Q7o=o("FlavaForPreTraining"),H7o=o(" (Flava model)"),U7o=l(),b_=a("li"),Qie=a("strong"),J7o=o("fnet"),Y7o=o(" \u2014 "),UN=a("a"),K7o=o("FNetForPreTraining"),Z7o=o(" (FNet model)"),eMo=l(),v_=a("li"),Hie=a("strong"),oMo=o("fsmt"),rMo=o(" \u2014 "),JN=a("a"),tMo=o("FSMTForConditionalGeneration"),aMo=o(" (FairSeq Machine-Translation model)"),nMo=l(),F_=a("li"),Uie=a("strong"),sMo=o("funnel"),lMo=o(" \u2014 "),YN=a("a"),iMo=o("FunnelForPreTraining"),dMo=o(" (Funnel Transformer model)"),cMo=l(),T_=a("li"),Jie=a("strong"),fMo=o("gpt2"),mMo=o(" \u2014 "),KN=a("a"),gMo=o("GPT2LMHeadModel"),hMo=o(" (OpenAI GPT-2 model)"),pMo=l(),M_=a("li"),Yie=a("strong"),uMo=o("ibert"),_Mo=o(" \u2014 "),ZN=a("a"),bMo=o("IBertForMaskedLM"),vMo=o(" (I-BERT model)"),FMo=l(),E_=a("li"),Kie=a("strong"),TMo=o("layoutlm"),MMo=o(" \u2014 "),ej=a("a"),EMo=o("LayoutLMForMaskedLM"),CMo=o(" (LayoutLM model)"),wMo=l(),C_=a("li"),Zie=a("strong"),AMo=o("longformer"),yMo=o(" \u2014 "),oj=a("a"),LMo=o("LongformerForMaskedLM"),xMo=o(" (Longformer model)"),$Mo=l(),w_=a("li"),ede=a("strong"),kMo=o("lxmert"),SMo=o(" \u2014 "),rj=a("a"),RMo=o("LxmertForPreTraining"),PMo=o(" (LXMERT model)"),BMo=l(),A_=a("li"),ode=a("strong"),IMo=o("megatron-bert"),qMo=o(" \u2014 "),tj=a("a"),NMo=o("MegatronBertForPreTraining"),jMo=o(" (MegatronBert model)"),DMo=l(),y_=a("li"),rde=a("strong"),GMo=o("mobilebert"),OMo=o(" \u2014 "),aj=a("a"),VMo=o("MobileBertForPreTraining"),XMo=o(" (MobileBERT model)"),zMo=l(),L_=a("li"),tde=a("strong"),WMo=o("mpnet"),QMo=o(" \u2014 "),nj=a("a"),HMo=o("MPNetForMaskedLM"),UMo=o(" (MPNet model)"),JMo=l(),x_=a("li"),ade=a("strong"),YMo=o("openai-gpt"),KMo=o(" \u2014 "),sj=a("a"),ZMo=o("OpenAIGPTLMHeadModel"),eEo=o(" (OpenAI GPT model)"),oEo=l(),$_=a("li"),nde=a("strong"),rEo=o("retribert"),tEo=o(" \u2014 "),lj=a("a"),aEo=o("RetriBertModel"),nEo=o(" (RetriBERT model)"),sEo=l(),k_=a("li"),sde=a("strong"),lEo=o("roberta"),iEo=o(" \u2014 "),ij=a("a"),dEo=o("RobertaForMaskedLM"),cEo=o(" (RoBERTa model)"),fEo=l(),S_=a("li"),lde=a("strong"),mEo=o("splinter"),gEo=o(" \u2014 "),dj=a("a"),hEo=o("SplinterForPreTraining"),pEo=o(" (Splinter model)"),uEo=l(),R_=a("li"),ide=a("strong"),_Eo=o("squeezebert"),bEo=o(" \u2014 "),cj=a("a"),vEo=o("SqueezeBertForMaskedLM"),FEo=o(" (SqueezeBERT model)"),TEo=l(),P_=a("li"),dde=a("strong"),MEo=o("t5"),EEo=o(" \u2014 "),fj=a("a"),CEo=o("T5ForConditionalGeneration"),wEo=o(" (T5 model)"),AEo=l(),B_=a("li"),cde=a("strong"),yEo=o("tapas"),LEo=o(" \u2014 "),mj=a("a"),xEo=o("TapasForMaskedLM"),$Eo=o(" (TAPAS model)"),kEo=l(),I_=a("li"),fde=a("strong"),SEo=o("transfo-xl"),REo=o(" \u2014 "),gj=a("a"),PEo=o("TransfoXLLMHeadModel"),BEo=o(" (Transformer-XL model)"),IEo=l(),q_=a("li"),mde=a("strong"),qEo=o("unispeech"),NEo=o(" \u2014 "),hj=a("a"),jEo=o("UniSpeechForPreTraining"),DEo=o(" (UniSpeech model)"),GEo=l(),N_=a("li"),gde=a("strong"),OEo=o("unispeech-sat"),VEo=o(" \u2014 "),pj=a("a"),XEo=o("UniSpeechSatForPreTraining"),zEo=o(" (UniSpeechSat model)"),WEo=l(),j_=a("li"),hde=a("strong"),QEo=o("visual_bert"),HEo=o(" \u2014 "),uj=a("a"),UEo=o("VisualBertForPreTraining"),JEo=o(" (VisualBert model)"),YEo=l(),D_=a("li"),pde=a("strong"),KEo=o("vit_mae"),ZEo=o(" \u2014 "),_j=a("a"),eCo=o("ViTMAEForPreTraining"),oCo=o(" (ViTMAE model)"),rCo=l(),G_=a("li"),ude=a("strong"),tCo=o("wav2vec2"),aCo=o(" \u2014 "),bj=a("a"),nCo=o("Wav2Vec2ForPreTraining"),sCo=o(" (Wav2Vec2 model)"),lCo=l(),O_=a("li"),_de=a("strong"),iCo=o("wav2vec2-conformer"),dCo=o(" \u2014 "),vj=a("a"),cCo=o("Wav2Vec2ConformerForPreTraining"),fCo=o(" (Wav2Vec2-Conformer model)"),mCo=l(),V_=a("li"),bde=a("strong"),gCo=o("xlm"),hCo=o(" \u2014 "),Fj=a("a"),pCo=o("XLMWithLMHeadModel"),uCo=o(" (XLM model)"),_Co=l(),X_=a("li"),vde=a("strong"),bCo=o("xlm-roberta"),vCo=o(" \u2014 "),Tj=a("a"),FCo=o("XLMRobertaForMaskedLM"),TCo=o(" (XLM-RoBERTa model)"),MCo=l(),z_=a("li"),Fde=a("strong"),ECo=o("xlm-roberta-xl"),CCo=o(" \u2014 "),Mj=a("a"),wCo=o("XLMRobertaXLForMaskedLM"),ACo=o(" (XLM-RoBERTa-XL model)"),yCo=l(),W_=a("li"),Tde=a("strong"),LCo=o("xlnet"),xCo=o(" \u2014 "),Ej=a("a"),$Co=o("XLNetLMHeadModel"),kCo=o(" (XLNet model)"),SCo=l(),Q_=a("p"),RCo=o("The model is set in evaluation mode by default using "),Mde=a("code"),PCo=o("model.eval()"),BCo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ede=a("code"),ICo=o("model.train()"),qCo=l(),F(H_.$$.fragment),bNe=l(),Pi=a("h2"),U_=a("a"),Cde=a("span"),F(dy.$$.fragment),NCo=l(),wde=a("span"),jCo=o("AutoModelForCausalLM"),vNe=l(),$o=a("div"),F(cy.$$.fragment),DCo=l(),Bi=a("p"),GCo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Cj=a("a"),OCo=o("from_pretrained()"),VCo=o(" class method or the "),wj=a("a"),XCo=o("from_config()"),zCo=o(` class
method.`),WCo=l(),fy=a("p"),QCo=o("This class cannot be instantiated directly using "),Ade=a("code"),HCo=o("__init__()"),UCo=o(" (throws an error)."),JCo=l(),nt=a("div"),F(my.$$.fragment),YCo=l(),yde=a("p"),KCo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ZCo=l(),Ii=a("p"),e3o=o(`Note:
Loading a model from its configuration file does `),Lde=a("strong"),o3o=o("not"),r3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aj=a("a"),t3o=o("from_pretrained()"),a3o=o(" to load the model weights."),n3o=l(),F(J_.$$.fragment),s3o=l(),Ke=a("div"),F(gy.$$.fragment),l3o=l(),xde=a("p"),i3o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),d3o=l(),$a=a("p"),c3o=o("The model class to instantiate is selected based on the "),$de=a("code"),f3o=o("model_type"),m3o=o(` property of the config object (either
passed as an argument or loaded from `),kde=a("code"),g3o=o("pretrained_model_name_or_path"),h3o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sde=a("code"),p3o=o("pretrained_model_name_or_path"),u3o=o(":"),_3o=l(),z=a("ul"),Y_=a("li"),Rde=a("strong"),b3o=o("bart"),v3o=o(" \u2014 "),yj=a("a"),F3o=o("BartForCausalLM"),T3o=o(" (BART model)"),M3o=l(),K_=a("li"),Pde=a("strong"),E3o=o("bert"),C3o=o(" \u2014 "),Lj=a("a"),w3o=o("BertLMHeadModel"),A3o=o(" (BERT model)"),y3o=l(),Z_=a("li"),Bde=a("strong"),L3o=o("bert-generation"),x3o=o(" \u2014 "),xj=a("a"),$3o=o("BertGenerationDecoder"),k3o=o(" (Bert Generation model)"),S3o=l(),e2=a("li"),Ide=a("strong"),R3o=o("big_bird"),P3o=o(" \u2014 "),$j=a("a"),B3o=o("BigBirdForCausalLM"),I3o=o(" (BigBird model)"),q3o=l(),o2=a("li"),qde=a("strong"),N3o=o("bigbird_pegasus"),j3o=o(" \u2014 "),kj=a("a"),D3o=o("BigBirdPegasusForCausalLM"),G3o=o(" (BigBirdPegasus model)"),O3o=l(),r2=a("li"),Nde=a("strong"),V3o=o("blenderbot"),X3o=o(" \u2014 "),Sj=a("a"),z3o=o("BlenderbotForCausalLM"),W3o=o(" (Blenderbot model)"),Q3o=l(),t2=a("li"),jde=a("strong"),H3o=o("blenderbot-small"),U3o=o(" \u2014 "),Rj=a("a"),J3o=o("BlenderbotSmallForCausalLM"),Y3o=o(" (BlenderbotSmall model)"),K3o=l(),a2=a("li"),Dde=a("strong"),Z3o=o("camembert"),ewo=o(" \u2014 "),Pj=a("a"),owo=o("CamembertForCausalLM"),rwo=o(" (CamemBERT model)"),two=l(),n2=a("li"),Gde=a("strong"),awo=o("ctrl"),nwo=o(" \u2014 "),Bj=a("a"),swo=o("CTRLLMHeadModel"),lwo=o(" (CTRL model)"),iwo=l(),s2=a("li"),Ode=a("strong"),dwo=o("data2vec-text"),cwo=o(" \u2014 "),Ij=a("a"),fwo=o("Data2VecTextForCausalLM"),mwo=o(" (Data2VecText model)"),gwo=l(),l2=a("li"),Vde=a("strong"),hwo=o("electra"),pwo=o(" \u2014 "),qj=a("a"),uwo=o("ElectraForCausalLM"),_wo=o(" (ELECTRA model)"),bwo=l(),i2=a("li"),Xde=a("strong"),vwo=o("gpt2"),Fwo=o(" \u2014 "),Nj=a("a"),Two=o("GPT2LMHeadModel"),Mwo=o(" (OpenAI GPT-2 model)"),Ewo=l(),d2=a("li"),zde=a("strong"),Cwo=o("gpt_neo"),wwo=o(" \u2014 "),jj=a("a"),Awo=o("GPTNeoForCausalLM"),ywo=o(" (GPT Neo model)"),Lwo=l(),c2=a("li"),Wde=a("strong"),xwo=o("gpt_neox"),$wo=o(" \u2014 "),Dj=a("a"),kwo=o("GPTNeoXForCausalLM"),Swo=o(" (GPT NeoX model)"),Rwo=l(),f2=a("li"),Qde=a("strong"),Pwo=o("gptj"),Bwo=o(" \u2014 "),Gj=a("a"),Iwo=o("GPTJForCausalLM"),qwo=o(" (GPT-J model)"),Nwo=l(),m2=a("li"),Hde=a("strong"),jwo=o("marian"),Dwo=o(" \u2014 "),Oj=a("a"),Gwo=o("MarianForCausalLM"),Owo=o(" (Marian model)"),Vwo=l(),g2=a("li"),Ude=a("strong"),Xwo=o("mbart"),zwo=o(" \u2014 "),Vj=a("a"),Wwo=o("MBartForCausalLM"),Qwo=o(" (mBART model)"),Hwo=l(),h2=a("li"),Jde=a("strong"),Uwo=o("megatron-bert"),Jwo=o(" \u2014 "),Xj=a("a"),Ywo=o("MegatronBertForCausalLM"),Kwo=o(" (MegatronBert model)"),Zwo=l(),p2=a("li"),Yde=a("strong"),e0o=o("openai-gpt"),o0o=o(" \u2014 "),zj=a("a"),r0o=o("OpenAIGPTLMHeadModel"),t0o=o(" (OpenAI GPT model)"),a0o=l(),u2=a("li"),Kde=a("strong"),n0o=o("opt"),s0o=o(" \u2014 "),Wj=a("a"),l0o=o("OPTForCausalLM"),i0o=o(" (OPT model)"),d0o=l(),_2=a("li"),Zde=a("strong"),c0o=o("pegasus"),f0o=o(" \u2014 "),Qj=a("a"),m0o=o("PegasusForCausalLM"),g0o=o(" (Pegasus model)"),h0o=l(),b2=a("li"),ece=a("strong"),p0o=o("plbart"),u0o=o(" \u2014 "),Hj=a("a"),_0o=o("PLBartForCausalLM"),b0o=o(" (PLBart model)"),v0o=l(),v2=a("li"),oce=a("strong"),F0o=o("prophetnet"),T0o=o(" \u2014 "),Uj=a("a"),M0o=o("ProphetNetForCausalLM"),E0o=o(" (ProphetNet model)"),C0o=l(),F2=a("li"),rce=a("strong"),w0o=o("qdqbert"),A0o=o(" \u2014 "),Jj=a("a"),y0o=o("QDQBertLMHeadModel"),L0o=o(" (QDQBert model)"),x0o=l(),T2=a("li"),tce=a("strong"),$0o=o("reformer"),k0o=o(" \u2014 "),Yj=a("a"),S0o=o("ReformerModelWithLMHead"),R0o=o(" (Reformer model)"),P0o=l(),M2=a("li"),ace=a("strong"),B0o=o("rembert"),I0o=o(" \u2014 "),Kj=a("a"),q0o=o("RemBertForCausalLM"),N0o=o(" (RemBERT model)"),j0o=l(),E2=a("li"),nce=a("strong"),D0o=o("roberta"),G0o=o(" \u2014 "),Zj=a("a"),O0o=o("RobertaForCausalLM"),V0o=o(" (RoBERTa model)"),X0o=l(),C2=a("li"),sce=a("strong"),z0o=o("roformer"),W0o=o(" \u2014 "),eD=a("a"),Q0o=o("RoFormerForCausalLM"),H0o=o(" (RoFormer model)"),U0o=l(),w2=a("li"),lce=a("strong"),J0o=o("speech_to_text_2"),Y0o=o(" \u2014 "),oD=a("a"),K0o=o("Speech2Text2ForCausalLM"),Z0o=o(" (Speech2Text2 model)"),e6o=l(),A2=a("li"),ice=a("strong"),o6o=o("transfo-xl"),r6o=o(" \u2014 "),rD=a("a"),t6o=o("TransfoXLLMHeadModel"),a6o=o(" (Transformer-XL model)"),n6o=l(),y2=a("li"),dce=a("strong"),s6o=o("trocr"),l6o=o(" \u2014 "),tD=a("a"),i6o=o("TrOCRForCausalLM"),d6o=o(" (TrOCR model)"),c6o=l(),L2=a("li"),cce=a("strong"),f6o=o("xglm"),m6o=o(" \u2014 "),aD=a("a"),g6o=o("XGLMForCausalLM"),h6o=o(" (XGLM model)"),p6o=l(),x2=a("li"),fce=a("strong"),u6o=o("xlm"),_6o=o(" \u2014 "),nD=a("a"),b6o=o("XLMWithLMHeadModel"),v6o=o(" (XLM model)"),F6o=l(),$2=a("li"),mce=a("strong"),T6o=o("xlm-prophetnet"),M6o=o(" \u2014 "),sD=a("a"),E6o=o("XLMProphetNetForCausalLM"),C6o=o(" (XLMProphetNet model)"),w6o=l(),k2=a("li"),gce=a("strong"),A6o=o("xlm-roberta"),y6o=o(" \u2014 "),lD=a("a"),L6o=o("XLMRobertaForCausalLM"),x6o=o(" (XLM-RoBERTa model)"),$6o=l(),S2=a("li"),hce=a("strong"),k6o=o("xlm-roberta-xl"),S6o=o(" \u2014 "),iD=a("a"),R6o=o("XLMRobertaXLForCausalLM"),P6o=o(" (XLM-RoBERTa-XL model)"),B6o=l(),R2=a("li"),pce=a("strong"),I6o=o("xlnet"),q6o=o(" \u2014 "),dD=a("a"),N6o=o("XLNetLMHeadModel"),j6o=o(" (XLNet model)"),D6o=l(),P2=a("p"),G6o=o("The model is set in evaluation mode by default using "),uce=a("code"),O6o=o("model.eval()"),V6o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_ce=a("code"),X6o=o("model.train()"),z6o=l(),F(B2.$$.fragment),FNe=l(),qi=a("h2"),I2=a("a"),bce=a("span"),F(hy.$$.fragment),W6o=l(),vce=a("span"),Q6o=o("AutoModelForMaskedLM"),TNe=l(),ko=a("div"),F(py.$$.fragment),H6o=l(),Ni=a("p"),U6o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cD=a("a"),J6o=o("from_pretrained()"),Y6o=o(" class method or the "),fD=a("a"),K6o=o("from_config()"),Z6o=o(` class
method.`),eAo=l(),uy=a("p"),oAo=o("This class cannot be instantiated directly using "),Fce=a("code"),rAo=o("__init__()"),tAo=o(" (throws an error)."),aAo=l(),st=a("div"),F(_y.$$.fragment),nAo=l(),Tce=a("p"),sAo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),lAo=l(),ji=a("p"),iAo=o(`Note:
Loading a model from its configuration file does `),Mce=a("strong"),dAo=o("not"),cAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mD=a("a"),fAo=o("from_pretrained()"),mAo=o(" to load the model weights."),gAo=l(),F(q2.$$.fragment),hAo=l(),Ze=a("div"),F(by.$$.fragment),pAo=l(),Ece=a("p"),uAo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_Ao=l(),ka=a("p"),bAo=o("The model class to instantiate is selected based on the "),Cce=a("code"),vAo=o("model_type"),FAo=o(` property of the config object (either
passed as an argument or loaded from `),wce=a("code"),TAo=o("pretrained_model_name_or_path"),MAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ace=a("code"),EAo=o("pretrained_model_name_or_path"),CAo=o(":"),wAo=l(),Q=a("ul"),N2=a("li"),yce=a("strong"),AAo=o("albert"),yAo=o(" \u2014 "),gD=a("a"),LAo=o("AlbertForMaskedLM"),xAo=o(" (ALBERT model)"),$Ao=l(),j2=a("li"),Lce=a("strong"),kAo=o("bart"),SAo=o(" \u2014 "),hD=a("a"),RAo=o("BartForConditionalGeneration"),PAo=o(" (BART model)"),BAo=l(),D2=a("li"),xce=a("strong"),IAo=o("bert"),qAo=o(" \u2014 "),pD=a("a"),NAo=o("BertForMaskedLM"),jAo=o(" (BERT model)"),DAo=l(),G2=a("li"),$ce=a("strong"),GAo=o("big_bird"),OAo=o(" \u2014 "),uD=a("a"),VAo=o("BigBirdForMaskedLM"),XAo=o(" (BigBird model)"),zAo=l(),O2=a("li"),kce=a("strong"),WAo=o("camembert"),QAo=o(" \u2014 "),_D=a("a"),HAo=o("CamembertForMaskedLM"),UAo=o(" (CamemBERT model)"),JAo=l(),V2=a("li"),Sce=a("strong"),YAo=o("convbert"),KAo=o(" \u2014 "),bD=a("a"),ZAo=o("ConvBertForMaskedLM"),eyo=o(" (ConvBERT model)"),oyo=l(),X2=a("li"),Rce=a("strong"),ryo=o("data2vec-text"),tyo=o(" \u2014 "),vD=a("a"),ayo=o("Data2VecTextForMaskedLM"),nyo=o(" (Data2VecText model)"),syo=l(),z2=a("li"),Pce=a("strong"),lyo=o("deberta"),iyo=o(" \u2014 "),FD=a("a"),dyo=o("DebertaForMaskedLM"),cyo=o(" (DeBERTa model)"),fyo=l(),W2=a("li"),Bce=a("strong"),myo=o("deberta-v2"),gyo=o(" \u2014 "),TD=a("a"),hyo=o("DebertaV2ForMaskedLM"),pyo=o(" (DeBERTa-v2 model)"),uyo=l(),Q2=a("li"),Ice=a("strong"),_yo=o("distilbert"),byo=o(" \u2014 "),MD=a("a"),vyo=o("DistilBertForMaskedLM"),Fyo=o(" (DistilBERT model)"),Tyo=l(),H2=a("li"),qce=a("strong"),Myo=o("electra"),Eyo=o(" \u2014 "),ED=a("a"),Cyo=o("ElectraForMaskedLM"),wyo=o(" (ELECTRA model)"),Ayo=l(),U2=a("li"),Nce=a("strong"),yyo=o("flaubert"),Lyo=o(" \u2014 "),CD=a("a"),xyo=o("FlaubertWithLMHeadModel"),$yo=o(" (FlauBERT model)"),kyo=l(),J2=a("li"),jce=a("strong"),Syo=o("fnet"),Ryo=o(" \u2014 "),wD=a("a"),Pyo=o("FNetForMaskedLM"),Byo=o(" (FNet model)"),Iyo=l(),Y2=a("li"),Dce=a("strong"),qyo=o("funnel"),Nyo=o(" \u2014 "),AD=a("a"),jyo=o("FunnelForMaskedLM"),Dyo=o(" (Funnel Transformer model)"),Gyo=l(),K2=a("li"),Gce=a("strong"),Oyo=o("ibert"),Vyo=o(" \u2014 "),yD=a("a"),Xyo=o("IBertForMaskedLM"),zyo=o(" (I-BERT model)"),Wyo=l(),Z2=a("li"),Oce=a("strong"),Qyo=o("layoutlm"),Hyo=o(" \u2014 "),LD=a("a"),Uyo=o("LayoutLMForMaskedLM"),Jyo=o(" (LayoutLM model)"),Yyo=l(),e1=a("li"),Vce=a("strong"),Kyo=o("longformer"),Zyo=o(" \u2014 "),xD=a("a"),eLo=o("LongformerForMaskedLM"),oLo=o(" (Longformer model)"),rLo=l(),o1=a("li"),Xce=a("strong"),tLo=o("mbart"),aLo=o(" \u2014 "),$D=a("a"),nLo=o("MBartForConditionalGeneration"),sLo=o(" (mBART model)"),lLo=l(),r1=a("li"),zce=a("strong"),iLo=o("megatron-bert"),dLo=o(" \u2014 "),kD=a("a"),cLo=o("MegatronBertForMaskedLM"),fLo=o(" (MegatronBert model)"),mLo=l(),t1=a("li"),Wce=a("strong"),gLo=o("mobilebert"),hLo=o(" \u2014 "),SD=a("a"),pLo=o("MobileBertForMaskedLM"),uLo=o(" (MobileBERT model)"),_Lo=l(),a1=a("li"),Qce=a("strong"),bLo=o("mpnet"),vLo=o(" \u2014 "),RD=a("a"),FLo=o("MPNetForMaskedLM"),TLo=o(" (MPNet model)"),MLo=l(),n1=a("li"),Hce=a("strong"),ELo=o("nystromformer"),CLo=o(" \u2014 "),PD=a("a"),wLo=o("NystromformerForMaskedLM"),ALo=o(" (Nystromformer model)"),yLo=l(),s1=a("li"),Uce=a("strong"),LLo=o("perceiver"),xLo=o(" \u2014 "),BD=a("a"),$Lo=o("PerceiverForMaskedLM"),kLo=o(" (Perceiver model)"),SLo=l(),l1=a("li"),Jce=a("strong"),RLo=o("qdqbert"),PLo=o(" \u2014 "),ID=a("a"),BLo=o("QDQBertForMaskedLM"),ILo=o(" (QDQBert model)"),qLo=l(),i1=a("li"),Yce=a("strong"),NLo=o("reformer"),jLo=o(" \u2014 "),qD=a("a"),DLo=o("ReformerForMaskedLM"),GLo=o(" (Reformer model)"),OLo=l(),d1=a("li"),Kce=a("strong"),VLo=o("rembert"),XLo=o(" \u2014 "),ND=a("a"),zLo=o("RemBertForMaskedLM"),WLo=o(" (RemBERT model)"),QLo=l(),c1=a("li"),Zce=a("strong"),HLo=o("roberta"),ULo=o(" \u2014 "),jD=a("a"),JLo=o("RobertaForMaskedLM"),YLo=o(" (RoBERTa model)"),KLo=l(),f1=a("li"),efe=a("strong"),ZLo=o("roformer"),e8o=o(" \u2014 "),DD=a("a"),o8o=o("RoFormerForMaskedLM"),r8o=o(" (RoFormer model)"),t8o=l(),m1=a("li"),ofe=a("strong"),a8o=o("squeezebert"),n8o=o(" \u2014 "),GD=a("a"),s8o=o("SqueezeBertForMaskedLM"),l8o=o(" (SqueezeBERT model)"),i8o=l(),g1=a("li"),rfe=a("strong"),d8o=o("tapas"),c8o=o(" \u2014 "),OD=a("a"),f8o=o("TapasForMaskedLM"),m8o=o(" (TAPAS model)"),g8o=l(),h1=a("li"),tfe=a("strong"),h8o=o("wav2vec2"),p8o=o(" \u2014 "),afe=a("code"),u8o=o("Wav2Vec2ForMaskedLM"),_8o=o(" (Wav2Vec2 model)"),b8o=l(),p1=a("li"),nfe=a("strong"),v8o=o("xlm"),F8o=o(" \u2014 "),VD=a("a"),T8o=o("XLMWithLMHeadModel"),M8o=o(" (XLM model)"),E8o=l(),u1=a("li"),sfe=a("strong"),C8o=o("xlm-roberta"),w8o=o(" \u2014 "),XD=a("a"),A8o=o("XLMRobertaForMaskedLM"),y8o=o(" (XLM-RoBERTa model)"),L8o=l(),_1=a("li"),lfe=a("strong"),x8o=o("xlm-roberta-xl"),$8o=o(" \u2014 "),zD=a("a"),k8o=o("XLMRobertaXLForMaskedLM"),S8o=o(" (XLM-RoBERTa-XL model)"),R8o=l(),b1=a("li"),ife=a("strong"),P8o=o("yoso"),B8o=o(" \u2014 "),WD=a("a"),I8o=o("YosoForMaskedLM"),q8o=o(" (YOSO model)"),N8o=l(),v1=a("p"),j8o=o("The model is set in evaluation mode by default using "),dfe=a("code"),D8o=o("model.eval()"),G8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cfe=a("code"),O8o=o("model.train()"),V8o=l(),F(F1.$$.fragment),MNe=l(),Di=a("h2"),T1=a("a"),ffe=a("span"),F(vy.$$.fragment),X8o=l(),mfe=a("span"),z8o=o("AutoModelForSeq2SeqLM"),ENe=l(),So=a("div"),F(Fy.$$.fragment),W8o=l(),Gi=a("p"),Q8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),QD=a("a"),H8o=o("from_pretrained()"),U8o=o(" class method or the "),HD=a("a"),J8o=o("from_config()"),Y8o=o(` class
method.`),K8o=l(),Ty=a("p"),Z8o=o("This class cannot be instantiated directly using "),gfe=a("code"),e9o=o("__init__()"),o9o=o(" (throws an error)."),r9o=l(),lt=a("div"),F(My.$$.fragment),t9o=l(),hfe=a("p"),a9o=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),n9o=l(),Oi=a("p"),s9o=o(`Note:
Loading a model from its configuration file does `),pfe=a("strong"),l9o=o("not"),i9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UD=a("a"),d9o=o("from_pretrained()"),c9o=o(" to load the model weights."),f9o=l(),F(M1.$$.fragment),m9o=l(),eo=a("div"),F(Ey.$$.fragment),g9o=l(),ufe=a("p"),h9o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),p9o=l(),Sa=a("p"),u9o=o("The model class to instantiate is selected based on the "),_fe=a("code"),_9o=o("model_type"),b9o=o(` property of the config object (either
passed as an argument or loaded from `),bfe=a("code"),v9o=o("pretrained_model_name_or_path"),F9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vfe=a("code"),T9o=o("pretrained_model_name_or_path"),M9o=o(":"),E9o=l(),ue=a("ul"),E1=a("li"),Ffe=a("strong"),C9o=o("bart"),w9o=o(" \u2014 "),JD=a("a"),A9o=o("BartForConditionalGeneration"),y9o=o(" (BART model)"),L9o=l(),C1=a("li"),Tfe=a("strong"),x9o=o("bigbird_pegasus"),$9o=o(" \u2014 "),YD=a("a"),k9o=o("BigBirdPegasusForConditionalGeneration"),S9o=o(" (BigBirdPegasus model)"),R9o=l(),w1=a("li"),Mfe=a("strong"),P9o=o("blenderbot"),B9o=o(" \u2014 "),KD=a("a"),I9o=o("BlenderbotForConditionalGeneration"),q9o=o(" (Blenderbot model)"),N9o=l(),A1=a("li"),Efe=a("strong"),j9o=o("blenderbot-small"),D9o=o(" \u2014 "),ZD=a("a"),G9o=o("BlenderbotSmallForConditionalGeneration"),O9o=o(" (BlenderbotSmall model)"),V9o=l(),y1=a("li"),Cfe=a("strong"),X9o=o("encoder-decoder"),z9o=o(" \u2014 "),eG=a("a"),W9o=o("EncoderDecoderModel"),Q9o=o(" (Encoder decoder model)"),H9o=l(),L1=a("li"),wfe=a("strong"),U9o=o("fsmt"),J9o=o(" \u2014 "),oG=a("a"),Y9o=o("FSMTForConditionalGeneration"),K9o=o(" (FairSeq Machine-Translation model)"),Z9o=l(),x1=a("li"),Afe=a("strong"),exo=o("led"),oxo=o(" \u2014 "),rG=a("a"),rxo=o("LEDForConditionalGeneration"),txo=o(" (LED model)"),axo=l(),$1=a("li"),yfe=a("strong"),nxo=o("m2m_100"),sxo=o(" \u2014 "),tG=a("a"),lxo=o("M2M100ForConditionalGeneration"),ixo=o(" (M2M100 model)"),dxo=l(),k1=a("li"),Lfe=a("strong"),cxo=o("marian"),fxo=o(" \u2014 "),aG=a("a"),mxo=o("MarianMTModel"),gxo=o(" (Marian model)"),hxo=l(),S1=a("li"),xfe=a("strong"),pxo=o("mbart"),uxo=o(" \u2014 "),nG=a("a"),_xo=o("MBartForConditionalGeneration"),bxo=o(" (mBART model)"),vxo=l(),R1=a("li"),$fe=a("strong"),Fxo=o("mt5"),Txo=o(" \u2014 "),sG=a("a"),Mxo=o("MT5ForConditionalGeneration"),Exo=o(" (mT5 model)"),Cxo=l(),P1=a("li"),kfe=a("strong"),wxo=o("pegasus"),Axo=o(" \u2014 "),lG=a("a"),yxo=o("PegasusForConditionalGeneration"),Lxo=o(" (Pegasus model)"),xxo=l(),B1=a("li"),Sfe=a("strong"),$xo=o("plbart"),kxo=o(" \u2014 "),iG=a("a"),Sxo=o("PLBartForConditionalGeneration"),Rxo=o(" (PLBart model)"),Pxo=l(),I1=a("li"),Rfe=a("strong"),Bxo=o("prophetnet"),Ixo=o(" \u2014 "),dG=a("a"),qxo=o("ProphetNetForConditionalGeneration"),Nxo=o(" (ProphetNet model)"),jxo=l(),q1=a("li"),Pfe=a("strong"),Dxo=o("t5"),Gxo=o(" \u2014 "),cG=a("a"),Oxo=o("T5ForConditionalGeneration"),Vxo=o(" (T5 model)"),Xxo=l(),N1=a("li"),Bfe=a("strong"),zxo=o("xlm-prophetnet"),Wxo=o(" \u2014 "),fG=a("a"),Qxo=o("XLMProphetNetForConditionalGeneration"),Hxo=o(" (XLMProphetNet model)"),Uxo=l(),j1=a("p"),Jxo=o("The model is set in evaluation mode by default using "),Ife=a("code"),Yxo=o("model.eval()"),Kxo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qfe=a("code"),Zxo=o("model.train()"),e$o=l(),F(D1.$$.fragment),CNe=l(),Vi=a("h2"),G1=a("a"),Nfe=a("span"),F(Cy.$$.fragment),o$o=l(),jfe=a("span"),r$o=o("AutoModelForSequenceClassification"),wNe=l(),Ro=a("div"),F(wy.$$.fragment),t$o=l(),Xi=a("p"),a$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),mG=a("a"),n$o=o("from_pretrained()"),s$o=o(" class method or the "),gG=a("a"),l$o=o("from_config()"),i$o=o(` class
method.`),d$o=l(),Ay=a("p"),c$o=o("This class cannot be instantiated directly using "),Dfe=a("code"),f$o=o("__init__()"),m$o=o(" (throws an error)."),g$o=l(),it=a("div"),F(yy.$$.fragment),h$o=l(),Gfe=a("p"),p$o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),u$o=l(),zi=a("p"),_$o=o(`Note:
Loading a model from its configuration file does `),Ofe=a("strong"),b$o=o("not"),v$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hG=a("a"),F$o=o("from_pretrained()"),T$o=o(" to load the model weights."),M$o=l(),F(O1.$$.fragment),E$o=l(),oo=a("div"),F(Ly.$$.fragment),C$o=l(),Vfe=a("p"),w$o=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),A$o=l(),Ra=a("p"),y$o=o("The model class to instantiate is selected based on the "),Xfe=a("code"),L$o=o("model_type"),x$o=o(` property of the config object (either
passed as an argument or loaded from `),zfe=a("code"),$$o=o("pretrained_model_name_or_path"),k$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wfe=a("code"),S$o=o("pretrained_model_name_or_path"),R$o=o(":"),P$o=l(),q=a("ul"),V1=a("li"),Qfe=a("strong"),B$o=o("albert"),I$o=o(" \u2014 "),pG=a("a"),q$o=o("AlbertForSequenceClassification"),N$o=o(" (ALBERT model)"),j$o=l(),X1=a("li"),Hfe=a("strong"),D$o=o("bart"),G$o=o(" \u2014 "),uG=a("a"),O$o=o("BartForSequenceClassification"),V$o=o(" (BART model)"),X$o=l(),z1=a("li"),Ufe=a("strong"),z$o=o("bert"),W$o=o(" \u2014 "),_G=a("a"),Q$o=o("BertForSequenceClassification"),H$o=o(" (BERT model)"),U$o=l(),W1=a("li"),Jfe=a("strong"),J$o=o("big_bird"),Y$o=o(" \u2014 "),bG=a("a"),K$o=o("BigBirdForSequenceClassification"),Z$o=o(" (BigBird model)"),eko=l(),Q1=a("li"),Yfe=a("strong"),oko=o("bigbird_pegasus"),rko=o(" \u2014 "),vG=a("a"),tko=o("BigBirdPegasusForSequenceClassification"),ako=o(" (BigBirdPegasus model)"),nko=l(),H1=a("li"),Kfe=a("strong"),sko=o("camembert"),lko=o(" \u2014 "),FG=a("a"),iko=o("CamembertForSequenceClassification"),dko=o(" (CamemBERT model)"),cko=l(),U1=a("li"),Zfe=a("strong"),fko=o("canine"),mko=o(" \u2014 "),TG=a("a"),gko=o("CanineForSequenceClassification"),hko=o(" (Canine model)"),pko=l(),J1=a("li"),eme=a("strong"),uko=o("convbert"),_ko=o(" \u2014 "),MG=a("a"),bko=o("ConvBertForSequenceClassification"),vko=o(" (ConvBERT model)"),Fko=l(),Y1=a("li"),ome=a("strong"),Tko=o("ctrl"),Mko=o(" \u2014 "),EG=a("a"),Eko=o("CTRLForSequenceClassification"),Cko=o(" (CTRL model)"),wko=l(),K1=a("li"),rme=a("strong"),Ako=o("data2vec-text"),yko=o(" \u2014 "),CG=a("a"),Lko=o("Data2VecTextForSequenceClassification"),xko=o(" (Data2VecText model)"),$ko=l(),Z1=a("li"),tme=a("strong"),kko=o("deberta"),Sko=o(" \u2014 "),wG=a("a"),Rko=o("DebertaForSequenceClassification"),Pko=o(" (DeBERTa model)"),Bko=l(),eb=a("li"),ame=a("strong"),Iko=o("deberta-v2"),qko=o(" \u2014 "),AG=a("a"),Nko=o("DebertaV2ForSequenceClassification"),jko=o(" (DeBERTa-v2 model)"),Dko=l(),ob=a("li"),nme=a("strong"),Gko=o("distilbert"),Oko=o(" \u2014 "),yG=a("a"),Vko=o("DistilBertForSequenceClassification"),Xko=o(" (DistilBERT model)"),zko=l(),rb=a("li"),sme=a("strong"),Wko=o("electra"),Qko=o(" \u2014 "),LG=a("a"),Hko=o("ElectraForSequenceClassification"),Uko=o(" (ELECTRA model)"),Jko=l(),tb=a("li"),lme=a("strong"),Yko=o("flaubert"),Kko=o(" \u2014 "),xG=a("a"),Zko=o("FlaubertForSequenceClassification"),eSo=o(" (FlauBERT model)"),oSo=l(),ab=a("li"),ime=a("strong"),rSo=o("fnet"),tSo=o(" \u2014 "),$G=a("a"),aSo=o("FNetForSequenceClassification"),nSo=o(" (FNet model)"),sSo=l(),nb=a("li"),dme=a("strong"),lSo=o("funnel"),iSo=o(" \u2014 "),kG=a("a"),dSo=o("FunnelForSequenceClassification"),cSo=o(" (Funnel Transformer model)"),fSo=l(),sb=a("li"),cme=a("strong"),mSo=o("gpt2"),gSo=o(" \u2014 "),SG=a("a"),hSo=o("GPT2ForSequenceClassification"),pSo=o(" (OpenAI GPT-2 model)"),uSo=l(),lb=a("li"),fme=a("strong"),_So=o("gpt_neo"),bSo=o(" \u2014 "),RG=a("a"),vSo=o("GPTNeoForSequenceClassification"),FSo=o(" (GPT Neo model)"),TSo=l(),ib=a("li"),mme=a("strong"),MSo=o("gptj"),ESo=o(" \u2014 "),PG=a("a"),CSo=o("GPTJForSequenceClassification"),wSo=o(" (GPT-J model)"),ASo=l(),db=a("li"),gme=a("strong"),ySo=o("ibert"),LSo=o(" \u2014 "),BG=a("a"),xSo=o("IBertForSequenceClassification"),$So=o(" (I-BERT model)"),kSo=l(),cb=a("li"),hme=a("strong"),SSo=o("layoutlm"),RSo=o(" \u2014 "),IG=a("a"),PSo=o("LayoutLMForSequenceClassification"),BSo=o(" (LayoutLM model)"),ISo=l(),fb=a("li"),pme=a("strong"),qSo=o("layoutlmv2"),NSo=o(" \u2014 "),qG=a("a"),jSo=o("LayoutLMv2ForSequenceClassification"),DSo=o(" (LayoutLMv2 model)"),GSo=l(),mb=a("li"),ume=a("strong"),OSo=o("layoutlmv3"),VSo=o(" \u2014 "),NG=a("a"),XSo=o("LayoutLMv3ForSequenceClassification"),zSo=o(" (LayoutLMv3 model)"),WSo=l(),gb=a("li"),_me=a("strong"),QSo=o("led"),HSo=o(" \u2014 "),jG=a("a"),USo=o("LEDForSequenceClassification"),JSo=o(" (LED model)"),YSo=l(),hb=a("li"),bme=a("strong"),KSo=o("longformer"),ZSo=o(" \u2014 "),DG=a("a"),eRo=o("LongformerForSequenceClassification"),oRo=o(" (Longformer model)"),rRo=l(),pb=a("li"),vme=a("strong"),tRo=o("mbart"),aRo=o(" \u2014 "),GG=a("a"),nRo=o("MBartForSequenceClassification"),sRo=o(" (mBART model)"),lRo=l(),ub=a("li"),Fme=a("strong"),iRo=o("megatron-bert"),dRo=o(" \u2014 "),OG=a("a"),cRo=o("MegatronBertForSequenceClassification"),fRo=o(" (MegatronBert model)"),mRo=l(),_b=a("li"),Tme=a("strong"),gRo=o("mobilebert"),hRo=o(" \u2014 "),VG=a("a"),pRo=o("MobileBertForSequenceClassification"),uRo=o(" (MobileBERT model)"),_Ro=l(),bb=a("li"),Mme=a("strong"),bRo=o("mpnet"),vRo=o(" \u2014 "),XG=a("a"),FRo=o("MPNetForSequenceClassification"),TRo=o(" (MPNet model)"),MRo=l(),vb=a("li"),Eme=a("strong"),ERo=o("nystromformer"),CRo=o(" \u2014 "),zG=a("a"),wRo=o("NystromformerForSequenceClassification"),ARo=o(" (Nystromformer model)"),yRo=l(),Fb=a("li"),Cme=a("strong"),LRo=o("openai-gpt"),xRo=o(" \u2014 "),WG=a("a"),$Ro=o("OpenAIGPTForSequenceClassification"),kRo=o(" (OpenAI GPT model)"),SRo=l(),Tb=a("li"),wme=a("strong"),RRo=o("perceiver"),PRo=o(" \u2014 "),QG=a("a"),BRo=o("PerceiverForSequenceClassification"),IRo=o(" (Perceiver model)"),qRo=l(),Mb=a("li"),Ame=a("strong"),NRo=o("plbart"),jRo=o(" \u2014 "),HG=a("a"),DRo=o("PLBartForSequenceClassification"),GRo=o(" (PLBart model)"),ORo=l(),Eb=a("li"),yme=a("strong"),VRo=o("qdqbert"),XRo=o(" \u2014 "),UG=a("a"),zRo=o("QDQBertForSequenceClassification"),WRo=o(" (QDQBert model)"),QRo=l(),Cb=a("li"),Lme=a("strong"),HRo=o("reformer"),URo=o(" \u2014 "),JG=a("a"),JRo=o("ReformerForSequenceClassification"),YRo=o(" (Reformer model)"),KRo=l(),wb=a("li"),xme=a("strong"),ZRo=o("rembert"),ePo=o(" \u2014 "),YG=a("a"),oPo=o("RemBertForSequenceClassification"),rPo=o(" (RemBERT model)"),tPo=l(),Ab=a("li"),$me=a("strong"),aPo=o("roberta"),nPo=o(" \u2014 "),KG=a("a"),sPo=o("RobertaForSequenceClassification"),lPo=o(" (RoBERTa model)"),iPo=l(),yb=a("li"),kme=a("strong"),dPo=o("roformer"),cPo=o(" \u2014 "),ZG=a("a"),fPo=o("RoFormerForSequenceClassification"),mPo=o(" (RoFormer model)"),gPo=l(),Lb=a("li"),Sme=a("strong"),hPo=o("squeezebert"),pPo=o(" \u2014 "),eO=a("a"),uPo=o("SqueezeBertForSequenceClassification"),_Po=o(" (SqueezeBERT model)"),bPo=l(),xb=a("li"),Rme=a("strong"),vPo=o("tapas"),FPo=o(" \u2014 "),oO=a("a"),TPo=o("TapasForSequenceClassification"),MPo=o(" (TAPAS model)"),EPo=l(),$b=a("li"),Pme=a("strong"),CPo=o("transfo-xl"),wPo=o(" \u2014 "),rO=a("a"),APo=o("TransfoXLForSequenceClassification"),yPo=o(" (Transformer-XL model)"),LPo=l(),kb=a("li"),Bme=a("strong"),xPo=o("xlm"),$Po=o(" \u2014 "),tO=a("a"),kPo=o("XLMForSequenceClassification"),SPo=o(" (XLM model)"),RPo=l(),Sb=a("li"),Ime=a("strong"),PPo=o("xlm-roberta"),BPo=o(" \u2014 "),aO=a("a"),IPo=o("XLMRobertaForSequenceClassification"),qPo=o(" (XLM-RoBERTa model)"),NPo=l(),Rb=a("li"),qme=a("strong"),jPo=o("xlm-roberta-xl"),DPo=o(" \u2014 "),nO=a("a"),GPo=o("XLMRobertaXLForSequenceClassification"),OPo=o(" (XLM-RoBERTa-XL model)"),VPo=l(),Pb=a("li"),Nme=a("strong"),XPo=o("xlnet"),zPo=o(" \u2014 "),sO=a("a"),WPo=o("XLNetForSequenceClassification"),QPo=o(" (XLNet model)"),HPo=l(),Bb=a("li"),jme=a("strong"),UPo=o("yoso"),JPo=o(" \u2014 "),lO=a("a"),YPo=o("YosoForSequenceClassification"),KPo=o(" (YOSO model)"),ZPo=l(),Ib=a("p"),eBo=o("The model is set in evaluation mode by default using "),Dme=a("code"),oBo=o("model.eval()"),rBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gme=a("code"),tBo=o("model.train()"),aBo=l(),F(qb.$$.fragment),ANe=l(),Wi=a("h2"),Nb=a("a"),Ome=a("span"),F(xy.$$.fragment),nBo=l(),Vme=a("span"),sBo=o("AutoModelForMultipleChoice"),yNe=l(),Po=a("div"),F($y.$$.fragment),lBo=l(),Qi=a("p"),iBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iO=a("a"),dBo=o("from_pretrained()"),cBo=o(" class method or the "),dO=a("a"),fBo=o("from_config()"),mBo=o(` class
method.`),gBo=l(),ky=a("p"),hBo=o("This class cannot be instantiated directly using "),Xme=a("code"),pBo=o("__init__()"),uBo=o(" (throws an error)."),_Bo=l(),dt=a("div"),F(Sy.$$.fragment),bBo=l(),zme=a("p"),vBo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),FBo=l(),Hi=a("p"),TBo=o(`Note:
Loading a model from its configuration file does `),Wme=a("strong"),MBo=o("not"),EBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cO=a("a"),CBo=o("from_pretrained()"),wBo=o(" to load the model weights."),ABo=l(),F(jb.$$.fragment),yBo=l(),ro=a("div"),F(Ry.$$.fragment),LBo=l(),Qme=a("p"),xBo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$Bo=l(),Pa=a("p"),kBo=o("The model class to instantiate is selected based on the "),Hme=a("code"),SBo=o("model_type"),RBo=o(` property of the config object (either
passed as an argument or loaded from `),Ume=a("code"),PBo=o("pretrained_model_name_or_path"),BBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jme=a("code"),IBo=o("pretrained_model_name_or_path"),qBo=o(":"),NBo=l(),K=a("ul"),Db=a("li"),Yme=a("strong"),jBo=o("albert"),DBo=o(" \u2014 "),fO=a("a"),GBo=o("AlbertForMultipleChoice"),OBo=o(" (ALBERT model)"),VBo=l(),Gb=a("li"),Kme=a("strong"),XBo=o("bert"),zBo=o(" \u2014 "),mO=a("a"),WBo=o("BertForMultipleChoice"),QBo=o(" (BERT model)"),HBo=l(),Ob=a("li"),Zme=a("strong"),UBo=o("big_bird"),JBo=o(" \u2014 "),gO=a("a"),YBo=o("BigBirdForMultipleChoice"),KBo=o(" (BigBird model)"),ZBo=l(),Vb=a("li"),ege=a("strong"),eIo=o("camembert"),oIo=o(" \u2014 "),hO=a("a"),rIo=o("CamembertForMultipleChoice"),tIo=o(" (CamemBERT model)"),aIo=l(),Xb=a("li"),oge=a("strong"),nIo=o("canine"),sIo=o(" \u2014 "),pO=a("a"),lIo=o("CanineForMultipleChoice"),iIo=o(" (Canine model)"),dIo=l(),zb=a("li"),rge=a("strong"),cIo=o("convbert"),fIo=o(" \u2014 "),uO=a("a"),mIo=o("ConvBertForMultipleChoice"),gIo=o(" (ConvBERT model)"),hIo=l(),Wb=a("li"),tge=a("strong"),pIo=o("data2vec-text"),uIo=o(" \u2014 "),_O=a("a"),_Io=o("Data2VecTextForMultipleChoice"),bIo=o(" (Data2VecText model)"),vIo=l(),Qb=a("li"),age=a("strong"),FIo=o("deberta-v2"),TIo=o(" \u2014 "),bO=a("a"),MIo=o("DebertaV2ForMultipleChoice"),EIo=o(" (DeBERTa-v2 model)"),CIo=l(),Hb=a("li"),nge=a("strong"),wIo=o("distilbert"),AIo=o(" \u2014 "),vO=a("a"),yIo=o("DistilBertForMultipleChoice"),LIo=o(" (DistilBERT model)"),xIo=l(),Ub=a("li"),sge=a("strong"),$Io=o("electra"),kIo=o(" \u2014 "),FO=a("a"),SIo=o("ElectraForMultipleChoice"),RIo=o(" (ELECTRA model)"),PIo=l(),Jb=a("li"),lge=a("strong"),BIo=o("flaubert"),IIo=o(" \u2014 "),TO=a("a"),qIo=o("FlaubertForMultipleChoice"),NIo=o(" (FlauBERT model)"),jIo=l(),Yb=a("li"),ige=a("strong"),DIo=o("fnet"),GIo=o(" \u2014 "),MO=a("a"),OIo=o("FNetForMultipleChoice"),VIo=o(" (FNet model)"),XIo=l(),Kb=a("li"),dge=a("strong"),zIo=o("funnel"),WIo=o(" \u2014 "),EO=a("a"),QIo=o("FunnelForMultipleChoice"),HIo=o(" (Funnel Transformer model)"),UIo=l(),Zb=a("li"),cge=a("strong"),JIo=o("ibert"),YIo=o(" \u2014 "),CO=a("a"),KIo=o("IBertForMultipleChoice"),ZIo=o(" (I-BERT model)"),eqo=l(),e4=a("li"),fge=a("strong"),oqo=o("longformer"),rqo=o(" \u2014 "),wO=a("a"),tqo=o("LongformerForMultipleChoice"),aqo=o(" (Longformer model)"),nqo=l(),o4=a("li"),mge=a("strong"),sqo=o("megatron-bert"),lqo=o(" \u2014 "),AO=a("a"),iqo=o("MegatronBertForMultipleChoice"),dqo=o(" (MegatronBert model)"),cqo=l(),r4=a("li"),gge=a("strong"),fqo=o("mobilebert"),mqo=o(" \u2014 "),yO=a("a"),gqo=o("MobileBertForMultipleChoice"),hqo=o(" (MobileBERT model)"),pqo=l(),t4=a("li"),hge=a("strong"),uqo=o("mpnet"),_qo=o(" \u2014 "),LO=a("a"),bqo=o("MPNetForMultipleChoice"),vqo=o(" (MPNet model)"),Fqo=l(),a4=a("li"),pge=a("strong"),Tqo=o("nystromformer"),Mqo=o(" \u2014 "),xO=a("a"),Eqo=o("NystromformerForMultipleChoice"),Cqo=o(" (Nystromformer model)"),wqo=l(),n4=a("li"),uge=a("strong"),Aqo=o("qdqbert"),yqo=o(" \u2014 "),$O=a("a"),Lqo=o("QDQBertForMultipleChoice"),xqo=o(" (QDQBert model)"),$qo=l(),s4=a("li"),_ge=a("strong"),kqo=o("rembert"),Sqo=o(" \u2014 "),kO=a("a"),Rqo=o("RemBertForMultipleChoice"),Pqo=o(" (RemBERT model)"),Bqo=l(),l4=a("li"),bge=a("strong"),Iqo=o("roberta"),qqo=o(" \u2014 "),SO=a("a"),Nqo=o("RobertaForMultipleChoice"),jqo=o(" (RoBERTa model)"),Dqo=l(),i4=a("li"),vge=a("strong"),Gqo=o("roformer"),Oqo=o(" \u2014 "),RO=a("a"),Vqo=o("RoFormerForMultipleChoice"),Xqo=o(" (RoFormer model)"),zqo=l(),d4=a("li"),Fge=a("strong"),Wqo=o("squeezebert"),Qqo=o(" \u2014 "),PO=a("a"),Hqo=o("SqueezeBertForMultipleChoice"),Uqo=o(" (SqueezeBERT model)"),Jqo=l(),c4=a("li"),Tge=a("strong"),Yqo=o("xlm"),Kqo=o(" \u2014 "),BO=a("a"),Zqo=o("XLMForMultipleChoice"),eNo=o(" (XLM model)"),oNo=l(),f4=a("li"),Mge=a("strong"),rNo=o("xlm-roberta"),tNo=o(" \u2014 "),IO=a("a"),aNo=o("XLMRobertaForMultipleChoice"),nNo=o(" (XLM-RoBERTa model)"),sNo=l(),m4=a("li"),Ege=a("strong"),lNo=o("xlm-roberta-xl"),iNo=o(" \u2014 "),qO=a("a"),dNo=o("XLMRobertaXLForMultipleChoice"),cNo=o(" (XLM-RoBERTa-XL model)"),fNo=l(),g4=a("li"),Cge=a("strong"),mNo=o("xlnet"),gNo=o(" \u2014 "),NO=a("a"),hNo=o("XLNetForMultipleChoice"),pNo=o(" (XLNet model)"),uNo=l(),h4=a("li"),wge=a("strong"),_No=o("yoso"),bNo=o(" \u2014 "),jO=a("a"),vNo=o("YosoForMultipleChoice"),FNo=o(" (YOSO model)"),TNo=l(),p4=a("p"),MNo=o("The model is set in evaluation mode by default using "),Age=a("code"),ENo=o("model.eval()"),CNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yge=a("code"),wNo=o("model.train()"),ANo=l(),F(u4.$$.fragment),LNe=l(),Ui=a("h2"),_4=a("a"),Lge=a("span"),F(Py.$$.fragment),yNo=l(),xge=a("span"),LNo=o("AutoModelForNextSentencePrediction"),xNe=l(),Bo=a("div"),F(By.$$.fragment),xNo=l(),Ji=a("p"),$No=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DO=a("a"),kNo=o("from_pretrained()"),SNo=o(" class method or the "),GO=a("a"),RNo=o("from_config()"),PNo=o(` class
method.`),BNo=l(),Iy=a("p"),INo=o("This class cannot be instantiated directly using "),$ge=a("code"),qNo=o("__init__()"),NNo=o(" (throws an error)."),jNo=l(),ct=a("div"),F(qy.$$.fragment),DNo=l(),kge=a("p"),GNo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ONo=l(),Yi=a("p"),VNo=o(`Note:
Loading a model from its configuration file does `),Sge=a("strong"),XNo=o("not"),zNo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OO=a("a"),WNo=o("from_pretrained()"),QNo=o(" to load the model weights."),HNo=l(),F(b4.$$.fragment),UNo=l(),to=a("div"),F(Ny.$$.fragment),JNo=l(),Rge=a("p"),YNo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),KNo=l(),Ba=a("p"),ZNo=o("The model class to instantiate is selected based on the "),Pge=a("code"),ejo=o("model_type"),ojo=o(` property of the config object (either
passed as an argument or loaded from `),Bge=a("code"),rjo=o("pretrained_model_name_or_path"),tjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ige=a("code"),ajo=o("pretrained_model_name_or_path"),njo=o(":"),sjo=l(),Yr=a("ul"),v4=a("li"),qge=a("strong"),ljo=o("bert"),ijo=o(" \u2014 "),VO=a("a"),djo=o("BertForNextSentencePrediction"),cjo=o(" (BERT model)"),fjo=l(),F4=a("li"),Nge=a("strong"),mjo=o("fnet"),gjo=o(" \u2014 "),XO=a("a"),hjo=o("FNetForNextSentencePrediction"),pjo=o(" (FNet model)"),ujo=l(),T4=a("li"),jge=a("strong"),_jo=o("megatron-bert"),bjo=o(" \u2014 "),zO=a("a"),vjo=o("MegatronBertForNextSentencePrediction"),Fjo=o(" (MegatronBert model)"),Tjo=l(),M4=a("li"),Dge=a("strong"),Mjo=o("mobilebert"),Ejo=o(" \u2014 "),WO=a("a"),Cjo=o("MobileBertForNextSentencePrediction"),wjo=o(" (MobileBERT model)"),Ajo=l(),E4=a("li"),Gge=a("strong"),yjo=o("qdqbert"),Ljo=o(" \u2014 "),QO=a("a"),xjo=o("QDQBertForNextSentencePrediction"),$jo=o(" (QDQBert model)"),kjo=l(),C4=a("p"),Sjo=o("The model is set in evaluation mode by default using "),Oge=a("code"),Rjo=o("model.eval()"),Pjo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vge=a("code"),Bjo=o("model.train()"),Ijo=l(),F(w4.$$.fragment),$Ne=l(),Ki=a("h2"),A4=a("a"),Xge=a("span"),F(jy.$$.fragment),qjo=l(),zge=a("span"),Njo=o("AutoModelForTokenClassification"),kNe=l(),Io=a("div"),F(Dy.$$.fragment),jjo=l(),Zi=a("p"),Djo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HO=a("a"),Gjo=o("from_pretrained()"),Ojo=o(" class method or the "),UO=a("a"),Vjo=o("from_config()"),Xjo=o(` class
method.`),zjo=l(),Gy=a("p"),Wjo=o("This class cannot be instantiated directly using "),Wge=a("code"),Qjo=o("__init__()"),Hjo=o(" (throws an error)."),Ujo=l(),ft=a("div"),F(Oy.$$.fragment),Jjo=l(),Qge=a("p"),Yjo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Kjo=l(),ed=a("p"),Zjo=o(`Note:
Loading a model from its configuration file does `),Hge=a("strong"),eDo=o("not"),oDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JO=a("a"),rDo=o("from_pretrained()"),tDo=o(" to load the model weights."),aDo=l(),F(y4.$$.fragment),nDo=l(),ao=a("div"),F(Vy.$$.fragment),sDo=l(),Uge=a("p"),lDo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),iDo=l(),Ia=a("p"),dDo=o("The model class to instantiate is selected based on the "),Jge=a("code"),cDo=o("model_type"),fDo=o(` property of the config object (either
passed as an argument or loaded from `),Yge=a("code"),mDo=o("pretrained_model_name_or_path"),gDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kge=a("code"),hDo=o("pretrained_model_name_or_path"),pDo=o(":"),uDo=l(),H=a("ul"),L4=a("li"),Zge=a("strong"),_Do=o("albert"),bDo=o(" \u2014 "),YO=a("a"),vDo=o("AlbertForTokenClassification"),FDo=o(" (ALBERT model)"),TDo=l(),x4=a("li"),ehe=a("strong"),MDo=o("bert"),EDo=o(" \u2014 "),KO=a("a"),CDo=o("BertForTokenClassification"),wDo=o(" (BERT model)"),ADo=l(),$4=a("li"),ohe=a("strong"),yDo=o("big_bird"),LDo=o(" \u2014 "),ZO=a("a"),xDo=o("BigBirdForTokenClassification"),$Do=o(" (BigBird model)"),kDo=l(),k4=a("li"),rhe=a("strong"),SDo=o("camembert"),RDo=o(" \u2014 "),eV=a("a"),PDo=o("CamembertForTokenClassification"),BDo=o(" (CamemBERT model)"),IDo=l(),S4=a("li"),the=a("strong"),qDo=o("canine"),NDo=o(" \u2014 "),oV=a("a"),jDo=o("CanineForTokenClassification"),DDo=o(" (Canine model)"),GDo=l(),R4=a("li"),ahe=a("strong"),ODo=o("convbert"),VDo=o(" \u2014 "),rV=a("a"),XDo=o("ConvBertForTokenClassification"),zDo=o(" (ConvBERT model)"),WDo=l(),P4=a("li"),nhe=a("strong"),QDo=o("data2vec-text"),HDo=o(" \u2014 "),tV=a("a"),UDo=o("Data2VecTextForTokenClassification"),JDo=o(" (Data2VecText model)"),YDo=l(),B4=a("li"),she=a("strong"),KDo=o("deberta"),ZDo=o(" \u2014 "),aV=a("a"),eGo=o("DebertaForTokenClassification"),oGo=o(" (DeBERTa model)"),rGo=l(),I4=a("li"),lhe=a("strong"),tGo=o("deberta-v2"),aGo=o(" \u2014 "),nV=a("a"),nGo=o("DebertaV2ForTokenClassification"),sGo=o(" (DeBERTa-v2 model)"),lGo=l(),q4=a("li"),ihe=a("strong"),iGo=o("distilbert"),dGo=o(" \u2014 "),sV=a("a"),cGo=o("DistilBertForTokenClassification"),fGo=o(" (DistilBERT model)"),mGo=l(),N4=a("li"),dhe=a("strong"),gGo=o("electra"),hGo=o(" \u2014 "),lV=a("a"),pGo=o("ElectraForTokenClassification"),uGo=o(" (ELECTRA model)"),_Go=l(),j4=a("li"),che=a("strong"),bGo=o("flaubert"),vGo=o(" \u2014 "),iV=a("a"),FGo=o("FlaubertForTokenClassification"),TGo=o(" (FlauBERT model)"),MGo=l(),D4=a("li"),fhe=a("strong"),EGo=o("fnet"),CGo=o(" \u2014 "),dV=a("a"),wGo=o("FNetForTokenClassification"),AGo=o(" (FNet model)"),yGo=l(),G4=a("li"),mhe=a("strong"),LGo=o("funnel"),xGo=o(" \u2014 "),cV=a("a"),$Go=o("FunnelForTokenClassification"),kGo=o(" (Funnel Transformer model)"),SGo=l(),O4=a("li"),ghe=a("strong"),RGo=o("gpt2"),PGo=o(" \u2014 "),fV=a("a"),BGo=o("GPT2ForTokenClassification"),IGo=o(" (OpenAI GPT-2 model)"),qGo=l(),V4=a("li"),hhe=a("strong"),NGo=o("ibert"),jGo=o(" \u2014 "),mV=a("a"),DGo=o("IBertForTokenClassification"),GGo=o(" (I-BERT model)"),OGo=l(),X4=a("li"),phe=a("strong"),VGo=o("layoutlm"),XGo=o(" \u2014 "),gV=a("a"),zGo=o("LayoutLMForTokenClassification"),WGo=o(" (LayoutLM model)"),QGo=l(),z4=a("li"),uhe=a("strong"),HGo=o("layoutlmv2"),UGo=o(" \u2014 "),hV=a("a"),JGo=o("LayoutLMv2ForTokenClassification"),YGo=o(" (LayoutLMv2 model)"),KGo=l(),W4=a("li"),_he=a("strong"),ZGo=o("layoutlmv3"),eOo=o(" \u2014 "),pV=a("a"),oOo=o("LayoutLMv3ForTokenClassification"),rOo=o(" (LayoutLMv3 model)"),tOo=l(),Q4=a("li"),bhe=a("strong"),aOo=o("longformer"),nOo=o(" \u2014 "),uV=a("a"),sOo=o("LongformerForTokenClassification"),lOo=o(" (Longformer model)"),iOo=l(),H4=a("li"),vhe=a("strong"),dOo=o("megatron-bert"),cOo=o(" \u2014 "),_V=a("a"),fOo=o("MegatronBertForTokenClassification"),mOo=o(" (MegatronBert model)"),gOo=l(),U4=a("li"),Fhe=a("strong"),hOo=o("mobilebert"),pOo=o(" \u2014 "),bV=a("a"),uOo=o("MobileBertForTokenClassification"),_Oo=o(" (MobileBERT model)"),bOo=l(),J4=a("li"),The=a("strong"),vOo=o("mpnet"),FOo=o(" \u2014 "),vV=a("a"),TOo=o("MPNetForTokenClassification"),MOo=o(" (MPNet model)"),EOo=l(),Y4=a("li"),Mhe=a("strong"),COo=o("nystromformer"),wOo=o(" \u2014 "),FV=a("a"),AOo=o("NystromformerForTokenClassification"),yOo=o(" (Nystromformer model)"),LOo=l(),K4=a("li"),Ehe=a("strong"),xOo=o("qdqbert"),$Oo=o(" \u2014 "),TV=a("a"),kOo=o("QDQBertForTokenClassification"),SOo=o(" (QDQBert model)"),ROo=l(),Z4=a("li"),Che=a("strong"),POo=o("rembert"),BOo=o(" \u2014 "),MV=a("a"),IOo=o("RemBertForTokenClassification"),qOo=o(" (RemBERT model)"),NOo=l(),ev=a("li"),whe=a("strong"),jOo=o("roberta"),DOo=o(" \u2014 "),EV=a("a"),GOo=o("RobertaForTokenClassification"),OOo=o(" (RoBERTa model)"),VOo=l(),ov=a("li"),Ahe=a("strong"),XOo=o("roformer"),zOo=o(" \u2014 "),CV=a("a"),WOo=o("RoFormerForTokenClassification"),QOo=o(" (RoFormer model)"),HOo=l(),rv=a("li"),yhe=a("strong"),UOo=o("squeezebert"),JOo=o(" \u2014 "),wV=a("a"),YOo=o("SqueezeBertForTokenClassification"),KOo=o(" (SqueezeBERT model)"),ZOo=l(),tv=a("li"),Lhe=a("strong"),eVo=o("xlm"),oVo=o(" \u2014 "),AV=a("a"),rVo=o("XLMForTokenClassification"),tVo=o(" (XLM model)"),aVo=l(),av=a("li"),xhe=a("strong"),nVo=o("xlm-roberta"),sVo=o(" \u2014 "),yV=a("a"),lVo=o("XLMRobertaForTokenClassification"),iVo=o(" (XLM-RoBERTa model)"),dVo=l(),nv=a("li"),$he=a("strong"),cVo=o("xlm-roberta-xl"),fVo=o(" \u2014 "),LV=a("a"),mVo=o("XLMRobertaXLForTokenClassification"),gVo=o(" (XLM-RoBERTa-XL model)"),hVo=l(),sv=a("li"),khe=a("strong"),pVo=o("xlnet"),uVo=o(" \u2014 "),xV=a("a"),_Vo=o("XLNetForTokenClassification"),bVo=o(" (XLNet model)"),vVo=l(),lv=a("li"),She=a("strong"),FVo=o("yoso"),TVo=o(" \u2014 "),$V=a("a"),MVo=o("YosoForTokenClassification"),EVo=o(" (YOSO model)"),CVo=l(),iv=a("p"),wVo=o("The model is set in evaluation mode by default using "),Rhe=a("code"),AVo=o("model.eval()"),yVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Phe=a("code"),LVo=o("model.train()"),xVo=l(),F(dv.$$.fragment),SNe=l(),od=a("h2"),cv=a("a"),Bhe=a("span"),F(Xy.$$.fragment),$Vo=l(),Ihe=a("span"),kVo=o("AutoModelForQuestionAnswering"),RNe=l(),qo=a("div"),F(zy.$$.fragment),SVo=l(),rd=a("p"),RVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),kV=a("a"),PVo=o("from_pretrained()"),BVo=o(" class method or the "),SV=a("a"),IVo=o("from_config()"),qVo=o(` class
method.`),NVo=l(),Wy=a("p"),jVo=o("This class cannot be instantiated directly using "),qhe=a("code"),DVo=o("__init__()"),GVo=o(" (throws an error)."),OVo=l(),mt=a("div"),F(Qy.$$.fragment),VVo=l(),Nhe=a("p"),XVo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),zVo=l(),td=a("p"),WVo=o(`Note:
Loading a model from its configuration file does `),jhe=a("strong"),QVo=o("not"),HVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RV=a("a"),UVo=o("from_pretrained()"),JVo=o(" to load the model weights."),YVo=l(),F(fv.$$.fragment),KVo=l(),no=a("div"),F(Hy.$$.fragment),ZVo=l(),Dhe=a("p"),eXo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),oXo=l(),qa=a("p"),rXo=o("The model class to instantiate is selected based on the "),Ghe=a("code"),tXo=o("model_type"),aXo=o(` property of the config object (either
passed as an argument or loaded from `),Ohe=a("code"),nXo=o("pretrained_model_name_or_path"),sXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vhe=a("code"),lXo=o("pretrained_model_name_or_path"),iXo=o(":"),dXo=l(),V=a("ul"),mv=a("li"),Xhe=a("strong"),cXo=o("albert"),fXo=o(" \u2014 "),PV=a("a"),mXo=o("AlbertForQuestionAnswering"),gXo=o(" (ALBERT model)"),hXo=l(),gv=a("li"),zhe=a("strong"),pXo=o("bart"),uXo=o(" \u2014 "),BV=a("a"),_Xo=o("BartForQuestionAnswering"),bXo=o(" (BART model)"),vXo=l(),hv=a("li"),Whe=a("strong"),FXo=o("bert"),TXo=o(" \u2014 "),IV=a("a"),MXo=o("BertForQuestionAnswering"),EXo=o(" (BERT model)"),CXo=l(),pv=a("li"),Qhe=a("strong"),wXo=o("big_bird"),AXo=o(" \u2014 "),qV=a("a"),yXo=o("BigBirdForQuestionAnswering"),LXo=o(" (BigBird model)"),xXo=l(),uv=a("li"),Hhe=a("strong"),$Xo=o("bigbird_pegasus"),kXo=o(" \u2014 "),NV=a("a"),SXo=o("BigBirdPegasusForQuestionAnswering"),RXo=o(" (BigBirdPegasus model)"),PXo=l(),_v=a("li"),Uhe=a("strong"),BXo=o("camembert"),IXo=o(" \u2014 "),jV=a("a"),qXo=o("CamembertForQuestionAnswering"),NXo=o(" (CamemBERT model)"),jXo=l(),bv=a("li"),Jhe=a("strong"),DXo=o("canine"),GXo=o(" \u2014 "),DV=a("a"),OXo=o("CanineForQuestionAnswering"),VXo=o(" (Canine model)"),XXo=l(),vv=a("li"),Yhe=a("strong"),zXo=o("convbert"),WXo=o(" \u2014 "),GV=a("a"),QXo=o("ConvBertForQuestionAnswering"),HXo=o(" (ConvBERT model)"),UXo=l(),Fv=a("li"),Khe=a("strong"),JXo=o("data2vec-text"),YXo=o(" \u2014 "),OV=a("a"),KXo=o("Data2VecTextForQuestionAnswering"),ZXo=o(" (Data2VecText model)"),ezo=l(),Tv=a("li"),Zhe=a("strong"),ozo=o("deberta"),rzo=o(" \u2014 "),VV=a("a"),tzo=o("DebertaForQuestionAnswering"),azo=o(" (DeBERTa model)"),nzo=l(),Mv=a("li"),epe=a("strong"),szo=o("deberta-v2"),lzo=o(" \u2014 "),XV=a("a"),izo=o("DebertaV2ForQuestionAnswering"),dzo=o(" (DeBERTa-v2 model)"),czo=l(),Ev=a("li"),ope=a("strong"),fzo=o("distilbert"),mzo=o(" \u2014 "),zV=a("a"),gzo=o("DistilBertForQuestionAnswering"),hzo=o(" (DistilBERT model)"),pzo=l(),Cv=a("li"),rpe=a("strong"),uzo=o("electra"),_zo=o(" \u2014 "),WV=a("a"),bzo=o("ElectraForQuestionAnswering"),vzo=o(" (ELECTRA model)"),Fzo=l(),wv=a("li"),tpe=a("strong"),Tzo=o("flaubert"),Mzo=o(" \u2014 "),QV=a("a"),Ezo=o("FlaubertForQuestionAnsweringSimple"),Czo=o(" (FlauBERT model)"),wzo=l(),Av=a("li"),ape=a("strong"),Azo=o("fnet"),yzo=o(" \u2014 "),HV=a("a"),Lzo=o("FNetForQuestionAnswering"),xzo=o(" (FNet model)"),$zo=l(),yv=a("li"),npe=a("strong"),kzo=o("funnel"),Szo=o(" \u2014 "),UV=a("a"),Rzo=o("FunnelForQuestionAnswering"),Pzo=o(" (Funnel Transformer model)"),Bzo=l(),Lv=a("li"),spe=a("strong"),Izo=o("gptj"),qzo=o(" \u2014 "),JV=a("a"),Nzo=o("GPTJForQuestionAnswering"),jzo=o(" (GPT-J model)"),Dzo=l(),xv=a("li"),lpe=a("strong"),Gzo=o("ibert"),Ozo=o(" \u2014 "),YV=a("a"),Vzo=o("IBertForQuestionAnswering"),Xzo=o(" (I-BERT model)"),zzo=l(),$v=a("li"),ipe=a("strong"),Wzo=o("layoutlmv2"),Qzo=o(" \u2014 "),KV=a("a"),Hzo=o("LayoutLMv2ForQuestionAnswering"),Uzo=o(" (LayoutLMv2 model)"),Jzo=l(),kv=a("li"),dpe=a("strong"),Yzo=o("layoutlmv3"),Kzo=o(" \u2014 "),ZV=a("a"),Zzo=o("LayoutLMv3ForQuestionAnswering"),eWo=o(" (LayoutLMv3 model)"),oWo=l(),Sv=a("li"),cpe=a("strong"),rWo=o("led"),tWo=o(" \u2014 "),eX=a("a"),aWo=o("LEDForQuestionAnswering"),nWo=o(" (LED model)"),sWo=l(),Rv=a("li"),fpe=a("strong"),lWo=o("longformer"),iWo=o(" \u2014 "),oX=a("a"),dWo=o("LongformerForQuestionAnswering"),cWo=o(" (Longformer model)"),fWo=l(),Pv=a("li"),mpe=a("strong"),mWo=o("lxmert"),gWo=o(" \u2014 "),rX=a("a"),hWo=o("LxmertForQuestionAnswering"),pWo=o(" (LXMERT model)"),uWo=l(),Bv=a("li"),gpe=a("strong"),_Wo=o("mbart"),bWo=o(" \u2014 "),tX=a("a"),vWo=o("MBartForQuestionAnswering"),FWo=o(" (mBART model)"),TWo=l(),Iv=a("li"),hpe=a("strong"),MWo=o("megatron-bert"),EWo=o(" \u2014 "),aX=a("a"),CWo=o("MegatronBertForQuestionAnswering"),wWo=o(" (MegatronBert model)"),AWo=l(),qv=a("li"),ppe=a("strong"),yWo=o("mobilebert"),LWo=o(" \u2014 "),nX=a("a"),xWo=o("MobileBertForQuestionAnswering"),$Wo=o(" (MobileBERT model)"),kWo=l(),Nv=a("li"),upe=a("strong"),SWo=o("mpnet"),RWo=o(" \u2014 "),sX=a("a"),PWo=o("MPNetForQuestionAnswering"),BWo=o(" (MPNet model)"),IWo=l(),jv=a("li"),_pe=a("strong"),qWo=o("nystromformer"),NWo=o(" \u2014 "),lX=a("a"),jWo=o("NystromformerForQuestionAnswering"),DWo=o(" (Nystromformer model)"),GWo=l(),Dv=a("li"),bpe=a("strong"),OWo=o("qdqbert"),VWo=o(" \u2014 "),iX=a("a"),XWo=o("QDQBertForQuestionAnswering"),zWo=o(" (QDQBert model)"),WWo=l(),Gv=a("li"),vpe=a("strong"),QWo=o("reformer"),HWo=o(" \u2014 "),dX=a("a"),UWo=o("ReformerForQuestionAnswering"),JWo=o(" (Reformer model)"),YWo=l(),Ov=a("li"),Fpe=a("strong"),KWo=o("rembert"),ZWo=o(" \u2014 "),cX=a("a"),eQo=o("RemBertForQuestionAnswering"),oQo=o(" (RemBERT model)"),rQo=l(),Vv=a("li"),Tpe=a("strong"),tQo=o("roberta"),aQo=o(" \u2014 "),fX=a("a"),nQo=o("RobertaForQuestionAnswering"),sQo=o(" (RoBERTa model)"),lQo=l(),Xv=a("li"),Mpe=a("strong"),iQo=o("roformer"),dQo=o(" \u2014 "),mX=a("a"),cQo=o("RoFormerForQuestionAnswering"),fQo=o(" (RoFormer model)"),mQo=l(),zv=a("li"),Epe=a("strong"),gQo=o("splinter"),hQo=o(" \u2014 "),gX=a("a"),pQo=o("SplinterForQuestionAnswering"),uQo=o(" (Splinter model)"),_Qo=l(),Wv=a("li"),Cpe=a("strong"),bQo=o("squeezebert"),vQo=o(" \u2014 "),hX=a("a"),FQo=o("SqueezeBertForQuestionAnswering"),TQo=o(" (SqueezeBERT model)"),MQo=l(),Qv=a("li"),wpe=a("strong"),EQo=o("xlm"),CQo=o(" \u2014 "),pX=a("a"),wQo=o("XLMForQuestionAnsweringSimple"),AQo=o(" (XLM model)"),yQo=l(),Hv=a("li"),Ape=a("strong"),LQo=o("xlm-roberta"),xQo=o(" \u2014 "),uX=a("a"),$Qo=o("XLMRobertaForQuestionAnswering"),kQo=o(" (XLM-RoBERTa model)"),SQo=l(),Uv=a("li"),ype=a("strong"),RQo=o("xlm-roberta-xl"),PQo=o(" \u2014 "),_X=a("a"),BQo=o("XLMRobertaXLForQuestionAnswering"),IQo=o(" (XLM-RoBERTa-XL model)"),qQo=l(),Jv=a("li"),Lpe=a("strong"),NQo=o("xlnet"),jQo=o(" \u2014 "),bX=a("a"),DQo=o("XLNetForQuestionAnsweringSimple"),GQo=o(" (XLNet model)"),OQo=l(),Yv=a("li"),xpe=a("strong"),VQo=o("yoso"),XQo=o(" \u2014 "),vX=a("a"),zQo=o("YosoForQuestionAnswering"),WQo=o(" (YOSO model)"),QQo=l(),Kv=a("p"),HQo=o("The model is set in evaluation mode by default using "),$pe=a("code"),UQo=o("model.eval()"),JQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kpe=a("code"),YQo=o("model.train()"),KQo=l(),F(Zv.$$.fragment),PNe=l(),ad=a("h2"),e5=a("a"),Spe=a("span"),F(Uy.$$.fragment),ZQo=l(),Rpe=a("span"),eHo=o("AutoModelForTableQuestionAnswering"),BNe=l(),No=a("div"),F(Jy.$$.fragment),oHo=l(),nd=a("p"),rHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),FX=a("a"),tHo=o("from_pretrained()"),aHo=o(" class method or the "),TX=a("a"),nHo=o("from_config()"),sHo=o(` class
method.`),lHo=l(),Yy=a("p"),iHo=o("This class cannot be instantiated directly using "),Ppe=a("code"),dHo=o("__init__()"),cHo=o(" (throws an error)."),fHo=l(),gt=a("div"),F(Ky.$$.fragment),mHo=l(),Bpe=a("p"),gHo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),hHo=l(),sd=a("p"),pHo=o(`Note:
Loading a model from its configuration file does `),Ipe=a("strong"),uHo=o("not"),_Ho=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=a("a"),bHo=o("from_pretrained()"),vHo=o(" to load the model weights."),FHo=l(),F(o5.$$.fragment),THo=l(),so=a("div"),F(Zy.$$.fragment),MHo=l(),qpe=a("p"),EHo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),CHo=l(),Na=a("p"),wHo=o("The model class to instantiate is selected based on the "),Npe=a("code"),AHo=o("model_type"),yHo=o(` property of the config object (either
passed as an argument or loaded from `),jpe=a("code"),LHo=o("pretrained_model_name_or_path"),xHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dpe=a("code"),$Ho=o("pretrained_model_name_or_path"),kHo=o(":"),SHo=l(),Gpe=a("ul"),r5=a("li"),Ope=a("strong"),RHo=o("tapas"),PHo=o(" \u2014 "),EX=a("a"),BHo=o("TapasForQuestionAnswering"),IHo=o(" (TAPAS model)"),qHo=l(),t5=a("p"),NHo=o("The model is set in evaluation mode by default using "),Vpe=a("code"),jHo=o("model.eval()"),DHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xpe=a("code"),GHo=o("model.train()"),OHo=l(),F(a5.$$.fragment),INe=l(),ld=a("h2"),n5=a("a"),zpe=a("span"),F(eL.$$.fragment),VHo=l(),Wpe=a("span"),XHo=o("AutoModelForImageClassification"),qNe=l(),jo=a("div"),F(oL.$$.fragment),zHo=l(),id=a("p"),WHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),CX=a("a"),QHo=o("from_pretrained()"),HHo=o(" class method or the "),wX=a("a"),UHo=o("from_config()"),JHo=o(` class
method.`),YHo=l(),rL=a("p"),KHo=o("This class cannot be instantiated directly using "),Qpe=a("code"),ZHo=o("__init__()"),eUo=o(" (throws an error)."),oUo=l(),ht=a("div"),F(tL.$$.fragment),rUo=l(),Hpe=a("p"),tUo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),aUo=l(),dd=a("p"),nUo=o(`Note:
Loading a model from its configuration file does `),Upe=a("strong"),sUo=o("not"),lUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AX=a("a"),iUo=o("from_pretrained()"),dUo=o(" to load the model weights."),cUo=l(),F(s5.$$.fragment),fUo=l(),lo=a("div"),F(aL.$$.fragment),mUo=l(),Jpe=a("p"),gUo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),hUo=l(),ja=a("p"),pUo=o("The model class to instantiate is selected based on the "),Ype=a("code"),uUo=o("model_type"),_Uo=o(` property of the config object (either
passed as an argument or loaded from `),Kpe=a("code"),bUo=o("pretrained_model_name_or_path"),vUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zpe=a("code"),FUo=o("pretrained_model_name_or_path"),TUo=o(":"),MUo=l(),Fe=a("ul"),l5=a("li"),eue=a("strong"),EUo=o("beit"),CUo=o(" \u2014 "),yX=a("a"),wUo=o("BeitForImageClassification"),AUo=o(" (BEiT model)"),yUo=l(),i5=a("li"),oue=a("strong"),LUo=o("convnext"),xUo=o(" \u2014 "),LX=a("a"),$Uo=o("ConvNextForImageClassification"),kUo=o(" (ConvNext model)"),SUo=l(),d5=a("li"),rue=a("strong"),RUo=o("cvt"),PUo=o(" \u2014 "),xX=a("a"),BUo=o("CvtForImageClassification"),IUo=o(" (CvT model)"),qUo=l(),c5=a("li"),tue=a("strong"),NUo=o("data2vec-vision"),jUo=o(" \u2014 "),$X=a("a"),DUo=o("Data2VecVisionForImageClassification"),GUo=o(" (Data2VecVision model)"),OUo=l(),Ns=a("li"),aue=a("strong"),VUo=o("deit"),XUo=o(" \u2014 "),kX=a("a"),zUo=o("DeiTForImageClassification"),WUo=o(" or "),SX=a("a"),QUo=o("DeiTForImageClassificationWithTeacher"),HUo=o(" (DeiT model)"),UUo=l(),f5=a("li"),nue=a("strong"),JUo=o("imagegpt"),YUo=o(" \u2014 "),RX=a("a"),KUo=o("ImageGPTForImageClassification"),ZUo=o(" (ImageGPT model)"),eJo=l(),pt=a("li"),sue=a("strong"),oJo=o("perceiver"),rJo=o(" \u2014 "),PX=a("a"),tJo=o("PerceiverForImageClassificationLearned"),aJo=o(" or "),BX=a("a"),nJo=o("PerceiverForImageClassificationFourier"),sJo=o(" or "),IX=a("a"),lJo=o("PerceiverForImageClassificationConvProcessing"),iJo=o(" (Perceiver model)"),dJo=l(),m5=a("li"),lue=a("strong"),cJo=o("poolformer"),fJo=o(" \u2014 "),qX=a("a"),mJo=o("PoolFormerForImageClassification"),gJo=o(" (PoolFormer model)"),hJo=l(),g5=a("li"),iue=a("strong"),pJo=o("regnet"),uJo=o(" \u2014 "),NX=a("a"),_Jo=o("RegNetForImageClassification"),bJo=o(" (RegNet model)"),vJo=l(),h5=a("li"),due=a("strong"),FJo=o("resnet"),TJo=o(" \u2014 "),jX=a("a"),MJo=o("ResNetForImageClassification"),EJo=o(" (ResNet model)"),CJo=l(),p5=a("li"),cue=a("strong"),wJo=o("segformer"),AJo=o(" \u2014 "),DX=a("a"),yJo=o("SegformerForImageClassification"),LJo=o(" (SegFormer model)"),xJo=l(),u5=a("li"),fue=a("strong"),$Jo=o("swin"),kJo=o(" \u2014 "),GX=a("a"),SJo=o("SwinForImageClassification"),RJo=o(" (Swin model)"),PJo=l(),_5=a("li"),mue=a("strong"),BJo=o("van"),IJo=o(" \u2014 "),OX=a("a"),qJo=o("VanForImageClassification"),NJo=o(" (VAN model)"),jJo=l(),b5=a("li"),gue=a("strong"),DJo=o("vit"),GJo=o(" \u2014 "),VX=a("a"),OJo=o("ViTForImageClassification"),VJo=o(" (ViT model)"),XJo=l(),v5=a("p"),zJo=o("The model is set in evaluation mode by default using "),hue=a("code"),WJo=o("model.eval()"),QJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pue=a("code"),HJo=o("model.train()"),UJo=l(),F(F5.$$.fragment),NNe=l(),cd=a("h2"),T5=a("a"),uue=a("span"),F(nL.$$.fragment),JJo=l(),_ue=a("span"),YJo=o("AutoModelForVision2Seq"),jNe=l(),Do=a("div"),F(sL.$$.fragment),KJo=l(),fd=a("p"),ZJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),XX=a("a"),eYo=o("from_pretrained()"),oYo=o(" class method or the "),zX=a("a"),rYo=o("from_config()"),tYo=o(` class
method.`),aYo=l(),lL=a("p"),nYo=o("This class cannot be instantiated directly using "),bue=a("code"),sYo=o("__init__()"),lYo=o(" (throws an error)."),iYo=l(),ut=a("div"),F(iL.$$.fragment),dYo=l(),vue=a("p"),cYo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),fYo=l(),md=a("p"),mYo=o(`Note:
Loading a model from its configuration file does `),Fue=a("strong"),gYo=o("not"),hYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WX=a("a"),pYo=o("from_pretrained()"),uYo=o(" to load the model weights."),_Yo=l(),F(M5.$$.fragment),bYo=l(),io=a("div"),F(dL.$$.fragment),vYo=l(),Tue=a("p"),FYo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),TYo=l(),Da=a("p"),MYo=o("The model class to instantiate is selected based on the "),Mue=a("code"),EYo=o("model_type"),CYo=o(` property of the config object (either
passed as an argument or loaded from `),Eue=a("code"),wYo=o("pretrained_model_name_or_path"),AYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cue=a("code"),yYo=o("pretrained_model_name_or_path"),LYo=o(":"),xYo=l(),wue=a("ul"),E5=a("li"),Aue=a("strong"),$Yo=o("vision-encoder-decoder"),kYo=o(" \u2014 "),QX=a("a"),SYo=o("VisionEncoderDecoderModel"),RYo=o(" (Vision Encoder decoder model)"),PYo=l(),C5=a("p"),BYo=o("The model is set in evaluation mode by default using "),yue=a("code"),IYo=o("model.eval()"),qYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lue=a("code"),NYo=o("model.train()"),jYo=l(),F(w5.$$.fragment),DNe=l(),gd=a("h2"),A5=a("a"),xue=a("span"),F(cL.$$.fragment),DYo=l(),$ue=a("span"),GYo=o("AutoModelForAudioClassification"),GNe=l(),Go=a("div"),F(fL.$$.fragment),OYo=l(),hd=a("p"),VYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),HX=a("a"),XYo=o("from_pretrained()"),zYo=o(" class method or the "),UX=a("a"),WYo=o("from_config()"),QYo=o(` class
method.`),HYo=l(),mL=a("p"),UYo=o("This class cannot be instantiated directly using "),kue=a("code"),JYo=o("__init__()"),YYo=o(" (throws an error)."),KYo=l(),_t=a("div"),F(gL.$$.fragment),ZYo=l(),Sue=a("p"),eKo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),oKo=l(),pd=a("p"),rKo=o(`Note:
Loading a model from its configuration file does `),Rue=a("strong"),tKo=o("not"),aKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=a("a"),nKo=o("from_pretrained()"),sKo=o(" to load the model weights."),lKo=l(),F(y5.$$.fragment),iKo=l(),co=a("div"),F(hL.$$.fragment),dKo=l(),Pue=a("p"),cKo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),fKo=l(),Ga=a("p"),mKo=o("The model class to instantiate is selected based on the "),Bue=a("code"),gKo=o("model_type"),hKo=o(` property of the config object (either
passed as an argument or loaded from `),Iue=a("code"),pKo=o("pretrained_model_name_or_path"),uKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),que=a("code"),_Ko=o("pretrained_model_name_or_path"),bKo=o(":"),vKo=l(),ke=a("ul"),L5=a("li"),Nue=a("strong"),FKo=o("data2vec-audio"),TKo=o(" \u2014 "),YX=a("a"),MKo=o("Data2VecAudioForSequenceClassification"),EKo=o(" (Data2VecAudio model)"),CKo=l(),x5=a("li"),jue=a("strong"),wKo=o("hubert"),AKo=o(" \u2014 "),KX=a("a"),yKo=o("HubertForSequenceClassification"),LKo=o(" (Hubert model)"),xKo=l(),$5=a("li"),Due=a("strong"),$Ko=o("sew"),kKo=o(" \u2014 "),ZX=a("a"),SKo=o("SEWForSequenceClassification"),RKo=o(" (SEW model)"),PKo=l(),k5=a("li"),Gue=a("strong"),BKo=o("sew-d"),IKo=o(" \u2014 "),ez=a("a"),qKo=o("SEWDForSequenceClassification"),NKo=o(" (SEW-D model)"),jKo=l(),S5=a("li"),Oue=a("strong"),DKo=o("unispeech"),GKo=o(" \u2014 "),oz=a("a"),OKo=o("UniSpeechForSequenceClassification"),VKo=o(" (UniSpeech model)"),XKo=l(),R5=a("li"),Vue=a("strong"),zKo=o("unispeech-sat"),WKo=o(" \u2014 "),rz=a("a"),QKo=o("UniSpeechSatForSequenceClassification"),HKo=o(" (UniSpeechSat model)"),UKo=l(),P5=a("li"),Xue=a("strong"),JKo=o("wav2vec2"),YKo=o(" \u2014 "),tz=a("a"),KKo=o("Wav2Vec2ForSequenceClassification"),ZKo=o(" (Wav2Vec2 model)"),eZo=l(),B5=a("li"),zue=a("strong"),oZo=o("wav2vec2-conformer"),rZo=o(" \u2014 "),az=a("a"),tZo=o("Wav2Vec2ConformerForSequenceClassification"),aZo=o(" (Wav2Vec2-Conformer model)"),nZo=l(),I5=a("li"),Wue=a("strong"),sZo=o("wavlm"),lZo=o(" \u2014 "),nz=a("a"),iZo=o("WavLMForSequenceClassification"),dZo=o(" (WavLM model)"),cZo=l(),q5=a("p"),fZo=o("The model is set in evaluation mode by default using "),Que=a("code"),mZo=o("model.eval()"),gZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hue=a("code"),hZo=o("model.train()"),pZo=l(),F(N5.$$.fragment),ONe=l(),ud=a("h2"),j5=a("a"),Uue=a("span"),F(pL.$$.fragment),uZo=l(),Jue=a("span"),_Zo=o("AutoModelForAudioFrameClassification"),VNe=l(),Oo=a("div"),F(uL.$$.fragment),bZo=l(),_d=a("p"),vZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),sz=a("a"),FZo=o("from_pretrained()"),TZo=o(" class method or the "),lz=a("a"),MZo=o("from_config()"),EZo=o(` class
method.`),CZo=l(),_L=a("p"),wZo=o("This class cannot be instantiated directly using "),Yue=a("code"),AZo=o("__init__()"),yZo=o(" (throws an error)."),LZo=l(),bt=a("div"),F(bL.$$.fragment),xZo=l(),Kue=a("p"),$Zo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),kZo=l(),bd=a("p"),SZo=o(`Note:
Loading a model from its configuration file does `),Zue=a("strong"),RZo=o("not"),PZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=a("a"),BZo=o("from_pretrained()"),IZo=o(" to load the model weights."),qZo=l(),F(D5.$$.fragment),NZo=l(),fo=a("div"),F(vL.$$.fragment),jZo=l(),e_e=a("p"),DZo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),GZo=l(),Oa=a("p"),OZo=o("The model class to instantiate is selected based on the "),o_e=a("code"),VZo=o("model_type"),XZo=o(` property of the config object (either
passed as an argument or loaded from `),r_e=a("code"),zZo=o("pretrained_model_name_or_path"),WZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t_e=a("code"),QZo=o("pretrained_model_name_or_path"),HZo=o(":"),UZo=l(),Kr=a("ul"),G5=a("li"),a_e=a("strong"),JZo=o("data2vec-audio"),YZo=o(" \u2014 "),dz=a("a"),KZo=o("Data2VecAudioForAudioFrameClassification"),ZZo=o(" (Data2VecAudio model)"),eer=l(),O5=a("li"),n_e=a("strong"),oer=o("unispeech-sat"),rer=o(" \u2014 "),cz=a("a"),ter=o("UniSpeechSatForAudioFrameClassification"),aer=o(" (UniSpeechSat model)"),ner=l(),V5=a("li"),s_e=a("strong"),ser=o("wav2vec2"),ler=o(" \u2014 "),fz=a("a"),ier=o("Wav2Vec2ForAudioFrameClassification"),der=o(" (Wav2Vec2 model)"),cer=l(),X5=a("li"),l_e=a("strong"),fer=o("wav2vec2-conformer"),mer=o(" \u2014 "),mz=a("a"),ger=o("Wav2Vec2ConformerForAudioFrameClassification"),her=o(" (Wav2Vec2-Conformer model)"),per=l(),z5=a("li"),i_e=a("strong"),uer=o("wavlm"),_er=o(" \u2014 "),gz=a("a"),ber=o("WavLMForAudioFrameClassification"),ver=o(" (WavLM model)"),Fer=l(),W5=a("p"),Ter=o("The model is set in evaluation mode by default using "),d_e=a("code"),Mer=o("model.eval()"),Eer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=a("code"),Cer=o("model.train()"),wer=l(),F(Q5.$$.fragment),XNe=l(),vd=a("h2"),H5=a("a"),f_e=a("span"),F(FL.$$.fragment),Aer=l(),m_e=a("span"),yer=o("AutoModelForCTC"),zNe=l(),Vo=a("div"),F(TL.$$.fragment),Ler=l(),Fd=a("p"),xer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),hz=a("a"),$er=o("from_pretrained()"),ker=o(" class method or the "),pz=a("a"),Ser=o("from_config()"),Rer=o(` class
method.`),Per=l(),ML=a("p"),Ber=o("This class cannot be instantiated directly using "),g_e=a("code"),Ier=o("__init__()"),qer=o(" (throws an error)."),Ner=l(),vt=a("div"),F(EL.$$.fragment),jer=l(),h_e=a("p"),Der=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Ger=l(),Td=a("p"),Oer=o(`Note:
Loading a model from its configuration file does `),p_e=a("strong"),Ver=o("not"),Xer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uz=a("a"),zer=o("from_pretrained()"),Wer=o(" to load the model weights."),Qer=l(),F(U5.$$.fragment),Her=l(),mo=a("div"),F(CL.$$.fragment),Uer=l(),u_e=a("p"),Jer=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Yer=l(),Va=a("p"),Ker=o("The model class to instantiate is selected based on the "),__e=a("code"),Zer=o("model_type"),eor=o(` property of the config object (either
passed as an argument or loaded from `),b_e=a("code"),oor=o("pretrained_model_name_or_path"),ror=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v_e=a("code"),tor=o("pretrained_model_name_or_path"),aor=o(":"),nor=l(),Se=a("ul"),J5=a("li"),F_e=a("strong"),sor=o("data2vec-audio"),lor=o(" \u2014 "),_z=a("a"),ior=o("Data2VecAudioForCTC"),dor=o(" (Data2VecAudio model)"),cor=l(),Y5=a("li"),T_e=a("strong"),mor=o("hubert"),gor=o(" \u2014 "),bz=a("a"),hor=o("HubertForCTC"),por=o(" (Hubert model)"),uor=l(),K5=a("li"),M_e=a("strong"),_or=o("sew"),bor=o(" \u2014 "),vz=a("a"),vor=o("SEWForCTC"),For=o(" (SEW model)"),Tor=l(),Z5=a("li"),E_e=a("strong"),Mor=o("sew-d"),Eor=o(" \u2014 "),Fz=a("a"),Cor=o("SEWDForCTC"),wor=o(" (SEW-D model)"),Aor=l(),eF=a("li"),C_e=a("strong"),yor=o("unispeech"),Lor=o(" \u2014 "),Tz=a("a"),xor=o("UniSpeechForCTC"),$or=o(" (UniSpeech model)"),kor=l(),oF=a("li"),w_e=a("strong"),Sor=o("unispeech-sat"),Ror=o(" \u2014 "),Mz=a("a"),Por=o("UniSpeechSatForCTC"),Bor=o(" (UniSpeechSat model)"),Ior=l(),rF=a("li"),A_e=a("strong"),qor=o("wav2vec2"),Nor=o(" \u2014 "),Ez=a("a"),jor=o("Wav2Vec2ForCTC"),Dor=o(" (Wav2Vec2 model)"),Gor=l(),tF=a("li"),y_e=a("strong"),Oor=o("wav2vec2-conformer"),Vor=o(" \u2014 "),Cz=a("a"),Xor=o("Wav2Vec2ConformerForCTC"),zor=o(" (Wav2Vec2-Conformer model)"),Wor=l(),aF=a("li"),L_e=a("strong"),Qor=o("wavlm"),Hor=o(" \u2014 "),wz=a("a"),Uor=o("WavLMForCTC"),Jor=o(" (WavLM model)"),Yor=l(),nF=a("p"),Kor=o("The model is set in evaluation mode by default using "),x_e=a("code"),Zor=o("model.eval()"),err=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$_e=a("code"),orr=o("model.train()"),rrr=l(),F(sF.$$.fragment),WNe=l(),Md=a("h2"),lF=a("a"),k_e=a("span"),F(wL.$$.fragment),trr=l(),S_e=a("span"),arr=o("AutoModelForSpeechSeq2Seq"),QNe=l(),Xo=a("div"),F(AL.$$.fragment),nrr=l(),Ed=a("p"),srr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Az=a("a"),lrr=o("from_pretrained()"),irr=o(" class method or the "),yz=a("a"),drr=o("from_config()"),crr=o(` class
method.`),frr=l(),yL=a("p"),mrr=o("This class cannot be instantiated directly using "),R_e=a("code"),grr=o("__init__()"),hrr=o(" (throws an error)."),prr=l(),Ft=a("div"),F(LL.$$.fragment),urr=l(),P_e=a("p"),_rr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),brr=l(),Cd=a("p"),vrr=o(`Note:
Loading a model from its configuration file does `),B_e=a("strong"),Frr=o("not"),Trr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=a("a"),Mrr=o("from_pretrained()"),Err=o(" to load the model weights."),Crr=l(),F(iF.$$.fragment),wrr=l(),go=a("div"),F(xL.$$.fragment),Arr=l(),I_e=a("p"),yrr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Lrr=l(),Xa=a("p"),xrr=o("The model class to instantiate is selected based on the "),q_e=a("code"),$rr=o("model_type"),krr=o(` property of the config object (either
passed as an argument or loaded from `),N_e=a("code"),Srr=o("pretrained_model_name_or_path"),Rrr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j_e=a("code"),Prr=o("pretrained_model_name_or_path"),Brr=o(":"),Irr=l(),$L=a("ul"),dF=a("li"),D_e=a("strong"),qrr=o("speech-encoder-decoder"),Nrr=o(" \u2014 "),xz=a("a"),jrr=o("SpeechEncoderDecoderModel"),Drr=o(" (Speech Encoder decoder model)"),Grr=l(),cF=a("li"),G_e=a("strong"),Orr=o("speech_to_text"),Vrr=o(" \u2014 "),$z=a("a"),Xrr=o("Speech2TextForConditionalGeneration"),zrr=o(" (Speech2Text model)"),Wrr=l(),fF=a("p"),Qrr=o("The model is set in evaluation mode by default using "),O_e=a("code"),Hrr=o("model.eval()"),Urr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V_e=a("code"),Jrr=o("model.train()"),Yrr=l(),F(mF.$$.fragment),HNe=l(),wd=a("h2"),gF=a("a"),X_e=a("span"),F(kL.$$.fragment),Krr=l(),z_e=a("span"),Zrr=o("AutoModelForAudioXVector"),UNe=l(),zo=a("div"),F(SL.$$.fragment),etr=l(),Ad=a("p"),otr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),kz=a("a"),rtr=o("from_pretrained()"),ttr=o(" class method or the "),Sz=a("a"),atr=o("from_config()"),ntr=o(` class
method.`),str=l(),RL=a("p"),ltr=o("This class cannot be instantiated directly using "),W_e=a("code"),itr=o("__init__()"),dtr=o(" (throws an error)."),ctr=l(),Tt=a("div"),F(PL.$$.fragment),ftr=l(),Q_e=a("p"),mtr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),gtr=l(),yd=a("p"),htr=o(`Note:
Loading a model from its configuration file does `),H_e=a("strong"),ptr=o("not"),utr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rz=a("a"),_tr=o("from_pretrained()"),btr=o(" to load the model weights."),vtr=l(),F(hF.$$.fragment),Ftr=l(),ho=a("div"),F(BL.$$.fragment),Ttr=l(),U_e=a("p"),Mtr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Etr=l(),za=a("p"),Ctr=o("The model class to instantiate is selected based on the "),J_e=a("code"),wtr=o("model_type"),Atr=o(` property of the config object (either
passed as an argument or loaded from `),Y_e=a("code"),ytr=o("pretrained_model_name_or_path"),Ltr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K_e=a("code"),xtr=o("pretrained_model_name_or_path"),$tr=o(":"),ktr=l(),Zr=a("ul"),pF=a("li"),Z_e=a("strong"),Str=o("data2vec-audio"),Rtr=o(" \u2014 "),Pz=a("a"),Ptr=o("Data2VecAudioForXVector"),Btr=o(" (Data2VecAudio model)"),Itr=l(),uF=a("li"),e2e=a("strong"),qtr=o("unispeech-sat"),Ntr=o(" \u2014 "),Bz=a("a"),jtr=o("UniSpeechSatForXVector"),Dtr=o(" (UniSpeechSat model)"),Gtr=l(),_F=a("li"),o2e=a("strong"),Otr=o("wav2vec2"),Vtr=o(" \u2014 "),Iz=a("a"),Xtr=o("Wav2Vec2ForXVector"),ztr=o(" (Wav2Vec2 model)"),Wtr=l(),bF=a("li"),r2e=a("strong"),Qtr=o("wav2vec2-conformer"),Htr=o(" \u2014 "),qz=a("a"),Utr=o("Wav2Vec2ConformerForXVector"),Jtr=o(" (Wav2Vec2-Conformer model)"),Ytr=l(),vF=a("li"),t2e=a("strong"),Ktr=o("wavlm"),Ztr=o(" \u2014 "),Nz=a("a"),ear=o("WavLMForXVector"),oar=o(" (WavLM model)"),rar=l(),FF=a("p"),tar=o("The model is set in evaluation mode by default using "),a2e=a("code"),aar=o("model.eval()"),nar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n2e=a("code"),sar=o("model.train()"),lar=l(),F(TF.$$.fragment),JNe=l(),Ld=a("h2"),MF=a("a"),s2e=a("span"),F(IL.$$.fragment),iar=l(),l2e=a("span"),dar=o("AutoModelForMaskedImageModeling"),YNe=l(),Wo=a("div"),F(qL.$$.fragment),car=l(),xd=a("p"),far=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),jz=a("a"),mar=o("from_pretrained()"),gar=o(" class method or the "),Dz=a("a"),har=o("from_config()"),par=o(` class
method.`),uar=l(),NL=a("p"),_ar=o("This class cannot be instantiated directly using "),i2e=a("code"),bar=o("__init__()"),Far=o(" (throws an error)."),Tar=l(),Mt=a("div"),F(jL.$$.fragment),Mar=l(),d2e=a("p"),Ear=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Car=l(),$d=a("p"),war=o(`Note:
Loading a model from its configuration file does `),c2e=a("strong"),Aar=o("not"),yar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gz=a("a"),Lar=o("from_pretrained()"),xar=o(" to load the model weights."),$ar=l(),F(EF.$$.fragment),kar=l(),po=a("div"),F(DL.$$.fragment),Sar=l(),f2e=a("p"),Rar=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Par=l(),Wa=a("p"),Bar=o("The model class to instantiate is selected based on the "),m2e=a("code"),Iar=o("model_type"),qar=o(` property of the config object (either
passed as an argument or loaded from `),g2e=a("code"),Nar=o("pretrained_model_name_or_path"),jar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h2e=a("code"),Dar=o("pretrained_model_name_or_path"),Gar=o(":"),Oar=l(),kd=a("ul"),CF=a("li"),p2e=a("strong"),Var=o("deit"),Xar=o(" \u2014 "),Oz=a("a"),zar=o("DeiTForMaskedImageModeling"),War=o(" (DeiT model)"),Qar=l(),wF=a("li"),u2e=a("strong"),Har=o("swin"),Uar=o(" \u2014 "),Vz=a("a"),Jar=o("SwinForMaskedImageModeling"),Yar=o(" (Swin model)"),Kar=l(),AF=a("li"),_2e=a("strong"),Zar=o("vit"),enr=o(" \u2014 "),Xz=a("a"),onr=o("ViTForMaskedImageModeling"),rnr=o(" (ViT model)"),tnr=l(),yF=a("p"),anr=o("The model is set in evaluation mode by default using "),b2e=a("code"),nnr=o("model.eval()"),snr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v2e=a("code"),lnr=o("model.train()"),inr=l(),F(LF.$$.fragment),KNe=l(),Sd=a("h2"),xF=a("a"),F2e=a("span"),F(GL.$$.fragment),dnr=l(),T2e=a("span"),cnr=o("AutoModelForObjectDetection"),ZNe=l(),Qo=a("div"),F(OL.$$.fragment),fnr=l(),Rd=a("p"),mnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),zz=a("a"),gnr=o("from_pretrained()"),hnr=o(" class method or the "),Wz=a("a"),pnr=o("from_config()"),unr=o(` class
method.`),_nr=l(),VL=a("p"),bnr=o("This class cannot be instantiated directly using "),M2e=a("code"),vnr=o("__init__()"),Fnr=o(" (throws an error)."),Tnr=l(),Et=a("div"),F(XL.$$.fragment),Mnr=l(),E2e=a("p"),Enr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Cnr=l(),Pd=a("p"),wnr=o(`Note:
Loading a model from its configuration file does `),C2e=a("strong"),Anr=o("not"),ynr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qz=a("a"),Lnr=o("from_pretrained()"),xnr=o(" to load the model weights."),$nr=l(),F($F.$$.fragment),knr=l(),uo=a("div"),F(zL.$$.fragment),Snr=l(),w2e=a("p"),Rnr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Pnr=l(),Qa=a("p"),Bnr=o("The model class to instantiate is selected based on the "),A2e=a("code"),Inr=o("model_type"),qnr=o(` property of the config object (either
passed as an argument or loaded from `),y2e=a("code"),Nnr=o("pretrained_model_name_or_path"),jnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=a("code"),Dnr=o("pretrained_model_name_or_path"),Gnr=o(":"),Onr=l(),WL=a("ul"),kF=a("li"),x2e=a("strong"),Vnr=o("detr"),Xnr=o(" \u2014 "),Hz=a("a"),znr=o("DetrForObjectDetection"),Wnr=o(" (DETR model)"),Qnr=l(),SF=a("li"),$2e=a("strong"),Hnr=o("yolos"),Unr=o(" \u2014 "),Uz=a("a"),Jnr=o("YolosForObjectDetection"),Ynr=o(" (YOLOS model)"),Knr=l(),RF=a("p"),Znr=o("The model is set in evaluation mode by default using "),k2e=a("code"),esr=o("model.eval()"),osr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S2e=a("code"),rsr=o("model.train()"),tsr=l(),F(PF.$$.fragment),eje=l(),Bd=a("h2"),BF=a("a"),R2e=a("span"),F(QL.$$.fragment),asr=l(),P2e=a("span"),nsr=o("AutoModelForImageSegmentation"),oje=l(),Ho=a("div"),F(HL.$$.fragment),ssr=l(),Id=a("p"),lsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Jz=a("a"),isr=o("from_pretrained()"),dsr=o(" class method or the "),Yz=a("a"),csr=o("from_config()"),fsr=o(` class
method.`),msr=l(),UL=a("p"),gsr=o("This class cannot be instantiated directly using "),B2e=a("code"),hsr=o("__init__()"),psr=o(" (throws an error)."),usr=l(),Ct=a("div"),F(JL.$$.fragment),_sr=l(),I2e=a("p"),bsr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),vsr=l(),qd=a("p"),Fsr=o(`Note:
Loading a model from its configuration file does `),q2e=a("strong"),Tsr=o("not"),Msr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kz=a("a"),Esr=o("from_pretrained()"),Csr=o(" to load the model weights."),wsr=l(),F(IF.$$.fragment),Asr=l(),_o=a("div"),F(YL.$$.fragment),ysr=l(),N2e=a("p"),Lsr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),xsr=l(),Ha=a("p"),$sr=o("The model class to instantiate is selected based on the "),j2e=a("code"),ksr=o("model_type"),Ssr=o(` property of the config object (either
passed as an argument or loaded from `),D2e=a("code"),Rsr=o("pretrained_model_name_or_path"),Psr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G2e=a("code"),Bsr=o("pretrained_model_name_or_path"),Isr=o(":"),qsr=l(),O2e=a("ul"),qF=a("li"),V2e=a("strong"),Nsr=o("detr"),jsr=o(" \u2014 "),Zz=a("a"),Dsr=o("DetrForSegmentation"),Gsr=o(" (DETR model)"),Osr=l(),NF=a("p"),Vsr=o("The model is set in evaluation mode by default using "),X2e=a("code"),Xsr=o("model.eval()"),zsr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z2e=a("code"),Wsr=o("model.train()"),Qsr=l(),F(jF.$$.fragment),rje=l(),Nd=a("h2"),DF=a("a"),W2e=a("span"),F(KL.$$.fragment),Hsr=l(),Q2e=a("span"),Usr=o("AutoModelForSemanticSegmentation"),tje=l(),Uo=a("div"),F(ZL.$$.fragment),Jsr=l(),jd=a("p"),Ysr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),eW=a("a"),Ksr=o("from_pretrained()"),Zsr=o(" class method or the "),oW=a("a"),elr=o("from_config()"),olr=o(` class
method.`),rlr=l(),e8=a("p"),tlr=o("This class cannot be instantiated directly using "),H2e=a("code"),alr=o("__init__()"),nlr=o(" (throws an error)."),slr=l(),wt=a("div"),F(o8.$$.fragment),llr=l(),U2e=a("p"),ilr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),dlr=l(),Dd=a("p"),clr=o(`Note:
Loading a model from its configuration file does `),J2e=a("strong"),flr=o("not"),mlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=a("a"),glr=o("from_pretrained()"),hlr=o(" to load the model weights."),plr=l(),F(GF.$$.fragment),ulr=l(),bo=a("div"),F(r8.$$.fragment),_lr=l(),Y2e=a("p"),blr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),vlr=l(),Ua=a("p"),Flr=o("The model class to instantiate is selected based on the "),K2e=a("code"),Tlr=o("model_type"),Mlr=o(` property of the config object (either
passed as an argument or loaded from `),Z2e=a("code"),Elr=o("pretrained_model_name_or_path"),Clr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e1e=a("code"),wlr=o("pretrained_model_name_or_path"),Alr=o(":"),ylr=l(),Ja=a("ul"),OF=a("li"),o1e=a("strong"),Llr=o("beit"),xlr=o(" \u2014 "),tW=a("a"),$lr=o("BeitForSemanticSegmentation"),klr=o(" (BEiT model)"),Slr=l(),VF=a("li"),r1e=a("strong"),Rlr=o("data2vec-vision"),Plr=o(" \u2014 "),aW=a("a"),Blr=o("Data2VecVisionForSemanticSegmentation"),Ilr=o(" (Data2VecVision model)"),qlr=l(),XF=a("li"),t1e=a("strong"),Nlr=o("dpt"),jlr=o(" \u2014 "),nW=a("a"),Dlr=o("DPTForSemanticSegmentation"),Glr=o(" (DPT model)"),Olr=l(),zF=a("li"),a1e=a("strong"),Vlr=o("segformer"),Xlr=o(" \u2014 "),sW=a("a"),zlr=o("SegformerForSemanticSegmentation"),Wlr=o(" (SegFormer model)"),Qlr=l(),WF=a("p"),Hlr=o("The model is set in evaluation mode by default using "),n1e=a("code"),Ulr=o("model.eval()"),Jlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s1e=a("code"),Ylr=o("model.train()"),Klr=l(),F(QF.$$.fragment),aje=l(),Gd=a("h2"),HF=a("a"),l1e=a("span"),F(t8.$$.fragment),Zlr=l(),i1e=a("span"),eir=o("AutoModelForInstanceSegmentation"),nje=l(),Jo=a("div"),F(a8.$$.fragment),oir=l(),Od=a("p"),rir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),lW=a("a"),tir=o("from_pretrained()"),air=o(" class method or the "),iW=a("a"),nir=o("from_config()"),sir=o(` class
method.`),lir=l(),n8=a("p"),iir=o("This class cannot be instantiated directly using "),d1e=a("code"),dir=o("__init__()"),cir=o(" (throws an error)."),fir=l(),At=a("div"),F(s8.$$.fragment),mir=l(),c1e=a("p"),gir=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),hir=l(),Vd=a("p"),pir=o(`Note:
Loading a model from its configuration file does `),f1e=a("strong"),uir=o("not"),_ir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dW=a("a"),bir=o("from_pretrained()"),vir=o(" to load the model weights."),Fir=l(),F(UF.$$.fragment),Tir=l(),vo=a("div"),F(l8.$$.fragment),Mir=l(),m1e=a("p"),Eir=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Cir=l(),Ya=a("p"),wir=o("The model class to instantiate is selected based on the "),g1e=a("code"),Air=o("model_type"),yir=o(` property of the config object (either
passed as an argument or loaded from `),h1e=a("code"),Lir=o("pretrained_model_name_or_path"),xir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p1e=a("code"),$ir=o("pretrained_model_name_or_path"),kir=o(":"),Sir=l(),u1e=a("ul"),JF=a("li"),_1e=a("strong"),Rir=o("maskformer"),Pir=o(" \u2014 "),cW=a("a"),Bir=o("MaskFormerForInstanceSegmentation"),Iir=o(" (MaskFormer model)"),qir=l(),YF=a("p"),Nir=o("The model is set in evaluation mode by default using "),b1e=a("code"),jir=o("model.eval()"),Dir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v1e=a("code"),Gir=o("model.train()"),Oir=l(),F(KF.$$.fragment),sje=l(),Xd=a("h2"),ZF=a("a"),F1e=a("span"),F(i8.$$.fragment),Vir=l(),T1e=a("span"),Xir=o("TFAutoModel"),lje=l(),Yo=a("div"),F(d8.$$.fragment),zir=l(),zd=a("p"),Wir=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),fW=a("a"),Qir=o("from_pretrained()"),Hir=o(" class method or the "),mW=a("a"),Uir=o("from_config()"),Jir=o(` class
method.`),Yir=l(),c8=a("p"),Kir=o("This class cannot be instantiated directly using "),M1e=a("code"),Zir=o("__init__()"),edr=o(" (throws an error)."),odr=l(),yt=a("div"),F(f8.$$.fragment),rdr=l(),E1e=a("p"),tdr=o("Instantiates one of the base model classes of the library from a configuration."),adr=l(),Wd=a("p"),ndr=o(`Note:
Loading a model from its configuration file does `),C1e=a("strong"),sdr=o("not"),ldr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gW=a("a"),idr=o("from_pretrained()"),ddr=o(" to load the model weights."),cdr=l(),F(eT.$$.fragment),fdr=l(),wr=a("div"),F(m8.$$.fragment),mdr=l(),w1e=a("p"),gdr=o("Instantiate one of the base model classes of the library from a pretrained model."),hdr=l(),Ka=a("p"),pdr=o("The model class to instantiate is selected based on the "),A1e=a("code"),udr=o("model_type"),_dr=o(` property of the config object (either
passed as an argument or loaded from `),y1e=a("code"),bdr=o("pretrained_model_name_or_path"),vdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L1e=a("code"),Fdr=o("pretrained_model_name_or_path"),Tdr=o(":"),Mdr=l(),N=a("ul"),oT=a("li"),x1e=a("strong"),Edr=o("albert"),Cdr=o(" \u2014 "),hW=a("a"),wdr=o("TFAlbertModel"),Adr=o(" (ALBERT model)"),ydr=l(),rT=a("li"),$1e=a("strong"),Ldr=o("bart"),xdr=o(" \u2014 "),pW=a("a"),$dr=o("TFBartModel"),kdr=o(" (BART model)"),Sdr=l(),tT=a("li"),k1e=a("strong"),Rdr=o("bert"),Pdr=o(" \u2014 "),uW=a("a"),Bdr=o("TFBertModel"),Idr=o(" (BERT model)"),qdr=l(),aT=a("li"),S1e=a("strong"),Ndr=o("blenderbot"),jdr=o(" \u2014 "),_W=a("a"),Ddr=o("TFBlenderbotModel"),Gdr=o(" (Blenderbot model)"),Odr=l(),nT=a("li"),R1e=a("strong"),Vdr=o("blenderbot-small"),Xdr=o(" \u2014 "),bW=a("a"),zdr=o("TFBlenderbotSmallModel"),Wdr=o(" (BlenderbotSmall model)"),Qdr=l(),sT=a("li"),P1e=a("strong"),Hdr=o("camembert"),Udr=o(" \u2014 "),vW=a("a"),Jdr=o("TFCamembertModel"),Ydr=o(" (CamemBERT model)"),Kdr=l(),lT=a("li"),B1e=a("strong"),Zdr=o("clip"),ecr=o(" \u2014 "),FW=a("a"),ocr=o("TFCLIPModel"),rcr=o(" (CLIP model)"),tcr=l(),iT=a("li"),I1e=a("strong"),acr=o("convbert"),ncr=o(" \u2014 "),TW=a("a"),scr=o("TFConvBertModel"),lcr=o(" (ConvBERT model)"),icr=l(),dT=a("li"),q1e=a("strong"),dcr=o("convnext"),ccr=o(" \u2014 "),MW=a("a"),fcr=o("TFConvNextModel"),mcr=o(" (ConvNext model)"),gcr=l(),cT=a("li"),N1e=a("strong"),hcr=o("ctrl"),pcr=o(" \u2014 "),EW=a("a"),ucr=o("TFCTRLModel"),_cr=o(" (CTRL model)"),bcr=l(),fT=a("li"),j1e=a("strong"),vcr=o("data2vec-vision"),Fcr=o(" \u2014 "),CW=a("a"),Tcr=o("TFData2VecVisionModel"),Mcr=o(" (Data2VecVision model)"),Ecr=l(),mT=a("li"),D1e=a("strong"),Ccr=o("deberta"),wcr=o(" \u2014 "),wW=a("a"),Acr=o("TFDebertaModel"),ycr=o(" (DeBERTa model)"),Lcr=l(),gT=a("li"),G1e=a("strong"),xcr=o("deberta-v2"),$cr=o(" \u2014 "),AW=a("a"),kcr=o("TFDebertaV2Model"),Scr=o(" (DeBERTa-v2 model)"),Rcr=l(),hT=a("li"),O1e=a("strong"),Pcr=o("distilbert"),Bcr=o(" \u2014 "),yW=a("a"),Icr=o("TFDistilBertModel"),qcr=o(" (DistilBERT model)"),Ncr=l(),pT=a("li"),V1e=a("strong"),jcr=o("dpr"),Dcr=o(" \u2014 "),LW=a("a"),Gcr=o("TFDPRQuestionEncoder"),Ocr=o(" (DPR model)"),Vcr=l(),uT=a("li"),X1e=a("strong"),Xcr=o("electra"),zcr=o(" \u2014 "),xW=a("a"),Wcr=o("TFElectraModel"),Qcr=o(" (ELECTRA model)"),Hcr=l(),_T=a("li"),z1e=a("strong"),Ucr=o("flaubert"),Jcr=o(" \u2014 "),$W=a("a"),Ycr=o("TFFlaubertModel"),Kcr=o(" (FlauBERT model)"),Zcr=l(),js=a("li"),W1e=a("strong"),efr=o("funnel"),ofr=o(" \u2014 "),kW=a("a"),rfr=o("TFFunnelModel"),tfr=o(" or "),SW=a("a"),afr=o("TFFunnelBaseModel"),nfr=o(" (Funnel Transformer model)"),sfr=l(),bT=a("li"),Q1e=a("strong"),lfr=o("gpt2"),ifr=o(" \u2014 "),RW=a("a"),dfr=o("TFGPT2Model"),cfr=o(" (OpenAI GPT-2 model)"),ffr=l(),vT=a("li"),H1e=a("strong"),mfr=o("gptj"),gfr=o(" \u2014 "),PW=a("a"),hfr=o("TFGPTJModel"),pfr=o(" (GPT-J model)"),ufr=l(),FT=a("li"),U1e=a("strong"),_fr=o("hubert"),bfr=o(" \u2014 "),BW=a("a"),vfr=o("TFHubertModel"),Ffr=o(" (Hubert model)"),Tfr=l(),TT=a("li"),J1e=a("strong"),Mfr=o("layoutlm"),Efr=o(" \u2014 "),IW=a("a"),Cfr=o("TFLayoutLMModel"),wfr=o(" (LayoutLM model)"),Afr=l(),MT=a("li"),Y1e=a("strong"),yfr=o("led"),Lfr=o(" \u2014 "),qW=a("a"),xfr=o("TFLEDModel"),$fr=o(" (LED model)"),kfr=l(),ET=a("li"),K1e=a("strong"),Sfr=o("longformer"),Rfr=o(" \u2014 "),NW=a("a"),Pfr=o("TFLongformerModel"),Bfr=o(" (Longformer model)"),Ifr=l(),CT=a("li"),Z1e=a("strong"),qfr=o("lxmert"),Nfr=o(" \u2014 "),jW=a("a"),jfr=o("TFLxmertModel"),Dfr=o(" (LXMERT model)"),Gfr=l(),wT=a("li"),ebe=a("strong"),Ofr=o("marian"),Vfr=o(" \u2014 "),DW=a("a"),Xfr=o("TFMarianModel"),zfr=o(" (Marian model)"),Wfr=l(),AT=a("li"),obe=a("strong"),Qfr=o("mbart"),Hfr=o(" \u2014 "),GW=a("a"),Ufr=o("TFMBartModel"),Jfr=o(" (mBART model)"),Yfr=l(),yT=a("li"),rbe=a("strong"),Kfr=o("mobilebert"),Zfr=o(" \u2014 "),OW=a("a"),emr=o("TFMobileBertModel"),omr=o(" (MobileBERT model)"),rmr=l(),LT=a("li"),tbe=a("strong"),tmr=o("mpnet"),amr=o(" \u2014 "),VW=a("a"),nmr=o("TFMPNetModel"),smr=o(" (MPNet model)"),lmr=l(),xT=a("li"),abe=a("strong"),imr=o("mt5"),dmr=o(" \u2014 "),XW=a("a"),cmr=o("TFMT5Model"),fmr=o(" (mT5 model)"),mmr=l(),$T=a("li"),nbe=a("strong"),gmr=o("openai-gpt"),hmr=o(" \u2014 "),zW=a("a"),pmr=o("TFOpenAIGPTModel"),umr=o(" (OpenAI GPT model)"),_mr=l(),kT=a("li"),sbe=a("strong"),bmr=o("pegasus"),vmr=o(" \u2014 "),WW=a("a"),Fmr=o("TFPegasusModel"),Tmr=o(" (Pegasus model)"),Mmr=l(),ST=a("li"),lbe=a("strong"),Emr=o("rembert"),Cmr=o(" \u2014 "),QW=a("a"),wmr=o("TFRemBertModel"),Amr=o(" (RemBERT model)"),ymr=l(),RT=a("li"),ibe=a("strong"),Lmr=o("roberta"),xmr=o(" \u2014 "),HW=a("a"),$mr=o("TFRobertaModel"),kmr=o(" (RoBERTa model)"),Smr=l(),PT=a("li"),dbe=a("strong"),Rmr=o("roformer"),Pmr=o(" \u2014 "),UW=a("a"),Bmr=o("TFRoFormerModel"),Imr=o(" (RoFormer model)"),qmr=l(),BT=a("li"),cbe=a("strong"),Nmr=o("speech_to_text"),jmr=o(" \u2014 "),JW=a("a"),Dmr=o("TFSpeech2TextModel"),Gmr=o(" (Speech2Text model)"),Omr=l(),IT=a("li"),fbe=a("strong"),Vmr=o("swin"),Xmr=o(" \u2014 "),YW=a("a"),zmr=o("TFSwinModel"),Wmr=o(" (Swin model)"),Qmr=l(),qT=a("li"),mbe=a("strong"),Hmr=o("t5"),Umr=o(" \u2014 "),KW=a("a"),Jmr=o("TFT5Model"),Ymr=o(" (T5 model)"),Kmr=l(),NT=a("li"),gbe=a("strong"),Zmr=o("tapas"),egr=o(" \u2014 "),ZW=a("a"),ogr=o("TFTapasModel"),rgr=o(" (TAPAS model)"),tgr=l(),jT=a("li"),hbe=a("strong"),agr=o("transfo-xl"),ngr=o(" \u2014 "),eQ=a("a"),sgr=o("TFTransfoXLModel"),lgr=o(" (Transformer-XL model)"),igr=l(),DT=a("li"),pbe=a("strong"),dgr=o("vit"),cgr=o(" \u2014 "),oQ=a("a"),fgr=o("TFViTModel"),mgr=o(" (ViT model)"),ggr=l(),GT=a("li"),ube=a("strong"),hgr=o("vit_mae"),pgr=o(" \u2014 "),rQ=a("a"),ugr=o("TFViTMAEModel"),_gr=o(" (ViTMAE model)"),bgr=l(),OT=a("li"),_be=a("strong"),vgr=o("wav2vec2"),Fgr=o(" \u2014 "),tQ=a("a"),Tgr=o("TFWav2Vec2Model"),Mgr=o(" (Wav2Vec2 model)"),Egr=l(),VT=a("li"),bbe=a("strong"),Cgr=o("xlm"),wgr=o(" \u2014 "),aQ=a("a"),Agr=o("TFXLMModel"),ygr=o(" (XLM model)"),Lgr=l(),XT=a("li"),vbe=a("strong"),xgr=o("xlm-roberta"),$gr=o(" \u2014 "),nQ=a("a"),kgr=o("TFXLMRobertaModel"),Sgr=o(" (XLM-RoBERTa model)"),Rgr=l(),zT=a("li"),Fbe=a("strong"),Pgr=o("xlnet"),Bgr=o(" \u2014 "),sQ=a("a"),Igr=o("TFXLNetModel"),qgr=o(" (XLNet model)"),Ngr=l(),F(WT.$$.fragment),ije=l(),Qd=a("h2"),QT=a("a"),Tbe=a("span"),F(g8.$$.fragment),jgr=l(),Mbe=a("span"),Dgr=o("TFAutoModelForPreTraining"),dje=l(),Ko=a("div"),F(h8.$$.fragment),Ggr=l(),Hd=a("p"),Ogr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lQ=a("a"),Vgr=o("from_pretrained()"),Xgr=o(" class method or the "),iQ=a("a"),zgr=o("from_config()"),Wgr=o(` class
method.`),Qgr=l(),p8=a("p"),Hgr=o("This class cannot be instantiated directly using "),Ebe=a("code"),Ugr=o("__init__()"),Jgr=o(" (throws an error)."),Ygr=l(),Lt=a("div"),F(u8.$$.fragment),Kgr=l(),Cbe=a("p"),Zgr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ehr=l(),Ud=a("p"),ohr=o(`Note:
Loading a model from its configuration file does `),wbe=a("strong"),rhr=o("not"),thr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dQ=a("a"),ahr=o("from_pretrained()"),nhr=o(" to load the model weights."),shr=l(),F(HT.$$.fragment),lhr=l(),Ar=a("div"),F(_8.$$.fragment),ihr=l(),Abe=a("p"),dhr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),chr=l(),Za=a("p"),fhr=o("The model class to instantiate is selected based on the "),ybe=a("code"),mhr=o("model_type"),ghr=o(` property of the config object (either
passed as an argument or loaded from `),Lbe=a("code"),hhr=o("pretrained_model_name_or_path"),phr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xbe=a("code"),uhr=o("pretrained_model_name_or_path"),_hr=o(":"),bhr=l(),se=a("ul"),UT=a("li"),$be=a("strong"),vhr=o("albert"),Fhr=o(" \u2014 "),cQ=a("a"),Thr=o("TFAlbertForPreTraining"),Mhr=o(" (ALBERT model)"),Ehr=l(),JT=a("li"),kbe=a("strong"),Chr=o("bart"),whr=o(" \u2014 "),fQ=a("a"),Ahr=o("TFBartForConditionalGeneration"),yhr=o(" (BART model)"),Lhr=l(),YT=a("li"),Sbe=a("strong"),xhr=o("bert"),$hr=o(" \u2014 "),mQ=a("a"),khr=o("TFBertForPreTraining"),Shr=o(" (BERT model)"),Rhr=l(),KT=a("li"),Rbe=a("strong"),Phr=o("camembert"),Bhr=o(" \u2014 "),gQ=a("a"),Ihr=o("TFCamembertForMaskedLM"),qhr=o(" (CamemBERT model)"),Nhr=l(),ZT=a("li"),Pbe=a("strong"),jhr=o("ctrl"),Dhr=o(" \u2014 "),hQ=a("a"),Ghr=o("TFCTRLLMHeadModel"),Ohr=o(" (CTRL model)"),Vhr=l(),e7=a("li"),Bbe=a("strong"),Xhr=o("distilbert"),zhr=o(" \u2014 "),pQ=a("a"),Whr=o("TFDistilBertForMaskedLM"),Qhr=o(" (DistilBERT model)"),Hhr=l(),o7=a("li"),Ibe=a("strong"),Uhr=o("electra"),Jhr=o(" \u2014 "),uQ=a("a"),Yhr=o("TFElectraForPreTraining"),Khr=o(" (ELECTRA model)"),Zhr=l(),r7=a("li"),qbe=a("strong"),epr=o("flaubert"),opr=o(" \u2014 "),_Q=a("a"),rpr=o("TFFlaubertWithLMHeadModel"),tpr=o(" (FlauBERT model)"),apr=l(),t7=a("li"),Nbe=a("strong"),npr=o("funnel"),spr=o(" \u2014 "),bQ=a("a"),lpr=o("TFFunnelForPreTraining"),ipr=o(" (Funnel Transformer model)"),dpr=l(),a7=a("li"),jbe=a("strong"),cpr=o("gpt2"),fpr=o(" \u2014 "),vQ=a("a"),mpr=o("TFGPT2LMHeadModel"),gpr=o(" (OpenAI GPT-2 model)"),hpr=l(),n7=a("li"),Dbe=a("strong"),ppr=o("layoutlm"),upr=o(" \u2014 "),FQ=a("a"),_pr=o("TFLayoutLMForMaskedLM"),bpr=o(" (LayoutLM model)"),vpr=l(),s7=a("li"),Gbe=a("strong"),Fpr=o("lxmert"),Tpr=o(" \u2014 "),TQ=a("a"),Mpr=o("TFLxmertForPreTraining"),Epr=o(" (LXMERT model)"),Cpr=l(),l7=a("li"),Obe=a("strong"),wpr=o("mobilebert"),Apr=o(" \u2014 "),MQ=a("a"),ypr=o("TFMobileBertForPreTraining"),Lpr=o(" (MobileBERT model)"),xpr=l(),i7=a("li"),Vbe=a("strong"),$pr=o("mpnet"),kpr=o(" \u2014 "),EQ=a("a"),Spr=o("TFMPNetForMaskedLM"),Rpr=o(" (MPNet model)"),Ppr=l(),d7=a("li"),Xbe=a("strong"),Bpr=o("openai-gpt"),Ipr=o(" \u2014 "),CQ=a("a"),qpr=o("TFOpenAIGPTLMHeadModel"),Npr=o(" (OpenAI GPT model)"),jpr=l(),c7=a("li"),zbe=a("strong"),Dpr=o("roberta"),Gpr=o(" \u2014 "),wQ=a("a"),Opr=o("TFRobertaForMaskedLM"),Vpr=o(" (RoBERTa model)"),Xpr=l(),f7=a("li"),Wbe=a("strong"),zpr=o("t5"),Wpr=o(" \u2014 "),AQ=a("a"),Qpr=o("TFT5ForConditionalGeneration"),Hpr=o(" (T5 model)"),Upr=l(),m7=a("li"),Qbe=a("strong"),Jpr=o("tapas"),Ypr=o(" \u2014 "),yQ=a("a"),Kpr=o("TFTapasForMaskedLM"),Zpr=o(" (TAPAS model)"),eur=l(),g7=a("li"),Hbe=a("strong"),our=o("transfo-xl"),rur=o(" \u2014 "),LQ=a("a"),tur=o("TFTransfoXLLMHeadModel"),aur=o(" (Transformer-XL model)"),nur=l(),h7=a("li"),Ube=a("strong"),sur=o("vit_mae"),lur=o(" \u2014 "),xQ=a("a"),iur=o("TFViTMAEForPreTraining"),dur=o(" (ViTMAE model)"),cur=l(),p7=a("li"),Jbe=a("strong"),fur=o("xlm"),mur=o(" \u2014 "),$Q=a("a"),gur=o("TFXLMWithLMHeadModel"),hur=o(" (XLM model)"),pur=l(),u7=a("li"),Ybe=a("strong"),uur=o("xlm-roberta"),_ur=o(" \u2014 "),kQ=a("a"),bur=o("TFXLMRobertaForMaskedLM"),vur=o(" (XLM-RoBERTa model)"),Fur=l(),_7=a("li"),Kbe=a("strong"),Tur=o("xlnet"),Mur=o(" \u2014 "),SQ=a("a"),Eur=o("TFXLNetLMHeadModel"),Cur=o(" (XLNet model)"),wur=l(),F(b7.$$.fragment),cje=l(),Jd=a("h2"),v7=a("a"),Zbe=a("span"),F(b8.$$.fragment),Aur=l(),e4e=a("span"),yur=o("TFAutoModelForCausalLM"),fje=l(),Zo=a("div"),F(v8.$$.fragment),Lur=l(),Yd=a("p"),xur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),RQ=a("a"),$ur=o("from_pretrained()"),kur=o(" class method or the "),PQ=a("a"),Sur=o("from_config()"),Rur=o(` class
method.`),Pur=l(),F8=a("p"),Bur=o("This class cannot be instantiated directly using "),o4e=a("code"),Iur=o("__init__()"),qur=o(" (throws an error)."),Nur=l(),xt=a("div"),F(T8.$$.fragment),jur=l(),r4e=a("p"),Dur=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Gur=l(),Kd=a("p"),Our=o(`Note:
Loading a model from its configuration file does `),t4e=a("strong"),Vur=o("not"),Xur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BQ=a("a"),zur=o("from_pretrained()"),Wur=o(" to load the model weights."),Qur=l(),F(F7.$$.fragment),Hur=l(),yr=a("div"),F(M8.$$.fragment),Uur=l(),a4e=a("p"),Jur=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Yur=l(),en=a("p"),Kur=o("The model class to instantiate is selected based on the "),n4e=a("code"),Zur=o("model_type"),e_r=o(` property of the config object (either
passed as an argument or loaded from `),s4e=a("code"),o_r=o("pretrained_model_name_or_path"),r_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l4e=a("code"),t_r=o("pretrained_model_name_or_path"),a_r=o(":"),n_r=l(),Me=a("ul"),T7=a("li"),i4e=a("strong"),s_r=o("bert"),l_r=o(" \u2014 "),IQ=a("a"),i_r=o("TFBertLMHeadModel"),d_r=o(" (BERT model)"),c_r=l(),M7=a("li"),d4e=a("strong"),f_r=o("camembert"),m_r=o(" \u2014 "),qQ=a("a"),g_r=o("TFCamembertForCausalLM"),h_r=o(" (CamemBERT model)"),p_r=l(),E7=a("li"),c4e=a("strong"),u_r=o("ctrl"),__r=o(" \u2014 "),NQ=a("a"),b_r=o("TFCTRLLMHeadModel"),v_r=o(" (CTRL model)"),F_r=l(),C7=a("li"),f4e=a("strong"),T_r=o("gpt2"),M_r=o(" \u2014 "),jQ=a("a"),E_r=o("TFGPT2LMHeadModel"),C_r=o(" (OpenAI GPT-2 model)"),w_r=l(),w7=a("li"),m4e=a("strong"),A_r=o("gptj"),y_r=o(" \u2014 "),DQ=a("a"),L_r=o("TFGPTJForCausalLM"),x_r=o(" (GPT-J model)"),$_r=l(),A7=a("li"),g4e=a("strong"),k_r=o("openai-gpt"),S_r=o(" \u2014 "),GQ=a("a"),R_r=o("TFOpenAIGPTLMHeadModel"),P_r=o(" (OpenAI GPT model)"),B_r=l(),y7=a("li"),h4e=a("strong"),I_r=o("rembert"),q_r=o(" \u2014 "),OQ=a("a"),N_r=o("TFRemBertForCausalLM"),j_r=o(" (RemBERT model)"),D_r=l(),L7=a("li"),p4e=a("strong"),G_r=o("roberta"),O_r=o(" \u2014 "),VQ=a("a"),V_r=o("TFRobertaForCausalLM"),X_r=o(" (RoBERTa model)"),z_r=l(),x7=a("li"),u4e=a("strong"),W_r=o("roformer"),Q_r=o(" \u2014 "),XQ=a("a"),H_r=o("TFRoFormerForCausalLM"),U_r=o(" (RoFormer model)"),J_r=l(),$7=a("li"),_4e=a("strong"),Y_r=o("transfo-xl"),K_r=o(" \u2014 "),zQ=a("a"),Z_r=o("TFTransfoXLLMHeadModel"),e2r=o(" (Transformer-XL model)"),o2r=l(),k7=a("li"),b4e=a("strong"),r2r=o("xlm"),t2r=o(" \u2014 "),WQ=a("a"),a2r=o("TFXLMWithLMHeadModel"),n2r=o(" (XLM model)"),s2r=l(),S7=a("li"),v4e=a("strong"),l2r=o("xlnet"),i2r=o(" \u2014 "),QQ=a("a"),d2r=o("TFXLNetLMHeadModel"),c2r=o(" (XLNet model)"),f2r=l(),F(R7.$$.fragment),mje=l(),Zd=a("h2"),P7=a("a"),F4e=a("span"),F(E8.$$.fragment),m2r=l(),T4e=a("span"),g2r=o("TFAutoModelForImageClassification"),gje=l(),er=a("div"),F(C8.$$.fragment),h2r=l(),ec=a("p"),p2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),HQ=a("a"),u2r=o("from_pretrained()"),_2r=o(" class method or the "),UQ=a("a"),b2r=o("from_config()"),v2r=o(` class
method.`),F2r=l(),w8=a("p"),T2r=o("This class cannot be instantiated directly using "),M4e=a("code"),M2r=o("__init__()"),E2r=o(" (throws an error)."),C2r=l(),$t=a("div"),F(A8.$$.fragment),w2r=l(),E4e=a("p"),A2r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),y2r=l(),oc=a("p"),L2r=o(`Note:
Loading a model from its configuration file does `),C4e=a("strong"),x2r=o("not"),$2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JQ=a("a"),k2r=o("from_pretrained()"),S2r=o(" to load the model weights."),R2r=l(),F(B7.$$.fragment),P2r=l(),Lr=a("div"),F(y8.$$.fragment),B2r=l(),w4e=a("p"),I2r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),q2r=l(),on=a("p"),N2r=o("The model class to instantiate is selected based on the "),A4e=a("code"),j2r=o("model_type"),D2r=o(` property of the config object (either
passed as an argument or loaded from `),y4e=a("code"),G2r=o("pretrained_model_name_or_path"),O2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L4e=a("code"),V2r=o("pretrained_model_name_or_path"),X2r=o(":"),z2r=l(),rn=a("ul"),I7=a("li"),x4e=a("strong"),W2r=o("convnext"),Q2r=o(" \u2014 "),YQ=a("a"),H2r=o("TFConvNextForImageClassification"),U2r=o(" (ConvNext model)"),J2r=l(),q7=a("li"),$4e=a("strong"),Y2r=o("data2vec-vision"),K2r=o(" \u2014 "),KQ=a("a"),Z2r=o("TFData2VecVisionForImageClassification"),e1r=o(" (Data2VecVision model)"),o1r=l(),N7=a("li"),k4e=a("strong"),r1r=o("swin"),t1r=o(" \u2014 "),ZQ=a("a"),a1r=o("TFSwinForImageClassification"),n1r=o(" (Swin model)"),s1r=l(),j7=a("li"),S4e=a("strong"),l1r=o("vit"),i1r=o(" \u2014 "),eH=a("a"),d1r=o("TFViTForImageClassification"),c1r=o(" (ViT model)"),f1r=l(),F(D7.$$.fragment),hje=l(),rc=a("h2"),G7=a("a"),R4e=a("span"),F(L8.$$.fragment),m1r=l(),P4e=a("span"),g1r=o("TFAutoModelForMaskedLM"),pje=l(),or=a("div"),F(x8.$$.fragment),h1r=l(),tc=a("p"),p1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),oH=a("a"),u1r=o("from_pretrained()"),_1r=o(" class method or the "),rH=a("a"),b1r=o("from_config()"),v1r=o(` class
method.`),F1r=l(),$8=a("p"),T1r=o("This class cannot be instantiated directly using "),B4e=a("code"),M1r=o("__init__()"),E1r=o(" (throws an error)."),C1r=l(),kt=a("div"),F(k8.$$.fragment),w1r=l(),I4e=a("p"),A1r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),y1r=l(),ac=a("p"),L1r=o(`Note:
Loading a model from its configuration file does `),q4e=a("strong"),x1r=o("not"),$1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=a("a"),k1r=o("from_pretrained()"),S1r=o(" to load the model weights."),R1r=l(),F(O7.$$.fragment),P1r=l(),xr=a("div"),F(S8.$$.fragment),B1r=l(),N4e=a("p"),I1r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),q1r=l(),tn=a("p"),N1r=o("The model class to instantiate is selected based on the "),j4e=a("code"),j1r=o("model_type"),D1r=o(` property of the config object (either
passed as an argument or loaded from `),D4e=a("code"),G1r=o("pretrained_model_name_or_path"),O1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G4e=a("code"),V1r=o("pretrained_model_name_or_path"),X1r=o(":"),z1r=l(),ie=a("ul"),V7=a("li"),O4e=a("strong"),W1r=o("albert"),Q1r=o(" \u2014 "),aH=a("a"),H1r=o("TFAlbertForMaskedLM"),U1r=o(" (ALBERT model)"),J1r=l(),X7=a("li"),V4e=a("strong"),Y1r=o("bert"),K1r=o(" \u2014 "),nH=a("a"),Z1r=o("TFBertForMaskedLM"),ebr=o(" (BERT model)"),obr=l(),z7=a("li"),X4e=a("strong"),rbr=o("camembert"),tbr=o(" \u2014 "),sH=a("a"),abr=o("TFCamembertForMaskedLM"),nbr=o(" (CamemBERT model)"),sbr=l(),W7=a("li"),z4e=a("strong"),lbr=o("convbert"),ibr=o(" \u2014 "),lH=a("a"),dbr=o("TFConvBertForMaskedLM"),cbr=o(" (ConvBERT model)"),fbr=l(),Q7=a("li"),W4e=a("strong"),mbr=o("deberta"),gbr=o(" \u2014 "),iH=a("a"),hbr=o("TFDebertaForMaskedLM"),pbr=o(" (DeBERTa model)"),ubr=l(),H7=a("li"),Q4e=a("strong"),_br=o("deberta-v2"),bbr=o(" \u2014 "),dH=a("a"),vbr=o("TFDebertaV2ForMaskedLM"),Fbr=o(" (DeBERTa-v2 model)"),Tbr=l(),U7=a("li"),H4e=a("strong"),Mbr=o("distilbert"),Ebr=o(" \u2014 "),cH=a("a"),Cbr=o("TFDistilBertForMaskedLM"),wbr=o(" (DistilBERT model)"),Abr=l(),J7=a("li"),U4e=a("strong"),ybr=o("electra"),Lbr=o(" \u2014 "),fH=a("a"),xbr=o("TFElectraForMaskedLM"),$br=o(" (ELECTRA model)"),kbr=l(),Y7=a("li"),J4e=a("strong"),Sbr=o("flaubert"),Rbr=o(" \u2014 "),mH=a("a"),Pbr=o("TFFlaubertWithLMHeadModel"),Bbr=o(" (FlauBERT model)"),Ibr=l(),K7=a("li"),Y4e=a("strong"),qbr=o("funnel"),Nbr=o(" \u2014 "),gH=a("a"),jbr=o("TFFunnelForMaskedLM"),Dbr=o(" (Funnel Transformer model)"),Gbr=l(),Z7=a("li"),K4e=a("strong"),Obr=o("layoutlm"),Vbr=o(" \u2014 "),hH=a("a"),Xbr=o("TFLayoutLMForMaskedLM"),zbr=o(" (LayoutLM model)"),Wbr=l(),eM=a("li"),Z4e=a("strong"),Qbr=o("longformer"),Hbr=o(" \u2014 "),pH=a("a"),Ubr=o("TFLongformerForMaskedLM"),Jbr=o(" (Longformer model)"),Ybr=l(),oM=a("li"),eve=a("strong"),Kbr=o("mobilebert"),Zbr=o(" \u2014 "),uH=a("a"),e4r=o("TFMobileBertForMaskedLM"),o4r=o(" (MobileBERT model)"),r4r=l(),rM=a("li"),ove=a("strong"),t4r=o("mpnet"),a4r=o(" \u2014 "),_H=a("a"),n4r=o("TFMPNetForMaskedLM"),s4r=o(" (MPNet model)"),l4r=l(),tM=a("li"),rve=a("strong"),i4r=o("rembert"),d4r=o(" \u2014 "),bH=a("a"),c4r=o("TFRemBertForMaskedLM"),f4r=o(" (RemBERT model)"),m4r=l(),aM=a("li"),tve=a("strong"),g4r=o("roberta"),h4r=o(" \u2014 "),vH=a("a"),p4r=o("TFRobertaForMaskedLM"),u4r=o(" (RoBERTa model)"),_4r=l(),nM=a("li"),ave=a("strong"),b4r=o("roformer"),v4r=o(" \u2014 "),FH=a("a"),F4r=o("TFRoFormerForMaskedLM"),T4r=o(" (RoFormer model)"),M4r=l(),sM=a("li"),nve=a("strong"),E4r=o("tapas"),C4r=o(" \u2014 "),TH=a("a"),w4r=o("TFTapasForMaskedLM"),A4r=o(" (TAPAS model)"),y4r=l(),lM=a("li"),sve=a("strong"),L4r=o("xlm"),x4r=o(" \u2014 "),MH=a("a"),$4r=o("TFXLMWithLMHeadModel"),k4r=o(" (XLM model)"),S4r=l(),iM=a("li"),lve=a("strong"),R4r=o("xlm-roberta"),P4r=o(" \u2014 "),EH=a("a"),B4r=o("TFXLMRobertaForMaskedLM"),I4r=o(" (XLM-RoBERTa model)"),q4r=l(),F(dM.$$.fragment),uje=l(),nc=a("h2"),cM=a("a"),ive=a("span"),F(R8.$$.fragment),N4r=l(),dve=a("span"),j4r=o("TFAutoModelForSeq2SeqLM"),_je=l(),rr=a("div"),F(P8.$$.fragment),D4r=l(),sc=a("p"),G4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),CH=a("a"),O4r=o("from_pretrained()"),V4r=o(" class method or the "),wH=a("a"),X4r=o("from_config()"),z4r=o(` class
method.`),W4r=l(),B8=a("p"),Q4r=o("This class cannot be instantiated directly using "),cve=a("code"),H4r=o("__init__()"),U4r=o(" (throws an error)."),J4r=l(),St=a("div"),F(I8.$$.fragment),Y4r=l(),fve=a("p"),K4r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Z4r=l(),lc=a("p"),evr=o(`Note:
Loading a model from its configuration file does `),mve=a("strong"),ovr=o("not"),rvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AH=a("a"),tvr=o("from_pretrained()"),avr=o(" to load the model weights."),nvr=l(),F(fM.$$.fragment),svr=l(),$r=a("div"),F(q8.$$.fragment),lvr=l(),gve=a("p"),ivr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dvr=l(),an=a("p"),cvr=o("The model class to instantiate is selected based on the "),hve=a("code"),fvr=o("model_type"),mvr=o(` property of the config object (either
passed as an argument or loaded from `),pve=a("code"),gvr=o("pretrained_model_name_or_path"),hvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=a("code"),pvr=o("pretrained_model_name_or_path"),uvr=o(":"),_vr=l(),ye=a("ul"),mM=a("li"),_ve=a("strong"),bvr=o("bart"),vvr=o(" \u2014 "),yH=a("a"),Fvr=o("TFBartForConditionalGeneration"),Tvr=o(" (BART model)"),Mvr=l(),gM=a("li"),bve=a("strong"),Evr=o("blenderbot"),Cvr=o(" \u2014 "),LH=a("a"),wvr=o("TFBlenderbotForConditionalGeneration"),Avr=o(" (Blenderbot model)"),yvr=l(),hM=a("li"),vve=a("strong"),Lvr=o("blenderbot-small"),xvr=o(" \u2014 "),xH=a("a"),$vr=o("TFBlenderbotSmallForConditionalGeneration"),kvr=o(" (BlenderbotSmall model)"),Svr=l(),pM=a("li"),Fve=a("strong"),Rvr=o("encoder-decoder"),Pvr=o(" \u2014 "),$H=a("a"),Bvr=o("TFEncoderDecoderModel"),Ivr=o(" (Encoder decoder model)"),qvr=l(),uM=a("li"),Tve=a("strong"),Nvr=o("led"),jvr=o(" \u2014 "),kH=a("a"),Dvr=o("TFLEDForConditionalGeneration"),Gvr=o(" (LED model)"),Ovr=l(),_M=a("li"),Mve=a("strong"),Vvr=o("marian"),Xvr=o(" \u2014 "),SH=a("a"),zvr=o("TFMarianMTModel"),Wvr=o(" (Marian model)"),Qvr=l(),bM=a("li"),Eve=a("strong"),Hvr=o("mbart"),Uvr=o(" \u2014 "),RH=a("a"),Jvr=o("TFMBartForConditionalGeneration"),Yvr=o(" (mBART model)"),Kvr=l(),vM=a("li"),Cve=a("strong"),Zvr=o("mt5"),e5r=o(" \u2014 "),PH=a("a"),o5r=o("TFMT5ForConditionalGeneration"),r5r=o(" (mT5 model)"),t5r=l(),FM=a("li"),wve=a("strong"),a5r=o("pegasus"),n5r=o(" \u2014 "),BH=a("a"),s5r=o("TFPegasusForConditionalGeneration"),l5r=o(" (Pegasus model)"),i5r=l(),TM=a("li"),Ave=a("strong"),d5r=o("t5"),c5r=o(" \u2014 "),IH=a("a"),f5r=o("TFT5ForConditionalGeneration"),m5r=o(" (T5 model)"),g5r=l(),F(MM.$$.fragment),bje=l(),ic=a("h2"),EM=a("a"),yve=a("span"),F(N8.$$.fragment),h5r=l(),Lve=a("span"),p5r=o("TFAutoModelForSequenceClassification"),vje=l(),tr=a("div"),F(j8.$$.fragment),u5r=l(),dc=a("p"),_5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qH=a("a"),b5r=o("from_pretrained()"),v5r=o(" class method or the "),NH=a("a"),F5r=o("from_config()"),T5r=o(` class
method.`),M5r=l(),D8=a("p"),E5r=o("This class cannot be instantiated directly using "),xve=a("code"),C5r=o("__init__()"),w5r=o(" (throws an error)."),A5r=l(),Rt=a("div"),F(G8.$$.fragment),y5r=l(),$ve=a("p"),L5r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),x5r=l(),cc=a("p"),$5r=o(`Note:
Loading a model from its configuration file does `),kve=a("strong"),k5r=o("not"),S5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=a("a"),R5r=o("from_pretrained()"),P5r=o(" to load the model weights."),B5r=l(),F(CM.$$.fragment),I5r=l(),kr=a("div"),F(O8.$$.fragment),q5r=l(),Sve=a("p"),N5r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),j5r=l(),nn=a("p"),D5r=o("The model class to instantiate is selected based on the "),Rve=a("code"),G5r=o("model_type"),O5r=o(` property of the config object (either
passed as an argument or loaded from `),Pve=a("code"),V5r=o("pretrained_model_name_or_path"),X5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bve=a("code"),z5r=o("pretrained_model_name_or_path"),W5r=o(":"),Q5r=l(),oe=a("ul"),wM=a("li"),Ive=a("strong"),H5r=o("albert"),U5r=o(" \u2014 "),DH=a("a"),J5r=o("TFAlbertForSequenceClassification"),Y5r=o(" (ALBERT model)"),K5r=l(),AM=a("li"),qve=a("strong"),Z5r=o("bert"),eFr=o(" \u2014 "),GH=a("a"),oFr=o("TFBertForSequenceClassification"),rFr=o(" (BERT model)"),tFr=l(),yM=a("li"),Nve=a("strong"),aFr=o("camembert"),nFr=o(" \u2014 "),OH=a("a"),sFr=o("TFCamembertForSequenceClassification"),lFr=o(" (CamemBERT model)"),iFr=l(),LM=a("li"),jve=a("strong"),dFr=o("convbert"),cFr=o(" \u2014 "),VH=a("a"),fFr=o("TFConvBertForSequenceClassification"),mFr=o(" (ConvBERT model)"),gFr=l(),xM=a("li"),Dve=a("strong"),hFr=o("ctrl"),pFr=o(" \u2014 "),XH=a("a"),uFr=o("TFCTRLForSequenceClassification"),_Fr=o(" (CTRL model)"),bFr=l(),$M=a("li"),Gve=a("strong"),vFr=o("deberta"),FFr=o(" \u2014 "),zH=a("a"),TFr=o("TFDebertaForSequenceClassification"),MFr=o(" (DeBERTa model)"),EFr=l(),kM=a("li"),Ove=a("strong"),CFr=o("deberta-v2"),wFr=o(" \u2014 "),WH=a("a"),AFr=o("TFDebertaV2ForSequenceClassification"),yFr=o(" (DeBERTa-v2 model)"),LFr=l(),SM=a("li"),Vve=a("strong"),xFr=o("distilbert"),$Fr=o(" \u2014 "),QH=a("a"),kFr=o("TFDistilBertForSequenceClassification"),SFr=o(" (DistilBERT model)"),RFr=l(),RM=a("li"),Xve=a("strong"),PFr=o("electra"),BFr=o(" \u2014 "),HH=a("a"),IFr=o("TFElectraForSequenceClassification"),qFr=o(" (ELECTRA model)"),NFr=l(),PM=a("li"),zve=a("strong"),jFr=o("flaubert"),DFr=o(" \u2014 "),UH=a("a"),GFr=o("TFFlaubertForSequenceClassification"),OFr=o(" (FlauBERT model)"),VFr=l(),BM=a("li"),Wve=a("strong"),XFr=o("funnel"),zFr=o(" \u2014 "),JH=a("a"),WFr=o("TFFunnelForSequenceClassification"),QFr=o(" (Funnel Transformer model)"),HFr=l(),IM=a("li"),Qve=a("strong"),UFr=o("gpt2"),JFr=o(" \u2014 "),YH=a("a"),YFr=o("TFGPT2ForSequenceClassification"),KFr=o(" (OpenAI GPT-2 model)"),ZFr=l(),qM=a("li"),Hve=a("strong"),eTr=o("gptj"),oTr=o(" \u2014 "),KH=a("a"),rTr=o("TFGPTJForSequenceClassification"),tTr=o(" (GPT-J model)"),aTr=l(),NM=a("li"),Uve=a("strong"),nTr=o("layoutlm"),sTr=o(" \u2014 "),ZH=a("a"),lTr=o("TFLayoutLMForSequenceClassification"),iTr=o(" (LayoutLM model)"),dTr=l(),jM=a("li"),Jve=a("strong"),cTr=o("longformer"),fTr=o(" \u2014 "),eU=a("a"),mTr=o("TFLongformerForSequenceClassification"),gTr=o(" (Longformer model)"),hTr=l(),DM=a("li"),Yve=a("strong"),pTr=o("mobilebert"),uTr=o(" \u2014 "),oU=a("a"),_Tr=o("TFMobileBertForSequenceClassification"),bTr=o(" (MobileBERT model)"),vTr=l(),GM=a("li"),Kve=a("strong"),FTr=o("mpnet"),TTr=o(" \u2014 "),rU=a("a"),MTr=o("TFMPNetForSequenceClassification"),ETr=o(" (MPNet model)"),CTr=l(),OM=a("li"),Zve=a("strong"),wTr=o("openai-gpt"),ATr=o(" \u2014 "),tU=a("a"),yTr=o("TFOpenAIGPTForSequenceClassification"),LTr=o(" (OpenAI GPT model)"),xTr=l(),VM=a("li"),e5e=a("strong"),$Tr=o("rembert"),kTr=o(" \u2014 "),aU=a("a"),STr=o("TFRemBertForSequenceClassification"),RTr=o(" (RemBERT model)"),PTr=l(),XM=a("li"),o5e=a("strong"),BTr=o("roberta"),ITr=o(" \u2014 "),nU=a("a"),qTr=o("TFRobertaForSequenceClassification"),NTr=o(" (RoBERTa model)"),jTr=l(),zM=a("li"),r5e=a("strong"),DTr=o("roformer"),GTr=o(" \u2014 "),sU=a("a"),OTr=o("TFRoFormerForSequenceClassification"),VTr=o(" (RoFormer model)"),XTr=l(),WM=a("li"),t5e=a("strong"),zTr=o("tapas"),WTr=o(" \u2014 "),lU=a("a"),QTr=o("TFTapasForSequenceClassification"),HTr=o(" (TAPAS model)"),UTr=l(),QM=a("li"),a5e=a("strong"),JTr=o("transfo-xl"),YTr=o(" \u2014 "),iU=a("a"),KTr=o("TFTransfoXLForSequenceClassification"),ZTr=o(" (Transformer-XL model)"),e7r=l(),HM=a("li"),n5e=a("strong"),o7r=o("xlm"),r7r=o(" \u2014 "),dU=a("a"),t7r=o("TFXLMForSequenceClassification"),a7r=o(" (XLM model)"),n7r=l(),UM=a("li"),s5e=a("strong"),s7r=o("xlm-roberta"),l7r=o(" \u2014 "),cU=a("a"),i7r=o("TFXLMRobertaForSequenceClassification"),d7r=o(" (XLM-RoBERTa model)"),c7r=l(),JM=a("li"),l5e=a("strong"),f7r=o("xlnet"),m7r=o(" \u2014 "),fU=a("a"),g7r=o("TFXLNetForSequenceClassification"),h7r=o(" (XLNet model)"),p7r=l(),F(YM.$$.fragment),Fje=l(),fc=a("h2"),KM=a("a"),i5e=a("span"),F(V8.$$.fragment),u7r=l(),d5e=a("span"),_7r=o("TFAutoModelForMultipleChoice"),Tje=l(),ar=a("div"),F(X8.$$.fragment),b7r=l(),mc=a("p"),v7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),mU=a("a"),F7r=o("from_pretrained()"),T7r=o(" class method or the "),gU=a("a"),M7r=o("from_config()"),E7r=o(` class
method.`),C7r=l(),z8=a("p"),w7r=o("This class cannot be instantiated directly using "),c5e=a("code"),A7r=o("__init__()"),y7r=o(" (throws an error)."),L7r=l(),Pt=a("div"),F(W8.$$.fragment),x7r=l(),f5e=a("p"),$7r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),k7r=l(),gc=a("p"),S7r=o(`Note:
Loading a model from its configuration file does `),m5e=a("strong"),R7r=o("not"),P7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hU=a("a"),B7r=o("from_pretrained()"),I7r=o(" to load the model weights."),q7r=l(),F(ZM.$$.fragment),N7r=l(),Sr=a("div"),F(Q8.$$.fragment),j7r=l(),g5e=a("p"),D7r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),G7r=l(),sn=a("p"),O7r=o("The model class to instantiate is selected based on the "),h5e=a("code"),V7r=o("model_type"),X7r=o(` property of the config object (either
passed as an argument or loaded from `),p5e=a("code"),z7r=o("pretrained_model_name_or_path"),W7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u5e=a("code"),Q7r=o("pretrained_model_name_or_path"),H7r=o(":"),U7r=l(),pe=a("ul"),eE=a("li"),_5e=a("strong"),J7r=o("albert"),Y7r=o(" \u2014 "),pU=a("a"),K7r=o("TFAlbertForMultipleChoice"),Z7r=o(" (ALBERT model)"),eMr=l(),oE=a("li"),b5e=a("strong"),oMr=o("bert"),rMr=o(" \u2014 "),uU=a("a"),tMr=o("TFBertForMultipleChoice"),aMr=o(" (BERT model)"),nMr=l(),rE=a("li"),v5e=a("strong"),sMr=o("camembert"),lMr=o(" \u2014 "),_U=a("a"),iMr=o("TFCamembertForMultipleChoice"),dMr=o(" (CamemBERT model)"),cMr=l(),tE=a("li"),F5e=a("strong"),fMr=o("convbert"),mMr=o(" \u2014 "),bU=a("a"),gMr=o("TFConvBertForMultipleChoice"),hMr=o(" (ConvBERT model)"),pMr=l(),aE=a("li"),T5e=a("strong"),uMr=o("distilbert"),_Mr=o(" \u2014 "),vU=a("a"),bMr=o("TFDistilBertForMultipleChoice"),vMr=o(" (DistilBERT model)"),FMr=l(),nE=a("li"),M5e=a("strong"),TMr=o("electra"),MMr=o(" \u2014 "),FU=a("a"),EMr=o("TFElectraForMultipleChoice"),CMr=o(" (ELECTRA model)"),wMr=l(),sE=a("li"),E5e=a("strong"),AMr=o("flaubert"),yMr=o(" \u2014 "),TU=a("a"),LMr=o("TFFlaubertForMultipleChoice"),xMr=o(" (FlauBERT model)"),$Mr=l(),lE=a("li"),C5e=a("strong"),kMr=o("funnel"),SMr=o(" \u2014 "),MU=a("a"),RMr=o("TFFunnelForMultipleChoice"),PMr=o(" (Funnel Transformer model)"),BMr=l(),iE=a("li"),w5e=a("strong"),IMr=o("longformer"),qMr=o(" \u2014 "),EU=a("a"),NMr=o("TFLongformerForMultipleChoice"),jMr=o(" (Longformer model)"),DMr=l(),dE=a("li"),A5e=a("strong"),GMr=o("mobilebert"),OMr=o(" \u2014 "),CU=a("a"),VMr=o("TFMobileBertForMultipleChoice"),XMr=o(" (MobileBERT model)"),zMr=l(),cE=a("li"),y5e=a("strong"),WMr=o("mpnet"),QMr=o(" \u2014 "),wU=a("a"),HMr=o("TFMPNetForMultipleChoice"),UMr=o(" (MPNet model)"),JMr=l(),fE=a("li"),L5e=a("strong"),YMr=o("rembert"),KMr=o(" \u2014 "),AU=a("a"),ZMr=o("TFRemBertForMultipleChoice"),eEr=o(" (RemBERT model)"),oEr=l(),mE=a("li"),x5e=a("strong"),rEr=o("roberta"),tEr=o(" \u2014 "),yU=a("a"),aEr=o("TFRobertaForMultipleChoice"),nEr=o(" (RoBERTa model)"),sEr=l(),gE=a("li"),$5e=a("strong"),lEr=o("roformer"),iEr=o(" \u2014 "),LU=a("a"),dEr=o("TFRoFormerForMultipleChoice"),cEr=o(" (RoFormer model)"),fEr=l(),hE=a("li"),k5e=a("strong"),mEr=o("xlm"),gEr=o(" \u2014 "),xU=a("a"),hEr=o("TFXLMForMultipleChoice"),pEr=o(" (XLM model)"),uEr=l(),pE=a("li"),S5e=a("strong"),_Er=o("xlm-roberta"),bEr=o(" \u2014 "),$U=a("a"),vEr=o("TFXLMRobertaForMultipleChoice"),FEr=o(" (XLM-RoBERTa model)"),TEr=l(),uE=a("li"),R5e=a("strong"),MEr=o("xlnet"),EEr=o(" \u2014 "),kU=a("a"),CEr=o("TFXLNetForMultipleChoice"),wEr=o(" (XLNet model)"),AEr=l(),F(_E.$$.fragment),Mje=l(),hc=a("h2"),bE=a("a"),P5e=a("span"),F(H8.$$.fragment),yEr=l(),B5e=a("span"),LEr=o("TFAutoModelForNextSentencePrediction"),Eje=l(),nr=a("div"),F(U8.$$.fragment),xEr=l(),pc=a("p"),$Er=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),SU=a("a"),kEr=o("from_pretrained()"),SEr=o(" class method or the "),RU=a("a"),REr=o("from_config()"),PEr=o(` class
method.`),BEr=l(),J8=a("p"),IEr=o("This class cannot be instantiated directly using "),I5e=a("code"),qEr=o("__init__()"),NEr=o(" (throws an error)."),jEr=l(),Bt=a("div"),F(Y8.$$.fragment),DEr=l(),q5e=a("p"),GEr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),OEr=l(),uc=a("p"),VEr=o(`Note:
Loading a model from its configuration file does `),N5e=a("strong"),XEr=o("not"),zEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PU=a("a"),WEr=o("from_pretrained()"),QEr=o(" to load the model weights."),HEr=l(),F(vE.$$.fragment),UEr=l(),Rr=a("div"),F(K8.$$.fragment),JEr=l(),j5e=a("p"),YEr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),KEr=l(),ln=a("p"),ZEr=o("The model class to instantiate is selected based on the "),D5e=a("code"),eCr=o("model_type"),oCr=o(` property of the config object (either
passed as an argument or loaded from `),G5e=a("code"),rCr=o("pretrained_model_name_or_path"),tCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O5e=a("code"),aCr=o("pretrained_model_name_or_path"),nCr=o(":"),sCr=l(),Z8=a("ul"),FE=a("li"),V5e=a("strong"),lCr=o("bert"),iCr=o(" \u2014 "),BU=a("a"),dCr=o("TFBertForNextSentencePrediction"),cCr=o(" (BERT model)"),fCr=l(),TE=a("li"),X5e=a("strong"),mCr=o("mobilebert"),gCr=o(" \u2014 "),IU=a("a"),hCr=o("TFMobileBertForNextSentencePrediction"),pCr=o(" (MobileBERT model)"),uCr=l(),F(ME.$$.fragment),Cje=l(),_c=a("h2"),EE=a("a"),z5e=a("span"),F(e9.$$.fragment),_Cr=l(),W5e=a("span"),bCr=o("TFAutoModelForTableQuestionAnswering"),wje=l(),sr=a("div"),F(o9.$$.fragment),vCr=l(),bc=a("p"),FCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qU=a("a"),TCr=o("from_pretrained()"),MCr=o(" class method or the "),NU=a("a"),ECr=o("from_config()"),CCr=o(` class
method.`),wCr=l(),r9=a("p"),ACr=o("This class cannot be instantiated directly using "),Q5e=a("code"),yCr=o("__init__()"),LCr=o(" (throws an error)."),xCr=l(),It=a("div"),F(t9.$$.fragment),$Cr=l(),H5e=a("p"),kCr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),SCr=l(),vc=a("p"),RCr=o(`Note:
Loading a model from its configuration file does `),U5e=a("strong"),PCr=o("not"),BCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jU=a("a"),ICr=o("from_pretrained()"),qCr=o(" to load the model weights."),NCr=l(),F(CE.$$.fragment),jCr=l(),Pr=a("div"),F(a9.$$.fragment),DCr=l(),J5e=a("p"),GCr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),OCr=l(),dn=a("p"),VCr=o("The model class to instantiate is selected based on the "),Y5e=a("code"),XCr=o("model_type"),zCr=o(` property of the config object (either
passed as an argument or loaded from `),K5e=a("code"),WCr=o("pretrained_model_name_or_path"),QCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z5e=a("code"),HCr=o("pretrained_model_name_or_path"),UCr=o(":"),JCr=l(),eFe=a("ul"),wE=a("li"),oFe=a("strong"),YCr=o("tapas"),KCr=o(" \u2014 "),DU=a("a"),ZCr=o("TFTapasForQuestionAnswering"),e3r=o(" (TAPAS model)"),o3r=l(),F(AE.$$.fragment),Aje=l(),Fc=a("h2"),yE=a("a"),rFe=a("span"),F(n9.$$.fragment),r3r=l(),tFe=a("span"),t3r=o("TFAutoModelForTokenClassification"),yje=l(),lr=a("div"),F(s9.$$.fragment),a3r=l(),Tc=a("p"),n3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),GU=a("a"),s3r=o("from_pretrained()"),l3r=o(" class method or the "),OU=a("a"),i3r=o("from_config()"),d3r=o(` class
method.`),c3r=l(),l9=a("p"),f3r=o("This class cannot be instantiated directly using "),aFe=a("code"),m3r=o("__init__()"),g3r=o(" (throws an error)."),h3r=l(),qt=a("div"),F(i9.$$.fragment),p3r=l(),nFe=a("p"),u3r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),_3r=l(),Mc=a("p"),b3r=o(`Note:
Loading a model from its configuration file does `),sFe=a("strong"),v3r=o("not"),F3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),T3r=o("from_pretrained()"),M3r=o(" to load the model weights."),E3r=l(),F(LE.$$.fragment),C3r=l(),Br=a("div"),F(d9.$$.fragment),w3r=l(),lFe=a("p"),A3r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),y3r=l(),cn=a("p"),L3r=o("The model class to instantiate is selected based on the "),iFe=a("code"),x3r=o("model_type"),$3r=o(` property of the config object (either
passed as an argument or loaded from `),dFe=a("code"),k3r=o("pretrained_model_name_or_path"),S3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cFe=a("code"),R3r=o("pretrained_model_name_or_path"),P3r=o(":"),B3r=l(),de=a("ul"),xE=a("li"),fFe=a("strong"),I3r=o("albert"),q3r=o(" \u2014 "),XU=a("a"),N3r=o("TFAlbertForTokenClassification"),j3r=o(" (ALBERT model)"),D3r=l(),$E=a("li"),mFe=a("strong"),G3r=o("bert"),O3r=o(" \u2014 "),zU=a("a"),V3r=o("TFBertForTokenClassification"),X3r=o(" (BERT model)"),z3r=l(),kE=a("li"),gFe=a("strong"),W3r=o("camembert"),Q3r=o(" \u2014 "),WU=a("a"),H3r=o("TFCamembertForTokenClassification"),U3r=o(" (CamemBERT model)"),J3r=l(),SE=a("li"),hFe=a("strong"),Y3r=o("convbert"),K3r=o(" \u2014 "),QU=a("a"),Z3r=o("TFConvBertForTokenClassification"),ewr=o(" (ConvBERT model)"),owr=l(),RE=a("li"),pFe=a("strong"),rwr=o("deberta"),twr=o(" \u2014 "),HU=a("a"),awr=o("TFDebertaForTokenClassification"),nwr=o(" (DeBERTa model)"),swr=l(),PE=a("li"),uFe=a("strong"),lwr=o("deberta-v2"),iwr=o(" \u2014 "),UU=a("a"),dwr=o("TFDebertaV2ForTokenClassification"),cwr=o(" (DeBERTa-v2 model)"),fwr=l(),BE=a("li"),_Fe=a("strong"),mwr=o("distilbert"),gwr=o(" \u2014 "),JU=a("a"),hwr=o("TFDistilBertForTokenClassification"),pwr=o(" (DistilBERT model)"),uwr=l(),IE=a("li"),bFe=a("strong"),_wr=o("electra"),bwr=o(" \u2014 "),YU=a("a"),vwr=o("TFElectraForTokenClassification"),Fwr=o(" (ELECTRA model)"),Twr=l(),qE=a("li"),vFe=a("strong"),Mwr=o("flaubert"),Ewr=o(" \u2014 "),KU=a("a"),Cwr=o("TFFlaubertForTokenClassification"),wwr=o(" (FlauBERT model)"),Awr=l(),NE=a("li"),FFe=a("strong"),ywr=o("funnel"),Lwr=o(" \u2014 "),ZU=a("a"),xwr=o("TFFunnelForTokenClassification"),$wr=o(" (Funnel Transformer model)"),kwr=l(),jE=a("li"),TFe=a("strong"),Swr=o("layoutlm"),Rwr=o(" \u2014 "),eJ=a("a"),Pwr=o("TFLayoutLMForTokenClassification"),Bwr=o(" (LayoutLM model)"),Iwr=l(),DE=a("li"),MFe=a("strong"),qwr=o("longformer"),Nwr=o(" \u2014 "),oJ=a("a"),jwr=o("TFLongformerForTokenClassification"),Dwr=o(" (Longformer model)"),Gwr=l(),GE=a("li"),EFe=a("strong"),Owr=o("mobilebert"),Vwr=o(" \u2014 "),rJ=a("a"),Xwr=o("TFMobileBertForTokenClassification"),zwr=o(" (MobileBERT model)"),Wwr=l(),OE=a("li"),CFe=a("strong"),Qwr=o("mpnet"),Hwr=o(" \u2014 "),tJ=a("a"),Uwr=o("TFMPNetForTokenClassification"),Jwr=o(" (MPNet model)"),Ywr=l(),VE=a("li"),wFe=a("strong"),Kwr=o("rembert"),Zwr=o(" \u2014 "),aJ=a("a"),e0r=o("TFRemBertForTokenClassification"),o0r=o(" (RemBERT model)"),r0r=l(),XE=a("li"),AFe=a("strong"),t0r=o("roberta"),a0r=o(" \u2014 "),nJ=a("a"),n0r=o("TFRobertaForTokenClassification"),s0r=o(" (RoBERTa model)"),l0r=l(),zE=a("li"),yFe=a("strong"),i0r=o("roformer"),d0r=o(" \u2014 "),sJ=a("a"),c0r=o("TFRoFormerForTokenClassification"),f0r=o(" (RoFormer model)"),m0r=l(),WE=a("li"),LFe=a("strong"),g0r=o("xlm"),h0r=o(" \u2014 "),lJ=a("a"),p0r=o("TFXLMForTokenClassification"),u0r=o(" (XLM model)"),_0r=l(),QE=a("li"),xFe=a("strong"),b0r=o("xlm-roberta"),v0r=o(" \u2014 "),iJ=a("a"),F0r=o("TFXLMRobertaForTokenClassification"),T0r=o(" (XLM-RoBERTa model)"),M0r=l(),HE=a("li"),$Fe=a("strong"),E0r=o("xlnet"),C0r=o(" \u2014 "),dJ=a("a"),w0r=o("TFXLNetForTokenClassification"),A0r=o(" (XLNet model)"),y0r=l(),F(UE.$$.fragment),Lje=l(),Ec=a("h2"),JE=a("a"),kFe=a("span"),F(c9.$$.fragment),L0r=l(),SFe=a("span"),x0r=o("TFAutoModelForQuestionAnswering"),xje=l(),ir=a("div"),F(f9.$$.fragment),$0r=l(),Cc=a("p"),k0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cJ=a("a"),S0r=o("from_pretrained()"),R0r=o(" class method or the "),fJ=a("a"),P0r=o("from_config()"),B0r=o(` class
method.`),I0r=l(),m9=a("p"),q0r=o("This class cannot be instantiated directly using "),RFe=a("code"),N0r=o("__init__()"),j0r=o(" (throws an error)."),D0r=l(),Nt=a("div"),F(g9.$$.fragment),G0r=l(),PFe=a("p"),O0r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),V0r=l(),wc=a("p"),X0r=o(`Note:
Loading a model from its configuration file does `),BFe=a("strong"),z0r=o("not"),W0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mJ=a("a"),Q0r=o("from_pretrained()"),H0r=o(" to load the model weights."),U0r=l(),F(YE.$$.fragment),J0r=l(),Ir=a("div"),F(h9.$$.fragment),Y0r=l(),IFe=a("p"),K0r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Z0r=l(),fn=a("p"),e6r=o("The model class to instantiate is selected based on the "),qFe=a("code"),o6r=o("model_type"),r6r=o(` property of the config object (either
passed as an argument or loaded from `),NFe=a("code"),t6r=o("pretrained_model_name_or_path"),a6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jFe=a("code"),n6r=o("pretrained_model_name_or_path"),s6r=o(":"),l6r=l(),ce=a("ul"),KE=a("li"),DFe=a("strong"),i6r=o("albert"),d6r=o(" \u2014 "),gJ=a("a"),c6r=o("TFAlbertForQuestionAnswering"),f6r=o(" (ALBERT model)"),m6r=l(),ZE=a("li"),GFe=a("strong"),g6r=o("bert"),h6r=o(" \u2014 "),hJ=a("a"),p6r=o("TFBertForQuestionAnswering"),u6r=o(" (BERT model)"),_6r=l(),eC=a("li"),OFe=a("strong"),b6r=o("camembert"),v6r=o(" \u2014 "),pJ=a("a"),F6r=o("TFCamembertForQuestionAnswering"),T6r=o(" (CamemBERT model)"),M6r=l(),oC=a("li"),VFe=a("strong"),E6r=o("convbert"),C6r=o(" \u2014 "),uJ=a("a"),w6r=o("TFConvBertForQuestionAnswering"),A6r=o(" (ConvBERT model)"),y6r=l(),rC=a("li"),XFe=a("strong"),L6r=o("deberta"),x6r=o(" \u2014 "),_J=a("a"),$6r=o("TFDebertaForQuestionAnswering"),k6r=o(" (DeBERTa model)"),S6r=l(),tC=a("li"),zFe=a("strong"),R6r=o("deberta-v2"),P6r=o(" \u2014 "),bJ=a("a"),B6r=o("TFDebertaV2ForQuestionAnswering"),I6r=o(" (DeBERTa-v2 model)"),q6r=l(),aC=a("li"),WFe=a("strong"),N6r=o("distilbert"),j6r=o(" \u2014 "),vJ=a("a"),D6r=o("TFDistilBertForQuestionAnswering"),G6r=o(" (DistilBERT model)"),O6r=l(),nC=a("li"),QFe=a("strong"),V6r=o("electra"),X6r=o(" \u2014 "),FJ=a("a"),z6r=o("TFElectraForQuestionAnswering"),W6r=o(" (ELECTRA model)"),Q6r=l(),sC=a("li"),HFe=a("strong"),H6r=o("flaubert"),U6r=o(" \u2014 "),TJ=a("a"),J6r=o("TFFlaubertForQuestionAnsweringSimple"),Y6r=o(" (FlauBERT model)"),K6r=l(),lC=a("li"),UFe=a("strong"),Z6r=o("funnel"),eAr=o(" \u2014 "),MJ=a("a"),oAr=o("TFFunnelForQuestionAnswering"),rAr=o(" (Funnel Transformer model)"),tAr=l(),iC=a("li"),JFe=a("strong"),aAr=o("gptj"),nAr=o(" \u2014 "),EJ=a("a"),sAr=o("TFGPTJForQuestionAnswering"),lAr=o(" (GPT-J model)"),iAr=l(),dC=a("li"),YFe=a("strong"),dAr=o("longformer"),cAr=o(" \u2014 "),CJ=a("a"),fAr=o("TFLongformerForQuestionAnswering"),mAr=o(" (Longformer model)"),gAr=l(),cC=a("li"),KFe=a("strong"),hAr=o("mobilebert"),pAr=o(" \u2014 "),wJ=a("a"),uAr=o("TFMobileBertForQuestionAnswering"),_Ar=o(" (MobileBERT model)"),bAr=l(),fC=a("li"),ZFe=a("strong"),vAr=o("mpnet"),FAr=o(" \u2014 "),AJ=a("a"),TAr=o("TFMPNetForQuestionAnswering"),MAr=o(" (MPNet model)"),EAr=l(),mC=a("li"),eTe=a("strong"),CAr=o("rembert"),wAr=o(" \u2014 "),yJ=a("a"),AAr=o("TFRemBertForQuestionAnswering"),yAr=o(" (RemBERT model)"),LAr=l(),gC=a("li"),oTe=a("strong"),xAr=o("roberta"),$Ar=o(" \u2014 "),LJ=a("a"),kAr=o("TFRobertaForQuestionAnswering"),SAr=o(" (RoBERTa model)"),RAr=l(),hC=a("li"),rTe=a("strong"),PAr=o("roformer"),BAr=o(" \u2014 "),xJ=a("a"),IAr=o("TFRoFormerForQuestionAnswering"),qAr=o(" (RoFormer model)"),NAr=l(),pC=a("li"),tTe=a("strong"),jAr=o("xlm"),DAr=o(" \u2014 "),$J=a("a"),GAr=o("TFXLMForQuestionAnsweringSimple"),OAr=o(" (XLM model)"),VAr=l(),uC=a("li"),aTe=a("strong"),XAr=o("xlm-roberta"),zAr=o(" \u2014 "),kJ=a("a"),WAr=o("TFXLMRobertaForQuestionAnswering"),QAr=o(" (XLM-RoBERTa model)"),HAr=l(),_C=a("li"),nTe=a("strong"),UAr=o("xlnet"),JAr=o(" \u2014 "),SJ=a("a"),YAr=o("TFXLNetForQuestionAnsweringSimple"),KAr=o(" (XLNet model)"),ZAr=l(),F(bC.$$.fragment),$je=l(),Ac=a("h2"),vC=a("a"),sTe=a("span"),F(p9.$$.fragment),eyr=l(),lTe=a("span"),oyr=o("TFAutoModelForVision2Seq"),kje=l(),dr=a("div"),F(u9.$$.fragment),ryr=l(),yc=a("p"),tyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),RJ=a("a"),ayr=o("from_pretrained()"),nyr=o(" class method or the "),PJ=a("a"),syr=o("from_config()"),lyr=o(` class
method.`),iyr=l(),_9=a("p"),dyr=o("This class cannot be instantiated directly using "),iTe=a("code"),cyr=o("__init__()"),fyr=o(" (throws an error)."),myr=l(),jt=a("div"),F(b9.$$.fragment),gyr=l(),dTe=a("p"),hyr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pyr=l(),Lc=a("p"),uyr=o(`Note:
Loading a model from its configuration file does `),cTe=a("strong"),_yr=o("not"),byr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=a("a"),vyr=o("from_pretrained()"),Fyr=o(" to load the model weights."),Tyr=l(),F(FC.$$.fragment),Myr=l(),qr=a("div"),F(v9.$$.fragment),Eyr=l(),fTe=a("p"),Cyr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),wyr=l(),mn=a("p"),Ayr=o("The model class to instantiate is selected based on the "),mTe=a("code"),yyr=o("model_type"),Lyr=o(` property of the config object (either
passed as an argument or loaded from `),gTe=a("code"),xyr=o("pretrained_model_name_or_path"),$yr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hTe=a("code"),kyr=o("pretrained_model_name_or_path"),Syr=o(":"),Ryr=l(),pTe=a("ul"),TC=a("li"),uTe=a("strong"),Pyr=o("vision-encoder-decoder"),Byr=o(" \u2014 "),IJ=a("a"),Iyr=o("TFVisionEncoderDecoderModel"),qyr=o(" (Vision Encoder decoder model)"),Nyr=l(),F(MC.$$.fragment),Sje=l(),xc=a("h2"),EC=a("a"),_Te=a("span"),F(F9.$$.fragment),jyr=l(),bTe=a("span"),Dyr=o("TFAutoModelForSpeechSeq2Seq"),Rje=l(),cr=a("div"),F(T9.$$.fragment),Gyr=l(),$c=a("p"),Oyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),qJ=a("a"),Vyr=o("from_pretrained()"),Xyr=o(" class method or the "),NJ=a("a"),zyr=o("from_config()"),Wyr=o(` class
method.`),Qyr=l(),M9=a("p"),Hyr=o("This class cannot be instantiated directly using "),vTe=a("code"),Uyr=o("__init__()"),Jyr=o(" (throws an error)."),Yyr=l(),Dt=a("div"),F(E9.$$.fragment),Kyr=l(),FTe=a("p"),Zyr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),eLr=l(),kc=a("p"),oLr=o(`Note:
Loading a model from its configuration file does `),TTe=a("strong"),rLr=o("not"),tLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jJ=a("a"),aLr=o("from_pretrained()"),nLr=o(" to load the model weights."),sLr=l(),F(CC.$$.fragment),lLr=l(),Nr=a("div"),F(C9.$$.fragment),iLr=l(),MTe=a("p"),dLr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),cLr=l(),gn=a("p"),fLr=o("The model class to instantiate is selected based on the "),ETe=a("code"),mLr=o("model_type"),gLr=o(` property of the config object (either
passed as an argument or loaded from `),CTe=a("code"),hLr=o("pretrained_model_name_or_path"),pLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wTe=a("code"),uLr=o("pretrained_model_name_or_path"),_Lr=o(":"),bLr=l(),ATe=a("ul"),wC=a("li"),yTe=a("strong"),vLr=o("speech_to_text"),FLr=o(" \u2014 "),DJ=a("a"),TLr=o("TFSpeech2TextForConditionalGeneration"),MLr=o(" (Speech2Text model)"),ELr=l(),F(AC.$$.fragment),Pje=l(),Sc=a("h2"),yC=a("a"),LTe=a("span"),F(w9.$$.fragment),CLr=l(),xTe=a("span"),wLr=o("FlaxAutoModel"),Bje=l(),fr=a("div"),F(A9.$$.fragment),ALr=l(),Rc=a("p"),yLr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),GJ=a("a"),LLr=o("from_pretrained()"),xLr=o(" class method or the "),OJ=a("a"),$Lr=o("from_config()"),kLr=o(` class
method.`),SLr=l(),y9=a("p"),RLr=o("This class cannot be instantiated directly using "),$Te=a("code"),PLr=o("__init__()"),BLr=o(" (throws an error)."),ILr=l(),Gt=a("div"),F(L9.$$.fragment),qLr=l(),kTe=a("p"),NLr=o("Instantiates one of the base model classes of the library from a configuration."),jLr=l(),Pc=a("p"),DLr=o(`Note:
Loading a model from its configuration file does `),STe=a("strong"),GLr=o("not"),OLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VJ=a("a"),VLr=o("from_pretrained()"),XLr=o(" to load the model weights."),zLr=l(),F(LC.$$.fragment),WLr=l(),jr=a("div"),F(x9.$$.fragment),QLr=l(),RTe=a("p"),HLr=o("Instantiate one of the base model classes of the library from a pretrained model."),ULr=l(),hn=a("p"),JLr=o("The model class to instantiate is selected based on the "),PTe=a("code"),YLr=o("model_type"),KLr=o(` property of the config object (either
passed as an argument or loaded from `),BTe=a("code"),ZLr=o("pretrained_model_name_or_path"),e8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ITe=a("code"),o8r=o("pretrained_model_name_or_path"),r8r=o(":"),t8r=l(),te=a("ul"),xC=a("li"),qTe=a("strong"),a8r=o("albert"),n8r=o(" \u2014 "),XJ=a("a"),s8r=o("FlaxAlbertModel"),l8r=o(" (ALBERT model)"),i8r=l(),$C=a("li"),NTe=a("strong"),d8r=o("bart"),c8r=o(" \u2014 "),zJ=a("a"),f8r=o("FlaxBartModel"),m8r=o(" (BART model)"),g8r=l(),kC=a("li"),jTe=a("strong"),h8r=o("beit"),p8r=o(" \u2014 "),WJ=a("a"),u8r=o("FlaxBeitModel"),_8r=o(" (BEiT model)"),b8r=l(),SC=a("li"),DTe=a("strong"),v8r=o("bert"),F8r=o(" \u2014 "),QJ=a("a"),T8r=o("FlaxBertModel"),M8r=o(" (BERT model)"),E8r=l(),RC=a("li"),GTe=a("strong"),C8r=o("big_bird"),w8r=o(" \u2014 "),HJ=a("a"),A8r=o("FlaxBigBirdModel"),y8r=o(" (BigBird model)"),L8r=l(),PC=a("li"),OTe=a("strong"),x8r=o("blenderbot"),$8r=o(" \u2014 "),UJ=a("a"),k8r=o("FlaxBlenderbotModel"),S8r=o(" (Blenderbot model)"),R8r=l(),BC=a("li"),VTe=a("strong"),P8r=o("blenderbot-small"),B8r=o(" \u2014 "),JJ=a("a"),I8r=o("FlaxBlenderbotSmallModel"),q8r=o(" (BlenderbotSmall model)"),N8r=l(),IC=a("li"),XTe=a("strong"),j8r=o("clip"),D8r=o(" \u2014 "),YJ=a("a"),G8r=o("FlaxCLIPModel"),O8r=o(" (CLIP model)"),V8r=l(),qC=a("li"),zTe=a("strong"),X8r=o("distilbert"),z8r=o(" \u2014 "),KJ=a("a"),W8r=o("FlaxDistilBertModel"),Q8r=o(" (DistilBERT model)"),H8r=l(),NC=a("li"),WTe=a("strong"),U8r=o("electra"),J8r=o(" \u2014 "),ZJ=a("a"),Y8r=o("FlaxElectraModel"),K8r=o(" (ELECTRA model)"),Z8r=l(),jC=a("li"),QTe=a("strong"),e9r=o("gpt2"),o9r=o(" \u2014 "),eY=a("a"),r9r=o("FlaxGPT2Model"),t9r=o(" (OpenAI GPT-2 model)"),a9r=l(),DC=a("li"),HTe=a("strong"),n9r=o("gpt_neo"),s9r=o(" \u2014 "),oY=a("a"),l9r=o("FlaxGPTNeoModel"),i9r=o(" (GPT Neo model)"),d9r=l(),GC=a("li"),UTe=a("strong"),c9r=o("gptj"),f9r=o(" \u2014 "),rY=a("a"),m9r=o("FlaxGPTJModel"),g9r=o(" (GPT-J model)"),h9r=l(),OC=a("li"),JTe=a("strong"),p9r=o("marian"),u9r=o(" \u2014 "),tY=a("a"),_9r=o("FlaxMarianModel"),b9r=o(" (Marian model)"),v9r=l(),VC=a("li"),YTe=a("strong"),F9r=o("mbart"),T9r=o(" \u2014 "),aY=a("a"),M9r=o("FlaxMBartModel"),E9r=o(" (mBART model)"),C9r=l(),XC=a("li"),KTe=a("strong"),w9r=o("mt5"),A9r=o(" \u2014 "),nY=a("a"),y9r=o("FlaxMT5Model"),L9r=o(" (mT5 model)"),x9r=l(),zC=a("li"),ZTe=a("strong"),$9r=o("pegasus"),k9r=o(" \u2014 "),sY=a("a"),S9r=o("FlaxPegasusModel"),R9r=o(" (Pegasus model)"),P9r=l(),WC=a("li"),e7e=a("strong"),B9r=o("roberta"),I9r=o(" \u2014 "),lY=a("a"),q9r=o("FlaxRobertaModel"),N9r=o(" (RoBERTa model)"),j9r=l(),QC=a("li"),o7e=a("strong"),D9r=o("roformer"),G9r=o(" \u2014 "),iY=a("a"),O9r=o("FlaxRoFormerModel"),V9r=o(" (RoFormer model)"),X9r=l(),HC=a("li"),r7e=a("strong"),z9r=o("t5"),W9r=o(" \u2014 "),dY=a("a"),Q9r=o("FlaxT5Model"),H9r=o(" (T5 model)"),U9r=l(),UC=a("li"),t7e=a("strong"),J9r=o("vision-text-dual-encoder"),Y9r=o(" \u2014 "),cY=a("a"),K9r=o("FlaxVisionTextDualEncoderModel"),Z9r=o(" (VisionTextDualEncoder model)"),exr=l(),JC=a("li"),a7e=a("strong"),oxr=o("vit"),rxr=o(" \u2014 "),fY=a("a"),txr=o("FlaxViTModel"),axr=o(" (ViT model)"),nxr=l(),YC=a("li"),n7e=a("strong"),sxr=o("wav2vec2"),lxr=o(" \u2014 "),mY=a("a"),ixr=o("FlaxWav2Vec2Model"),dxr=o(" (Wav2Vec2 model)"),cxr=l(),KC=a("li"),s7e=a("strong"),fxr=o("xglm"),mxr=o(" \u2014 "),gY=a("a"),gxr=o("FlaxXGLMModel"),hxr=o(" (XGLM model)"),pxr=l(),ZC=a("li"),l7e=a("strong"),uxr=o("xlm-roberta"),_xr=o(" \u2014 "),hY=a("a"),bxr=o("FlaxXLMRobertaModel"),vxr=o(" (XLM-RoBERTa model)"),Fxr=l(),F(e3.$$.fragment),Ije=l(),Bc=a("h2"),o3=a("a"),i7e=a("span"),F($9.$$.fragment),Txr=l(),d7e=a("span"),Mxr=o("FlaxAutoModelForCausalLM"),qje=l(),mr=a("div"),F(k9.$$.fragment),Exr=l(),Ic=a("p"),Cxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),pY=a("a"),wxr=o("from_pretrained()"),Axr=o(" class method or the "),uY=a("a"),yxr=o("from_config()"),Lxr=o(` class
method.`),xxr=l(),S9=a("p"),$xr=o("This class cannot be instantiated directly using "),c7e=a("code"),kxr=o("__init__()"),Sxr=o(" (throws an error)."),Rxr=l(),Ot=a("div"),F(R9.$$.fragment),Pxr=l(),f7e=a("p"),Bxr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Ixr=l(),qc=a("p"),qxr=o(`Note:
Loading a model from its configuration file does `),m7e=a("strong"),Nxr=o("not"),jxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Y=a("a"),Dxr=o("from_pretrained()"),Gxr=o(" to load the model weights."),Oxr=l(),F(r3.$$.fragment),Vxr=l(),Dr=a("div"),F(P9.$$.fragment),Xxr=l(),g7e=a("p"),zxr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Wxr=l(),pn=a("p"),Qxr=o("The model class to instantiate is selected based on the "),h7e=a("code"),Hxr=o("model_type"),Uxr=o(` property of the config object (either
passed as an argument or loaded from `),p7e=a("code"),Jxr=o("pretrained_model_name_or_path"),Yxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u7e=a("code"),Kxr=o("pretrained_model_name_or_path"),Zxr=o(":"),e$r=l(),Re=a("ul"),t3=a("li"),_7e=a("strong"),o$r=o("bart"),r$r=o(" \u2014 "),bY=a("a"),t$r=o("FlaxBartForCausalLM"),a$r=o(" (BART model)"),n$r=l(),a3=a("li"),b7e=a("strong"),s$r=o("bert"),l$r=o(" \u2014 "),vY=a("a"),i$r=o("FlaxBertForCausalLM"),d$r=o(" (BERT model)"),c$r=l(),n3=a("li"),v7e=a("strong"),f$r=o("big_bird"),m$r=o(" \u2014 "),FY=a("a"),g$r=o("FlaxBigBirdForCausalLM"),h$r=o(" (BigBird model)"),p$r=l(),s3=a("li"),F7e=a("strong"),u$r=o("electra"),_$r=o(" \u2014 "),TY=a("a"),b$r=o("FlaxElectraForCausalLM"),v$r=o(" (ELECTRA model)"),F$r=l(),l3=a("li"),T7e=a("strong"),T$r=o("gpt2"),M$r=o(" \u2014 "),MY=a("a"),E$r=o("FlaxGPT2LMHeadModel"),C$r=o(" (OpenAI GPT-2 model)"),w$r=l(),i3=a("li"),M7e=a("strong"),A$r=o("gpt_neo"),y$r=o(" \u2014 "),EY=a("a"),L$r=o("FlaxGPTNeoForCausalLM"),x$r=o(" (GPT Neo model)"),$$r=l(),d3=a("li"),E7e=a("strong"),k$r=o("gptj"),S$r=o(" \u2014 "),CY=a("a"),R$r=o("FlaxGPTJForCausalLM"),P$r=o(" (GPT-J model)"),B$r=l(),c3=a("li"),C7e=a("strong"),I$r=o("roberta"),q$r=o(" \u2014 "),wY=a("a"),N$r=o("FlaxRobertaForCausalLM"),j$r=o(" (RoBERTa model)"),D$r=l(),f3=a("li"),w7e=a("strong"),G$r=o("xglm"),O$r=o(" \u2014 "),AY=a("a"),V$r=o("FlaxXGLMForCausalLM"),X$r=o(" (XGLM model)"),z$r=l(),F(m3.$$.fragment),Nje=l(),Nc=a("h2"),g3=a("a"),A7e=a("span"),F(B9.$$.fragment),W$r=l(),y7e=a("span"),Q$r=o("FlaxAutoModelForPreTraining"),jje=l(),gr=a("div"),F(I9.$$.fragment),H$r=l(),jc=a("p"),U$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yY=a("a"),J$r=o("from_pretrained()"),Y$r=o(" class method or the "),LY=a("a"),K$r=o("from_config()"),Z$r=o(` class
method.`),ekr=l(),q9=a("p"),okr=o("This class cannot be instantiated directly using "),L7e=a("code"),rkr=o("__init__()"),tkr=o(" (throws an error)."),akr=l(),Vt=a("div"),F(N9.$$.fragment),nkr=l(),x7e=a("p"),skr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),lkr=l(),Dc=a("p"),ikr=o(`Note:
Loading a model from its configuration file does `),$7e=a("strong"),dkr=o("not"),ckr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xY=a("a"),fkr=o("from_pretrained()"),mkr=o(" to load the model weights."),gkr=l(),F(h3.$$.fragment),hkr=l(),Gr=a("div"),F(j9.$$.fragment),pkr=l(),k7e=a("p"),ukr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),_kr=l(),un=a("p"),bkr=o("The model class to instantiate is selected based on the "),S7e=a("code"),vkr=o("model_type"),Fkr=o(` property of the config object (either
passed as an argument or loaded from `),R7e=a("code"),Tkr=o("pretrained_model_name_or_path"),Mkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P7e=a("code"),Ekr=o("pretrained_model_name_or_path"),Ckr=o(":"),wkr=l(),Ee=a("ul"),p3=a("li"),B7e=a("strong"),Akr=o("albert"),ykr=o(" \u2014 "),$Y=a("a"),Lkr=o("FlaxAlbertForPreTraining"),xkr=o(" (ALBERT model)"),$kr=l(),u3=a("li"),I7e=a("strong"),kkr=o("bart"),Skr=o(" \u2014 "),kY=a("a"),Rkr=o("FlaxBartForConditionalGeneration"),Pkr=o(" (BART model)"),Bkr=l(),_3=a("li"),q7e=a("strong"),Ikr=o("bert"),qkr=o(" \u2014 "),SY=a("a"),Nkr=o("FlaxBertForPreTraining"),jkr=o(" (BERT model)"),Dkr=l(),b3=a("li"),N7e=a("strong"),Gkr=o("big_bird"),Okr=o(" \u2014 "),RY=a("a"),Vkr=o("FlaxBigBirdForPreTraining"),Xkr=o(" (BigBird model)"),zkr=l(),v3=a("li"),j7e=a("strong"),Wkr=o("electra"),Qkr=o(" \u2014 "),PY=a("a"),Hkr=o("FlaxElectraForPreTraining"),Ukr=o(" (ELECTRA model)"),Jkr=l(),F3=a("li"),D7e=a("strong"),Ykr=o("mbart"),Kkr=o(" \u2014 "),BY=a("a"),Zkr=o("FlaxMBartForConditionalGeneration"),eSr=o(" (mBART model)"),oSr=l(),T3=a("li"),G7e=a("strong"),rSr=o("mt5"),tSr=o(" \u2014 "),IY=a("a"),aSr=o("FlaxMT5ForConditionalGeneration"),nSr=o(" (mT5 model)"),sSr=l(),M3=a("li"),O7e=a("strong"),lSr=o("roberta"),iSr=o(" \u2014 "),qY=a("a"),dSr=o("FlaxRobertaForMaskedLM"),cSr=o(" (RoBERTa model)"),fSr=l(),E3=a("li"),V7e=a("strong"),mSr=o("roformer"),gSr=o(" \u2014 "),NY=a("a"),hSr=o("FlaxRoFormerForMaskedLM"),pSr=o(" (RoFormer model)"),uSr=l(),C3=a("li"),X7e=a("strong"),_Sr=o("t5"),bSr=o(" \u2014 "),jY=a("a"),vSr=o("FlaxT5ForConditionalGeneration"),FSr=o(" (T5 model)"),TSr=l(),w3=a("li"),z7e=a("strong"),MSr=o("wav2vec2"),ESr=o(" \u2014 "),DY=a("a"),CSr=o("FlaxWav2Vec2ForPreTraining"),wSr=o(" (Wav2Vec2 model)"),ASr=l(),A3=a("li"),W7e=a("strong"),ySr=o("xlm-roberta"),LSr=o(" \u2014 "),GY=a("a"),xSr=o("FlaxXLMRobertaForMaskedLM"),$Sr=o(" (XLM-RoBERTa model)"),kSr=l(),F(y3.$$.fragment),Dje=l(),Gc=a("h2"),L3=a("a"),Q7e=a("span"),F(D9.$$.fragment),SSr=l(),H7e=a("span"),RSr=o("FlaxAutoModelForMaskedLM"),Gje=l(),hr=a("div"),F(G9.$$.fragment),PSr=l(),Oc=a("p"),BSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),OY=a("a"),ISr=o("from_pretrained()"),qSr=o(" class method or the "),VY=a("a"),NSr=o("from_config()"),jSr=o(` class
method.`),DSr=l(),O9=a("p"),GSr=o("This class cannot be instantiated directly using "),U7e=a("code"),OSr=o("__init__()"),VSr=o(" (throws an error)."),XSr=l(),Xt=a("div"),F(V9.$$.fragment),zSr=l(),J7e=a("p"),WSr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),QSr=l(),Vc=a("p"),HSr=o(`Note:
Loading a model from its configuration file does `),Y7e=a("strong"),USr=o("not"),JSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XY=a("a"),YSr=o("from_pretrained()"),KSr=o(" to load the model weights."),ZSr=l(),F(x3.$$.fragment),eRr=l(),Or=a("div"),F(X9.$$.fragment),oRr=l(),K7e=a("p"),rRr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),tRr=l(),_n=a("p"),aRr=o("The model class to instantiate is selected based on the "),Z7e=a("code"),nRr=o("model_type"),sRr=o(` property of the config object (either
passed as an argument or loaded from `),eMe=a("code"),lRr=o("pretrained_model_name_or_path"),iRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oMe=a("code"),dRr=o("pretrained_model_name_or_path"),cRr=o(":"),fRr=l(),Le=a("ul"),$3=a("li"),rMe=a("strong"),mRr=o("albert"),gRr=o(" \u2014 "),zY=a("a"),hRr=o("FlaxAlbertForMaskedLM"),pRr=o(" (ALBERT model)"),uRr=l(),k3=a("li"),tMe=a("strong"),_Rr=o("bart"),bRr=o(" \u2014 "),WY=a("a"),vRr=o("FlaxBartForConditionalGeneration"),FRr=o(" (BART model)"),TRr=l(),S3=a("li"),aMe=a("strong"),MRr=o("bert"),ERr=o(" \u2014 "),QY=a("a"),CRr=o("FlaxBertForMaskedLM"),wRr=o(" (BERT model)"),ARr=l(),R3=a("li"),nMe=a("strong"),yRr=o("big_bird"),LRr=o(" \u2014 "),HY=a("a"),xRr=o("FlaxBigBirdForMaskedLM"),$Rr=o(" (BigBird model)"),kRr=l(),P3=a("li"),sMe=a("strong"),SRr=o("distilbert"),RRr=o(" \u2014 "),UY=a("a"),PRr=o("FlaxDistilBertForMaskedLM"),BRr=o(" (DistilBERT model)"),IRr=l(),B3=a("li"),lMe=a("strong"),qRr=o("electra"),NRr=o(" \u2014 "),JY=a("a"),jRr=o("FlaxElectraForMaskedLM"),DRr=o(" (ELECTRA model)"),GRr=l(),I3=a("li"),iMe=a("strong"),ORr=o("mbart"),VRr=o(" \u2014 "),YY=a("a"),XRr=o("FlaxMBartForConditionalGeneration"),zRr=o(" (mBART model)"),WRr=l(),q3=a("li"),dMe=a("strong"),QRr=o("roberta"),HRr=o(" \u2014 "),KY=a("a"),URr=o("FlaxRobertaForMaskedLM"),JRr=o(" (RoBERTa model)"),YRr=l(),N3=a("li"),cMe=a("strong"),KRr=o("roformer"),ZRr=o(" \u2014 "),ZY=a("a"),ePr=o("FlaxRoFormerForMaskedLM"),oPr=o(" (RoFormer model)"),rPr=l(),j3=a("li"),fMe=a("strong"),tPr=o("xlm-roberta"),aPr=o(" \u2014 "),eK=a("a"),nPr=o("FlaxXLMRobertaForMaskedLM"),sPr=o(" (XLM-RoBERTa model)"),lPr=l(),F(D3.$$.fragment),Oje=l(),Xc=a("h2"),G3=a("a"),mMe=a("span"),F(z9.$$.fragment),iPr=l(),gMe=a("span"),dPr=o("FlaxAutoModelForSeq2SeqLM"),Vje=l(),pr=a("div"),F(W9.$$.fragment),cPr=l(),zc=a("p"),fPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),oK=a("a"),mPr=o("from_pretrained()"),gPr=o(" class method or the "),rK=a("a"),hPr=o("from_config()"),pPr=o(` class
method.`),uPr=l(),Q9=a("p"),_Pr=o("This class cannot be instantiated directly using "),hMe=a("code"),bPr=o("__init__()"),vPr=o(" (throws an error)."),FPr=l(),zt=a("div"),F(H9.$$.fragment),TPr=l(),pMe=a("p"),MPr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),EPr=l(),Wc=a("p"),CPr=o(`Note:
Loading a model from its configuration file does `),uMe=a("strong"),wPr=o("not"),APr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=a("a"),yPr=o("from_pretrained()"),LPr=o(" to load the model weights."),xPr=l(),F(O3.$$.fragment),$Pr=l(),Vr=a("div"),F(U9.$$.fragment),kPr=l(),_Me=a("p"),SPr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),RPr=l(),bn=a("p"),PPr=o("The model class to instantiate is selected based on the "),bMe=a("code"),BPr=o("model_type"),IPr=o(` property of the config object (either
passed as an argument or loaded from `),vMe=a("code"),qPr=o("pretrained_model_name_or_path"),NPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FMe=a("code"),jPr=o("pretrained_model_name_or_path"),DPr=o(":"),GPr=l(),Pe=a("ul"),V3=a("li"),TMe=a("strong"),OPr=o("bart"),VPr=o(" \u2014 "),aK=a("a"),XPr=o("FlaxBartForConditionalGeneration"),zPr=o(" (BART model)"),WPr=l(),X3=a("li"),MMe=a("strong"),QPr=o("blenderbot"),HPr=o(" \u2014 "),nK=a("a"),UPr=o("FlaxBlenderbotForConditionalGeneration"),JPr=o(" (Blenderbot model)"),YPr=l(),z3=a("li"),EMe=a("strong"),KPr=o("blenderbot-small"),ZPr=o(" \u2014 "),sK=a("a"),eBr=o("FlaxBlenderbotSmallForConditionalGeneration"),oBr=o(" (BlenderbotSmall model)"),rBr=l(),W3=a("li"),CMe=a("strong"),tBr=o("encoder-decoder"),aBr=o(" \u2014 "),lK=a("a"),nBr=o("FlaxEncoderDecoderModel"),sBr=o(" (Encoder decoder model)"),lBr=l(),Q3=a("li"),wMe=a("strong"),iBr=o("marian"),dBr=o(" \u2014 "),iK=a("a"),cBr=o("FlaxMarianMTModel"),fBr=o(" (Marian model)"),mBr=l(),H3=a("li"),AMe=a("strong"),gBr=o("mbart"),hBr=o(" \u2014 "),dK=a("a"),pBr=o("FlaxMBartForConditionalGeneration"),uBr=o(" (mBART model)"),_Br=l(),U3=a("li"),yMe=a("strong"),bBr=o("mt5"),vBr=o(" \u2014 "),cK=a("a"),FBr=o("FlaxMT5ForConditionalGeneration"),TBr=o(" (mT5 model)"),MBr=l(),J3=a("li"),LMe=a("strong"),EBr=o("pegasus"),CBr=o(" \u2014 "),fK=a("a"),wBr=o("FlaxPegasusForConditionalGeneration"),ABr=o(" (Pegasus model)"),yBr=l(),Y3=a("li"),xMe=a("strong"),LBr=o("t5"),xBr=o(" \u2014 "),mK=a("a"),$Br=o("FlaxT5ForConditionalGeneration"),kBr=o(" (T5 model)"),SBr=l(),F(K3.$$.fragment),Xje=l(),Qc=a("h2"),Z3=a("a"),$Me=a("span"),F(J9.$$.fragment),RBr=l(),kMe=a("span"),PBr=o("FlaxAutoModelForSequenceClassification"),zje=l(),ur=a("div"),F(Y9.$$.fragment),BBr=l(),Hc=a("p"),IBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gK=a("a"),qBr=o("from_pretrained()"),NBr=o(" class method or the "),hK=a("a"),jBr=o("from_config()"),DBr=o(` class
method.`),GBr=l(),K9=a("p"),OBr=o("This class cannot be instantiated directly using "),SMe=a("code"),VBr=o("__init__()"),XBr=o(" (throws an error)."),zBr=l(),Wt=a("div"),F(Z9.$$.fragment),WBr=l(),RMe=a("p"),QBr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),HBr=l(),Uc=a("p"),UBr=o(`Note:
Loading a model from its configuration file does `),PMe=a("strong"),JBr=o("not"),YBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pK=a("a"),KBr=o("from_pretrained()"),ZBr=o(" to load the model weights."),eIr=l(),F(ew.$$.fragment),oIr=l(),Xr=a("div"),F(ex.$$.fragment),rIr=l(),BMe=a("p"),tIr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),aIr=l(),vn=a("p"),nIr=o("The model class to instantiate is selected based on the "),IMe=a("code"),sIr=o("model_type"),lIr=o(` property of the config object (either
passed as an argument or loaded from `),qMe=a("code"),iIr=o("pretrained_model_name_or_path"),dIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NMe=a("code"),cIr=o("pretrained_model_name_or_path"),fIr=o(":"),mIr=l(),xe=a("ul"),ow=a("li"),jMe=a("strong"),gIr=o("albert"),hIr=o(" \u2014 "),uK=a("a"),pIr=o("FlaxAlbertForSequenceClassification"),uIr=o(" (ALBERT model)"),_Ir=l(),rw=a("li"),DMe=a("strong"),bIr=o("bart"),vIr=o(" \u2014 "),_K=a("a"),FIr=o("FlaxBartForSequenceClassification"),TIr=o(" (BART model)"),MIr=l(),tw=a("li"),GMe=a("strong"),EIr=o("bert"),CIr=o(" \u2014 "),bK=a("a"),wIr=o("FlaxBertForSequenceClassification"),AIr=o(" (BERT model)"),yIr=l(),aw=a("li"),OMe=a("strong"),LIr=o("big_bird"),xIr=o(" \u2014 "),vK=a("a"),$Ir=o("FlaxBigBirdForSequenceClassification"),kIr=o(" (BigBird model)"),SIr=l(),nw=a("li"),VMe=a("strong"),RIr=o("distilbert"),PIr=o(" \u2014 "),FK=a("a"),BIr=o("FlaxDistilBertForSequenceClassification"),IIr=o(" (DistilBERT model)"),qIr=l(),sw=a("li"),XMe=a("strong"),NIr=o("electra"),jIr=o(" \u2014 "),TK=a("a"),DIr=o("FlaxElectraForSequenceClassification"),GIr=o(" (ELECTRA model)"),OIr=l(),lw=a("li"),zMe=a("strong"),VIr=o("mbart"),XIr=o(" \u2014 "),MK=a("a"),zIr=o("FlaxMBartForSequenceClassification"),WIr=o(" (mBART model)"),QIr=l(),iw=a("li"),WMe=a("strong"),HIr=o("roberta"),UIr=o(" \u2014 "),EK=a("a"),JIr=o("FlaxRobertaForSequenceClassification"),YIr=o(" (RoBERTa model)"),KIr=l(),dw=a("li"),QMe=a("strong"),ZIr=o("roformer"),eqr=o(" \u2014 "),CK=a("a"),oqr=o("FlaxRoFormerForSequenceClassification"),rqr=o(" (RoFormer model)"),tqr=l(),cw=a("li"),HMe=a("strong"),aqr=o("xlm-roberta"),nqr=o(" \u2014 "),wK=a("a"),sqr=o("FlaxXLMRobertaForSequenceClassification"),lqr=o(" (XLM-RoBERTa model)"),iqr=l(),F(fw.$$.fragment),Wje=l(),Jc=a("h2"),mw=a("a"),UMe=a("span"),F(ox.$$.fragment),dqr=l(),JMe=a("span"),cqr=o("FlaxAutoModelForQuestionAnswering"),Qje=l(),_r=a("div"),F(rx.$$.fragment),fqr=l(),Yc=a("p"),mqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),AK=a("a"),gqr=o("from_pretrained()"),hqr=o(" class method or the "),yK=a("a"),pqr=o("from_config()"),uqr=o(` class
method.`),_qr=l(),tx=a("p"),bqr=o("This class cannot be instantiated directly using "),YMe=a("code"),vqr=o("__init__()"),Fqr=o(" (throws an error)."),Tqr=l(),Qt=a("div"),F(ax.$$.fragment),Mqr=l(),KMe=a("p"),Eqr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Cqr=l(),Kc=a("p"),wqr=o(`Note:
Loading a model from its configuration file does `),ZMe=a("strong"),Aqr=o("not"),yqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LK=a("a"),Lqr=o("from_pretrained()"),xqr=o(" to load the model weights."),$qr=l(),F(gw.$$.fragment),kqr=l(),zr=a("div"),F(nx.$$.fragment),Sqr=l(),eEe=a("p"),Rqr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Pqr=l(),Fn=a("p"),Bqr=o("The model class to instantiate is selected based on the "),oEe=a("code"),Iqr=o("model_type"),qqr=o(` property of the config object (either
passed as an argument or loaded from `),rEe=a("code"),Nqr=o("pretrained_model_name_or_path"),jqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=a("code"),Dqr=o("pretrained_model_name_or_path"),Gqr=o(":"),Oqr=l(),$e=a("ul"),hw=a("li"),aEe=a("strong"),Vqr=o("albert"),Xqr=o(" \u2014 "),xK=a("a"),zqr=o("FlaxAlbertForQuestionAnswering"),Wqr=o(" (ALBERT model)"),Qqr=l(),pw=a("li"),nEe=a("strong"),Hqr=o("bart"),Uqr=o(" \u2014 "),$K=a("a"),Jqr=o("FlaxBartForQuestionAnswering"),Yqr=o(" (BART model)"),Kqr=l(),uw=a("li"),sEe=a("strong"),Zqr=o("bert"),eNr=o(" \u2014 "),kK=a("a"),oNr=o("FlaxBertForQuestionAnswering"),rNr=o(" (BERT model)"),tNr=l(),_w=a("li"),lEe=a("strong"),aNr=o("big_bird"),nNr=o(" \u2014 "),SK=a("a"),sNr=o("FlaxBigBirdForQuestionAnswering"),lNr=o(" (BigBird model)"),iNr=l(),bw=a("li"),iEe=a("strong"),dNr=o("distilbert"),cNr=o(" \u2014 "),RK=a("a"),fNr=o("FlaxDistilBertForQuestionAnswering"),mNr=o(" (DistilBERT model)"),gNr=l(),vw=a("li"),dEe=a("strong"),hNr=o("electra"),pNr=o(" \u2014 "),PK=a("a"),uNr=o("FlaxElectraForQuestionAnswering"),_Nr=o(" (ELECTRA model)"),bNr=l(),Fw=a("li"),cEe=a("strong"),vNr=o("mbart"),FNr=o(" \u2014 "),BK=a("a"),TNr=o("FlaxMBartForQuestionAnswering"),MNr=o(" (mBART model)"),ENr=l(),Tw=a("li"),fEe=a("strong"),CNr=o("roberta"),wNr=o(" \u2014 "),IK=a("a"),ANr=o("FlaxRobertaForQuestionAnswering"),yNr=o(" (RoBERTa model)"),LNr=l(),Mw=a("li"),mEe=a("strong"),xNr=o("roformer"),$Nr=o(" \u2014 "),qK=a("a"),kNr=o("FlaxRoFormerForQuestionAnswering"),SNr=o(" (RoFormer model)"),RNr=l(),Ew=a("li"),gEe=a("strong"),PNr=o("xlm-roberta"),BNr=o(" \u2014 "),NK=a("a"),INr=o("FlaxXLMRobertaForQuestionAnswering"),qNr=o(" (XLM-RoBERTa model)"),NNr=l(),F(Cw.$$.fragment),Hje=l(),Zc=a("h2"),ww=a("a"),hEe=a("span"),F(sx.$$.fragment),jNr=l(),pEe=a("span"),DNr=o("FlaxAutoModelForTokenClassification"),Uje=l(),br=a("div"),F(lx.$$.fragment),GNr=l(),ef=a("p"),ONr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),jK=a("a"),VNr=o("from_pretrained()"),XNr=o(" class method or the "),DK=a("a"),zNr=o("from_config()"),WNr=o(` class
method.`),QNr=l(),ix=a("p"),HNr=o("This class cannot be instantiated directly using "),uEe=a("code"),UNr=o("__init__()"),JNr=o(" (throws an error)."),YNr=l(),Ht=a("div"),F(dx.$$.fragment),KNr=l(),_Ee=a("p"),ZNr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ejr=l(),of=a("p"),ojr=o(`Note:
Loading a model from its configuration file does `),bEe=a("strong"),rjr=o("not"),tjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=a("a"),ajr=o("from_pretrained()"),njr=o(" to load the model weights."),sjr=l(),F(Aw.$$.fragment),ljr=l(),Wr=a("div"),F(cx.$$.fragment),ijr=l(),vEe=a("p"),djr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cjr=l(),Tn=a("p"),fjr=o("The model class to instantiate is selected based on the "),FEe=a("code"),mjr=o("model_type"),gjr=o(` property of the config object (either
passed as an argument or loaded from `),TEe=a("code"),hjr=o("pretrained_model_name_or_path"),pjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MEe=a("code"),ujr=o("pretrained_model_name_or_path"),_jr=o(":"),bjr=l(),De=a("ul"),yw=a("li"),EEe=a("strong"),vjr=o("albert"),Fjr=o(" \u2014 "),OK=a("a"),Tjr=o("FlaxAlbertForTokenClassification"),Mjr=o(" (ALBERT model)"),Ejr=l(),Lw=a("li"),CEe=a("strong"),Cjr=o("bert"),wjr=o(" \u2014 "),VK=a("a"),Ajr=o("FlaxBertForTokenClassification"),yjr=o(" (BERT model)"),Ljr=l(),xw=a("li"),wEe=a("strong"),xjr=o("big_bird"),$jr=o(" \u2014 "),XK=a("a"),kjr=o("FlaxBigBirdForTokenClassification"),Sjr=o(" (BigBird model)"),Rjr=l(),$w=a("li"),AEe=a("strong"),Pjr=o("distilbert"),Bjr=o(" \u2014 "),zK=a("a"),Ijr=o("FlaxDistilBertForTokenClassification"),qjr=o(" (DistilBERT model)"),Njr=l(),kw=a("li"),yEe=a("strong"),jjr=o("electra"),Djr=o(" \u2014 "),WK=a("a"),Gjr=o("FlaxElectraForTokenClassification"),Ojr=o(" (ELECTRA model)"),Vjr=l(),Sw=a("li"),LEe=a("strong"),Xjr=o("roberta"),zjr=o(" \u2014 "),QK=a("a"),Wjr=o("FlaxRobertaForTokenClassification"),Qjr=o(" (RoBERTa model)"),Hjr=l(),Rw=a("li"),xEe=a("strong"),Ujr=o("roformer"),Jjr=o(" \u2014 "),HK=a("a"),Yjr=o("FlaxRoFormerForTokenClassification"),Kjr=o(" (RoFormer model)"),Zjr=l(),Pw=a("li"),$Ee=a("strong"),eDr=o("xlm-roberta"),oDr=o(" \u2014 "),UK=a("a"),rDr=o("FlaxXLMRobertaForTokenClassification"),tDr=o(" (XLM-RoBERTa model)"),aDr=l(),F(Bw.$$.fragment),Jje=l(),rf=a("h2"),Iw=a("a"),kEe=a("span"),F(fx.$$.fragment),nDr=l(),SEe=a("span"),sDr=o("FlaxAutoModelForMultipleChoice"),Yje=l(),vr=a("div"),F(mx.$$.fragment),lDr=l(),tf=a("p"),iDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),JK=a("a"),dDr=o("from_pretrained()"),cDr=o(" class method or the "),YK=a("a"),fDr=o("from_config()"),mDr=o(` class
method.`),gDr=l(),gx=a("p"),hDr=o("This class cannot be instantiated directly using "),REe=a("code"),pDr=o("__init__()"),uDr=o(" (throws an error)."),_Dr=l(),Ut=a("div"),F(hx.$$.fragment),bDr=l(),PEe=a("p"),vDr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),FDr=l(),af=a("p"),TDr=o(`Note:
Loading a model from its configuration file does `),BEe=a("strong"),MDr=o("not"),EDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KK=a("a"),CDr=o("from_pretrained()"),wDr=o(" to load the model weights."),ADr=l(),F(qw.$$.fragment),yDr=l(),Qr=a("div"),F(px.$$.fragment),LDr=l(),IEe=a("p"),xDr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$Dr=l(),Mn=a("p"),kDr=o("The model class to instantiate is selected based on the "),qEe=a("code"),SDr=o("model_type"),RDr=o(` property of the config object (either
passed as an argument or loaded from `),NEe=a("code"),PDr=o("pretrained_model_name_or_path"),BDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jEe=a("code"),IDr=o("pretrained_model_name_or_path"),qDr=o(":"),NDr=l(),Ge=a("ul"),Nw=a("li"),DEe=a("strong"),jDr=o("albert"),DDr=o(" \u2014 "),ZK=a("a"),GDr=o("FlaxAlbertForMultipleChoice"),ODr=o(" (ALBERT model)"),VDr=l(),jw=a("li"),GEe=a("strong"),XDr=o("bert"),zDr=o(" \u2014 "),eZ=a("a"),WDr=o("FlaxBertForMultipleChoice"),QDr=o(" (BERT model)"),HDr=l(),Dw=a("li"),OEe=a("strong"),UDr=o("big_bird"),JDr=o(" \u2014 "),oZ=a("a"),YDr=o("FlaxBigBirdForMultipleChoice"),KDr=o(" (BigBird model)"),ZDr=l(),Gw=a("li"),VEe=a("strong"),eGr=o("distilbert"),oGr=o(" \u2014 "),rZ=a("a"),rGr=o("FlaxDistilBertForMultipleChoice"),tGr=o(" (DistilBERT model)"),aGr=l(),Ow=a("li"),XEe=a("strong"),nGr=o("electra"),sGr=o(" \u2014 "),tZ=a("a"),lGr=o("FlaxElectraForMultipleChoice"),iGr=o(" (ELECTRA model)"),dGr=l(),Vw=a("li"),zEe=a("strong"),cGr=o("roberta"),fGr=o(" \u2014 "),aZ=a("a"),mGr=o("FlaxRobertaForMultipleChoice"),gGr=o(" (RoBERTa model)"),hGr=l(),Xw=a("li"),WEe=a("strong"),pGr=o("roformer"),uGr=o(" \u2014 "),nZ=a("a"),_Gr=o("FlaxRoFormerForMultipleChoice"),bGr=o(" (RoFormer model)"),vGr=l(),zw=a("li"),QEe=a("strong"),FGr=o("xlm-roberta"),TGr=o(" \u2014 "),sZ=a("a"),MGr=o("FlaxXLMRobertaForMultipleChoice"),EGr=o(" (XLM-RoBERTa model)"),CGr=l(),F(Ww.$$.fragment),Kje=l(),nf=a("h2"),Qw=a("a"),HEe=a("span"),F(ux.$$.fragment),wGr=l(),UEe=a("span"),AGr=o("FlaxAutoModelForNextSentencePrediction"),Zje=l(),Fr=a("div"),F(_x.$$.fragment),yGr=l(),sf=a("p"),LGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),lZ=a("a"),xGr=o("from_pretrained()"),$Gr=o(" class method or the "),iZ=a("a"),kGr=o("from_config()"),SGr=o(` class
method.`),RGr=l(),bx=a("p"),PGr=o("This class cannot be instantiated directly using "),JEe=a("code"),BGr=o("__init__()"),IGr=o(" (throws an error)."),qGr=l(),Jt=a("div"),F(vx.$$.fragment),NGr=l(),YEe=a("p"),jGr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),DGr=l(),lf=a("p"),GGr=o(`Note:
Loading a model from its configuration file does `),KEe=a("strong"),OGr=o("not"),VGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dZ=a("a"),XGr=o("from_pretrained()"),zGr=o(" to load the model weights."),WGr=l(),F(Hw.$$.fragment),QGr=l(),Hr=a("div"),F(Fx.$$.fragment),HGr=l(),ZEe=a("p"),UGr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),JGr=l(),En=a("p"),YGr=o("The model class to instantiate is selected based on the "),eCe=a("code"),KGr=o("model_type"),ZGr=o(` property of the config object (either
passed as an argument or loaded from `),oCe=a("code"),eOr=o("pretrained_model_name_or_path"),oOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rCe=a("code"),rOr=o("pretrained_model_name_or_path"),tOr=o(":"),aOr=l(),tCe=a("ul"),Uw=a("li"),aCe=a("strong"),nOr=o("bert"),sOr=o(" \u2014 "),cZ=a("a"),lOr=o("FlaxBertForNextSentencePrediction"),iOr=o(" (BERT model)"),dOr=l(),F(Jw.$$.fragment),eDe=l(),df=a("h2"),Yw=a("a"),nCe=a("span"),F(Tx.$$.fragment),cOr=l(),sCe=a("span"),fOr=o("FlaxAutoModelForImageClassification"),oDe=l(),Tr=a("div"),F(Mx.$$.fragment),mOr=l(),cf=a("p"),gOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),fZ=a("a"),hOr=o("from_pretrained()"),pOr=o(" class method or the "),mZ=a("a"),uOr=o("from_config()"),_Or=o(` class
method.`),bOr=l(),Ex=a("p"),vOr=o("This class cannot be instantiated directly using "),lCe=a("code"),FOr=o("__init__()"),TOr=o(" (throws an error)."),MOr=l(),Yt=a("div"),F(Cx.$$.fragment),EOr=l(),iCe=a("p"),COr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),wOr=l(),ff=a("p"),AOr=o(`Note:
Loading a model from its configuration file does `),dCe=a("strong"),yOr=o("not"),LOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=a("a"),xOr=o("from_pretrained()"),$Or=o(" to load the model weights."),kOr=l(),F(Kw.$$.fragment),SOr=l(),Ur=a("div"),F(wx.$$.fragment),ROr=l(),cCe=a("p"),POr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),BOr=l(),Cn=a("p"),IOr=o("The model class to instantiate is selected based on the "),fCe=a("code"),qOr=o("model_type"),NOr=o(` property of the config object (either
passed as an argument or loaded from `),mCe=a("code"),jOr=o("pretrained_model_name_or_path"),DOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gCe=a("code"),GOr=o("pretrained_model_name_or_path"),OOr=o(":"),VOr=l(),Ax=a("ul"),Zw=a("li"),hCe=a("strong"),XOr=o("beit"),zOr=o(" \u2014 "),hZ=a("a"),WOr=o("FlaxBeitForImageClassification"),QOr=o(" (BEiT model)"),HOr=l(),e0=a("li"),pCe=a("strong"),UOr=o("vit"),JOr=o(" \u2014 "),pZ=a("a"),YOr=o("FlaxViTForImageClassification"),KOr=o(" (ViT model)"),ZOr=l(),F(o0.$$.fragment),rDe=l(),mf=a("h2"),r0=a("a"),uCe=a("span"),F(yx.$$.fragment),eVr=l(),_Ce=a("span"),oVr=o("FlaxAutoModelForVision2Seq"),tDe=l(),Mr=a("div"),F(Lx.$$.fragment),rVr=l(),gf=a("p"),tVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),uZ=a("a"),aVr=o("from_pretrained()"),nVr=o(" class method or the "),_Z=a("a"),sVr=o("from_config()"),lVr=o(` class
method.`),iVr=l(),xx=a("p"),dVr=o("This class cannot be instantiated directly using "),bCe=a("code"),cVr=o("__init__()"),fVr=o(" (throws an error)."),mVr=l(),Kt=a("div"),F($x.$$.fragment),gVr=l(),vCe=a("p"),hVr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pVr=l(),hf=a("p"),uVr=o(`Note:
Loading a model from its configuration file does `),FCe=a("strong"),_Vr=o("not"),bVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bZ=a("a"),vVr=o("from_pretrained()"),FVr=o(" to load the model weights."),TVr=l(),F(t0.$$.fragment),MVr=l(),Jr=a("div"),F(kx.$$.fragment),EVr=l(),TCe=a("p"),CVr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),wVr=l(),wn=a("p"),AVr=o("The model class to instantiate is selected based on the "),MCe=a("code"),yVr=o("model_type"),LVr=o(` property of the config object (either
passed as an argument or loaded from `),ECe=a("code"),xVr=o("pretrained_model_name_or_path"),$Vr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CCe=a("code"),kVr=o("pretrained_model_name_or_path"),SVr=o(":"),RVr=l(),wCe=a("ul"),a0=a("li"),ACe=a("strong"),PVr=o("vision-encoder-decoder"),BVr=o(" \u2014 "),vZ=a("a"),IVr=o("FlaxVisionEncoderDecoderModel"),qVr=o(" (Vision Encoder decoder model)"),NVr=l(),F(n0.$$.fragment),this.h()},l(f){const _=T$t('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var Sx=s(p);m=n(Sx,"A",{id:!0,class:!0,href:!0});var yCe=s(m);u=n(yCe,"SPAN",{});var LCe=s(u);T(d.$$.fragment,LCe),LCe.forEach(t),yCe.forEach(t),h=i(Sx),Mo=n(Sx,"SPAN",{});var xCe=s(Mo);hi=r(xCe,"Auto Classes"),xCe.forEach(t),Sx.forEach(t),bf=i(f),rt=n(f,"P",{});var Rx=s(rt);pi=r(Rx,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ui=n(Rx,"CODE",{});var $Ce=s(ui);EA=r($Ce,"from_pretrained()"),$Ce.forEach(t),vf=r(Rx,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Rx.forEach(t),je=i(f),We=n(f,"P",{});var An=s(We);_i=r(An,"Instantiating one of "),yn=n(An,"A",{href:!0});var kCe=s(yn);CA=r(kCe,"AutoConfig"),kCe.forEach(t),Ln=r(An,", "),xn=n(An,"A",{href:!0});var SCe=s(xn);wA=r(SCe,"AutoModel"),SCe.forEach(t),bi=r(An,`, and
`),$n=n(An,"A",{href:!0});var RCe=s($n);AA=r(RCe,"AutoTokenizer"),RCe.forEach(t),vi=r(An," will directly create a class of the relevant architecture. For instance"),An.forEach(t),Ff=i(f),T(Ca.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var Px=s(Ae);H$=r(Px,"will create a model that is an instance of "),Fi=n(Px,"A",{href:!0});var PCe=s(Fi);U$=r(PCe,"BertModel"),PCe.forEach(t),J$=r(Px,"."),Px.forEach(t),Eo=i(f),wa=n(f,"P",{});var Bx=s(wa);Y$=r(Bx,"There is one class of "),Tf=n(Bx,"CODE",{});var BCe=s(Tf);K$=r(BCe,"AutoModel"),BCe.forEach(t),mOe=r(Bx," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Bx.forEach(t),oNe=i(f),Ti=n(f,"H2",{class:!0});var Ix=s(Ti);Mf=n(Ix,"A",{id:!0,class:!0,href:!0});var ICe=s(Mf);moe=n(ICe,"SPAN",{});var qCe=s(moe);T(yA.$$.fragment,qCe),qCe.forEach(t),ICe.forEach(t),gOe=i(Ix),goe=n(Ix,"SPAN",{});var NCe=s(goe);hOe=r(NCe,"Extending the Auto Classes"),NCe.forEach(t),Ix.forEach(t),rNe=i(f),kn=n(f,"P",{});var pf=s(kn);pOe=r(pf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hoe=n(pf,"CODE",{});var jCe=s(hoe);uOe=r(jCe,"NewModel"),jCe.forEach(t),_Oe=r(pf,", make sure you have a "),poe=n(pf,"CODE",{});var DCe=s(poe);bOe=r(DCe,"NewModelConfig"),DCe.forEach(t),vOe=r(pf,` then you can add those to the auto
classes like this:`),pf.forEach(t),tNe=i(f),T(LA.$$.fragment,f),aNe=i(f),Z$=n(f,"P",{});var GCe=s(Z$);FOe=r(GCe,"You will then be able to use the auto classes like you would usually do!"),GCe.forEach(t),nNe=i(f),T(Ef.$$.fragment,f),sNe=i(f),Mi=n(f,"H2",{class:!0});var qx=s(Mi);Cf=n(qx,"A",{id:!0,class:!0,href:!0});var OCe=s(Cf);uoe=n(OCe,"SPAN",{});var VCe=s(uoe);T(xA.$$.fragment,VCe),VCe.forEach(t),OCe.forEach(t),TOe=i(qx),_oe=n(qx,"SPAN",{});var XCe=s(_oe);MOe=r(XCe,"AutoConfig"),XCe.forEach(t),qx.forEach(t),lNe=i(f),Co=n(f,"DIV",{class:!0});var et=s(Co);T($A.$$.fragment,et),EOe=i(et),kA=n(et,"P",{});var Nx=s(kA);COe=r(Nx,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),ek=n(Nx,"A",{href:!0});var zCe=s(ek);wOe=r(zCe,"from_pretrained()"),zCe.forEach(t),AOe=r(Nx," class method."),Nx.forEach(t),yOe=i(et),SA=n(et,"P",{});var jx=s(SA);LOe=r(jx,"This class cannot be instantiated directly using "),boe=n(jx,"CODE",{});var WCe=s(boe);xOe=r(WCe,"__init__()"),WCe.forEach(t),$Oe=r(jx," (throws an error)."),jx.forEach(t),kOe=i(et),Er=n(et,"DIV",{class:!0});var ot=s(Er);T(RA.$$.fragment,ot),SOe=i(ot),voe=n(ot,"P",{});var QCe=s(voe);ROe=r(QCe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),QCe.forEach(t),POe=i(ot),Ei=n(ot,"P",{});var uf=s(Ei);BOe=r(uf,"The configuration class to instantiate is selected based on the "),Foe=n(uf,"CODE",{});var HCe=s(Foe);IOe=r(HCe,"model_type"),HCe.forEach(t),qOe=r(uf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Toe=n(uf,"CODE",{});var UCe=s(Toe);NOe=r(UCe,"pretrained_model_name_or_path"),UCe.forEach(t),jOe=r(uf,":"),uf.forEach(t),DOe=i(ot),A=n(ot,"UL",{});var y=s(A);wf=n(y,"LI",{});var s0=s(wf);Moe=n(s0,"STRONG",{});var JCe=s(Moe);GOe=r(JCe,"albert"),JCe.forEach(t),OOe=r(s0," \u2014 "),ok=n(s0,"A",{href:!0});var YCe=s(ok);VOe=r(YCe,"AlbertConfig"),YCe.forEach(t),XOe=r(s0," (ALBERT model)"),s0.forEach(t),zOe=i(y),Af=n(y,"LI",{});var l0=s(Af);Eoe=n(l0,"STRONG",{});var KCe=s(Eoe);WOe=r(KCe,"bart"),KCe.forEach(t),QOe=r(l0," \u2014 "),rk=n(l0,"A",{href:!0});var ZCe=s(rk);HOe=r(ZCe,"BartConfig"),ZCe.forEach(t),UOe=r(l0," (BART model)"),l0.forEach(t),JOe=i(y),yf=n(y,"LI",{});var i0=s(yf);Coe=n(i0,"STRONG",{});var e3e=s(Coe);YOe=r(e3e,"beit"),e3e.forEach(t),KOe=r(i0," \u2014 "),tk=n(i0,"A",{href:!0});var o3e=s(tk);ZOe=r(o3e,"BeitConfig"),o3e.forEach(t),eVe=r(i0," (BEiT model)"),i0.forEach(t),oVe=i(y),Lf=n(y,"LI",{});var d0=s(Lf);woe=n(d0,"STRONG",{});var r3e=s(woe);rVe=r(r3e,"bert"),r3e.forEach(t),tVe=r(d0," \u2014 "),ak=n(d0,"A",{href:!0});var t3e=s(ak);aVe=r(t3e,"BertConfig"),t3e.forEach(t),nVe=r(d0," (BERT model)"),d0.forEach(t),sVe=i(y),xf=n(y,"LI",{});var c0=s(xf);Aoe=n(c0,"STRONG",{});var a3e=s(Aoe);lVe=r(a3e,"bert-generation"),a3e.forEach(t),iVe=r(c0," \u2014 "),nk=n(c0,"A",{href:!0});var n3e=s(nk);dVe=r(n3e,"BertGenerationConfig"),n3e.forEach(t),cVe=r(c0," (Bert Generation model)"),c0.forEach(t),fVe=i(y),$f=n(y,"LI",{});var f0=s($f);yoe=n(f0,"STRONG",{});var s3e=s(yoe);mVe=r(s3e,"big_bird"),s3e.forEach(t),gVe=r(f0," \u2014 "),sk=n(f0,"A",{href:!0});var l3e=s(sk);hVe=r(l3e,"BigBirdConfig"),l3e.forEach(t),pVe=r(f0," (BigBird model)"),f0.forEach(t),uVe=i(y),kf=n(y,"LI",{});var m0=s(kf);Loe=n(m0,"STRONG",{});var i3e=s(Loe);_Ve=r(i3e,"bigbird_pegasus"),i3e.forEach(t),bVe=r(m0," \u2014 "),lk=n(m0,"A",{href:!0});var d3e=s(lk);vVe=r(d3e,"BigBirdPegasusConfig"),d3e.forEach(t),FVe=r(m0," (BigBirdPegasus model)"),m0.forEach(t),TVe=i(y),Sf=n(y,"LI",{});var g0=s(Sf);xoe=n(g0,"STRONG",{});var c3e=s(xoe);MVe=r(c3e,"blenderbot"),c3e.forEach(t),EVe=r(g0," \u2014 "),ik=n(g0,"A",{href:!0});var f3e=s(ik);CVe=r(f3e,"BlenderbotConfig"),f3e.forEach(t),wVe=r(g0," (Blenderbot model)"),g0.forEach(t),AVe=i(y),Rf=n(y,"LI",{});var h0=s(Rf);$oe=n(h0,"STRONG",{});var m3e=s($oe);yVe=r(m3e,"blenderbot-small"),m3e.forEach(t),LVe=r(h0," \u2014 "),dk=n(h0,"A",{href:!0});var g3e=s(dk);xVe=r(g3e,"BlenderbotSmallConfig"),g3e.forEach(t),$Ve=r(h0," (BlenderbotSmall model)"),h0.forEach(t),kVe=i(y),Pf=n(y,"LI",{});var p0=s(Pf);koe=n(p0,"STRONG",{});var h3e=s(koe);SVe=r(h3e,"camembert"),h3e.forEach(t),RVe=r(p0," \u2014 "),ck=n(p0,"A",{href:!0});var p3e=s(ck);PVe=r(p3e,"CamembertConfig"),p3e.forEach(t),BVe=r(p0," (CamemBERT model)"),p0.forEach(t),IVe=i(y),Bf=n(y,"LI",{});var u0=s(Bf);Soe=n(u0,"STRONG",{});var u3e=s(Soe);qVe=r(u3e,"canine"),u3e.forEach(t),NVe=r(u0," \u2014 "),fk=n(u0,"A",{href:!0});var _3e=s(fk);jVe=r(_3e,"CanineConfig"),_3e.forEach(t),DVe=r(u0," (Canine model)"),u0.forEach(t),GVe=i(y),If=n(y,"LI",{});var _0=s(If);Roe=n(_0,"STRONG",{});var b3e=s(Roe);OVe=r(b3e,"clip"),b3e.forEach(t),VVe=r(_0," \u2014 "),mk=n(_0,"A",{href:!0});var v3e=s(mk);XVe=r(v3e,"CLIPConfig"),v3e.forEach(t),zVe=r(_0," (CLIP model)"),_0.forEach(t),WVe=i(y),qf=n(y,"LI",{});var b0=s(qf);Poe=n(b0,"STRONG",{});var F3e=s(Poe);QVe=r(F3e,"convbert"),F3e.forEach(t),HVe=r(b0," \u2014 "),gk=n(b0,"A",{href:!0});var T3e=s(gk);UVe=r(T3e,"ConvBertConfig"),T3e.forEach(t),JVe=r(b0," (ConvBERT model)"),b0.forEach(t),YVe=i(y),Nf=n(y,"LI",{});var v0=s(Nf);Boe=n(v0,"STRONG",{});var M3e=s(Boe);KVe=r(M3e,"convnext"),M3e.forEach(t),ZVe=r(v0," \u2014 "),hk=n(v0,"A",{href:!0});var E3e=s(hk);eXe=r(E3e,"ConvNextConfig"),E3e.forEach(t),oXe=r(v0," (ConvNext model)"),v0.forEach(t),rXe=i(y),jf=n(y,"LI",{});var F0=s(jf);Ioe=n(F0,"STRONG",{});var C3e=s(Ioe);tXe=r(C3e,"ctrl"),C3e.forEach(t),aXe=r(F0," \u2014 "),pk=n(F0,"A",{href:!0});var w3e=s(pk);nXe=r(w3e,"CTRLConfig"),w3e.forEach(t),sXe=r(F0," (CTRL model)"),F0.forEach(t),lXe=i(y),Df=n(y,"LI",{});var T0=s(Df);qoe=n(T0,"STRONG",{});var A3e=s(qoe);iXe=r(A3e,"cvt"),A3e.forEach(t),dXe=r(T0," \u2014 "),uk=n(T0,"A",{href:!0});var y3e=s(uk);cXe=r(y3e,"CvtConfig"),y3e.forEach(t),fXe=r(T0," (CvT model)"),T0.forEach(t),mXe=i(y),Gf=n(y,"LI",{});var M0=s(Gf);Noe=n(M0,"STRONG",{});var L3e=s(Noe);gXe=r(L3e,"data2vec-audio"),L3e.forEach(t),hXe=r(M0," \u2014 "),_k=n(M0,"A",{href:!0});var x3e=s(_k);pXe=r(x3e,"Data2VecAudioConfig"),x3e.forEach(t),uXe=r(M0," (Data2VecAudio model)"),M0.forEach(t),_Xe=i(y),Of=n(y,"LI",{});var E0=s(Of);joe=n(E0,"STRONG",{});var $3e=s(joe);bXe=r($3e,"data2vec-text"),$3e.forEach(t),vXe=r(E0," \u2014 "),bk=n(E0,"A",{href:!0});var k3e=s(bk);FXe=r(k3e,"Data2VecTextConfig"),k3e.forEach(t),TXe=r(E0," (Data2VecText model)"),E0.forEach(t),MXe=i(y),Vf=n(y,"LI",{});var C0=s(Vf);Doe=n(C0,"STRONG",{});var S3e=s(Doe);EXe=r(S3e,"data2vec-vision"),S3e.forEach(t),CXe=r(C0," \u2014 "),vk=n(C0,"A",{href:!0});var R3e=s(vk);wXe=r(R3e,"Data2VecVisionConfig"),R3e.forEach(t),AXe=r(C0," (Data2VecVision model)"),C0.forEach(t),yXe=i(y),Xf=n(y,"LI",{});var w0=s(Xf);Goe=n(w0,"STRONG",{});var P3e=s(Goe);LXe=r(P3e,"deberta"),P3e.forEach(t),xXe=r(w0," \u2014 "),Fk=n(w0,"A",{href:!0});var B3e=s(Fk);$Xe=r(B3e,"DebertaConfig"),B3e.forEach(t),kXe=r(w0," (DeBERTa model)"),w0.forEach(t),SXe=i(y),zf=n(y,"LI",{});var A0=s(zf);Ooe=n(A0,"STRONG",{});var I3e=s(Ooe);RXe=r(I3e,"deberta-v2"),I3e.forEach(t),PXe=r(A0," \u2014 "),Tk=n(A0,"A",{href:!0});var q3e=s(Tk);BXe=r(q3e,"DebertaV2Config"),q3e.forEach(t),IXe=r(A0," (DeBERTa-v2 model)"),A0.forEach(t),qXe=i(y),Wf=n(y,"LI",{});var y0=s(Wf);Voe=n(y0,"STRONG",{});var N3e=s(Voe);NXe=r(N3e,"decision_transformer"),N3e.forEach(t),jXe=r(y0," \u2014 "),Mk=n(y0,"A",{href:!0});var j3e=s(Mk);DXe=r(j3e,"DecisionTransformerConfig"),j3e.forEach(t),GXe=r(y0," (Decision Transformer model)"),y0.forEach(t),OXe=i(y),Qf=n(y,"LI",{});var L0=s(Qf);Xoe=n(L0,"STRONG",{});var D3e=s(Xoe);VXe=r(D3e,"deit"),D3e.forEach(t),XXe=r(L0," \u2014 "),Ek=n(L0,"A",{href:!0});var DVr=s(Ek);zXe=r(DVr,"DeiTConfig"),DVr.forEach(t),WXe=r(L0," (DeiT model)"),L0.forEach(t),QXe=i(y),Hf=n(y,"LI",{});var G3e=s(Hf);zoe=n(G3e,"STRONG",{});var GVr=s(zoe);HXe=r(GVr,"detr"),GVr.forEach(t),UXe=r(G3e," \u2014 "),Ck=n(G3e,"A",{href:!0});var OVr=s(Ck);JXe=r(OVr,"DetrConfig"),OVr.forEach(t),YXe=r(G3e," (DETR model)"),G3e.forEach(t),KXe=i(y),Uf=n(y,"LI",{});var O3e=s(Uf);Woe=n(O3e,"STRONG",{});var VVr=s(Woe);ZXe=r(VVr,"distilbert"),VVr.forEach(t),eze=r(O3e," \u2014 "),wk=n(O3e,"A",{href:!0});var XVr=s(wk);oze=r(XVr,"DistilBertConfig"),XVr.forEach(t),rze=r(O3e," (DistilBERT model)"),O3e.forEach(t),tze=i(y),Jf=n(y,"LI",{});var V3e=s(Jf);Qoe=n(V3e,"STRONG",{});var zVr=s(Qoe);aze=r(zVr,"dpr"),zVr.forEach(t),nze=r(V3e," \u2014 "),Ak=n(V3e,"A",{href:!0});var WVr=s(Ak);sze=r(WVr,"DPRConfig"),WVr.forEach(t),lze=r(V3e," (DPR model)"),V3e.forEach(t),ize=i(y),Yf=n(y,"LI",{});var X3e=s(Yf);Hoe=n(X3e,"STRONG",{});var QVr=s(Hoe);dze=r(QVr,"dpt"),QVr.forEach(t),cze=r(X3e," \u2014 "),yk=n(X3e,"A",{href:!0});var HVr=s(yk);fze=r(HVr,"DPTConfig"),HVr.forEach(t),mze=r(X3e," (DPT model)"),X3e.forEach(t),gze=i(y),Kf=n(y,"LI",{});var z3e=s(Kf);Uoe=n(z3e,"STRONG",{});var UVr=s(Uoe);hze=r(UVr,"electra"),UVr.forEach(t),pze=r(z3e," \u2014 "),Lk=n(z3e,"A",{href:!0});var JVr=s(Lk);uze=r(JVr,"ElectraConfig"),JVr.forEach(t),_ze=r(z3e," (ELECTRA model)"),z3e.forEach(t),bze=i(y),Zf=n(y,"LI",{});var W3e=s(Zf);Joe=n(W3e,"STRONG",{});var YVr=s(Joe);vze=r(YVr,"encoder-decoder"),YVr.forEach(t),Fze=r(W3e," \u2014 "),xk=n(W3e,"A",{href:!0});var KVr=s(xk);Tze=r(KVr,"EncoderDecoderConfig"),KVr.forEach(t),Mze=r(W3e," (Encoder decoder model)"),W3e.forEach(t),Eze=i(y),em=n(y,"LI",{});var Q3e=s(em);Yoe=n(Q3e,"STRONG",{});var ZVr=s(Yoe);Cze=r(ZVr,"flaubert"),ZVr.forEach(t),wze=r(Q3e," \u2014 "),$k=n(Q3e,"A",{href:!0});var eXr=s($k);Aze=r(eXr,"FlaubertConfig"),eXr.forEach(t),yze=r(Q3e," (FlauBERT model)"),Q3e.forEach(t),Lze=i(y),om=n(y,"LI",{});var H3e=s(om);Koe=n(H3e,"STRONG",{});var oXr=s(Koe);xze=r(oXr,"flava"),oXr.forEach(t),$ze=r(H3e," \u2014 "),kk=n(H3e,"A",{href:!0});var rXr=s(kk);kze=r(rXr,"FlavaConfig"),rXr.forEach(t),Sze=r(H3e," (Flava model)"),H3e.forEach(t),Rze=i(y),rm=n(y,"LI",{});var U3e=s(rm);Zoe=n(U3e,"STRONG",{});var tXr=s(Zoe);Pze=r(tXr,"fnet"),tXr.forEach(t),Bze=r(U3e," \u2014 "),Sk=n(U3e,"A",{href:!0});var aXr=s(Sk);Ize=r(aXr,"FNetConfig"),aXr.forEach(t),qze=r(U3e," (FNet model)"),U3e.forEach(t),Nze=i(y),tm=n(y,"LI",{});var J3e=s(tm);ere=n(J3e,"STRONG",{});var nXr=s(ere);jze=r(nXr,"fsmt"),nXr.forEach(t),Dze=r(J3e," \u2014 "),Rk=n(J3e,"A",{href:!0});var sXr=s(Rk);Gze=r(sXr,"FSMTConfig"),sXr.forEach(t),Oze=r(J3e," (FairSeq Machine-Translation model)"),J3e.forEach(t),Vze=i(y),am=n(y,"LI",{});var Y3e=s(am);ore=n(Y3e,"STRONG",{});var lXr=s(ore);Xze=r(lXr,"funnel"),lXr.forEach(t),zze=r(Y3e," \u2014 "),Pk=n(Y3e,"A",{href:!0});var iXr=s(Pk);Wze=r(iXr,"FunnelConfig"),iXr.forEach(t),Qze=r(Y3e," (Funnel Transformer model)"),Y3e.forEach(t),Hze=i(y),nm=n(y,"LI",{});var K3e=s(nm);rre=n(K3e,"STRONG",{});var dXr=s(rre);Uze=r(dXr,"glpn"),dXr.forEach(t),Jze=r(K3e," \u2014 "),Bk=n(K3e,"A",{href:!0});var cXr=s(Bk);Yze=r(cXr,"GLPNConfig"),cXr.forEach(t),Kze=r(K3e," (GLPN model)"),K3e.forEach(t),Zze=i(y),sm=n(y,"LI",{});var Z3e=s(sm);tre=n(Z3e,"STRONG",{});var fXr=s(tre);eWe=r(fXr,"gpt2"),fXr.forEach(t),oWe=r(Z3e," \u2014 "),Ik=n(Z3e,"A",{href:!0});var mXr=s(Ik);rWe=r(mXr,"GPT2Config"),mXr.forEach(t),tWe=r(Z3e," (OpenAI GPT-2 model)"),Z3e.forEach(t),aWe=i(y),lm=n(y,"LI",{});var ewe=s(lm);are=n(ewe,"STRONG",{});var gXr=s(are);nWe=r(gXr,"gpt_neo"),gXr.forEach(t),sWe=r(ewe," \u2014 "),qk=n(ewe,"A",{href:!0});var hXr=s(qk);lWe=r(hXr,"GPTNeoConfig"),hXr.forEach(t),iWe=r(ewe," (GPT Neo model)"),ewe.forEach(t),dWe=i(y),im=n(y,"LI",{});var owe=s(im);nre=n(owe,"STRONG",{});var pXr=s(nre);cWe=r(pXr,"gpt_neox"),pXr.forEach(t),fWe=r(owe," \u2014 "),Nk=n(owe,"A",{href:!0});var uXr=s(Nk);mWe=r(uXr,"GPTNeoXConfig"),uXr.forEach(t),gWe=r(owe," (GPT NeoX model)"),owe.forEach(t),hWe=i(y),dm=n(y,"LI",{});var rwe=s(dm);sre=n(rwe,"STRONG",{});var _Xr=s(sre);pWe=r(_Xr,"gptj"),_Xr.forEach(t),uWe=r(rwe," \u2014 "),jk=n(rwe,"A",{href:!0});var bXr=s(jk);_We=r(bXr,"GPTJConfig"),bXr.forEach(t),bWe=r(rwe," (GPT-J model)"),rwe.forEach(t),vWe=i(y),cm=n(y,"LI",{});var twe=s(cm);lre=n(twe,"STRONG",{});var vXr=s(lre);FWe=r(vXr,"hubert"),vXr.forEach(t),TWe=r(twe," \u2014 "),Dk=n(twe,"A",{href:!0});var FXr=s(Dk);MWe=r(FXr,"HubertConfig"),FXr.forEach(t),EWe=r(twe," (Hubert model)"),twe.forEach(t),CWe=i(y),fm=n(y,"LI",{});var awe=s(fm);ire=n(awe,"STRONG",{});var TXr=s(ire);wWe=r(TXr,"ibert"),TXr.forEach(t),AWe=r(awe," \u2014 "),Gk=n(awe,"A",{href:!0});var MXr=s(Gk);yWe=r(MXr,"IBertConfig"),MXr.forEach(t),LWe=r(awe," (I-BERT model)"),awe.forEach(t),xWe=i(y),mm=n(y,"LI",{});var nwe=s(mm);dre=n(nwe,"STRONG",{});var EXr=s(dre);$We=r(EXr,"imagegpt"),EXr.forEach(t),kWe=r(nwe," \u2014 "),Ok=n(nwe,"A",{href:!0});var CXr=s(Ok);SWe=r(CXr,"ImageGPTConfig"),CXr.forEach(t),RWe=r(nwe," (ImageGPT model)"),nwe.forEach(t),PWe=i(y),gm=n(y,"LI",{});var swe=s(gm);cre=n(swe,"STRONG",{});var wXr=s(cre);BWe=r(wXr,"layoutlm"),wXr.forEach(t),IWe=r(swe," \u2014 "),Vk=n(swe,"A",{href:!0});var AXr=s(Vk);qWe=r(AXr,"LayoutLMConfig"),AXr.forEach(t),NWe=r(swe," (LayoutLM model)"),swe.forEach(t),jWe=i(y),hm=n(y,"LI",{});var lwe=s(hm);fre=n(lwe,"STRONG",{});var yXr=s(fre);DWe=r(yXr,"layoutlmv2"),yXr.forEach(t),GWe=r(lwe," \u2014 "),Xk=n(lwe,"A",{href:!0});var LXr=s(Xk);OWe=r(LXr,"LayoutLMv2Config"),LXr.forEach(t),VWe=r(lwe," (LayoutLMv2 model)"),lwe.forEach(t),XWe=i(y),pm=n(y,"LI",{});var iwe=s(pm);mre=n(iwe,"STRONG",{});var xXr=s(mre);zWe=r(xXr,"layoutlmv3"),xXr.forEach(t),WWe=r(iwe," \u2014 "),zk=n(iwe,"A",{href:!0});var $Xr=s(zk);QWe=r($Xr,"LayoutLMv3Config"),$Xr.forEach(t),HWe=r(iwe," (LayoutLMv3 model)"),iwe.forEach(t),UWe=i(y),um=n(y,"LI",{});var dwe=s(um);gre=n(dwe,"STRONG",{});var kXr=s(gre);JWe=r(kXr,"led"),kXr.forEach(t),YWe=r(dwe," \u2014 "),Wk=n(dwe,"A",{href:!0});var SXr=s(Wk);KWe=r(SXr,"LEDConfig"),SXr.forEach(t),ZWe=r(dwe," (LED model)"),dwe.forEach(t),eQe=i(y),_m=n(y,"LI",{});var cwe=s(_m);hre=n(cwe,"STRONG",{});var RXr=s(hre);oQe=r(RXr,"longformer"),RXr.forEach(t),rQe=r(cwe," \u2014 "),Qk=n(cwe,"A",{href:!0});var PXr=s(Qk);tQe=r(PXr,"LongformerConfig"),PXr.forEach(t),aQe=r(cwe," (Longformer model)"),cwe.forEach(t),nQe=i(y),bm=n(y,"LI",{});var fwe=s(bm);pre=n(fwe,"STRONG",{});var BXr=s(pre);sQe=r(BXr,"luke"),BXr.forEach(t),lQe=r(fwe," \u2014 "),Hk=n(fwe,"A",{href:!0});var IXr=s(Hk);iQe=r(IXr,"LukeConfig"),IXr.forEach(t),dQe=r(fwe," (LUKE model)"),fwe.forEach(t),cQe=i(y),vm=n(y,"LI",{});var mwe=s(vm);ure=n(mwe,"STRONG",{});var qXr=s(ure);fQe=r(qXr,"lxmert"),qXr.forEach(t),mQe=r(mwe," \u2014 "),Uk=n(mwe,"A",{href:!0});var NXr=s(Uk);gQe=r(NXr,"LxmertConfig"),NXr.forEach(t),hQe=r(mwe," (LXMERT model)"),mwe.forEach(t),pQe=i(y),Fm=n(y,"LI",{});var gwe=s(Fm);_re=n(gwe,"STRONG",{});var jXr=s(_re);uQe=r(jXr,"m2m_100"),jXr.forEach(t),_Qe=r(gwe," \u2014 "),Jk=n(gwe,"A",{href:!0});var DXr=s(Jk);bQe=r(DXr,"M2M100Config"),DXr.forEach(t),vQe=r(gwe," (M2M100 model)"),gwe.forEach(t),FQe=i(y),Tm=n(y,"LI",{});var hwe=s(Tm);bre=n(hwe,"STRONG",{});var GXr=s(bre);TQe=r(GXr,"marian"),GXr.forEach(t),MQe=r(hwe," \u2014 "),Yk=n(hwe,"A",{href:!0});var OXr=s(Yk);EQe=r(OXr,"MarianConfig"),OXr.forEach(t),CQe=r(hwe," (Marian model)"),hwe.forEach(t),wQe=i(y),Mm=n(y,"LI",{});var pwe=s(Mm);vre=n(pwe,"STRONG",{});var VXr=s(vre);AQe=r(VXr,"maskformer"),VXr.forEach(t),yQe=r(pwe," \u2014 "),Kk=n(pwe,"A",{href:!0});var XXr=s(Kk);LQe=r(XXr,"MaskFormerConfig"),XXr.forEach(t),xQe=r(pwe," (MaskFormer model)"),pwe.forEach(t),$Qe=i(y),Em=n(y,"LI",{});var uwe=s(Em);Fre=n(uwe,"STRONG",{});var zXr=s(Fre);kQe=r(zXr,"mbart"),zXr.forEach(t),SQe=r(uwe," \u2014 "),Zk=n(uwe,"A",{href:!0});var WXr=s(Zk);RQe=r(WXr,"MBartConfig"),WXr.forEach(t),PQe=r(uwe," (mBART model)"),uwe.forEach(t),BQe=i(y),Cm=n(y,"LI",{});var _we=s(Cm);Tre=n(_we,"STRONG",{});var QXr=s(Tre);IQe=r(QXr,"megatron-bert"),QXr.forEach(t),qQe=r(_we," \u2014 "),eS=n(_we,"A",{href:!0});var HXr=s(eS);NQe=r(HXr,"MegatronBertConfig"),HXr.forEach(t),jQe=r(_we," (MegatronBert model)"),_we.forEach(t),DQe=i(y),wm=n(y,"LI",{});var bwe=s(wm);Mre=n(bwe,"STRONG",{});var UXr=s(Mre);GQe=r(UXr,"mobilebert"),UXr.forEach(t),OQe=r(bwe," \u2014 "),oS=n(bwe,"A",{href:!0});var JXr=s(oS);VQe=r(JXr,"MobileBertConfig"),JXr.forEach(t),XQe=r(bwe," (MobileBERT model)"),bwe.forEach(t),zQe=i(y),Am=n(y,"LI",{});var vwe=s(Am);Ere=n(vwe,"STRONG",{});var YXr=s(Ere);WQe=r(YXr,"mpnet"),YXr.forEach(t),QQe=r(vwe," \u2014 "),rS=n(vwe,"A",{href:!0});var KXr=s(rS);HQe=r(KXr,"MPNetConfig"),KXr.forEach(t),UQe=r(vwe," (MPNet model)"),vwe.forEach(t),JQe=i(y),ym=n(y,"LI",{});var Fwe=s(ym);Cre=n(Fwe,"STRONG",{});var ZXr=s(Cre);YQe=r(ZXr,"mt5"),ZXr.forEach(t),KQe=r(Fwe," \u2014 "),tS=n(Fwe,"A",{href:!0});var ezr=s(tS);ZQe=r(ezr,"MT5Config"),ezr.forEach(t),eHe=r(Fwe," (mT5 model)"),Fwe.forEach(t),oHe=i(y),Lm=n(y,"LI",{});var Twe=s(Lm);wre=n(Twe,"STRONG",{});var ozr=s(wre);rHe=r(ozr,"nystromformer"),ozr.forEach(t),tHe=r(Twe," \u2014 "),aS=n(Twe,"A",{href:!0});var rzr=s(aS);aHe=r(rzr,"NystromformerConfig"),rzr.forEach(t),nHe=r(Twe," (Nystromformer model)"),Twe.forEach(t),sHe=i(y),xm=n(y,"LI",{});var Mwe=s(xm);Are=n(Mwe,"STRONG",{});var tzr=s(Are);lHe=r(tzr,"openai-gpt"),tzr.forEach(t),iHe=r(Mwe," \u2014 "),nS=n(Mwe,"A",{href:!0});var azr=s(nS);dHe=r(azr,"OpenAIGPTConfig"),azr.forEach(t),cHe=r(Mwe," (OpenAI GPT model)"),Mwe.forEach(t),fHe=i(y),$m=n(y,"LI",{});var Ewe=s($m);yre=n(Ewe,"STRONG",{});var nzr=s(yre);mHe=r(nzr,"opt"),nzr.forEach(t),gHe=r(Ewe," \u2014 "),sS=n(Ewe,"A",{href:!0});var szr=s(sS);hHe=r(szr,"OPTConfig"),szr.forEach(t),pHe=r(Ewe," (OPT model)"),Ewe.forEach(t),uHe=i(y),km=n(y,"LI",{});var Cwe=s(km);Lre=n(Cwe,"STRONG",{});var lzr=s(Lre);_He=r(lzr,"pegasus"),lzr.forEach(t),bHe=r(Cwe," \u2014 "),lS=n(Cwe,"A",{href:!0});var izr=s(lS);vHe=r(izr,"PegasusConfig"),izr.forEach(t),FHe=r(Cwe," (Pegasus model)"),Cwe.forEach(t),THe=i(y),Sm=n(y,"LI",{});var wwe=s(Sm);xre=n(wwe,"STRONG",{});var dzr=s(xre);MHe=r(dzr,"perceiver"),dzr.forEach(t),EHe=r(wwe," \u2014 "),iS=n(wwe,"A",{href:!0});var czr=s(iS);CHe=r(czr,"PerceiverConfig"),czr.forEach(t),wHe=r(wwe," (Perceiver model)"),wwe.forEach(t),AHe=i(y),Rm=n(y,"LI",{});var Awe=s(Rm);$re=n(Awe,"STRONG",{});var fzr=s($re);yHe=r(fzr,"plbart"),fzr.forEach(t),LHe=r(Awe," \u2014 "),dS=n(Awe,"A",{href:!0});var mzr=s(dS);xHe=r(mzr,"PLBartConfig"),mzr.forEach(t),$He=r(Awe," (PLBart model)"),Awe.forEach(t),kHe=i(y),Pm=n(y,"LI",{});var ywe=s(Pm);kre=n(ywe,"STRONG",{});var gzr=s(kre);SHe=r(gzr,"poolformer"),gzr.forEach(t),RHe=r(ywe," \u2014 "),cS=n(ywe,"A",{href:!0});var hzr=s(cS);PHe=r(hzr,"PoolFormerConfig"),hzr.forEach(t),BHe=r(ywe," (PoolFormer model)"),ywe.forEach(t),IHe=i(y),Bm=n(y,"LI",{});var Lwe=s(Bm);Sre=n(Lwe,"STRONG",{});var pzr=s(Sre);qHe=r(pzr,"prophetnet"),pzr.forEach(t),NHe=r(Lwe," \u2014 "),fS=n(Lwe,"A",{href:!0});var uzr=s(fS);jHe=r(uzr,"ProphetNetConfig"),uzr.forEach(t),DHe=r(Lwe," (ProphetNet model)"),Lwe.forEach(t),GHe=i(y),Im=n(y,"LI",{});var xwe=s(Im);Rre=n(xwe,"STRONG",{});var _zr=s(Rre);OHe=r(_zr,"qdqbert"),_zr.forEach(t),VHe=r(xwe," \u2014 "),mS=n(xwe,"A",{href:!0});var bzr=s(mS);XHe=r(bzr,"QDQBertConfig"),bzr.forEach(t),zHe=r(xwe," (QDQBert model)"),xwe.forEach(t),WHe=i(y),qm=n(y,"LI",{});var $we=s(qm);Pre=n($we,"STRONG",{});var vzr=s(Pre);QHe=r(vzr,"rag"),vzr.forEach(t),HHe=r($we," \u2014 "),gS=n($we,"A",{href:!0});var Fzr=s(gS);UHe=r(Fzr,"RagConfig"),Fzr.forEach(t),JHe=r($we," (RAG model)"),$we.forEach(t),YHe=i(y),Nm=n(y,"LI",{});var kwe=s(Nm);Bre=n(kwe,"STRONG",{});var Tzr=s(Bre);KHe=r(Tzr,"realm"),Tzr.forEach(t),ZHe=r(kwe," \u2014 "),hS=n(kwe,"A",{href:!0});var Mzr=s(hS);eUe=r(Mzr,"RealmConfig"),Mzr.forEach(t),oUe=r(kwe," (Realm model)"),kwe.forEach(t),rUe=i(y),jm=n(y,"LI",{});var Swe=s(jm);Ire=n(Swe,"STRONG",{});var Ezr=s(Ire);tUe=r(Ezr,"reformer"),Ezr.forEach(t),aUe=r(Swe," \u2014 "),pS=n(Swe,"A",{href:!0});var Czr=s(pS);nUe=r(Czr,"ReformerConfig"),Czr.forEach(t),sUe=r(Swe," (Reformer model)"),Swe.forEach(t),lUe=i(y),Dm=n(y,"LI",{});var Rwe=s(Dm);qre=n(Rwe,"STRONG",{});var wzr=s(qre);iUe=r(wzr,"regnet"),wzr.forEach(t),dUe=r(Rwe," \u2014 "),uS=n(Rwe,"A",{href:!0});var Azr=s(uS);cUe=r(Azr,"RegNetConfig"),Azr.forEach(t),fUe=r(Rwe," (RegNet model)"),Rwe.forEach(t),mUe=i(y),Gm=n(y,"LI",{});var Pwe=s(Gm);Nre=n(Pwe,"STRONG",{});var yzr=s(Nre);gUe=r(yzr,"rembert"),yzr.forEach(t),hUe=r(Pwe," \u2014 "),_S=n(Pwe,"A",{href:!0});var Lzr=s(_S);pUe=r(Lzr,"RemBertConfig"),Lzr.forEach(t),uUe=r(Pwe," (RemBERT model)"),Pwe.forEach(t),_Ue=i(y),Om=n(y,"LI",{});var Bwe=s(Om);jre=n(Bwe,"STRONG",{});var xzr=s(jre);bUe=r(xzr,"resnet"),xzr.forEach(t),vUe=r(Bwe," \u2014 "),bS=n(Bwe,"A",{href:!0});var $zr=s(bS);FUe=r($zr,"ResNetConfig"),$zr.forEach(t),TUe=r(Bwe," (ResNet model)"),Bwe.forEach(t),MUe=i(y),Vm=n(y,"LI",{});var Iwe=s(Vm);Dre=n(Iwe,"STRONG",{});var kzr=s(Dre);EUe=r(kzr,"retribert"),kzr.forEach(t),CUe=r(Iwe," \u2014 "),vS=n(Iwe,"A",{href:!0});var Szr=s(vS);wUe=r(Szr,"RetriBertConfig"),Szr.forEach(t),AUe=r(Iwe," (RetriBERT model)"),Iwe.forEach(t),yUe=i(y),Xm=n(y,"LI",{});var qwe=s(Xm);Gre=n(qwe,"STRONG",{});var Rzr=s(Gre);LUe=r(Rzr,"roberta"),Rzr.forEach(t),xUe=r(qwe," \u2014 "),FS=n(qwe,"A",{href:!0});var Pzr=s(FS);$Ue=r(Pzr,"RobertaConfig"),Pzr.forEach(t),kUe=r(qwe," (RoBERTa model)"),qwe.forEach(t),SUe=i(y),zm=n(y,"LI",{});var Nwe=s(zm);Ore=n(Nwe,"STRONG",{});var Bzr=s(Ore);RUe=r(Bzr,"roformer"),Bzr.forEach(t),PUe=r(Nwe," \u2014 "),TS=n(Nwe,"A",{href:!0});var Izr=s(TS);BUe=r(Izr,"RoFormerConfig"),Izr.forEach(t),IUe=r(Nwe," (RoFormer model)"),Nwe.forEach(t),qUe=i(y),Wm=n(y,"LI",{});var jwe=s(Wm);Vre=n(jwe,"STRONG",{});var qzr=s(Vre);NUe=r(qzr,"segformer"),qzr.forEach(t),jUe=r(jwe," \u2014 "),MS=n(jwe,"A",{href:!0});var Nzr=s(MS);DUe=r(Nzr,"SegformerConfig"),Nzr.forEach(t),GUe=r(jwe," (SegFormer model)"),jwe.forEach(t),OUe=i(y),Qm=n(y,"LI",{});var Dwe=s(Qm);Xre=n(Dwe,"STRONG",{});var jzr=s(Xre);VUe=r(jzr,"sew"),jzr.forEach(t),XUe=r(Dwe," \u2014 "),ES=n(Dwe,"A",{href:!0});var Dzr=s(ES);zUe=r(Dzr,"SEWConfig"),Dzr.forEach(t),WUe=r(Dwe," (SEW model)"),Dwe.forEach(t),QUe=i(y),Hm=n(y,"LI",{});var Gwe=s(Hm);zre=n(Gwe,"STRONG",{});var Gzr=s(zre);HUe=r(Gzr,"sew-d"),Gzr.forEach(t),UUe=r(Gwe," \u2014 "),CS=n(Gwe,"A",{href:!0});var Ozr=s(CS);JUe=r(Ozr,"SEWDConfig"),Ozr.forEach(t),YUe=r(Gwe," (SEW-D model)"),Gwe.forEach(t),KUe=i(y),Um=n(y,"LI",{});var Owe=s(Um);Wre=n(Owe,"STRONG",{});var Vzr=s(Wre);ZUe=r(Vzr,"speech-encoder-decoder"),Vzr.forEach(t),eJe=r(Owe," \u2014 "),wS=n(Owe,"A",{href:!0});var Xzr=s(wS);oJe=r(Xzr,"SpeechEncoderDecoderConfig"),Xzr.forEach(t),rJe=r(Owe," (Speech Encoder decoder model)"),Owe.forEach(t),tJe=i(y),Jm=n(y,"LI",{});var Vwe=s(Jm);Qre=n(Vwe,"STRONG",{});var zzr=s(Qre);aJe=r(zzr,"speech_to_text"),zzr.forEach(t),nJe=r(Vwe," \u2014 "),AS=n(Vwe,"A",{href:!0});var Wzr=s(AS);sJe=r(Wzr,"Speech2TextConfig"),Wzr.forEach(t),lJe=r(Vwe," (Speech2Text model)"),Vwe.forEach(t),iJe=i(y),Ym=n(y,"LI",{});var Xwe=s(Ym);Hre=n(Xwe,"STRONG",{});var Qzr=s(Hre);dJe=r(Qzr,"speech_to_text_2"),Qzr.forEach(t),cJe=r(Xwe," \u2014 "),yS=n(Xwe,"A",{href:!0});var Hzr=s(yS);fJe=r(Hzr,"Speech2Text2Config"),Hzr.forEach(t),mJe=r(Xwe," (Speech2Text2 model)"),Xwe.forEach(t),gJe=i(y),Km=n(y,"LI",{});var zwe=s(Km);Ure=n(zwe,"STRONG",{});var Uzr=s(Ure);hJe=r(Uzr,"splinter"),Uzr.forEach(t),pJe=r(zwe," \u2014 "),LS=n(zwe,"A",{href:!0});var Jzr=s(LS);uJe=r(Jzr,"SplinterConfig"),Jzr.forEach(t),_Je=r(zwe," (Splinter model)"),zwe.forEach(t),bJe=i(y),Zm=n(y,"LI",{});var Wwe=s(Zm);Jre=n(Wwe,"STRONG",{});var Yzr=s(Jre);vJe=r(Yzr,"squeezebert"),Yzr.forEach(t),FJe=r(Wwe," \u2014 "),xS=n(Wwe,"A",{href:!0});var Kzr=s(xS);TJe=r(Kzr,"SqueezeBertConfig"),Kzr.forEach(t),MJe=r(Wwe," (SqueezeBERT model)"),Wwe.forEach(t),EJe=i(y),eg=n(y,"LI",{});var Qwe=s(eg);Yre=n(Qwe,"STRONG",{});var Zzr=s(Yre);CJe=r(Zzr,"swin"),Zzr.forEach(t),wJe=r(Qwe," \u2014 "),$S=n(Qwe,"A",{href:!0});var eWr=s($S);AJe=r(eWr,"SwinConfig"),eWr.forEach(t),yJe=r(Qwe," (Swin model)"),Qwe.forEach(t),LJe=i(y),og=n(y,"LI",{});var Hwe=s(og);Kre=n(Hwe,"STRONG",{});var oWr=s(Kre);xJe=r(oWr,"t5"),oWr.forEach(t),$Je=r(Hwe," \u2014 "),kS=n(Hwe,"A",{href:!0});var rWr=s(kS);kJe=r(rWr,"T5Config"),rWr.forEach(t),SJe=r(Hwe," (T5 model)"),Hwe.forEach(t),RJe=i(y),rg=n(y,"LI",{});var Uwe=s(rg);Zre=n(Uwe,"STRONG",{});var tWr=s(Zre);PJe=r(tWr,"tapas"),tWr.forEach(t),BJe=r(Uwe," \u2014 "),SS=n(Uwe,"A",{href:!0});var aWr=s(SS);IJe=r(aWr,"TapasConfig"),aWr.forEach(t),qJe=r(Uwe," (TAPAS model)"),Uwe.forEach(t),NJe=i(y),tg=n(y,"LI",{});var Jwe=s(tg);ete=n(Jwe,"STRONG",{});var nWr=s(ete);jJe=r(nWr,"trajectory_transformer"),nWr.forEach(t),DJe=r(Jwe," \u2014 "),RS=n(Jwe,"A",{href:!0});var sWr=s(RS);GJe=r(sWr,"TrajectoryTransformerConfig"),sWr.forEach(t),OJe=r(Jwe," (Trajectory Transformer model)"),Jwe.forEach(t),VJe=i(y),ag=n(y,"LI",{});var Ywe=s(ag);ote=n(Ywe,"STRONG",{});var lWr=s(ote);XJe=r(lWr,"transfo-xl"),lWr.forEach(t),zJe=r(Ywe," \u2014 "),PS=n(Ywe,"A",{href:!0});var iWr=s(PS);WJe=r(iWr,"TransfoXLConfig"),iWr.forEach(t),QJe=r(Ywe," (Transformer-XL model)"),Ywe.forEach(t),HJe=i(y),ng=n(y,"LI",{});var Kwe=s(ng);rte=n(Kwe,"STRONG",{});var dWr=s(rte);UJe=r(dWr,"trocr"),dWr.forEach(t),JJe=r(Kwe," \u2014 "),BS=n(Kwe,"A",{href:!0});var cWr=s(BS);YJe=r(cWr,"TrOCRConfig"),cWr.forEach(t),KJe=r(Kwe," (TrOCR model)"),Kwe.forEach(t),ZJe=i(y),sg=n(y,"LI",{});var Zwe=s(sg);tte=n(Zwe,"STRONG",{});var fWr=s(tte);eYe=r(fWr,"unispeech"),fWr.forEach(t),oYe=r(Zwe," \u2014 "),IS=n(Zwe,"A",{href:!0});var mWr=s(IS);rYe=r(mWr,"UniSpeechConfig"),mWr.forEach(t),tYe=r(Zwe," (UniSpeech model)"),Zwe.forEach(t),aYe=i(y),lg=n(y,"LI",{});var e0e=s(lg);ate=n(e0e,"STRONG",{});var gWr=s(ate);nYe=r(gWr,"unispeech-sat"),gWr.forEach(t),sYe=r(e0e," \u2014 "),qS=n(e0e,"A",{href:!0});var hWr=s(qS);lYe=r(hWr,"UniSpeechSatConfig"),hWr.forEach(t),iYe=r(e0e," (UniSpeechSat model)"),e0e.forEach(t),dYe=i(y),ig=n(y,"LI",{});var o0e=s(ig);nte=n(o0e,"STRONG",{});var pWr=s(nte);cYe=r(pWr,"van"),pWr.forEach(t),fYe=r(o0e," \u2014 "),NS=n(o0e,"A",{href:!0});var uWr=s(NS);mYe=r(uWr,"VanConfig"),uWr.forEach(t),gYe=r(o0e," (VAN model)"),o0e.forEach(t),hYe=i(y),dg=n(y,"LI",{});var r0e=s(dg);ste=n(r0e,"STRONG",{});var _Wr=s(ste);pYe=r(_Wr,"vilt"),_Wr.forEach(t),uYe=r(r0e," \u2014 "),jS=n(r0e,"A",{href:!0});var bWr=s(jS);_Ye=r(bWr,"ViltConfig"),bWr.forEach(t),bYe=r(r0e," (ViLT model)"),r0e.forEach(t),vYe=i(y),cg=n(y,"LI",{});var t0e=s(cg);lte=n(t0e,"STRONG",{});var vWr=s(lte);FYe=r(vWr,"vision-encoder-decoder"),vWr.forEach(t),TYe=r(t0e," \u2014 "),DS=n(t0e,"A",{href:!0});var FWr=s(DS);MYe=r(FWr,"VisionEncoderDecoderConfig"),FWr.forEach(t),EYe=r(t0e," (Vision Encoder decoder model)"),t0e.forEach(t),CYe=i(y),fg=n(y,"LI",{});var a0e=s(fg);ite=n(a0e,"STRONG",{});var TWr=s(ite);wYe=r(TWr,"vision-text-dual-encoder"),TWr.forEach(t),AYe=r(a0e," \u2014 "),GS=n(a0e,"A",{href:!0});var MWr=s(GS);yYe=r(MWr,"VisionTextDualEncoderConfig"),MWr.forEach(t),LYe=r(a0e," (VisionTextDualEncoder model)"),a0e.forEach(t),xYe=i(y),mg=n(y,"LI",{});var n0e=s(mg);dte=n(n0e,"STRONG",{});var EWr=s(dte);$Ye=r(EWr,"visual_bert"),EWr.forEach(t),kYe=r(n0e," \u2014 "),OS=n(n0e,"A",{href:!0});var CWr=s(OS);SYe=r(CWr,"VisualBertConfig"),CWr.forEach(t),RYe=r(n0e," (VisualBert model)"),n0e.forEach(t),PYe=i(y),gg=n(y,"LI",{});var s0e=s(gg);cte=n(s0e,"STRONG",{});var wWr=s(cte);BYe=r(wWr,"vit"),wWr.forEach(t),IYe=r(s0e," \u2014 "),VS=n(s0e,"A",{href:!0});var AWr=s(VS);qYe=r(AWr,"ViTConfig"),AWr.forEach(t),NYe=r(s0e," (ViT model)"),s0e.forEach(t),jYe=i(y),hg=n(y,"LI",{});var l0e=s(hg);fte=n(l0e,"STRONG",{});var yWr=s(fte);DYe=r(yWr,"vit_mae"),yWr.forEach(t),GYe=r(l0e," \u2014 "),XS=n(l0e,"A",{href:!0});var LWr=s(XS);OYe=r(LWr,"ViTMAEConfig"),LWr.forEach(t),VYe=r(l0e," (ViTMAE model)"),l0e.forEach(t),XYe=i(y),pg=n(y,"LI",{});var i0e=s(pg);mte=n(i0e,"STRONG",{});var xWr=s(mte);zYe=r(xWr,"wav2vec2"),xWr.forEach(t),WYe=r(i0e," \u2014 "),zS=n(i0e,"A",{href:!0});var $Wr=s(zS);QYe=r($Wr,"Wav2Vec2Config"),$Wr.forEach(t),HYe=r(i0e," (Wav2Vec2 model)"),i0e.forEach(t),UYe=i(y),ug=n(y,"LI",{});var d0e=s(ug);gte=n(d0e,"STRONG",{});var kWr=s(gte);JYe=r(kWr,"wav2vec2-conformer"),kWr.forEach(t),YYe=r(d0e," \u2014 "),WS=n(d0e,"A",{href:!0});var SWr=s(WS);KYe=r(SWr,"Wav2Vec2ConformerConfig"),SWr.forEach(t),ZYe=r(d0e," (Wav2Vec2-Conformer model)"),d0e.forEach(t),eKe=i(y),_g=n(y,"LI",{});var c0e=s(_g);hte=n(c0e,"STRONG",{});var RWr=s(hte);oKe=r(RWr,"wavlm"),RWr.forEach(t),rKe=r(c0e," \u2014 "),QS=n(c0e,"A",{href:!0});var PWr=s(QS);tKe=r(PWr,"WavLMConfig"),PWr.forEach(t),aKe=r(c0e," (WavLM model)"),c0e.forEach(t),nKe=i(y),bg=n(y,"LI",{});var f0e=s(bg);pte=n(f0e,"STRONG",{});var BWr=s(pte);sKe=r(BWr,"xglm"),BWr.forEach(t),lKe=r(f0e," \u2014 "),HS=n(f0e,"A",{href:!0});var IWr=s(HS);iKe=r(IWr,"XGLMConfig"),IWr.forEach(t),dKe=r(f0e," (XGLM model)"),f0e.forEach(t),cKe=i(y),vg=n(y,"LI",{});var m0e=s(vg);ute=n(m0e,"STRONG",{});var qWr=s(ute);fKe=r(qWr,"xlm"),qWr.forEach(t),mKe=r(m0e," \u2014 "),US=n(m0e,"A",{href:!0});var NWr=s(US);gKe=r(NWr,"XLMConfig"),NWr.forEach(t),hKe=r(m0e," (XLM model)"),m0e.forEach(t),pKe=i(y),Fg=n(y,"LI",{});var g0e=s(Fg);_te=n(g0e,"STRONG",{});var jWr=s(_te);uKe=r(jWr,"xlm-prophetnet"),jWr.forEach(t),_Ke=r(g0e," \u2014 "),JS=n(g0e,"A",{href:!0});var DWr=s(JS);bKe=r(DWr,"XLMProphetNetConfig"),DWr.forEach(t),vKe=r(g0e," (XLMProphetNet model)"),g0e.forEach(t),FKe=i(y),Tg=n(y,"LI",{});var h0e=s(Tg);bte=n(h0e,"STRONG",{});var GWr=s(bte);TKe=r(GWr,"xlm-roberta"),GWr.forEach(t),MKe=r(h0e," \u2014 "),YS=n(h0e,"A",{href:!0});var OWr=s(YS);EKe=r(OWr,"XLMRobertaConfig"),OWr.forEach(t),CKe=r(h0e," (XLM-RoBERTa model)"),h0e.forEach(t),wKe=i(y),Mg=n(y,"LI",{});var p0e=s(Mg);vte=n(p0e,"STRONG",{});var VWr=s(vte);AKe=r(VWr,"xlm-roberta-xl"),VWr.forEach(t),yKe=r(p0e," \u2014 "),KS=n(p0e,"A",{href:!0});var XWr=s(KS);LKe=r(XWr,"XLMRobertaXLConfig"),XWr.forEach(t),xKe=r(p0e," (XLM-RoBERTa-XL model)"),p0e.forEach(t),$Ke=i(y),Eg=n(y,"LI",{});var u0e=s(Eg);Fte=n(u0e,"STRONG",{});var zWr=s(Fte);kKe=r(zWr,"xlnet"),zWr.forEach(t),SKe=r(u0e," \u2014 "),ZS=n(u0e,"A",{href:!0});var WWr=s(ZS);RKe=r(WWr,"XLNetConfig"),WWr.forEach(t),PKe=r(u0e," (XLNet model)"),u0e.forEach(t),BKe=i(y),Cg=n(y,"LI",{});var _0e=s(Cg);Tte=n(_0e,"STRONG",{});var QWr=s(Tte);IKe=r(QWr,"yolos"),QWr.forEach(t),qKe=r(_0e," \u2014 "),eR=n(_0e,"A",{href:!0});var HWr=s(eR);NKe=r(HWr,"YolosConfig"),HWr.forEach(t),jKe=r(_0e," (YOLOS model)"),_0e.forEach(t),DKe=i(y),wg=n(y,"LI",{});var b0e=s(wg);Mte=n(b0e,"STRONG",{});var UWr=s(Mte);GKe=r(UWr,"yoso"),UWr.forEach(t),OKe=r(b0e," \u2014 "),oR=n(b0e,"A",{href:!0});var JWr=s(oR);VKe=r(JWr,"YosoConfig"),JWr.forEach(t),XKe=r(b0e," (YOSO model)"),b0e.forEach(t),y.forEach(t),zKe=i(ot),T(Ag.$$.fragment,ot),ot.forEach(t),WKe=i(et),yg=n(et,"DIV",{class:!0});var nDe=s(yg);T(PA.$$.fragment,nDe),QKe=i(nDe),Ete=n(nDe,"P",{});var YWr=s(Ete);HKe=r(YWr,"Register a new configuration for this class."),YWr.forEach(t),nDe.forEach(t),et.forEach(t),iNe=i(f),Ci=n(f,"H2",{class:!0});var sDe=s(Ci);Lg=n(sDe,"A",{id:!0,class:!0,href:!0});var KWr=s(Lg);Cte=n(KWr,"SPAN",{});var ZWr=s(Cte);T(BA.$$.fragment,ZWr),ZWr.forEach(t),KWr.forEach(t),UKe=i(sDe),wte=n(sDe,"SPAN",{});var eQr=s(wte);JKe=r(eQr,"AutoTokenizer"),eQr.forEach(t),sDe.forEach(t),dNe=i(f),wo=n(f,"DIV",{class:!0});var Ds=s(wo);T(IA.$$.fragment,Ds),YKe=i(Ds),qA=n(Ds,"P",{});var lDe=s(qA);KKe=r(lDe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rR=n(lDe,"A",{href:!0});var oQr=s(rR);ZKe=r(oQr,"AutoTokenizer.from_pretrained()"),oQr.forEach(t),eZe=r(lDe," class method."),lDe.forEach(t),oZe=i(Ds),NA=n(Ds,"P",{});var iDe=s(NA);rZe=r(iDe,"This class cannot be instantiated directly using "),Ate=n(iDe,"CODE",{});var rQr=s(Ate);tZe=r(rQr,"__init__()"),rQr.forEach(t),aZe=r(iDe," (throws an error)."),iDe.forEach(t),nZe=i(Ds),Cr=n(Ds,"DIV",{class:!0});var Gs=s(Cr);T(jA.$$.fragment,Gs),sZe=i(Gs),yte=n(Gs,"P",{});var tQr=s(yte);lZe=r(tQr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),tQr.forEach(t),iZe=i(Gs),Aa=n(Gs,"P",{});var x0=s(Aa);dZe=r(x0,"The tokenizer class to instantiate is selected based on the "),Lte=n(x0,"CODE",{});var aQr=s(Lte);cZe=r(aQr,"model_type"),aQr.forEach(t),fZe=r(x0,` property of the config object (either
passed as an argument or loaded from `),xte=n(x0,"CODE",{});var nQr=s(xte);mZe=r(nQr,"pretrained_model_name_or_path"),nQr.forEach(t),gZe=r(x0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$te=n(x0,"CODE",{});var sQr=s($te);hZe=r(sQr,"pretrained_model_name_or_path"),sQr.forEach(t),pZe=r(x0,":"),x0.forEach(t),uZe=i(Gs),k=n(Gs,"UL",{});var S=s(k);Sn=n(S,"LI",{});var Dx=s(Sn);kte=n(Dx,"STRONG",{});var lQr=s(kte);_Ze=r(lQr,"albert"),lQr.forEach(t),bZe=r(Dx," \u2014 "),tR=n(Dx,"A",{href:!0});var iQr=s(tR);vZe=r(iQr,"AlbertTokenizer"),iQr.forEach(t),FZe=r(Dx," or "),aR=n(Dx,"A",{href:!0});var dQr=s(aR);TZe=r(dQr,"AlbertTokenizerFast"),dQr.forEach(t),MZe=r(Dx," (ALBERT model)"),Dx.forEach(t),EZe=i(S),Rn=n(S,"LI",{});var Gx=s(Rn);Ste=n(Gx,"STRONG",{});var cQr=s(Ste);CZe=r(cQr,"bart"),cQr.forEach(t),wZe=r(Gx," \u2014 "),nR=n(Gx,"A",{href:!0});var fQr=s(nR);AZe=r(fQr,"BartTokenizer"),fQr.forEach(t),yZe=r(Gx," or "),sR=n(Gx,"A",{href:!0});var mQr=s(sR);LZe=r(mQr,"BartTokenizerFast"),mQr.forEach(t),xZe=r(Gx," (BART model)"),Gx.forEach(t),$Ze=i(S),Pn=n(S,"LI",{});var Ox=s(Pn);Rte=n(Ox,"STRONG",{});var gQr=s(Rte);kZe=r(gQr,"barthez"),gQr.forEach(t),SZe=r(Ox," \u2014 "),lR=n(Ox,"A",{href:!0});var hQr=s(lR);RZe=r(hQr,"BarthezTokenizer"),hQr.forEach(t),PZe=r(Ox," or "),iR=n(Ox,"A",{href:!0});var pQr=s(iR);BZe=r(pQr,"BarthezTokenizerFast"),pQr.forEach(t),IZe=r(Ox," (BARThez model)"),Ox.forEach(t),qZe=i(S),Bn=n(S,"LI",{});var Vx=s(Bn);Pte=n(Vx,"STRONG",{});var uQr=s(Pte);NZe=r(uQr,"bartpho"),uQr.forEach(t),jZe=r(Vx," \u2014 "),dR=n(Vx,"A",{href:!0});var _Qr=s(dR);DZe=r(_Qr,"BartphoTokenizer"),_Qr.forEach(t),GZe=r(Vx," or "),cR=n(Vx,"A",{href:!0});var bQr=s(cR);OZe=r(bQr,"BartphoTokenizerFast"),bQr.forEach(t),VZe=r(Vx," (BARTpho model)"),Vx.forEach(t),XZe=i(S),In=n(S,"LI",{});var Xx=s(In);Bte=n(Xx,"STRONG",{});var vQr=s(Bte);zZe=r(vQr,"bert"),vQr.forEach(t),WZe=r(Xx," \u2014 "),fR=n(Xx,"A",{href:!0});var FQr=s(fR);QZe=r(FQr,"BertTokenizer"),FQr.forEach(t),HZe=r(Xx," or "),mR=n(Xx,"A",{href:!0});var TQr=s(mR);UZe=r(TQr,"BertTokenizerFast"),TQr.forEach(t),JZe=r(Xx," (BERT model)"),Xx.forEach(t),YZe=i(S),xg=n(S,"LI",{});var v0e=s(xg);Ite=n(v0e,"STRONG",{});var MQr=s(Ite);KZe=r(MQr,"bert-generation"),MQr.forEach(t),ZZe=r(v0e," \u2014 "),gR=n(v0e,"A",{href:!0});var EQr=s(gR);eeo=r(EQr,"BertGenerationTokenizer"),EQr.forEach(t),oeo=r(v0e," (Bert Generation model)"),v0e.forEach(t),reo=i(S),$g=n(S,"LI",{});var F0e=s($g);qte=n(F0e,"STRONG",{});var CQr=s(qte);teo=r(CQr,"bert-japanese"),CQr.forEach(t),aeo=r(F0e," \u2014 "),hR=n(F0e,"A",{href:!0});var wQr=s(hR);neo=r(wQr,"BertJapaneseTokenizer"),wQr.forEach(t),seo=r(F0e," (BertJapanese model)"),F0e.forEach(t),leo=i(S),qn=n(S,"LI",{});var zx=s(qn);Nte=n(zx,"STRONG",{});var AQr=s(Nte);ieo=r(AQr,"bertweet"),AQr.forEach(t),deo=r(zx," \u2014 "),pR=n(zx,"A",{href:!0});var yQr=s(pR);ceo=r(yQr,"BertweetTokenizer"),yQr.forEach(t),feo=r(zx," or "),uR=n(zx,"A",{href:!0});var LQr=s(uR);meo=r(LQr,"BertweetTokenizerFast"),LQr.forEach(t),geo=r(zx," (Bertweet model)"),zx.forEach(t),heo=i(S),Nn=n(S,"LI",{});var Wx=s(Nn);jte=n(Wx,"STRONG",{});var xQr=s(jte);peo=r(xQr,"big_bird"),xQr.forEach(t),ueo=r(Wx," \u2014 "),_R=n(Wx,"A",{href:!0});var $Qr=s(_R);_eo=r($Qr,"BigBirdTokenizer"),$Qr.forEach(t),beo=r(Wx," or "),bR=n(Wx,"A",{href:!0});var kQr=s(bR);veo=r(kQr,"BigBirdTokenizerFast"),kQr.forEach(t),Feo=r(Wx," (BigBird model)"),Wx.forEach(t),Teo=i(S),jn=n(S,"LI",{});var Qx=s(jn);Dte=n(Qx,"STRONG",{});var SQr=s(Dte);Meo=r(SQr,"bigbird_pegasus"),SQr.forEach(t),Eeo=r(Qx," \u2014 "),vR=n(Qx,"A",{href:!0});var RQr=s(vR);Ceo=r(RQr,"PegasusTokenizer"),RQr.forEach(t),weo=r(Qx," or "),FR=n(Qx,"A",{href:!0});var PQr=s(FR);Aeo=r(PQr,"PegasusTokenizerFast"),PQr.forEach(t),yeo=r(Qx," (BigBirdPegasus model)"),Qx.forEach(t),Leo=i(S),Dn=n(S,"LI",{});var Hx=s(Dn);Gte=n(Hx,"STRONG",{});var BQr=s(Gte);xeo=r(BQr,"blenderbot"),BQr.forEach(t),$eo=r(Hx," \u2014 "),TR=n(Hx,"A",{href:!0});var IQr=s(TR);keo=r(IQr,"BlenderbotTokenizer"),IQr.forEach(t),Seo=r(Hx," or "),MR=n(Hx,"A",{href:!0});var qQr=s(MR);Reo=r(qQr,"BlenderbotTokenizerFast"),qQr.forEach(t),Peo=r(Hx," (Blenderbot model)"),Hx.forEach(t),Beo=i(S),kg=n(S,"LI",{});var T0e=s(kg);Ote=n(T0e,"STRONG",{});var NQr=s(Ote);Ieo=r(NQr,"blenderbot-small"),NQr.forEach(t),qeo=r(T0e," \u2014 "),ER=n(T0e,"A",{href:!0});var jQr=s(ER);Neo=r(jQr,"BlenderbotSmallTokenizer"),jQr.forEach(t),jeo=r(T0e," (BlenderbotSmall model)"),T0e.forEach(t),Deo=i(S),Sg=n(S,"LI",{});var M0e=s(Sg);Vte=n(M0e,"STRONG",{});var DQr=s(Vte);Geo=r(DQr,"byt5"),DQr.forEach(t),Oeo=r(M0e," \u2014 "),CR=n(M0e,"A",{href:!0});var GQr=s(CR);Veo=r(GQr,"ByT5Tokenizer"),GQr.forEach(t),Xeo=r(M0e," (ByT5 model)"),M0e.forEach(t),zeo=i(S),Gn=n(S,"LI",{});var Ux=s(Gn);Xte=n(Ux,"STRONG",{});var OQr=s(Xte);Weo=r(OQr,"camembert"),OQr.forEach(t),Qeo=r(Ux," \u2014 "),wR=n(Ux,"A",{href:!0});var VQr=s(wR);Heo=r(VQr,"CamembertTokenizer"),VQr.forEach(t),Ueo=r(Ux," or "),AR=n(Ux,"A",{href:!0});var XQr=s(AR);Jeo=r(XQr,"CamembertTokenizerFast"),XQr.forEach(t),Yeo=r(Ux," (CamemBERT model)"),Ux.forEach(t),Keo=i(S),Rg=n(S,"LI",{});var E0e=s(Rg);zte=n(E0e,"STRONG",{});var zQr=s(zte);Zeo=r(zQr,"canine"),zQr.forEach(t),eoo=r(E0e," \u2014 "),yR=n(E0e,"A",{href:!0});var WQr=s(yR);ooo=r(WQr,"CanineTokenizer"),WQr.forEach(t),roo=r(E0e," (Canine model)"),E0e.forEach(t),too=i(S),On=n(S,"LI",{});var Jx=s(On);Wte=n(Jx,"STRONG",{});var QQr=s(Wte);aoo=r(QQr,"clip"),QQr.forEach(t),noo=r(Jx," \u2014 "),LR=n(Jx,"A",{href:!0});var HQr=s(LR);soo=r(HQr,"CLIPTokenizer"),HQr.forEach(t),loo=r(Jx," or "),xR=n(Jx,"A",{href:!0});var UQr=s(xR);ioo=r(UQr,"CLIPTokenizerFast"),UQr.forEach(t),doo=r(Jx," (CLIP model)"),Jx.forEach(t),coo=i(S),Vn=n(S,"LI",{});var Yx=s(Vn);Qte=n(Yx,"STRONG",{});var JQr=s(Qte);foo=r(JQr,"convbert"),JQr.forEach(t),moo=r(Yx," \u2014 "),$R=n(Yx,"A",{href:!0});var YQr=s($R);goo=r(YQr,"ConvBertTokenizer"),YQr.forEach(t),hoo=r(Yx," or "),kR=n(Yx,"A",{href:!0});var KQr=s(kR);poo=r(KQr,"ConvBertTokenizerFast"),KQr.forEach(t),uoo=r(Yx," (ConvBERT model)"),Yx.forEach(t),_oo=i(S),Xn=n(S,"LI",{});var Kx=s(Xn);Hte=n(Kx,"STRONG",{});var ZQr=s(Hte);boo=r(ZQr,"cpm"),ZQr.forEach(t),voo=r(Kx," \u2014 "),SR=n(Kx,"A",{href:!0});var eHr=s(SR);Foo=r(eHr,"CpmTokenizer"),eHr.forEach(t),Too=r(Kx," or "),RR=n(Kx,"A",{href:!0});var oHr=s(RR);Moo=r(oHr,"CpmTokenizerFast"),oHr.forEach(t),Eoo=r(Kx," (CPM model)"),Kx.forEach(t),Coo=i(S),Pg=n(S,"LI",{});var C0e=s(Pg);Ute=n(C0e,"STRONG",{});var rHr=s(Ute);woo=r(rHr,"ctrl"),rHr.forEach(t),Aoo=r(C0e," \u2014 "),PR=n(C0e,"A",{href:!0});var tHr=s(PR);yoo=r(tHr,"CTRLTokenizer"),tHr.forEach(t),Loo=r(C0e," (CTRL model)"),C0e.forEach(t),xoo=i(S),zn=n(S,"LI",{});var Zx=s(zn);Jte=n(Zx,"STRONG",{});var aHr=s(Jte);$oo=r(aHr,"data2vec-text"),aHr.forEach(t),koo=r(Zx," \u2014 "),BR=n(Zx,"A",{href:!0});var nHr=s(BR);Soo=r(nHr,"RobertaTokenizer"),nHr.forEach(t),Roo=r(Zx," or "),IR=n(Zx,"A",{href:!0});var sHr=s(IR);Poo=r(sHr,"RobertaTokenizerFast"),sHr.forEach(t),Boo=r(Zx," (Data2VecText model)"),Zx.forEach(t),Ioo=i(S),Wn=n(S,"LI",{});var e$=s(Wn);Yte=n(e$,"STRONG",{});var lHr=s(Yte);qoo=r(lHr,"deberta"),lHr.forEach(t),Noo=r(e$," \u2014 "),qR=n(e$,"A",{href:!0});var iHr=s(qR);joo=r(iHr,"DebertaTokenizer"),iHr.forEach(t),Doo=r(e$," or "),NR=n(e$,"A",{href:!0});var dHr=s(NR);Goo=r(dHr,"DebertaTokenizerFast"),dHr.forEach(t),Ooo=r(e$," (DeBERTa model)"),e$.forEach(t),Voo=i(S),Qn=n(S,"LI",{});var o$=s(Qn);Kte=n(o$,"STRONG",{});var cHr=s(Kte);Xoo=r(cHr,"deberta-v2"),cHr.forEach(t),zoo=r(o$," \u2014 "),jR=n(o$,"A",{href:!0});var fHr=s(jR);Woo=r(fHr,"DebertaV2Tokenizer"),fHr.forEach(t),Qoo=r(o$," or "),DR=n(o$,"A",{href:!0});var mHr=s(DR);Hoo=r(mHr,"DebertaV2TokenizerFast"),mHr.forEach(t),Uoo=r(o$," (DeBERTa-v2 model)"),o$.forEach(t),Joo=i(S),Hn=n(S,"LI",{});var r$=s(Hn);Zte=n(r$,"STRONG",{});var gHr=s(Zte);Yoo=r(gHr,"distilbert"),gHr.forEach(t),Koo=r(r$," \u2014 "),GR=n(r$,"A",{href:!0});var hHr=s(GR);Zoo=r(hHr,"DistilBertTokenizer"),hHr.forEach(t),ero=r(r$," or "),OR=n(r$,"A",{href:!0});var pHr=s(OR);oro=r(pHr,"DistilBertTokenizerFast"),pHr.forEach(t),rro=r(r$," (DistilBERT model)"),r$.forEach(t),tro=i(S),Un=n(S,"LI",{});var t$=s(Un);eae=n(t$,"STRONG",{});var uHr=s(eae);aro=r(uHr,"dpr"),uHr.forEach(t),nro=r(t$," \u2014 "),VR=n(t$,"A",{href:!0});var _Hr=s(VR);sro=r(_Hr,"DPRQuestionEncoderTokenizer"),_Hr.forEach(t),lro=r(t$," or "),XR=n(t$,"A",{href:!0});var bHr=s(XR);iro=r(bHr,"DPRQuestionEncoderTokenizerFast"),bHr.forEach(t),dro=r(t$," (DPR model)"),t$.forEach(t),cro=i(S),Jn=n(S,"LI",{});var a$=s(Jn);oae=n(a$,"STRONG",{});var vHr=s(oae);fro=r(vHr,"electra"),vHr.forEach(t),mro=r(a$," \u2014 "),zR=n(a$,"A",{href:!0});var FHr=s(zR);gro=r(FHr,"ElectraTokenizer"),FHr.forEach(t),hro=r(a$," or "),WR=n(a$,"A",{href:!0});var THr=s(WR);pro=r(THr,"ElectraTokenizerFast"),THr.forEach(t),uro=r(a$," (ELECTRA model)"),a$.forEach(t),_ro=i(S),Bg=n(S,"LI",{});var w0e=s(Bg);rae=n(w0e,"STRONG",{});var MHr=s(rae);bro=r(MHr,"flaubert"),MHr.forEach(t),vro=r(w0e," \u2014 "),QR=n(w0e,"A",{href:!0});var EHr=s(QR);Fro=r(EHr,"FlaubertTokenizer"),EHr.forEach(t),Tro=r(w0e," (FlauBERT model)"),w0e.forEach(t),Mro=i(S),Yn=n(S,"LI",{});var n$=s(Yn);tae=n(n$,"STRONG",{});var CHr=s(tae);Ero=r(CHr,"fnet"),CHr.forEach(t),Cro=r(n$," \u2014 "),HR=n(n$,"A",{href:!0});var wHr=s(HR);wro=r(wHr,"FNetTokenizer"),wHr.forEach(t),Aro=r(n$," or "),UR=n(n$,"A",{href:!0});var AHr=s(UR);yro=r(AHr,"FNetTokenizerFast"),AHr.forEach(t),Lro=r(n$," (FNet model)"),n$.forEach(t),xro=i(S),Ig=n(S,"LI",{});var A0e=s(Ig);aae=n(A0e,"STRONG",{});var yHr=s(aae);$ro=r(yHr,"fsmt"),yHr.forEach(t),kro=r(A0e," \u2014 "),JR=n(A0e,"A",{href:!0});var LHr=s(JR);Sro=r(LHr,"FSMTTokenizer"),LHr.forEach(t),Rro=r(A0e," (FairSeq Machine-Translation model)"),A0e.forEach(t),Pro=i(S),Kn=n(S,"LI",{});var s$=s(Kn);nae=n(s$,"STRONG",{});var xHr=s(nae);Bro=r(xHr,"funnel"),xHr.forEach(t),Iro=r(s$," \u2014 "),YR=n(s$,"A",{href:!0});var $Hr=s(YR);qro=r($Hr,"FunnelTokenizer"),$Hr.forEach(t),Nro=r(s$," or "),KR=n(s$,"A",{href:!0});var kHr=s(KR);jro=r(kHr,"FunnelTokenizerFast"),kHr.forEach(t),Dro=r(s$," (Funnel Transformer model)"),s$.forEach(t),Gro=i(S),Zn=n(S,"LI",{});var l$=s(Zn);sae=n(l$,"STRONG",{});var SHr=s(sae);Oro=r(SHr,"gpt2"),SHr.forEach(t),Vro=r(l$," \u2014 "),ZR=n(l$,"A",{href:!0});var RHr=s(ZR);Xro=r(RHr,"GPT2Tokenizer"),RHr.forEach(t),zro=r(l$," or "),eP=n(l$,"A",{href:!0});var PHr=s(eP);Wro=r(PHr,"GPT2TokenizerFast"),PHr.forEach(t),Qro=r(l$," (OpenAI GPT-2 model)"),l$.forEach(t),Hro=i(S),es=n(S,"LI",{});var i$=s(es);lae=n(i$,"STRONG",{});var BHr=s(lae);Uro=r(BHr,"gpt_neo"),BHr.forEach(t),Jro=r(i$," \u2014 "),oP=n(i$,"A",{href:!0});var IHr=s(oP);Yro=r(IHr,"GPT2Tokenizer"),IHr.forEach(t),Kro=r(i$," or "),rP=n(i$,"A",{href:!0});var qHr=s(rP);Zro=r(qHr,"GPT2TokenizerFast"),qHr.forEach(t),eto=r(i$," (GPT Neo model)"),i$.forEach(t),oto=i(S),qg=n(S,"LI",{});var y0e=s(qg);iae=n(y0e,"STRONG",{});var NHr=s(iae);rto=r(NHr,"gpt_neox"),NHr.forEach(t),tto=r(y0e," \u2014 "),tP=n(y0e,"A",{href:!0});var jHr=s(tP);ato=r(jHr,"GPTNeoXTokenizerFast"),jHr.forEach(t),nto=r(y0e," (GPT NeoX model)"),y0e.forEach(t),sto=i(S),os=n(S,"LI",{});var d$=s(os);dae=n(d$,"STRONG",{});var DHr=s(dae);lto=r(DHr,"gptj"),DHr.forEach(t),ito=r(d$," \u2014 "),aP=n(d$,"A",{href:!0});var GHr=s(aP);dto=r(GHr,"GPT2Tokenizer"),GHr.forEach(t),cto=r(d$," or "),nP=n(d$,"A",{href:!0});var OHr=s(nP);fto=r(OHr,"GPT2TokenizerFast"),OHr.forEach(t),mto=r(d$," (GPT-J model)"),d$.forEach(t),gto=i(S),rs=n(S,"LI",{});var c$=s(rs);cae=n(c$,"STRONG",{});var VHr=s(cae);hto=r(VHr,"herbert"),VHr.forEach(t),pto=r(c$," \u2014 "),sP=n(c$,"A",{href:!0});var XHr=s(sP);uto=r(XHr,"HerbertTokenizer"),XHr.forEach(t),_to=r(c$," or "),lP=n(c$,"A",{href:!0});var zHr=s(lP);bto=r(zHr,"HerbertTokenizerFast"),zHr.forEach(t),vto=r(c$," (HerBERT model)"),c$.forEach(t),Fto=i(S),Ng=n(S,"LI",{});var L0e=s(Ng);fae=n(L0e,"STRONG",{});var WHr=s(fae);Tto=r(WHr,"hubert"),WHr.forEach(t),Mto=r(L0e," \u2014 "),iP=n(L0e,"A",{href:!0});var QHr=s(iP);Eto=r(QHr,"Wav2Vec2CTCTokenizer"),QHr.forEach(t),Cto=r(L0e," (Hubert model)"),L0e.forEach(t),wto=i(S),ts=n(S,"LI",{});var f$=s(ts);mae=n(f$,"STRONG",{});var HHr=s(mae);Ato=r(HHr,"ibert"),HHr.forEach(t),yto=r(f$," \u2014 "),dP=n(f$,"A",{href:!0});var UHr=s(dP);Lto=r(UHr,"RobertaTokenizer"),UHr.forEach(t),xto=r(f$," or "),cP=n(f$,"A",{href:!0});var JHr=s(cP);$to=r(JHr,"RobertaTokenizerFast"),JHr.forEach(t),kto=r(f$," (I-BERT model)"),f$.forEach(t),Sto=i(S),as=n(S,"LI",{});var m$=s(as);gae=n(m$,"STRONG",{});var YHr=s(gae);Rto=r(YHr,"layoutlm"),YHr.forEach(t),Pto=r(m$," \u2014 "),fP=n(m$,"A",{href:!0});var KHr=s(fP);Bto=r(KHr,"LayoutLMTokenizer"),KHr.forEach(t),Ito=r(m$," or "),mP=n(m$,"A",{href:!0});var ZHr=s(mP);qto=r(ZHr,"LayoutLMTokenizerFast"),ZHr.forEach(t),Nto=r(m$," (LayoutLM model)"),m$.forEach(t),jto=i(S),ns=n(S,"LI",{});var g$=s(ns);hae=n(g$,"STRONG",{});var eUr=s(hae);Dto=r(eUr,"layoutlmv2"),eUr.forEach(t),Gto=r(g$," \u2014 "),gP=n(g$,"A",{href:!0});var oUr=s(gP);Oto=r(oUr,"LayoutLMv2Tokenizer"),oUr.forEach(t),Vto=r(g$," or "),hP=n(g$,"A",{href:!0});var rUr=s(hP);Xto=r(rUr,"LayoutLMv2TokenizerFast"),rUr.forEach(t),zto=r(g$," (LayoutLMv2 model)"),g$.forEach(t),Wto=i(S),ss=n(S,"LI",{});var h$=s(ss);pae=n(h$,"STRONG",{});var tUr=s(pae);Qto=r(tUr,"layoutlmv3"),tUr.forEach(t),Hto=r(h$," \u2014 "),pP=n(h$,"A",{href:!0});var aUr=s(pP);Uto=r(aUr,"LayoutLMv3Tokenizer"),aUr.forEach(t),Jto=r(h$," or "),uP=n(h$,"A",{href:!0});var nUr=s(uP);Yto=r(nUr,"LayoutLMv3TokenizerFast"),nUr.forEach(t),Kto=r(h$," (LayoutLMv3 model)"),h$.forEach(t),Zto=i(S),ls=n(S,"LI",{});var p$=s(ls);uae=n(p$,"STRONG",{});var sUr=s(uae);eao=r(sUr,"layoutxlm"),sUr.forEach(t),oao=r(p$," \u2014 "),_P=n(p$,"A",{href:!0});var lUr=s(_P);rao=r(lUr,"LayoutXLMTokenizer"),lUr.forEach(t),tao=r(p$," or "),bP=n(p$,"A",{href:!0});var iUr=s(bP);aao=r(iUr,"LayoutXLMTokenizerFast"),iUr.forEach(t),nao=r(p$," (LayoutXLM model)"),p$.forEach(t),sao=i(S),is=n(S,"LI",{});var u$=s(is);_ae=n(u$,"STRONG",{});var dUr=s(_ae);lao=r(dUr,"led"),dUr.forEach(t),iao=r(u$," \u2014 "),vP=n(u$,"A",{href:!0});var cUr=s(vP);dao=r(cUr,"LEDTokenizer"),cUr.forEach(t),cao=r(u$," or "),FP=n(u$,"A",{href:!0});var fUr=s(FP);fao=r(fUr,"LEDTokenizerFast"),fUr.forEach(t),mao=r(u$," (LED model)"),u$.forEach(t),gao=i(S),ds=n(S,"LI",{});var _$=s(ds);bae=n(_$,"STRONG",{});var mUr=s(bae);hao=r(mUr,"longformer"),mUr.forEach(t),pao=r(_$," \u2014 "),TP=n(_$,"A",{href:!0});var gUr=s(TP);uao=r(gUr,"LongformerTokenizer"),gUr.forEach(t),_ao=r(_$," or "),MP=n(_$,"A",{href:!0});var hUr=s(MP);bao=r(hUr,"LongformerTokenizerFast"),hUr.forEach(t),vao=r(_$," (Longformer model)"),_$.forEach(t),Fao=i(S),jg=n(S,"LI",{});var x0e=s(jg);vae=n(x0e,"STRONG",{});var pUr=s(vae);Tao=r(pUr,"luke"),pUr.forEach(t),Mao=r(x0e," \u2014 "),EP=n(x0e,"A",{href:!0});var uUr=s(EP);Eao=r(uUr,"LukeTokenizer"),uUr.forEach(t),Cao=r(x0e," (LUKE model)"),x0e.forEach(t),wao=i(S),cs=n(S,"LI",{});var b$=s(cs);Fae=n(b$,"STRONG",{});var _Ur=s(Fae);Aao=r(_Ur,"lxmert"),_Ur.forEach(t),yao=r(b$," \u2014 "),CP=n(b$,"A",{href:!0});var bUr=s(CP);Lao=r(bUr,"LxmertTokenizer"),bUr.forEach(t),xao=r(b$," or "),wP=n(b$,"A",{href:!0});var vUr=s(wP);$ao=r(vUr,"LxmertTokenizerFast"),vUr.forEach(t),kao=r(b$," (LXMERT model)"),b$.forEach(t),Sao=i(S),Dg=n(S,"LI",{});var $0e=s(Dg);Tae=n($0e,"STRONG",{});var FUr=s(Tae);Rao=r(FUr,"m2m_100"),FUr.forEach(t),Pao=r($0e," \u2014 "),AP=n($0e,"A",{href:!0});var TUr=s(AP);Bao=r(TUr,"M2M100Tokenizer"),TUr.forEach(t),Iao=r($0e," (M2M100 model)"),$0e.forEach(t),qao=i(S),Gg=n(S,"LI",{});var k0e=s(Gg);Mae=n(k0e,"STRONG",{});var MUr=s(Mae);Nao=r(MUr,"marian"),MUr.forEach(t),jao=r(k0e," \u2014 "),yP=n(k0e,"A",{href:!0});var EUr=s(yP);Dao=r(EUr,"MarianTokenizer"),EUr.forEach(t),Gao=r(k0e," (Marian model)"),k0e.forEach(t),Oao=i(S),fs=n(S,"LI",{});var v$=s(fs);Eae=n(v$,"STRONG",{});var CUr=s(Eae);Vao=r(CUr,"mbart"),CUr.forEach(t),Xao=r(v$," \u2014 "),LP=n(v$,"A",{href:!0});var wUr=s(LP);zao=r(wUr,"MBartTokenizer"),wUr.forEach(t),Wao=r(v$," or "),xP=n(v$,"A",{href:!0});var AUr=s(xP);Qao=r(AUr,"MBartTokenizerFast"),AUr.forEach(t),Hao=r(v$," (mBART model)"),v$.forEach(t),Uao=i(S),ms=n(S,"LI",{});var F$=s(ms);Cae=n(F$,"STRONG",{});var yUr=s(Cae);Jao=r(yUr,"mbart50"),yUr.forEach(t),Yao=r(F$," \u2014 "),$P=n(F$,"A",{href:!0});var LUr=s($P);Kao=r(LUr,"MBart50Tokenizer"),LUr.forEach(t),Zao=r(F$," or "),kP=n(F$,"A",{href:!0});var xUr=s(kP);eno=r(xUr,"MBart50TokenizerFast"),xUr.forEach(t),ono=r(F$," (mBART-50 model)"),F$.forEach(t),rno=i(S),gs=n(S,"LI",{});var T$=s(gs);wae=n(T$,"STRONG",{});var $Ur=s(wae);tno=r($Ur,"megatron-bert"),$Ur.forEach(t),ano=r(T$," \u2014 "),SP=n(T$,"A",{href:!0});var kUr=s(SP);nno=r(kUr,"BertTokenizer"),kUr.forEach(t),sno=r(T$," or "),RP=n(T$,"A",{href:!0});var SUr=s(RP);lno=r(SUr,"BertTokenizerFast"),SUr.forEach(t),ino=r(T$," (MegatronBert model)"),T$.forEach(t),dno=i(S),Og=n(S,"LI",{});var S0e=s(Og);Aae=n(S0e,"STRONG",{});var RUr=s(Aae);cno=r(RUr,"mluke"),RUr.forEach(t),fno=r(S0e," \u2014 "),PP=n(S0e,"A",{href:!0});var PUr=s(PP);mno=r(PUr,"MLukeTokenizer"),PUr.forEach(t),gno=r(S0e," (mLUKE model)"),S0e.forEach(t),hno=i(S),hs=n(S,"LI",{});var M$=s(hs);yae=n(M$,"STRONG",{});var BUr=s(yae);pno=r(BUr,"mobilebert"),BUr.forEach(t),uno=r(M$," \u2014 "),BP=n(M$,"A",{href:!0});var IUr=s(BP);_no=r(IUr,"MobileBertTokenizer"),IUr.forEach(t),bno=r(M$," or "),IP=n(M$,"A",{href:!0});var qUr=s(IP);vno=r(qUr,"MobileBertTokenizerFast"),qUr.forEach(t),Fno=r(M$," (MobileBERT model)"),M$.forEach(t),Tno=i(S),ps=n(S,"LI",{});var E$=s(ps);Lae=n(E$,"STRONG",{});var NUr=s(Lae);Mno=r(NUr,"mpnet"),NUr.forEach(t),Eno=r(E$," \u2014 "),qP=n(E$,"A",{href:!0});var jUr=s(qP);Cno=r(jUr,"MPNetTokenizer"),jUr.forEach(t),wno=r(E$," or "),NP=n(E$,"A",{href:!0});var DUr=s(NP);Ano=r(DUr,"MPNetTokenizerFast"),DUr.forEach(t),yno=r(E$," (MPNet model)"),E$.forEach(t),Lno=i(S),us=n(S,"LI",{});var C$=s(us);xae=n(C$,"STRONG",{});var GUr=s(xae);xno=r(GUr,"mt5"),GUr.forEach(t),$no=r(C$," \u2014 "),jP=n(C$,"A",{href:!0});var OUr=s(jP);kno=r(OUr,"MT5Tokenizer"),OUr.forEach(t),Sno=r(C$," or "),DP=n(C$,"A",{href:!0});var VUr=s(DP);Rno=r(VUr,"MT5TokenizerFast"),VUr.forEach(t),Pno=r(C$," (mT5 model)"),C$.forEach(t),Bno=i(S),_s=n(S,"LI",{});var w$=s(_s);$ae=n(w$,"STRONG",{});var XUr=s($ae);Ino=r(XUr,"nystromformer"),XUr.forEach(t),qno=r(w$," \u2014 "),GP=n(w$,"A",{href:!0});var zUr=s(GP);Nno=r(zUr,"AlbertTokenizer"),zUr.forEach(t),jno=r(w$," or "),OP=n(w$,"A",{href:!0});var WUr=s(OP);Dno=r(WUr,"AlbertTokenizerFast"),WUr.forEach(t),Gno=r(w$," (Nystromformer model)"),w$.forEach(t),Ono=i(S),bs=n(S,"LI",{});var A$=s(bs);kae=n(A$,"STRONG",{});var QUr=s(kae);Vno=r(QUr,"openai-gpt"),QUr.forEach(t),Xno=r(A$," \u2014 "),VP=n(A$,"A",{href:!0});var HUr=s(VP);zno=r(HUr,"OpenAIGPTTokenizer"),HUr.forEach(t),Wno=r(A$," or "),XP=n(A$,"A",{href:!0});var UUr=s(XP);Qno=r(UUr,"OpenAIGPTTokenizerFast"),UUr.forEach(t),Hno=r(A$," (OpenAI GPT model)"),A$.forEach(t),Uno=i(S),Vg=n(S,"LI",{});var R0e=s(Vg);Sae=n(R0e,"STRONG",{});var JUr=s(Sae);Jno=r(JUr,"opt"),JUr.forEach(t),Yno=r(R0e," \u2014 "),zP=n(R0e,"A",{href:!0});var YUr=s(zP);Kno=r(YUr,"GPT2Tokenizer"),YUr.forEach(t),Zno=r(R0e," (OPT model)"),R0e.forEach(t),eso=i(S),vs=n(S,"LI",{});var y$=s(vs);Rae=n(y$,"STRONG",{});var KUr=s(Rae);oso=r(KUr,"pegasus"),KUr.forEach(t),rso=r(y$," \u2014 "),WP=n(y$,"A",{href:!0});var ZUr=s(WP);tso=r(ZUr,"PegasusTokenizer"),ZUr.forEach(t),aso=r(y$," or "),QP=n(y$,"A",{href:!0});var eJr=s(QP);nso=r(eJr,"PegasusTokenizerFast"),eJr.forEach(t),sso=r(y$," (Pegasus model)"),y$.forEach(t),lso=i(S),Xg=n(S,"LI",{});var P0e=s(Xg);Pae=n(P0e,"STRONG",{});var oJr=s(Pae);iso=r(oJr,"perceiver"),oJr.forEach(t),dso=r(P0e," \u2014 "),HP=n(P0e,"A",{href:!0});var rJr=s(HP);cso=r(rJr,"PerceiverTokenizer"),rJr.forEach(t),fso=r(P0e," (Perceiver model)"),P0e.forEach(t),mso=i(S),Fs=n(S,"LI",{});var L$=s(Fs);Bae=n(L$,"STRONG",{});var tJr=s(Bae);gso=r(tJr,"phobert"),tJr.forEach(t),hso=r(L$," \u2014 "),UP=n(L$,"A",{href:!0});var aJr=s(UP);pso=r(aJr,"PhobertTokenizer"),aJr.forEach(t),uso=r(L$," or "),JP=n(L$,"A",{href:!0});var nJr=s(JP);_so=r(nJr,"PhobertTokenizerFast"),nJr.forEach(t),bso=r(L$," (PhoBERT model)"),L$.forEach(t),vso=i(S),zg=n(S,"LI",{});var B0e=s(zg);Iae=n(B0e,"STRONG",{});var sJr=s(Iae);Fso=r(sJr,"plbart"),sJr.forEach(t),Tso=r(B0e," \u2014 "),YP=n(B0e,"A",{href:!0});var lJr=s(YP);Mso=r(lJr,"PLBartTokenizer"),lJr.forEach(t),Eso=r(B0e," (PLBart model)"),B0e.forEach(t),Cso=i(S),Wg=n(S,"LI",{});var I0e=s(Wg);qae=n(I0e,"STRONG",{});var iJr=s(qae);wso=r(iJr,"prophetnet"),iJr.forEach(t),Aso=r(I0e," \u2014 "),KP=n(I0e,"A",{href:!0});var dJr=s(KP);yso=r(dJr,"ProphetNetTokenizer"),dJr.forEach(t),Lso=r(I0e," (ProphetNet model)"),I0e.forEach(t),xso=i(S),Ts=n(S,"LI",{});var x$=s(Ts);Nae=n(x$,"STRONG",{});var cJr=s(Nae);$so=r(cJr,"qdqbert"),cJr.forEach(t),kso=r(x$," \u2014 "),ZP=n(x$,"A",{href:!0});var fJr=s(ZP);Sso=r(fJr,"BertTokenizer"),fJr.forEach(t),Rso=r(x$," or "),eB=n(x$,"A",{href:!0});var mJr=s(eB);Pso=r(mJr,"BertTokenizerFast"),mJr.forEach(t),Bso=r(x$," (QDQBert model)"),x$.forEach(t),Iso=i(S),Qg=n(S,"LI",{});var q0e=s(Qg);jae=n(q0e,"STRONG",{});var gJr=s(jae);qso=r(gJr,"rag"),gJr.forEach(t),Nso=r(q0e," \u2014 "),oB=n(q0e,"A",{href:!0});var hJr=s(oB);jso=r(hJr,"RagTokenizer"),hJr.forEach(t),Dso=r(q0e," (RAG model)"),q0e.forEach(t),Gso=i(S),Ms=n(S,"LI",{});var $$=s(Ms);Dae=n($$,"STRONG",{});var pJr=s(Dae);Oso=r(pJr,"realm"),pJr.forEach(t),Vso=r($$," \u2014 "),rB=n($$,"A",{href:!0});var uJr=s(rB);Xso=r(uJr,"RealmTokenizer"),uJr.forEach(t),zso=r($$," or "),tB=n($$,"A",{href:!0});var _Jr=s(tB);Wso=r(_Jr,"RealmTokenizerFast"),_Jr.forEach(t),Qso=r($$," (Realm model)"),$$.forEach(t),Hso=i(S),Es=n(S,"LI",{});var k$=s(Es);Gae=n(k$,"STRONG",{});var bJr=s(Gae);Uso=r(bJr,"reformer"),bJr.forEach(t),Jso=r(k$," \u2014 "),aB=n(k$,"A",{href:!0});var vJr=s(aB);Yso=r(vJr,"ReformerTokenizer"),vJr.forEach(t),Kso=r(k$," or "),nB=n(k$,"A",{href:!0});var FJr=s(nB);Zso=r(FJr,"ReformerTokenizerFast"),FJr.forEach(t),elo=r(k$," (Reformer model)"),k$.forEach(t),olo=i(S),Cs=n(S,"LI",{});var S$=s(Cs);Oae=n(S$,"STRONG",{});var TJr=s(Oae);rlo=r(TJr,"rembert"),TJr.forEach(t),tlo=r(S$," \u2014 "),sB=n(S$,"A",{href:!0});var MJr=s(sB);alo=r(MJr,"RemBertTokenizer"),MJr.forEach(t),nlo=r(S$," or "),lB=n(S$,"A",{href:!0});var EJr=s(lB);slo=r(EJr,"RemBertTokenizerFast"),EJr.forEach(t),llo=r(S$," (RemBERT model)"),S$.forEach(t),ilo=i(S),ws=n(S,"LI",{});var R$=s(ws);Vae=n(R$,"STRONG",{});var CJr=s(Vae);dlo=r(CJr,"retribert"),CJr.forEach(t),clo=r(R$," \u2014 "),iB=n(R$,"A",{href:!0});var wJr=s(iB);flo=r(wJr,"RetriBertTokenizer"),wJr.forEach(t),mlo=r(R$," or "),dB=n(R$,"A",{href:!0});var AJr=s(dB);glo=r(AJr,"RetriBertTokenizerFast"),AJr.forEach(t),hlo=r(R$," (RetriBERT model)"),R$.forEach(t),plo=i(S),As=n(S,"LI",{});var P$=s(As);Xae=n(P$,"STRONG",{});var yJr=s(Xae);ulo=r(yJr,"roberta"),yJr.forEach(t),_lo=r(P$," \u2014 "),cB=n(P$,"A",{href:!0});var LJr=s(cB);blo=r(LJr,"RobertaTokenizer"),LJr.forEach(t),vlo=r(P$," or "),fB=n(P$,"A",{href:!0});var xJr=s(fB);Flo=r(xJr,"RobertaTokenizerFast"),xJr.forEach(t),Tlo=r(P$," (RoBERTa model)"),P$.forEach(t),Mlo=i(S),ys=n(S,"LI",{});var B$=s(ys);zae=n(B$,"STRONG",{});var $Jr=s(zae);Elo=r($Jr,"roformer"),$Jr.forEach(t),Clo=r(B$," \u2014 "),mB=n(B$,"A",{href:!0});var kJr=s(mB);wlo=r(kJr,"RoFormerTokenizer"),kJr.forEach(t),Alo=r(B$," or "),gB=n(B$,"A",{href:!0});var SJr=s(gB);ylo=r(SJr,"RoFormerTokenizerFast"),SJr.forEach(t),Llo=r(B$," (RoFormer model)"),B$.forEach(t),xlo=i(S),Hg=n(S,"LI",{});var N0e=s(Hg);Wae=n(N0e,"STRONG",{});var RJr=s(Wae);$lo=r(RJr,"speech_to_text"),RJr.forEach(t),klo=r(N0e," \u2014 "),hB=n(N0e,"A",{href:!0});var PJr=s(hB);Slo=r(PJr,"Speech2TextTokenizer"),PJr.forEach(t),Rlo=r(N0e," (Speech2Text model)"),N0e.forEach(t),Plo=i(S),Ug=n(S,"LI",{});var j0e=s(Ug);Qae=n(j0e,"STRONG",{});var BJr=s(Qae);Blo=r(BJr,"speech_to_text_2"),BJr.forEach(t),Ilo=r(j0e," \u2014 "),pB=n(j0e,"A",{href:!0});var IJr=s(pB);qlo=r(IJr,"Speech2Text2Tokenizer"),IJr.forEach(t),Nlo=r(j0e," (Speech2Text2 model)"),j0e.forEach(t),jlo=i(S),Ls=n(S,"LI",{});var I$=s(Ls);Hae=n(I$,"STRONG",{});var qJr=s(Hae);Dlo=r(qJr,"splinter"),qJr.forEach(t),Glo=r(I$," \u2014 "),uB=n(I$,"A",{href:!0});var NJr=s(uB);Olo=r(NJr,"SplinterTokenizer"),NJr.forEach(t),Vlo=r(I$," or "),_B=n(I$,"A",{href:!0});var jJr=s(_B);Xlo=r(jJr,"SplinterTokenizerFast"),jJr.forEach(t),zlo=r(I$," (Splinter model)"),I$.forEach(t),Wlo=i(S),xs=n(S,"LI",{});var q$=s(xs);Uae=n(q$,"STRONG",{});var DJr=s(Uae);Qlo=r(DJr,"squeezebert"),DJr.forEach(t),Hlo=r(q$," \u2014 "),bB=n(q$,"A",{href:!0});var GJr=s(bB);Ulo=r(GJr,"SqueezeBertTokenizer"),GJr.forEach(t),Jlo=r(q$," or "),vB=n(q$,"A",{href:!0});var OJr=s(vB);Ylo=r(OJr,"SqueezeBertTokenizerFast"),OJr.forEach(t),Klo=r(q$," (SqueezeBERT model)"),q$.forEach(t),Zlo=i(S),$s=n(S,"LI",{});var N$=s($s);Jae=n(N$,"STRONG",{});var VJr=s(Jae);eio=r(VJr,"t5"),VJr.forEach(t),oio=r(N$," \u2014 "),FB=n(N$,"A",{href:!0});var XJr=s(FB);rio=r(XJr,"T5Tokenizer"),XJr.forEach(t),tio=r(N$," or "),TB=n(N$,"A",{href:!0});var zJr=s(TB);aio=r(zJr,"T5TokenizerFast"),zJr.forEach(t),nio=r(N$," (T5 model)"),N$.forEach(t),sio=i(S),Jg=n(S,"LI",{});var D0e=s(Jg);Yae=n(D0e,"STRONG",{});var WJr=s(Yae);lio=r(WJr,"tapas"),WJr.forEach(t),iio=r(D0e," \u2014 "),MB=n(D0e,"A",{href:!0});var QJr=s(MB);dio=r(QJr,"TapasTokenizer"),QJr.forEach(t),cio=r(D0e," (TAPAS model)"),D0e.forEach(t),fio=i(S),Yg=n(S,"LI",{});var G0e=s(Yg);Kae=n(G0e,"STRONG",{});var HJr=s(Kae);mio=r(HJr,"tapex"),HJr.forEach(t),gio=r(G0e," \u2014 "),EB=n(G0e,"A",{href:!0});var UJr=s(EB);hio=r(UJr,"TapexTokenizer"),UJr.forEach(t),pio=r(G0e," (TAPEX model)"),G0e.forEach(t),uio=i(S),Kg=n(S,"LI",{});var O0e=s(Kg);Zae=n(O0e,"STRONG",{});var JJr=s(Zae);_io=r(JJr,"transfo-xl"),JJr.forEach(t),bio=r(O0e," \u2014 "),CB=n(O0e,"A",{href:!0});var YJr=s(CB);vio=r(YJr,"TransfoXLTokenizer"),YJr.forEach(t),Fio=r(O0e," (Transformer-XL model)"),O0e.forEach(t),Tio=i(S),ks=n(S,"LI",{});var j$=s(ks);ene=n(j$,"STRONG",{});var KJr=s(ene);Mio=r(KJr,"visual_bert"),KJr.forEach(t),Eio=r(j$," \u2014 "),wB=n(j$,"A",{href:!0});var ZJr=s(wB);Cio=r(ZJr,"BertTokenizer"),ZJr.forEach(t),wio=r(j$," or "),AB=n(j$,"A",{href:!0});var eYr=s(AB);Aio=r(eYr,"BertTokenizerFast"),eYr.forEach(t),yio=r(j$," (VisualBert model)"),j$.forEach(t),Lio=i(S),Zg=n(S,"LI",{});var V0e=s(Zg);one=n(V0e,"STRONG",{});var oYr=s(one);xio=r(oYr,"wav2vec2"),oYr.forEach(t),$io=r(V0e," \u2014 "),yB=n(V0e,"A",{href:!0});var rYr=s(yB);kio=r(rYr,"Wav2Vec2CTCTokenizer"),rYr.forEach(t),Sio=r(V0e," (Wav2Vec2 model)"),V0e.forEach(t),Rio=i(S),eh=n(S,"LI",{});var X0e=s(eh);rne=n(X0e,"STRONG",{});var tYr=s(rne);Pio=r(tYr,"wav2vec2-conformer"),tYr.forEach(t),Bio=r(X0e," \u2014 "),LB=n(X0e,"A",{href:!0});var aYr=s(LB);Iio=r(aYr,"Wav2Vec2CTCTokenizer"),aYr.forEach(t),qio=r(X0e," (Wav2Vec2-Conformer model)"),X0e.forEach(t),Nio=i(S),oh=n(S,"LI",{});var z0e=s(oh);tne=n(z0e,"STRONG",{});var nYr=s(tne);jio=r(nYr,"wav2vec2_phoneme"),nYr.forEach(t),Dio=r(z0e," \u2014 "),xB=n(z0e,"A",{href:!0});var sYr=s(xB);Gio=r(sYr,"Wav2Vec2PhonemeCTCTokenizer"),sYr.forEach(t),Oio=r(z0e," (Wav2Vec2Phoneme model)"),z0e.forEach(t),Vio=i(S),Ss=n(S,"LI",{});var D$=s(Ss);ane=n(D$,"STRONG",{});var lYr=s(ane);Xio=r(lYr,"xglm"),lYr.forEach(t),zio=r(D$," \u2014 "),$B=n(D$,"A",{href:!0});var iYr=s($B);Wio=r(iYr,"XGLMTokenizer"),iYr.forEach(t),Qio=r(D$," or "),kB=n(D$,"A",{href:!0});var dYr=s(kB);Hio=r(dYr,"XGLMTokenizerFast"),dYr.forEach(t),Uio=r(D$," (XGLM model)"),D$.forEach(t),Jio=i(S),rh=n(S,"LI",{});var W0e=s(rh);nne=n(W0e,"STRONG",{});var cYr=s(nne);Yio=r(cYr,"xlm"),cYr.forEach(t),Kio=r(W0e," \u2014 "),SB=n(W0e,"A",{href:!0});var fYr=s(SB);Zio=r(fYr,"XLMTokenizer"),fYr.forEach(t),edo=r(W0e," (XLM model)"),W0e.forEach(t),odo=i(S),th=n(S,"LI",{});var Q0e=s(th);sne=n(Q0e,"STRONG",{});var mYr=s(sne);rdo=r(mYr,"xlm-prophetnet"),mYr.forEach(t),tdo=r(Q0e," \u2014 "),RB=n(Q0e,"A",{href:!0});var gYr=s(RB);ado=r(gYr,"XLMProphetNetTokenizer"),gYr.forEach(t),ndo=r(Q0e," (XLMProphetNet model)"),Q0e.forEach(t),sdo=i(S),Rs=n(S,"LI",{});var G$=s(Rs);lne=n(G$,"STRONG",{});var hYr=s(lne);ldo=r(hYr,"xlm-roberta"),hYr.forEach(t),ido=r(G$," \u2014 "),PB=n(G$,"A",{href:!0});var pYr=s(PB);ddo=r(pYr,"XLMRobertaTokenizer"),pYr.forEach(t),cdo=r(G$," or "),BB=n(G$,"A",{href:!0});var uYr=s(BB);fdo=r(uYr,"XLMRobertaTokenizerFast"),uYr.forEach(t),mdo=r(G$," (XLM-RoBERTa model)"),G$.forEach(t),gdo=i(S),Ps=n(S,"LI",{});var O$=s(Ps);ine=n(O$,"STRONG",{});var _Yr=s(ine);hdo=r(_Yr,"xlm-roberta-xl"),_Yr.forEach(t),pdo=r(O$," \u2014 "),IB=n(O$,"A",{href:!0});var bYr=s(IB);udo=r(bYr,"RobertaTokenizer"),bYr.forEach(t),_do=r(O$," or "),qB=n(O$,"A",{href:!0});var vYr=s(qB);bdo=r(vYr,"RobertaTokenizerFast"),vYr.forEach(t),vdo=r(O$," (XLM-RoBERTa-XL model)"),O$.forEach(t),Fdo=i(S),Bs=n(S,"LI",{});var V$=s(Bs);dne=n(V$,"STRONG",{});var FYr=s(dne);Tdo=r(FYr,"xlnet"),FYr.forEach(t),Mdo=r(V$," \u2014 "),NB=n(V$,"A",{href:!0});var TYr=s(NB);Edo=r(TYr,"XLNetTokenizer"),TYr.forEach(t),Cdo=r(V$," or "),jB=n(V$,"A",{href:!0});var MYr=s(jB);wdo=r(MYr,"XLNetTokenizerFast"),MYr.forEach(t),Ado=r(V$," (XLNet model)"),V$.forEach(t),ydo=i(S),Is=n(S,"LI",{});var X$=s(Is);cne=n(X$,"STRONG",{});var EYr=s(cne);Ldo=r(EYr,"yoso"),EYr.forEach(t),xdo=r(X$," \u2014 "),DB=n(X$,"A",{href:!0});var CYr=s(DB);$do=r(CYr,"AlbertTokenizer"),CYr.forEach(t),kdo=r(X$," or "),GB=n(X$,"A",{href:!0});var wYr=s(GB);Sdo=r(wYr,"AlbertTokenizerFast"),wYr.forEach(t),Rdo=r(X$," (YOSO model)"),X$.forEach(t),S.forEach(t),Pdo=i(Gs),T(ah.$$.fragment,Gs),Gs.forEach(t),Bdo=i(Ds),nh=n(Ds,"DIV",{class:!0});var dDe=s(nh);T(DA.$$.fragment,dDe),Ido=i(dDe),fne=n(dDe,"P",{});var AYr=s(fne);qdo=r(AYr,"Register a new tokenizer in this mapping."),AYr.forEach(t),dDe.forEach(t),Ds.forEach(t),cNe=i(f),wi=n(f,"H2",{class:!0});var cDe=s(wi);sh=n(cDe,"A",{id:!0,class:!0,href:!0});var yYr=s(sh);mne=n(yYr,"SPAN",{});var LYr=s(mne);T(GA.$$.fragment,LYr),LYr.forEach(t),yYr.forEach(t),Ndo=i(cDe),gne=n(cDe,"SPAN",{});var xYr=s(gne);jdo=r(xYr,"AutoFeatureExtractor"),xYr.forEach(t),cDe.forEach(t),fNe=i(f),Ao=n(f,"DIV",{class:!0});var Os=s(Ao);T(OA.$$.fragment,Os),Ddo=i(Os),VA=n(Os,"P",{});var fDe=s(VA);Gdo=r(fDe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),OB=n(fDe,"A",{href:!0});var $Yr=s(OB);Odo=r($Yr,"AutoFeatureExtractor.from_pretrained()"),$Yr.forEach(t),Vdo=r(fDe," class method."),fDe.forEach(t),Xdo=i(Os),XA=n(Os,"P",{});var mDe=s(XA);zdo=r(mDe,"This class cannot be instantiated directly using "),hne=n(mDe,"CODE",{});var kYr=s(hne);Wdo=r(kYr,"__init__()"),kYr.forEach(t),Qdo=r(mDe," (throws an error)."),mDe.forEach(t),Hdo=i(Os),He=n(Os,"DIV",{class:!0});var Zt=s(He);T(zA.$$.fragment,Zt),Udo=i(Zt),pne=n(Zt,"P",{});var SYr=s(pne);Jdo=r(SYr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),SYr.forEach(t),Ydo=i(Zt),ya=n(Zt,"P",{});var $0=s(ya);Kdo=r($0,"The feature extractor class to instantiate is selected based on the "),une=n($0,"CODE",{});var RYr=s(une);Zdo=r(RYr,"model_type"),RYr.forEach(t),eco=r($0,` property of the config object
(either passed as an argument or loaded from `),_ne=n($0,"CODE",{});var PYr=s(_ne);oco=r(PYr,"pretrained_model_name_or_path"),PYr.forEach(t),rco=r($0,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),bne=n($0,"CODE",{});var BYr=s(bne);tco=r(BYr,"pretrained_model_name_or_path"),BYr.forEach(t),aco=r($0,":"),$0.forEach(t),nco=i(Zt),Y=n(Zt,"UL",{});var Z=s(Y);lh=n(Z,"LI",{});var H0e=s(lh);vne=n(H0e,"STRONG",{});var IYr=s(vne);sco=r(IYr,"beit"),IYr.forEach(t),lco=r(H0e," \u2014 "),VB=n(H0e,"A",{href:!0});var qYr=s(VB);ico=r(qYr,"BeitFeatureExtractor"),qYr.forEach(t),dco=r(H0e," (BEiT model)"),H0e.forEach(t),cco=i(Z),ih=n(Z,"LI",{});var U0e=s(ih);Fne=n(U0e,"STRONG",{});var NYr=s(Fne);fco=r(NYr,"clip"),NYr.forEach(t),mco=r(U0e," \u2014 "),XB=n(U0e,"A",{href:!0});var jYr=s(XB);gco=r(jYr,"CLIPFeatureExtractor"),jYr.forEach(t),hco=r(U0e," (CLIP model)"),U0e.forEach(t),pco=i(Z),dh=n(Z,"LI",{});var J0e=s(dh);Tne=n(J0e,"STRONG",{});var DYr=s(Tne);uco=r(DYr,"convnext"),DYr.forEach(t),_co=r(J0e," \u2014 "),zB=n(J0e,"A",{href:!0});var GYr=s(zB);bco=r(GYr,"ConvNextFeatureExtractor"),GYr.forEach(t),vco=r(J0e," (ConvNext model)"),J0e.forEach(t),Fco=i(Z),ch=n(Z,"LI",{});var Y0e=s(ch);Mne=n(Y0e,"STRONG",{});var OYr=s(Mne);Tco=r(OYr,"cvt"),OYr.forEach(t),Mco=r(Y0e," \u2014 "),WB=n(Y0e,"A",{href:!0});var VYr=s(WB);Eco=r(VYr,"ConvNextFeatureExtractor"),VYr.forEach(t),Cco=r(Y0e," (CvT model)"),Y0e.forEach(t),wco=i(Z),fh=n(Z,"LI",{});var K0e=s(fh);Ene=n(K0e,"STRONG",{});var XYr=s(Ene);Aco=r(XYr,"data2vec-audio"),XYr.forEach(t),yco=r(K0e," \u2014 "),QB=n(K0e,"A",{href:!0});var zYr=s(QB);Lco=r(zYr,"Wav2Vec2FeatureExtractor"),zYr.forEach(t),xco=r(K0e," (Data2VecAudio model)"),K0e.forEach(t),$co=i(Z),mh=n(Z,"LI",{});var Z0e=s(mh);Cne=n(Z0e,"STRONG",{});var WYr=s(Cne);kco=r(WYr,"data2vec-vision"),WYr.forEach(t),Sco=r(Z0e," \u2014 "),HB=n(Z0e,"A",{href:!0});var QYr=s(HB);Rco=r(QYr,"BeitFeatureExtractor"),QYr.forEach(t),Pco=r(Z0e," (Data2VecVision model)"),Z0e.forEach(t),Bco=i(Z),gh=n(Z,"LI",{});var e6e=s(gh);wne=n(e6e,"STRONG",{});var HYr=s(wne);Ico=r(HYr,"deit"),HYr.forEach(t),qco=r(e6e," \u2014 "),UB=n(e6e,"A",{href:!0});var UYr=s(UB);Nco=r(UYr,"DeiTFeatureExtractor"),UYr.forEach(t),jco=r(e6e," (DeiT model)"),e6e.forEach(t),Dco=i(Z),hh=n(Z,"LI",{});var o6e=s(hh);Ane=n(o6e,"STRONG",{});var JYr=s(Ane);Gco=r(JYr,"detr"),JYr.forEach(t),Oco=r(o6e," \u2014 "),JB=n(o6e,"A",{href:!0});var YYr=s(JB);Vco=r(YYr,"DetrFeatureExtractor"),YYr.forEach(t),Xco=r(o6e," (DETR model)"),o6e.forEach(t),zco=i(Z),ph=n(Z,"LI",{});var r6e=s(ph);yne=n(r6e,"STRONG",{});var KYr=s(yne);Wco=r(KYr,"dpt"),KYr.forEach(t),Qco=r(r6e," \u2014 "),YB=n(r6e,"A",{href:!0});var ZYr=s(YB);Hco=r(ZYr,"DPTFeatureExtractor"),ZYr.forEach(t),Uco=r(r6e," (DPT model)"),r6e.forEach(t),Jco=i(Z),uh=n(Z,"LI",{});var t6e=s(uh);Lne=n(t6e,"STRONG",{});var eKr=s(Lne);Yco=r(eKr,"flava"),eKr.forEach(t),Kco=r(t6e," \u2014 "),KB=n(t6e,"A",{href:!0});var oKr=s(KB);Zco=r(oKr,"FlavaFeatureExtractor"),oKr.forEach(t),efo=r(t6e," (Flava model)"),t6e.forEach(t),ofo=i(Z),_h=n(Z,"LI",{});var a6e=s(_h);xne=n(a6e,"STRONG",{});var rKr=s(xne);rfo=r(rKr,"glpn"),rKr.forEach(t),tfo=r(a6e," \u2014 "),ZB=n(a6e,"A",{href:!0});var tKr=s(ZB);afo=r(tKr,"GLPNFeatureExtractor"),tKr.forEach(t),nfo=r(a6e," (GLPN model)"),a6e.forEach(t),sfo=i(Z),bh=n(Z,"LI",{});var n6e=s(bh);$ne=n(n6e,"STRONG",{});var aKr=s($ne);lfo=r(aKr,"hubert"),aKr.forEach(t),ifo=r(n6e," \u2014 "),eI=n(n6e,"A",{href:!0});var nKr=s(eI);dfo=r(nKr,"Wav2Vec2FeatureExtractor"),nKr.forEach(t),cfo=r(n6e," (Hubert model)"),n6e.forEach(t),ffo=i(Z),vh=n(Z,"LI",{});var s6e=s(vh);kne=n(s6e,"STRONG",{});var sKr=s(kne);mfo=r(sKr,"imagegpt"),sKr.forEach(t),gfo=r(s6e," \u2014 "),oI=n(s6e,"A",{href:!0});var lKr=s(oI);hfo=r(lKr,"ImageGPTFeatureExtractor"),lKr.forEach(t),pfo=r(s6e," (ImageGPT model)"),s6e.forEach(t),ufo=i(Z),Fh=n(Z,"LI",{});var l6e=s(Fh);Sne=n(l6e,"STRONG",{});var iKr=s(Sne);_fo=r(iKr,"layoutlmv2"),iKr.forEach(t),bfo=r(l6e," \u2014 "),rI=n(l6e,"A",{href:!0});var dKr=s(rI);vfo=r(dKr,"LayoutLMv2FeatureExtractor"),dKr.forEach(t),Ffo=r(l6e," (LayoutLMv2 model)"),l6e.forEach(t),Tfo=i(Z),Th=n(Z,"LI",{});var i6e=s(Th);Rne=n(i6e,"STRONG",{});var cKr=s(Rne);Mfo=r(cKr,"layoutlmv3"),cKr.forEach(t),Efo=r(i6e," \u2014 "),tI=n(i6e,"A",{href:!0});var fKr=s(tI);Cfo=r(fKr,"LayoutLMv3FeatureExtractor"),fKr.forEach(t),wfo=r(i6e," (LayoutLMv3 model)"),i6e.forEach(t),Afo=i(Z),Mh=n(Z,"LI",{});var d6e=s(Mh);Pne=n(d6e,"STRONG",{});var mKr=s(Pne);yfo=r(mKr,"maskformer"),mKr.forEach(t),Lfo=r(d6e," \u2014 "),aI=n(d6e,"A",{href:!0});var gKr=s(aI);xfo=r(gKr,"MaskFormerFeatureExtractor"),gKr.forEach(t),$fo=r(d6e," (MaskFormer model)"),d6e.forEach(t),kfo=i(Z),Eh=n(Z,"LI",{});var c6e=s(Eh);Bne=n(c6e,"STRONG",{});var hKr=s(Bne);Sfo=r(hKr,"perceiver"),hKr.forEach(t),Rfo=r(c6e," \u2014 "),nI=n(c6e,"A",{href:!0});var pKr=s(nI);Pfo=r(pKr,"PerceiverFeatureExtractor"),pKr.forEach(t),Bfo=r(c6e," (Perceiver model)"),c6e.forEach(t),Ifo=i(Z),Ch=n(Z,"LI",{});var f6e=s(Ch);Ine=n(f6e,"STRONG",{});var uKr=s(Ine);qfo=r(uKr,"poolformer"),uKr.forEach(t),Nfo=r(f6e," \u2014 "),sI=n(f6e,"A",{href:!0});var _Kr=s(sI);jfo=r(_Kr,"PoolFormerFeatureExtractor"),_Kr.forEach(t),Dfo=r(f6e," (PoolFormer model)"),f6e.forEach(t),Gfo=i(Z),wh=n(Z,"LI",{});var m6e=s(wh);qne=n(m6e,"STRONG",{});var bKr=s(qne);Ofo=r(bKr,"regnet"),bKr.forEach(t),Vfo=r(m6e," \u2014 "),lI=n(m6e,"A",{href:!0});var vKr=s(lI);Xfo=r(vKr,"ConvNextFeatureExtractor"),vKr.forEach(t),zfo=r(m6e," (RegNet model)"),m6e.forEach(t),Wfo=i(Z),Ah=n(Z,"LI",{});var g6e=s(Ah);Nne=n(g6e,"STRONG",{});var FKr=s(Nne);Qfo=r(FKr,"resnet"),FKr.forEach(t),Hfo=r(g6e," \u2014 "),iI=n(g6e,"A",{href:!0});var TKr=s(iI);Ufo=r(TKr,"ConvNextFeatureExtractor"),TKr.forEach(t),Jfo=r(g6e," (ResNet model)"),g6e.forEach(t),Yfo=i(Z),yh=n(Z,"LI",{});var h6e=s(yh);jne=n(h6e,"STRONG",{});var MKr=s(jne);Kfo=r(MKr,"segformer"),MKr.forEach(t),Zfo=r(h6e," \u2014 "),dI=n(h6e,"A",{href:!0});var EKr=s(dI);emo=r(EKr,"SegformerFeatureExtractor"),EKr.forEach(t),omo=r(h6e," (SegFormer model)"),h6e.forEach(t),rmo=i(Z),Lh=n(Z,"LI",{});var p6e=s(Lh);Dne=n(p6e,"STRONG",{});var CKr=s(Dne);tmo=r(CKr,"speech_to_text"),CKr.forEach(t),amo=r(p6e," \u2014 "),cI=n(p6e,"A",{href:!0});var wKr=s(cI);nmo=r(wKr,"Speech2TextFeatureExtractor"),wKr.forEach(t),smo=r(p6e," (Speech2Text model)"),p6e.forEach(t),lmo=i(Z),xh=n(Z,"LI",{});var u6e=s(xh);Gne=n(u6e,"STRONG",{});var AKr=s(Gne);imo=r(AKr,"swin"),AKr.forEach(t),dmo=r(u6e," \u2014 "),fI=n(u6e,"A",{href:!0});var yKr=s(fI);cmo=r(yKr,"ViTFeatureExtractor"),yKr.forEach(t),fmo=r(u6e," (Swin model)"),u6e.forEach(t),mmo=i(Z),$h=n(Z,"LI",{});var _6e=s($h);One=n(_6e,"STRONG",{});var LKr=s(One);gmo=r(LKr,"van"),LKr.forEach(t),hmo=r(_6e," \u2014 "),mI=n(_6e,"A",{href:!0});var xKr=s(mI);pmo=r(xKr,"ConvNextFeatureExtractor"),xKr.forEach(t),umo=r(_6e," (VAN model)"),_6e.forEach(t),_mo=i(Z),kh=n(Z,"LI",{});var b6e=s(kh);Vne=n(b6e,"STRONG",{});var $Kr=s(Vne);bmo=r($Kr,"vit"),$Kr.forEach(t),vmo=r(b6e," \u2014 "),gI=n(b6e,"A",{href:!0});var kKr=s(gI);Fmo=r(kKr,"ViTFeatureExtractor"),kKr.forEach(t),Tmo=r(b6e," (ViT model)"),b6e.forEach(t),Mmo=i(Z),Sh=n(Z,"LI",{});var v6e=s(Sh);Xne=n(v6e,"STRONG",{});var SKr=s(Xne);Emo=r(SKr,"vit_mae"),SKr.forEach(t),Cmo=r(v6e," \u2014 "),hI=n(v6e,"A",{href:!0});var RKr=s(hI);wmo=r(RKr,"ViTFeatureExtractor"),RKr.forEach(t),Amo=r(v6e," (ViTMAE model)"),v6e.forEach(t),ymo=i(Z),Rh=n(Z,"LI",{});var F6e=s(Rh);zne=n(F6e,"STRONG",{});var PKr=s(zne);Lmo=r(PKr,"wav2vec2"),PKr.forEach(t),xmo=r(F6e," \u2014 "),pI=n(F6e,"A",{href:!0});var BKr=s(pI);$mo=r(BKr,"Wav2Vec2FeatureExtractor"),BKr.forEach(t),kmo=r(F6e," (Wav2Vec2 model)"),F6e.forEach(t),Smo=i(Z),Ph=n(Z,"LI",{});var T6e=s(Ph);Wne=n(T6e,"STRONG",{});var IKr=s(Wne);Rmo=r(IKr,"wav2vec2-conformer"),IKr.forEach(t),Pmo=r(T6e," \u2014 "),uI=n(T6e,"A",{href:!0});var qKr=s(uI);Bmo=r(qKr,"Wav2Vec2FeatureExtractor"),qKr.forEach(t),Imo=r(T6e," (Wav2Vec2-Conformer model)"),T6e.forEach(t),qmo=i(Z),Bh=n(Z,"LI",{});var M6e=s(Bh);Qne=n(M6e,"STRONG",{});var NKr=s(Qne);Nmo=r(NKr,"yolos"),NKr.forEach(t),jmo=r(M6e," \u2014 "),_I=n(M6e,"A",{href:!0});var jKr=s(_I);Dmo=r(jKr,"YolosFeatureExtractor"),jKr.forEach(t),Gmo=r(M6e," (YOLOS model)"),M6e.forEach(t),Z.forEach(t),Omo=i(Zt),T(Ih.$$.fragment,Zt),Vmo=i(Zt),T(qh.$$.fragment,Zt),Zt.forEach(t),Xmo=i(Os),Nh=n(Os,"DIV",{class:!0});var gDe=s(Nh);T(WA.$$.fragment,gDe),zmo=i(gDe),Hne=n(gDe,"P",{});var DKr=s(Hne);Wmo=r(DKr,"Register a new feature extractor for this class."),DKr.forEach(t),gDe.forEach(t),Os.forEach(t),mNe=i(f),Ai=n(f,"H2",{class:!0});var hDe=s(Ai);jh=n(hDe,"A",{id:!0,class:!0,href:!0});var GKr=s(jh);Une=n(GKr,"SPAN",{});var OKr=s(Une);T(QA.$$.fragment,OKr),OKr.forEach(t),GKr.forEach(t),Qmo=i(hDe),Jne=n(hDe,"SPAN",{});var VKr=s(Jne);Hmo=r(VKr,"AutoProcessor"),VKr.forEach(t),hDe.forEach(t),gNe=i(f),yo=n(f,"DIV",{class:!0});var Vs=s(yo);T(HA.$$.fragment,Vs),Umo=i(Vs),UA=n(Vs,"P",{});var pDe=s(UA);Jmo=r(pDe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),bI=n(pDe,"A",{href:!0});var XKr=s(bI);Ymo=r(XKr,"AutoProcessor.from_pretrained()"),XKr.forEach(t),Kmo=r(pDe," class method."),pDe.forEach(t),Zmo=i(Vs),JA=n(Vs,"P",{});var uDe=s(JA);ego=r(uDe,"This class cannot be instantiated directly using "),Yne=n(uDe,"CODE",{});var zKr=s(Yne);ogo=r(zKr,"__init__()"),zKr.forEach(t),rgo=r(uDe," (throws an error)."),uDe.forEach(t),tgo=i(Vs),Ue=n(Vs,"DIV",{class:!0});var ea=s(Ue);T(YA.$$.fragment,ea),ago=i(ea),Kne=n(ea,"P",{});var WKr=s(Kne);ngo=r(WKr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),WKr.forEach(t),sgo=i(ea),yi=n(ea,"P",{});var FZ=s(yi);lgo=r(FZ,"The processor class to instantiate is selected based on the "),Zne=n(FZ,"CODE",{});var QKr=s(Zne);igo=r(QKr,"model_type"),QKr.forEach(t),dgo=r(FZ,` property of the config object (either
passed as an argument or loaded from `),ese=n(FZ,"CODE",{});var HKr=s(ese);cgo=r(HKr,"pretrained_model_name_or_path"),HKr.forEach(t),fgo=r(FZ," if possible):"),FZ.forEach(t),mgo=i(ea),he=n(ea,"UL",{});var _e=s(he);Dh=n(_e,"LI",{});var E6e=s(Dh);ose=n(E6e,"STRONG",{});var UKr=s(ose);ggo=r(UKr,"clip"),UKr.forEach(t),hgo=r(E6e," \u2014 "),vI=n(E6e,"A",{href:!0});var JKr=s(vI);pgo=r(JKr,"CLIPProcessor"),JKr.forEach(t),ugo=r(E6e," (CLIP model)"),E6e.forEach(t),_go=i(_e),Gh=n(_e,"LI",{});var C6e=s(Gh);rse=n(C6e,"STRONG",{});var YKr=s(rse);bgo=r(YKr,"flava"),YKr.forEach(t),vgo=r(C6e," \u2014 "),tse=n(C6e,"CODE",{});var KKr=s(tse);Fgo=r(KKr,"FLAVAProcessor"),KKr.forEach(t),Tgo=r(C6e," (Flava model)"),C6e.forEach(t),Mgo=i(_e),Oh=n(_e,"LI",{});var w6e=s(Oh);ase=n(w6e,"STRONG",{});var ZKr=s(ase);Ego=r(ZKr,"layoutlmv2"),ZKr.forEach(t),Cgo=r(w6e," \u2014 "),FI=n(w6e,"A",{href:!0});var eZr=s(FI);wgo=r(eZr,"LayoutLMv2Processor"),eZr.forEach(t),Ago=r(w6e," (LayoutLMv2 model)"),w6e.forEach(t),ygo=i(_e),Vh=n(_e,"LI",{});var A6e=s(Vh);nse=n(A6e,"STRONG",{});var oZr=s(nse);Lgo=r(oZr,"layoutlmv3"),oZr.forEach(t),xgo=r(A6e," \u2014 "),TI=n(A6e,"A",{href:!0});var rZr=s(TI);$go=r(rZr,"LayoutLMv3Processor"),rZr.forEach(t),kgo=r(A6e," (LayoutLMv3 model)"),A6e.forEach(t),Sgo=i(_e),Xh=n(_e,"LI",{});var y6e=s(Xh);sse=n(y6e,"STRONG",{});var tZr=s(sse);Rgo=r(tZr,"layoutxlm"),tZr.forEach(t),Pgo=r(y6e," \u2014 "),MI=n(y6e,"A",{href:!0});var aZr=s(MI);Bgo=r(aZr,"LayoutXLMProcessor"),aZr.forEach(t),Igo=r(y6e," (LayoutXLM model)"),y6e.forEach(t),qgo=i(_e),zh=n(_e,"LI",{});var L6e=s(zh);lse=n(L6e,"STRONG",{});var nZr=s(lse);Ngo=r(nZr,"sew"),nZr.forEach(t),jgo=r(L6e," \u2014 "),EI=n(L6e,"A",{href:!0});var sZr=s(EI);Dgo=r(sZr,"Wav2Vec2Processor"),sZr.forEach(t),Ggo=r(L6e," (SEW model)"),L6e.forEach(t),Ogo=i(_e),Wh=n(_e,"LI",{});var x6e=s(Wh);ise=n(x6e,"STRONG",{});var lZr=s(ise);Vgo=r(lZr,"sew-d"),lZr.forEach(t),Xgo=r(x6e," \u2014 "),CI=n(x6e,"A",{href:!0});var iZr=s(CI);zgo=r(iZr,"Wav2Vec2Processor"),iZr.forEach(t),Wgo=r(x6e," (SEW-D model)"),x6e.forEach(t),Qgo=i(_e),Qh=n(_e,"LI",{});var $6e=s(Qh);dse=n($6e,"STRONG",{});var dZr=s(dse);Hgo=r(dZr,"speech_to_text"),dZr.forEach(t),Ugo=r($6e," \u2014 "),wI=n($6e,"A",{href:!0});var cZr=s(wI);Jgo=r(cZr,"Speech2TextProcessor"),cZr.forEach(t),Ygo=r($6e," (Speech2Text model)"),$6e.forEach(t),Kgo=i(_e),Hh=n(_e,"LI",{});var k6e=s(Hh);cse=n(k6e,"STRONG",{});var fZr=s(cse);Zgo=r(fZr,"speech_to_text_2"),fZr.forEach(t),eho=r(k6e," \u2014 "),AI=n(k6e,"A",{href:!0});var mZr=s(AI);oho=r(mZr,"Speech2Text2Processor"),mZr.forEach(t),rho=r(k6e," (Speech2Text2 model)"),k6e.forEach(t),tho=i(_e),Uh=n(_e,"LI",{});var S6e=s(Uh);fse=n(S6e,"STRONG",{});var gZr=s(fse);aho=r(gZr,"trocr"),gZr.forEach(t),nho=r(S6e," \u2014 "),yI=n(S6e,"A",{href:!0});var hZr=s(yI);sho=r(hZr,"TrOCRProcessor"),hZr.forEach(t),lho=r(S6e," (TrOCR model)"),S6e.forEach(t),iho=i(_e),Jh=n(_e,"LI",{});var R6e=s(Jh);mse=n(R6e,"STRONG",{});var pZr=s(mse);dho=r(pZr,"unispeech"),pZr.forEach(t),cho=r(R6e," \u2014 "),LI=n(R6e,"A",{href:!0});var uZr=s(LI);fho=r(uZr,"Wav2Vec2Processor"),uZr.forEach(t),mho=r(R6e," (UniSpeech model)"),R6e.forEach(t),gho=i(_e),Yh=n(_e,"LI",{});var P6e=s(Yh);gse=n(P6e,"STRONG",{});var _Zr=s(gse);hho=r(_Zr,"unispeech-sat"),_Zr.forEach(t),pho=r(P6e," \u2014 "),xI=n(P6e,"A",{href:!0});var bZr=s(xI);uho=r(bZr,"Wav2Vec2Processor"),bZr.forEach(t),_ho=r(P6e," (UniSpeechSat model)"),P6e.forEach(t),bho=i(_e),Kh=n(_e,"LI",{});var B6e=s(Kh);hse=n(B6e,"STRONG",{});var vZr=s(hse);vho=r(vZr,"vilt"),vZr.forEach(t),Fho=r(B6e," \u2014 "),$I=n(B6e,"A",{href:!0});var FZr=s($I);Tho=r(FZr,"ViltProcessor"),FZr.forEach(t),Mho=r(B6e," (ViLT model)"),B6e.forEach(t),Eho=i(_e),Zh=n(_e,"LI",{});var I6e=s(Zh);pse=n(I6e,"STRONG",{});var TZr=s(pse);Cho=r(TZr,"vision-text-dual-encoder"),TZr.forEach(t),who=r(I6e," \u2014 "),kI=n(I6e,"A",{href:!0});var MZr=s(kI);Aho=r(MZr,"VisionTextDualEncoderProcessor"),MZr.forEach(t),yho=r(I6e," (VisionTextDualEncoder model)"),I6e.forEach(t),Lho=i(_e),ep=n(_e,"LI",{});var q6e=s(ep);use=n(q6e,"STRONG",{});var EZr=s(use);xho=r(EZr,"wav2vec2"),EZr.forEach(t),$ho=r(q6e," \u2014 "),SI=n(q6e,"A",{href:!0});var CZr=s(SI);kho=r(CZr,"Wav2Vec2Processor"),CZr.forEach(t),Sho=r(q6e," (Wav2Vec2 model)"),q6e.forEach(t),Rho=i(_e),op=n(_e,"LI",{});var N6e=s(op);_se=n(N6e,"STRONG",{});var wZr=s(_se);Pho=r(wZr,"wav2vec2-conformer"),wZr.forEach(t),Bho=r(N6e," \u2014 "),RI=n(N6e,"A",{href:!0});var AZr=s(RI);Iho=r(AZr,"Wav2Vec2Processor"),AZr.forEach(t),qho=r(N6e," (Wav2Vec2-Conformer model)"),N6e.forEach(t),Nho=i(_e),rp=n(_e,"LI",{});var j6e=s(rp);bse=n(j6e,"STRONG",{});var yZr=s(bse);jho=r(yZr,"wavlm"),yZr.forEach(t),Dho=r(j6e," \u2014 "),PI=n(j6e,"A",{href:!0});var LZr=s(PI);Gho=r(LZr,"Wav2Vec2Processor"),LZr.forEach(t),Oho=r(j6e," (WavLM model)"),j6e.forEach(t),_e.forEach(t),Vho=i(ea),T(tp.$$.fragment,ea),Xho=i(ea),T(ap.$$.fragment,ea),ea.forEach(t),zho=i(Vs),np=n(Vs,"DIV",{class:!0});var _De=s(np);T(KA.$$.fragment,_De),Who=i(_De),vse=n(_De,"P",{});var xZr=s(vse);Qho=r(xZr,"Register a new processor for this class."),xZr.forEach(t),_De.forEach(t),Vs.forEach(t),hNe=i(f),Li=n(f,"H2",{class:!0});var bDe=s(Li);sp=n(bDe,"A",{id:!0,class:!0,href:!0});var $Zr=s(sp);Fse=n($Zr,"SPAN",{});var kZr=s(Fse);T(ZA.$$.fragment,kZr),kZr.forEach(t),$Zr.forEach(t),Hho=i(bDe),Tse=n(bDe,"SPAN",{});var SZr=s(Tse);Uho=r(SZr,"AutoModel"),SZr.forEach(t),bDe.forEach(t),pNe=i(f),Lo=n(f,"DIV",{class:!0});var Xs=s(Lo);T(ey.$$.fragment,Xs),Jho=i(Xs),xi=n(Xs,"P",{});var TZ=s(xi);Yho=r(TZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),BI=n(TZ,"A",{href:!0});var RZr=s(BI);Kho=r(RZr,"from_pretrained()"),RZr.forEach(t),Zho=r(TZ," class method or the "),II=n(TZ,"A",{href:!0});var PZr=s(II);epo=r(PZr,"from_config()"),PZr.forEach(t),opo=r(TZ,` class
method.`),TZ.forEach(t),rpo=i(Xs),oy=n(Xs,"P",{});var vDe=s(oy);tpo=r(vDe,"This class cannot be instantiated directly using "),Mse=n(vDe,"CODE",{});var BZr=s(Mse);apo=r(BZr,"__init__()"),BZr.forEach(t),npo=r(vDe," (throws an error)."),vDe.forEach(t),spo=i(Xs),tt=n(Xs,"DIV",{class:!0});var k0=s(tt);T(ry.$$.fragment,k0),lpo=i(k0),Ese=n(k0,"P",{});var IZr=s(Ese);ipo=r(IZr,"Instantiates one of the base model classes of the library from a configuration."),IZr.forEach(t),dpo=i(k0),$i=n(k0,"P",{});var MZ=s($i);cpo=r(MZ,`Note:
Loading a model from its configuration file does `),Cse=n(MZ,"STRONG",{});var qZr=s(Cse);fpo=r(qZr,"not"),qZr.forEach(t),mpo=r(MZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),qI=n(MZ,"A",{href:!0});var NZr=s(qI);gpo=r(NZr,"from_pretrained()"),NZr.forEach(t),hpo=r(MZ," to load the model weights."),MZ.forEach(t),ppo=i(k0),T(lp.$$.fragment,k0),k0.forEach(t),upo=i(Xs),Je=n(Xs,"DIV",{class:!0});var oa=s(Je);T(ty.$$.fragment,oa),_po=i(oa),wse=n(oa,"P",{});var jZr=s(wse);bpo=r(jZr,"Instantiate one of the base model classes of the library from a pretrained model."),jZr.forEach(t),vpo=i(oa),La=n(oa,"P",{});var S0=s(La);Fpo=r(S0,"The model class to instantiate is selected based on the "),Ase=n(S0,"CODE",{});var DZr=s(Ase);Tpo=r(DZr,"model_type"),DZr.forEach(t),Mpo=r(S0,` property of the config object (either
passed as an argument or loaded from `),yse=n(S0,"CODE",{});var GZr=s(yse);Epo=r(GZr,"pretrained_model_name_or_path"),GZr.forEach(t),Cpo=r(S0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lse=n(S0,"CODE",{});var OZr=s(Lse);wpo=r(OZr,"pretrained_model_name_or_path"),OZr.forEach(t),Apo=r(S0,":"),S0.forEach(t),ypo=i(oa),x=n(oa,"UL",{});var $=s(x);ip=n($,"LI",{});var D6e=s(ip);xse=n(D6e,"STRONG",{});var VZr=s(xse);Lpo=r(VZr,"albert"),VZr.forEach(t),xpo=r(D6e," \u2014 "),NI=n(D6e,"A",{href:!0});var XZr=s(NI);$po=r(XZr,"AlbertModel"),XZr.forEach(t),kpo=r(D6e," (ALBERT model)"),D6e.forEach(t),Spo=i($),dp=n($,"LI",{});var G6e=s(dp);$se=n(G6e,"STRONG",{});var zZr=s($se);Rpo=r(zZr,"bart"),zZr.forEach(t),Ppo=r(G6e," \u2014 "),jI=n(G6e,"A",{href:!0});var WZr=s(jI);Bpo=r(WZr,"BartModel"),WZr.forEach(t),Ipo=r(G6e," (BART model)"),G6e.forEach(t),qpo=i($),cp=n($,"LI",{});var O6e=s(cp);kse=n(O6e,"STRONG",{});var QZr=s(kse);Npo=r(QZr,"beit"),QZr.forEach(t),jpo=r(O6e," \u2014 "),DI=n(O6e,"A",{href:!0});var HZr=s(DI);Dpo=r(HZr,"BeitModel"),HZr.forEach(t),Gpo=r(O6e," (BEiT model)"),O6e.forEach(t),Opo=i($),fp=n($,"LI",{});var V6e=s(fp);Sse=n(V6e,"STRONG",{});var UZr=s(Sse);Vpo=r(UZr,"bert"),UZr.forEach(t),Xpo=r(V6e," \u2014 "),GI=n(V6e,"A",{href:!0});var JZr=s(GI);zpo=r(JZr,"BertModel"),JZr.forEach(t),Wpo=r(V6e," (BERT model)"),V6e.forEach(t),Qpo=i($),mp=n($,"LI",{});var X6e=s(mp);Rse=n(X6e,"STRONG",{});var YZr=s(Rse);Hpo=r(YZr,"bert-generation"),YZr.forEach(t),Upo=r(X6e," \u2014 "),OI=n(X6e,"A",{href:!0});var KZr=s(OI);Jpo=r(KZr,"BertGenerationEncoder"),KZr.forEach(t),Ypo=r(X6e," (Bert Generation model)"),X6e.forEach(t),Kpo=i($),gp=n($,"LI",{});var z6e=s(gp);Pse=n(z6e,"STRONG",{});var ZZr=s(Pse);Zpo=r(ZZr,"big_bird"),ZZr.forEach(t),euo=r(z6e," \u2014 "),VI=n(z6e,"A",{href:!0});var eet=s(VI);ouo=r(eet,"BigBirdModel"),eet.forEach(t),ruo=r(z6e," (BigBird model)"),z6e.forEach(t),tuo=i($),hp=n($,"LI",{});var W6e=s(hp);Bse=n(W6e,"STRONG",{});var oet=s(Bse);auo=r(oet,"bigbird_pegasus"),oet.forEach(t),nuo=r(W6e," \u2014 "),XI=n(W6e,"A",{href:!0});var ret=s(XI);suo=r(ret,"BigBirdPegasusModel"),ret.forEach(t),luo=r(W6e," (BigBirdPegasus model)"),W6e.forEach(t),iuo=i($),pp=n($,"LI",{});var Q6e=s(pp);Ise=n(Q6e,"STRONG",{});var tet=s(Ise);duo=r(tet,"blenderbot"),tet.forEach(t),cuo=r(Q6e," \u2014 "),zI=n(Q6e,"A",{href:!0});var aet=s(zI);fuo=r(aet,"BlenderbotModel"),aet.forEach(t),muo=r(Q6e," (Blenderbot model)"),Q6e.forEach(t),guo=i($),up=n($,"LI",{});var H6e=s(up);qse=n(H6e,"STRONG",{});var net=s(qse);huo=r(net,"blenderbot-small"),net.forEach(t),puo=r(H6e," \u2014 "),WI=n(H6e,"A",{href:!0});var set=s(WI);uuo=r(set,"BlenderbotSmallModel"),set.forEach(t),_uo=r(H6e," (BlenderbotSmall model)"),H6e.forEach(t),buo=i($),_p=n($,"LI",{});var U6e=s(_p);Nse=n(U6e,"STRONG",{});var iet=s(Nse);vuo=r(iet,"camembert"),iet.forEach(t),Fuo=r(U6e," \u2014 "),QI=n(U6e,"A",{href:!0});var det=s(QI);Tuo=r(det,"CamembertModel"),det.forEach(t),Muo=r(U6e," (CamemBERT model)"),U6e.forEach(t),Euo=i($),bp=n($,"LI",{});var J6e=s(bp);jse=n(J6e,"STRONG",{});var cet=s(jse);Cuo=r(cet,"canine"),cet.forEach(t),wuo=r(J6e," \u2014 "),HI=n(J6e,"A",{href:!0});var fet=s(HI);Auo=r(fet,"CanineModel"),fet.forEach(t),yuo=r(J6e," (Canine model)"),J6e.forEach(t),Luo=i($),vp=n($,"LI",{});var Y6e=s(vp);Dse=n(Y6e,"STRONG",{});var met=s(Dse);xuo=r(met,"clip"),met.forEach(t),$uo=r(Y6e," \u2014 "),UI=n(Y6e,"A",{href:!0});var get=s(UI);kuo=r(get,"CLIPModel"),get.forEach(t),Suo=r(Y6e," (CLIP model)"),Y6e.forEach(t),Ruo=i($),Fp=n($,"LI",{});var K6e=s(Fp);Gse=n(K6e,"STRONG",{});var het=s(Gse);Puo=r(het,"convbert"),het.forEach(t),Buo=r(K6e," \u2014 "),JI=n(K6e,"A",{href:!0});var pet=s(JI);Iuo=r(pet,"ConvBertModel"),pet.forEach(t),quo=r(K6e," (ConvBERT model)"),K6e.forEach(t),Nuo=i($),Tp=n($,"LI",{});var Z6e=s(Tp);Ose=n(Z6e,"STRONG",{});var uet=s(Ose);juo=r(uet,"convnext"),uet.forEach(t),Duo=r(Z6e," \u2014 "),YI=n(Z6e,"A",{href:!0});var _et=s(YI);Guo=r(_et,"ConvNextModel"),_et.forEach(t),Ouo=r(Z6e," (ConvNext model)"),Z6e.forEach(t),Vuo=i($),Mp=n($,"LI",{});var eAe=s(Mp);Vse=n(eAe,"STRONG",{});var bet=s(Vse);Xuo=r(bet,"ctrl"),bet.forEach(t),zuo=r(eAe," \u2014 "),KI=n(eAe,"A",{href:!0});var vet=s(KI);Wuo=r(vet,"CTRLModel"),vet.forEach(t),Quo=r(eAe," (CTRL model)"),eAe.forEach(t),Huo=i($),Ep=n($,"LI",{});var oAe=s(Ep);Xse=n(oAe,"STRONG",{});var Fet=s(Xse);Uuo=r(Fet,"cvt"),Fet.forEach(t),Juo=r(oAe," \u2014 "),ZI=n(oAe,"A",{href:!0});var Tet=s(ZI);Yuo=r(Tet,"CvtModel"),Tet.forEach(t),Kuo=r(oAe," (CvT model)"),oAe.forEach(t),Zuo=i($),Cp=n($,"LI",{});var rAe=s(Cp);zse=n(rAe,"STRONG",{});var Met=s(zse);e_o=r(Met,"data2vec-audio"),Met.forEach(t),o_o=r(rAe," \u2014 "),eq=n(rAe,"A",{href:!0});var Eet=s(eq);r_o=r(Eet,"Data2VecAudioModel"),Eet.forEach(t),t_o=r(rAe," (Data2VecAudio model)"),rAe.forEach(t),a_o=i($),wp=n($,"LI",{});var tAe=s(wp);Wse=n(tAe,"STRONG",{});var Cet=s(Wse);n_o=r(Cet,"data2vec-text"),Cet.forEach(t),s_o=r(tAe," \u2014 "),oq=n(tAe,"A",{href:!0});var wet=s(oq);l_o=r(wet,"Data2VecTextModel"),wet.forEach(t),i_o=r(tAe," (Data2VecText model)"),tAe.forEach(t),d_o=i($),Ap=n($,"LI",{});var aAe=s(Ap);Qse=n(aAe,"STRONG",{});var Aet=s(Qse);c_o=r(Aet,"data2vec-vision"),Aet.forEach(t),f_o=r(aAe," \u2014 "),rq=n(aAe,"A",{href:!0});var yet=s(rq);m_o=r(yet,"Data2VecVisionModel"),yet.forEach(t),g_o=r(aAe," (Data2VecVision model)"),aAe.forEach(t),h_o=i($),yp=n($,"LI",{});var nAe=s(yp);Hse=n(nAe,"STRONG",{});var Let=s(Hse);p_o=r(Let,"deberta"),Let.forEach(t),u_o=r(nAe," \u2014 "),tq=n(nAe,"A",{href:!0});var xet=s(tq);__o=r(xet,"DebertaModel"),xet.forEach(t),b_o=r(nAe," (DeBERTa model)"),nAe.forEach(t),v_o=i($),Lp=n($,"LI",{});var sAe=s(Lp);Use=n(sAe,"STRONG",{});var $et=s(Use);F_o=r($et,"deberta-v2"),$et.forEach(t),T_o=r(sAe," \u2014 "),aq=n(sAe,"A",{href:!0});var ket=s(aq);M_o=r(ket,"DebertaV2Model"),ket.forEach(t),E_o=r(sAe," (DeBERTa-v2 model)"),sAe.forEach(t),C_o=i($),xp=n($,"LI",{});var lAe=s(xp);Jse=n(lAe,"STRONG",{});var Set=s(Jse);w_o=r(Set,"decision_transformer"),Set.forEach(t),A_o=r(lAe," \u2014 "),nq=n(lAe,"A",{href:!0});var Ret=s(nq);y_o=r(Ret,"DecisionTransformerModel"),Ret.forEach(t),L_o=r(lAe," (Decision Transformer model)"),lAe.forEach(t),x_o=i($),$p=n($,"LI",{});var iAe=s($p);Yse=n(iAe,"STRONG",{});var Pet=s(Yse);$_o=r(Pet,"deit"),Pet.forEach(t),k_o=r(iAe," \u2014 "),sq=n(iAe,"A",{href:!0});var Bet=s(sq);S_o=r(Bet,"DeiTModel"),Bet.forEach(t),R_o=r(iAe," (DeiT model)"),iAe.forEach(t),P_o=i($),kp=n($,"LI",{});var dAe=s(kp);Kse=n(dAe,"STRONG",{});var Iet=s(Kse);B_o=r(Iet,"detr"),Iet.forEach(t),I_o=r(dAe," \u2014 "),lq=n(dAe,"A",{href:!0});var qet=s(lq);q_o=r(qet,"DetrModel"),qet.forEach(t),N_o=r(dAe," (DETR model)"),dAe.forEach(t),j_o=i($),Sp=n($,"LI",{});var cAe=s(Sp);Zse=n(cAe,"STRONG",{});var Net=s(Zse);D_o=r(Net,"distilbert"),Net.forEach(t),G_o=r(cAe," \u2014 "),iq=n(cAe,"A",{href:!0});var jet=s(iq);O_o=r(jet,"DistilBertModel"),jet.forEach(t),V_o=r(cAe," (DistilBERT model)"),cAe.forEach(t),X_o=i($),Rp=n($,"LI",{});var fAe=s(Rp);ele=n(fAe,"STRONG",{});var Det=s(ele);z_o=r(Det,"dpr"),Det.forEach(t),W_o=r(fAe," \u2014 "),dq=n(fAe,"A",{href:!0});var Get=s(dq);Q_o=r(Get,"DPRQuestionEncoder"),Get.forEach(t),H_o=r(fAe," (DPR model)"),fAe.forEach(t),U_o=i($),Pp=n($,"LI",{});var mAe=s(Pp);ole=n(mAe,"STRONG",{});var Oet=s(ole);J_o=r(Oet,"dpt"),Oet.forEach(t),Y_o=r(mAe," \u2014 "),cq=n(mAe,"A",{href:!0});var Vet=s(cq);K_o=r(Vet,"DPTModel"),Vet.forEach(t),Z_o=r(mAe," (DPT model)"),mAe.forEach(t),e2o=i($),Bp=n($,"LI",{});var gAe=s(Bp);rle=n(gAe,"STRONG",{});var Xet=s(rle);o2o=r(Xet,"electra"),Xet.forEach(t),r2o=r(gAe," \u2014 "),fq=n(gAe,"A",{href:!0});var zet=s(fq);t2o=r(zet,"ElectraModel"),zet.forEach(t),a2o=r(gAe," (ELECTRA model)"),gAe.forEach(t),n2o=i($),Ip=n($,"LI",{});var hAe=s(Ip);tle=n(hAe,"STRONG",{});var Wet=s(tle);s2o=r(Wet,"flaubert"),Wet.forEach(t),l2o=r(hAe," \u2014 "),mq=n(hAe,"A",{href:!0});var Qet=s(mq);i2o=r(Qet,"FlaubertModel"),Qet.forEach(t),d2o=r(hAe," (FlauBERT model)"),hAe.forEach(t),c2o=i($),qp=n($,"LI",{});var pAe=s(qp);ale=n(pAe,"STRONG",{});var Het=s(ale);f2o=r(Het,"flava"),Het.forEach(t),m2o=r(pAe," \u2014 "),gq=n(pAe,"A",{href:!0});var Uet=s(gq);g2o=r(Uet,"FlavaModel"),Uet.forEach(t),h2o=r(pAe," (Flava model)"),pAe.forEach(t),p2o=i($),Np=n($,"LI",{});var uAe=s(Np);nle=n(uAe,"STRONG",{});var Jet=s(nle);u2o=r(Jet,"fnet"),Jet.forEach(t),_2o=r(uAe," \u2014 "),hq=n(uAe,"A",{href:!0});var Yet=s(hq);b2o=r(Yet,"FNetModel"),Yet.forEach(t),v2o=r(uAe," (FNet model)"),uAe.forEach(t),F2o=i($),jp=n($,"LI",{});var _Ae=s(jp);sle=n(_Ae,"STRONG",{});var Ket=s(sle);T2o=r(Ket,"fsmt"),Ket.forEach(t),M2o=r(_Ae," \u2014 "),pq=n(_Ae,"A",{href:!0});var Zet=s(pq);E2o=r(Zet,"FSMTModel"),Zet.forEach(t),C2o=r(_Ae," (FairSeq Machine-Translation model)"),_Ae.forEach(t),w2o=i($),qs=n($,"LI",{});var z$=s(qs);lle=n(z$,"STRONG",{});var eot=s(lle);A2o=r(eot,"funnel"),eot.forEach(t),y2o=r(z$," \u2014 "),uq=n(z$,"A",{href:!0});var oot=s(uq);L2o=r(oot,"FunnelModel"),oot.forEach(t),x2o=r(z$," or "),_q=n(z$,"A",{href:!0});var rot=s(_q);$2o=r(rot,"FunnelBaseModel"),rot.forEach(t),k2o=r(z$," (Funnel Transformer model)"),z$.forEach(t),S2o=i($),Dp=n($,"LI",{});var bAe=s(Dp);ile=n(bAe,"STRONG",{});var tot=s(ile);R2o=r(tot,"glpn"),tot.forEach(t),P2o=r(bAe," \u2014 "),bq=n(bAe,"A",{href:!0});var aot=s(bq);B2o=r(aot,"GLPNModel"),aot.forEach(t),I2o=r(bAe," (GLPN model)"),bAe.forEach(t),q2o=i($),Gp=n($,"LI",{});var vAe=s(Gp);dle=n(vAe,"STRONG",{});var not=s(dle);N2o=r(not,"gpt2"),not.forEach(t),j2o=r(vAe," \u2014 "),vq=n(vAe,"A",{href:!0});var sot=s(vq);D2o=r(sot,"GPT2Model"),sot.forEach(t),G2o=r(vAe," (OpenAI GPT-2 model)"),vAe.forEach(t),O2o=i($),Op=n($,"LI",{});var FAe=s(Op);cle=n(FAe,"STRONG",{});var lot=s(cle);V2o=r(lot,"gpt_neo"),lot.forEach(t),X2o=r(FAe," \u2014 "),Fq=n(FAe,"A",{href:!0});var iot=s(Fq);z2o=r(iot,"GPTNeoModel"),iot.forEach(t),W2o=r(FAe," (GPT Neo model)"),FAe.forEach(t),Q2o=i($),Vp=n($,"LI",{});var TAe=s(Vp);fle=n(TAe,"STRONG",{});var dot=s(fle);H2o=r(dot,"gpt_neox"),dot.forEach(t),U2o=r(TAe," \u2014 "),Tq=n(TAe,"A",{href:!0});var cot=s(Tq);J2o=r(cot,"GPTNeoXModel"),cot.forEach(t),Y2o=r(TAe," (GPT NeoX model)"),TAe.forEach(t),K2o=i($),Xp=n($,"LI",{});var MAe=s(Xp);mle=n(MAe,"STRONG",{});var fot=s(mle);Z2o=r(fot,"gptj"),fot.forEach(t),e1o=r(MAe," \u2014 "),Mq=n(MAe,"A",{href:!0});var mot=s(Mq);o1o=r(mot,"GPTJModel"),mot.forEach(t),r1o=r(MAe," (GPT-J model)"),MAe.forEach(t),t1o=i($),zp=n($,"LI",{});var EAe=s(zp);gle=n(EAe,"STRONG",{});var got=s(gle);a1o=r(got,"hubert"),got.forEach(t),n1o=r(EAe," \u2014 "),Eq=n(EAe,"A",{href:!0});var hot=s(Eq);s1o=r(hot,"HubertModel"),hot.forEach(t),l1o=r(EAe," (Hubert model)"),EAe.forEach(t),i1o=i($),Wp=n($,"LI",{});var CAe=s(Wp);hle=n(CAe,"STRONG",{});var pot=s(hle);d1o=r(pot,"ibert"),pot.forEach(t),c1o=r(CAe," \u2014 "),Cq=n(CAe,"A",{href:!0});var uot=s(Cq);f1o=r(uot,"IBertModel"),uot.forEach(t),m1o=r(CAe," (I-BERT model)"),CAe.forEach(t),g1o=i($),Qp=n($,"LI",{});var wAe=s(Qp);ple=n(wAe,"STRONG",{});var _ot=s(ple);h1o=r(_ot,"imagegpt"),_ot.forEach(t),p1o=r(wAe," \u2014 "),wq=n(wAe,"A",{href:!0});var bot=s(wq);u1o=r(bot,"ImageGPTModel"),bot.forEach(t),_1o=r(wAe," (ImageGPT model)"),wAe.forEach(t),b1o=i($),Hp=n($,"LI",{});var AAe=s(Hp);ule=n(AAe,"STRONG",{});var vot=s(ule);v1o=r(vot,"layoutlm"),vot.forEach(t),F1o=r(AAe," \u2014 "),Aq=n(AAe,"A",{href:!0});var Fot=s(Aq);T1o=r(Fot,"LayoutLMModel"),Fot.forEach(t),M1o=r(AAe," (LayoutLM model)"),AAe.forEach(t),E1o=i($),Up=n($,"LI",{});var yAe=s(Up);_le=n(yAe,"STRONG",{});var Tot=s(_le);C1o=r(Tot,"layoutlmv2"),Tot.forEach(t),w1o=r(yAe," \u2014 "),yq=n(yAe,"A",{href:!0});var Mot=s(yq);A1o=r(Mot,"LayoutLMv2Model"),Mot.forEach(t),y1o=r(yAe," (LayoutLMv2 model)"),yAe.forEach(t),L1o=i($),Jp=n($,"LI",{});var LAe=s(Jp);ble=n(LAe,"STRONG",{});var Eot=s(ble);x1o=r(Eot,"layoutlmv3"),Eot.forEach(t),$1o=r(LAe," \u2014 "),Lq=n(LAe,"A",{href:!0});var Cot=s(Lq);k1o=r(Cot,"LayoutLMv3Model"),Cot.forEach(t),S1o=r(LAe," (LayoutLMv3 model)"),LAe.forEach(t),R1o=i($),Yp=n($,"LI",{});var xAe=s(Yp);vle=n(xAe,"STRONG",{});var wot=s(vle);P1o=r(wot,"led"),wot.forEach(t),B1o=r(xAe," \u2014 "),xq=n(xAe,"A",{href:!0});var Aot=s(xq);I1o=r(Aot,"LEDModel"),Aot.forEach(t),q1o=r(xAe," (LED model)"),xAe.forEach(t),N1o=i($),Kp=n($,"LI",{});var $Ae=s(Kp);Fle=n($Ae,"STRONG",{});var yot=s(Fle);j1o=r(yot,"longformer"),yot.forEach(t),D1o=r($Ae," \u2014 "),$q=n($Ae,"A",{href:!0});var Lot=s($q);G1o=r(Lot,"LongformerModel"),Lot.forEach(t),O1o=r($Ae," (Longformer model)"),$Ae.forEach(t),V1o=i($),Zp=n($,"LI",{});var kAe=s(Zp);Tle=n(kAe,"STRONG",{});var xot=s(Tle);X1o=r(xot,"luke"),xot.forEach(t),z1o=r(kAe," \u2014 "),kq=n(kAe,"A",{href:!0});var $ot=s(kq);W1o=r($ot,"LukeModel"),$ot.forEach(t),Q1o=r(kAe," (LUKE model)"),kAe.forEach(t),H1o=i($),eu=n($,"LI",{});var SAe=s(eu);Mle=n(SAe,"STRONG",{});var kot=s(Mle);U1o=r(kot,"lxmert"),kot.forEach(t),J1o=r(SAe," \u2014 "),Sq=n(SAe,"A",{href:!0});var Sot=s(Sq);Y1o=r(Sot,"LxmertModel"),Sot.forEach(t),K1o=r(SAe," (LXMERT model)"),SAe.forEach(t),Z1o=i($),ou=n($,"LI",{});var RAe=s(ou);Ele=n(RAe,"STRONG",{});var Rot=s(Ele);ebo=r(Rot,"m2m_100"),Rot.forEach(t),obo=r(RAe," \u2014 "),Rq=n(RAe,"A",{href:!0});var Pot=s(Rq);rbo=r(Pot,"M2M100Model"),Pot.forEach(t),tbo=r(RAe," (M2M100 model)"),RAe.forEach(t),abo=i($),ru=n($,"LI",{});var PAe=s(ru);Cle=n(PAe,"STRONG",{});var Bot=s(Cle);nbo=r(Bot,"marian"),Bot.forEach(t),sbo=r(PAe," \u2014 "),Pq=n(PAe,"A",{href:!0});var Iot=s(Pq);lbo=r(Iot,"MarianModel"),Iot.forEach(t),ibo=r(PAe," (Marian model)"),PAe.forEach(t),dbo=i($),tu=n($,"LI",{});var BAe=s(tu);wle=n(BAe,"STRONG",{});var qot=s(wle);cbo=r(qot,"maskformer"),qot.forEach(t),fbo=r(BAe," \u2014 "),Bq=n(BAe,"A",{href:!0});var Not=s(Bq);mbo=r(Not,"MaskFormerModel"),Not.forEach(t),gbo=r(BAe," (MaskFormer model)"),BAe.forEach(t),hbo=i($),au=n($,"LI",{});var IAe=s(au);Ale=n(IAe,"STRONG",{});var jot=s(Ale);pbo=r(jot,"mbart"),jot.forEach(t),ubo=r(IAe," \u2014 "),Iq=n(IAe,"A",{href:!0});var Dot=s(Iq);_bo=r(Dot,"MBartModel"),Dot.forEach(t),bbo=r(IAe," (mBART model)"),IAe.forEach(t),vbo=i($),nu=n($,"LI",{});var qAe=s(nu);yle=n(qAe,"STRONG",{});var Got=s(yle);Fbo=r(Got,"megatron-bert"),Got.forEach(t),Tbo=r(qAe," \u2014 "),qq=n(qAe,"A",{href:!0});var Oot=s(qq);Mbo=r(Oot,"MegatronBertModel"),Oot.forEach(t),Ebo=r(qAe," (MegatronBert model)"),qAe.forEach(t),Cbo=i($),su=n($,"LI",{});var NAe=s(su);Lle=n(NAe,"STRONG",{});var Vot=s(Lle);wbo=r(Vot,"mobilebert"),Vot.forEach(t),Abo=r(NAe," \u2014 "),Nq=n(NAe,"A",{href:!0});var Xot=s(Nq);ybo=r(Xot,"MobileBertModel"),Xot.forEach(t),Lbo=r(NAe," (MobileBERT model)"),NAe.forEach(t),xbo=i($),lu=n($,"LI",{});var jAe=s(lu);xle=n(jAe,"STRONG",{});var zot=s(xle);$bo=r(zot,"mpnet"),zot.forEach(t),kbo=r(jAe," \u2014 "),jq=n(jAe,"A",{href:!0});var Wot=s(jq);Sbo=r(Wot,"MPNetModel"),Wot.forEach(t),Rbo=r(jAe," (MPNet model)"),jAe.forEach(t),Pbo=i($),iu=n($,"LI",{});var DAe=s(iu);$le=n(DAe,"STRONG",{});var Qot=s($le);Bbo=r(Qot,"mt5"),Qot.forEach(t),Ibo=r(DAe," \u2014 "),Dq=n(DAe,"A",{href:!0});var Hot=s(Dq);qbo=r(Hot,"MT5Model"),Hot.forEach(t),Nbo=r(DAe," (mT5 model)"),DAe.forEach(t),jbo=i($),du=n($,"LI",{});var GAe=s(du);kle=n(GAe,"STRONG",{});var Uot=s(kle);Dbo=r(Uot,"nystromformer"),Uot.forEach(t),Gbo=r(GAe," \u2014 "),Gq=n(GAe,"A",{href:!0});var Jot=s(Gq);Obo=r(Jot,"NystromformerModel"),Jot.forEach(t),Vbo=r(GAe," (Nystromformer model)"),GAe.forEach(t),Xbo=i($),cu=n($,"LI",{});var OAe=s(cu);Sle=n(OAe,"STRONG",{});var Yot=s(Sle);zbo=r(Yot,"openai-gpt"),Yot.forEach(t),Wbo=r(OAe," \u2014 "),Oq=n(OAe,"A",{href:!0});var Kot=s(Oq);Qbo=r(Kot,"OpenAIGPTModel"),Kot.forEach(t),Hbo=r(OAe," (OpenAI GPT model)"),OAe.forEach(t),Ubo=i($),fu=n($,"LI",{});var VAe=s(fu);Rle=n(VAe,"STRONG",{});var Zot=s(Rle);Jbo=r(Zot,"opt"),Zot.forEach(t),Ybo=r(VAe," \u2014 "),Vq=n(VAe,"A",{href:!0});var ert=s(Vq);Kbo=r(ert,"OPTModel"),ert.forEach(t),Zbo=r(VAe," (OPT model)"),VAe.forEach(t),e4o=i($),mu=n($,"LI",{});var XAe=s(mu);Ple=n(XAe,"STRONG",{});var ort=s(Ple);o4o=r(ort,"pegasus"),ort.forEach(t),r4o=r(XAe," \u2014 "),Xq=n(XAe,"A",{href:!0});var rrt=s(Xq);t4o=r(rrt,"PegasusModel"),rrt.forEach(t),a4o=r(XAe," (Pegasus model)"),XAe.forEach(t),n4o=i($),gu=n($,"LI",{});var zAe=s(gu);Ble=n(zAe,"STRONG",{});var trt=s(Ble);s4o=r(trt,"perceiver"),trt.forEach(t),l4o=r(zAe," \u2014 "),zq=n(zAe,"A",{href:!0});var art=s(zq);i4o=r(art,"PerceiverModel"),art.forEach(t),d4o=r(zAe," (Perceiver model)"),zAe.forEach(t),c4o=i($),hu=n($,"LI",{});var WAe=s(hu);Ile=n(WAe,"STRONG",{});var nrt=s(Ile);f4o=r(nrt,"plbart"),nrt.forEach(t),m4o=r(WAe," \u2014 "),Wq=n(WAe,"A",{href:!0});var srt=s(Wq);g4o=r(srt,"PLBartModel"),srt.forEach(t),h4o=r(WAe," (PLBart model)"),WAe.forEach(t),p4o=i($),pu=n($,"LI",{});var QAe=s(pu);qle=n(QAe,"STRONG",{});var lrt=s(qle);u4o=r(lrt,"poolformer"),lrt.forEach(t),_4o=r(QAe," \u2014 "),Qq=n(QAe,"A",{href:!0});var irt=s(Qq);b4o=r(irt,"PoolFormerModel"),irt.forEach(t),v4o=r(QAe," (PoolFormer model)"),QAe.forEach(t),F4o=i($),uu=n($,"LI",{});var HAe=s(uu);Nle=n(HAe,"STRONG",{});var drt=s(Nle);T4o=r(drt,"prophetnet"),drt.forEach(t),M4o=r(HAe," \u2014 "),Hq=n(HAe,"A",{href:!0});var crt=s(Hq);E4o=r(crt,"ProphetNetModel"),crt.forEach(t),C4o=r(HAe," (ProphetNet model)"),HAe.forEach(t),w4o=i($),_u=n($,"LI",{});var UAe=s(_u);jle=n(UAe,"STRONG",{});var frt=s(jle);A4o=r(frt,"qdqbert"),frt.forEach(t),y4o=r(UAe," \u2014 "),Uq=n(UAe,"A",{href:!0});var mrt=s(Uq);L4o=r(mrt,"QDQBertModel"),mrt.forEach(t),x4o=r(UAe," (QDQBert model)"),UAe.forEach(t),$4o=i($),bu=n($,"LI",{});var JAe=s(bu);Dle=n(JAe,"STRONG",{});var grt=s(Dle);k4o=r(grt,"reformer"),grt.forEach(t),S4o=r(JAe," \u2014 "),Jq=n(JAe,"A",{href:!0});var hrt=s(Jq);R4o=r(hrt,"ReformerModel"),hrt.forEach(t),P4o=r(JAe," (Reformer model)"),JAe.forEach(t),B4o=i($),vu=n($,"LI",{});var YAe=s(vu);Gle=n(YAe,"STRONG",{});var prt=s(Gle);I4o=r(prt,"regnet"),prt.forEach(t),q4o=r(YAe," \u2014 "),Yq=n(YAe,"A",{href:!0});var urt=s(Yq);N4o=r(urt,"RegNetModel"),urt.forEach(t),j4o=r(YAe," (RegNet model)"),YAe.forEach(t),D4o=i($),Fu=n($,"LI",{});var KAe=s(Fu);Ole=n(KAe,"STRONG",{});var _rt=s(Ole);G4o=r(_rt,"rembert"),_rt.forEach(t),O4o=r(KAe," \u2014 "),Kq=n(KAe,"A",{href:!0});var brt=s(Kq);V4o=r(brt,"RemBertModel"),brt.forEach(t),X4o=r(KAe," (RemBERT model)"),KAe.forEach(t),z4o=i($),Tu=n($,"LI",{});var ZAe=s(Tu);Vle=n(ZAe,"STRONG",{});var vrt=s(Vle);W4o=r(vrt,"resnet"),vrt.forEach(t),Q4o=r(ZAe," \u2014 "),Zq=n(ZAe,"A",{href:!0});var Frt=s(Zq);H4o=r(Frt,"ResNetModel"),Frt.forEach(t),U4o=r(ZAe," (ResNet model)"),ZAe.forEach(t),J4o=i($),Mu=n($,"LI",{});var eye=s(Mu);Xle=n(eye,"STRONG",{});var Trt=s(Xle);Y4o=r(Trt,"retribert"),Trt.forEach(t),K4o=r(eye," \u2014 "),eN=n(eye,"A",{href:!0});var Mrt=s(eN);Z4o=r(Mrt,"RetriBertModel"),Mrt.forEach(t),evo=r(eye," (RetriBERT model)"),eye.forEach(t),ovo=i($),Eu=n($,"LI",{});var oye=s(Eu);zle=n(oye,"STRONG",{});var Ert=s(zle);rvo=r(Ert,"roberta"),Ert.forEach(t),tvo=r(oye," \u2014 "),oN=n(oye,"A",{href:!0});var Crt=s(oN);avo=r(Crt,"RobertaModel"),Crt.forEach(t),nvo=r(oye," (RoBERTa model)"),oye.forEach(t),svo=i($),Cu=n($,"LI",{});var rye=s(Cu);Wle=n(rye,"STRONG",{});var wrt=s(Wle);lvo=r(wrt,"roformer"),wrt.forEach(t),ivo=r(rye," \u2014 "),rN=n(rye,"A",{href:!0});var Art=s(rN);dvo=r(Art,"RoFormerModel"),Art.forEach(t),cvo=r(rye," (RoFormer model)"),rye.forEach(t),fvo=i($),wu=n($,"LI",{});var tye=s(wu);Qle=n(tye,"STRONG",{});var yrt=s(Qle);mvo=r(yrt,"segformer"),yrt.forEach(t),gvo=r(tye," \u2014 "),tN=n(tye,"A",{href:!0});var Lrt=s(tN);hvo=r(Lrt,"SegformerModel"),Lrt.forEach(t),pvo=r(tye," (SegFormer model)"),tye.forEach(t),uvo=i($),Au=n($,"LI",{});var aye=s(Au);Hle=n(aye,"STRONG",{});var xrt=s(Hle);_vo=r(xrt,"sew"),xrt.forEach(t),bvo=r(aye," \u2014 "),aN=n(aye,"A",{href:!0});var $rt=s(aN);vvo=r($rt,"SEWModel"),$rt.forEach(t),Fvo=r(aye," (SEW model)"),aye.forEach(t),Tvo=i($),yu=n($,"LI",{});var nye=s(yu);Ule=n(nye,"STRONG",{});var krt=s(Ule);Mvo=r(krt,"sew-d"),krt.forEach(t),Evo=r(nye," \u2014 "),nN=n(nye,"A",{href:!0});var Srt=s(nN);Cvo=r(Srt,"SEWDModel"),Srt.forEach(t),wvo=r(nye," (SEW-D model)"),nye.forEach(t),Avo=i($),Lu=n($,"LI",{});var sye=s(Lu);Jle=n(sye,"STRONG",{});var Rrt=s(Jle);yvo=r(Rrt,"speech_to_text"),Rrt.forEach(t),Lvo=r(sye," \u2014 "),sN=n(sye,"A",{href:!0});var Prt=s(sN);xvo=r(Prt,"Speech2TextModel"),Prt.forEach(t),$vo=r(sye," (Speech2Text model)"),sye.forEach(t),kvo=i($),xu=n($,"LI",{});var lye=s(xu);Yle=n(lye,"STRONG",{});var Brt=s(Yle);Svo=r(Brt,"splinter"),Brt.forEach(t),Rvo=r(lye," \u2014 "),lN=n(lye,"A",{href:!0});var Irt=s(lN);Pvo=r(Irt,"SplinterModel"),Irt.forEach(t),Bvo=r(lye," (Splinter model)"),lye.forEach(t),Ivo=i($),$u=n($,"LI",{});var iye=s($u);Kle=n(iye,"STRONG",{});var qrt=s(Kle);qvo=r(qrt,"squeezebert"),qrt.forEach(t),Nvo=r(iye," \u2014 "),iN=n(iye,"A",{href:!0});var Nrt=s(iN);jvo=r(Nrt,"SqueezeBertModel"),Nrt.forEach(t),Dvo=r(iye," (SqueezeBERT model)"),iye.forEach(t),Gvo=i($),ku=n($,"LI",{});var dye=s(ku);Zle=n(dye,"STRONG",{});var jrt=s(Zle);Ovo=r(jrt,"swin"),jrt.forEach(t),Vvo=r(dye," \u2014 "),dN=n(dye,"A",{href:!0});var Drt=s(dN);Xvo=r(Drt,"SwinModel"),Drt.forEach(t),zvo=r(dye," (Swin model)"),dye.forEach(t),Wvo=i($),Su=n($,"LI",{});var cye=s(Su);eie=n(cye,"STRONG",{});var Grt=s(eie);Qvo=r(Grt,"t5"),Grt.forEach(t),Hvo=r(cye," \u2014 "),cN=n(cye,"A",{href:!0});var Ort=s(cN);Uvo=r(Ort,"T5Model"),Ort.forEach(t),Jvo=r(cye," (T5 model)"),cye.forEach(t),Yvo=i($),Ru=n($,"LI",{});var fye=s(Ru);oie=n(fye,"STRONG",{});var Vrt=s(oie);Kvo=r(Vrt,"tapas"),Vrt.forEach(t),Zvo=r(fye," \u2014 "),fN=n(fye,"A",{href:!0});var Xrt=s(fN);e5o=r(Xrt,"TapasModel"),Xrt.forEach(t),o5o=r(fye," (TAPAS model)"),fye.forEach(t),r5o=i($),Pu=n($,"LI",{});var mye=s(Pu);rie=n(mye,"STRONG",{});var zrt=s(rie);t5o=r(zrt,"trajectory_transformer"),zrt.forEach(t),a5o=r(mye," \u2014 "),mN=n(mye,"A",{href:!0});var Wrt=s(mN);n5o=r(Wrt,"TrajectoryTransformerModel"),Wrt.forEach(t),s5o=r(mye," (Trajectory Transformer model)"),mye.forEach(t),l5o=i($),Bu=n($,"LI",{});var gye=s(Bu);tie=n(gye,"STRONG",{});var Qrt=s(tie);i5o=r(Qrt,"transfo-xl"),Qrt.forEach(t),d5o=r(gye," \u2014 "),gN=n(gye,"A",{href:!0});var Hrt=s(gN);c5o=r(Hrt,"TransfoXLModel"),Hrt.forEach(t),f5o=r(gye," (Transformer-XL model)"),gye.forEach(t),m5o=i($),Iu=n($,"LI",{});var hye=s(Iu);aie=n(hye,"STRONG",{});var Urt=s(aie);g5o=r(Urt,"unispeech"),Urt.forEach(t),h5o=r(hye," \u2014 "),hN=n(hye,"A",{href:!0});var Jrt=s(hN);p5o=r(Jrt,"UniSpeechModel"),Jrt.forEach(t),u5o=r(hye," (UniSpeech model)"),hye.forEach(t),_5o=i($),qu=n($,"LI",{});var pye=s(qu);nie=n(pye,"STRONG",{});var Yrt=s(nie);b5o=r(Yrt,"unispeech-sat"),Yrt.forEach(t),v5o=r(pye," \u2014 "),pN=n(pye,"A",{href:!0});var Krt=s(pN);F5o=r(Krt,"UniSpeechSatModel"),Krt.forEach(t),T5o=r(pye," (UniSpeechSat model)"),pye.forEach(t),M5o=i($),Nu=n($,"LI",{});var uye=s(Nu);sie=n(uye,"STRONG",{});var Zrt=s(sie);E5o=r(Zrt,"van"),Zrt.forEach(t),C5o=r(uye," \u2014 "),uN=n(uye,"A",{href:!0});var ett=s(uN);w5o=r(ett,"VanModel"),ett.forEach(t),A5o=r(uye," (VAN model)"),uye.forEach(t),y5o=i($),ju=n($,"LI",{});var _ye=s(ju);lie=n(_ye,"STRONG",{});var ott=s(lie);L5o=r(ott,"vilt"),ott.forEach(t),x5o=r(_ye," \u2014 "),_N=n(_ye,"A",{href:!0});var rtt=s(_N);$5o=r(rtt,"ViltModel"),rtt.forEach(t),k5o=r(_ye," (ViLT model)"),_ye.forEach(t),S5o=i($),Du=n($,"LI",{});var bye=s(Du);iie=n(bye,"STRONG",{});var ttt=s(iie);R5o=r(ttt,"vision-text-dual-encoder"),ttt.forEach(t),P5o=r(bye," \u2014 "),bN=n(bye,"A",{href:!0});var att=s(bN);B5o=r(att,"VisionTextDualEncoderModel"),att.forEach(t),I5o=r(bye," (VisionTextDualEncoder model)"),bye.forEach(t),q5o=i($),Gu=n($,"LI",{});var vye=s(Gu);die=n(vye,"STRONG",{});var ntt=s(die);N5o=r(ntt,"visual_bert"),ntt.forEach(t),j5o=r(vye," \u2014 "),vN=n(vye,"A",{href:!0});var stt=s(vN);D5o=r(stt,"VisualBertModel"),stt.forEach(t),G5o=r(vye," (VisualBert model)"),vye.forEach(t),O5o=i($),Ou=n($,"LI",{});var Fye=s(Ou);cie=n(Fye,"STRONG",{});var ltt=s(cie);V5o=r(ltt,"vit"),ltt.forEach(t),X5o=r(Fye," \u2014 "),FN=n(Fye,"A",{href:!0});var itt=s(FN);z5o=r(itt,"ViTModel"),itt.forEach(t),W5o=r(Fye," (ViT model)"),Fye.forEach(t),Q5o=i($),Vu=n($,"LI",{});var Tye=s(Vu);fie=n(Tye,"STRONG",{});var dtt=s(fie);H5o=r(dtt,"vit_mae"),dtt.forEach(t),U5o=r(Tye," \u2014 "),TN=n(Tye,"A",{href:!0});var ctt=s(TN);J5o=r(ctt,"ViTMAEModel"),ctt.forEach(t),Y5o=r(Tye," (ViTMAE model)"),Tye.forEach(t),K5o=i($),Xu=n($,"LI",{});var Mye=s(Xu);mie=n(Mye,"STRONG",{});var ftt=s(mie);Z5o=r(ftt,"wav2vec2"),ftt.forEach(t),eFo=r(Mye," \u2014 "),MN=n(Mye,"A",{href:!0});var mtt=s(MN);oFo=r(mtt,"Wav2Vec2Model"),mtt.forEach(t),rFo=r(Mye," (Wav2Vec2 model)"),Mye.forEach(t),tFo=i($),zu=n($,"LI",{});var Eye=s(zu);gie=n(Eye,"STRONG",{});var gtt=s(gie);aFo=r(gtt,"wav2vec2-conformer"),gtt.forEach(t),nFo=r(Eye," \u2014 "),EN=n(Eye,"A",{href:!0});var htt=s(EN);sFo=r(htt,"Wav2Vec2ConformerModel"),htt.forEach(t),lFo=r(Eye," (Wav2Vec2-Conformer model)"),Eye.forEach(t),iFo=i($),Wu=n($,"LI",{});var Cye=s(Wu);hie=n(Cye,"STRONG",{});var ptt=s(hie);dFo=r(ptt,"wavlm"),ptt.forEach(t),cFo=r(Cye," \u2014 "),CN=n(Cye,"A",{href:!0});var utt=s(CN);fFo=r(utt,"WavLMModel"),utt.forEach(t),mFo=r(Cye," (WavLM model)"),Cye.forEach(t),gFo=i($),Qu=n($,"LI",{});var wye=s(Qu);pie=n(wye,"STRONG",{});var _tt=s(pie);hFo=r(_tt,"xglm"),_tt.forEach(t),pFo=r(wye," \u2014 "),wN=n(wye,"A",{href:!0});var btt=s(wN);uFo=r(btt,"XGLMModel"),btt.forEach(t),_Fo=r(wye," (XGLM model)"),wye.forEach(t),bFo=i($),Hu=n($,"LI",{});var Aye=s(Hu);uie=n(Aye,"STRONG",{});var vtt=s(uie);vFo=r(vtt,"xlm"),vtt.forEach(t),FFo=r(Aye," \u2014 "),AN=n(Aye,"A",{href:!0});var Ftt=s(AN);TFo=r(Ftt,"XLMModel"),Ftt.forEach(t),MFo=r(Aye," (XLM model)"),Aye.forEach(t),EFo=i($),Uu=n($,"LI",{});var yye=s(Uu);_ie=n(yye,"STRONG",{});var Ttt=s(_ie);CFo=r(Ttt,"xlm-prophetnet"),Ttt.forEach(t),wFo=r(yye," \u2014 "),yN=n(yye,"A",{href:!0});var Mtt=s(yN);AFo=r(Mtt,"XLMProphetNetModel"),Mtt.forEach(t),yFo=r(yye," (XLMProphetNet model)"),yye.forEach(t),LFo=i($),Ju=n($,"LI",{});var Lye=s(Ju);bie=n(Lye,"STRONG",{});var Ett=s(bie);xFo=r(Ett,"xlm-roberta"),Ett.forEach(t),$Fo=r(Lye," \u2014 "),LN=n(Lye,"A",{href:!0});var Ctt=s(LN);kFo=r(Ctt,"XLMRobertaModel"),Ctt.forEach(t),SFo=r(Lye," (XLM-RoBERTa model)"),Lye.forEach(t),RFo=i($),Yu=n($,"LI",{});var xye=s(Yu);vie=n(xye,"STRONG",{});var wtt=s(vie);PFo=r(wtt,"xlm-roberta-xl"),wtt.forEach(t),BFo=r(xye," \u2014 "),xN=n(xye,"A",{href:!0});var Att=s(xN);IFo=r(Att,"XLMRobertaXLModel"),Att.forEach(t),qFo=r(xye," (XLM-RoBERTa-XL model)"),xye.forEach(t),NFo=i($),Ku=n($,"LI",{});var $ye=s(Ku);Fie=n($ye,"STRONG",{});var ytt=s(Fie);jFo=r(ytt,"xlnet"),ytt.forEach(t),DFo=r($ye," \u2014 "),$N=n($ye,"A",{href:!0});var Ltt=s($N);GFo=r(Ltt,"XLNetModel"),Ltt.forEach(t),OFo=r($ye," (XLNet model)"),$ye.forEach(t),VFo=i($),Zu=n($,"LI",{});var kye=s(Zu);Tie=n(kye,"STRONG",{});var xtt=s(Tie);XFo=r(xtt,"yolos"),xtt.forEach(t),zFo=r(kye," \u2014 "),kN=n(kye,"A",{href:!0});var $tt=s(kN);WFo=r($tt,"YolosModel"),$tt.forEach(t),QFo=r(kye," (YOLOS model)"),kye.forEach(t),HFo=i($),e_=n($,"LI",{});var Sye=s(e_);Mie=n(Sye,"STRONG",{});var ktt=s(Mie);UFo=r(ktt,"yoso"),ktt.forEach(t),JFo=r(Sye," \u2014 "),SN=n(Sye,"A",{href:!0});var Stt=s(SN);YFo=r(Stt,"YosoModel"),Stt.forEach(t),KFo=r(Sye," (YOSO model)"),Sye.forEach(t),$.forEach(t),ZFo=i(oa),o_=n(oa,"P",{});var Rye=s(o_);eTo=r(Rye,"The model is set in evaluation mode by default using "),Eie=n(Rye,"CODE",{});var Rtt=s(Eie);oTo=r(Rtt,"model.eval()"),Rtt.forEach(t),rTo=r(Rye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cie=n(Rye,"CODE",{});var Ptt=s(Cie);tTo=r(Ptt,"model.train()"),Ptt.forEach(t),Rye.forEach(t),aTo=i(oa),T(r_.$$.fragment,oa),oa.forEach(t),Xs.forEach(t),uNe=i(f),ki=n(f,"H2",{class:!0});var FDe=s(ki);t_=n(FDe,"A",{id:!0,class:!0,href:!0});var Btt=s(t_);wie=n(Btt,"SPAN",{});var Itt=s(wie);T(ay.$$.fragment,Itt),Itt.forEach(t),Btt.forEach(t),nTo=i(FDe),Aie=n(FDe,"SPAN",{});var qtt=s(Aie);sTo=r(qtt,"AutoModelForPreTraining"),qtt.forEach(t),FDe.forEach(t),_Ne=i(f),xo=n(f,"DIV",{class:!0});var zs=s(xo);T(ny.$$.fragment,zs),lTo=i(zs),Si=n(zs,"P",{});var EZ=s(Si);iTo=r(EZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),RN=n(EZ,"A",{href:!0});var Ntt=s(RN);dTo=r(Ntt,"from_pretrained()"),Ntt.forEach(t),cTo=r(EZ," class method or the "),PN=n(EZ,"A",{href:!0});var jtt=s(PN);fTo=r(jtt,"from_config()"),jtt.forEach(t),mTo=r(EZ,` class
method.`),EZ.forEach(t),gTo=i(zs),sy=n(zs,"P",{});var TDe=s(sy);hTo=r(TDe,"This class cannot be instantiated directly using "),yie=n(TDe,"CODE",{});var Dtt=s(yie);pTo=r(Dtt,"__init__()"),Dtt.forEach(t),uTo=r(TDe," (throws an error)."),TDe.forEach(t),_To=i(zs),at=n(zs,"DIV",{class:!0});var R0=s(at);T(ly.$$.fragment,R0),bTo=i(R0),Lie=n(R0,"P",{});var Gtt=s(Lie);vTo=r(Gtt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Gtt.forEach(t),FTo=i(R0),Ri=n(R0,"P",{});var CZ=s(Ri);TTo=r(CZ,`Note:
Loading a model from its configuration file does `),xie=n(CZ,"STRONG",{});var Ott=s(xie);MTo=r(Ott,"not"),Ott.forEach(t),ETo=r(CZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),BN=n(CZ,"A",{href:!0});var Vtt=s(BN);CTo=r(Vtt,"from_pretrained()"),Vtt.forEach(t),wTo=r(CZ," to load the model weights."),CZ.forEach(t),ATo=i(R0),T(a_.$$.fragment,R0),R0.forEach(t),yTo=i(zs),Ye=n(zs,"DIV",{class:!0});var ra=s(Ye);T(iy.$$.fragment,ra),LTo=i(ra),$ie=n(ra,"P",{});var Xtt=s($ie);xTo=r(Xtt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Xtt.forEach(t),$To=i(ra),xa=n(ra,"P",{});var P0=s(xa);kTo=r(P0,"The model class to instantiate is selected based on the "),kie=n(P0,"CODE",{});var ztt=s(kie);STo=r(ztt,"model_type"),ztt.forEach(t),RTo=r(P0,` property of the config object (either
passed as an argument or loaded from `),Sie=n(P0,"CODE",{});var Wtt=s(Sie);PTo=r(Wtt,"pretrained_model_name_or_path"),Wtt.forEach(t),BTo=r(P0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rie=n(P0,"CODE",{});var Qtt=s(Rie);ITo=r(Qtt,"pretrained_model_name_or_path"),Qtt.forEach(t),qTo=r(P0,":"),P0.forEach(t),NTo=i(ra),G=n(ra,"UL",{});var O=s(G);n_=n(O,"LI",{});var Pye=s(n_);Pie=n(Pye,"STRONG",{});var Htt=s(Pie);jTo=r(Htt,"albert"),Htt.forEach(t),DTo=r(Pye," \u2014 "),IN=n(Pye,"A",{href:!0});var Utt=s(IN);GTo=r(Utt,"AlbertForPreTraining"),Utt.forEach(t),OTo=r(Pye," (ALBERT model)"),Pye.forEach(t),VTo=i(O),s_=n(O,"LI",{});var Bye=s(s_);Bie=n(Bye,"STRONG",{});var Jtt=s(Bie);XTo=r(Jtt,"bart"),Jtt.forEach(t),zTo=r(Bye," \u2014 "),qN=n(Bye,"A",{href:!0});var Ytt=s(qN);WTo=r(Ytt,"BartForConditionalGeneration"),Ytt.forEach(t),QTo=r(Bye," (BART model)"),Bye.forEach(t),HTo=i(O),l_=n(O,"LI",{});var Iye=s(l_);Iie=n(Iye,"STRONG",{});var Ktt=s(Iie);UTo=r(Ktt,"bert"),Ktt.forEach(t),JTo=r(Iye," \u2014 "),NN=n(Iye,"A",{href:!0});var Ztt=s(NN);YTo=r(Ztt,"BertForPreTraining"),Ztt.forEach(t),KTo=r(Iye," (BERT model)"),Iye.forEach(t),ZTo=i(O),i_=n(O,"LI",{});var qye=s(i_);qie=n(qye,"STRONG",{});var eat=s(qie);e7o=r(eat,"big_bird"),eat.forEach(t),o7o=r(qye," \u2014 "),jN=n(qye,"A",{href:!0});var oat=s(jN);r7o=r(oat,"BigBirdForPreTraining"),oat.forEach(t),t7o=r(qye," (BigBird model)"),qye.forEach(t),a7o=i(O),d_=n(O,"LI",{});var Nye=s(d_);Nie=n(Nye,"STRONG",{});var rat=s(Nie);n7o=r(rat,"camembert"),rat.forEach(t),s7o=r(Nye," \u2014 "),DN=n(Nye,"A",{href:!0});var tat=s(DN);l7o=r(tat,"CamembertForMaskedLM"),tat.forEach(t),i7o=r(Nye," (CamemBERT model)"),Nye.forEach(t),d7o=i(O),c_=n(O,"LI",{});var jye=s(c_);jie=n(jye,"STRONG",{});var aat=s(jie);c7o=r(aat,"ctrl"),aat.forEach(t),f7o=r(jye," \u2014 "),GN=n(jye,"A",{href:!0});var nat=s(GN);m7o=r(nat,"CTRLLMHeadModel"),nat.forEach(t),g7o=r(jye," (CTRL model)"),jye.forEach(t),h7o=i(O),f_=n(O,"LI",{});var Dye=s(f_);Die=n(Dye,"STRONG",{});var sat=s(Die);p7o=r(sat,"data2vec-text"),sat.forEach(t),u7o=r(Dye," \u2014 "),ON=n(Dye,"A",{href:!0});var lat=s(ON);_7o=r(lat,"Data2VecTextForMaskedLM"),lat.forEach(t),b7o=r(Dye," (Data2VecText model)"),Dye.forEach(t),v7o=i(O),m_=n(O,"LI",{});var Gye=s(m_);Gie=n(Gye,"STRONG",{});var iat=s(Gie);F7o=r(iat,"deberta"),iat.forEach(t),T7o=r(Gye," \u2014 "),VN=n(Gye,"A",{href:!0});var dat=s(VN);M7o=r(dat,"DebertaForMaskedLM"),dat.forEach(t),E7o=r(Gye," (DeBERTa model)"),Gye.forEach(t),C7o=i(O),g_=n(O,"LI",{});var Oye=s(g_);Oie=n(Oye,"STRONG",{});var cat=s(Oie);w7o=r(cat,"deberta-v2"),cat.forEach(t),A7o=r(Oye," \u2014 "),XN=n(Oye,"A",{href:!0});var fat=s(XN);y7o=r(fat,"DebertaV2ForMaskedLM"),fat.forEach(t),L7o=r(Oye," (DeBERTa-v2 model)"),Oye.forEach(t),x7o=i(O),h_=n(O,"LI",{});var Vye=s(h_);Vie=n(Vye,"STRONG",{});var mat=s(Vie);$7o=r(mat,"distilbert"),mat.forEach(t),k7o=r(Vye," \u2014 "),zN=n(Vye,"A",{href:!0});var gat=s(zN);S7o=r(gat,"DistilBertForMaskedLM"),gat.forEach(t),R7o=r(Vye," (DistilBERT model)"),Vye.forEach(t),P7o=i(O),p_=n(O,"LI",{});var Xye=s(p_);Xie=n(Xye,"STRONG",{});var hat=s(Xie);B7o=r(hat,"electra"),hat.forEach(t),I7o=r(Xye," \u2014 "),WN=n(Xye,"A",{href:!0});var pat=s(WN);q7o=r(pat,"ElectraForPreTraining"),pat.forEach(t),N7o=r(Xye," (ELECTRA model)"),Xye.forEach(t),j7o=i(O),u_=n(O,"LI",{});var zye=s(u_);zie=n(zye,"STRONG",{});var uat=s(zie);D7o=r(uat,"flaubert"),uat.forEach(t),G7o=r(zye," \u2014 "),QN=n(zye,"A",{href:!0});var _at=s(QN);O7o=r(_at,"FlaubertWithLMHeadModel"),_at.forEach(t),V7o=r(zye," (FlauBERT model)"),zye.forEach(t),X7o=i(O),__=n(O,"LI",{});var Wye=s(__);Wie=n(Wye,"STRONG",{});var bat=s(Wie);z7o=r(bat,"flava"),bat.forEach(t),W7o=r(Wye," \u2014 "),HN=n(Wye,"A",{href:!0});var vat=s(HN);Q7o=r(vat,"FlavaForPreTraining"),vat.forEach(t),H7o=r(Wye," (Flava model)"),Wye.forEach(t),U7o=i(O),b_=n(O,"LI",{});var Qye=s(b_);Qie=n(Qye,"STRONG",{});var Fat=s(Qie);J7o=r(Fat,"fnet"),Fat.forEach(t),Y7o=r(Qye," \u2014 "),UN=n(Qye,"A",{href:!0});var Tat=s(UN);K7o=r(Tat,"FNetForPreTraining"),Tat.forEach(t),Z7o=r(Qye," (FNet model)"),Qye.forEach(t),eMo=i(O),v_=n(O,"LI",{});var Hye=s(v_);Hie=n(Hye,"STRONG",{});var Mat=s(Hie);oMo=r(Mat,"fsmt"),Mat.forEach(t),rMo=r(Hye," \u2014 "),JN=n(Hye,"A",{href:!0});var Eat=s(JN);tMo=r(Eat,"FSMTForConditionalGeneration"),Eat.forEach(t),aMo=r(Hye," (FairSeq Machine-Translation model)"),Hye.forEach(t),nMo=i(O),F_=n(O,"LI",{});var Uye=s(F_);Uie=n(Uye,"STRONG",{});var Cat=s(Uie);sMo=r(Cat,"funnel"),Cat.forEach(t),lMo=r(Uye," \u2014 "),YN=n(Uye,"A",{href:!0});var wat=s(YN);iMo=r(wat,"FunnelForPreTraining"),wat.forEach(t),dMo=r(Uye," (Funnel Transformer model)"),Uye.forEach(t),cMo=i(O),T_=n(O,"LI",{});var Jye=s(T_);Jie=n(Jye,"STRONG",{});var Aat=s(Jie);fMo=r(Aat,"gpt2"),Aat.forEach(t),mMo=r(Jye," \u2014 "),KN=n(Jye,"A",{href:!0});var yat=s(KN);gMo=r(yat,"GPT2LMHeadModel"),yat.forEach(t),hMo=r(Jye," (OpenAI GPT-2 model)"),Jye.forEach(t),pMo=i(O),M_=n(O,"LI",{});var Yye=s(M_);Yie=n(Yye,"STRONG",{});var Lat=s(Yie);uMo=r(Lat,"ibert"),Lat.forEach(t),_Mo=r(Yye," \u2014 "),ZN=n(Yye,"A",{href:!0});var xat=s(ZN);bMo=r(xat,"IBertForMaskedLM"),xat.forEach(t),vMo=r(Yye," (I-BERT model)"),Yye.forEach(t),FMo=i(O),E_=n(O,"LI",{});var Kye=s(E_);Kie=n(Kye,"STRONG",{});var $at=s(Kie);TMo=r($at,"layoutlm"),$at.forEach(t),MMo=r(Kye," \u2014 "),ej=n(Kye,"A",{href:!0});var kat=s(ej);EMo=r(kat,"LayoutLMForMaskedLM"),kat.forEach(t),CMo=r(Kye," (LayoutLM model)"),Kye.forEach(t),wMo=i(O),C_=n(O,"LI",{});var Zye=s(C_);Zie=n(Zye,"STRONG",{});var Sat=s(Zie);AMo=r(Sat,"longformer"),Sat.forEach(t),yMo=r(Zye," \u2014 "),oj=n(Zye,"A",{href:!0});var Rat=s(oj);LMo=r(Rat,"LongformerForMaskedLM"),Rat.forEach(t),xMo=r(Zye," (Longformer model)"),Zye.forEach(t),$Mo=i(O),w_=n(O,"LI",{});var eLe=s(w_);ede=n(eLe,"STRONG",{});var Pat=s(ede);kMo=r(Pat,"lxmert"),Pat.forEach(t),SMo=r(eLe," \u2014 "),rj=n(eLe,"A",{href:!0});var Bat=s(rj);RMo=r(Bat,"LxmertForPreTraining"),Bat.forEach(t),PMo=r(eLe," (LXMERT model)"),eLe.forEach(t),BMo=i(O),A_=n(O,"LI",{});var oLe=s(A_);ode=n(oLe,"STRONG",{});var Iat=s(ode);IMo=r(Iat,"megatron-bert"),Iat.forEach(t),qMo=r(oLe," \u2014 "),tj=n(oLe,"A",{href:!0});var qat=s(tj);NMo=r(qat,"MegatronBertForPreTraining"),qat.forEach(t),jMo=r(oLe," (MegatronBert model)"),oLe.forEach(t),DMo=i(O),y_=n(O,"LI",{});var rLe=s(y_);rde=n(rLe,"STRONG",{});var Nat=s(rde);GMo=r(Nat,"mobilebert"),Nat.forEach(t),OMo=r(rLe," \u2014 "),aj=n(rLe,"A",{href:!0});var jat=s(aj);VMo=r(jat,"MobileBertForPreTraining"),jat.forEach(t),XMo=r(rLe," (MobileBERT model)"),rLe.forEach(t),zMo=i(O),L_=n(O,"LI",{});var tLe=s(L_);tde=n(tLe,"STRONG",{});var Dat=s(tde);WMo=r(Dat,"mpnet"),Dat.forEach(t),QMo=r(tLe," \u2014 "),nj=n(tLe,"A",{href:!0});var Gat=s(nj);HMo=r(Gat,"MPNetForMaskedLM"),Gat.forEach(t),UMo=r(tLe," (MPNet model)"),tLe.forEach(t),JMo=i(O),x_=n(O,"LI",{});var aLe=s(x_);ade=n(aLe,"STRONG",{});var Oat=s(ade);YMo=r(Oat,"openai-gpt"),Oat.forEach(t),KMo=r(aLe," \u2014 "),sj=n(aLe,"A",{href:!0});var Vat=s(sj);ZMo=r(Vat,"OpenAIGPTLMHeadModel"),Vat.forEach(t),eEo=r(aLe," (OpenAI GPT model)"),aLe.forEach(t),oEo=i(O),$_=n(O,"LI",{});var nLe=s($_);nde=n(nLe,"STRONG",{});var Xat=s(nde);rEo=r(Xat,"retribert"),Xat.forEach(t),tEo=r(nLe," \u2014 "),lj=n(nLe,"A",{href:!0});var zat=s(lj);aEo=r(zat,"RetriBertModel"),zat.forEach(t),nEo=r(nLe," (RetriBERT model)"),nLe.forEach(t),sEo=i(O),k_=n(O,"LI",{});var sLe=s(k_);sde=n(sLe,"STRONG",{});var Wat=s(sde);lEo=r(Wat,"roberta"),Wat.forEach(t),iEo=r(sLe," \u2014 "),ij=n(sLe,"A",{href:!0});var Qat=s(ij);dEo=r(Qat,"RobertaForMaskedLM"),Qat.forEach(t),cEo=r(sLe," (RoBERTa model)"),sLe.forEach(t),fEo=i(O),S_=n(O,"LI",{});var lLe=s(S_);lde=n(lLe,"STRONG",{});var Hat=s(lde);mEo=r(Hat,"splinter"),Hat.forEach(t),gEo=r(lLe," \u2014 "),dj=n(lLe,"A",{href:!0});var Uat=s(dj);hEo=r(Uat,"SplinterForPreTraining"),Uat.forEach(t),pEo=r(lLe," (Splinter model)"),lLe.forEach(t),uEo=i(O),R_=n(O,"LI",{});var iLe=s(R_);ide=n(iLe,"STRONG",{});var Jat=s(ide);_Eo=r(Jat,"squeezebert"),Jat.forEach(t),bEo=r(iLe," \u2014 "),cj=n(iLe,"A",{href:!0});var Yat=s(cj);vEo=r(Yat,"SqueezeBertForMaskedLM"),Yat.forEach(t),FEo=r(iLe," (SqueezeBERT model)"),iLe.forEach(t),TEo=i(O),P_=n(O,"LI",{});var dLe=s(P_);dde=n(dLe,"STRONG",{});var Kat=s(dde);MEo=r(Kat,"t5"),Kat.forEach(t),EEo=r(dLe," \u2014 "),fj=n(dLe,"A",{href:!0});var Zat=s(fj);CEo=r(Zat,"T5ForConditionalGeneration"),Zat.forEach(t),wEo=r(dLe," (T5 model)"),dLe.forEach(t),AEo=i(O),B_=n(O,"LI",{});var cLe=s(B_);cde=n(cLe,"STRONG",{});var ent=s(cde);yEo=r(ent,"tapas"),ent.forEach(t),LEo=r(cLe," \u2014 "),mj=n(cLe,"A",{href:!0});var ont=s(mj);xEo=r(ont,"TapasForMaskedLM"),ont.forEach(t),$Eo=r(cLe," (TAPAS model)"),cLe.forEach(t),kEo=i(O),I_=n(O,"LI",{});var fLe=s(I_);fde=n(fLe,"STRONG",{});var rnt=s(fde);SEo=r(rnt,"transfo-xl"),rnt.forEach(t),REo=r(fLe," \u2014 "),gj=n(fLe,"A",{href:!0});var tnt=s(gj);PEo=r(tnt,"TransfoXLLMHeadModel"),tnt.forEach(t),BEo=r(fLe," (Transformer-XL model)"),fLe.forEach(t),IEo=i(O),q_=n(O,"LI",{});var mLe=s(q_);mde=n(mLe,"STRONG",{});var ant=s(mde);qEo=r(ant,"unispeech"),ant.forEach(t),NEo=r(mLe," \u2014 "),hj=n(mLe,"A",{href:!0});var nnt=s(hj);jEo=r(nnt,"UniSpeechForPreTraining"),nnt.forEach(t),DEo=r(mLe," (UniSpeech model)"),mLe.forEach(t),GEo=i(O),N_=n(O,"LI",{});var gLe=s(N_);gde=n(gLe,"STRONG",{});var snt=s(gde);OEo=r(snt,"unispeech-sat"),snt.forEach(t),VEo=r(gLe," \u2014 "),pj=n(gLe,"A",{href:!0});var lnt=s(pj);XEo=r(lnt,"UniSpeechSatForPreTraining"),lnt.forEach(t),zEo=r(gLe," (UniSpeechSat model)"),gLe.forEach(t),WEo=i(O),j_=n(O,"LI",{});var hLe=s(j_);hde=n(hLe,"STRONG",{});var int=s(hde);QEo=r(int,"visual_bert"),int.forEach(t),HEo=r(hLe," \u2014 "),uj=n(hLe,"A",{href:!0});var dnt=s(uj);UEo=r(dnt,"VisualBertForPreTraining"),dnt.forEach(t),JEo=r(hLe," (VisualBert model)"),hLe.forEach(t),YEo=i(O),D_=n(O,"LI",{});var pLe=s(D_);pde=n(pLe,"STRONG",{});var cnt=s(pde);KEo=r(cnt,"vit_mae"),cnt.forEach(t),ZEo=r(pLe," \u2014 "),_j=n(pLe,"A",{href:!0});var fnt=s(_j);eCo=r(fnt,"ViTMAEForPreTraining"),fnt.forEach(t),oCo=r(pLe," (ViTMAE model)"),pLe.forEach(t),rCo=i(O),G_=n(O,"LI",{});var uLe=s(G_);ude=n(uLe,"STRONG",{});var mnt=s(ude);tCo=r(mnt,"wav2vec2"),mnt.forEach(t),aCo=r(uLe," \u2014 "),bj=n(uLe,"A",{href:!0});var gnt=s(bj);nCo=r(gnt,"Wav2Vec2ForPreTraining"),gnt.forEach(t),sCo=r(uLe," (Wav2Vec2 model)"),uLe.forEach(t),lCo=i(O),O_=n(O,"LI",{});var _Le=s(O_);_de=n(_Le,"STRONG",{});var hnt=s(_de);iCo=r(hnt,"wav2vec2-conformer"),hnt.forEach(t),dCo=r(_Le," \u2014 "),vj=n(_Le,"A",{href:!0});var pnt=s(vj);cCo=r(pnt,"Wav2Vec2ConformerForPreTraining"),pnt.forEach(t),fCo=r(_Le," (Wav2Vec2-Conformer model)"),_Le.forEach(t),mCo=i(O),V_=n(O,"LI",{});var bLe=s(V_);bde=n(bLe,"STRONG",{});var unt=s(bde);gCo=r(unt,"xlm"),unt.forEach(t),hCo=r(bLe," \u2014 "),Fj=n(bLe,"A",{href:!0});var _nt=s(Fj);pCo=r(_nt,"XLMWithLMHeadModel"),_nt.forEach(t),uCo=r(bLe," (XLM model)"),bLe.forEach(t),_Co=i(O),X_=n(O,"LI",{});var vLe=s(X_);vde=n(vLe,"STRONG",{});var bnt=s(vde);bCo=r(bnt,"xlm-roberta"),bnt.forEach(t),vCo=r(vLe," \u2014 "),Tj=n(vLe,"A",{href:!0});var vnt=s(Tj);FCo=r(vnt,"XLMRobertaForMaskedLM"),vnt.forEach(t),TCo=r(vLe," (XLM-RoBERTa model)"),vLe.forEach(t),MCo=i(O),z_=n(O,"LI",{});var FLe=s(z_);Fde=n(FLe,"STRONG",{});var Fnt=s(Fde);ECo=r(Fnt,"xlm-roberta-xl"),Fnt.forEach(t),CCo=r(FLe," \u2014 "),Mj=n(FLe,"A",{href:!0});var Tnt=s(Mj);wCo=r(Tnt,"XLMRobertaXLForMaskedLM"),Tnt.forEach(t),ACo=r(FLe," (XLM-RoBERTa-XL model)"),FLe.forEach(t),yCo=i(O),W_=n(O,"LI",{});var TLe=s(W_);Tde=n(TLe,"STRONG",{});var Mnt=s(Tde);LCo=r(Mnt,"xlnet"),Mnt.forEach(t),xCo=r(TLe," \u2014 "),Ej=n(TLe,"A",{href:!0});var Ent=s(Ej);$Co=r(Ent,"XLNetLMHeadModel"),Ent.forEach(t),kCo=r(TLe," (XLNet model)"),TLe.forEach(t),O.forEach(t),SCo=i(ra),Q_=n(ra,"P",{});var MLe=s(Q_);RCo=r(MLe,"The model is set in evaluation mode by default using "),Mde=n(MLe,"CODE",{});var Cnt=s(Mde);PCo=r(Cnt,"model.eval()"),Cnt.forEach(t),BCo=r(MLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ede=n(MLe,"CODE",{});var wnt=s(Ede);ICo=r(wnt,"model.train()"),wnt.forEach(t),MLe.forEach(t),qCo=i(ra),T(H_.$$.fragment,ra),ra.forEach(t),zs.forEach(t),bNe=i(f),Pi=n(f,"H2",{class:!0});var MDe=s(Pi);U_=n(MDe,"A",{id:!0,class:!0,href:!0});var Ant=s(U_);Cde=n(Ant,"SPAN",{});var ynt=s(Cde);T(dy.$$.fragment,ynt),ynt.forEach(t),Ant.forEach(t),NCo=i(MDe),wde=n(MDe,"SPAN",{});var Lnt=s(wde);jCo=r(Lnt,"AutoModelForCausalLM"),Lnt.forEach(t),MDe.forEach(t),vNe=i(f),$o=n(f,"DIV",{class:!0});var Ws=s($o);T(cy.$$.fragment,Ws),DCo=i(Ws),Bi=n(Ws,"P",{});var wZ=s(Bi);GCo=r(wZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Cj=n(wZ,"A",{href:!0});var xnt=s(Cj);OCo=r(xnt,"from_pretrained()"),xnt.forEach(t),VCo=r(wZ," class method or the "),wj=n(wZ,"A",{href:!0});var $nt=s(wj);XCo=r($nt,"from_config()"),$nt.forEach(t),zCo=r(wZ,` class
method.`),wZ.forEach(t),WCo=i(Ws),fy=n(Ws,"P",{});var EDe=s(fy);QCo=r(EDe,"This class cannot be instantiated directly using "),Ade=n(EDe,"CODE",{});var knt=s(Ade);HCo=r(knt,"__init__()"),knt.forEach(t),UCo=r(EDe," (throws an error)."),EDe.forEach(t),JCo=i(Ws),nt=n(Ws,"DIV",{class:!0});var B0=s(nt);T(my.$$.fragment,B0),YCo=i(B0),yde=n(B0,"P",{});var Snt=s(yde);KCo=r(Snt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Snt.forEach(t),ZCo=i(B0),Ii=n(B0,"P",{});var AZ=s(Ii);e3o=r(AZ,`Note:
Loading a model from its configuration file does `),Lde=n(AZ,"STRONG",{});var Rnt=s(Lde);o3o=r(Rnt,"not"),Rnt.forEach(t),r3o=r(AZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aj=n(AZ,"A",{href:!0});var Pnt=s(Aj);t3o=r(Pnt,"from_pretrained()"),Pnt.forEach(t),a3o=r(AZ," to load the model weights."),AZ.forEach(t),n3o=i(B0),T(J_.$$.fragment,B0),B0.forEach(t),s3o=i(Ws),Ke=n(Ws,"DIV",{class:!0});var ta=s(Ke);T(gy.$$.fragment,ta),l3o=i(ta),xde=n(ta,"P",{});var Bnt=s(xde);i3o=r(Bnt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Bnt.forEach(t),d3o=i(ta),$a=n(ta,"P",{});var I0=s($a);c3o=r(I0,"The model class to instantiate is selected based on the "),$de=n(I0,"CODE",{});var Int=s($de);f3o=r(Int,"model_type"),Int.forEach(t),m3o=r(I0,` property of the config object (either
passed as an argument or loaded from `),kde=n(I0,"CODE",{});var qnt=s(kde);g3o=r(qnt,"pretrained_model_name_or_path"),qnt.forEach(t),h3o=r(I0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sde=n(I0,"CODE",{});var Nnt=s(Sde);p3o=r(Nnt,"pretrained_model_name_or_path"),Nnt.forEach(t),u3o=r(I0,":"),I0.forEach(t),_3o=i(ta),z=n(ta,"UL",{});var W=s(z);Y_=n(W,"LI",{});var ELe=s(Y_);Rde=n(ELe,"STRONG",{});var jnt=s(Rde);b3o=r(jnt,"bart"),jnt.forEach(t),v3o=r(ELe," \u2014 "),yj=n(ELe,"A",{href:!0});var Dnt=s(yj);F3o=r(Dnt,"BartForCausalLM"),Dnt.forEach(t),T3o=r(ELe," (BART model)"),ELe.forEach(t),M3o=i(W),K_=n(W,"LI",{});var CLe=s(K_);Pde=n(CLe,"STRONG",{});var Gnt=s(Pde);E3o=r(Gnt,"bert"),Gnt.forEach(t),C3o=r(CLe," \u2014 "),Lj=n(CLe,"A",{href:!0});var Ont=s(Lj);w3o=r(Ont,"BertLMHeadModel"),Ont.forEach(t),A3o=r(CLe," (BERT model)"),CLe.forEach(t),y3o=i(W),Z_=n(W,"LI",{});var wLe=s(Z_);Bde=n(wLe,"STRONG",{});var Vnt=s(Bde);L3o=r(Vnt,"bert-generation"),Vnt.forEach(t),x3o=r(wLe," \u2014 "),xj=n(wLe,"A",{href:!0});var Xnt=s(xj);$3o=r(Xnt,"BertGenerationDecoder"),Xnt.forEach(t),k3o=r(wLe," (Bert Generation model)"),wLe.forEach(t),S3o=i(W),e2=n(W,"LI",{});var ALe=s(e2);Ide=n(ALe,"STRONG",{});var znt=s(Ide);R3o=r(znt,"big_bird"),znt.forEach(t),P3o=r(ALe," \u2014 "),$j=n(ALe,"A",{href:!0});var Wnt=s($j);B3o=r(Wnt,"BigBirdForCausalLM"),Wnt.forEach(t),I3o=r(ALe," (BigBird model)"),ALe.forEach(t),q3o=i(W),o2=n(W,"LI",{});var yLe=s(o2);qde=n(yLe,"STRONG",{});var Qnt=s(qde);N3o=r(Qnt,"bigbird_pegasus"),Qnt.forEach(t),j3o=r(yLe," \u2014 "),kj=n(yLe,"A",{href:!0});var Hnt=s(kj);D3o=r(Hnt,"BigBirdPegasusForCausalLM"),Hnt.forEach(t),G3o=r(yLe," (BigBirdPegasus model)"),yLe.forEach(t),O3o=i(W),r2=n(W,"LI",{});var LLe=s(r2);Nde=n(LLe,"STRONG",{});var Unt=s(Nde);V3o=r(Unt,"blenderbot"),Unt.forEach(t),X3o=r(LLe," \u2014 "),Sj=n(LLe,"A",{href:!0});var Jnt=s(Sj);z3o=r(Jnt,"BlenderbotForCausalLM"),Jnt.forEach(t),W3o=r(LLe," (Blenderbot model)"),LLe.forEach(t),Q3o=i(W),t2=n(W,"LI",{});var xLe=s(t2);jde=n(xLe,"STRONG",{});var Ynt=s(jde);H3o=r(Ynt,"blenderbot-small"),Ynt.forEach(t),U3o=r(xLe," \u2014 "),Rj=n(xLe,"A",{href:!0});var Knt=s(Rj);J3o=r(Knt,"BlenderbotSmallForCausalLM"),Knt.forEach(t),Y3o=r(xLe," (BlenderbotSmall model)"),xLe.forEach(t),K3o=i(W),a2=n(W,"LI",{});var $Le=s(a2);Dde=n($Le,"STRONG",{});var Znt=s(Dde);Z3o=r(Znt,"camembert"),Znt.forEach(t),ewo=r($Le," \u2014 "),Pj=n($Le,"A",{href:!0});var est=s(Pj);owo=r(est,"CamembertForCausalLM"),est.forEach(t),rwo=r($Le," (CamemBERT model)"),$Le.forEach(t),two=i(W),n2=n(W,"LI",{});var kLe=s(n2);Gde=n(kLe,"STRONG",{});var ost=s(Gde);awo=r(ost,"ctrl"),ost.forEach(t),nwo=r(kLe," \u2014 "),Bj=n(kLe,"A",{href:!0});var rst=s(Bj);swo=r(rst,"CTRLLMHeadModel"),rst.forEach(t),lwo=r(kLe," (CTRL model)"),kLe.forEach(t),iwo=i(W),s2=n(W,"LI",{});var SLe=s(s2);Ode=n(SLe,"STRONG",{});var tst=s(Ode);dwo=r(tst,"data2vec-text"),tst.forEach(t),cwo=r(SLe," \u2014 "),Ij=n(SLe,"A",{href:!0});var ast=s(Ij);fwo=r(ast,"Data2VecTextForCausalLM"),ast.forEach(t),mwo=r(SLe," (Data2VecText model)"),SLe.forEach(t),gwo=i(W),l2=n(W,"LI",{});var RLe=s(l2);Vde=n(RLe,"STRONG",{});var nst=s(Vde);hwo=r(nst,"electra"),nst.forEach(t),pwo=r(RLe," \u2014 "),qj=n(RLe,"A",{href:!0});var sst=s(qj);uwo=r(sst,"ElectraForCausalLM"),sst.forEach(t),_wo=r(RLe," (ELECTRA model)"),RLe.forEach(t),bwo=i(W),i2=n(W,"LI",{});var PLe=s(i2);Xde=n(PLe,"STRONG",{});var lst=s(Xde);vwo=r(lst,"gpt2"),lst.forEach(t),Fwo=r(PLe," \u2014 "),Nj=n(PLe,"A",{href:!0});var ist=s(Nj);Two=r(ist,"GPT2LMHeadModel"),ist.forEach(t),Mwo=r(PLe," (OpenAI GPT-2 model)"),PLe.forEach(t),Ewo=i(W),d2=n(W,"LI",{});var BLe=s(d2);zde=n(BLe,"STRONG",{});var dst=s(zde);Cwo=r(dst,"gpt_neo"),dst.forEach(t),wwo=r(BLe," \u2014 "),jj=n(BLe,"A",{href:!0});var cst=s(jj);Awo=r(cst,"GPTNeoForCausalLM"),cst.forEach(t),ywo=r(BLe," (GPT Neo model)"),BLe.forEach(t),Lwo=i(W),c2=n(W,"LI",{});var ILe=s(c2);Wde=n(ILe,"STRONG",{});var fst=s(Wde);xwo=r(fst,"gpt_neox"),fst.forEach(t),$wo=r(ILe," \u2014 "),Dj=n(ILe,"A",{href:!0});var mst=s(Dj);kwo=r(mst,"GPTNeoXForCausalLM"),mst.forEach(t),Swo=r(ILe," (GPT NeoX model)"),ILe.forEach(t),Rwo=i(W),f2=n(W,"LI",{});var qLe=s(f2);Qde=n(qLe,"STRONG",{});var gst=s(Qde);Pwo=r(gst,"gptj"),gst.forEach(t),Bwo=r(qLe," \u2014 "),Gj=n(qLe,"A",{href:!0});var hst=s(Gj);Iwo=r(hst,"GPTJForCausalLM"),hst.forEach(t),qwo=r(qLe," (GPT-J model)"),qLe.forEach(t),Nwo=i(W),m2=n(W,"LI",{});var NLe=s(m2);Hde=n(NLe,"STRONG",{});var pst=s(Hde);jwo=r(pst,"marian"),pst.forEach(t),Dwo=r(NLe," \u2014 "),Oj=n(NLe,"A",{href:!0});var ust=s(Oj);Gwo=r(ust,"MarianForCausalLM"),ust.forEach(t),Owo=r(NLe," (Marian model)"),NLe.forEach(t),Vwo=i(W),g2=n(W,"LI",{});var jLe=s(g2);Ude=n(jLe,"STRONG",{});var _st=s(Ude);Xwo=r(_st,"mbart"),_st.forEach(t),zwo=r(jLe," \u2014 "),Vj=n(jLe,"A",{href:!0});var bst=s(Vj);Wwo=r(bst,"MBartForCausalLM"),bst.forEach(t),Qwo=r(jLe," (mBART model)"),jLe.forEach(t),Hwo=i(W),h2=n(W,"LI",{});var DLe=s(h2);Jde=n(DLe,"STRONG",{});var vst=s(Jde);Uwo=r(vst,"megatron-bert"),vst.forEach(t),Jwo=r(DLe," \u2014 "),Xj=n(DLe,"A",{href:!0});var Fst=s(Xj);Ywo=r(Fst,"MegatronBertForCausalLM"),Fst.forEach(t),Kwo=r(DLe," (MegatronBert model)"),DLe.forEach(t),Zwo=i(W),p2=n(W,"LI",{});var GLe=s(p2);Yde=n(GLe,"STRONG",{});var Tst=s(Yde);e0o=r(Tst,"openai-gpt"),Tst.forEach(t),o0o=r(GLe," \u2014 "),zj=n(GLe,"A",{href:!0});var Mst=s(zj);r0o=r(Mst,"OpenAIGPTLMHeadModel"),Mst.forEach(t),t0o=r(GLe," (OpenAI GPT model)"),GLe.forEach(t),a0o=i(W),u2=n(W,"LI",{});var OLe=s(u2);Kde=n(OLe,"STRONG",{});var Est=s(Kde);n0o=r(Est,"opt"),Est.forEach(t),s0o=r(OLe," \u2014 "),Wj=n(OLe,"A",{href:!0});var Cst=s(Wj);l0o=r(Cst,"OPTForCausalLM"),Cst.forEach(t),i0o=r(OLe," (OPT model)"),OLe.forEach(t),d0o=i(W),_2=n(W,"LI",{});var VLe=s(_2);Zde=n(VLe,"STRONG",{});var wst=s(Zde);c0o=r(wst,"pegasus"),wst.forEach(t),f0o=r(VLe," \u2014 "),Qj=n(VLe,"A",{href:!0});var Ast=s(Qj);m0o=r(Ast,"PegasusForCausalLM"),Ast.forEach(t),g0o=r(VLe," (Pegasus model)"),VLe.forEach(t),h0o=i(W),b2=n(W,"LI",{});var XLe=s(b2);ece=n(XLe,"STRONG",{});var yst=s(ece);p0o=r(yst,"plbart"),yst.forEach(t),u0o=r(XLe," \u2014 "),Hj=n(XLe,"A",{href:!0});var Lst=s(Hj);_0o=r(Lst,"PLBartForCausalLM"),Lst.forEach(t),b0o=r(XLe," (PLBart model)"),XLe.forEach(t),v0o=i(W),v2=n(W,"LI",{});var zLe=s(v2);oce=n(zLe,"STRONG",{});var xst=s(oce);F0o=r(xst,"prophetnet"),xst.forEach(t),T0o=r(zLe," \u2014 "),Uj=n(zLe,"A",{href:!0});var $st=s(Uj);M0o=r($st,"ProphetNetForCausalLM"),$st.forEach(t),E0o=r(zLe," (ProphetNet model)"),zLe.forEach(t),C0o=i(W),F2=n(W,"LI",{});var WLe=s(F2);rce=n(WLe,"STRONG",{});var kst=s(rce);w0o=r(kst,"qdqbert"),kst.forEach(t),A0o=r(WLe," \u2014 "),Jj=n(WLe,"A",{href:!0});var Sst=s(Jj);y0o=r(Sst,"QDQBertLMHeadModel"),Sst.forEach(t),L0o=r(WLe," (QDQBert model)"),WLe.forEach(t),x0o=i(W),T2=n(W,"LI",{});var QLe=s(T2);tce=n(QLe,"STRONG",{});var Rst=s(tce);$0o=r(Rst,"reformer"),Rst.forEach(t),k0o=r(QLe," \u2014 "),Yj=n(QLe,"A",{href:!0});var Pst=s(Yj);S0o=r(Pst,"ReformerModelWithLMHead"),Pst.forEach(t),R0o=r(QLe," (Reformer model)"),QLe.forEach(t),P0o=i(W),M2=n(W,"LI",{});var HLe=s(M2);ace=n(HLe,"STRONG",{});var Bst=s(ace);B0o=r(Bst,"rembert"),Bst.forEach(t),I0o=r(HLe," \u2014 "),Kj=n(HLe,"A",{href:!0});var Ist=s(Kj);q0o=r(Ist,"RemBertForCausalLM"),Ist.forEach(t),N0o=r(HLe," (RemBERT model)"),HLe.forEach(t),j0o=i(W),E2=n(W,"LI",{});var ULe=s(E2);nce=n(ULe,"STRONG",{});var qst=s(nce);D0o=r(qst,"roberta"),qst.forEach(t),G0o=r(ULe," \u2014 "),Zj=n(ULe,"A",{href:!0});var Nst=s(Zj);O0o=r(Nst,"RobertaForCausalLM"),Nst.forEach(t),V0o=r(ULe," (RoBERTa model)"),ULe.forEach(t),X0o=i(W),C2=n(W,"LI",{});var JLe=s(C2);sce=n(JLe,"STRONG",{});var jst=s(sce);z0o=r(jst,"roformer"),jst.forEach(t),W0o=r(JLe," \u2014 "),eD=n(JLe,"A",{href:!0});var Dst=s(eD);Q0o=r(Dst,"RoFormerForCausalLM"),Dst.forEach(t),H0o=r(JLe," (RoFormer model)"),JLe.forEach(t),U0o=i(W),w2=n(W,"LI",{});var YLe=s(w2);lce=n(YLe,"STRONG",{});var Gst=s(lce);J0o=r(Gst,"speech_to_text_2"),Gst.forEach(t),Y0o=r(YLe," \u2014 "),oD=n(YLe,"A",{href:!0});var Ost=s(oD);K0o=r(Ost,"Speech2Text2ForCausalLM"),Ost.forEach(t),Z0o=r(YLe," (Speech2Text2 model)"),YLe.forEach(t),e6o=i(W),A2=n(W,"LI",{});var KLe=s(A2);ice=n(KLe,"STRONG",{});var Vst=s(ice);o6o=r(Vst,"transfo-xl"),Vst.forEach(t),r6o=r(KLe," \u2014 "),rD=n(KLe,"A",{href:!0});var Xst=s(rD);t6o=r(Xst,"TransfoXLLMHeadModel"),Xst.forEach(t),a6o=r(KLe," (Transformer-XL model)"),KLe.forEach(t),n6o=i(W),y2=n(W,"LI",{});var ZLe=s(y2);dce=n(ZLe,"STRONG",{});var zst=s(dce);s6o=r(zst,"trocr"),zst.forEach(t),l6o=r(ZLe," \u2014 "),tD=n(ZLe,"A",{href:!0});var Wst=s(tD);i6o=r(Wst,"TrOCRForCausalLM"),Wst.forEach(t),d6o=r(ZLe," (TrOCR model)"),ZLe.forEach(t),c6o=i(W),L2=n(W,"LI",{});var e8e=s(L2);cce=n(e8e,"STRONG",{});var Qst=s(cce);f6o=r(Qst,"xglm"),Qst.forEach(t),m6o=r(e8e," \u2014 "),aD=n(e8e,"A",{href:!0});var Hst=s(aD);g6o=r(Hst,"XGLMForCausalLM"),Hst.forEach(t),h6o=r(e8e," (XGLM model)"),e8e.forEach(t),p6o=i(W),x2=n(W,"LI",{});var o8e=s(x2);fce=n(o8e,"STRONG",{});var Ust=s(fce);u6o=r(Ust,"xlm"),Ust.forEach(t),_6o=r(o8e," \u2014 "),nD=n(o8e,"A",{href:!0});var Jst=s(nD);b6o=r(Jst,"XLMWithLMHeadModel"),Jst.forEach(t),v6o=r(o8e," (XLM model)"),o8e.forEach(t),F6o=i(W),$2=n(W,"LI",{});var r8e=s($2);mce=n(r8e,"STRONG",{});var Yst=s(mce);T6o=r(Yst,"xlm-prophetnet"),Yst.forEach(t),M6o=r(r8e," \u2014 "),sD=n(r8e,"A",{href:!0});var Kst=s(sD);E6o=r(Kst,"XLMProphetNetForCausalLM"),Kst.forEach(t),C6o=r(r8e," (XLMProphetNet model)"),r8e.forEach(t),w6o=i(W),k2=n(W,"LI",{});var t8e=s(k2);gce=n(t8e,"STRONG",{});var Zst=s(gce);A6o=r(Zst,"xlm-roberta"),Zst.forEach(t),y6o=r(t8e," \u2014 "),lD=n(t8e,"A",{href:!0});var elt=s(lD);L6o=r(elt,"XLMRobertaForCausalLM"),elt.forEach(t),x6o=r(t8e," (XLM-RoBERTa model)"),t8e.forEach(t),$6o=i(W),S2=n(W,"LI",{});var a8e=s(S2);hce=n(a8e,"STRONG",{});var olt=s(hce);k6o=r(olt,"xlm-roberta-xl"),olt.forEach(t),S6o=r(a8e," \u2014 "),iD=n(a8e,"A",{href:!0});var rlt=s(iD);R6o=r(rlt,"XLMRobertaXLForCausalLM"),rlt.forEach(t),P6o=r(a8e," (XLM-RoBERTa-XL model)"),a8e.forEach(t),B6o=i(W),R2=n(W,"LI",{});var n8e=s(R2);pce=n(n8e,"STRONG",{});var tlt=s(pce);I6o=r(tlt,"xlnet"),tlt.forEach(t),q6o=r(n8e," \u2014 "),dD=n(n8e,"A",{href:!0});var alt=s(dD);N6o=r(alt,"XLNetLMHeadModel"),alt.forEach(t),j6o=r(n8e," (XLNet model)"),n8e.forEach(t),W.forEach(t),D6o=i(ta),P2=n(ta,"P",{});var s8e=s(P2);G6o=r(s8e,"The model is set in evaluation mode by default using "),uce=n(s8e,"CODE",{});var nlt=s(uce);O6o=r(nlt,"model.eval()"),nlt.forEach(t),V6o=r(s8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_ce=n(s8e,"CODE",{});var slt=s(_ce);X6o=r(slt,"model.train()"),slt.forEach(t),s8e.forEach(t),z6o=i(ta),T(B2.$$.fragment,ta),ta.forEach(t),Ws.forEach(t),FNe=i(f),qi=n(f,"H2",{class:!0});var CDe=s(qi);I2=n(CDe,"A",{id:!0,class:!0,href:!0});var llt=s(I2);bce=n(llt,"SPAN",{});var ilt=s(bce);T(hy.$$.fragment,ilt),ilt.forEach(t),llt.forEach(t),W6o=i(CDe),vce=n(CDe,"SPAN",{});var dlt=s(vce);Q6o=r(dlt,"AutoModelForMaskedLM"),dlt.forEach(t),CDe.forEach(t),TNe=i(f),ko=n(f,"DIV",{class:!0});var Qs=s(ko);T(py.$$.fragment,Qs),H6o=i(Qs),Ni=n(Qs,"P",{});var yZ=s(Ni);U6o=r(yZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cD=n(yZ,"A",{href:!0});var clt=s(cD);J6o=r(clt,"from_pretrained()"),clt.forEach(t),Y6o=r(yZ," class method or the "),fD=n(yZ,"A",{href:!0});var flt=s(fD);K6o=r(flt,"from_config()"),flt.forEach(t),Z6o=r(yZ,` class
method.`),yZ.forEach(t),eAo=i(Qs),uy=n(Qs,"P",{});var wDe=s(uy);oAo=r(wDe,"This class cannot be instantiated directly using "),Fce=n(wDe,"CODE",{});var mlt=s(Fce);rAo=r(mlt,"__init__()"),mlt.forEach(t),tAo=r(wDe," (throws an error)."),wDe.forEach(t),aAo=i(Qs),st=n(Qs,"DIV",{class:!0});var q0=s(st);T(_y.$$.fragment,q0),nAo=i(q0),Tce=n(q0,"P",{});var glt=s(Tce);sAo=r(glt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),glt.forEach(t),lAo=i(q0),ji=n(q0,"P",{});var LZ=s(ji);iAo=r(LZ,`Note:
Loading a model from its configuration file does `),Mce=n(LZ,"STRONG",{});var hlt=s(Mce);dAo=r(hlt,"not"),hlt.forEach(t),cAo=r(LZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),mD=n(LZ,"A",{href:!0});var plt=s(mD);fAo=r(plt,"from_pretrained()"),plt.forEach(t),mAo=r(LZ," to load the model weights."),LZ.forEach(t),gAo=i(q0),T(q2.$$.fragment,q0),q0.forEach(t),hAo=i(Qs),Ze=n(Qs,"DIV",{class:!0});var aa=s(Ze);T(by.$$.fragment,aa),pAo=i(aa),Ece=n(aa,"P",{});var ult=s(Ece);uAo=r(ult,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ult.forEach(t),_Ao=i(aa),ka=n(aa,"P",{});var N0=s(ka);bAo=r(N0,"The model class to instantiate is selected based on the "),Cce=n(N0,"CODE",{});var _lt=s(Cce);vAo=r(_lt,"model_type"),_lt.forEach(t),FAo=r(N0,` property of the config object (either
passed as an argument or loaded from `),wce=n(N0,"CODE",{});var blt=s(wce);TAo=r(blt,"pretrained_model_name_or_path"),blt.forEach(t),MAo=r(N0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ace=n(N0,"CODE",{});var vlt=s(Ace);EAo=r(vlt,"pretrained_model_name_or_path"),vlt.forEach(t),CAo=r(N0,":"),N0.forEach(t),wAo=i(aa),Q=n(aa,"UL",{});var U=s(Q);N2=n(U,"LI",{});var l8e=s(N2);yce=n(l8e,"STRONG",{});var Flt=s(yce);AAo=r(Flt,"albert"),Flt.forEach(t),yAo=r(l8e," \u2014 "),gD=n(l8e,"A",{href:!0});var Tlt=s(gD);LAo=r(Tlt,"AlbertForMaskedLM"),Tlt.forEach(t),xAo=r(l8e," (ALBERT model)"),l8e.forEach(t),$Ao=i(U),j2=n(U,"LI",{});var i8e=s(j2);Lce=n(i8e,"STRONG",{});var Mlt=s(Lce);kAo=r(Mlt,"bart"),Mlt.forEach(t),SAo=r(i8e," \u2014 "),hD=n(i8e,"A",{href:!0});var Elt=s(hD);RAo=r(Elt,"BartForConditionalGeneration"),Elt.forEach(t),PAo=r(i8e," (BART model)"),i8e.forEach(t),BAo=i(U),D2=n(U,"LI",{});var d8e=s(D2);xce=n(d8e,"STRONG",{});var Clt=s(xce);IAo=r(Clt,"bert"),Clt.forEach(t),qAo=r(d8e," \u2014 "),pD=n(d8e,"A",{href:!0});var wlt=s(pD);NAo=r(wlt,"BertForMaskedLM"),wlt.forEach(t),jAo=r(d8e," (BERT model)"),d8e.forEach(t),DAo=i(U),G2=n(U,"LI",{});var c8e=s(G2);$ce=n(c8e,"STRONG",{});var Alt=s($ce);GAo=r(Alt,"big_bird"),Alt.forEach(t),OAo=r(c8e," \u2014 "),uD=n(c8e,"A",{href:!0});var ylt=s(uD);VAo=r(ylt,"BigBirdForMaskedLM"),ylt.forEach(t),XAo=r(c8e," (BigBird model)"),c8e.forEach(t),zAo=i(U),O2=n(U,"LI",{});var f8e=s(O2);kce=n(f8e,"STRONG",{});var Llt=s(kce);WAo=r(Llt,"camembert"),Llt.forEach(t),QAo=r(f8e," \u2014 "),_D=n(f8e,"A",{href:!0});var xlt=s(_D);HAo=r(xlt,"CamembertForMaskedLM"),xlt.forEach(t),UAo=r(f8e," (CamemBERT model)"),f8e.forEach(t),JAo=i(U),V2=n(U,"LI",{});var m8e=s(V2);Sce=n(m8e,"STRONG",{});var $lt=s(Sce);YAo=r($lt,"convbert"),$lt.forEach(t),KAo=r(m8e," \u2014 "),bD=n(m8e,"A",{href:!0});var klt=s(bD);ZAo=r(klt,"ConvBertForMaskedLM"),klt.forEach(t),eyo=r(m8e," (ConvBERT model)"),m8e.forEach(t),oyo=i(U),X2=n(U,"LI",{});var g8e=s(X2);Rce=n(g8e,"STRONG",{});var Slt=s(Rce);ryo=r(Slt,"data2vec-text"),Slt.forEach(t),tyo=r(g8e," \u2014 "),vD=n(g8e,"A",{href:!0});var Rlt=s(vD);ayo=r(Rlt,"Data2VecTextForMaskedLM"),Rlt.forEach(t),nyo=r(g8e," (Data2VecText model)"),g8e.forEach(t),syo=i(U),z2=n(U,"LI",{});var h8e=s(z2);Pce=n(h8e,"STRONG",{});var Plt=s(Pce);lyo=r(Plt,"deberta"),Plt.forEach(t),iyo=r(h8e," \u2014 "),FD=n(h8e,"A",{href:!0});var Blt=s(FD);dyo=r(Blt,"DebertaForMaskedLM"),Blt.forEach(t),cyo=r(h8e," (DeBERTa model)"),h8e.forEach(t),fyo=i(U),W2=n(U,"LI",{});var p8e=s(W2);Bce=n(p8e,"STRONG",{});var Ilt=s(Bce);myo=r(Ilt,"deberta-v2"),Ilt.forEach(t),gyo=r(p8e," \u2014 "),TD=n(p8e,"A",{href:!0});var qlt=s(TD);hyo=r(qlt,"DebertaV2ForMaskedLM"),qlt.forEach(t),pyo=r(p8e," (DeBERTa-v2 model)"),p8e.forEach(t),uyo=i(U),Q2=n(U,"LI",{});var u8e=s(Q2);Ice=n(u8e,"STRONG",{});var Nlt=s(Ice);_yo=r(Nlt,"distilbert"),Nlt.forEach(t),byo=r(u8e," \u2014 "),MD=n(u8e,"A",{href:!0});var jlt=s(MD);vyo=r(jlt,"DistilBertForMaskedLM"),jlt.forEach(t),Fyo=r(u8e," (DistilBERT model)"),u8e.forEach(t),Tyo=i(U),H2=n(U,"LI",{});var _8e=s(H2);qce=n(_8e,"STRONG",{});var Dlt=s(qce);Myo=r(Dlt,"electra"),Dlt.forEach(t),Eyo=r(_8e," \u2014 "),ED=n(_8e,"A",{href:!0});var Glt=s(ED);Cyo=r(Glt,"ElectraForMaskedLM"),Glt.forEach(t),wyo=r(_8e," (ELECTRA model)"),_8e.forEach(t),Ayo=i(U),U2=n(U,"LI",{});var b8e=s(U2);Nce=n(b8e,"STRONG",{});var Olt=s(Nce);yyo=r(Olt,"flaubert"),Olt.forEach(t),Lyo=r(b8e," \u2014 "),CD=n(b8e,"A",{href:!0});var Vlt=s(CD);xyo=r(Vlt,"FlaubertWithLMHeadModel"),Vlt.forEach(t),$yo=r(b8e," (FlauBERT model)"),b8e.forEach(t),kyo=i(U),J2=n(U,"LI",{});var v8e=s(J2);jce=n(v8e,"STRONG",{});var Xlt=s(jce);Syo=r(Xlt,"fnet"),Xlt.forEach(t),Ryo=r(v8e," \u2014 "),wD=n(v8e,"A",{href:!0});var zlt=s(wD);Pyo=r(zlt,"FNetForMaskedLM"),zlt.forEach(t),Byo=r(v8e," (FNet model)"),v8e.forEach(t),Iyo=i(U),Y2=n(U,"LI",{});var F8e=s(Y2);Dce=n(F8e,"STRONG",{});var Wlt=s(Dce);qyo=r(Wlt,"funnel"),Wlt.forEach(t),Nyo=r(F8e," \u2014 "),AD=n(F8e,"A",{href:!0});var Qlt=s(AD);jyo=r(Qlt,"FunnelForMaskedLM"),Qlt.forEach(t),Dyo=r(F8e," (Funnel Transformer model)"),F8e.forEach(t),Gyo=i(U),K2=n(U,"LI",{});var T8e=s(K2);Gce=n(T8e,"STRONG",{});var Hlt=s(Gce);Oyo=r(Hlt,"ibert"),Hlt.forEach(t),Vyo=r(T8e," \u2014 "),yD=n(T8e,"A",{href:!0});var Ult=s(yD);Xyo=r(Ult,"IBertForMaskedLM"),Ult.forEach(t),zyo=r(T8e," (I-BERT model)"),T8e.forEach(t),Wyo=i(U),Z2=n(U,"LI",{});var M8e=s(Z2);Oce=n(M8e,"STRONG",{});var Jlt=s(Oce);Qyo=r(Jlt,"layoutlm"),Jlt.forEach(t),Hyo=r(M8e," \u2014 "),LD=n(M8e,"A",{href:!0});var Ylt=s(LD);Uyo=r(Ylt,"LayoutLMForMaskedLM"),Ylt.forEach(t),Jyo=r(M8e," (LayoutLM model)"),M8e.forEach(t),Yyo=i(U),e1=n(U,"LI",{});var E8e=s(e1);Vce=n(E8e,"STRONG",{});var Klt=s(Vce);Kyo=r(Klt,"longformer"),Klt.forEach(t),Zyo=r(E8e," \u2014 "),xD=n(E8e,"A",{href:!0});var Zlt=s(xD);eLo=r(Zlt,"LongformerForMaskedLM"),Zlt.forEach(t),oLo=r(E8e," (Longformer model)"),E8e.forEach(t),rLo=i(U),o1=n(U,"LI",{});var C8e=s(o1);Xce=n(C8e,"STRONG",{});var eit=s(Xce);tLo=r(eit,"mbart"),eit.forEach(t),aLo=r(C8e," \u2014 "),$D=n(C8e,"A",{href:!0});var oit=s($D);nLo=r(oit,"MBartForConditionalGeneration"),oit.forEach(t),sLo=r(C8e," (mBART model)"),C8e.forEach(t),lLo=i(U),r1=n(U,"LI",{});var w8e=s(r1);zce=n(w8e,"STRONG",{});var rit=s(zce);iLo=r(rit,"megatron-bert"),rit.forEach(t),dLo=r(w8e," \u2014 "),kD=n(w8e,"A",{href:!0});var tit=s(kD);cLo=r(tit,"MegatronBertForMaskedLM"),tit.forEach(t),fLo=r(w8e," (MegatronBert model)"),w8e.forEach(t),mLo=i(U),t1=n(U,"LI",{});var A8e=s(t1);Wce=n(A8e,"STRONG",{});var ait=s(Wce);gLo=r(ait,"mobilebert"),ait.forEach(t),hLo=r(A8e," \u2014 "),SD=n(A8e,"A",{href:!0});var nit=s(SD);pLo=r(nit,"MobileBertForMaskedLM"),nit.forEach(t),uLo=r(A8e," (MobileBERT model)"),A8e.forEach(t),_Lo=i(U),a1=n(U,"LI",{});var y8e=s(a1);Qce=n(y8e,"STRONG",{});var sit=s(Qce);bLo=r(sit,"mpnet"),sit.forEach(t),vLo=r(y8e," \u2014 "),RD=n(y8e,"A",{href:!0});var lit=s(RD);FLo=r(lit,"MPNetForMaskedLM"),lit.forEach(t),TLo=r(y8e," (MPNet model)"),y8e.forEach(t),MLo=i(U),n1=n(U,"LI",{});var L8e=s(n1);Hce=n(L8e,"STRONG",{});var iit=s(Hce);ELo=r(iit,"nystromformer"),iit.forEach(t),CLo=r(L8e," \u2014 "),PD=n(L8e,"A",{href:!0});var dit=s(PD);wLo=r(dit,"NystromformerForMaskedLM"),dit.forEach(t),ALo=r(L8e," (Nystromformer model)"),L8e.forEach(t),yLo=i(U),s1=n(U,"LI",{});var x8e=s(s1);Uce=n(x8e,"STRONG",{});var cit=s(Uce);LLo=r(cit,"perceiver"),cit.forEach(t),xLo=r(x8e," \u2014 "),BD=n(x8e,"A",{href:!0});var fit=s(BD);$Lo=r(fit,"PerceiverForMaskedLM"),fit.forEach(t),kLo=r(x8e," (Perceiver model)"),x8e.forEach(t),SLo=i(U),l1=n(U,"LI",{});var $8e=s(l1);Jce=n($8e,"STRONG",{});var mit=s(Jce);RLo=r(mit,"qdqbert"),mit.forEach(t),PLo=r($8e," \u2014 "),ID=n($8e,"A",{href:!0});var git=s(ID);BLo=r(git,"QDQBertForMaskedLM"),git.forEach(t),ILo=r($8e," (QDQBert model)"),$8e.forEach(t),qLo=i(U),i1=n(U,"LI",{});var k8e=s(i1);Yce=n(k8e,"STRONG",{});var hit=s(Yce);NLo=r(hit,"reformer"),hit.forEach(t),jLo=r(k8e," \u2014 "),qD=n(k8e,"A",{href:!0});var pit=s(qD);DLo=r(pit,"ReformerForMaskedLM"),pit.forEach(t),GLo=r(k8e," (Reformer model)"),k8e.forEach(t),OLo=i(U),d1=n(U,"LI",{});var S8e=s(d1);Kce=n(S8e,"STRONG",{});var uit=s(Kce);VLo=r(uit,"rembert"),uit.forEach(t),XLo=r(S8e," \u2014 "),ND=n(S8e,"A",{href:!0});var _it=s(ND);zLo=r(_it,"RemBertForMaskedLM"),_it.forEach(t),WLo=r(S8e," (RemBERT model)"),S8e.forEach(t),QLo=i(U),c1=n(U,"LI",{});var R8e=s(c1);Zce=n(R8e,"STRONG",{});var bit=s(Zce);HLo=r(bit,"roberta"),bit.forEach(t),ULo=r(R8e," \u2014 "),jD=n(R8e,"A",{href:!0});var vit=s(jD);JLo=r(vit,"RobertaForMaskedLM"),vit.forEach(t),YLo=r(R8e," (RoBERTa model)"),R8e.forEach(t),KLo=i(U),f1=n(U,"LI",{});var P8e=s(f1);efe=n(P8e,"STRONG",{});var Fit=s(efe);ZLo=r(Fit,"roformer"),Fit.forEach(t),e8o=r(P8e," \u2014 "),DD=n(P8e,"A",{href:!0});var Tit=s(DD);o8o=r(Tit,"RoFormerForMaskedLM"),Tit.forEach(t),r8o=r(P8e," (RoFormer model)"),P8e.forEach(t),t8o=i(U),m1=n(U,"LI",{});var B8e=s(m1);ofe=n(B8e,"STRONG",{});var Mit=s(ofe);a8o=r(Mit,"squeezebert"),Mit.forEach(t),n8o=r(B8e," \u2014 "),GD=n(B8e,"A",{href:!0});var Eit=s(GD);s8o=r(Eit,"SqueezeBertForMaskedLM"),Eit.forEach(t),l8o=r(B8e," (SqueezeBERT model)"),B8e.forEach(t),i8o=i(U),g1=n(U,"LI",{});var I8e=s(g1);rfe=n(I8e,"STRONG",{});var Cit=s(rfe);d8o=r(Cit,"tapas"),Cit.forEach(t),c8o=r(I8e," \u2014 "),OD=n(I8e,"A",{href:!0});var wit=s(OD);f8o=r(wit,"TapasForMaskedLM"),wit.forEach(t),m8o=r(I8e," (TAPAS model)"),I8e.forEach(t),g8o=i(U),h1=n(U,"LI",{});var q8e=s(h1);tfe=n(q8e,"STRONG",{});var Ait=s(tfe);h8o=r(Ait,"wav2vec2"),Ait.forEach(t),p8o=r(q8e," \u2014 "),afe=n(q8e,"CODE",{});var yit=s(afe);u8o=r(yit,"Wav2Vec2ForMaskedLM"),yit.forEach(t),_8o=r(q8e," (Wav2Vec2 model)"),q8e.forEach(t),b8o=i(U),p1=n(U,"LI",{});var N8e=s(p1);nfe=n(N8e,"STRONG",{});var Lit=s(nfe);v8o=r(Lit,"xlm"),Lit.forEach(t),F8o=r(N8e," \u2014 "),VD=n(N8e,"A",{href:!0});var xit=s(VD);T8o=r(xit,"XLMWithLMHeadModel"),xit.forEach(t),M8o=r(N8e," (XLM model)"),N8e.forEach(t),E8o=i(U),u1=n(U,"LI",{});var j8e=s(u1);sfe=n(j8e,"STRONG",{});var $it=s(sfe);C8o=r($it,"xlm-roberta"),$it.forEach(t),w8o=r(j8e," \u2014 "),XD=n(j8e,"A",{href:!0});var kit=s(XD);A8o=r(kit,"XLMRobertaForMaskedLM"),kit.forEach(t),y8o=r(j8e," (XLM-RoBERTa model)"),j8e.forEach(t),L8o=i(U),_1=n(U,"LI",{});var D8e=s(_1);lfe=n(D8e,"STRONG",{});var Sit=s(lfe);x8o=r(Sit,"xlm-roberta-xl"),Sit.forEach(t),$8o=r(D8e," \u2014 "),zD=n(D8e,"A",{href:!0});var Rit=s(zD);k8o=r(Rit,"XLMRobertaXLForMaskedLM"),Rit.forEach(t),S8o=r(D8e," (XLM-RoBERTa-XL model)"),D8e.forEach(t),R8o=i(U),b1=n(U,"LI",{});var G8e=s(b1);ife=n(G8e,"STRONG",{});var Pit=s(ife);P8o=r(Pit,"yoso"),Pit.forEach(t),B8o=r(G8e," \u2014 "),WD=n(G8e,"A",{href:!0});var Bit=s(WD);I8o=r(Bit,"YosoForMaskedLM"),Bit.forEach(t),q8o=r(G8e," (YOSO model)"),G8e.forEach(t),U.forEach(t),N8o=i(aa),v1=n(aa,"P",{});var O8e=s(v1);j8o=r(O8e,"The model is set in evaluation mode by default using "),dfe=n(O8e,"CODE",{});var Iit=s(dfe);D8o=r(Iit,"model.eval()"),Iit.forEach(t),G8o=r(O8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cfe=n(O8e,"CODE",{});var qit=s(cfe);O8o=r(qit,"model.train()"),qit.forEach(t),O8e.forEach(t),V8o=i(aa),T(F1.$$.fragment,aa),aa.forEach(t),Qs.forEach(t),MNe=i(f),Di=n(f,"H2",{class:!0});var ADe=s(Di);T1=n(ADe,"A",{id:!0,class:!0,href:!0});var Nit=s(T1);ffe=n(Nit,"SPAN",{});var jit=s(ffe);T(vy.$$.fragment,jit),jit.forEach(t),Nit.forEach(t),X8o=i(ADe),mfe=n(ADe,"SPAN",{});var Dit=s(mfe);z8o=r(Dit,"AutoModelForSeq2SeqLM"),Dit.forEach(t),ADe.forEach(t),ENe=i(f),So=n(f,"DIV",{class:!0});var Hs=s(So);T(Fy.$$.fragment,Hs),W8o=i(Hs),Gi=n(Hs,"P",{});var xZ=s(Gi);Q8o=r(xZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),QD=n(xZ,"A",{href:!0});var Git=s(QD);H8o=r(Git,"from_pretrained()"),Git.forEach(t),U8o=r(xZ," class method or the "),HD=n(xZ,"A",{href:!0});var Oit=s(HD);J8o=r(Oit,"from_config()"),Oit.forEach(t),Y8o=r(xZ,` class
method.`),xZ.forEach(t),K8o=i(Hs),Ty=n(Hs,"P",{});var yDe=s(Ty);Z8o=r(yDe,"This class cannot be instantiated directly using "),gfe=n(yDe,"CODE",{});var Vit=s(gfe);e9o=r(Vit,"__init__()"),Vit.forEach(t),o9o=r(yDe," (throws an error)."),yDe.forEach(t),r9o=i(Hs),lt=n(Hs,"DIV",{class:!0});var j0=s(lt);T(My.$$.fragment,j0),t9o=i(j0),hfe=n(j0,"P",{});var Xit=s(hfe);a9o=r(Xit,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Xit.forEach(t),n9o=i(j0),Oi=n(j0,"P",{});var $Z=s(Oi);s9o=r($Z,`Note:
Loading a model from its configuration file does `),pfe=n($Z,"STRONG",{});var zit=s(pfe);l9o=r(zit,"not"),zit.forEach(t),i9o=r($Z,` load the model weights. It only affects the
model\u2019s configuration. Use `),UD=n($Z,"A",{href:!0});var Wit=s(UD);d9o=r(Wit,"from_pretrained()"),Wit.forEach(t),c9o=r($Z," to load the model weights."),$Z.forEach(t),f9o=i(j0),T(M1.$$.fragment,j0),j0.forEach(t),m9o=i(Hs),eo=n(Hs,"DIV",{class:!0});var na=s(eo);T(Ey.$$.fragment,na),g9o=i(na),ufe=n(na,"P",{});var Qit=s(ufe);h9o=r(Qit,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Qit.forEach(t),p9o=i(na),Sa=n(na,"P",{});var D0=s(Sa);u9o=r(D0,"The model class to instantiate is selected based on the "),_fe=n(D0,"CODE",{});var Hit=s(_fe);_9o=r(Hit,"model_type"),Hit.forEach(t),b9o=r(D0,` property of the config object (either
passed as an argument or loaded from `),bfe=n(D0,"CODE",{});var Uit=s(bfe);v9o=r(Uit,"pretrained_model_name_or_path"),Uit.forEach(t),F9o=r(D0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vfe=n(D0,"CODE",{});var Jit=s(vfe);T9o=r(Jit,"pretrained_model_name_or_path"),Jit.forEach(t),M9o=r(D0,":"),D0.forEach(t),E9o=i(na),ue=n(na,"UL",{});var ve=s(ue);E1=n(ve,"LI",{});var V8e=s(E1);Ffe=n(V8e,"STRONG",{});var Yit=s(Ffe);C9o=r(Yit,"bart"),Yit.forEach(t),w9o=r(V8e," \u2014 "),JD=n(V8e,"A",{href:!0});var Kit=s(JD);A9o=r(Kit,"BartForConditionalGeneration"),Kit.forEach(t),y9o=r(V8e," (BART model)"),V8e.forEach(t),L9o=i(ve),C1=n(ve,"LI",{});var X8e=s(C1);Tfe=n(X8e,"STRONG",{});var Zit=s(Tfe);x9o=r(Zit,"bigbird_pegasus"),Zit.forEach(t),$9o=r(X8e," \u2014 "),YD=n(X8e,"A",{href:!0});var edt=s(YD);k9o=r(edt,"BigBirdPegasusForConditionalGeneration"),edt.forEach(t),S9o=r(X8e," (BigBirdPegasus model)"),X8e.forEach(t),R9o=i(ve),w1=n(ve,"LI",{});var z8e=s(w1);Mfe=n(z8e,"STRONG",{});var odt=s(Mfe);P9o=r(odt,"blenderbot"),odt.forEach(t),B9o=r(z8e," \u2014 "),KD=n(z8e,"A",{href:!0});var rdt=s(KD);I9o=r(rdt,"BlenderbotForConditionalGeneration"),rdt.forEach(t),q9o=r(z8e," (Blenderbot model)"),z8e.forEach(t),N9o=i(ve),A1=n(ve,"LI",{});var W8e=s(A1);Efe=n(W8e,"STRONG",{});var tdt=s(Efe);j9o=r(tdt,"blenderbot-small"),tdt.forEach(t),D9o=r(W8e," \u2014 "),ZD=n(W8e,"A",{href:!0});var adt=s(ZD);G9o=r(adt,"BlenderbotSmallForConditionalGeneration"),adt.forEach(t),O9o=r(W8e," (BlenderbotSmall model)"),W8e.forEach(t),V9o=i(ve),y1=n(ve,"LI",{});var Q8e=s(y1);Cfe=n(Q8e,"STRONG",{});var ndt=s(Cfe);X9o=r(ndt,"encoder-decoder"),ndt.forEach(t),z9o=r(Q8e," \u2014 "),eG=n(Q8e,"A",{href:!0});var sdt=s(eG);W9o=r(sdt,"EncoderDecoderModel"),sdt.forEach(t),Q9o=r(Q8e," (Encoder decoder model)"),Q8e.forEach(t),H9o=i(ve),L1=n(ve,"LI",{});var H8e=s(L1);wfe=n(H8e,"STRONG",{});var ldt=s(wfe);U9o=r(ldt,"fsmt"),ldt.forEach(t),J9o=r(H8e," \u2014 "),oG=n(H8e,"A",{href:!0});var idt=s(oG);Y9o=r(idt,"FSMTForConditionalGeneration"),idt.forEach(t),K9o=r(H8e," (FairSeq Machine-Translation model)"),H8e.forEach(t),Z9o=i(ve),x1=n(ve,"LI",{});var U8e=s(x1);Afe=n(U8e,"STRONG",{});var ddt=s(Afe);exo=r(ddt,"led"),ddt.forEach(t),oxo=r(U8e," \u2014 "),rG=n(U8e,"A",{href:!0});var cdt=s(rG);rxo=r(cdt,"LEDForConditionalGeneration"),cdt.forEach(t),txo=r(U8e," (LED model)"),U8e.forEach(t),axo=i(ve),$1=n(ve,"LI",{});var J8e=s($1);yfe=n(J8e,"STRONG",{});var fdt=s(yfe);nxo=r(fdt,"m2m_100"),fdt.forEach(t),sxo=r(J8e," \u2014 "),tG=n(J8e,"A",{href:!0});var mdt=s(tG);lxo=r(mdt,"M2M100ForConditionalGeneration"),mdt.forEach(t),ixo=r(J8e," (M2M100 model)"),J8e.forEach(t),dxo=i(ve),k1=n(ve,"LI",{});var Y8e=s(k1);Lfe=n(Y8e,"STRONG",{});var gdt=s(Lfe);cxo=r(gdt,"marian"),gdt.forEach(t),fxo=r(Y8e," \u2014 "),aG=n(Y8e,"A",{href:!0});var hdt=s(aG);mxo=r(hdt,"MarianMTModel"),hdt.forEach(t),gxo=r(Y8e," (Marian model)"),Y8e.forEach(t),hxo=i(ve),S1=n(ve,"LI",{});var K8e=s(S1);xfe=n(K8e,"STRONG",{});var pdt=s(xfe);pxo=r(pdt,"mbart"),pdt.forEach(t),uxo=r(K8e," \u2014 "),nG=n(K8e,"A",{href:!0});var udt=s(nG);_xo=r(udt,"MBartForConditionalGeneration"),udt.forEach(t),bxo=r(K8e," (mBART model)"),K8e.forEach(t),vxo=i(ve),R1=n(ve,"LI",{});var Z8e=s(R1);$fe=n(Z8e,"STRONG",{});var _dt=s($fe);Fxo=r(_dt,"mt5"),_dt.forEach(t),Txo=r(Z8e," \u2014 "),sG=n(Z8e,"A",{href:!0});var bdt=s(sG);Mxo=r(bdt,"MT5ForConditionalGeneration"),bdt.forEach(t),Exo=r(Z8e," (mT5 model)"),Z8e.forEach(t),Cxo=i(ve),P1=n(ve,"LI",{});var e9e=s(P1);kfe=n(e9e,"STRONG",{});var vdt=s(kfe);wxo=r(vdt,"pegasus"),vdt.forEach(t),Axo=r(e9e," \u2014 "),lG=n(e9e,"A",{href:!0});var Fdt=s(lG);yxo=r(Fdt,"PegasusForConditionalGeneration"),Fdt.forEach(t),Lxo=r(e9e," (Pegasus model)"),e9e.forEach(t),xxo=i(ve),B1=n(ve,"LI",{});var o9e=s(B1);Sfe=n(o9e,"STRONG",{});var Tdt=s(Sfe);$xo=r(Tdt,"plbart"),Tdt.forEach(t),kxo=r(o9e," \u2014 "),iG=n(o9e,"A",{href:!0});var Mdt=s(iG);Sxo=r(Mdt,"PLBartForConditionalGeneration"),Mdt.forEach(t),Rxo=r(o9e," (PLBart model)"),o9e.forEach(t),Pxo=i(ve),I1=n(ve,"LI",{});var r9e=s(I1);Rfe=n(r9e,"STRONG",{});var Edt=s(Rfe);Bxo=r(Edt,"prophetnet"),Edt.forEach(t),Ixo=r(r9e," \u2014 "),dG=n(r9e,"A",{href:!0});var Cdt=s(dG);qxo=r(Cdt,"ProphetNetForConditionalGeneration"),Cdt.forEach(t),Nxo=r(r9e," (ProphetNet model)"),r9e.forEach(t),jxo=i(ve),q1=n(ve,"LI",{});var t9e=s(q1);Pfe=n(t9e,"STRONG",{});var wdt=s(Pfe);Dxo=r(wdt,"t5"),wdt.forEach(t),Gxo=r(t9e," \u2014 "),cG=n(t9e,"A",{href:!0});var Adt=s(cG);Oxo=r(Adt,"T5ForConditionalGeneration"),Adt.forEach(t),Vxo=r(t9e," (T5 model)"),t9e.forEach(t),Xxo=i(ve),N1=n(ve,"LI",{});var a9e=s(N1);Bfe=n(a9e,"STRONG",{});var ydt=s(Bfe);zxo=r(ydt,"xlm-prophetnet"),ydt.forEach(t),Wxo=r(a9e," \u2014 "),fG=n(a9e,"A",{href:!0});var Ldt=s(fG);Qxo=r(Ldt,"XLMProphetNetForConditionalGeneration"),Ldt.forEach(t),Hxo=r(a9e," (XLMProphetNet model)"),a9e.forEach(t),ve.forEach(t),Uxo=i(na),j1=n(na,"P",{});var n9e=s(j1);Jxo=r(n9e,"The model is set in evaluation mode by default using "),Ife=n(n9e,"CODE",{});var xdt=s(Ife);Yxo=r(xdt,"model.eval()"),xdt.forEach(t),Kxo=r(n9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qfe=n(n9e,"CODE",{});var $dt=s(qfe);Zxo=r($dt,"model.train()"),$dt.forEach(t),n9e.forEach(t),e$o=i(na),T(D1.$$.fragment,na),na.forEach(t),Hs.forEach(t),CNe=i(f),Vi=n(f,"H2",{class:!0});var LDe=s(Vi);G1=n(LDe,"A",{id:!0,class:!0,href:!0});var kdt=s(G1);Nfe=n(kdt,"SPAN",{});var Sdt=s(Nfe);T(Cy.$$.fragment,Sdt),Sdt.forEach(t),kdt.forEach(t),o$o=i(LDe),jfe=n(LDe,"SPAN",{});var Rdt=s(jfe);r$o=r(Rdt,"AutoModelForSequenceClassification"),Rdt.forEach(t),LDe.forEach(t),wNe=i(f),Ro=n(f,"DIV",{class:!0});var Us=s(Ro);T(wy.$$.fragment,Us),t$o=i(Us),Xi=n(Us,"P",{});var kZ=s(Xi);a$o=r(kZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),mG=n(kZ,"A",{href:!0});var Pdt=s(mG);n$o=r(Pdt,"from_pretrained()"),Pdt.forEach(t),s$o=r(kZ," class method or the "),gG=n(kZ,"A",{href:!0});var Bdt=s(gG);l$o=r(Bdt,"from_config()"),Bdt.forEach(t),i$o=r(kZ,` class
method.`),kZ.forEach(t),d$o=i(Us),Ay=n(Us,"P",{});var xDe=s(Ay);c$o=r(xDe,"This class cannot be instantiated directly using "),Dfe=n(xDe,"CODE",{});var Idt=s(Dfe);f$o=r(Idt,"__init__()"),Idt.forEach(t),m$o=r(xDe," (throws an error)."),xDe.forEach(t),g$o=i(Us),it=n(Us,"DIV",{class:!0});var G0=s(it);T(yy.$$.fragment,G0),h$o=i(G0),Gfe=n(G0,"P",{});var qdt=s(Gfe);p$o=r(qdt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),qdt.forEach(t),u$o=i(G0),zi=n(G0,"P",{});var SZ=s(zi);_$o=r(SZ,`Note:
Loading a model from its configuration file does `),Ofe=n(SZ,"STRONG",{});var Ndt=s(Ofe);b$o=r(Ndt,"not"),Ndt.forEach(t),v$o=r(SZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hG=n(SZ,"A",{href:!0});var jdt=s(hG);F$o=r(jdt,"from_pretrained()"),jdt.forEach(t),T$o=r(SZ," to load the model weights."),SZ.forEach(t),M$o=i(G0),T(O1.$$.fragment,G0),G0.forEach(t),E$o=i(Us),oo=n(Us,"DIV",{class:!0});var sa=s(oo);T(Ly.$$.fragment,sa),C$o=i(sa),Vfe=n(sa,"P",{});var Ddt=s(Vfe);w$o=r(Ddt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ddt.forEach(t),A$o=i(sa),Ra=n(sa,"P",{});var O0=s(Ra);y$o=r(O0,"The model class to instantiate is selected based on the "),Xfe=n(O0,"CODE",{});var Gdt=s(Xfe);L$o=r(Gdt,"model_type"),Gdt.forEach(t),x$o=r(O0,` property of the config object (either
passed as an argument or loaded from `),zfe=n(O0,"CODE",{});var Odt=s(zfe);$$o=r(Odt,"pretrained_model_name_or_path"),Odt.forEach(t),k$o=r(O0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wfe=n(O0,"CODE",{});var Vdt=s(Wfe);S$o=r(Vdt,"pretrained_model_name_or_path"),Vdt.forEach(t),R$o=r(O0,":"),O0.forEach(t),P$o=i(sa),q=n(sa,"UL",{});var j=s(q);V1=n(j,"LI",{});var s9e=s(V1);Qfe=n(s9e,"STRONG",{});var Xdt=s(Qfe);B$o=r(Xdt,"albert"),Xdt.forEach(t),I$o=r(s9e," \u2014 "),pG=n(s9e,"A",{href:!0});var zdt=s(pG);q$o=r(zdt,"AlbertForSequenceClassification"),zdt.forEach(t),N$o=r(s9e," (ALBERT model)"),s9e.forEach(t),j$o=i(j),X1=n(j,"LI",{});var l9e=s(X1);Hfe=n(l9e,"STRONG",{});var Wdt=s(Hfe);D$o=r(Wdt,"bart"),Wdt.forEach(t),G$o=r(l9e," \u2014 "),uG=n(l9e,"A",{href:!0});var Qdt=s(uG);O$o=r(Qdt,"BartForSequenceClassification"),Qdt.forEach(t),V$o=r(l9e," (BART model)"),l9e.forEach(t),X$o=i(j),z1=n(j,"LI",{});var i9e=s(z1);Ufe=n(i9e,"STRONG",{});var Hdt=s(Ufe);z$o=r(Hdt,"bert"),Hdt.forEach(t),W$o=r(i9e," \u2014 "),_G=n(i9e,"A",{href:!0});var Udt=s(_G);Q$o=r(Udt,"BertForSequenceClassification"),Udt.forEach(t),H$o=r(i9e," (BERT model)"),i9e.forEach(t),U$o=i(j),W1=n(j,"LI",{});var d9e=s(W1);Jfe=n(d9e,"STRONG",{});var Jdt=s(Jfe);J$o=r(Jdt,"big_bird"),Jdt.forEach(t),Y$o=r(d9e," \u2014 "),bG=n(d9e,"A",{href:!0});var Ydt=s(bG);K$o=r(Ydt,"BigBirdForSequenceClassification"),Ydt.forEach(t),Z$o=r(d9e," (BigBird model)"),d9e.forEach(t),eko=i(j),Q1=n(j,"LI",{});var c9e=s(Q1);Yfe=n(c9e,"STRONG",{});var Kdt=s(Yfe);oko=r(Kdt,"bigbird_pegasus"),Kdt.forEach(t),rko=r(c9e," \u2014 "),vG=n(c9e,"A",{href:!0});var Zdt=s(vG);tko=r(Zdt,"BigBirdPegasusForSequenceClassification"),Zdt.forEach(t),ako=r(c9e," (BigBirdPegasus model)"),c9e.forEach(t),nko=i(j),H1=n(j,"LI",{});var f9e=s(H1);Kfe=n(f9e,"STRONG",{});var ect=s(Kfe);sko=r(ect,"camembert"),ect.forEach(t),lko=r(f9e," \u2014 "),FG=n(f9e,"A",{href:!0});var oct=s(FG);iko=r(oct,"CamembertForSequenceClassification"),oct.forEach(t),dko=r(f9e," (CamemBERT model)"),f9e.forEach(t),cko=i(j),U1=n(j,"LI",{});var m9e=s(U1);Zfe=n(m9e,"STRONG",{});var rct=s(Zfe);fko=r(rct,"canine"),rct.forEach(t),mko=r(m9e," \u2014 "),TG=n(m9e,"A",{href:!0});var tct=s(TG);gko=r(tct,"CanineForSequenceClassification"),tct.forEach(t),hko=r(m9e," (Canine model)"),m9e.forEach(t),pko=i(j),J1=n(j,"LI",{});var g9e=s(J1);eme=n(g9e,"STRONG",{});var act=s(eme);uko=r(act,"convbert"),act.forEach(t),_ko=r(g9e," \u2014 "),MG=n(g9e,"A",{href:!0});var nct=s(MG);bko=r(nct,"ConvBertForSequenceClassification"),nct.forEach(t),vko=r(g9e," (ConvBERT model)"),g9e.forEach(t),Fko=i(j),Y1=n(j,"LI",{});var h9e=s(Y1);ome=n(h9e,"STRONG",{});var sct=s(ome);Tko=r(sct,"ctrl"),sct.forEach(t),Mko=r(h9e," \u2014 "),EG=n(h9e,"A",{href:!0});var lct=s(EG);Eko=r(lct,"CTRLForSequenceClassification"),lct.forEach(t),Cko=r(h9e," (CTRL model)"),h9e.forEach(t),wko=i(j),K1=n(j,"LI",{});var p9e=s(K1);rme=n(p9e,"STRONG",{});var ict=s(rme);Ako=r(ict,"data2vec-text"),ict.forEach(t),yko=r(p9e," \u2014 "),CG=n(p9e,"A",{href:!0});var dct=s(CG);Lko=r(dct,"Data2VecTextForSequenceClassification"),dct.forEach(t),xko=r(p9e," (Data2VecText model)"),p9e.forEach(t),$ko=i(j),Z1=n(j,"LI",{});var u9e=s(Z1);tme=n(u9e,"STRONG",{});var cct=s(tme);kko=r(cct,"deberta"),cct.forEach(t),Sko=r(u9e," \u2014 "),wG=n(u9e,"A",{href:!0});var fct=s(wG);Rko=r(fct,"DebertaForSequenceClassification"),fct.forEach(t),Pko=r(u9e," (DeBERTa model)"),u9e.forEach(t),Bko=i(j),eb=n(j,"LI",{});var _9e=s(eb);ame=n(_9e,"STRONG",{});var mct=s(ame);Iko=r(mct,"deberta-v2"),mct.forEach(t),qko=r(_9e," \u2014 "),AG=n(_9e,"A",{href:!0});var gct=s(AG);Nko=r(gct,"DebertaV2ForSequenceClassification"),gct.forEach(t),jko=r(_9e," (DeBERTa-v2 model)"),_9e.forEach(t),Dko=i(j),ob=n(j,"LI",{});var b9e=s(ob);nme=n(b9e,"STRONG",{});var hct=s(nme);Gko=r(hct,"distilbert"),hct.forEach(t),Oko=r(b9e," \u2014 "),yG=n(b9e,"A",{href:!0});var pct=s(yG);Vko=r(pct,"DistilBertForSequenceClassification"),pct.forEach(t),Xko=r(b9e," (DistilBERT model)"),b9e.forEach(t),zko=i(j),rb=n(j,"LI",{});var v9e=s(rb);sme=n(v9e,"STRONG",{});var uct=s(sme);Wko=r(uct,"electra"),uct.forEach(t),Qko=r(v9e," \u2014 "),LG=n(v9e,"A",{href:!0});var _ct=s(LG);Hko=r(_ct,"ElectraForSequenceClassification"),_ct.forEach(t),Uko=r(v9e," (ELECTRA model)"),v9e.forEach(t),Jko=i(j),tb=n(j,"LI",{});var F9e=s(tb);lme=n(F9e,"STRONG",{});var bct=s(lme);Yko=r(bct,"flaubert"),bct.forEach(t),Kko=r(F9e," \u2014 "),xG=n(F9e,"A",{href:!0});var vct=s(xG);Zko=r(vct,"FlaubertForSequenceClassification"),vct.forEach(t),eSo=r(F9e," (FlauBERT model)"),F9e.forEach(t),oSo=i(j),ab=n(j,"LI",{});var T9e=s(ab);ime=n(T9e,"STRONG",{});var Fct=s(ime);rSo=r(Fct,"fnet"),Fct.forEach(t),tSo=r(T9e," \u2014 "),$G=n(T9e,"A",{href:!0});var Tct=s($G);aSo=r(Tct,"FNetForSequenceClassification"),Tct.forEach(t),nSo=r(T9e," (FNet model)"),T9e.forEach(t),sSo=i(j),nb=n(j,"LI",{});var M9e=s(nb);dme=n(M9e,"STRONG",{});var Mct=s(dme);lSo=r(Mct,"funnel"),Mct.forEach(t),iSo=r(M9e," \u2014 "),kG=n(M9e,"A",{href:!0});var Ect=s(kG);dSo=r(Ect,"FunnelForSequenceClassification"),Ect.forEach(t),cSo=r(M9e," (Funnel Transformer model)"),M9e.forEach(t),fSo=i(j),sb=n(j,"LI",{});var E9e=s(sb);cme=n(E9e,"STRONG",{});var Cct=s(cme);mSo=r(Cct,"gpt2"),Cct.forEach(t),gSo=r(E9e," \u2014 "),SG=n(E9e,"A",{href:!0});var wct=s(SG);hSo=r(wct,"GPT2ForSequenceClassification"),wct.forEach(t),pSo=r(E9e," (OpenAI GPT-2 model)"),E9e.forEach(t),uSo=i(j),lb=n(j,"LI",{});var C9e=s(lb);fme=n(C9e,"STRONG",{});var Act=s(fme);_So=r(Act,"gpt_neo"),Act.forEach(t),bSo=r(C9e," \u2014 "),RG=n(C9e,"A",{href:!0});var yct=s(RG);vSo=r(yct,"GPTNeoForSequenceClassification"),yct.forEach(t),FSo=r(C9e," (GPT Neo model)"),C9e.forEach(t),TSo=i(j),ib=n(j,"LI",{});var w9e=s(ib);mme=n(w9e,"STRONG",{});var Lct=s(mme);MSo=r(Lct,"gptj"),Lct.forEach(t),ESo=r(w9e," \u2014 "),PG=n(w9e,"A",{href:!0});var xct=s(PG);CSo=r(xct,"GPTJForSequenceClassification"),xct.forEach(t),wSo=r(w9e," (GPT-J model)"),w9e.forEach(t),ASo=i(j),db=n(j,"LI",{});var A9e=s(db);gme=n(A9e,"STRONG",{});var $ct=s(gme);ySo=r($ct,"ibert"),$ct.forEach(t),LSo=r(A9e," \u2014 "),BG=n(A9e,"A",{href:!0});var kct=s(BG);xSo=r(kct,"IBertForSequenceClassification"),kct.forEach(t),$So=r(A9e," (I-BERT model)"),A9e.forEach(t),kSo=i(j),cb=n(j,"LI",{});var y9e=s(cb);hme=n(y9e,"STRONG",{});var Sct=s(hme);SSo=r(Sct,"layoutlm"),Sct.forEach(t),RSo=r(y9e," \u2014 "),IG=n(y9e,"A",{href:!0});var Rct=s(IG);PSo=r(Rct,"LayoutLMForSequenceClassification"),Rct.forEach(t),BSo=r(y9e," (LayoutLM model)"),y9e.forEach(t),ISo=i(j),fb=n(j,"LI",{});var L9e=s(fb);pme=n(L9e,"STRONG",{});var Pct=s(pme);qSo=r(Pct,"layoutlmv2"),Pct.forEach(t),NSo=r(L9e," \u2014 "),qG=n(L9e,"A",{href:!0});var Bct=s(qG);jSo=r(Bct,"LayoutLMv2ForSequenceClassification"),Bct.forEach(t),DSo=r(L9e," (LayoutLMv2 model)"),L9e.forEach(t),GSo=i(j),mb=n(j,"LI",{});var x9e=s(mb);ume=n(x9e,"STRONG",{});var Ict=s(ume);OSo=r(Ict,"layoutlmv3"),Ict.forEach(t),VSo=r(x9e," \u2014 "),NG=n(x9e,"A",{href:!0});var qct=s(NG);XSo=r(qct,"LayoutLMv3ForSequenceClassification"),qct.forEach(t),zSo=r(x9e," (LayoutLMv3 model)"),x9e.forEach(t),WSo=i(j),gb=n(j,"LI",{});var $9e=s(gb);_me=n($9e,"STRONG",{});var Nct=s(_me);QSo=r(Nct,"led"),Nct.forEach(t),HSo=r($9e," \u2014 "),jG=n($9e,"A",{href:!0});var jct=s(jG);USo=r(jct,"LEDForSequenceClassification"),jct.forEach(t),JSo=r($9e," (LED model)"),$9e.forEach(t),YSo=i(j),hb=n(j,"LI",{});var k9e=s(hb);bme=n(k9e,"STRONG",{});var Dct=s(bme);KSo=r(Dct,"longformer"),Dct.forEach(t),ZSo=r(k9e," \u2014 "),DG=n(k9e,"A",{href:!0});var Gct=s(DG);eRo=r(Gct,"LongformerForSequenceClassification"),Gct.forEach(t),oRo=r(k9e," (Longformer model)"),k9e.forEach(t),rRo=i(j),pb=n(j,"LI",{});var S9e=s(pb);vme=n(S9e,"STRONG",{});var Oct=s(vme);tRo=r(Oct,"mbart"),Oct.forEach(t),aRo=r(S9e," \u2014 "),GG=n(S9e,"A",{href:!0});var Vct=s(GG);nRo=r(Vct,"MBartForSequenceClassification"),Vct.forEach(t),sRo=r(S9e," (mBART model)"),S9e.forEach(t),lRo=i(j),ub=n(j,"LI",{});var R9e=s(ub);Fme=n(R9e,"STRONG",{});var Xct=s(Fme);iRo=r(Xct,"megatron-bert"),Xct.forEach(t),dRo=r(R9e," \u2014 "),OG=n(R9e,"A",{href:!0});var zct=s(OG);cRo=r(zct,"MegatronBertForSequenceClassification"),zct.forEach(t),fRo=r(R9e," (MegatronBert model)"),R9e.forEach(t),mRo=i(j),_b=n(j,"LI",{});var P9e=s(_b);Tme=n(P9e,"STRONG",{});var Wct=s(Tme);gRo=r(Wct,"mobilebert"),Wct.forEach(t),hRo=r(P9e," \u2014 "),VG=n(P9e,"A",{href:!0});var Qct=s(VG);pRo=r(Qct,"MobileBertForSequenceClassification"),Qct.forEach(t),uRo=r(P9e," (MobileBERT model)"),P9e.forEach(t),_Ro=i(j),bb=n(j,"LI",{});var B9e=s(bb);Mme=n(B9e,"STRONG",{});var Hct=s(Mme);bRo=r(Hct,"mpnet"),Hct.forEach(t),vRo=r(B9e," \u2014 "),XG=n(B9e,"A",{href:!0});var Uct=s(XG);FRo=r(Uct,"MPNetForSequenceClassification"),Uct.forEach(t),TRo=r(B9e," (MPNet model)"),B9e.forEach(t),MRo=i(j),vb=n(j,"LI",{});var I9e=s(vb);Eme=n(I9e,"STRONG",{});var Jct=s(Eme);ERo=r(Jct,"nystromformer"),Jct.forEach(t),CRo=r(I9e," \u2014 "),zG=n(I9e,"A",{href:!0});var Yct=s(zG);wRo=r(Yct,"NystromformerForSequenceClassification"),Yct.forEach(t),ARo=r(I9e," (Nystromformer model)"),I9e.forEach(t),yRo=i(j),Fb=n(j,"LI",{});var q9e=s(Fb);Cme=n(q9e,"STRONG",{});var Kct=s(Cme);LRo=r(Kct,"openai-gpt"),Kct.forEach(t),xRo=r(q9e," \u2014 "),WG=n(q9e,"A",{href:!0});var Zct=s(WG);$Ro=r(Zct,"OpenAIGPTForSequenceClassification"),Zct.forEach(t),kRo=r(q9e," (OpenAI GPT model)"),q9e.forEach(t),SRo=i(j),Tb=n(j,"LI",{});var N9e=s(Tb);wme=n(N9e,"STRONG",{});var eft=s(wme);RRo=r(eft,"perceiver"),eft.forEach(t),PRo=r(N9e," \u2014 "),QG=n(N9e,"A",{href:!0});var oft=s(QG);BRo=r(oft,"PerceiverForSequenceClassification"),oft.forEach(t),IRo=r(N9e," (Perceiver model)"),N9e.forEach(t),qRo=i(j),Mb=n(j,"LI",{});var j9e=s(Mb);Ame=n(j9e,"STRONG",{});var rft=s(Ame);NRo=r(rft,"plbart"),rft.forEach(t),jRo=r(j9e," \u2014 "),HG=n(j9e,"A",{href:!0});var tft=s(HG);DRo=r(tft,"PLBartForSequenceClassification"),tft.forEach(t),GRo=r(j9e," (PLBart model)"),j9e.forEach(t),ORo=i(j),Eb=n(j,"LI",{});var D9e=s(Eb);yme=n(D9e,"STRONG",{});var aft=s(yme);VRo=r(aft,"qdqbert"),aft.forEach(t),XRo=r(D9e," \u2014 "),UG=n(D9e,"A",{href:!0});var nft=s(UG);zRo=r(nft,"QDQBertForSequenceClassification"),nft.forEach(t),WRo=r(D9e," (QDQBert model)"),D9e.forEach(t),QRo=i(j),Cb=n(j,"LI",{});var G9e=s(Cb);Lme=n(G9e,"STRONG",{});var sft=s(Lme);HRo=r(sft,"reformer"),sft.forEach(t),URo=r(G9e," \u2014 "),JG=n(G9e,"A",{href:!0});var lft=s(JG);JRo=r(lft,"ReformerForSequenceClassification"),lft.forEach(t),YRo=r(G9e," (Reformer model)"),G9e.forEach(t),KRo=i(j),wb=n(j,"LI",{});var O9e=s(wb);xme=n(O9e,"STRONG",{});var ift=s(xme);ZRo=r(ift,"rembert"),ift.forEach(t),ePo=r(O9e," \u2014 "),YG=n(O9e,"A",{href:!0});var dft=s(YG);oPo=r(dft,"RemBertForSequenceClassification"),dft.forEach(t),rPo=r(O9e," (RemBERT model)"),O9e.forEach(t),tPo=i(j),Ab=n(j,"LI",{});var V9e=s(Ab);$me=n(V9e,"STRONG",{});var cft=s($me);aPo=r(cft,"roberta"),cft.forEach(t),nPo=r(V9e," \u2014 "),KG=n(V9e,"A",{href:!0});var fft=s(KG);sPo=r(fft,"RobertaForSequenceClassification"),fft.forEach(t),lPo=r(V9e," (RoBERTa model)"),V9e.forEach(t),iPo=i(j),yb=n(j,"LI",{});var X9e=s(yb);kme=n(X9e,"STRONG",{});var mft=s(kme);dPo=r(mft,"roformer"),mft.forEach(t),cPo=r(X9e," \u2014 "),ZG=n(X9e,"A",{href:!0});var gft=s(ZG);fPo=r(gft,"RoFormerForSequenceClassification"),gft.forEach(t),mPo=r(X9e," (RoFormer model)"),X9e.forEach(t),gPo=i(j),Lb=n(j,"LI",{});var z9e=s(Lb);Sme=n(z9e,"STRONG",{});var hft=s(Sme);hPo=r(hft,"squeezebert"),hft.forEach(t),pPo=r(z9e," \u2014 "),eO=n(z9e,"A",{href:!0});var pft=s(eO);uPo=r(pft,"SqueezeBertForSequenceClassification"),pft.forEach(t),_Po=r(z9e," (SqueezeBERT model)"),z9e.forEach(t),bPo=i(j),xb=n(j,"LI",{});var W9e=s(xb);Rme=n(W9e,"STRONG",{});var uft=s(Rme);vPo=r(uft,"tapas"),uft.forEach(t),FPo=r(W9e," \u2014 "),oO=n(W9e,"A",{href:!0});var _ft=s(oO);TPo=r(_ft,"TapasForSequenceClassification"),_ft.forEach(t),MPo=r(W9e," (TAPAS model)"),W9e.forEach(t),EPo=i(j),$b=n(j,"LI",{});var Q9e=s($b);Pme=n(Q9e,"STRONG",{});var bft=s(Pme);CPo=r(bft,"transfo-xl"),bft.forEach(t),wPo=r(Q9e," \u2014 "),rO=n(Q9e,"A",{href:!0});var vft=s(rO);APo=r(vft,"TransfoXLForSequenceClassification"),vft.forEach(t),yPo=r(Q9e," (Transformer-XL model)"),Q9e.forEach(t),LPo=i(j),kb=n(j,"LI",{});var H9e=s(kb);Bme=n(H9e,"STRONG",{});var Fft=s(Bme);xPo=r(Fft,"xlm"),Fft.forEach(t),$Po=r(H9e," \u2014 "),tO=n(H9e,"A",{href:!0});var Tft=s(tO);kPo=r(Tft,"XLMForSequenceClassification"),Tft.forEach(t),SPo=r(H9e," (XLM model)"),H9e.forEach(t),RPo=i(j),Sb=n(j,"LI",{});var U9e=s(Sb);Ime=n(U9e,"STRONG",{});var Mft=s(Ime);PPo=r(Mft,"xlm-roberta"),Mft.forEach(t),BPo=r(U9e," \u2014 "),aO=n(U9e,"A",{href:!0});var Eft=s(aO);IPo=r(Eft,"XLMRobertaForSequenceClassification"),Eft.forEach(t),qPo=r(U9e," (XLM-RoBERTa model)"),U9e.forEach(t),NPo=i(j),Rb=n(j,"LI",{});var J9e=s(Rb);qme=n(J9e,"STRONG",{});var Cft=s(qme);jPo=r(Cft,"xlm-roberta-xl"),Cft.forEach(t),DPo=r(J9e," \u2014 "),nO=n(J9e,"A",{href:!0});var wft=s(nO);GPo=r(wft,"XLMRobertaXLForSequenceClassification"),wft.forEach(t),OPo=r(J9e," (XLM-RoBERTa-XL model)"),J9e.forEach(t),VPo=i(j),Pb=n(j,"LI",{});var Y9e=s(Pb);Nme=n(Y9e,"STRONG",{});var Aft=s(Nme);XPo=r(Aft,"xlnet"),Aft.forEach(t),zPo=r(Y9e," \u2014 "),sO=n(Y9e,"A",{href:!0});var yft=s(sO);WPo=r(yft,"XLNetForSequenceClassification"),yft.forEach(t),QPo=r(Y9e," (XLNet model)"),Y9e.forEach(t),HPo=i(j),Bb=n(j,"LI",{});var K9e=s(Bb);jme=n(K9e,"STRONG",{});var Lft=s(jme);UPo=r(Lft,"yoso"),Lft.forEach(t),JPo=r(K9e," \u2014 "),lO=n(K9e,"A",{href:!0});var xft=s(lO);YPo=r(xft,"YosoForSequenceClassification"),xft.forEach(t),KPo=r(K9e," (YOSO model)"),K9e.forEach(t),j.forEach(t),ZPo=i(sa),Ib=n(sa,"P",{});var Z9e=s(Ib);eBo=r(Z9e,"The model is set in evaluation mode by default using "),Dme=n(Z9e,"CODE",{});var $ft=s(Dme);oBo=r($ft,"model.eval()"),$ft.forEach(t),rBo=r(Z9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gme=n(Z9e,"CODE",{});var kft=s(Gme);tBo=r(kft,"model.train()"),kft.forEach(t),Z9e.forEach(t),aBo=i(sa),T(qb.$$.fragment,sa),sa.forEach(t),Us.forEach(t),ANe=i(f),Wi=n(f,"H2",{class:!0});var $De=s(Wi);Nb=n($De,"A",{id:!0,class:!0,href:!0});var Sft=s(Nb);Ome=n(Sft,"SPAN",{});var Rft=s(Ome);T(xy.$$.fragment,Rft),Rft.forEach(t),Sft.forEach(t),nBo=i($De),Vme=n($De,"SPAN",{});var Pft=s(Vme);sBo=r(Pft,"AutoModelForMultipleChoice"),Pft.forEach(t),$De.forEach(t),yNe=i(f),Po=n(f,"DIV",{class:!0});var Js=s(Po);T($y.$$.fragment,Js),lBo=i(Js),Qi=n(Js,"P",{});var RZ=s(Qi);iBo=r(RZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iO=n(RZ,"A",{href:!0});var Bft=s(iO);dBo=r(Bft,"from_pretrained()"),Bft.forEach(t),cBo=r(RZ," class method or the "),dO=n(RZ,"A",{href:!0});var Ift=s(dO);fBo=r(Ift,"from_config()"),Ift.forEach(t),mBo=r(RZ,` class
method.`),RZ.forEach(t),gBo=i(Js),ky=n(Js,"P",{});var kDe=s(ky);hBo=r(kDe,"This class cannot be instantiated directly using "),Xme=n(kDe,"CODE",{});var qft=s(Xme);pBo=r(qft,"__init__()"),qft.forEach(t),uBo=r(kDe," (throws an error)."),kDe.forEach(t),_Bo=i(Js),dt=n(Js,"DIV",{class:!0});var V0=s(dt);T(Sy.$$.fragment,V0),bBo=i(V0),zme=n(V0,"P",{});var Nft=s(zme);vBo=r(Nft,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Nft.forEach(t),FBo=i(V0),Hi=n(V0,"P",{});var PZ=s(Hi);TBo=r(PZ,`Note:
Loading a model from its configuration file does `),Wme=n(PZ,"STRONG",{});var jft=s(Wme);MBo=r(jft,"not"),jft.forEach(t),EBo=r(PZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),cO=n(PZ,"A",{href:!0});var Dft=s(cO);CBo=r(Dft,"from_pretrained()"),Dft.forEach(t),wBo=r(PZ," to load the model weights."),PZ.forEach(t),ABo=i(V0),T(jb.$$.fragment,V0),V0.forEach(t),yBo=i(Js),ro=n(Js,"DIV",{class:!0});var la=s(ro);T(Ry.$$.fragment,la),LBo=i(la),Qme=n(la,"P",{});var Gft=s(Qme);xBo=r(Gft,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Gft.forEach(t),$Bo=i(la),Pa=n(la,"P",{});var X0=s(Pa);kBo=r(X0,"The model class to instantiate is selected based on the "),Hme=n(X0,"CODE",{});var Oft=s(Hme);SBo=r(Oft,"model_type"),Oft.forEach(t),RBo=r(X0,` property of the config object (either
passed as an argument or loaded from `),Ume=n(X0,"CODE",{});var Vft=s(Ume);PBo=r(Vft,"pretrained_model_name_or_path"),Vft.forEach(t),BBo=r(X0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jme=n(X0,"CODE",{});var Xft=s(Jme);IBo=r(Xft,"pretrained_model_name_or_path"),Xft.forEach(t),qBo=r(X0,":"),X0.forEach(t),NBo=i(la),K=n(la,"UL",{});var ee=s(K);Db=n(ee,"LI",{});var exe=s(Db);Yme=n(exe,"STRONG",{});var zft=s(Yme);jBo=r(zft,"albert"),zft.forEach(t),DBo=r(exe," \u2014 "),fO=n(exe,"A",{href:!0});var Wft=s(fO);GBo=r(Wft,"AlbertForMultipleChoice"),Wft.forEach(t),OBo=r(exe," (ALBERT model)"),exe.forEach(t),VBo=i(ee),Gb=n(ee,"LI",{});var oxe=s(Gb);Kme=n(oxe,"STRONG",{});var Qft=s(Kme);XBo=r(Qft,"bert"),Qft.forEach(t),zBo=r(oxe," \u2014 "),mO=n(oxe,"A",{href:!0});var Hft=s(mO);WBo=r(Hft,"BertForMultipleChoice"),Hft.forEach(t),QBo=r(oxe," (BERT model)"),oxe.forEach(t),HBo=i(ee),Ob=n(ee,"LI",{});var rxe=s(Ob);Zme=n(rxe,"STRONG",{});var Uft=s(Zme);UBo=r(Uft,"big_bird"),Uft.forEach(t),JBo=r(rxe," \u2014 "),gO=n(rxe,"A",{href:!0});var Jft=s(gO);YBo=r(Jft,"BigBirdForMultipleChoice"),Jft.forEach(t),KBo=r(rxe," (BigBird model)"),rxe.forEach(t),ZBo=i(ee),Vb=n(ee,"LI",{});var txe=s(Vb);ege=n(txe,"STRONG",{});var Yft=s(ege);eIo=r(Yft,"camembert"),Yft.forEach(t),oIo=r(txe," \u2014 "),hO=n(txe,"A",{href:!0});var Kft=s(hO);rIo=r(Kft,"CamembertForMultipleChoice"),Kft.forEach(t),tIo=r(txe," (CamemBERT model)"),txe.forEach(t),aIo=i(ee),Xb=n(ee,"LI",{});var axe=s(Xb);oge=n(axe,"STRONG",{});var Zft=s(oge);nIo=r(Zft,"canine"),Zft.forEach(t),sIo=r(axe," \u2014 "),pO=n(axe,"A",{href:!0});var emt=s(pO);lIo=r(emt,"CanineForMultipleChoice"),emt.forEach(t),iIo=r(axe," (Canine model)"),axe.forEach(t),dIo=i(ee),zb=n(ee,"LI",{});var nxe=s(zb);rge=n(nxe,"STRONG",{});var omt=s(rge);cIo=r(omt,"convbert"),omt.forEach(t),fIo=r(nxe," \u2014 "),uO=n(nxe,"A",{href:!0});var rmt=s(uO);mIo=r(rmt,"ConvBertForMultipleChoice"),rmt.forEach(t),gIo=r(nxe," (ConvBERT model)"),nxe.forEach(t),hIo=i(ee),Wb=n(ee,"LI",{});var sxe=s(Wb);tge=n(sxe,"STRONG",{});var tmt=s(tge);pIo=r(tmt,"data2vec-text"),tmt.forEach(t),uIo=r(sxe," \u2014 "),_O=n(sxe,"A",{href:!0});var amt=s(_O);_Io=r(amt,"Data2VecTextForMultipleChoice"),amt.forEach(t),bIo=r(sxe," (Data2VecText model)"),sxe.forEach(t),vIo=i(ee),Qb=n(ee,"LI",{});var lxe=s(Qb);age=n(lxe,"STRONG",{});var nmt=s(age);FIo=r(nmt,"deberta-v2"),nmt.forEach(t),TIo=r(lxe," \u2014 "),bO=n(lxe,"A",{href:!0});var smt=s(bO);MIo=r(smt,"DebertaV2ForMultipleChoice"),smt.forEach(t),EIo=r(lxe," (DeBERTa-v2 model)"),lxe.forEach(t),CIo=i(ee),Hb=n(ee,"LI",{});var ixe=s(Hb);nge=n(ixe,"STRONG",{});var lmt=s(nge);wIo=r(lmt,"distilbert"),lmt.forEach(t),AIo=r(ixe," \u2014 "),vO=n(ixe,"A",{href:!0});var imt=s(vO);yIo=r(imt,"DistilBertForMultipleChoice"),imt.forEach(t),LIo=r(ixe," (DistilBERT model)"),ixe.forEach(t),xIo=i(ee),Ub=n(ee,"LI",{});var dxe=s(Ub);sge=n(dxe,"STRONG",{});var dmt=s(sge);$Io=r(dmt,"electra"),dmt.forEach(t),kIo=r(dxe," \u2014 "),FO=n(dxe,"A",{href:!0});var cmt=s(FO);SIo=r(cmt,"ElectraForMultipleChoice"),cmt.forEach(t),RIo=r(dxe," (ELECTRA model)"),dxe.forEach(t),PIo=i(ee),Jb=n(ee,"LI",{});var cxe=s(Jb);lge=n(cxe,"STRONG",{});var fmt=s(lge);BIo=r(fmt,"flaubert"),fmt.forEach(t),IIo=r(cxe," \u2014 "),TO=n(cxe,"A",{href:!0});var mmt=s(TO);qIo=r(mmt,"FlaubertForMultipleChoice"),mmt.forEach(t),NIo=r(cxe," (FlauBERT model)"),cxe.forEach(t),jIo=i(ee),Yb=n(ee,"LI",{});var fxe=s(Yb);ige=n(fxe,"STRONG",{});var gmt=s(ige);DIo=r(gmt,"fnet"),gmt.forEach(t),GIo=r(fxe," \u2014 "),MO=n(fxe,"A",{href:!0});var hmt=s(MO);OIo=r(hmt,"FNetForMultipleChoice"),hmt.forEach(t),VIo=r(fxe," (FNet model)"),fxe.forEach(t),XIo=i(ee),Kb=n(ee,"LI",{});var mxe=s(Kb);dge=n(mxe,"STRONG",{});var pmt=s(dge);zIo=r(pmt,"funnel"),pmt.forEach(t),WIo=r(mxe," \u2014 "),EO=n(mxe,"A",{href:!0});var umt=s(EO);QIo=r(umt,"FunnelForMultipleChoice"),umt.forEach(t),HIo=r(mxe," (Funnel Transformer model)"),mxe.forEach(t),UIo=i(ee),Zb=n(ee,"LI",{});var gxe=s(Zb);cge=n(gxe,"STRONG",{});var _mt=s(cge);JIo=r(_mt,"ibert"),_mt.forEach(t),YIo=r(gxe," \u2014 "),CO=n(gxe,"A",{href:!0});var bmt=s(CO);KIo=r(bmt,"IBertForMultipleChoice"),bmt.forEach(t),ZIo=r(gxe," (I-BERT model)"),gxe.forEach(t),eqo=i(ee),e4=n(ee,"LI",{});var hxe=s(e4);fge=n(hxe,"STRONG",{});var vmt=s(fge);oqo=r(vmt,"longformer"),vmt.forEach(t),rqo=r(hxe," \u2014 "),wO=n(hxe,"A",{href:!0});var Fmt=s(wO);tqo=r(Fmt,"LongformerForMultipleChoice"),Fmt.forEach(t),aqo=r(hxe," (Longformer model)"),hxe.forEach(t),nqo=i(ee),o4=n(ee,"LI",{});var pxe=s(o4);mge=n(pxe,"STRONG",{});var Tmt=s(mge);sqo=r(Tmt,"megatron-bert"),Tmt.forEach(t),lqo=r(pxe," \u2014 "),AO=n(pxe,"A",{href:!0});var Mmt=s(AO);iqo=r(Mmt,"MegatronBertForMultipleChoice"),Mmt.forEach(t),dqo=r(pxe," (MegatronBert model)"),pxe.forEach(t),cqo=i(ee),r4=n(ee,"LI",{});var uxe=s(r4);gge=n(uxe,"STRONG",{});var Emt=s(gge);fqo=r(Emt,"mobilebert"),Emt.forEach(t),mqo=r(uxe," \u2014 "),yO=n(uxe,"A",{href:!0});var Cmt=s(yO);gqo=r(Cmt,"MobileBertForMultipleChoice"),Cmt.forEach(t),hqo=r(uxe," (MobileBERT model)"),uxe.forEach(t),pqo=i(ee),t4=n(ee,"LI",{});var _xe=s(t4);hge=n(_xe,"STRONG",{});var wmt=s(hge);uqo=r(wmt,"mpnet"),wmt.forEach(t),_qo=r(_xe," \u2014 "),LO=n(_xe,"A",{href:!0});var Amt=s(LO);bqo=r(Amt,"MPNetForMultipleChoice"),Amt.forEach(t),vqo=r(_xe," (MPNet model)"),_xe.forEach(t),Fqo=i(ee),a4=n(ee,"LI",{});var bxe=s(a4);pge=n(bxe,"STRONG",{});var ymt=s(pge);Tqo=r(ymt,"nystromformer"),ymt.forEach(t),Mqo=r(bxe," \u2014 "),xO=n(bxe,"A",{href:!0});var Lmt=s(xO);Eqo=r(Lmt,"NystromformerForMultipleChoice"),Lmt.forEach(t),Cqo=r(bxe," (Nystromformer model)"),bxe.forEach(t),wqo=i(ee),n4=n(ee,"LI",{});var vxe=s(n4);uge=n(vxe,"STRONG",{});var xmt=s(uge);Aqo=r(xmt,"qdqbert"),xmt.forEach(t),yqo=r(vxe," \u2014 "),$O=n(vxe,"A",{href:!0});var $mt=s($O);Lqo=r($mt,"QDQBertForMultipleChoice"),$mt.forEach(t),xqo=r(vxe," (QDQBert model)"),vxe.forEach(t),$qo=i(ee),s4=n(ee,"LI",{});var Fxe=s(s4);_ge=n(Fxe,"STRONG",{});var kmt=s(_ge);kqo=r(kmt,"rembert"),kmt.forEach(t),Sqo=r(Fxe," \u2014 "),kO=n(Fxe,"A",{href:!0});var Smt=s(kO);Rqo=r(Smt,"RemBertForMultipleChoice"),Smt.forEach(t),Pqo=r(Fxe," (RemBERT model)"),Fxe.forEach(t),Bqo=i(ee),l4=n(ee,"LI",{});var Txe=s(l4);bge=n(Txe,"STRONG",{});var Rmt=s(bge);Iqo=r(Rmt,"roberta"),Rmt.forEach(t),qqo=r(Txe," \u2014 "),SO=n(Txe,"A",{href:!0});var Pmt=s(SO);Nqo=r(Pmt,"RobertaForMultipleChoice"),Pmt.forEach(t),jqo=r(Txe," (RoBERTa model)"),Txe.forEach(t),Dqo=i(ee),i4=n(ee,"LI",{});var Mxe=s(i4);vge=n(Mxe,"STRONG",{});var Bmt=s(vge);Gqo=r(Bmt,"roformer"),Bmt.forEach(t),Oqo=r(Mxe," \u2014 "),RO=n(Mxe,"A",{href:!0});var Imt=s(RO);Vqo=r(Imt,"RoFormerForMultipleChoice"),Imt.forEach(t),Xqo=r(Mxe," (RoFormer model)"),Mxe.forEach(t),zqo=i(ee),d4=n(ee,"LI",{});var Exe=s(d4);Fge=n(Exe,"STRONG",{});var qmt=s(Fge);Wqo=r(qmt,"squeezebert"),qmt.forEach(t),Qqo=r(Exe," \u2014 "),PO=n(Exe,"A",{href:!0});var Nmt=s(PO);Hqo=r(Nmt,"SqueezeBertForMultipleChoice"),Nmt.forEach(t),Uqo=r(Exe," (SqueezeBERT model)"),Exe.forEach(t),Jqo=i(ee),c4=n(ee,"LI",{});var Cxe=s(c4);Tge=n(Cxe,"STRONG",{});var jmt=s(Tge);Yqo=r(jmt,"xlm"),jmt.forEach(t),Kqo=r(Cxe," \u2014 "),BO=n(Cxe,"A",{href:!0});var Dmt=s(BO);Zqo=r(Dmt,"XLMForMultipleChoice"),Dmt.forEach(t),eNo=r(Cxe," (XLM model)"),Cxe.forEach(t),oNo=i(ee),f4=n(ee,"LI",{});var wxe=s(f4);Mge=n(wxe,"STRONG",{});var Gmt=s(Mge);rNo=r(Gmt,"xlm-roberta"),Gmt.forEach(t),tNo=r(wxe," \u2014 "),IO=n(wxe,"A",{href:!0});var Omt=s(IO);aNo=r(Omt,"XLMRobertaForMultipleChoice"),Omt.forEach(t),nNo=r(wxe," (XLM-RoBERTa model)"),wxe.forEach(t),sNo=i(ee),m4=n(ee,"LI",{});var Axe=s(m4);Ege=n(Axe,"STRONG",{});var Vmt=s(Ege);lNo=r(Vmt,"xlm-roberta-xl"),Vmt.forEach(t),iNo=r(Axe," \u2014 "),qO=n(Axe,"A",{href:!0});var Xmt=s(qO);dNo=r(Xmt,"XLMRobertaXLForMultipleChoice"),Xmt.forEach(t),cNo=r(Axe," (XLM-RoBERTa-XL model)"),Axe.forEach(t),fNo=i(ee),g4=n(ee,"LI",{});var yxe=s(g4);Cge=n(yxe,"STRONG",{});var zmt=s(Cge);mNo=r(zmt,"xlnet"),zmt.forEach(t),gNo=r(yxe," \u2014 "),NO=n(yxe,"A",{href:!0});var Wmt=s(NO);hNo=r(Wmt,"XLNetForMultipleChoice"),Wmt.forEach(t),pNo=r(yxe," (XLNet model)"),yxe.forEach(t),uNo=i(ee),h4=n(ee,"LI",{});var Lxe=s(h4);wge=n(Lxe,"STRONG",{});var Qmt=s(wge);_No=r(Qmt,"yoso"),Qmt.forEach(t),bNo=r(Lxe," \u2014 "),jO=n(Lxe,"A",{href:!0});var Hmt=s(jO);vNo=r(Hmt,"YosoForMultipleChoice"),Hmt.forEach(t),FNo=r(Lxe," (YOSO model)"),Lxe.forEach(t),ee.forEach(t),TNo=i(la),p4=n(la,"P",{});var xxe=s(p4);MNo=r(xxe,"The model is set in evaluation mode by default using "),Age=n(xxe,"CODE",{});var Umt=s(Age);ENo=r(Umt,"model.eval()"),Umt.forEach(t),CNo=r(xxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yge=n(xxe,"CODE",{});var Jmt=s(yge);wNo=r(Jmt,"model.train()"),Jmt.forEach(t),xxe.forEach(t),ANo=i(la),T(u4.$$.fragment,la),la.forEach(t),Js.forEach(t),LNe=i(f),Ui=n(f,"H2",{class:!0});var SDe=s(Ui);_4=n(SDe,"A",{id:!0,class:!0,href:!0});var Ymt=s(_4);Lge=n(Ymt,"SPAN",{});var Kmt=s(Lge);T(Py.$$.fragment,Kmt),Kmt.forEach(t),Ymt.forEach(t),yNo=i(SDe),xge=n(SDe,"SPAN",{});var Zmt=s(xge);LNo=r(Zmt,"AutoModelForNextSentencePrediction"),Zmt.forEach(t),SDe.forEach(t),xNe=i(f),Bo=n(f,"DIV",{class:!0});var Ys=s(Bo);T(By.$$.fragment,Ys),xNo=i(Ys),Ji=n(Ys,"P",{});var BZ=s(Ji);$No=r(BZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DO=n(BZ,"A",{href:!0});var egt=s(DO);kNo=r(egt,"from_pretrained()"),egt.forEach(t),SNo=r(BZ," class method or the "),GO=n(BZ,"A",{href:!0});var ogt=s(GO);RNo=r(ogt,"from_config()"),ogt.forEach(t),PNo=r(BZ,` class
method.`),BZ.forEach(t),BNo=i(Ys),Iy=n(Ys,"P",{});var RDe=s(Iy);INo=r(RDe,"This class cannot be instantiated directly using "),$ge=n(RDe,"CODE",{});var rgt=s($ge);qNo=r(rgt,"__init__()"),rgt.forEach(t),NNo=r(RDe," (throws an error)."),RDe.forEach(t),jNo=i(Ys),ct=n(Ys,"DIV",{class:!0});var z0=s(ct);T(qy.$$.fragment,z0),DNo=i(z0),kge=n(z0,"P",{});var tgt=s(kge);GNo=r(tgt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),tgt.forEach(t),ONo=i(z0),Yi=n(z0,"P",{});var IZ=s(Yi);VNo=r(IZ,`Note:
Loading a model from its configuration file does `),Sge=n(IZ,"STRONG",{});var agt=s(Sge);XNo=r(agt,"not"),agt.forEach(t),zNo=r(IZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),OO=n(IZ,"A",{href:!0});var ngt=s(OO);WNo=r(ngt,"from_pretrained()"),ngt.forEach(t),QNo=r(IZ," to load the model weights."),IZ.forEach(t),HNo=i(z0),T(b4.$$.fragment,z0),z0.forEach(t),UNo=i(Ys),to=n(Ys,"DIV",{class:!0});var ia=s(to);T(Ny.$$.fragment,ia),JNo=i(ia),Rge=n(ia,"P",{});var sgt=s(Rge);YNo=r(sgt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),sgt.forEach(t),KNo=i(ia),Ba=n(ia,"P",{});var W0=s(Ba);ZNo=r(W0,"The model class to instantiate is selected based on the "),Pge=n(W0,"CODE",{});var lgt=s(Pge);ejo=r(lgt,"model_type"),lgt.forEach(t),ojo=r(W0,` property of the config object (either
passed as an argument or loaded from `),Bge=n(W0,"CODE",{});var igt=s(Bge);rjo=r(igt,"pretrained_model_name_or_path"),igt.forEach(t),tjo=r(W0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ige=n(W0,"CODE",{});var dgt=s(Ige);ajo=r(dgt,"pretrained_model_name_or_path"),dgt.forEach(t),njo=r(W0,":"),W0.forEach(t),sjo=i(ia),Yr=n(ia,"UL",{});var Ks=s(Yr);v4=n(Ks,"LI",{});var $xe=s(v4);qge=n($xe,"STRONG",{});var cgt=s(qge);ljo=r(cgt,"bert"),cgt.forEach(t),ijo=r($xe," \u2014 "),VO=n($xe,"A",{href:!0});var fgt=s(VO);djo=r(fgt,"BertForNextSentencePrediction"),fgt.forEach(t),cjo=r($xe," (BERT model)"),$xe.forEach(t),fjo=i(Ks),F4=n(Ks,"LI",{});var kxe=s(F4);Nge=n(kxe,"STRONG",{});var mgt=s(Nge);mjo=r(mgt,"fnet"),mgt.forEach(t),gjo=r(kxe," \u2014 "),XO=n(kxe,"A",{href:!0});var ggt=s(XO);hjo=r(ggt,"FNetForNextSentencePrediction"),ggt.forEach(t),pjo=r(kxe," (FNet model)"),kxe.forEach(t),ujo=i(Ks),T4=n(Ks,"LI",{});var Sxe=s(T4);jge=n(Sxe,"STRONG",{});var hgt=s(jge);_jo=r(hgt,"megatron-bert"),hgt.forEach(t),bjo=r(Sxe," \u2014 "),zO=n(Sxe,"A",{href:!0});var pgt=s(zO);vjo=r(pgt,"MegatronBertForNextSentencePrediction"),pgt.forEach(t),Fjo=r(Sxe," (MegatronBert model)"),Sxe.forEach(t),Tjo=i(Ks),M4=n(Ks,"LI",{});var Rxe=s(M4);Dge=n(Rxe,"STRONG",{});var ugt=s(Dge);Mjo=r(ugt,"mobilebert"),ugt.forEach(t),Ejo=r(Rxe," \u2014 "),WO=n(Rxe,"A",{href:!0});var _gt=s(WO);Cjo=r(_gt,"MobileBertForNextSentencePrediction"),_gt.forEach(t),wjo=r(Rxe," (MobileBERT model)"),Rxe.forEach(t),Ajo=i(Ks),E4=n(Ks,"LI",{});var Pxe=s(E4);Gge=n(Pxe,"STRONG",{});var bgt=s(Gge);yjo=r(bgt,"qdqbert"),bgt.forEach(t),Ljo=r(Pxe," \u2014 "),QO=n(Pxe,"A",{href:!0});var vgt=s(QO);xjo=r(vgt,"QDQBertForNextSentencePrediction"),vgt.forEach(t),$jo=r(Pxe," (QDQBert model)"),Pxe.forEach(t),Ks.forEach(t),kjo=i(ia),C4=n(ia,"P",{});var Bxe=s(C4);Sjo=r(Bxe,"The model is set in evaluation mode by default using "),Oge=n(Bxe,"CODE",{});var Fgt=s(Oge);Rjo=r(Fgt,"model.eval()"),Fgt.forEach(t),Pjo=r(Bxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vge=n(Bxe,"CODE",{});var Tgt=s(Vge);Bjo=r(Tgt,"model.train()"),Tgt.forEach(t),Bxe.forEach(t),Ijo=i(ia),T(w4.$$.fragment,ia),ia.forEach(t),Ys.forEach(t),$Ne=i(f),Ki=n(f,"H2",{class:!0});var PDe=s(Ki);A4=n(PDe,"A",{id:!0,class:!0,href:!0});var Mgt=s(A4);Xge=n(Mgt,"SPAN",{});var Egt=s(Xge);T(jy.$$.fragment,Egt),Egt.forEach(t),Mgt.forEach(t),qjo=i(PDe),zge=n(PDe,"SPAN",{});var Cgt=s(zge);Njo=r(Cgt,"AutoModelForTokenClassification"),Cgt.forEach(t),PDe.forEach(t),kNe=i(f),Io=n(f,"DIV",{class:!0});var Zs=s(Io);T(Dy.$$.fragment,Zs),jjo=i(Zs),Zi=n(Zs,"P",{});var qZ=s(Zi);Djo=r(qZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HO=n(qZ,"A",{href:!0});var wgt=s(HO);Gjo=r(wgt,"from_pretrained()"),wgt.forEach(t),Ojo=r(qZ," class method or the "),UO=n(qZ,"A",{href:!0});var Agt=s(UO);Vjo=r(Agt,"from_config()"),Agt.forEach(t),Xjo=r(qZ,` class
method.`),qZ.forEach(t),zjo=i(Zs),Gy=n(Zs,"P",{});var BDe=s(Gy);Wjo=r(BDe,"This class cannot be instantiated directly using "),Wge=n(BDe,"CODE",{});var ygt=s(Wge);Qjo=r(ygt,"__init__()"),ygt.forEach(t),Hjo=r(BDe," (throws an error)."),BDe.forEach(t),Ujo=i(Zs),ft=n(Zs,"DIV",{class:!0});var Q0=s(ft);T(Oy.$$.fragment,Q0),Jjo=i(Q0),Qge=n(Q0,"P",{});var Lgt=s(Qge);Yjo=r(Lgt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Lgt.forEach(t),Kjo=i(Q0),ed=n(Q0,"P",{});var NZ=s(ed);Zjo=r(NZ,`Note:
Loading a model from its configuration file does `),Hge=n(NZ,"STRONG",{});var xgt=s(Hge);eDo=r(xgt,"not"),xgt.forEach(t),oDo=r(NZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JO=n(NZ,"A",{href:!0});var $gt=s(JO);rDo=r($gt,"from_pretrained()"),$gt.forEach(t),tDo=r(NZ," to load the model weights."),NZ.forEach(t),aDo=i(Q0),T(y4.$$.fragment,Q0),Q0.forEach(t),nDo=i(Zs),ao=n(Zs,"DIV",{class:!0});var da=s(ao);T(Vy.$$.fragment,da),sDo=i(da),Uge=n(da,"P",{});var kgt=s(Uge);lDo=r(kgt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),kgt.forEach(t),iDo=i(da),Ia=n(da,"P",{});var H0=s(Ia);dDo=r(H0,"The model class to instantiate is selected based on the "),Jge=n(H0,"CODE",{});var Sgt=s(Jge);cDo=r(Sgt,"model_type"),Sgt.forEach(t),fDo=r(H0,` property of the config object (either
passed as an argument or loaded from `),Yge=n(H0,"CODE",{});var Rgt=s(Yge);mDo=r(Rgt,"pretrained_model_name_or_path"),Rgt.forEach(t),gDo=r(H0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kge=n(H0,"CODE",{});var Pgt=s(Kge);hDo=r(Pgt,"pretrained_model_name_or_path"),Pgt.forEach(t),pDo=r(H0,":"),H0.forEach(t),uDo=i(da),H=n(da,"UL",{});var J=s(H);L4=n(J,"LI",{});var Ixe=s(L4);Zge=n(Ixe,"STRONG",{});var Bgt=s(Zge);_Do=r(Bgt,"albert"),Bgt.forEach(t),bDo=r(Ixe," \u2014 "),YO=n(Ixe,"A",{href:!0});var Igt=s(YO);vDo=r(Igt,"AlbertForTokenClassification"),Igt.forEach(t),FDo=r(Ixe," (ALBERT model)"),Ixe.forEach(t),TDo=i(J),x4=n(J,"LI",{});var qxe=s(x4);ehe=n(qxe,"STRONG",{});var qgt=s(ehe);MDo=r(qgt,"bert"),qgt.forEach(t),EDo=r(qxe," \u2014 "),KO=n(qxe,"A",{href:!0});var Ngt=s(KO);CDo=r(Ngt,"BertForTokenClassification"),Ngt.forEach(t),wDo=r(qxe," (BERT model)"),qxe.forEach(t),ADo=i(J),$4=n(J,"LI",{});var Nxe=s($4);ohe=n(Nxe,"STRONG",{});var jgt=s(ohe);yDo=r(jgt,"big_bird"),jgt.forEach(t),LDo=r(Nxe," \u2014 "),ZO=n(Nxe,"A",{href:!0});var Dgt=s(ZO);xDo=r(Dgt,"BigBirdForTokenClassification"),Dgt.forEach(t),$Do=r(Nxe," (BigBird model)"),Nxe.forEach(t),kDo=i(J),k4=n(J,"LI",{});var jxe=s(k4);rhe=n(jxe,"STRONG",{});var Ggt=s(rhe);SDo=r(Ggt,"camembert"),Ggt.forEach(t),RDo=r(jxe," \u2014 "),eV=n(jxe,"A",{href:!0});var Ogt=s(eV);PDo=r(Ogt,"CamembertForTokenClassification"),Ogt.forEach(t),BDo=r(jxe," (CamemBERT model)"),jxe.forEach(t),IDo=i(J),S4=n(J,"LI",{});var Dxe=s(S4);the=n(Dxe,"STRONG",{});var Vgt=s(the);qDo=r(Vgt,"canine"),Vgt.forEach(t),NDo=r(Dxe," \u2014 "),oV=n(Dxe,"A",{href:!0});var Xgt=s(oV);jDo=r(Xgt,"CanineForTokenClassification"),Xgt.forEach(t),DDo=r(Dxe," (Canine model)"),Dxe.forEach(t),GDo=i(J),R4=n(J,"LI",{});var Gxe=s(R4);ahe=n(Gxe,"STRONG",{});var zgt=s(ahe);ODo=r(zgt,"convbert"),zgt.forEach(t),VDo=r(Gxe," \u2014 "),rV=n(Gxe,"A",{href:!0});var Wgt=s(rV);XDo=r(Wgt,"ConvBertForTokenClassification"),Wgt.forEach(t),zDo=r(Gxe," (ConvBERT model)"),Gxe.forEach(t),WDo=i(J),P4=n(J,"LI",{});var Oxe=s(P4);nhe=n(Oxe,"STRONG",{});var Qgt=s(nhe);QDo=r(Qgt,"data2vec-text"),Qgt.forEach(t),HDo=r(Oxe," \u2014 "),tV=n(Oxe,"A",{href:!0});var Hgt=s(tV);UDo=r(Hgt,"Data2VecTextForTokenClassification"),Hgt.forEach(t),JDo=r(Oxe," (Data2VecText model)"),Oxe.forEach(t),YDo=i(J),B4=n(J,"LI",{});var Vxe=s(B4);she=n(Vxe,"STRONG",{});var Ugt=s(she);KDo=r(Ugt,"deberta"),Ugt.forEach(t),ZDo=r(Vxe," \u2014 "),aV=n(Vxe,"A",{href:!0});var Jgt=s(aV);eGo=r(Jgt,"DebertaForTokenClassification"),Jgt.forEach(t),oGo=r(Vxe," (DeBERTa model)"),Vxe.forEach(t),rGo=i(J),I4=n(J,"LI",{});var Xxe=s(I4);lhe=n(Xxe,"STRONG",{});var Ygt=s(lhe);tGo=r(Ygt,"deberta-v2"),Ygt.forEach(t),aGo=r(Xxe," \u2014 "),nV=n(Xxe,"A",{href:!0});var Kgt=s(nV);nGo=r(Kgt,"DebertaV2ForTokenClassification"),Kgt.forEach(t),sGo=r(Xxe," (DeBERTa-v2 model)"),Xxe.forEach(t),lGo=i(J),q4=n(J,"LI",{});var zxe=s(q4);ihe=n(zxe,"STRONG",{});var Zgt=s(ihe);iGo=r(Zgt,"distilbert"),Zgt.forEach(t),dGo=r(zxe," \u2014 "),sV=n(zxe,"A",{href:!0});var eht=s(sV);cGo=r(eht,"DistilBertForTokenClassification"),eht.forEach(t),fGo=r(zxe," (DistilBERT model)"),zxe.forEach(t),mGo=i(J),N4=n(J,"LI",{});var Wxe=s(N4);dhe=n(Wxe,"STRONG",{});var oht=s(dhe);gGo=r(oht,"electra"),oht.forEach(t),hGo=r(Wxe," \u2014 "),lV=n(Wxe,"A",{href:!0});var rht=s(lV);pGo=r(rht,"ElectraForTokenClassification"),rht.forEach(t),uGo=r(Wxe," (ELECTRA model)"),Wxe.forEach(t),_Go=i(J),j4=n(J,"LI",{});var Qxe=s(j4);che=n(Qxe,"STRONG",{});var tht=s(che);bGo=r(tht,"flaubert"),tht.forEach(t),vGo=r(Qxe," \u2014 "),iV=n(Qxe,"A",{href:!0});var aht=s(iV);FGo=r(aht,"FlaubertForTokenClassification"),aht.forEach(t),TGo=r(Qxe," (FlauBERT model)"),Qxe.forEach(t),MGo=i(J),D4=n(J,"LI",{});var Hxe=s(D4);fhe=n(Hxe,"STRONG",{});var nht=s(fhe);EGo=r(nht,"fnet"),nht.forEach(t),CGo=r(Hxe," \u2014 "),dV=n(Hxe,"A",{href:!0});var sht=s(dV);wGo=r(sht,"FNetForTokenClassification"),sht.forEach(t),AGo=r(Hxe," (FNet model)"),Hxe.forEach(t),yGo=i(J),G4=n(J,"LI",{});var Uxe=s(G4);mhe=n(Uxe,"STRONG",{});var lht=s(mhe);LGo=r(lht,"funnel"),lht.forEach(t),xGo=r(Uxe," \u2014 "),cV=n(Uxe,"A",{href:!0});var iht=s(cV);$Go=r(iht,"FunnelForTokenClassification"),iht.forEach(t),kGo=r(Uxe," (Funnel Transformer model)"),Uxe.forEach(t),SGo=i(J),O4=n(J,"LI",{});var Jxe=s(O4);ghe=n(Jxe,"STRONG",{});var dht=s(ghe);RGo=r(dht,"gpt2"),dht.forEach(t),PGo=r(Jxe," \u2014 "),fV=n(Jxe,"A",{href:!0});var cht=s(fV);BGo=r(cht,"GPT2ForTokenClassification"),cht.forEach(t),IGo=r(Jxe," (OpenAI GPT-2 model)"),Jxe.forEach(t),qGo=i(J),V4=n(J,"LI",{});var Yxe=s(V4);hhe=n(Yxe,"STRONG",{});var fht=s(hhe);NGo=r(fht,"ibert"),fht.forEach(t),jGo=r(Yxe," \u2014 "),mV=n(Yxe,"A",{href:!0});var mht=s(mV);DGo=r(mht,"IBertForTokenClassification"),mht.forEach(t),GGo=r(Yxe," (I-BERT model)"),Yxe.forEach(t),OGo=i(J),X4=n(J,"LI",{});var Kxe=s(X4);phe=n(Kxe,"STRONG",{});var ght=s(phe);VGo=r(ght,"layoutlm"),ght.forEach(t),XGo=r(Kxe," \u2014 "),gV=n(Kxe,"A",{href:!0});var hht=s(gV);zGo=r(hht,"LayoutLMForTokenClassification"),hht.forEach(t),WGo=r(Kxe," (LayoutLM model)"),Kxe.forEach(t),QGo=i(J),z4=n(J,"LI",{});var Zxe=s(z4);uhe=n(Zxe,"STRONG",{});var pht=s(uhe);HGo=r(pht,"layoutlmv2"),pht.forEach(t),UGo=r(Zxe," \u2014 "),hV=n(Zxe,"A",{href:!0});var uht=s(hV);JGo=r(uht,"LayoutLMv2ForTokenClassification"),uht.forEach(t),YGo=r(Zxe," (LayoutLMv2 model)"),Zxe.forEach(t),KGo=i(J),W4=n(J,"LI",{});var e$e=s(W4);_he=n(e$e,"STRONG",{});var _ht=s(_he);ZGo=r(_ht,"layoutlmv3"),_ht.forEach(t),eOo=r(e$e," \u2014 "),pV=n(e$e,"A",{href:!0});var bht=s(pV);oOo=r(bht,"LayoutLMv3ForTokenClassification"),bht.forEach(t),rOo=r(e$e," (LayoutLMv3 model)"),e$e.forEach(t),tOo=i(J),Q4=n(J,"LI",{});var o$e=s(Q4);bhe=n(o$e,"STRONG",{});var vht=s(bhe);aOo=r(vht,"longformer"),vht.forEach(t),nOo=r(o$e," \u2014 "),uV=n(o$e,"A",{href:!0});var Fht=s(uV);sOo=r(Fht,"LongformerForTokenClassification"),Fht.forEach(t),lOo=r(o$e," (Longformer model)"),o$e.forEach(t),iOo=i(J),H4=n(J,"LI",{});var r$e=s(H4);vhe=n(r$e,"STRONG",{});var Tht=s(vhe);dOo=r(Tht,"megatron-bert"),Tht.forEach(t),cOo=r(r$e," \u2014 "),_V=n(r$e,"A",{href:!0});var Mht=s(_V);fOo=r(Mht,"MegatronBertForTokenClassification"),Mht.forEach(t),mOo=r(r$e," (MegatronBert model)"),r$e.forEach(t),gOo=i(J),U4=n(J,"LI",{});var t$e=s(U4);Fhe=n(t$e,"STRONG",{});var Eht=s(Fhe);hOo=r(Eht,"mobilebert"),Eht.forEach(t),pOo=r(t$e," \u2014 "),bV=n(t$e,"A",{href:!0});var Cht=s(bV);uOo=r(Cht,"MobileBertForTokenClassification"),Cht.forEach(t),_Oo=r(t$e," (MobileBERT model)"),t$e.forEach(t),bOo=i(J),J4=n(J,"LI",{});var a$e=s(J4);The=n(a$e,"STRONG",{});var wht=s(The);vOo=r(wht,"mpnet"),wht.forEach(t),FOo=r(a$e," \u2014 "),vV=n(a$e,"A",{href:!0});var Aht=s(vV);TOo=r(Aht,"MPNetForTokenClassification"),Aht.forEach(t),MOo=r(a$e," (MPNet model)"),a$e.forEach(t),EOo=i(J),Y4=n(J,"LI",{});var n$e=s(Y4);Mhe=n(n$e,"STRONG",{});var yht=s(Mhe);COo=r(yht,"nystromformer"),yht.forEach(t),wOo=r(n$e," \u2014 "),FV=n(n$e,"A",{href:!0});var Lht=s(FV);AOo=r(Lht,"NystromformerForTokenClassification"),Lht.forEach(t),yOo=r(n$e," (Nystromformer model)"),n$e.forEach(t),LOo=i(J),K4=n(J,"LI",{});var s$e=s(K4);Ehe=n(s$e,"STRONG",{});var xht=s(Ehe);xOo=r(xht,"qdqbert"),xht.forEach(t),$Oo=r(s$e," \u2014 "),TV=n(s$e,"A",{href:!0});var $ht=s(TV);kOo=r($ht,"QDQBertForTokenClassification"),$ht.forEach(t),SOo=r(s$e," (QDQBert model)"),s$e.forEach(t),ROo=i(J),Z4=n(J,"LI",{});var l$e=s(Z4);Che=n(l$e,"STRONG",{});var kht=s(Che);POo=r(kht,"rembert"),kht.forEach(t),BOo=r(l$e," \u2014 "),MV=n(l$e,"A",{href:!0});var Sht=s(MV);IOo=r(Sht,"RemBertForTokenClassification"),Sht.forEach(t),qOo=r(l$e," (RemBERT model)"),l$e.forEach(t),NOo=i(J),ev=n(J,"LI",{});var i$e=s(ev);whe=n(i$e,"STRONG",{});var Rht=s(whe);jOo=r(Rht,"roberta"),Rht.forEach(t),DOo=r(i$e," \u2014 "),EV=n(i$e,"A",{href:!0});var Pht=s(EV);GOo=r(Pht,"RobertaForTokenClassification"),Pht.forEach(t),OOo=r(i$e," (RoBERTa model)"),i$e.forEach(t),VOo=i(J),ov=n(J,"LI",{});var d$e=s(ov);Ahe=n(d$e,"STRONG",{});var Bht=s(Ahe);XOo=r(Bht,"roformer"),Bht.forEach(t),zOo=r(d$e," \u2014 "),CV=n(d$e,"A",{href:!0});var Iht=s(CV);WOo=r(Iht,"RoFormerForTokenClassification"),Iht.forEach(t),QOo=r(d$e," (RoFormer model)"),d$e.forEach(t),HOo=i(J),rv=n(J,"LI",{});var c$e=s(rv);yhe=n(c$e,"STRONG",{});var qht=s(yhe);UOo=r(qht,"squeezebert"),qht.forEach(t),JOo=r(c$e," \u2014 "),wV=n(c$e,"A",{href:!0});var Nht=s(wV);YOo=r(Nht,"SqueezeBertForTokenClassification"),Nht.forEach(t),KOo=r(c$e," (SqueezeBERT model)"),c$e.forEach(t),ZOo=i(J),tv=n(J,"LI",{});var f$e=s(tv);Lhe=n(f$e,"STRONG",{});var jht=s(Lhe);eVo=r(jht,"xlm"),jht.forEach(t),oVo=r(f$e," \u2014 "),AV=n(f$e,"A",{href:!0});var Dht=s(AV);rVo=r(Dht,"XLMForTokenClassification"),Dht.forEach(t),tVo=r(f$e," (XLM model)"),f$e.forEach(t),aVo=i(J),av=n(J,"LI",{});var m$e=s(av);xhe=n(m$e,"STRONG",{});var Ght=s(xhe);nVo=r(Ght,"xlm-roberta"),Ght.forEach(t),sVo=r(m$e," \u2014 "),yV=n(m$e,"A",{href:!0});var Oht=s(yV);lVo=r(Oht,"XLMRobertaForTokenClassification"),Oht.forEach(t),iVo=r(m$e," (XLM-RoBERTa model)"),m$e.forEach(t),dVo=i(J),nv=n(J,"LI",{});var g$e=s(nv);$he=n(g$e,"STRONG",{});var Vht=s($he);cVo=r(Vht,"xlm-roberta-xl"),Vht.forEach(t),fVo=r(g$e," \u2014 "),LV=n(g$e,"A",{href:!0});var Xht=s(LV);mVo=r(Xht,"XLMRobertaXLForTokenClassification"),Xht.forEach(t),gVo=r(g$e," (XLM-RoBERTa-XL model)"),g$e.forEach(t),hVo=i(J),sv=n(J,"LI",{});var h$e=s(sv);khe=n(h$e,"STRONG",{});var zht=s(khe);pVo=r(zht,"xlnet"),zht.forEach(t),uVo=r(h$e," \u2014 "),xV=n(h$e,"A",{href:!0});var Wht=s(xV);_Vo=r(Wht,"XLNetForTokenClassification"),Wht.forEach(t),bVo=r(h$e," (XLNet model)"),h$e.forEach(t),vVo=i(J),lv=n(J,"LI",{});var p$e=s(lv);She=n(p$e,"STRONG",{});var Qht=s(She);FVo=r(Qht,"yoso"),Qht.forEach(t),TVo=r(p$e," \u2014 "),$V=n(p$e,"A",{href:!0});var Hht=s($V);MVo=r(Hht,"YosoForTokenClassification"),Hht.forEach(t),EVo=r(p$e," (YOSO model)"),p$e.forEach(t),J.forEach(t),CVo=i(da),iv=n(da,"P",{});var u$e=s(iv);wVo=r(u$e,"The model is set in evaluation mode by default using "),Rhe=n(u$e,"CODE",{});var Uht=s(Rhe);AVo=r(Uht,"model.eval()"),Uht.forEach(t),yVo=r(u$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Phe=n(u$e,"CODE",{});var Jht=s(Phe);LVo=r(Jht,"model.train()"),Jht.forEach(t),u$e.forEach(t),xVo=i(da),T(dv.$$.fragment,da),da.forEach(t),Zs.forEach(t),SNe=i(f),od=n(f,"H2",{class:!0});var IDe=s(od);cv=n(IDe,"A",{id:!0,class:!0,href:!0});var Yht=s(cv);Bhe=n(Yht,"SPAN",{});var Kht=s(Bhe);T(Xy.$$.fragment,Kht),Kht.forEach(t),Yht.forEach(t),$Vo=i(IDe),Ihe=n(IDe,"SPAN",{});var Zht=s(Ihe);kVo=r(Zht,"AutoModelForQuestionAnswering"),Zht.forEach(t),IDe.forEach(t),RNe=i(f),qo=n(f,"DIV",{class:!0});var el=s(qo);T(zy.$$.fragment,el),SVo=i(el),rd=n(el,"P",{});var jZ=s(rd);RVo=r(jZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),kV=n(jZ,"A",{href:!0});var ept=s(kV);PVo=r(ept,"from_pretrained()"),ept.forEach(t),BVo=r(jZ," class method or the "),SV=n(jZ,"A",{href:!0});var opt=s(SV);IVo=r(opt,"from_config()"),opt.forEach(t),qVo=r(jZ,` class
method.`),jZ.forEach(t),NVo=i(el),Wy=n(el,"P",{});var qDe=s(Wy);jVo=r(qDe,"This class cannot be instantiated directly using "),qhe=n(qDe,"CODE",{});var rpt=s(qhe);DVo=r(rpt,"__init__()"),rpt.forEach(t),GVo=r(qDe," (throws an error)."),qDe.forEach(t),OVo=i(el),mt=n(el,"DIV",{class:!0});var U0=s(mt);T(Qy.$$.fragment,U0),VVo=i(U0),Nhe=n(U0,"P",{});var tpt=s(Nhe);XVo=r(tpt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),tpt.forEach(t),zVo=i(U0),td=n(U0,"P",{});var DZ=s(td);WVo=r(DZ,`Note:
Loading a model from its configuration file does `),jhe=n(DZ,"STRONG",{});var apt=s(jhe);QVo=r(apt,"not"),apt.forEach(t),HVo=r(DZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),RV=n(DZ,"A",{href:!0});var npt=s(RV);UVo=r(npt,"from_pretrained()"),npt.forEach(t),JVo=r(DZ," to load the model weights."),DZ.forEach(t),YVo=i(U0),T(fv.$$.fragment,U0),U0.forEach(t),KVo=i(el),no=n(el,"DIV",{class:!0});var ca=s(no);T(Hy.$$.fragment,ca),ZVo=i(ca),Dhe=n(ca,"P",{});var spt=s(Dhe);eXo=r(spt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),spt.forEach(t),oXo=i(ca),qa=n(ca,"P",{});var J0=s(qa);rXo=r(J0,"The model class to instantiate is selected based on the "),Ghe=n(J0,"CODE",{});var lpt=s(Ghe);tXo=r(lpt,"model_type"),lpt.forEach(t),aXo=r(J0,` property of the config object (either
passed as an argument or loaded from `),Ohe=n(J0,"CODE",{});var ipt=s(Ohe);nXo=r(ipt,"pretrained_model_name_or_path"),ipt.forEach(t),sXo=r(J0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vhe=n(J0,"CODE",{});var dpt=s(Vhe);lXo=r(dpt,"pretrained_model_name_or_path"),dpt.forEach(t),iXo=r(J0,":"),J0.forEach(t),dXo=i(ca),V=n(ca,"UL",{});var X=s(V);mv=n(X,"LI",{});var _$e=s(mv);Xhe=n(_$e,"STRONG",{});var cpt=s(Xhe);cXo=r(cpt,"albert"),cpt.forEach(t),fXo=r(_$e," \u2014 "),PV=n(_$e,"A",{href:!0});var fpt=s(PV);mXo=r(fpt,"AlbertForQuestionAnswering"),fpt.forEach(t),gXo=r(_$e," (ALBERT model)"),_$e.forEach(t),hXo=i(X),gv=n(X,"LI",{});var b$e=s(gv);zhe=n(b$e,"STRONG",{});var mpt=s(zhe);pXo=r(mpt,"bart"),mpt.forEach(t),uXo=r(b$e," \u2014 "),BV=n(b$e,"A",{href:!0});var gpt=s(BV);_Xo=r(gpt,"BartForQuestionAnswering"),gpt.forEach(t),bXo=r(b$e," (BART model)"),b$e.forEach(t),vXo=i(X),hv=n(X,"LI",{});var v$e=s(hv);Whe=n(v$e,"STRONG",{});var hpt=s(Whe);FXo=r(hpt,"bert"),hpt.forEach(t),TXo=r(v$e," \u2014 "),IV=n(v$e,"A",{href:!0});var ppt=s(IV);MXo=r(ppt,"BertForQuestionAnswering"),ppt.forEach(t),EXo=r(v$e," (BERT model)"),v$e.forEach(t),CXo=i(X),pv=n(X,"LI",{});var F$e=s(pv);Qhe=n(F$e,"STRONG",{});var upt=s(Qhe);wXo=r(upt,"big_bird"),upt.forEach(t),AXo=r(F$e," \u2014 "),qV=n(F$e,"A",{href:!0});var _pt=s(qV);yXo=r(_pt,"BigBirdForQuestionAnswering"),_pt.forEach(t),LXo=r(F$e," (BigBird model)"),F$e.forEach(t),xXo=i(X),uv=n(X,"LI",{});var T$e=s(uv);Hhe=n(T$e,"STRONG",{});var bpt=s(Hhe);$Xo=r(bpt,"bigbird_pegasus"),bpt.forEach(t),kXo=r(T$e," \u2014 "),NV=n(T$e,"A",{href:!0});var vpt=s(NV);SXo=r(vpt,"BigBirdPegasusForQuestionAnswering"),vpt.forEach(t),RXo=r(T$e," (BigBirdPegasus model)"),T$e.forEach(t),PXo=i(X),_v=n(X,"LI",{});var M$e=s(_v);Uhe=n(M$e,"STRONG",{});var Fpt=s(Uhe);BXo=r(Fpt,"camembert"),Fpt.forEach(t),IXo=r(M$e," \u2014 "),jV=n(M$e,"A",{href:!0});var Tpt=s(jV);qXo=r(Tpt,"CamembertForQuestionAnswering"),Tpt.forEach(t),NXo=r(M$e," (CamemBERT model)"),M$e.forEach(t),jXo=i(X),bv=n(X,"LI",{});var E$e=s(bv);Jhe=n(E$e,"STRONG",{});var Mpt=s(Jhe);DXo=r(Mpt,"canine"),Mpt.forEach(t),GXo=r(E$e," \u2014 "),DV=n(E$e,"A",{href:!0});var Ept=s(DV);OXo=r(Ept,"CanineForQuestionAnswering"),Ept.forEach(t),VXo=r(E$e," (Canine model)"),E$e.forEach(t),XXo=i(X),vv=n(X,"LI",{});var C$e=s(vv);Yhe=n(C$e,"STRONG",{});var Cpt=s(Yhe);zXo=r(Cpt,"convbert"),Cpt.forEach(t),WXo=r(C$e," \u2014 "),GV=n(C$e,"A",{href:!0});var wpt=s(GV);QXo=r(wpt,"ConvBertForQuestionAnswering"),wpt.forEach(t),HXo=r(C$e," (ConvBERT model)"),C$e.forEach(t),UXo=i(X),Fv=n(X,"LI",{});var w$e=s(Fv);Khe=n(w$e,"STRONG",{});var Apt=s(Khe);JXo=r(Apt,"data2vec-text"),Apt.forEach(t),YXo=r(w$e," \u2014 "),OV=n(w$e,"A",{href:!0});var ypt=s(OV);KXo=r(ypt,"Data2VecTextForQuestionAnswering"),ypt.forEach(t),ZXo=r(w$e," (Data2VecText model)"),w$e.forEach(t),ezo=i(X),Tv=n(X,"LI",{});var A$e=s(Tv);Zhe=n(A$e,"STRONG",{});var Lpt=s(Zhe);ozo=r(Lpt,"deberta"),Lpt.forEach(t),rzo=r(A$e," \u2014 "),VV=n(A$e,"A",{href:!0});var xpt=s(VV);tzo=r(xpt,"DebertaForQuestionAnswering"),xpt.forEach(t),azo=r(A$e," (DeBERTa model)"),A$e.forEach(t),nzo=i(X),Mv=n(X,"LI",{});var y$e=s(Mv);epe=n(y$e,"STRONG",{});var $pt=s(epe);szo=r($pt,"deberta-v2"),$pt.forEach(t),lzo=r(y$e," \u2014 "),XV=n(y$e,"A",{href:!0});var kpt=s(XV);izo=r(kpt,"DebertaV2ForQuestionAnswering"),kpt.forEach(t),dzo=r(y$e," (DeBERTa-v2 model)"),y$e.forEach(t),czo=i(X),Ev=n(X,"LI",{});var L$e=s(Ev);ope=n(L$e,"STRONG",{});var Spt=s(ope);fzo=r(Spt,"distilbert"),Spt.forEach(t),mzo=r(L$e," \u2014 "),zV=n(L$e,"A",{href:!0});var Rpt=s(zV);gzo=r(Rpt,"DistilBertForQuestionAnswering"),Rpt.forEach(t),hzo=r(L$e," (DistilBERT model)"),L$e.forEach(t),pzo=i(X),Cv=n(X,"LI",{});var x$e=s(Cv);rpe=n(x$e,"STRONG",{});var Ppt=s(rpe);uzo=r(Ppt,"electra"),Ppt.forEach(t),_zo=r(x$e," \u2014 "),WV=n(x$e,"A",{href:!0});var Bpt=s(WV);bzo=r(Bpt,"ElectraForQuestionAnswering"),Bpt.forEach(t),vzo=r(x$e," (ELECTRA model)"),x$e.forEach(t),Fzo=i(X),wv=n(X,"LI",{});var $$e=s(wv);tpe=n($$e,"STRONG",{});var Ipt=s(tpe);Tzo=r(Ipt,"flaubert"),Ipt.forEach(t),Mzo=r($$e," \u2014 "),QV=n($$e,"A",{href:!0});var qpt=s(QV);Ezo=r(qpt,"FlaubertForQuestionAnsweringSimple"),qpt.forEach(t),Czo=r($$e," (FlauBERT model)"),$$e.forEach(t),wzo=i(X),Av=n(X,"LI",{});var k$e=s(Av);ape=n(k$e,"STRONG",{});var Npt=s(ape);Azo=r(Npt,"fnet"),Npt.forEach(t),yzo=r(k$e," \u2014 "),HV=n(k$e,"A",{href:!0});var jpt=s(HV);Lzo=r(jpt,"FNetForQuestionAnswering"),jpt.forEach(t),xzo=r(k$e," (FNet model)"),k$e.forEach(t),$zo=i(X),yv=n(X,"LI",{});var S$e=s(yv);npe=n(S$e,"STRONG",{});var Dpt=s(npe);kzo=r(Dpt,"funnel"),Dpt.forEach(t),Szo=r(S$e," \u2014 "),UV=n(S$e,"A",{href:!0});var Gpt=s(UV);Rzo=r(Gpt,"FunnelForQuestionAnswering"),Gpt.forEach(t),Pzo=r(S$e," (Funnel Transformer model)"),S$e.forEach(t),Bzo=i(X),Lv=n(X,"LI",{});var R$e=s(Lv);spe=n(R$e,"STRONG",{});var Opt=s(spe);Izo=r(Opt,"gptj"),Opt.forEach(t),qzo=r(R$e," \u2014 "),JV=n(R$e,"A",{href:!0});var Vpt=s(JV);Nzo=r(Vpt,"GPTJForQuestionAnswering"),Vpt.forEach(t),jzo=r(R$e," (GPT-J model)"),R$e.forEach(t),Dzo=i(X),xv=n(X,"LI",{});var P$e=s(xv);lpe=n(P$e,"STRONG",{});var Xpt=s(lpe);Gzo=r(Xpt,"ibert"),Xpt.forEach(t),Ozo=r(P$e," \u2014 "),YV=n(P$e,"A",{href:!0});var zpt=s(YV);Vzo=r(zpt,"IBertForQuestionAnswering"),zpt.forEach(t),Xzo=r(P$e," (I-BERT model)"),P$e.forEach(t),zzo=i(X),$v=n(X,"LI",{});var B$e=s($v);ipe=n(B$e,"STRONG",{});var Wpt=s(ipe);Wzo=r(Wpt,"layoutlmv2"),Wpt.forEach(t),Qzo=r(B$e," \u2014 "),KV=n(B$e,"A",{href:!0});var Qpt=s(KV);Hzo=r(Qpt,"LayoutLMv2ForQuestionAnswering"),Qpt.forEach(t),Uzo=r(B$e," (LayoutLMv2 model)"),B$e.forEach(t),Jzo=i(X),kv=n(X,"LI",{});var I$e=s(kv);dpe=n(I$e,"STRONG",{});var Hpt=s(dpe);Yzo=r(Hpt,"layoutlmv3"),Hpt.forEach(t),Kzo=r(I$e," \u2014 "),ZV=n(I$e,"A",{href:!0});var Upt=s(ZV);Zzo=r(Upt,"LayoutLMv3ForQuestionAnswering"),Upt.forEach(t),eWo=r(I$e," (LayoutLMv3 model)"),I$e.forEach(t),oWo=i(X),Sv=n(X,"LI",{});var q$e=s(Sv);cpe=n(q$e,"STRONG",{});var Jpt=s(cpe);rWo=r(Jpt,"led"),Jpt.forEach(t),tWo=r(q$e," \u2014 "),eX=n(q$e,"A",{href:!0});var Ypt=s(eX);aWo=r(Ypt,"LEDForQuestionAnswering"),Ypt.forEach(t),nWo=r(q$e," (LED model)"),q$e.forEach(t),sWo=i(X),Rv=n(X,"LI",{});var N$e=s(Rv);fpe=n(N$e,"STRONG",{});var Kpt=s(fpe);lWo=r(Kpt,"longformer"),Kpt.forEach(t),iWo=r(N$e," \u2014 "),oX=n(N$e,"A",{href:!0});var Zpt=s(oX);dWo=r(Zpt,"LongformerForQuestionAnswering"),Zpt.forEach(t),cWo=r(N$e," (Longformer model)"),N$e.forEach(t),fWo=i(X),Pv=n(X,"LI",{});var j$e=s(Pv);mpe=n(j$e,"STRONG",{});var eut=s(mpe);mWo=r(eut,"lxmert"),eut.forEach(t),gWo=r(j$e," \u2014 "),rX=n(j$e,"A",{href:!0});var out=s(rX);hWo=r(out,"LxmertForQuestionAnswering"),out.forEach(t),pWo=r(j$e," (LXMERT model)"),j$e.forEach(t),uWo=i(X),Bv=n(X,"LI",{});var D$e=s(Bv);gpe=n(D$e,"STRONG",{});var rut=s(gpe);_Wo=r(rut,"mbart"),rut.forEach(t),bWo=r(D$e," \u2014 "),tX=n(D$e,"A",{href:!0});var tut=s(tX);vWo=r(tut,"MBartForQuestionAnswering"),tut.forEach(t),FWo=r(D$e," (mBART model)"),D$e.forEach(t),TWo=i(X),Iv=n(X,"LI",{});var G$e=s(Iv);hpe=n(G$e,"STRONG",{});var aut=s(hpe);MWo=r(aut,"megatron-bert"),aut.forEach(t),EWo=r(G$e," \u2014 "),aX=n(G$e,"A",{href:!0});var nut=s(aX);CWo=r(nut,"MegatronBertForQuestionAnswering"),nut.forEach(t),wWo=r(G$e," (MegatronBert model)"),G$e.forEach(t),AWo=i(X),qv=n(X,"LI",{});var O$e=s(qv);ppe=n(O$e,"STRONG",{});var sut=s(ppe);yWo=r(sut,"mobilebert"),sut.forEach(t),LWo=r(O$e," \u2014 "),nX=n(O$e,"A",{href:!0});var lut=s(nX);xWo=r(lut,"MobileBertForQuestionAnswering"),lut.forEach(t),$Wo=r(O$e," (MobileBERT model)"),O$e.forEach(t),kWo=i(X),Nv=n(X,"LI",{});var V$e=s(Nv);upe=n(V$e,"STRONG",{});var iut=s(upe);SWo=r(iut,"mpnet"),iut.forEach(t),RWo=r(V$e," \u2014 "),sX=n(V$e,"A",{href:!0});var dut=s(sX);PWo=r(dut,"MPNetForQuestionAnswering"),dut.forEach(t),BWo=r(V$e," (MPNet model)"),V$e.forEach(t),IWo=i(X),jv=n(X,"LI",{});var X$e=s(jv);_pe=n(X$e,"STRONG",{});var cut=s(_pe);qWo=r(cut,"nystromformer"),cut.forEach(t),NWo=r(X$e," \u2014 "),lX=n(X$e,"A",{href:!0});var fut=s(lX);jWo=r(fut,"NystromformerForQuestionAnswering"),fut.forEach(t),DWo=r(X$e," (Nystromformer model)"),X$e.forEach(t),GWo=i(X),Dv=n(X,"LI",{});var z$e=s(Dv);bpe=n(z$e,"STRONG",{});var mut=s(bpe);OWo=r(mut,"qdqbert"),mut.forEach(t),VWo=r(z$e," \u2014 "),iX=n(z$e,"A",{href:!0});var gut=s(iX);XWo=r(gut,"QDQBertForQuestionAnswering"),gut.forEach(t),zWo=r(z$e," (QDQBert model)"),z$e.forEach(t),WWo=i(X),Gv=n(X,"LI",{});var W$e=s(Gv);vpe=n(W$e,"STRONG",{});var hut=s(vpe);QWo=r(hut,"reformer"),hut.forEach(t),HWo=r(W$e," \u2014 "),dX=n(W$e,"A",{href:!0});var put=s(dX);UWo=r(put,"ReformerForQuestionAnswering"),put.forEach(t),JWo=r(W$e," (Reformer model)"),W$e.forEach(t),YWo=i(X),Ov=n(X,"LI",{});var Q$e=s(Ov);Fpe=n(Q$e,"STRONG",{});var uut=s(Fpe);KWo=r(uut,"rembert"),uut.forEach(t),ZWo=r(Q$e," \u2014 "),cX=n(Q$e,"A",{href:!0});var _ut=s(cX);eQo=r(_ut,"RemBertForQuestionAnswering"),_ut.forEach(t),oQo=r(Q$e," (RemBERT model)"),Q$e.forEach(t),rQo=i(X),Vv=n(X,"LI",{});var H$e=s(Vv);Tpe=n(H$e,"STRONG",{});var but=s(Tpe);tQo=r(but,"roberta"),but.forEach(t),aQo=r(H$e," \u2014 "),fX=n(H$e,"A",{href:!0});var vut=s(fX);nQo=r(vut,"RobertaForQuestionAnswering"),vut.forEach(t),sQo=r(H$e," (RoBERTa model)"),H$e.forEach(t),lQo=i(X),Xv=n(X,"LI",{});var U$e=s(Xv);Mpe=n(U$e,"STRONG",{});var Fut=s(Mpe);iQo=r(Fut,"roformer"),Fut.forEach(t),dQo=r(U$e," \u2014 "),mX=n(U$e,"A",{href:!0});var Tut=s(mX);cQo=r(Tut,"RoFormerForQuestionAnswering"),Tut.forEach(t),fQo=r(U$e," (RoFormer model)"),U$e.forEach(t),mQo=i(X),zv=n(X,"LI",{});var J$e=s(zv);Epe=n(J$e,"STRONG",{});var Mut=s(Epe);gQo=r(Mut,"splinter"),Mut.forEach(t),hQo=r(J$e," \u2014 "),gX=n(J$e,"A",{href:!0});var Eut=s(gX);pQo=r(Eut,"SplinterForQuestionAnswering"),Eut.forEach(t),uQo=r(J$e," (Splinter model)"),J$e.forEach(t),_Qo=i(X),Wv=n(X,"LI",{});var Y$e=s(Wv);Cpe=n(Y$e,"STRONG",{});var Cut=s(Cpe);bQo=r(Cut,"squeezebert"),Cut.forEach(t),vQo=r(Y$e," \u2014 "),hX=n(Y$e,"A",{href:!0});var wut=s(hX);FQo=r(wut,"SqueezeBertForQuestionAnswering"),wut.forEach(t),TQo=r(Y$e," (SqueezeBERT model)"),Y$e.forEach(t),MQo=i(X),Qv=n(X,"LI",{});var K$e=s(Qv);wpe=n(K$e,"STRONG",{});var Aut=s(wpe);EQo=r(Aut,"xlm"),Aut.forEach(t),CQo=r(K$e," \u2014 "),pX=n(K$e,"A",{href:!0});var yut=s(pX);wQo=r(yut,"XLMForQuestionAnsweringSimple"),yut.forEach(t),AQo=r(K$e," (XLM model)"),K$e.forEach(t),yQo=i(X),Hv=n(X,"LI",{});var Z$e=s(Hv);Ape=n(Z$e,"STRONG",{});var Lut=s(Ape);LQo=r(Lut,"xlm-roberta"),Lut.forEach(t),xQo=r(Z$e," \u2014 "),uX=n(Z$e,"A",{href:!0});var xut=s(uX);$Qo=r(xut,"XLMRobertaForQuestionAnswering"),xut.forEach(t),kQo=r(Z$e," (XLM-RoBERTa model)"),Z$e.forEach(t),SQo=i(X),Uv=n(X,"LI",{});var eke=s(Uv);ype=n(eke,"STRONG",{});var $ut=s(ype);RQo=r($ut,"xlm-roberta-xl"),$ut.forEach(t),PQo=r(eke," \u2014 "),_X=n(eke,"A",{href:!0});var kut=s(_X);BQo=r(kut,"XLMRobertaXLForQuestionAnswering"),kut.forEach(t),IQo=r(eke," (XLM-RoBERTa-XL model)"),eke.forEach(t),qQo=i(X),Jv=n(X,"LI",{});var oke=s(Jv);Lpe=n(oke,"STRONG",{});var Sut=s(Lpe);NQo=r(Sut,"xlnet"),Sut.forEach(t),jQo=r(oke," \u2014 "),bX=n(oke,"A",{href:!0});var Rut=s(bX);DQo=r(Rut,"XLNetForQuestionAnsweringSimple"),Rut.forEach(t),GQo=r(oke," (XLNet model)"),oke.forEach(t),OQo=i(X),Yv=n(X,"LI",{});var rke=s(Yv);xpe=n(rke,"STRONG",{});var Put=s(xpe);VQo=r(Put,"yoso"),Put.forEach(t),XQo=r(rke," \u2014 "),vX=n(rke,"A",{href:!0});var But=s(vX);zQo=r(But,"YosoForQuestionAnswering"),But.forEach(t),WQo=r(rke," (YOSO model)"),rke.forEach(t),X.forEach(t),QQo=i(ca),Kv=n(ca,"P",{});var tke=s(Kv);HQo=r(tke,"The model is set in evaluation mode by default using "),$pe=n(tke,"CODE",{});var Iut=s($pe);UQo=r(Iut,"model.eval()"),Iut.forEach(t),JQo=r(tke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kpe=n(tke,"CODE",{});var qut=s(kpe);YQo=r(qut,"model.train()"),qut.forEach(t),tke.forEach(t),KQo=i(ca),T(Zv.$$.fragment,ca),ca.forEach(t),el.forEach(t),PNe=i(f),ad=n(f,"H2",{class:!0});var NDe=s(ad);e5=n(NDe,"A",{id:!0,class:!0,href:!0});var Nut=s(e5);Spe=n(Nut,"SPAN",{});var jut=s(Spe);T(Uy.$$.fragment,jut),jut.forEach(t),Nut.forEach(t),ZQo=i(NDe),Rpe=n(NDe,"SPAN",{});var Dut=s(Rpe);eHo=r(Dut,"AutoModelForTableQuestionAnswering"),Dut.forEach(t),NDe.forEach(t),BNe=i(f),No=n(f,"DIV",{class:!0});var ol=s(No);T(Jy.$$.fragment,ol),oHo=i(ol),nd=n(ol,"P",{});var GZ=s(nd);rHo=r(GZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),FX=n(GZ,"A",{href:!0});var Gut=s(FX);tHo=r(Gut,"from_pretrained()"),Gut.forEach(t),aHo=r(GZ," class method or the "),TX=n(GZ,"A",{href:!0});var Out=s(TX);nHo=r(Out,"from_config()"),Out.forEach(t),sHo=r(GZ,` class
method.`),GZ.forEach(t),lHo=i(ol),Yy=n(ol,"P",{});var jDe=s(Yy);iHo=r(jDe,"This class cannot be instantiated directly using "),Ppe=n(jDe,"CODE",{});var Vut=s(Ppe);dHo=r(Vut,"__init__()"),Vut.forEach(t),cHo=r(jDe," (throws an error)."),jDe.forEach(t),fHo=i(ol),gt=n(ol,"DIV",{class:!0});var Y0=s(gt);T(Ky.$$.fragment,Y0),mHo=i(Y0),Bpe=n(Y0,"P",{});var Xut=s(Bpe);gHo=r(Xut,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Xut.forEach(t),hHo=i(Y0),sd=n(Y0,"P",{});var OZ=s(sd);pHo=r(OZ,`Note:
Loading a model from its configuration file does `),Ipe=n(OZ,"STRONG",{});var zut=s(Ipe);uHo=r(zut,"not"),zut.forEach(t),_Ho=r(OZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=n(OZ,"A",{href:!0});var Wut=s(MX);bHo=r(Wut,"from_pretrained()"),Wut.forEach(t),vHo=r(OZ," to load the model weights."),OZ.forEach(t),FHo=i(Y0),T(o5.$$.fragment,Y0),Y0.forEach(t),THo=i(ol),so=n(ol,"DIV",{class:!0});var fa=s(so);T(Zy.$$.fragment,fa),MHo=i(fa),qpe=n(fa,"P",{});var Qut=s(qpe);EHo=r(Qut,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Qut.forEach(t),CHo=i(fa),Na=n(fa,"P",{});var K0=s(Na);wHo=r(K0,"The model class to instantiate is selected based on the "),Npe=n(K0,"CODE",{});var Hut=s(Npe);AHo=r(Hut,"model_type"),Hut.forEach(t),yHo=r(K0,` property of the config object (either
passed as an argument or loaded from `),jpe=n(K0,"CODE",{});var Uut=s(jpe);LHo=r(Uut,"pretrained_model_name_or_path"),Uut.forEach(t),xHo=r(K0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dpe=n(K0,"CODE",{});var Jut=s(Dpe);$Ho=r(Jut,"pretrained_model_name_or_path"),Jut.forEach(t),kHo=r(K0,":"),K0.forEach(t),SHo=i(fa),Gpe=n(fa,"UL",{});var Yut=s(Gpe);r5=n(Yut,"LI",{});var ake=s(r5);Ope=n(ake,"STRONG",{});var Kut=s(Ope);RHo=r(Kut,"tapas"),Kut.forEach(t),PHo=r(ake," \u2014 "),EX=n(ake,"A",{href:!0});var Zut=s(EX);BHo=r(Zut,"TapasForQuestionAnswering"),Zut.forEach(t),IHo=r(ake," (TAPAS model)"),ake.forEach(t),Yut.forEach(t),qHo=i(fa),t5=n(fa,"P",{});var nke=s(t5);NHo=r(nke,"The model is set in evaluation mode by default using "),Vpe=n(nke,"CODE",{});var e_t=s(Vpe);jHo=r(e_t,"model.eval()"),e_t.forEach(t),DHo=r(nke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xpe=n(nke,"CODE",{});var o_t=s(Xpe);GHo=r(o_t,"model.train()"),o_t.forEach(t),nke.forEach(t),OHo=i(fa),T(a5.$$.fragment,fa),fa.forEach(t),ol.forEach(t),INe=i(f),ld=n(f,"H2",{class:!0});var DDe=s(ld);n5=n(DDe,"A",{id:!0,class:!0,href:!0});var r_t=s(n5);zpe=n(r_t,"SPAN",{});var t_t=s(zpe);T(eL.$$.fragment,t_t),t_t.forEach(t),r_t.forEach(t),VHo=i(DDe),Wpe=n(DDe,"SPAN",{});var a_t=s(Wpe);XHo=r(a_t,"AutoModelForImageClassification"),a_t.forEach(t),DDe.forEach(t),qNe=i(f),jo=n(f,"DIV",{class:!0});var rl=s(jo);T(oL.$$.fragment,rl),zHo=i(rl),id=n(rl,"P",{});var VZ=s(id);WHo=r(VZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),CX=n(VZ,"A",{href:!0});var n_t=s(CX);QHo=r(n_t,"from_pretrained()"),n_t.forEach(t),HHo=r(VZ," class method or the "),wX=n(VZ,"A",{href:!0});var s_t=s(wX);UHo=r(s_t,"from_config()"),s_t.forEach(t),JHo=r(VZ,` class
method.`),VZ.forEach(t),YHo=i(rl),rL=n(rl,"P",{});var GDe=s(rL);KHo=r(GDe,"This class cannot be instantiated directly using "),Qpe=n(GDe,"CODE",{});var l_t=s(Qpe);ZHo=r(l_t,"__init__()"),l_t.forEach(t),eUo=r(GDe," (throws an error)."),GDe.forEach(t),oUo=i(rl),ht=n(rl,"DIV",{class:!0});var Z0=s(ht);T(tL.$$.fragment,Z0),rUo=i(Z0),Hpe=n(Z0,"P",{});var i_t=s(Hpe);tUo=r(i_t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),i_t.forEach(t),aUo=i(Z0),dd=n(Z0,"P",{});var XZ=s(dd);nUo=r(XZ,`Note:
Loading a model from its configuration file does `),Upe=n(XZ,"STRONG",{});var d_t=s(Upe);sUo=r(d_t,"not"),d_t.forEach(t),lUo=r(XZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),AX=n(XZ,"A",{href:!0});var c_t=s(AX);iUo=r(c_t,"from_pretrained()"),c_t.forEach(t),dUo=r(XZ," to load the model weights."),XZ.forEach(t),cUo=i(Z0),T(s5.$$.fragment,Z0),Z0.forEach(t),fUo=i(rl),lo=n(rl,"DIV",{class:!0});var ma=s(lo);T(aL.$$.fragment,ma),mUo=i(ma),Jpe=n(ma,"P",{});var f_t=s(Jpe);gUo=r(f_t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),f_t.forEach(t),hUo=i(ma),ja=n(ma,"P",{});var e6=s(ja);pUo=r(e6,"The model class to instantiate is selected based on the "),Ype=n(e6,"CODE",{});var m_t=s(Ype);uUo=r(m_t,"model_type"),m_t.forEach(t),_Uo=r(e6,` property of the config object (either
passed as an argument or loaded from `),Kpe=n(e6,"CODE",{});var g_t=s(Kpe);bUo=r(g_t,"pretrained_model_name_or_path"),g_t.forEach(t),vUo=r(e6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zpe=n(e6,"CODE",{});var h_t=s(Zpe);FUo=r(h_t,"pretrained_model_name_or_path"),h_t.forEach(t),TUo=r(e6,":"),e6.forEach(t),MUo=i(ma),Fe=n(ma,"UL",{});var Te=s(Fe);l5=n(Te,"LI",{});var ske=s(l5);eue=n(ske,"STRONG",{});var p_t=s(eue);EUo=r(p_t,"beit"),p_t.forEach(t),CUo=r(ske," \u2014 "),yX=n(ske,"A",{href:!0});var u_t=s(yX);wUo=r(u_t,"BeitForImageClassification"),u_t.forEach(t),AUo=r(ske," (BEiT model)"),ske.forEach(t),yUo=i(Te),i5=n(Te,"LI",{});var lke=s(i5);oue=n(lke,"STRONG",{});var __t=s(oue);LUo=r(__t,"convnext"),__t.forEach(t),xUo=r(lke," \u2014 "),LX=n(lke,"A",{href:!0});var b_t=s(LX);$Uo=r(b_t,"ConvNextForImageClassification"),b_t.forEach(t),kUo=r(lke," (ConvNext model)"),lke.forEach(t),SUo=i(Te),d5=n(Te,"LI",{});var ike=s(d5);rue=n(ike,"STRONG",{});var v_t=s(rue);RUo=r(v_t,"cvt"),v_t.forEach(t),PUo=r(ike," \u2014 "),xX=n(ike,"A",{href:!0});var F_t=s(xX);BUo=r(F_t,"CvtForImageClassification"),F_t.forEach(t),IUo=r(ike," (CvT model)"),ike.forEach(t),qUo=i(Te),c5=n(Te,"LI",{});var dke=s(c5);tue=n(dke,"STRONG",{});var T_t=s(tue);NUo=r(T_t,"data2vec-vision"),T_t.forEach(t),jUo=r(dke," \u2014 "),$X=n(dke,"A",{href:!0});var M_t=s($X);DUo=r(M_t,"Data2VecVisionForImageClassification"),M_t.forEach(t),GUo=r(dke," (Data2VecVision model)"),dke.forEach(t),OUo=i(Te),Ns=n(Te,"LI",{});var W$=s(Ns);aue=n(W$,"STRONG",{});var E_t=s(aue);VUo=r(E_t,"deit"),E_t.forEach(t),XUo=r(W$," \u2014 "),kX=n(W$,"A",{href:!0});var C_t=s(kX);zUo=r(C_t,"DeiTForImageClassification"),C_t.forEach(t),WUo=r(W$," or "),SX=n(W$,"A",{href:!0});var w_t=s(SX);QUo=r(w_t,"DeiTForImageClassificationWithTeacher"),w_t.forEach(t),HUo=r(W$," (DeiT model)"),W$.forEach(t),UUo=i(Te),f5=n(Te,"LI",{});var cke=s(f5);nue=n(cke,"STRONG",{});var A_t=s(nue);JUo=r(A_t,"imagegpt"),A_t.forEach(t),YUo=r(cke," \u2014 "),RX=n(cke,"A",{href:!0});var y_t=s(RX);KUo=r(y_t,"ImageGPTForImageClassification"),y_t.forEach(t),ZUo=r(cke," (ImageGPT model)"),cke.forEach(t),eJo=i(Te),pt=n(Te,"LI",{});var _f=s(pt);sue=n(_f,"STRONG",{});var L_t=s(sue);oJo=r(L_t,"perceiver"),L_t.forEach(t),rJo=r(_f," \u2014 "),PX=n(_f,"A",{href:!0});var x_t=s(PX);tJo=r(x_t,"PerceiverForImageClassificationLearned"),x_t.forEach(t),aJo=r(_f," or "),BX=n(_f,"A",{href:!0});var $_t=s(BX);nJo=r($_t,"PerceiverForImageClassificationFourier"),$_t.forEach(t),sJo=r(_f," or "),IX=n(_f,"A",{href:!0});var k_t=s(IX);lJo=r(k_t,"PerceiverForImageClassificationConvProcessing"),k_t.forEach(t),iJo=r(_f," (Perceiver model)"),_f.forEach(t),dJo=i(Te),m5=n(Te,"LI",{});var fke=s(m5);lue=n(fke,"STRONG",{});var S_t=s(lue);cJo=r(S_t,"poolformer"),S_t.forEach(t),fJo=r(fke," \u2014 "),qX=n(fke,"A",{href:!0});var R_t=s(qX);mJo=r(R_t,"PoolFormerForImageClassification"),R_t.forEach(t),gJo=r(fke," (PoolFormer model)"),fke.forEach(t),hJo=i(Te),g5=n(Te,"LI",{});var mke=s(g5);iue=n(mke,"STRONG",{});var P_t=s(iue);pJo=r(P_t,"regnet"),P_t.forEach(t),uJo=r(mke," \u2014 "),NX=n(mke,"A",{href:!0});var B_t=s(NX);_Jo=r(B_t,"RegNetForImageClassification"),B_t.forEach(t),bJo=r(mke," (RegNet model)"),mke.forEach(t),vJo=i(Te),h5=n(Te,"LI",{});var gke=s(h5);due=n(gke,"STRONG",{});var I_t=s(due);FJo=r(I_t,"resnet"),I_t.forEach(t),TJo=r(gke," \u2014 "),jX=n(gke,"A",{href:!0});var q_t=s(jX);MJo=r(q_t,"ResNetForImageClassification"),q_t.forEach(t),EJo=r(gke," (ResNet model)"),gke.forEach(t),CJo=i(Te),p5=n(Te,"LI",{});var hke=s(p5);cue=n(hke,"STRONG",{});var N_t=s(cue);wJo=r(N_t,"segformer"),N_t.forEach(t),AJo=r(hke," \u2014 "),DX=n(hke,"A",{href:!0});var j_t=s(DX);yJo=r(j_t,"SegformerForImageClassification"),j_t.forEach(t),LJo=r(hke," (SegFormer model)"),hke.forEach(t),xJo=i(Te),u5=n(Te,"LI",{});var pke=s(u5);fue=n(pke,"STRONG",{});var D_t=s(fue);$Jo=r(D_t,"swin"),D_t.forEach(t),kJo=r(pke," \u2014 "),GX=n(pke,"A",{href:!0});var G_t=s(GX);SJo=r(G_t,"SwinForImageClassification"),G_t.forEach(t),RJo=r(pke," (Swin model)"),pke.forEach(t),PJo=i(Te),_5=n(Te,"LI",{});var uke=s(_5);mue=n(uke,"STRONG",{});var O_t=s(mue);BJo=r(O_t,"van"),O_t.forEach(t),IJo=r(uke," \u2014 "),OX=n(uke,"A",{href:!0});var V_t=s(OX);qJo=r(V_t,"VanForImageClassification"),V_t.forEach(t),NJo=r(uke," (VAN model)"),uke.forEach(t),jJo=i(Te),b5=n(Te,"LI",{});var _ke=s(b5);gue=n(_ke,"STRONG",{});var X_t=s(gue);DJo=r(X_t,"vit"),X_t.forEach(t),GJo=r(_ke," \u2014 "),VX=n(_ke,"A",{href:!0});var z_t=s(VX);OJo=r(z_t,"ViTForImageClassification"),z_t.forEach(t),VJo=r(_ke," (ViT model)"),_ke.forEach(t),Te.forEach(t),XJo=i(ma),v5=n(ma,"P",{});var bke=s(v5);zJo=r(bke,"The model is set in evaluation mode by default using "),hue=n(bke,"CODE",{});var W_t=s(hue);WJo=r(W_t,"model.eval()"),W_t.forEach(t),QJo=r(bke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pue=n(bke,"CODE",{});var Q_t=s(pue);HJo=r(Q_t,"model.train()"),Q_t.forEach(t),bke.forEach(t),UJo=i(ma),T(F5.$$.fragment,ma),ma.forEach(t),rl.forEach(t),NNe=i(f),cd=n(f,"H2",{class:!0});var ODe=s(cd);T5=n(ODe,"A",{id:!0,class:!0,href:!0});var H_t=s(T5);uue=n(H_t,"SPAN",{});var U_t=s(uue);T(nL.$$.fragment,U_t),U_t.forEach(t),H_t.forEach(t),JJo=i(ODe),_ue=n(ODe,"SPAN",{});var J_t=s(_ue);YJo=r(J_t,"AutoModelForVision2Seq"),J_t.forEach(t),ODe.forEach(t),jNe=i(f),Do=n(f,"DIV",{class:!0});var tl=s(Do);T(sL.$$.fragment,tl),KJo=i(tl),fd=n(tl,"P",{});var zZ=s(fd);ZJo=r(zZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),XX=n(zZ,"A",{href:!0});var Y_t=s(XX);eYo=r(Y_t,"from_pretrained()"),Y_t.forEach(t),oYo=r(zZ," class method or the "),zX=n(zZ,"A",{href:!0});var K_t=s(zX);rYo=r(K_t,"from_config()"),K_t.forEach(t),tYo=r(zZ,` class
method.`),zZ.forEach(t),aYo=i(tl),lL=n(tl,"P",{});var VDe=s(lL);nYo=r(VDe,"This class cannot be instantiated directly using "),bue=n(VDe,"CODE",{});var Z_t=s(bue);sYo=r(Z_t,"__init__()"),Z_t.forEach(t),lYo=r(VDe," (throws an error)."),VDe.forEach(t),iYo=i(tl),ut=n(tl,"DIV",{class:!0});var o6=s(ut);T(iL.$$.fragment,o6),dYo=i(o6),vue=n(o6,"P",{});var e2t=s(vue);cYo=r(e2t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),e2t.forEach(t),fYo=i(o6),md=n(o6,"P",{});var WZ=s(md);mYo=r(WZ,`Note:
Loading a model from its configuration file does `),Fue=n(WZ,"STRONG",{});var o2t=s(Fue);gYo=r(o2t,"not"),o2t.forEach(t),hYo=r(WZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),WX=n(WZ,"A",{href:!0});var r2t=s(WX);pYo=r(r2t,"from_pretrained()"),r2t.forEach(t),uYo=r(WZ," to load the model weights."),WZ.forEach(t),_Yo=i(o6),T(M5.$$.fragment,o6),o6.forEach(t),bYo=i(tl),io=n(tl,"DIV",{class:!0});var ga=s(io);T(dL.$$.fragment,ga),vYo=i(ga),Tue=n(ga,"P",{});var t2t=s(Tue);FYo=r(t2t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),t2t.forEach(t),TYo=i(ga),Da=n(ga,"P",{});var r6=s(Da);MYo=r(r6,"The model class to instantiate is selected based on the "),Mue=n(r6,"CODE",{});var a2t=s(Mue);EYo=r(a2t,"model_type"),a2t.forEach(t),CYo=r(r6,` property of the config object (either
passed as an argument or loaded from `),Eue=n(r6,"CODE",{});var n2t=s(Eue);wYo=r(n2t,"pretrained_model_name_or_path"),n2t.forEach(t),AYo=r(r6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cue=n(r6,"CODE",{});var s2t=s(Cue);yYo=r(s2t,"pretrained_model_name_or_path"),s2t.forEach(t),LYo=r(r6,":"),r6.forEach(t),xYo=i(ga),wue=n(ga,"UL",{});var l2t=s(wue);E5=n(l2t,"LI",{});var vke=s(E5);Aue=n(vke,"STRONG",{});var i2t=s(Aue);$Yo=r(i2t,"vision-encoder-decoder"),i2t.forEach(t),kYo=r(vke," \u2014 "),QX=n(vke,"A",{href:!0});var d2t=s(QX);SYo=r(d2t,"VisionEncoderDecoderModel"),d2t.forEach(t),RYo=r(vke," (Vision Encoder decoder model)"),vke.forEach(t),l2t.forEach(t),PYo=i(ga),C5=n(ga,"P",{});var Fke=s(C5);BYo=r(Fke,"The model is set in evaluation mode by default using "),yue=n(Fke,"CODE",{});var c2t=s(yue);IYo=r(c2t,"model.eval()"),c2t.forEach(t),qYo=r(Fke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lue=n(Fke,"CODE",{});var f2t=s(Lue);NYo=r(f2t,"model.train()"),f2t.forEach(t),Fke.forEach(t),jYo=i(ga),T(w5.$$.fragment,ga),ga.forEach(t),tl.forEach(t),DNe=i(f),gd=n(f,"H2",{class:!0});var XDe=s(gd);A5=n(XDe,"A",{id:!0,class:!0,href:!0});var m2t=s(A5);xue=n(m2t,"SPAN",{});var g2t=s(xue);T(cL.$$.fragment,g2t),g2t.forEach(t),m2t.forEach(t),DYo=i(XDe),$ue=n(XDe,"SPAN",{});var h2t=s($ue);GYo=r(h2t,"AutoModelForAudioClassification"),h2t.forEach(t),XDe.forEach(t),GNe=i(f),Go=n(f,"DIV",{class:!0});var al=s(Go);T(fL.$$.fragment,al),OYo=i(al),hd=n(al,"P",{});var QZ=s(hd);VYo=r(QZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),HX=n(QZ,"A",{href:!0});var p2t=s(HX);XYo=r(p2t,"from_pretrained()"),p2t.forEach(t),zYo=r(QZ," class method or the "),UX=n(QZ,"A",{href:!0});var u2t=s(UX);WYo=r(u2t,"from_config()"),u2t.forEach(t),QYo=r(QZ,` class
method.`),QZ.forEach(t),HYo=i(al),mL=n(al,"P",{});var zDe=s(mL);UYo=r(zDe,"This class cannot be instantiated directly using "),kue=n(zDe,"CODE",{});var _2t=s(kue);JYo=r(_2t,"__init__()"),_2t.forEach(t),YYo=r(zDe," (throws an error)."),zDe.forEach(t),KYo=i(al),_t=n(al,"DIV",{class:!0});var t6=s(_t);T(gL.$$.fragment,t6),ZYo=i(t6),Sue=n(t6,"P",{});var b2t=s(Sue);eKo=r(b2t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),b2t.forEach(t),oKo=i(t6),pd=n(t6,"P",{});var HZ=s(pd);rKo=r(HZ,`Note:
Loading a model from its configuration file does `),Rue=n(HZ,"STRONG",{});var v2t=s(Rue);tKo=r(v2t,"not"),v2t.forEach(t),aKo=r(HZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=n(HZ,"A",{href:!0});var F2t=s(JX);nKo=r(F2t,"from_pretrained()"),F2t.forEach(t),sKo=r(HZ," to load the model weights."),HZ.forEach(t),lKo=i(t6),T(y5.$$.fragment,t6),t6.forEach(t),iKo=i(al),co=n(al,"DIV",{class:!0});var ha=s(co);T(hL.$$.fragment,ha),dKo=i(ha),Pue=n(ha,"P",{});var T2t=s(Pue);cKo=r(T2t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),T2t.forEach(t),fKo=i(ha),Ga=n(ha,"P",{});var a6=s(Ga);mKo=r(a6,"The model class to instantiate is selected based on the "),Bue=n(a6,"CODE",{});var M2t=s(Bue);gKo=r(M2t,"model_type"),M2t.forEach(t),hKo=r(a6,` property of the config object (either
passed as an argument or loaded from `),Iue=n(a6,"CODE",{});var E2t=s(Iue);pKo=r(E2t,"pretrained_model_name_or_path"),E2t.forEach(t),uKo=r(a6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),que=n(a6,"CODE",{});var C2t=s(que);_Ko=r(C2t,"pretrained_model_name_or_path"),C2t.forEach(t),bKo=r(a6,":"),a6.forEach(t),vKo=i(ha),ke=n(ha,"UL",{});var Oe=s(ke);L5=n(Oe,"LI",{});var Tke=s(L5);Nue=n(Tke,"STRONG",{});var w2t=s(Nue);FKo=r(w2t,"data2vec-audio"),w2t.forEach(t),TKo=r(Tke," \u2014 "),YX=n(Tke,"A",{href:!0});var A2t=s(YX);MKo=r(A2t,"Data2VecAudioForSequenceClassification"),A2t.forEach(t),EKo=r(Tke," (Data2VecAudio model)"),Tke.forEach(t),CKo=i(Oe),x5=n(Oe,"LI",{});var Mke=s(x5);jue=n(Mke,"STRONG",{});var y2t=s(jue);wKo=r(y2t,"hubert"),y2t.forEach(t),AKo=r(Mke," \u2014 "),KX=n(Mke,"A",{href:!0});var L2t=s(KX);yKo=r(L2t,"HubertForSequenceClassification"),L2t.forEach(t),LKo=r(Mke," (Hubert model)"),Mke.forEach(t),xKo=i(Oe),$5=n(Oe,"LI",{});var Eke=s($5);Due=n(Eke,"STRONG",{});var x2t=s(Due);$Ko=r(x2t,"sew"),x2t.forEach(t),kKo=r(Eke," \u2014 "),ZX=n(Eke,"A",{href:!0});var $2t=s(ZX);SKo=r($2t,"SEWForSequenceClassification"),$2t.forEach(t),RKo=r(Eke," (SEW model)"),Eke.forEach(t),PKo=i(Oe),k5=n(Oe,"LI",{});var Cke=s(k5);Gue=n(Cke,"STRONG",{});var k2t=s(Gue);BKo=r(k2t,"sew-d"),k2t.forEach(t),IKo=r(Cke," \u2014 "),ez=n(Cke,"A",{href:!0});var S2t=s(ez);qKo=r(S2t,"SEWDForSequenceClassification"),S2t.forEach(t),NKo=r(Cke," (SEW-D model)"),Cke.forEach(t),jKo=i(Oe),S5=n(Oe,"LI",{});var wke=s(S5);Oue=n(wke,"STRONG",{});var R2t=s(Oue);DKo=r(R2t,"unispeech"),R2t.forEach(t),GKo=r(wke," \u2014 "),oz=n(wke,"A",{href:!0});var P2t=s(oz);OKo=r(P2t,"UniSpeechForSequenceClassification"),P2t.forEach(t),VKo=r(wke," (UniSpeech model)"),wke.forEach(t),XKo=i(Oe),R5=n(Oe,"LI",{});var Ake=s(R5);Vue=n(Ake,"STRONG",{});var B2t=s(Vue);zKo=r(B2t,"unispeech-sat"),B2t.forEach(t),WKo=r(Ake," \u2014 "),rz=n(Ake,"A",{href:!0});var I2t=s(rz);QKo=r(I2t,"UniSpeechSatForSequenceClassification"),I2t.forEach(t),HKo=r(Ake," (UniSpeechSat model)"),Ake.forEach(t),UKo=i(Oe),P5=n(Oe,"LI",{});var yke=s(P5);Xue=n(yke,"STRONG",{});var q2t=s(Xue);JKo=r(q2t,"wav2vec2"),q2t.forEach(t),YKo=r(yke," \u2014 "),tz=n(yke,"A",{href:!0});var N2t=s(tz);KKo=r(N2t,"Wav2Vec2ForSequenceClassification"),N2t.forEach(t),ZKo=r(yke," (Wav2Vec2 model)"),yke.forEach(t),eZo=i(Oe),B5=n(Oe,"LI",{});var Lke=s(B5);zue=n(Lke,"STRONG",{});var j2t=s(zue);oZo=r(j2t,"wav2vec2-conformer"),j2t.forEach(t),rZo=r(Lke," \u2014 "),az=n(Lke,"A",{href:!0});var D2t=s(az);tZo=r(D2t,"Wav2Vec2ConformerForSequenceClassification"),D2t.forEach(t),aZo=r(Lke," (Wav2Vec2-Conformer model)"),Lke.forEach(t),nZo=i(Oe),I5=n(Oe,"LI",{});var xke=s(I5);Wue=n(xke,"STRONG",{});var G2t=s(Wue);sZo=r(G2t,"wavlm"),G2t.forEach(t),lZo=r(xke," \u2014 "),nz=n(xke,"A",{href:!0});var O2t=s(nz);iZo=r(O2t,"WavLMForSequenceClassification"),O2t.forEach(t),dZo=r(xke," (WavLM model)"),xke.forEach(t),Oe.forEach(t),cZo=i(ha),q5=n(ha,"P",{});var $ke=s(q5);fZo=r($ke,"The model is set in evaluation mode by default using "),Que=n($ke,"CODE",{});var V2t=s(Que);mZo=r(V2t,"model.eval()"),V2t.forEach(t),gZo=r($ke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hue=n($ke,"CODE",{});var X2t=s(Hue);hZo=r(X2t,"model.train()"),X2t.forEach(t),$ke.forEach(t),pZo=i(ha),T(N5.$$.fragment,ha),ha.forEach(t),al.forEach(t),ONe=i(f),ud=n(f,"H2",{class:!0});var WDe=s(ud);j5=n(WDe,"A",{id:!0,class:!0,href:!0});var z2t=s(j5);Uue=n(z2t,"SPAN",{});var W2t=s(Uue);T(pL.$$.fragment,W2t),W2t.forEach(t),z2t.forEach(t),uZo=i(WDe),Jue=n(WDe,"SPAN",{});var Q2t=s(Jue);_Zo=r(Q2t,"AutoModelForAudioFrameClassification"),Q2t.forEach(t),WDe.forEach(t),VNe=i(f),Oo=n(f,"DIV",{class:!0});var nl=s(Oo);T(uL.$$.fragment,nl),bZo=i(nl),_d=n(nl,"P",{});var UZ=s(_d);vZo=r(UZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),sz=n(UZ,"A",{href:!0});var H2t=s(sz);FZo=r(H2t,"from_pretrained()"),H2t.forEach(t),TZo=r(UZ," class method or the "),lz=n(UZ,"A",{href:!0});var U2t=s(lz);MZo=r(U2t,"from_config()"),U2t.forEach(t),EZo=r(UZ,` class
method.`),UZ.forEach(t),CZo=i(nl),_L=n(nl,"P",{});var QDe=s(_L);wZo=r(QDe,"This class cannot be instantiated directly using "),Yue=n(QDe,"CODE",{});var J2t=s(Yue);AZo=r(J2t,"__init__()"),J2t.forEach(t),yZo=r(QDe," (throws an error)."),QDe.forEach(t),LZo=i(nl),bt=n(nl,"DIV",{class:!0});var n6=s(bt);T(bL.$$.fragment,n6),xZo=i(n6),Kue=n(n6,"P",{});var Y2t=s(Kue);$Zo=r(Y2t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Y2t.forEach(t),kZo=i(n6),bd=n(n6,"P",{});var JZ=s(bd);SZo=r(JZ,`Note:
Loading a model from its configuration file does `),Zue=n(JZ,"STRONG",{});var K2t=s(Zue);RZo=r(K2t,"not"),K2t.forEach(t),PZo=r(JZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=n(JZ,"A",{href:!0});var Z2t=s(iz);BZo=r(Z2t,"from_pretrained()"),Z2t.forEach(t),IZo=r(JZ," to load the model weights."),JZ.forEach(t),qZo=i(n6),T(D5.$$.fragment,n6),n6.forEach(t),NZo=i(nl),fo=n(nl,"DIV",{class:!0});var pa=s(fo);T(vL.$$.fragment,pa),jZo=i(pa),e_e=n(pa,"P",{});var e1t=s(e_e);DZo=r(e1t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),e1t.forEach(t),GZo=i(pa),Oa=n(pa,"P",{});var s6=s(Oa);OZo=r(s6,"The model class to instantiate is selected based on the "),o_e=n(s6,"CODE",{});var o1t=s(o_e);VZo=r(o1t,"model_type"),o1t.forEach(t),XZo=r(s6,` property of the config object (either
passed as an argument or loaded from `),r_e=n(s6,"CODE",{});var r1t=s(r_e);zZo=r(r1t,"pretrained_model_name_or_path"),r1t.forEach(t),WZo=r(s6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t_e=n(s6,"CODE",{});var t1t=s(t_e);QZo=r(t1t,"pretrained_model_name_or_path"),t1t.forEach(t),HZo=r(s6,":"),s6.forEach(t),UZo=i(pa),Kr=n(pa,"UL",{});var sl=s(Kr);G5=n(sl,"LI",{});var kke=s(G5);a_e=n(kke,"STRONG",{});var a1t=s(a_e);JZo=r(a1t,"data2vec-audio"),a1t.forEach(t),YZo=r(kke," \u2014 "),dz=n(kke,"A",{href:!0});var n1t=s(dz);KZo=r(n1t,"Data2VecAudioForAudioFrameClassification"),n1t.forEach(t),ZZo=r(kke," (Data2VecAudio model)"),kke.forEach(t),eer=i(sl),O5=n(sl,"LI",{});var Ske=s(O5);n_e=n(Ske,"STRONG",{});var s1t=s(n_e);oer=r(s1t,"unispeech-sat"),s1t.forEach(t),rer=r(Ske," \u2014 "),cz=n(Ske,"A",{href:!0});var l1t=s(cz);ter=r(l1t,"UniSpeechSatForAudioFrameClassification"),l1t.forEach(t),aer=r(Ske," (UniSpeechSat model)"),Ske.forEach(t),ner=i(sl),V5=n(sl,"LI",{});var Rke=s(V5);s_e=n(Rke,"STRONG",{});var i1t=s(s_e);ser=r(i1t,"wav2vec2"),i1t.forEach(t),ler=r(Rke," \u2014 "),fz=n(Rke,"A",{href:!0});var d1t=s(fz);ier=r(d1t,"Wav2Vec2ForAudioFrameClassification"),d1t.forEach(t),der=r(Rke," (Wav2Vec2 model)"),Rke.forEach(t),cer=i(sl),X5=n(sl,"LI",{});var Pke=s(X5);l_e=n(Pke,"STRONG",{});var c1t=s(l_e);fer=r(c1t,"wav2vec2-conformer"),c1t.forEach(t),mer=r(Pke," \u2014 "),mz=n(Pke,"A",{href:!0});var f1t=s(mz);ger=r(f1t,"Wav2Vec2ConformerForAudioFrameClassification"),f1t.forEach(t),her=r(Pke," (Wav2Vec2-Conformer model)"),Pke.forEach(t),per=i(sl),z5=n(sl,"LI",{});var Bke=s(z5);i_e=n(Bke,"STRONG",{});var m1t=s(i_e);uer=r(m1t,"wavlm"),m1t.forEach(t),_er=r(Bke," \u2014 "),gz=n(Bke,"A",{href:!0});var g1t=s(gz);ber=r(g1t,"WavLMForAudioFrameClassification"),g1t.forEach(t),ver=r(Bke," (WavLM model)"),Bke.forEach(t),sl.forEach(t),Fer=i(pa),W5=n(pa,"P",{});var Ike=s(W5);Ter=r(Ike,"The model is set in evaluation mode by default using "),d_e=n(Ike,"CODE",{});var h1t=s(d_e);Mer=r(h1t,"model.eval()"),h1t.forEach(t),Eer=r(Ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=n(Ike,"CODE",{});var p1t=s(c_e);Cer=r(p1t,"model.train()"),p1t.forEach(t),Ike.forEach(t),wer=i(pa),T(Q5.$$.fragment,pa),pa.forEach(t),nl.forEach(t),XNe=i(f),vd=n(f,"H2",{class:!0});var HDe=s(vd);H5=n(HDe,"A",{id:!0,class:!0,href:!0});var u1t=s(H5);f_e=n(u1t,"SPAN",{});var _1t=s(f_e);T(FL.$$.fragment,_1t),_1t.forEach(t),u1t.forEach(t),Aer=i(HDe),m_e=n(HDe,"SPAN",{});var b1t=s(m_e);yer=r(b1t,"AutoModelForCTC"),b1t.forEach(t),HDe.forEach(t),zNe=i(f),Vo=n(f,"DIV",{class:!0});var ll=s(Vo);T(TL.$$.fragment,ll),Ler=i(ll),Fd=n(ll,"P",{});var YZ=s(Fd);xer=r(YZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),hz=n(YZ,"A",{href:!0});var v1t=s(hz);$er=r(v1t,"from_pretrained()"),v1t.forEach(t),ker=r(YZ," class method or the "),pz=n(YZ,"A",{href:!0});var F1t=s(pz);Ser=r(F1t,"from_config()"),F1t.forEach(t),Rer=r(YZ,` class
method.`),YZ.forEach(t),Per=i(ll),ML=n(ll,"P",{});var UDe=s(ML);Ber=r(UDe,"This class cannot be instantiated directly using "),g_e=n(UDe,"CODE",{});var T1t=s(g_e);Ier=r(T1t,"__init__()"),T1t.forEach(t),qer=r(UDe," (throws an error)."),UDe.forEach(t),Ner=i(ll),vt=n(ll,"DIV",{class:!0});var l6=s(vt);T(EL.$$.fragment,l6),jer=i(l6),h_e=n(l6,"P",{});var M1t=s(h_e);Der=r(M1t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),M1t.forEach(t),Ger=i(l6),Td=n(l6,"P",{});var KZ=s(Td);Oer=r(KZ,`Note:
Loading a model from its configuration file does `),p_e=n(KZ,"STRONG",{});var E1t=s(p_e);Ver=r(E1t,"not"),E1t.forEach(t),Xer=r(KZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),uz=n(KZ,"A",{href:!0});var C1t=s(uz);zer=r(C1t,"from_pretrained()"),C1t.forEach(t),Wer=r(KZ," to load the model weights."),KZ.forEach(t),Qer=i(l6),T(U5.$$.fragment,l6),l6.forEach(t),Her=i(ll),mo=n(ll,"DIV",{class:!0});var ua=s(mo);T(CL.$$.fragment,ua),Uer=i(ua),u_e=n(ua,"P",{});var w1t=s(u_e);Jer=r(w1t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),w1t.forEach(t),Yer=i(ua),Va=n(ua,"P",{});var i6=s(Va);Ker=r(i6,"The model class to instantiate is selected based on the "),__e=n(i6,"CODE",{});var A1t=s(__e);Zer=r(A1t,"model_type"),A1t.forEach(t),eor=r(i6,` property of the config object (either
passed as an argument or loaded from `),b_e=n(i6,"CODE",{});var y1t=s(b_e);oor=r(y1t,"pretrained_model_name_or_path"),y1t.forEach(t),ror=r(i6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v_e=n(i6,"CODE",{});var L1t=s(v_e);tor=r(L1t,"pretrained_model_name_or_path"),L1t.forEach(t),aor=r(i6,":"),i6.forEach(t),nor=i(ua),Se=n(ua,"UL",{});var Ve=s(Se);J5=n(Ve,"LI",{});var qke=s(J5);F_e=n(qke,"STRONG",{});var x1t=s(F_e);sor=r(x1t,"data2vec-audio"),x1t.forEach(t),lor=r(qke," \u2014 "),_z=n(qke,"A",{href:!0});var $1t=s(_z);ior=r($1t,"Data2VecAudioForCTC"),$1t.forEach(t),dor=r(qke," (Data2VecAudio model)"),qke.forEach(t),cor=i(Ve),Y5=n(Ve,"LI",{});var Nke=s(Y5);T_e=n(Nke,"STRONG",{});var k1t=s(T_e);mor=r(k1t,"hubert"),k1t.forEach(t),gor=r(Nke," \u2014 "),bz=n(Nke,"A",{href:!0});var S1t=s(bz);hor=r(S1t,"HubertForCTC"),S1t.forEach(t),por=r(Nke," (Hubert model)"),Nke.forEach(t),uor=i(Ve),K5=n(Ve,"LI",{});var jke=s(K5);M_e=n(jke,"STRONG",{});var R1t=s(M_e);_or=r(R1t,"sew"),R1t.forEach(t),bor=r(jke," \u2014 "),vz=n(jke,"A",{href:!0});var P1t=s(vz);vor=r(P1t,"SEWForCTC"),P1t.forEach(t),For=r(jke," (SEW model)"),jke.forEach(t),Tor=i(Ve),Z5=n(Ve,"LI",{});var Dke=s(Z5);E_e=n(Dke,"STRONG",{});var B1t=s(E_e);Mor=r(B1t,"sew-d"),B1t.forEach(t),Eor=r(Dke," \u2014 "),Fz=n(Dke,"A",{href:!0});var I1t=s(Fz);Cor=r(I1t,"SEWDForCTC"),I1t.forEach(t),wor=r(Dke," (SEW-D model)"),Dke.forEach(t),Aor=i(Ve),eF=n(Ve,"LI",{});var Gke=s(eF);C_e=n(Gke,"STRONG",{});var q1t=s(C_e);yor=r(q1t,"unispeech"),q1t.forEach(t),Lor=r(Gke," \u2014 "),Tz=n(Gke,"A",{href:!0});var N1t=s(Tz);xor=r(N1t,"UniSpeechForCTC"),N1t.forEach(t),$or=r(Gke," (UniSpeech model)"),Gke.forEach(t),kor=i(Ve),oF=n(Ve,"LI",{});var Oke=s(oF);w_e=n(Oke,"STRONG",{});var j1t=s(w_e);Sor=r(j1t,"unispeech-sat"),j1t.forEach(t),Ror=r(Oke," \u2014 "),Mz=n(Oke,"A",{href:!0});var D1t=s(Mz);Por=r(D1t,"UniSpeechSatForCTC"),D1t.forEach(t),Bor=r(Oke," (UniSpeechSat model)"),Oke.forEach(t),Ior=i(Ve),rF=n(Ve,"LI",{});var Vke=s(rF);A_e=n(Vke,"STRONG",{});var G1t=s(A_e);qor=r(G1t,"wav2vec2"),G1t.forEach(t),Nor=r(Vke," \u2014 "),Ez=n(Vke,"A",{href:!0});var O1t=s(Ez);jor=r(O1t,"Wav2Vec2ForCTC"),O1t.forEach(t),Dor=r(Vke," (Wav2Vec2 model)"),Vke.forEach(t),Gor=i(Ve),tF=n(Ve,"LI",{});var Xke=s(tF);y_e=n(Xke,"STRONG",{});var V1t=s(y_e);Oor=r(V1t,"wav2vec2-conformer"),V1t.forEach(t),Vor=r(Xke," \u2014 "),Cz=n(Xke,"A",{href:!0});var X1t=s(Cz);Xor=r(X1t,"Wav2Vec2ConformerForCTC"),X1t.forEach(t),zor=r(Xke," (Wav2Vec2-Conformer model)"),Xke.forEach(t),Wor=i(Ve),aF=n(Ve,"LI",{});var zke=s(aF);L_e=n(zke,"STRONG",{});var z1t=s(L_e);Qor=r(z1t,"wavlm"),z1t.forEach(t),Hor=r(zke," \u2014 "),wz=n(zke,"A",{href:!0});var W1t=s(wz);Uor=r(W1t,"WavLMForCTC"),W1t.forEach(t),Jor=r(zke," (WavLM model)"),zke.forEach(t),Ve.forEach(t),Yor=i(ua),nF=n(ua,"P",{});var Wke=s(nF);Kor=r(Wke,"The model is set in evaluation mode by default using "),x_e=n(Wke,"CODE",{});var Q1t=s(x_e);Zor=r(Q1t,"model.eval()"),Q1t.forEach(t),err=r(Wke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$_e=n(Wke,"CODE",{});var H1t=s($_e);orr=r(H1t,"model.train()"),H1t.forEach(t),Wke.forEach(t),rrr=i(ua),T(sF.$$.fragment,ua),ua.forEach(t),ll.forEach(t),WNe=i(f),Md=n(f,"H2",{class:!0});var JDe=s(Md);lF=n(JDe,"A",{id:!0,class:!0,href:!0});var U1t=s(lF);k_e=n(U1t,"SPAN",{});var J1t=s(k_e);T(wL.$$.fragment,J1t),J1t.forEach(t),U1t.forEach(t),trr=i(JDe),S_e=n(JDe,"SPAN",{});var Y1t=s(S_e);arr=r(Y1t,"AutoModelForSpeechSeq2Seq"),Y1t.forEach(t),JDe.forEach(t),QNe=i(f),Xo=n(f,"DIV",{class:!0});var il=s(Xo);T(AL.$$.fragment,il),nrr=i(il),Ed=n(il,"P",{});var ZZ=s(Ed);srr=r(ZZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Az=n(ZZ,"A",{href:!0});var K1t=s(Az);lrr=r(K1t,"from_pretrained()"),K1t.forEach(t),irr=r(ZZ," class method or the "),yz=n(ZZ,"A",{href:!0});var Z1t=s(yz);drr=r(Z1t,"from_config()"),Z1t.forEach(t),crr=r(ZZ,` class
method.`),ZZ.forEach(t),frr=i(il),yL=n(il,"P",{});var YDe=s(yL);mrr=r(YDe,"This class cannot be instantiated directly using "),R_e=n(YDe,"CODE",{});var ebt=s(R_e);grr=r(ebt,"__init__()"),ebt.forEach(t),hrr=r(YDe," (throws an error)."),YDe.forEach(t),prr=i(il),Ft=n(il,"DIV",{class:!0});var d6=s(Ft);T(LL.$$.fragment,d6),urr=i(d6),P_e=n(d6,"P",{});var obt=s(P_e);_rr=r(obt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),obt.forEach(t),brr=i(d6),Cd=n(d6,"P",{});var eee=s(Cd);vrr=r(eee,`Note:
Loading a model from its configuration file does `),B_e=n(eee,"STRONG",{});var rbt=s(B_e);Frr=r(rbt,"not"),rbt.forEach(t),Trr=r(eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=n(eee,"A",{href:!0});var tbt=s(Lz);Mrr=r(tbt,"from_pretrained()"),tbt.forEach(t),Err=r(eee," to load the model weights."),eee.forEach(t),Crr=i(d6),T(iF.$$.fragment,d6),d6.forEach(t),wrr=i(il),go=n(il,"DIV",{class:!0});var _a=s(go);T(xL.$$.fragment,_a),Arr=i(_a),I_e=n(_a,"P",{});var abt=s(I_e);yrr=r(abt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),abt.forEach(t),Lrr=i(_a),Xa=n(_a,"P",{});var c6=s(Xa);xrr=r(c6,"The model class to instantiate is selected based on the "),q_e=n(c6,"CODE",{});var nbt=s(q_e);$rr=r(nbt,"model_type"),nbt.forEach(t),krr=r(c6,` property of the config object (either
passed as an argument or loaded from `),N_e=n(c6,"CODE",{});var sbt=s(N_e);Srr=r(sbt,"pretrained_model_name_or_path"),sbt.forEach(t),Rrr=r(c6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j_e=n(c6,"CODE",{});var lbt=s(j_e);Prr=r(lbt,"pretrained_model_name_or_path"),lbt.forEach(t),Brr=r(c6,":"),c6.forEach(t),Irr=i(_a),$L=n(_a,"UL",{});var KDe=s($L);dF=n(KDe,"LI",{});var Qke=s(dF);D_e=n(Qke,"STRONG",{});var ibt=s(D_e);qrr=r(ibt,"speech-encoder-decoder"),ibt.forEach(t),Nrr=r(Qke," \u2014 "),xz=n(Qke,"A",{href:!0});var dbt=s(xz);jrr=r(dbt,"SpeechEncoderDecoderModel"),dbt.forEach(t),Drr=r(Qke," (Speech Encoder decoder model)"),Qke.forEach(t),Grr=i(KDe),cF=n(KDe,"LI",{});var Hke=s(cF);G_e=n(Hke,"STRONG",{});var cbt=s(G_e);Orr=r(cbt,"speech_to_text"),cbt.forEach(t),Vrr=r(Hke," \u2014 "),$z=n(Hke,"A",{href:!0});var fbt=s($z);Xrr=r(fbt,"Speech2TextForConditionalGeneration"),fbt.forEach(t),zrr=r(Hke," (Speech2Text model)"),Hke.forEach(t),KDe.forEach(t),Wrr=i(_a),fF=n(_a,"P",{});var Uke=s(fF);Qrr=r(Uke,"The model is set in evaluation mode by default using "),O_e=n(Uke,"CODE",{});var mbt=s(O_e);Hrr=r(mbt,"model.eval()"),mbt.forEach(t),Urr=r(Uke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V_e=n(Uke,"CODE",{});var gbt=s(V_e);Jrr=r(gbt,"model.train()"),gbt.forEach(t),Uke.forEach(t),Yrr=i(_a),T(mF.$$.fragment,_a),_a.forEach(t),il.forEach(t),HNe=i(f),wd=n(f,"H2",{class:!0});var ZDe=s(wd);gF=n(ZDe,"A",{id:!0,class:!0,href:!0});var hbt=s(gF);X_e=n(hbt,"SPAN",{});var pbt=s(X_e);T(kL.$$.fragment,pbt),pbt.forEach(t),hbt.forEach(t),Krr=i(ZDe),z_e=n(ZDe,"SPAN",{});var ubt=s(z_e);Zrr=r(ubt,"AutoModelForAudioXVector"),ubt.forEach(t),ZDe.forEach(t),UNe=i(f),zo=n(f,"DIV",{class:!0});var dl=s(zo);T(SL.$$.fragment,dl),etr=i(dl),Ad=n(dl,"P",{});var oee=s(Ad);otr=r(oee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),kz=n(oee,"A",{href:!0});var _bt=s(kz);rtr=r(_bt,"from_pretrained()"),_bt.forEach(t),ttr=r(oee," class method or the "),Sz=n(oee,"A",{href:!0});var bbt=s(Sz);atr=r(bbt,"from_config()"),bbt.forEach(t),ntr=r(oee,` class
method.`),oee.forEach(t),str=i(dl),RL=n(dl,"P",{});var eGe=s(RL);ltr=r(eGe,"This class cannot be instantiated directly using "),W_e=n(eGe,"CODE",{});var vbt=s(W_e);itr=r(vbt,"__init__()"),vbt.forEach(t),dtr=r(eGe," (throws an error)."),eGe.forEach(t),ctr=i(dl),Tt=n(dl,"DIV",{class:!0});var f6=s(Tt);T(PL.$$.fragment,f6),ftr=i(f6),Q_e=n(f6,"P",{});var Fbt=s(Q_e);mtr=r(Fbt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Fbt.forEach(t),gtr=i(f6),yd=n(f6,"P",{});var ree=s(yd);htr=r(ree,`Note:
Loading a model from its configuration file does `),H_e=n(ree,"STRONG",{});var Tbt=s(H_e);ptr=r(Tbt,"not"),Tbt.forEach(t),utr=r(ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rz=n(ree,"A",{href:!0});var Mbt=s(Rz);_tr=r(Mbt,"from_pretrained()"),Mbt.forEach(t),btr=r(ree," to load the model weights."),ree.forEach(t),vtr=i(f6),T(hF.$$.fragment,f6),f6.forEach(t),Ftr=i(dl),ho=n(dl,"DIV",{class:!0});var ba=s(ho);T(BL.$$.fragment,ba),Ttr=i(ba),U_e=n(ba,"P",{});var Ebt=s(U_e);Mtr=r(Ebt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Ebt.forEach(t),Etr=i(ba),za=n(ba,"P",{});var m6=s(za);Ctr=r(m6,"The model class to instantiate is selected based on the "),J_e=n(m6,"CODE",{});var Cbt=s(J_e);wtr=r(Cbt,"model_type"),Cbt.forEach(t),Atr=r(m6,` property of the config object (either
passed as an argument or loaded from `),Y_e=n(m6,"CODE",{});var wbt=s(Y_e);ytr=r(wbt,"pretrained_model_name_or_path"),wbt.forEach(t),Ltr=r(m6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K_e=n(m6,"CODE",{});var Abt=s(K_e);xtr=r(Abt,"pretrained_model_name_or_path"),Abt.forEach(t),$tr=r(m6,":"),m6.forEach(t),ktr=i(ba),Zr=n(ba,"UL",{});var cl=s(Zr);pF=n(cl,"LI",{});var Jke=s(pF);Z_e=n(Jke,"STRONG",{});var ybt=s(Z_e);Str=r(ybt,"data2vec-audio"),ybt.forEach(t),Rtr=r(Jke," \u2014 "),Pz=n(Jke,"A",{href:!0});var Lbt=s(Pz);Ptr=r(Lbt,"Data2VecAudioForXVector"),Lbt.forEach(t),Btr=r(Jke," (Data2VecAudio model)"),Jke.forEach(t),Itr=i(cl),uF=n(cl,"LI",{});var Yke=s(uF);e2e=n(Yke,"STRONG",{});var xbt=s(e2e);qtr=r(xbt,"unispeech-sat"),xbt.forEach(t),Ntr=r(Yke," \u2014 "),Bz=n(Yke,"A",{href:!0});var $bt=s(Bz);jtr=r($bt,"UniSpeechSatForXVector"),$bt.forEach(t),Dtr=r(Yke," (UniSpeechSat model)"),Yke.forEach(t),Gtr=i(cl),_F=n(cl,"LI",{});var Kke=s(_F);o2e=n(Kke,"STRONG",{});var kbt=s(o2e);Otr=r(kbt,"wav2vec2"),kbt.forEach(t),Vtr=r(Kke," \u2014 "),Iz=n(Kke,"A",{href:!0});var Sbt=s(Iz);Xtr=r(Sbt,"Wav2Vec2ForXVector"),Sbt.forEach(t),ztr=r(Kke," (Wav2Vec2 model)"),Kke.forEach(t),Wtr=i(cl),bF=n(cl,"LI",{});var Zke=s(bF);r2e=n(Zke,"STRONG",{});var Rbt=s(r2e);Qtr=r(Rbt,"wav2vec2-conformer"),Rbt.forEach(t),Htr=r(Zke," \u2014 "),qz=n(Zke,"A",{href:!0});var Pbt=s(qz);Utr=r(Pbt,"Wav2Vec2ConformerForXVector"),Pbt.forEach(t),Jtr=r(Zke," (Wav2Vec2-Conformer model)"),Zke.forEach(t),Ytr=i(cl),vF=n(cl,"LI",{});var eSe=s(vF);t2e=n(eSe,"STRONG",{});var Bbt=s(t2e);Ktr=r(Bbt,"wavlm"),Bbt.forEach(t),Ztr=r(eSe," \u2014 "),Nz=n(eSe,"A",{href:!0});var Ibt=s(Nz);ear=r(Ibt,"WavLMForXVector"),Ibt.forEach(t),oar=r(eSe," (WavLM model)"),eSe.forEach(t),cl.forEach(t),rar=i(ba),FF=n(ba,"P",{});var oSe=s(FF);tar=r(oSe,"The model is set in evaluation mode by default using "),a2e=n(oSe,"CODE",{});var qbt=s(a2e);aar=r(qbt,"model.eval()"),qbt.forEach(t),nar=r(oSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n2e=n(oSe,"CODE",{});var Nbt=s(n2e);sar=r(Nbt,"model.train()"),Nbt.forEach(t),oSe.forEach(t),lar=i(ba),T(TF.$$.fragment,ba),ba.forEach(t),dl.forEach(t),JNe=i(f),Ld=n(f,"H2",{class:!0});var oGe=s(Ld);MF=n(oGe,"A",{id:!0,class:!0,href:!0});var jbt=s(MF);s2e=n(jbt,"SPAN",{});var Dbt=s(s2e);T(IL.$$.fragment,Dbt),Dbt.forEach(t),jbt.forEach(t),iar=i(oGe),l2e=n(oGe,"SPAN",{});var Gbt=s(l2e);dar=r(Gbt,"AutoModelForMaskedImageModeling"),Gbt.forEach(t),oGe.forEach(t),YNe=i(f),Wo=n(f,"DIV",{class:!0});var fl=s(Wo);T(qL.$$.fragment,fl),car=i(fl),xd=n(fl,"P",{});var tee=s(xd);far=r(tee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),jz=n(tee,"A",{href:!0});var Obt=s(jz);mar=r(Obt,"from_pretrained()"),Obt.forEach(t),gar=r(tee," class method or the "),Dz=n(tee,"A",{href:!0});var Vbt=s(Dz);har=r(Vbt,"from_config()"),Vbt.forEach(t),par=r(tee,` class
method.`),tee.forEach(t),uar=i(fl),NL=n(fl,"P",{});var rGe=s(NL);_ar=r(rGe,"This class cannot be instantiated directly using "),i2e=n(rGe,"CODE",{});var Xbt=s(i2e);bar=r(Xbt,"__init__()"),Xbt.forEach(t),Far=r(rGe," (throws an error)."),rGe.forEach(t),Tar=i(fl),Mt=n(fl,"DIV",{class:!0});var g6=s(Mt);T(jL.$$.fragment,g6),Mar=i(g6),d2e=n(g6,"P",{});var zbt=s(d2e);Ear=r(zbt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),zbt.forEach(t),Car=i(g6),$d=n(g6,"P",{});var aee=s($d);war=r(aee,`Note:
Loading a model from its configuration file does `),c2e=n(aee,"STRONG",{});var Wbt=s(c2e);Aar=r(Wbt,"not"),Wbt.forEach(t),yar=r(aee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gz=n(aee,"A",{href:!0});var Qbt=s(Gz);Lar=r(Qbt,"from_pretrained()"),Qbt.forEach(t),xar=r(aee," to load the model weights."),aee.forEach(t),$ar=i(g6),T(EF.$$.fragment,g6),g6.forEach(t),kar=i(fl),po=n(fl,"DIV",{class:!0});var va=s(po);T(DL.$$.fragment,va),Sar=i(va),f2e=n(va,"P",{});var Hbt=s(f2e);Rar=r(Hbt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Hbt.forEach(t),Par=i(va),Wa=n(va,"P",{});var h6=s(Wa);Bar=r(h6,"The model class to instantiate is selected based on the "),m2e=n(h6,"CODE",{});var Ubt=s(m2e);Iar=r(Ubt,"model_type"),Ubt.forEach(t),qar=r(h6,` property of the config object (either
passed as an argument or loaded from `),g2e=n(h6,"CODE",{});var Jbt=s(g2e);Nar=r(Jbt,"pretrained_model_name_or_path"),Jbt.forEach(t),jar=r(h6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h2e=n(h6,"CODE",{});var Ybt=s(h2e);Dar=r(Ybt,"pretrained_model_name_or_path"),Ybt.forEach(t),Gar=r(h6,":"),h6.forEach(t),Oar=i(va),kd=n(va,"UL",{});var nee=s(kd);CF=n(nee,"LI",{});var rSe=s(CF);p2e=n(rSe,"STRONG",{});var Kbt=s(p2e);Var=r(Kbt,"deit"),Kbt.forEach(t),Xar=r(rSe," \u2014 "),Oz=n(rSe,"A",{href:!0});var Zbt=s(Oz);zar=r(Zbt,"DeiTForMaskedImageModeling"),Zbt.forEach(t),War=r(rSe," (DeiT model)"),rSe.forEach(t),Qar=i(nee),wF=n(nee,"LI",{});var tSe=s(wF);u2e=n(tSe,"STRONG",{});var e4t=s(u2e);Har=r(e4t,"swin"),e4t.forEach(t),Uar=r(tSe," \u2014 "),Vz=n(tSe,"A",{href:!0});var o4t=s(Vz);Jar=r(o4t,"SwinForMaskedImageModeling"),o4t.forEach(t),Yar=r(tSe," (Swin model)"),tSe.forEach(t),Kar=i(nee),AF=n(nee,"LI",{});var aSe=s(AF);_2e=n(aSe,"STRONG",{});var r4t=s(_2e);Zar=r(r4t,"vit"),r4t.forEach(t),enr=r(aSe," \u2014 "),Xz=n(aSe,"A",{href:!0});var t4t=s(Xz);onr=r(t4t,"ViTForMaskedImageModeling"),t4t.forEach(t),rnr=r(aSe," (ViT model)"),aSe.forEach(t),nee.forEach(t),tnr=i(va),yF=n(va,"P",{});var nSe=s(yF);anr=r(nSe,"The model is set in evaluation mode by default using "),b2e=n(nSe,"CODE",{});var a4t=s(b2e);nnr=r(a4t,"model.eval()"),a4t.forEach(t),snr=r(nSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v2e=n(nSe,"CODE",{});var n4t=s(v2e);lnr=r(n4t,"model.train()"),n4t.forEach(t),nSe.forEach(t),inr=i(va),T(LF.$$.fragment,va),va.forEach(t),fl.forEach(t),KNe=i(f),Sd=n(f,"H2",{class:!0});var tGe=s(Sd);xF=n(tGe,"A",{id:!0,class:!0,href:!0});var s4t=s(xF);F2e=n(s4t,"SPAN",{});var l4t=s(F2e);T(GL.$$.fragment,l4t),l4t.forEach(t),s4t.forEach(t),dnr=i(tGe),T2e=n(tGe,"SPAN",{});var i4t=s(T2e);cnr=r(i4t,"AutoModelForObjectDetection"),i4t.forEach(t),tGe.forEach(t),ZNe=i(f),Qo=n(f,"DIV",{class:!0});var ml=s(Qo);T(OL.$$.fragment,ml),fnr=i(ml),Rd=n(ml,"P",{});var see=s(Rd);mnr=r(see,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),zz=n(see,"A",{href:!0});var d4t=s(zz);gnr=r(d4t,"from_pretrained()"),d4t.forEach(t),hnr=r(see," class method or the "),Wz=n(see,"A",{href:!0});var c4t=s(Wz);pnr=r(c4t,"from_config()"),c4t.forEach(t),unr=r(see,` class
method.`),see.forEach(t),_nr=i(ml),VL=n(ml,"P",{});var aGe=s(VL);bnr=r(aGe,"This class cannot be instantiated directly using "),M2e=n(aGe,"CODE",{});var f4t=s(M2e);vnr=r(f4t,"__init__()"),f4t.forEach(t),Fnr=r(aGe," (throws an error)."),aGe.forEach(t),Tnr=i(ml),Et=n(ml,"DIV",{class:!0});var p6=s(Et);T(XL.$$.fragment,p6),Mnr=i(p6),E2e=n(p6,"P",{});var m4t=s(E2e);Enr=r(m4t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),m4t.forEach(t),Cnr=i(p6),Pd=n(p6,"P",{});var lee=s(Pd);wnr=r(lee,`Note:
Loading a model from its configuration file does `),C2e=n(lee,"STRONG",{});var g4t=s(C2e);Anr=r(g4t,"not"),g4t.forEach(t),ynr=r(lee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qz=n(lee,"A",{href:!0});var h4t=s(Qz);Lnr=r(h4t,"from_pretrained()"),h4t.forEach(t),xnr=r(lee," to load the model weights."),lee.forEach(t),$nr=i(p6),T($F.$$.fragment,p6),p6.forEach(t),knr=i(ml),uo=n(ml,"DIV",{class:!0});var Fa=s(uo);T(zL.$$.fragment,Fa),Snr=i(Fa),w2e=n(Fa,"P",{});var p4t=s(w2e);Rnr=r(p4t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),p4t.forEach(t),Pnr=i(Fa),Qa=n(Fa,"P",{});var u6=s(Qa);Bnr=r(u6,"The model class to instantiate is selected based on the "),A2e=n(u6,"CODE",{});var u4t=s(A2e);Inr=r(u4t,"model_type"),u4t.forEach(t),qnr=r(u6,` property of the config object (either
passed as an argument or loaded from `),y2e=n(u6,"CODE",{});var _4t=s(y2e);Nnr=r(_4t,"pretrained_model_name_or_path"),_4t.forEach(t),jnr=r(u6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=n(u6,"CODE",{});var b4t=s(L2e);Dnr=r(b4t,"pretrained_model_name_or_path"),b4t.forEach(t),Gnr=r(u6,":"),u6.forEach(t),Onr=i(Fa),WL=n(Fa,"UL",{});var nGe=s(WL);kF=n(nGe,"LI",{});var sSe=s(kF);x2e=n(sSe,"STRONG",{});var v4t=s(x2e);Vnr=r(v4t,"detr"),v4t.forEach(t),Xnr=r(sSe," \u2014 "),Hz=n(sSe,"A",{href:!0});var F4t=s(Hz);znr=r(F4t,"DetrForObjectDetection"),F4t.forEach(t),Wnr=r(sSe," (DETR model)"),sSe.forEach(t),Qnr=i(nGe),SF=n(nGe,"LI",{});var lSe=s(SF);$2e=n(lSe,"STRONG",{});var T4t=s($2e);Hnr=r(T4t,"yolos"),T4t.forEach(t),Unr=r(lSe," \u2014 "),Uz=n(lSe,"A",{href:!0});var M4t=s(Uz);Jnr=r(M4t,"YolosForObjectDetection"),M4t.forEach(t),Ynr=r(lSe," (YOLOS model)"),lSe.forEach(t),nGe.forEach(t),Knr=i(Fa),RF=n(Fa,"P",{});var iSe=s(RF);Znr=r(iSe,"The model is set in evaluation mode by default using "),k2e=n(iSe,"CODE",{});var E4t=s(k2e);esr=r(E4t,"model.eval()"),E4t.forEach(t),osr=r(iSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S2e=n(iSe,"CODE",{});var C4t=s(S2e);rsr=r(C4t,"model.train()"),C4t.forEach(t),iSe.forEach(t),tsr=i(Fa),T(PF.$$.fragment,Fa),Fa.forEach(t),ml.forEach(t),eje=i(f),Bd=n(f,"H2",{class:!0});var sGe=s(Bd);BF=n(sGe,"A",{id:!0,class:!0,href:!0});var w4t=s(BF);R2e=n(w4t,"SPAN",{});var A4t=s(R2e);T(QL.$$.fragment,A4t),A4t.forEach(t),w4t.forEach(t),asr=i(sGe),P2e=n(sGe,"SPAN",{});var y4t=s(P2e);nsr=r(y4t,"AutoModelForImageSegmentation"),y4t.forEach(t),sGe.forEach(t),oje=i(f),Ho=n(f,"DIV",{class:!0});var gl=s(Ho);T(HL.$$.fragment,gl),ssr=i(gl),Id=n(gl,"P",{});var iee=s(Id);lsr=r(iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Jz=n(iee,"A",{href:!0});var L4t=s(Jz);isr=r(L4t,"from_pretrained()"),L4t.forEach(t),dsr=r(iee," class method or the "),Yz=n(iee,"A",{href:!0});var x4t=s(Yz);csr=r(x4t,"from_config()"),x4t.forEach(t),fsr=r(iee,` class
method.`),iee.forEach(t),msr=i(gl),UL=n(gl,"P",{});var lGe=s(UL);gsr=r(lGe,"This class cannot be instantiated directly using "),B2e=n(lGe,"CODE",{});var $4t=s(B2e);hsr=r($4t,"__init__()"),$4t.forEach(t),psr=r(lGe," (throws an error)."),lGe.forEach(t),usr=i(gl),Ct=n(gl,"DIV",{class:!0});var _6=s(Ct);T(JL.$$.fragment,_6),_sr=i(_6),I2e=n(_6,"P",{});var k4t=s(I2e);bsr=r(k4t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),k4t.forEach(t),vsr=i(_6),qd=n(_6,"P",{});var dee=s(qd);Fsr=r(dee,`Note:
Loading a model from its configuration file does `),q2e=n(dee,"STRONG",{});var S4t=s(q2e);Tsr=r(S4t,"not"),S4t.forEach(t),Msr=r(dee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kz=n(dee,"A",{href:!0});var R4t=s(Kz);Esr=r(R4t,"from_pretrained()"),R4t.forEach(t),Csr=r(dee," to load the model weights."),dee.forEach(t),wsr=i(_6),T(IF.$$.fragment,_6),_6.forEach(t),Asr=i(gl),_o=n(gl,"DIV",{class:!0});var Ta=s(_o);T(YL.$$.fragment,Ta),ysr=i(Ta),N2e=n(Ta,"P",{});var P4t=s(N2e);Lsr=r(P4t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),P4t.forEach(t),xsr=i(Ta),Ha=n(Ta,"P",{});var b6=s(Ha);$sr=r(b6,"The model class to instantiate is selected based on the "),j2e=n(b6,"CODE",{});var B4t=s(j2e);ksr=r(B4t,"model_type"),B4t.forEach(t),Ssr=r(b6,` property of the config object (either
passed as an argument or loaded from `),D2e=n(b6,"CODE",{});var I4t=s(D2e);Rsr=r(I4t,"pretrained_model_name_or_path"),I4t.forEach(t),Psr=r(b6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G2e=n(b6,"CODE",{});var q4t=s(G2e);Bsr=r(q4t,"pretrained_model_name_or_path"),q4t.forEach(t),Isr=r(b6,":"),b6.forEach(t),qsr=i(Ta),O2e=n(Ta,"UL",{});var N4t=s(O2e);qF=n(N4t,"LI",{});var dSe=s(qF);V2e=n(dSe,"STRONG",{});var j4t=s(V2e);Nsr=r(j4t,"detr"),j4t.forEach(t),jsr=r(dSe," \u2014 "),Zz=n(dSe,"A",{href:!0});var D4t=s(Zz);Dsr=r(D4t,"DetrForSegmentation"),D4t.forEach(t),Gsr=r(dSe," (DETR model)"),dSe.forEach(t),N4t.forEach(t),Osr=i(Ta),NF=n(Ta,"P",{});var cSe=s(NF);Vsr=r(cSe,"The model is set in evaluation mode by default using "),X2e=n(cSe,"CODE",{});var G4t=s(X2e);Xsr=r(G4t,"model.eval()"),G4t.forEach(t),zsr=r(cSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z2e=n(cSe,"CODE",{});var O4t=s(z2e);Wsr=r(O4t,"model.train()"),O4t.forEach(t),cSe.forEach(t),Qsr=i(Ta),T(jF.$$.fragment,Ta),Ta.forEach(t),gl.forEach(t),rje=i(f),Nd=n(f,"H2",{class:!0});var iGe=s(Nd);DF=n(iGe,"A",{id:!0,class:!0,href:!0});var V4t=s(DF);W2e=n(V4t,"SPAN",{});var X4t=s(W2e);T(KL.$$.fragment,X4t),X4t.forEach(t),V4t.forEach(t),Hsr=i(iGe),Q2e=n(iGe,"SPAN",{});var z4t=s(Q2e);Usr=r(z4t,"AutoModelForSemanticSegmentation"),z4t.forEach(t),iGe.forEach(t),tje=i(f),Uo=n(f,"DIV",{class:!0});var hl=s(Uo);T(ZL.$$.fragment,hl),Jsr=i(hl),jd=n(hl,"P",{});var cee=s(jd);Ysr=r(cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),eW=n(cee,"A",{href:!0});var W4t=s(eW);Ksr=r(W4t,"from_pretrained()"),W4t.forEach(t),Zsr=r(cee," class method or the "),oW=n(cee,"A",{href:!0});var Q4t=s(oW);elr=r(Q4t,"from_config()"),Q4t.forEach(t),olr=r(cee,` class
method.`),cee.forEach(t),rlr=i(hl),e8=n(hl,"P",{});var dGe=s(e8);tlr=r(dGe,"This class cannot be instantiated directly using "),H2e=n(dGe,"CODE",{});var H4t=s(H2e);alr=r(H4t,"__init__()"),H4t.forEach(t),nlr=r(dGe," (throws an error)."),dGe.forEach(t),slr=i(hl),wt=n(hl,"DIV",{class:!0});var v6=s(wt);T(o8.$$.fragment,v6),llr=i(v6),U2e=n(v6,"P",{});var U4t=s(U2e);ilr=r(U4t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),U4t.forEach(t),dlr=i(v6),Dd=n(v6,"P",{});var fee=s(Dd);clr=r(fee,`Note:
Loading a model from its configuration file does `),J2e=n(fee,"STRONG",{});var J4t=s(J2e);flr=r(J4t,"not"),J4t.forEach(t),mlr=r(fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=n(fee,"A",{href:!0});var Y4t=s(rW);glr=r(Y4t,"from_pretrained()"),Y4t.forEach(t),hlr=r(fee," to load the model weights."),fee.forEach(t),plr=i(v6),T(GF.$$.fragment,v6),v6.forEach(t),ulr=i(hl),bo=n(hl,"DIV",{class:!0});var Ma=s(bo);T(r8.$$.fragment,Ma),_lr=i(Ma),Y2e=n(Ma,"P",{});var K4t=s(Y2e);blr=r(K4t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),K4t.forEach(t),vlr=i(Ma),Ua=n(Ma,"P",{});var F6=s(Ua);Flr=r(F6,"The model class to instantiate is selected based on the "),K2e=n(F6,"CODE",{});var Z4t=s(K2e);Tlr=r(Z4t,"model_type"),Z4t.forEach(t),Mlr=r(F6,` property of the config object (either
passed as an argument or loaded from `),Z2e=n(F6,"CODE",{});var evt=s(Z2e);Elr=r(evt,"pretrained_model_name_or_path"),evt.forEach(t),Clr=r(F6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e1e=n(F6,"CODE",{});var ovt=s(e1e);wlr=r(ovt,"pretrained_model_name_or_path"),ovt.forEach(t),Alr=r(F6,":"),F6.forEach(t),ylr=i(Ma),Ja=n(Ma,"UL",{});var T6=s(Ja);OF=n(T6,"LI",{});var fSe=s(OF);o1e=n(fSe,"STRONG",{});var rvt=s(o1e);Llr=r(rvt,"beit"),rvt.forEach(t),xlr=r(fSe," \u2014 "),tW=n(fSe,"A",{href:!0});var tvt=s(tW);$lr=r(tvt,"BeitForSemanticSegmentation"),tvt.forEach(t),klr=r(fSe," (BEiT model)"),fSe.forEach(t),Slr=i(T6),VF=n(T6,"LI",{});var mSe=s(VF);r1e=n(mSe,"STRONG",{});var avt=s(r1e);Rlr=r(avt,"data2vec-vision"),avt.forEach(t),Plr=r(mSe," \u2014 "),aW=n(mSe,"A",{href:!0});var nvt=s(aW);Blr=r(nvt,"Data2VecVisionForSemanticSegmentation"),nvt.forEach(t),Ilr=r(mSe," (Data2VecVision model)"),mSe.forEach(t),qlr=i(T6),XF=n(T6,"LI",{});var gSe=s(XF);t1e=n(gSe,"STRONG",{});var svt=s(t1e);Nlr=r(svt,"dpt"),svt.forEach(t),jlr=r(gSe," \u2014 "),nW=n(gSe,"A",{href:!0});var lvt=s(nW);Dlr=r(lvt,"DPTForSemanticSegmentation"),lvt.forEach(t),Glr=r(gSe," (DPT model)"),gSe.forEach(t),Olr=i(T6),zF=n(T6,"LI",{});var hSe=s(zF);a1e=n(hSe,"STRONG",{});var ivt=s(a1e);Vlr=r(ivt,"segformer"),ivt.forEach(t),Xlr=r(hSe," \u2014 "),sW=n(hSe,"A",{href:!0});var dvt=s(sW);zlr=r(dvt,"SegformerForSemanticSegmentation"),dvt.forEach(t),Wlr=r(hSe," (SegFormer model)"),hSe.forEach(t),T6.forEach(t),Qlr=i(Ma),WF=n(Ma,"P",{});var pSe=s(WF);Hlr=r(pSe,"The model is set in evaluation mode by default using "),n1e=n(pSe,"CODE",{});var cvt=s(n1e);Ulr=r(cvt,"model.eval()"),cvt.forEach(t),Jlr=r(pSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s1e=n(pSe,"CODE",{});var fvt=s(s1e);Ylr=r(fvt,"model.train()"),fvt.forEach(t),pSe.forEach(t),Klr=i(Ma),T(QF.$$.fragment,Ma),Ma.forEach(t),hl.forEach(t),aje=i(f),Gd=n(f,"H2",{class:!0});var cGe=s(Gd);HF=n(cGe,"A",{id:!0,class:!0,href:!0});var mvt=s(HF);l1e=n(mvt,"SPAN",{});var gvt=s(l1e);T(t8.$$.fragment,gvt),gvt.forEach(t),mvt.forEach(t),Zlr=i(cGe),i1e=n(cGe,"SPAN",{});var hvt=s(i1e);eir=r(hvt,"AutoModelForInstanceSegmentation"),hvt.forEach(t),cGe.forEach(t),nje=i(f),Jo=n(f,"DIV",{class:!0});var pl=s(Jo);T(a8.$$.fragment,pl),oir=i(pl),Od=n(pl,"P",{});var mee=s(Od);rir=r(mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),lW=n(mee,"A",{href:!0});var pvt=s(lW);tir=r(pvt,"from_pretrained()"),pvt.forEach(t),air=r(mee," class method or the "),iW=n(mee,"A",{href:!0});var uvt=s(iW);nir=r(uvt,"from_config()"),uvt.forEach(t),sir=r(mee,` class
method.`),mee.forEach(t),lir=i(pl),n8=n(pl,"P",{});var fGe=s(n8);iir=r(fGe,"This class cannot be instantiated directly using "),d1e=n(fGe,"CODE",{});var _vt=s(d1e);dir=r(_vt,"__init__()"),_vt.forEach(t),cir=r(fGe," (throws an error)."),fGe.forEach(t),fir=i(pl),At=n(pl,"DIV",{class:!0});var M6=s(At);T(s8.$$.fragment,M6),mir=i(M6),c1e=n(M6,"P",{});var bvt=s(c1e);gir=r(bvt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),bvt.forEach(t),hir=i(M6),Vd=n(M6,"P",{});var gee=s(Vd);pir=r(gee,`Note:
Loading a model from its configuration file does `),f1e=n(gee,"STRONG",{});var vvt=s(f1e);uir=r(vvt,"not"),vvt.forEach(t),_ir=r(gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),dW=n(gee,"A",{href:!0});var Fvt=s(dW);bir=r(Fvt,"from_pretrained()"),Fvt.forEach(t),vir=r(gee," to load the model weights."),gee.forEach(t),Fir=i(M6),T(UF.$$.fragment,M6),M6.forEach(t),Tir=i(pl),vo=n(pl,"DIV",{class:!0});var Ea=s(vo);T(l8.$$.fragment,Ea),Mir=i(Ea),m1e=n(Ea,"P",{});var Tvt=s(m1e);Eir=r(Tvt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Tvt.forEach(t),Cir=i(Ea),Ya=n(Ea,"P",{});var E6=s(Ya);wir=r(E6,"The model class to instantiate is selected based on the "),g1e=n(E6,"CODE",{});var Mvt=s(g1e);Air=r(Mvt,"model_type"),Mvt.forEach(t),yir=r(E6,` property of the config object (either
passed as an argument or loaded from `),h1e=n(E6,"CODE",{});var Evt=s(h1e);Lir=r(Evt,"pretrained_model_name_or_path"),Evt.forEach(t),xir=r(E6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p1e=n(E6,"CODE",{});var Cvt=s(p1e);$ir=r(Cvt,"pretrained_model_name_or_path"),Cvt.forEach(t),kir=r(E6,":"),E6.forEach(t),Sir=i(Ea),u1e=n(Ea,"UL",{});var wvt=s(u1e);JF=n(wvt,"LI",{});var uSe=s(JF);_1e=n(uSe,"STRONG",{});var Avt=s(_1e);Rir=r(Avt,"maskformer"),Avt.forEach(t),Pir=r(uSe," \u2014 "),cW=n(uSe,"A",{href:!0});var yvt=s(cW);Bir=r(yvt,"MaskFormerForInstanceSegmentation"),yvt.forEach(t),Iir=r(uSe," (MaskFormer model)"),uSe.forEach(t),wvt.forEach(t),qir=i(Ea),YF=n(Ea,"P",{});var _Se=s(YF);Nir=r(_Se,"The model is set in evaluation mode by default using "),b1e=n(_Se,"CODE",{});var Lvt=s(b1e);jir=r(Lvt,"model.eval()"),Lvt.forEach(t),Dir=r(_Se,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v1e=n(_Se,"CODE",{});var xvt=s(v1e);Gir=r(xvt,"model.train()"),xvt.forEach(t),_Se.forEach(t),Oir=i(Ea),T(KF.$$.fragment,Ea),Ea.forEach(t),pl.forEach(t),sje=i(f),Xd=n(f,"H2",{class:!0});var mGe=s(Xd);ZF=n(mGe,"A",{id:!0,class:!0,href:!0});var $vt=s(ZF);F1e=n($vt,"SPAN",{});var kvt=s(F1e);T(i8.$$.fragment,kvt),kvt.forEach(t),$vt.forEach(t),Vir=i(mGe),T1e=n(mGe,"SPAN",{});var Svt=s(T1e);Xir=r(Svt,"TFAutoModel"),Svt.forEach(t),mGe.forEach(t),lje=i(f),Yo=n(f,"DIV",{class:!0});var ul=s(Yo);T(d8.$$.fragment,ul),zir=i(ul),zd=n(ul,"P",{});var hee=s(zd);Wir=r(hee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),fW=n(hee,"A",{href:!0});var Rvt=s(fW);Qir=r(Rvt,"from_pretrained()"),Rvt.forEach(t),Hir=r(hee," class method or the "),mW=n(hee,"A",{href:!0});var Pvt=s(mW);Uir=r(Pvt,"from_config()"),Pvt.forEach(t),Jir=r(hee,` class
method.`),hee.forEach(t),Yir=i(ul),c8=n(ul,"P",{});var gGe=s(c8);Kir=r(gGe,"This class cannot be instantiated directly using "),M1e=n(gGe,"CODE",{});var Bvt=s(M1e);Zir=r(Bvt,"__init__()"),Bvt.forEach(t),edr=r(gGe," (throws an error)."),gGe.forEach(t),odr=i(ul),yt=n(ul,"DIV",{class:!0});var C6=s(yt);T(f8.$$.fragment,C6),rdr=i(C6),E1e=n(C6,"P",{});var Ivt=s(E1e);tdr=r(Ivt,"Instantiates one of the base model classes of the library from a configuration."),Ivt.forEach(t),adr=i(C6),Wd=n(C6,"P",{});var pee=s(Wd);ndr=r(pee,`Note:
Loading a model from its configuration file does `),C1e=n(pee,"STRONG",{});var qvt=s(C1e);sdr=r(qvt,"not"),qvt.forEach(t),ldr=r(pee,` load the model weights. It only affects the
model\u2019s configuration. Use `),gW=n(pee,"A",{href:!0});var Nvt=s(gW);idr=r(Nvt,"from_pretrained()"),Nvt.forEach(t),ddr=r(pee," to load the model weights."),pee.forEach(t),cdr=i(C6),T(eT.$$.fragment,C6),C6.forEach(t),fdr=i(ul),wr=n(ul,"DIV",{class:!0});var _l=s(wr);T(m8.$$.fragment,_l),mdr=i(_l),w1e=n(_l,"P",{});var jvt=s(w1e);gdr=r(jvt,"Instantiate one of the base model classes of the library from a pretrained model."),jvt.forEach(t),hdr=i(_l),Ka=n(_l,"P",{});var w6=s(Ka);pdr=r(w6,"The model class to instantiate is selected based on the "),A1e=n(w6,"CODE",{});var Dvt=s(A1e);udr=r(Dvt,"model_type"),Dvt.forEach(t),_dr=r(w6,` property of the config object (either
passed as an argument or loaded from `),y1e=n(w6,"CODE",{});var Gvt=s(y1e);bdr=r(Gvt,"pretrained_model_name_or_path"),Gvt.forEach(t),vdr=r(w6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L1e=n(w6,"CODE",{});var Ovt=s(L1e);Fdr=r(Ovt,"pretrained_model_name_or_path"),Ovt.forEach(t),Tdr=r(w6,":"),w6.forEach(t),Mdr=i(_l),N=n(_l,"UL",{});var D=s(N);oT=n(D,"LI",{});var bSe=s(oT);x1e=n(bSe,"STRONG",{});var Vvt=s(x1e);Edr=r(Vvt,"albert"),Vvt.forEach(t),Cdr=r(bSe," \u2014 "),hW=n(bSe,"A",{href:!0});var Xvt=s(hW);wdr=r(Xvt,"TFAlbertModel"),Xvt.forEach(t),Adr=r(bSe," (ALBERT model)"),bSe.forEach(t),ydr=i(D),rT=n(D,"LI",{});var vSe=s(rT);$1e=n(vSe,"STRONG",{});var zvt=s($1e);Ldr=r(zvt,"bart"),zvt.forEach(t),xdr=r(vSe," \u2014 "),pW=n(vSe,"A",{href:!0});var Wvt=s(pW);$dr=r(Wvt,"TFBartModel"),Wvt.forEach(t),kdr=r(vSe," (BART model)"),vSe.forEach(t),Sdr=i(D),tT=n(D,"LI",{});var FSe=s(tT);k1e=n(FSe,"STRONG",{});var Qvt=s(k1e);Rdr=r(Qvt,"bert"),Qvt.forEach(t),Pdr=r(FSe," \u2014 "),uW=n(FSe,"A",{href:!0});var Hvt=s(uW);Bdr=r(Hvt,"TFBertModel"),Hvt.forEach(t),Idr=r(FSe," (BERT model)"),FSe.forEach(t),qdr=i(D),aT=n(D,"LI",{});var TSe=s(aT);S1e=n(TSe,"STRONG",{});var Uvt=s(S1e);Ndr=r(Uvt,"blenderbot"),Uvt.forEach(t),jdr=r(TSe," \u2014 "),_W=n(TSe,"A",{href:!0});var Jvt=s(_W);Ddr=r(Jvt,"TFBlenderbotModel"),Jvt.forEach(t),Gdr=r(TSe," (Blenderbot model)"),TSe.forEach(t),Odr=i(D),nT=n(D,"LI",{});var MSe=s(nT);R1e=n(MSe,"STRONG",{});var Yvt=s(R1e);Vdr=r(Yvt,"blenderbot-small"),Yvt.forEach(t),Xdr=r(MSe," \u2014 "),bW=n(MSe,"A",{href:!0});var Kvt=s(bW);zdr=r(Kvt,"TFBlenderbotSmallModel"),Kvt.forEach(t),Wdr=r(MSe," (BlenderbotSmall model)"),MSe.forEach(t),Qdr=i(D),sT=n(D,"LI",{});var ESe=s(sT);P1e=n(ESe,"STRONG",{});var Zvt=s(P1e);Hdr=r(Zvt,"camembert"),Zvt.forEach(t),Udr=r(ESe," \u2014 "),vW=n(ESe,"A",{href:!0});var e5t=s(vW);Jdr=r(e5t,"TFCamembertModel"),e5t.forEach(t),Ydr=r(ESe," (CamemBERT model)"),ESe.forEach(t),Kdr=i(D),lT=n(D,"LI",{});var CSe=s(lT);B1e=n(CSe,"STRONG",{});var o5t=s(B1e);Zdr=r(o5t,"clip"),o5t.forEach(t),ecr=r(CSe," \u2014 "),FW=n(CSe,"A",{href:!0});var r5t=s(FW);ocr=r(r5t,"TFCLIPModel"),r5t.forEach(t),rcr=r(CSe," (CLIP model)"),CSe.forEach(t),tcr=i(D),iT=n(D,"LI",{});var wSe=s(iT);I1e=n(wSe,"STRONG",{});var t5t=s(I1e);acr=r(t5t,"convbert"),t5t.forEach(t),ncr=r(wSe," \u2014 "),TW=n(wSe,"A",{href:!0});var a5t=s(TW);scr=r(a5t,"TFConvBertModel"),a5t.forEach(t),lcr=r(wSe," (ConvBERT model)"),wSe.forEach(t),icr=i(D),dT=n(D,"LI",{});var ASe=s(dT);q1e=n(ASe,"STRONG",{});var n5t=s(q1e);dcr=r(n5t,"convnext"),n5t.forEach(t),ccr=r(ASe," \u2014 "),MW=n(ASe,"A",{href:!0});var s5t=s(MW);fcr=r(s5t,"TFConvNextModel"),s5t.forEach(t),mcr=r(ASe," (ConvNext model)"),ASe.forEach(t),gcr=i(D),cT=n(D,"LI",{});var ySe=s(cT);N1e=n(ySe,"STRONG",{});var l5t=s(N1e);hcr=r(l5t,"ctrl"),l5t.forEach(t),pcr=r(ySe," \u2014 "),EW=n(ySe,"A",{href:!0});var i5t=s(EW);ucr=r(i5t,"TFCTRLModel"),i5t.forEach(t),_cr=r(ySe," (CTRL model)"),ySe.forEach(t),bcr=i(D),fT=n(D,"LI",{});var LSe=s(fT);j1e=n(LSe,"STRONG",{});var d5t=s(j1e);vcr=r(d5t,"data2vec-vision"),d5t.forEach(t),Fcr=r(LSe," \u2014 "),CW=n(LSe,"A",{href:!0});var c5t=s(CW);Tcr=r(c5t,"TFData2VecVisionModel"),c5t.forEach(t),Mcr=r(LSe," (Data2VecVision model)"),LSe.forEach(t),Ecr=i(D),mT=n(D,"LI",{});var xSe=s(mT);D1e=n(xSe,"STRONG",{});var f5t=s(D1e);Ccr=r(f5t,"deberta"),f5t.forEach(t),wcr=r(xSe," \u2014 "),wW=n(xSe,"A",{href:!0});var m5t=s(wW);Acr=r(m5t,"TFDebertaModel"),m5t.forEach(t),ycr=r(xSe," (DeBERTa model)"),xSe.forEach(t),Lcr=i(D),gT=n(D,"LI",{});var $Se=s(gT);G1e=n($Se,"STRONG",{});var g5t=s(G1e);xcr=r(g5t,"deberta-v2"),g5t.forEach(t),$cr=r($Se," \u2014 "),AW=n($Se,"A",{href:!0});var h5t=s(AW);kcr=r(h5t,"TFDebertaV2Model"),h5t.forEach(t),Scr=r($Se," (DeBERTa-v2 model)"),$Se.forEach(t),Rcr=i(D),hT=n(D,"LI",{});var kSe=s(hT);O1e=n(kSe,"STRONG",{});var p5t=s(O1e);Pcr=r(p5t,"distilbert"),p5t.forEach(t),Bcr=r(kSe," \u2014 "),yW=n(kSe,"A",{href:!0});var u5t=s(yW);Icr=r(u5t,"TFDistilBertModel"),u5t.forEach(t),qcr=r(kSe," (DistilBERT model)"),kSe.forEach(t),Ncr=i(D),pT=n(D,"LI",{});var SSe=s(pT);V1e=n(SSe,"STRONG",{});var _5t=s(V1e);jcr=r(_5t,"dpr"),_5t.forEach(t),Dcr=r(SSe," \u2014 "),LW=n(SSe,"A",{href:!0});var b5t=s(LW);Gcr=r(b5t,"TFDPRQuestionEncoder"),b5t.forEach(t),Ocr=r(SSe," (DPR model)"),SSe.forEach(t),Vcr=i(D),uT=n(D,"LI",{});var RSe=s(uT);X1e=n(RSe,"STRONG",{});var v5t=s(X1e);Xcr=r(v5t,"electra"),v5t.forEach(t),zcr=r(RSe," \u2014 "),xW=n(RSe,"A",{href:!0});var F5t=s(xW);Wcr=r(F5t,"TFElectraModel"),F5t.forEach(t),Qcr=r(RSe," (ELECTRA model)"),RSe.forEach(t),Hcr=i(D),_T=n(D,"LI",{});var PSe=s(_T);z1e=n(PSe,"STRONG",{});var T5t=s(z1e);Ucr=r(T5t,"flaubert"),T5t.forEach(t),Jcr=r(PSe," \u2014 "),$W=n(PSe,"A",{href:!0});var M5t=s($W);Ycr=r(M5t,"TFFlaubertModel"),M5t.forEach(t),Kcr=r(PSe," (FlauBERT model)"),PSe.forEach(t),Zcr=i(D),js=n(D,"LI",{});var Q$=s(js);W1e=n(Q$,"STRONG",{});var E5t=s(W1e);efr=r(E5t,"funnel"),E5t.forEach(t),ofr=r(Q$," \u2014 "),kW=n(Q$,"A",{href:!0});var C5t=s(kW);rfr=r(C5t,"TFFunnelModel"),C5t.forEach(t),tfr=r(Q$," or "),SW=n(Q$,"A",{href:!0});var w5t=s(SW);afr=r(w5t,"TFFunnelBaseModel"),w5t.forEach(t),nfr=r(Q$," (Funnel Transformer model)"),Q$.forEach(t),sfr=i(D),bT=n(D,"LI",{});var BSe=s(bT);Q1e=n(BSe,"STRONG",{});var A5t=s(Q1e);lfr=r(A5t,"gpt2"),A5t.forEach(t),ifr=r(BSe," \u2014 "),RW=n(BSe,"A",{href:!0});var y5t=s(RW);dfr=r(y5t,"TFGPT2Model"),y5t.forEach(t),cfr=r(BSe," (OpenAI GPT-2 model)"),BSe.forEach(t),ffr=i(D),vT=n(D,"LI",{});var ISe=s(vT);H1e=n(ISe,"STRONG",{});var L5t=s(H1e);mfr=r(L5t,"gptj"),L5t.forEach(t),gfr=r(ISe," \u2014 "),PW=n(ISe,"A",{href:!0});var x5t=s(PW);hfr=r(x5t,"TFGPTJModel"),x5t.forEach(t),pfr=r(ISe," (GPT-J model)"),ISe.forEach(t),ufr=i(D),FT=n(D,"LI",{});var qSe=s(FT);U1e=n(qSe,"STRONG",{});var $5t=s(U1e);_fr=r($5t,"hubert"),$5t.forEach(t),bfr=r(qSe," \u2014 "),BW=n(qSe,"A",{href:!0});var k5t=s(BW);vfr=r(k5t,"TFHubertModel"),k5t.forEach(t),Ffr=r(qSe," (Hubert model)"),qSe.forEach(t),Tfr=i(D),TT=n(D,"LI",{});var NSe=s(TT);J1e=n(NSe,"STRONG",{});var S5t=s(J1e);Mfr=r(S5t,"layoutlm"),S5t.forEach(t),Efr=r(NSe," \u2014 "),IW=n(NSe,"A",{href:!0});var R5t=s(IW);Cfr=r(R5t,"TFLayoutLMModel"),R5t.forEach(t),wfr=r(NSe," (LayoutLM model)"),NSe.forEach(t),Afr=i(D),MT=n(D,"LI",{});var jSe=s(MT);Y1e=n(jSe,"STRONG",{});var P5t=s(Y1e);yfr=r(P5t,"led"),P5t.forEach(t),Lfr=r(jSe," \u2014 "),qW=n(jSe,"A",{href:!0});var B5t=s(qW);xfr=r(B5t,"TFLEDModel"),B5t.forEach(t),$fr=r(jSe," (LED model)"),jSe.forEach(t),kfr=i(D),ET=n(D,"LI",{});var DSe=s(ET);K1e=n(DSe,"STRONG",{});var I5t=s(K1e);Sfr=r(I5t,"longformer"),I5t.forEach(t),Rfr=r(DSe," \u2014 "),NW=n(DSe,"A",{href:!0});var q5t=s(NW);Pfr=r(q5t,"TFLongformerModel"),q5t.forEach(t),Bfr=r(DSe," (Longformer model)"),DSe.forEach(t),Ifr=i(D),CT=n(D,"LI",{});var GSe=s(CT);Z1e=n(GSe,"STRONG",{});var N5t=s(Z1e);qfr=r(N5t,"lxmert"),N5t.forEach(t),Nfr=r(GSe," \u2014 "),jW=n(GSe,"A",{href:!0});var j5t=s(jW);jfr=r(j5t,"TFLxmertModel"),j5t.forEach(t),Dfr=r(GSe," (LXMERT model)"),GSe.forEach(t),Gfr=i(D),wT=n(D,"LI",{});var OSe=s(wT);ebe=n(OSe,"STRONG",{});var D5t=s(ebe);Ofr=r(D5t,"marian"),D5t.forEach(t),Vfr=r(OSe," \u2014 "),DW=n(OSe,"A",{href:!0});var G5t=s(DW);Xfr=r(G5t,"TFMarianModel"),G5t.forEach(t),zfr=r(OSe," (Marian model)"),OSe.forEach(t),Wfr=i(D),AT=n(D,"LI",{});var VSe=s(AT);obe=n(VSe,"STRONG",{});var O5t=s(obe);Qfr=r(O5t,"mbart"),O5t.forEach(t),Hfr=r(VSe," \u2014 "),GW=n(VSe,"A",{href:!0});var V5t=s(GW);Ufr=r(V5t,"TFMBartModel"),V5t.forEach(t),Jfr=r(VSe," (mBART model)"),VSe.forEach(t),Yfr=i(D),yT=n(D,"LI",{});var XSe=s(yT);rbe=n(XSe,"STRONG",{});var X5t=s(rbe);Kfr=r(X5t,"mobilebert"),X5t.forEach(t),Zfr=r(XSe," \u2014 "),OW=n(XSe,"A",{href:!0});var z5t=s(OW);emr=r(z5t,"TFMobileBertModel"),z5t.forEach(t),omr=r(XSe," (MobileBERT model)"),XSe.forEach(t),rmr=i(D),LT=n(D,"LI",{});var zSe=s(LT);tbe=n(zSe,"STRONG",{});var W5t=s(tbe);tmr=r(W5t,"mpnet"),W5t.forEach(t),amr=r(zSe," \u2014 "),VW=n(zSe,"A",{href:!0});var Q5t=s(VW);nmr=r(Q5t,"TFMPNetModel"),Q5t.forEach(t),smr=r(zSe," (MPNet model)"),zSe.forEach(t),lmr=i(D),xT=n(D,"LI",{});var WSe=s(xT);abe=n(WSe,"STRONG",{});var H5t=s(abe);imr=r(H5t,"mt5"),H5t.forEach(t),dmr=r(WSe," \u2014 "),XW=n(WSe,"A",{href:!0});var U5t=s(XW);cmr=r(U5t,"TFMT5Model"),U5t.forEach(t),fmr=r(WSe," (mT5 model)"),WSe.forEach(t),mmr=i(D),$T=n(D,"LI",{});var QSe=s($T);nbe=n(QSe,"STRONG",{});var J5t=s(nbe);gmr=r(J5t,"openai-gpt"),J5t.forEach(t),hmr=r(QSe," \u2014 "),zW=n(QSe,"A",{href:!0});var Y5t=s(zW);pmr=r(Y5t,"TFOpenAIGPTModel"),Y5t.forEach(t),umr=r(QSe," (OpenAI GPT model)"),QSe.forEach(t),_mr=i(D),kT=n(D,"LI",{});var HSe=s(kT);sbe=n(HSe,"STRONG",{});var K5t=s(sbe);bmr=r(K5t,"pegasus"),K5t.forEach(t),vmr=r(HSe," \u2014 "),WW=n(HSe,"A",{href:!0});var Z5t=s(WW);Fmr=r(Z5t,"TFPegasusModel"),Z5t.forEach(t),Tmr=r(HSe," (Pegasus model)"),HSe.forEach(t),Mmr=i(D),ST=n(D,"LI",{});var USe=s(ST);lbe=n(USe,"STRONG",{});var eFt=s(lbe);Emr=r(eFt,"rembert"),eFt.forEach(t),Cmr=r(USe," \u2014 "),QW=n(USe,"A",{href:!0});var oFt=s(QW);wmr=r(oFt,"TFRemBertModel"),oFt.forEach(t),Amr=r(USe," (RemBERT model)"),USe.forEach(t),ymr=i(D),RT=n(D,"LI",{});var JSe=s(RT);ibe=n(JSe,"STRONG",{});var rFt=s(ibe);Lmr=r(rFt,"roberta"),rFt.forEach(t),xmr=r(JSe," \u2014 "),HW=n(JSe,"A",{href:!0});var tFt=s(HW);$mr=r(tFt,"TFRobertaModel"),tFt.forEach(t),kmr=r(JSe," (RoBERTa model)"),JSe.forEach(t),Smr=i(D),PT=n(D,"LI",{});var YSe=s(PT);dbe=n(YSe,"STRONG",{});var aFt=s(dbe);Rmr=r(aFt,"roformer"),aFt.forEach(t),Pmr=r(YSe," \u2014 "),UW=n(YSe,"A",{href:!0});var nFt=s(UW);Bmr=r(nFt,"TFRoFormerModel"),nFt.forEach(t),Imr=r(YSe," (RoFormer model)"),YSe.forEach(t),qmr=i(D),BT=n(D,"LI",{});var KSe=s(BT);cbe=n(KSe,"STRONG",{});var sFt=s(cbe);Nmr=r(sFt,"speech_to_text"),sFt.forEach(t),jmr=r(KSe," \u2014 "),JW=n(KSe,"A",{href:!0});var lFt=s(JW);Dmr=r(lFt,"TFSpeech2TextModel"),lFt.forEach(t),Gmr=r(KSe," (Speech2Text model)"),KSe.forEach(t),Omr=i(D),IT=n(D,"LI",{});var ZSe=s(IT);fbe=n(ZSe,"STRONG",{});var iFt=s(fbe);Vmr=r(iFt,"swin"),iFt.forEach(t),Xmr=r(ZSe," \u2014 "),YW=n(ZSe,"A",{href:!0});var dFt=s(YW);zmr=r(dFt,"TFSwinModel"),dFt.forEach(t),Wmr=r(ZSe," (Swin model)"),ZSe.forEach(t),Qmr=i(D),qT=n(D,"LI",{});var eRe=s(qT);mbe=n(eRe,"STRONG",{});var cFt=s(mbe);Hmr=r(cFt,"t5"),cFt.forEach(t),Umr=r(eRe," \u2014 "),KW=n(eRe,"A",{href:!0});var fFt=s(KW);Jmr=r(fFt,"TFT5Model"),fFt.forEach(t),Ymr=r(eRe," (T5 model)"),eRe.forEach(t),Kmr=i(D),NT=n(D,"LI",{});var oRe=s(NT);gbe=n(oRe,"STRONG",{});var mFt=s(gbe);Zmr=r(mFt,"tapas"),mFt.forEach(t),egr=r(oRe," \u2014 "),ZW=n(oRe,"A",{href:!0});var gFt=s(ZW);ogr=r(gFt,"TFTapasModel"),gFt.forEach(t),rgr=r(oRe," (TAPAS model)"),oRe.forEach(t),tgr=i(D),jT=n(D,"LI",{});var rRe=s(jT);hbe=n(rRe,"STRONG",{});var hFt=s(hbe);agr=r(hFt,"transfo-xl"),hFt.forEach(t),ngr=r(rRe," \u2014 "),eQ=n(rRe,"A",{href:!0});var pFt=s(eQ);sgr=r(pFt,"TFTransfoXLModel"),pFt.forEach(t),lgr=r(rRe," (Transformer-XL model)"),rRe.forEach(t),igr=i(D),DT=n(D,"LI",{});var tRe=s(DT);pbe=n(tRe,"STRONG",{});var uFt=s(pbe);dgr=r(uFt,"vit"),uFt.forEach(t),cgr=r(tRe," \u2014 "),oQ=n(tRe,"A",{href:!0});var _Ft=s(oQ);fgr=r(_Ft,"TFViTModel"),_Ft.forEach(t),mgr=r(tRe," (ViT model)"),tRe.forEach(t),ggr=i(D),GT=n(D,"LI",{});var aRe=s(GT);ube=n(aRe,"STRONG",{});var bFt=s(ube);hgr=r(bFt,"vit_mae"),bFt.forEach(t),pgr=r(aRe," \u2014 "),rQ=n(aRe,"A",{href:!0});var vFt=s(rQ);ugr=r(vFt,"TFViTMAEModel"),vFt.forEach(t),_gr=r(aRe," (ViTMAE model)"),aRe.forEach(t),bgr=i(D),OT=n(D,"LI",{});var nRe=s(OT);_be=n(nRe,"STRONG",{});var FFt=s(_be);vgr=r(FFt,"wav2vec2"),FFt.forEach(t),Fgr=r(nRe," \u2014 "),tQ=n(nRe,"A",{href:!0});var TFt=s(tQ);Tgr=r(TFt,"TFWav2Vec2Model"),TFt.forEach(t),Mgr=r(nRe," (Wav2Vec2 model)"),nRe.forEach(t),Egr=i(D),VT=n(D,"LI",{});var sRe=s(VT);bbe=n(sRe,"STRONG",{});var MFt=s(bbe);Cgr=r(MFt,"xlm"),MFt.forEach(t),wgr=r(sRe," \u2014 "),aQ=n(sRe,"A",{href:!0});var EFt=s(aQ);Agr=r(EFt,"TFXLMModel"),EFt.forEach(t),ygr=r(sRe," (XLM model)"),sRe.forEach(t),Lgr=i(D),XT=n(D,"LI",{});var lRe=s(XT);vbe=n(lRe,"STRONG",{});var CFt=s(vbe);xgr=r(CFt,"xlm-roberta"),CFt.forEach(t),$gr=r(lRe," \u2014 "),nQ=n(lRe,"A",{href:!0});var wFt=s(nQ);kgr=r(wFt,"TFXLMRobertaModel"),wFt.forEach(t),Sgr=r(lRe," (XLM-RoBERTa model)"),lRe.forEach(t),Rgr=i(D),zT=n(D,"LI",{});var iRe=s(zT);Fbe=n(iRe,"STRONG",{});var AFt=s(Fbe);Pgr=r(AFt,"xlnet"),AFt.forEach(t),Bgr=r(iRe," \u2014 "),sQ=n(iRe,"A",{href:!0});var yFt=s(sQ);Igr=r(yFt,"TFXLNetModel"),yFt.forEach(t),qgr=r(iRe," (XLNet model)"),iRe.forEach(t),D.forEach(t),Ngr=i(_l),T(WT.$$.fragment,_l),_l.forEach(t),ul.forEach(t),ije=i(f),Qd=n(f,"H2",{class:!0});var hGe=s(Qd);QT=n(hGe,"A",{id:!0,class:!0,href:!0});var LFt=s(QT);Tbe=n(LFt,"SPAN",{});var xFt=s(Tbe);T(g8.$$.fragment,xFt),xFt.forEach(t),LFt.forEach(t),jgr=i(hGe),Mbe=n(hGe,"SPAN",{});var $Ft=s(Mbe);Dgr=r($Ft,"TFAutoModelForPreTraining"),$Ft.forEach(t),hGe.forEach(t),dje=i(f),Ko=n(f,"DIV",{class:!0});var bl=s(Ko);T(h8.$$.fragment,bl),Ggr=i(bl),Hd=n(bl,"P",{});var uee=s(Hd);Ogr=r(uee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lQ=n(uee,"A",{href:!0});var kFt=s(lQ);Vgr=r(kFt,"from_pretrained()"),kFt.forEach(t),Xgr=r(uee," class method or the "),iQ=n(uee,"A",{href:!0});var SFt=s(iQ);zgr=r(SFt,"from_config()"),SFt.forEach(t),Wgr=r(uee,` class
method.`),uee.forEach(t),Qgr=i(bl),p8=n(bl,"P",{});var pGe=s(p8);Hgr=r(pGe,"This class cannot be instantiated directly using "),Ebe=n(pGe,"CODE",{});var RFt=s(Ebe);Ugr=r(RFt,"__init__()"),RFt.forEach(t),Jgr=r(pGe," (throws an error)."),pGe.forEach(t),Ygr=i(bl),Lt=n(bl,"DIV",{class:!0});var A6=s(Lt);T(u8.$$.fragment,A6),Kgr=i(A6),Cbe=n(A6,"P",{});var PFt=s(Cbe);Zgr=r(PFt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),PFt.forEach(t),ehr=i(A6),Ud=n(A6,"P",{});var _ee=s(Ud);ohr=r(_ee,`Note:
Loading a model from its configuration file does `),wbe=n(_ee,"STRONG",{});var BFt=s(wbe);rhr=r(BFt,"not"),BFt.forEach(t),thr=r(_ee,` load the model weights. It only affects the
model\u2019s configuration. Use `),dQ=n(_ee,"A",{href:!0});var IFt=s(dQ);ahr=r(IFt,"from_pretrained()"),IFt.forEach(t),nhr=r(_ee," to load the model weights."),_ee.forEach(t),shr=i(A6),T(HT.$$.fragment,A6),A6.forEach(t),lhr=i(bl),Ar=n(bl,"DIV",{class:!0});var vl=s(Ar);T(_8.$$.fragment,vl),ihr=i(vl),Abe=n(vl,"P",{});var qFt=s(Abe);dhr=r(qFt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),qFt.forEach(t),chr=i(vl),Za=n(vl,"P",{});var y6=s(Za);fhr=r(y6,"The model class to instantiate is selected based on the "),ybe=n(y6,"CODE",{});var NFt=s(ybe);mhr=r(NFt,"model_type"),NFt.forEach(t),ghr=r(y6,` property of the config object (either
passed as an argument or loaded from `),Lbe=n(y6,"CODE",{});var jFt=s(Lbe);hhr=r(jFt,"pretrained_model_name_or_path"),jFt.forEach(t),phr=r(y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xbe=n(y6,"CODE",{});var DFt=s(xbe);uhr=r(DFt,"pretrained_model_name_or_path"),DFt.forEach(t),_hr=r(y6,":"),y6.forEach(t),bhr=i(vl),se=n(vl,"UL",{});var le=s(se);UT=n(le,"LI",{});var dRe=s(UT);$be=n(dRe,"STRONG",{});var GFt=s($be);vhr=r(GFt,"albert"),GFt.forEach(t),Fhr=r(dRe," \u2014 "),cQ=n(dRe,"A",{href:!0});var OFt=s(cQ);Thr=r(OFt,"TFAlbertForPreTraining"),OFt.forEach(t),Mhr=r(dRe," (ALBERT model)"),dRe.forEach(t),Ehr=i(le),JT=n(le,"LI",{});var cRe=s(JT);kbe=n(cRe,"STRONG",{});var VFt=s(kbe);Chr=r(VFt,"bart"),VFt.forEach(t),whr=r(cRe," \u2014 "),fQ=n(cRe,"A",{href:!0});var XFt=s(fQ);Ahr=r(XFt,"TFBartForConditionalGeneration"),XFt.forEach(t),yhr=r(cRe," (BART model)"),cRe.forEach(t),Lhr=i(le),YT=n(le,"LI",{});var fRe=s(YT);Sbe=n(fRe,"STRONG",{});var zFt=s(Sbe);xhr=r(zFt,"bert"),zFt.forEach(t),$hr=r(fRe," \u2014 "),mQ=n(fRe,"A",{href:!0});var WFt=s(mQ);khr=r(WFt,"TFBertForPreTraining"),WFt.forEach(t),Shr=r(fRe," (BERT model)"),fRe.forEach(t),Rhr=i(le),KT=n(le,"LI",{});var mRe=s(KT);Rbe=n(mRe,"STRONG",{});var QFt=s(Rbe);Phr=r(QFt,"camembert"),QFt.forEach(t),Bhr=r(mRe," \u2014 "),gQ=n(mRe,"A",{href:!0});var HFt=s(gQ);Ihr=r(HFt,"TFCamembertForMaskedLM"),HFt.forEach(t),qhr=r(mRe," (CamemBERT model)"),mRe.forEach(t),Nhr=i(le),ZT=n(le,"LI",{});var gRe=s(ZT);Pbe=n(gRe,"STRONG",{});var UFt=s(Pbe);jhr=r(UFt,"ctrl"),UFt.forEach(t),Dhr=r(gRe," \u2014 "),hQ=n(gRe,"A",{href:!0});var JFt=s(hQ);Ghr=r(JFt,"TFCTRLLMHeadModel"),JFt.forEach(t),Ohr=r(gRe," (CTRL model)"),gRe.forEach(t),Vhr=i(le),e7=n(le,"LI",{});var hRe=s(e7);Bbe=n(hRe,"STRONG",{});var YFt=s(Bbe);Xhr=r(YFt,"distilbert"),YFt.forEach(t),zhr=r(hRe," \u2014 "),pQ=n(hRe,"A",{href:!0});var KFt=s(pQ);Whr=r(KFt,"TFDistilBertForMaskedLM"),KFt.forEach(t),Qhr=r(hRe," (DistilBERT model)"),hRe.forEach(t),Hhr=i(le),o7=n(le,"LI",{});var pRe=s(o7);Ibe=n(pRe,"STRONG",{});var ZFt=s(Ibe);Uhr=r(ZFt,"electra"),ZFt.forEach(t),Jhr=r(pRe," \u2014 "),uQ=n(pRe,"A",{href:!0});var eTt=s(uQ);Yhr=r(eTt,"TFElectraForPreTraining"),eTt.forEach(t),Khr=r(pRe," (ELECTRA model)"),pRe.forEach(t),Zhr=i(le),r7=n(le,"LI",{});var uRe=s(r7);qbe=n(uRe,"STRONG",{});var oTt=s(qbe);epr=r(oTt,"flaubert"),oTt.forEach(t),opr=r(uRe," \u2014 "),_Q=n(uRe,"A",{href:!0});var rTt=s(_Q);rpr=r(rTt,"TFFlaubertWithLMHeadModel"),rTt.forEach(t),tpr=r(uRe," (FlauBERT model)"),uRe.forEach(t),apr=i(le),t7=n(le,"LI",{});var _Re=s(t7);Nbe=n(_Re,"STRONG",{});var tTt=s(Nbe);npr=r(tTt,"funnel"),tTt.forEach(t),spr=r(_Re," \u2014 "),bQ=n(_Re,"A",{href:!0});var aTt=s(bQ);lpr=r(aTt,"TFFunnelForPreTraining"),aTt.forEach(t),ipr=r(_Re," (Funnel Transformer model)"),_Re.forEach(t),dpr=i(le),a7=n(le,"LI",{});var bRe=s(a7);jbe=n(bRe,"STRONG",{});var nTt=s(jbe);cpr=r(nTt,"gpt2"),nTt.forEach(t),fpr=r(bRe," \u2014 "),vQ=n(bRe,"A",{href:!0});var sTt=s(vQ);mpr=r(sTt,"TFGPT2LMHeadModel"),sTt.forEach(t),gpr=r(bRe," (OpenAI GPT-2 model)"),bRe.forEach(t),hpr=i(le),n7=n(le,"LI",{});var vRe=s(n7);Dbe=n(vRe,"STRONG",{});var lTt=s(Dbe);ppr=r(lTt,"layoutlm"),lTt.forEach(t),upr=r(vRe," \u2014 "),FQ=n(vRe,"A",{href:!0});var iTt=s(FQ);_pr=r(iTt,"TFLayoutLMForMaskedLM"),iTt.forEach(t),bpr=r(vRe," (LayoutLM model)"),vRe.forEach(t),vpr=i(le),s7=n(le,"LI",{});var FRe=s(s7);Gbe=n(FRe,"STRONG",{});var dTt=s(Gbe);Fpr=r(dTt,"lxmert"),dTt.forEach(t),Tpr=r(FRe," \u2014 "),TQ=n(FRe,"A",{href:!0});var cTt=s(TQ);Mpr=r(cTt,"TFLxmertForPreTraining"),cTt.forEach(t),Epr=r(FRe," (LXMERT model)"),FRe.forEach(t),Cpr=i(le),l7=n(le,"LI",{});var TRe=s(l7);Obe=n(TRe,"STRONG",{});var fTt=s(Obe);wpr=r(fTt,"mobilebert"),fTt.forEach(t),Apr=r(TRe," \u2014 "),MQ=n(TRe,"A",{href:!0});var mTt=s(MQ);ypr=r(mTt,"TFMobileBertForPreTraining"),mTt.forEach(t),Lpr=r(TRe," (MobileBERT model)"),TRe.forEach(t),xpr=i(le),i7=n(le,"LI",{});var MRe=s(i7);Vbe=n(MRe,"STRONG",{});var gTt=s(Vbe);$pr=r(gTt,"mpnet"),gTt.forEach(t),kpr=r(MRe," \u2014 "),EQ=n(MRe,"A",{href:!0});var hTt=s(EQ);Spr=r(hTt,"TFMPNetForMaskedLM"),hTt.forEach(t),Rpr=r(MRe," (MPNet model)"),MRe.forEach(t),Ppr=i(le),d7=n(le,"LI",{});var ERe=s(d7);Xbe=n(ERe,"STRONG",{});var pTt=s(Xbe);Bpr=r(pTt,"openai-gpt"),pTt.forEach(t),Ipr=r(ERe," \u2014 "),CQ=n(ERe,"A",{href:!0});var uTt=s(CQ);qpr=r(uTt,"TFOpenAIGPTLMHeadModel"),uTt.forEach(t),Npr=r(ERe," (OpenAI GPT model)"),ERe.forEach(t),jpr=i(le),c7=n(le,"LI",{});var CRe=s(c7);zbe=n(CRe,"STRONG",{});var _Tt=s(zbe);Dpr=r(_Tt,"roberta"),_Tt.forEach(t),Gpr=r(CRe," \u2014 "),wQ=n(CRe,"A",{href:!0});var bTt=s(wQ);Opr=r(bTt,"TFRobertaForMaskedLM"),bTt.forEach(t),Vpr=r(CRe," (RoBERTa model)"),CRe.forEach(t),Xpr=i(le),f7=n(le,"LI",{});var wRe=s(f7);Wbe=n(wRe,"STRONG",{});var vTt=s(Wbe);zpr=r(vTt,"t5"),vTt.forEach(t),Wpr=r(wRe," \u2014 "),AQ=n(wRe,"A",{href:!0});var FTt=s(AQ);Qpr=r(FTt,"TFT5ForConditionalGeneration"),FTt.forEach(t),Hpr=r(wRe," (T5 model)"),wRe.forEach(t),Upr=i(le),m7=n(le,"LI",{});var ARe=s(m7);Qbe=n(ARe,"STRONG",{});var TTt=s(Qbe);Jpr=r(TTt,"tapas"),TTt.forEach(t),Ypr=r(ARe," \u2014 "),yQ=n(ARe,"A",{href:!0});var MTt=s(yQ);Kpr=r(MTt,"TFTapasForMaskedLM"),MTt.forEach(t),Zpr=r(ARe," (TAPAS model)"),ARe.forEach(t),eur=i(le),g7=n(le,"LI",{});var yRe=s(g7);Hbe=n(yRe,"STRONG",{});var ETt=s(Hbe);our=r(ETt,"transfo-xl"),ETt.forEach(t),rur=r(yRe," \u2014 "),LQ=n(yRe,"A",{href:!0});var CTt=s(LQ);tur=r(CTt,"TFTransfoXLLMHeadModel"),CTt.forEach(t),aur=r(yRe," (Transformer-XL model)"),yRe.forEach(t),nur=i(le),h7=n(le,"LI",{});var LRe=s(h7);Ube=n(LRe,"STRONG",{});var wTt=s(Ube);sur=r(wTt,"vit_mae"),wTt.forEach(t),lur=r(LRe," \u2014 "),xQ=n(LRe,"A",{href:!0});var ATt=s(xQ);iur=r(ATt,"TFViTMAEForPreTraining"),ATt.forEach(t),dur=r(LRe," (ViTMAE model)"),LRe.forEach(t),cur=i(le),p7=n(le,"LI",{});var xRe=s(p7);Jbe=n(xRe,"STRONG",{});var yTt=s(Jbe);fur=r(yTt,"xlm"),yTt.forEach(t),mur=r(xRe," \u2014 "),$Q=n(xRe,"A",{href:!0});var LTt=s($Q);gur=r(LTt,"TFXLMWithLMHeadModel"),LTt.forEach(t),hur=r(xRe," (XLM model)"),xRe.forEach(t),pur=i(le),u7=n(le,"LI",{});var $Re=s(u7);Ybe=n($Re,"STRONG",{});var xTt=s(Ybe);uur=r(xTt,"xlm-roberta"),xTt.forEach(t),_ur=r($Re," \u2014 "),kQ=n($Re,"A",{href:!0});var $Tt=s(kQ);bur=r($Tt,"TFXLMRobertaForMaskedLM"),$Tt.forEach(t),vur=r($Re," (XLM-RoBERTa model)"),$Re.forEach(t),Fur=i(le),_7=n(le,"LI",{});var kRe=s(_7);Kbe=n(kRe,"STRONG",{});var kTt=s(Kbe);Tur=r(kTt,"xlnet"),kTt.forEach(t),Mur=r(kRe," \u2014 "),SQ=n(kRe,"A",{href:!0});var STt=s(SQ);Eur=r(STt,"TFXLNetLMHeadModel"),STt.forEach(t),Cur=r(kRe," (XLNet model)"),kRe.forEach(t),le.forEach(t),wur=i(vl),T(b7.$$.fragment,vl),vl.forEach(t),bl.forEach(t),cje=i(f),Jd=n(f,"H2",{class:!0});var uGe=s(Jd);v7=n(uGe,"A",{id:!0,class:!0,href:!0});var RTt=s(v7);Zbe=n(RTt,"SPAN",{});var PTt=s(Zbe);T(b8.$$.fragment,PTt),PTt.forEach(t),RTt.forEach(t),Aur=i(uGe),e4e=n(uGe,"SPAN",{});var BTt=s(e4e);yur=r(BTt,"TFAutoModelForCausalLM"),BTt.forEach(t),uGe.forEach(t),fje=i(f),Zo=n(f,"DIV",{class:!0});var Fl=s(Zo);T(v8.$$.fragment,Fl),Lur=i(Fl),Yd=n(Fl,"P",{});var bee=s(Yd);xur=r(bee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),RQ=n(bee,"A",{href:!0});var ITt=s(RQ);$ur=r(ITt,"from_pretrained()"),ITt.forEach(t),kur=r(bee," class method or the "),PQ=n(bee,"A",{href:!0});var qTt=s(PQ);Sur=r(qTt,"from_config()"),qTt.forEach(t),Rur=r(bee,` class
method.`),bee.forEach(t),Pur=i(Fl),F8=n(Fl,"P",{});var _Ge=s(F8);Bur=r(_Ge,"This class cannot be instantiated directly using "),o4e=n(_Ge,"CODE",{});var NTt=s(o4e);Iur=r(NTt,"__init__()"),NTt.forEach(t),qur=r(_Ge," (throws an error)."),_Ge.forEach(t),Nur=i(Fl),xt=n(Fl,"DIV",{class:!0});var L6=s(xt);T(T8.$$.fragment,L6),jur=i(L6),r4e=n(L6,"P",{});var jTt=s(r4e);Dur=r(jTt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),jTt.forEach(t),Gur=i(L6),Kd=n(L6,"P",{});var vee=s(Kd);Our=r(vee,`Note:
Loading a model from its configuration file does `),t4e=n(vee,"STRONG",{});var DTt=s(t4e);Vur=r(DTt,"not"),DTt.forEach(t),Xur=r(vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),BQ=n(vee,"A",{href:!0});var GTt=s(BQ);zur=r(GTt,"from_pretrained()"),GTt.forEach(t),Wur=r(vee," to load the model weights."),vee.forEach(t),Qur=i(L6),T(F7.$$.fragment,L6),L6.forEach(t),Hur=i(Fl),yr=n(Fl,"DIV",{class:!0});var Tl=s(yr);T(M8.$$.fragment,Tl),Uur=i(Tl),a4e=n(Tl,"P",{});var OTt=s(a4e);Jur=r(OTt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),OTt.forEach(t),Yur=i(Tl),en=n(Tl,"P",{});var x6=s(en);Kur=r(x6,"The model class to instantiate is selected based on the "),n4e=n(x6,"CODE",{});var VTt=s(n4e);Zur=r(VTt,"model_type"),VTt.forEach(t),e_r=r(x6,` property of the config object (either
passed as an argument or loaded from `),s4e=n(x6,"CODE",{});var XTt=s(s4e);o_r=r(XTt,"pretrained_model_name_or_path"),XTt.forEach(t),r_r=r(x6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l4e=n(x6,"CODE",{});var zTt=s(l4e);t_r=r(zTt,"pretrained_model_name_or_path"),zTt.forEach(t),a_r=r(x6,":"),x6.forEach(t),n_r=i(Tl),Me=n(Tl,"UL",{});var Ce=s(Me);T7=n(Ce,"LI",{});var SRe=s(T7);i4e=n(SRe,"STRONG",{});var WTt=s(i4e);s_r=r(WTt,"bert"),WTt.forEach(t),l_r=r(SRe," \u2014 "),IQ=n(SRe,"A",{href:!0});var QTt=s(IQ);i_r=r(QTt,"TFBertLMHeadModel"),QTt.forEach(t),d_r=r(SRe," (BERT model)"),SRe.forEach(t),c_r=i(Ce),M7=n(Ce,"LI",{});var RRe=s(M7);d4e=n(RRe,"STRONG",{});var HTt=s(d4e);f_r=r(HTt,"camembert"),HTt.forEach(t),m_r=r(RRe," \u2014 "),qQ=n(RRe,"A",{href:!0});var UTt=s(qQ);g_r=r(UTt,"TFCamembertForCausalLM"),UTt.forEach(t),h_r=r(RRe," (CamemBERT model)"),RRe.forEach(t),p_r=i(Ce),E7=n(Ce,"LI",{});var PRe=s(E7);c4e=n(PRe,"STRONG",{});var JTt=s(c4e);u_r=r(JTt,"ctrl"),JTt.forEach(t),__r=r(PRe," \u2014 "),NQ=n(PRe,"A",{href:!0});var YTt=s(NQ);b_r=r(YTt,"TFCTRLLMHeadModel"),YTt.forEach(t),v_r=r(PRe," (CTRL model)"),PRe.forEach(t),F_r=i(Ce),C7=n(Ce,"LI",{});var BRe=s(C7);f4e=n(BRe,"STRONG",{});var KTt=s(f4e);T_r=r(KTt,"gpt2"),KTt.forEach(t),M_r=r(BRe," \u2014 "),jQ=n(BRe,"A",{href:!0});var ZTt=s(jQ);E_r=r(ZTt,"TFGPT2LMHeadModel"),ZTt.forEach(t),C_r=r(BRe," (OpenAI GPT-2 model)"),BRe.forEach(t),w_r=i(Ce),w7=n(Ce,"LI",{});var IRe=s(w7);m4e=n(IRe,"STRONG",{});var e7t=s(m4e);A_r=r(e7t,"gptj"),e7t.forEach(t),y_r=r(IRe," \u2014 "),DQ=n(IRe,"A",{href:!0});var o7t=s(DQ);L_r=r(o7t,"TFGPTJForCausalLM"),o7t.forEach(t),x_r=r(IRe," (GPT-J model)"),IRe.forEach(t),$_r=i(Ce),A7=n(Ce,"LI",{});var qRe=s(A7);g4e=n(qRe,"STRONG",{});var r7t=s(g4e);k_r=r(r7t,"openai-gpt"),r7t.forEach(t),S_r=r(qRe," \u2014 "),GQ=n(qRe,"A",{href:!0});var t7t=s(GQ);R_r=r(t7t,"TFOpenAIGPTLMHeadModel"),t7t.forEach(t),P_r=r(qRe," (OpenAI GPT model)"),qRe.forEach(t),B_r=i(Ce),y7=n(Ce,"LI",{});var NRe=s(y7);h4e=n(NRe,"STRONG",{});var a7t=s(h4e);I_r=r(a7t,"rembert"),a7t.forEach(t),q_r=r(NRe," \u2014 "),OQ=n(NRe,"A",{href:!0});var n7t=s(OQ);N_r=r(n7t,"TFRemBertForCausalLM"),n7t.forEach(t),j_r=r(NRe," (RemBERT model)"),NRe.forEach(t),D_r=i(Ce),L7=n(Ce,"LI",{});var jRe=s(L7);p4e=n(jRe,"STRONG",{});var s7t=s(p4e);G_r=r(s7t,"roberta"),s7t.forEach(t),O_r=r(jRe," \u2014 "),VQ=n(jRe,"A",{href:!0});var l7t=s(VQ);V_r=r(l7t,"TFRobertaForCausalLM"),l7t.forEach(t),X_r=r(jRe," (RoBERTa model)"),jRe.forEach(t),z_r=i(Ce),x7=n(Ce,"LI",{});var DRe=s(x7);u4e=n(DRe,"STRONG",{});var i7t=s(u4e);W_r=r(i7t,"roformer"),i7t.forEach(t),Q_r=r(DRe," \u2014 "),XQ=n(DRe,"A",{href:!0});var d7t=s(XQ);H_r=r(d7t,"TFRoFormerForCausalLM"),d7t.forEach(t),U_r=r(DRe," (RoFormer model)"),DRe.forEach(t),J_r=i(Ce),$7=n(Ce,"LI",{});var GRe=s($7);_4e=n(GRe,"STRONG",{});var c7t=s(_4e);Y_r=r(c7t,"transfo-xl"),c7t.forEach(t),K_r=r(GRe," \u2014 "),zQ=n(GRe,"A",{href:!0});var f7t=s(zQ);Z_r=r(f7t,"TFTransfoXLLMHeadModel"),f7t.forEach(t),e2r=r(GRe," (Transformer-XL model)"),GRe.forEach(t),o2r=i(Ce),k7=n(Ce,"LI",{});var ORe=s(k7);b4e=n(ORe,"STRONG",{});var m7t=s(b4e);r2r=r(m7t,"xlm"),m7t.forEach(t),t2r=r(ORe," \u2014 "),WQ=n(ORe,"A",{href:!0});var g7t=s(WQ);a2r=r(g7t,"TFXLMWithLMHeadModel"),g7t.forEach(t),n2r=r(ORe," (XLM model)"),ORe.forEach(t),s2r=i(Ce),S7=n(Ce,"LI",{});var VRe=s(S7);v4e=n(VRe,"STRONG",{});var h7t=s(v4e);l2r=r(h7t,"xlnet"),h7t.forEach(t),i2r=r(VRe," \u2014 "),QQ=n(VRe,"A",{href:!0});var p7t=s(QQ);d2r=r(p7t,"TFXLNetLMHeadModel"),p7t.forEach(t),c2r=r(VRe," (XLNet model)"),VRe.forEach(t),Ce.forEach(t),f2r=i(Tl),T(R7.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),mje=i(f),Zd=n(f,"H2",{class:!0});var bGe=s(Zd);P7=n(bGe,"A",{id:!0,class:!0,href:!0});var u7t=s(P7);F4e=n(u7t,"SPAN",{});var _7t=s(F4e);T(E8.$$.fragment,_7t),_7t.forEach(t),u7t.forEach(t),m2r=i(bGe),T4e=n(bGe,"SPAN",{});var b7t=s(T4e);g2r=r(b7t,"TFAutoModelForImageClassification"),b7t.forEach(t),bGe.forEach(t),gje=i(f),er=n(f,"DIV",{class:!0});var Ml=s(er);T(C8.$$.fragment,Ml),h2r=i(Ml),ec=n(Ml,"P",{});var Fee=s(ec);p2r=r(Fee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),HQ=n(Fee,"A",{href:!0});var v7t=s(HQ);u2r=r(v7t,"from_pretrained()"),v7t.forEach(t),_2r=r(Fee," class method or the "),UQ=n(Fee,"A",{href:!0});var F7t=s(UQ);b2r=r(F7t,"from_config()"),F7t.forEach(t),v2r=r(Fee,` class
method.`),Fee.forEach(t),F2r=i(Ml),w8=n(Ml,"P",{});var vGe=s(w8);T2r=r(vGe,"This class cannot be instantiated directly using "),M4e=n(vGe,"CODE",{});var T7t=s(M4e);M2r=r(T7t,"__init__()"),T7t.forEach(t),E2r=r(vGe," (throws an error)."),vGe.forEach(t),C2r=i(Ml),$t=n(Ml,"DIV",{class:!0});var $6=s($t);T(A8.$$.fragment,$6),w2r=i($6),E4e=n($6,"P",{});var M7t=s(E4e);A2r=r(M7t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),M7t.forEach(t),y2r=i($6),oc=n($6,"P",{});var Tee=s(oc);L2r=r(Tee,`Note:
Loading a model from its configuration file does `),C4e=n(Tee,"STRONG",{});var E7t=s(C4e);x2r=r(E7t,"not"),E7t.forEach(t),$2r=r(Tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),JQ=n(Tee,"A",{href:!0});var C7t=s(JQ);k2r=r(C7t,"from_pretrained()"),C7t.forEach(t),S2r=r(Tee," to load the model weights."),Tee.forEach(t),R2r=i($6),T(B7.$$.fragment,$6),$6.forEach(t),P2r=i(Ml),Lr=n(Ml,"DIV",{class:!0});var El=s(Lr);T(y8.$$.fragment,El),B2r=i(El),w4e=n(El,"P",{});var w7t=s(w4e);I2r=r(w7t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),w7t.forEach(t),q2r=i(El),on=n(El,"P",{});var k6=s(on);N2r=r(k6,"The model class to instantiate is selected based on the "),A4e=n(k6,"CODE",{});var A7t=s(A4e);j2r=r(A7t,"model_type"),A7t.forEach(t),D2r=r(k6,` property of the config object (either
passed as an argument or loaded from `),y4e=n(k6,"CODE",{});var y7t=s(y4e);G2r=r(y7t,"pretrained_model_name_or_path"),y7t.forEach(t),O2r=r(k6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L4e=n(k6,"CODE",{});var L7t=s(L4e);V2r=r(L7t,"pretrained_model_name_or_path"),L7t.forEach(t),X2r=r(k6,":"),k6.forEach(t),z2r=i(El),rn=n(El,"UL",{});var S6=s(rn);I7=n(S6,"LI",{});var XRe=s(I7);x4e=n(XRe,"STRONG",{});var x7t=s(x4e);W2r=r(x7t,"convnext"),x7t.forEach(t),Q2r=r(XRe," \u2014 "),YQ=n(XRe,"A",{href:!0});var $7t=s(YQ);H2r=r($7t,"TFConvNextForImageClassification"),$7t.forEach(t),U2r=r(XRe," (ConvNext model)"),XRe.forEach(t),J2r=i(S6),q7=n(S6,"LI",{});var zRe=s(q7);$4e=n(zRe,"STRONG",{});var k7t=s($4e);Y2r=r(k7t,"data2vec-vision"),k7t.forEach(t),K2r=r(zRe," \u2014 "),KQ=n(zRe,"A",{href:!0});var S7t=s(KQ);Z2r=r(S7t,"TFData2VecVisionForImageClassification"),S7t.forEach(t),e1r=r(zRe," (Data2VecVision model)"),zRe.forEach(t),o1r=i(S6),N7=n(S6,"LI",{});var WRe=s(N7);k4e=n(WRe,"STRONG",{});var R7t=s(k4e);r1r=r(R7t,"swin"),R7t.forEach(t),t1r=r(WRe," \u2014 "),ZQ=n(WRe,"A",{href:!0});var P7t=s(ZQ);a1r=r(P7t,"TFSwinForImageClassification"),P7t.forEach(t),n1r=r(WRe," (Swin model)"),WRe.forEach(t),s1r=i(S6),j7=n(S6,"LI",{});var QRe=s(j7);S4e=n(QRe,"STRONG",{});var B7t=s(S4e);l1r=r(B7t,"vit"),B7t.forEach(t),i1r=r(QRe," \u2014 "),eH=n(QRe,"A",{href:!0});var I7t=s(eH);d1r=r(I7t,"TFViTForImageClassification"),I7t.forEach(t),c1r=r(QRe," (ViT model)"),QRe.forEach(t),S6.forEach(t),f1r=i(El),T(D7.$$.fragment,El),El.forEach(t),Ml.forEach(t),hje=i(f),rc=n(f,"H2",{class:!0});var FGe=s(rc);G7=n(FGe,"A",{id:!0,class:!0,href:!0});var q7t=s(G7);R4e=n(q7t,"SPAN",{});var N7t=s(R4e);T(L8.$$.fragment,N7t),N7t.forEach(t),q7t.forEach(t),m1r=i(FGe),P4e=n(FGe,"SPAN",{});var j7t=s(P4e);g1r=r(j7t,"TFAutoModelForMaskedLM"),j7t.forEach(t),FGe.forEach(t),pje=i(f),or=n(f,"DIV",{class:!0});var Cl=s(or);T(x8.$$.fragment,Cl),h1r=i(Cl),tc=n(Cl,"P",{});var Mee=s(tc);p1r=r(Mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),oH=n(Mee,"A",{href:!0});var D7t=s(oH);u1r=r(D7t,"from_pretrained()"),D7t.forEach(t),_1r=r(Mee," class method or the "),rH=n(Mee,"A",{href:!0});var G7t=s(rH);b1r=r(G7t,"from_config()"),G7t.forEach(t),v1r=r(Mee,` class
method.`),Mee.forEach(t),F1r=i(Cl),$8=n(Cl,"P",{});var TGe=s($8);T1r=r(TGe,"This class cannot be instantiated directly using "),B4e=n(TGe,"CODE",{});var O7t=s(B4e);M1r=r(O7t,"__init__()"),O7t.forEach(t),E1r=r(TGe," (throws an error)."),TGe.forEach(t),C1r=i(Cl),kt=n(Cl,"DIV",{class:!0});var R6=s(kt);T(k8.$$.fragment,R6),w1r=i(R6),I4e=n(R6,"P",{});var V7t=s(I4e);A1r=r(V7t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),V7t.forEach(t),y1r=i(R6),ac=n(R6,"P",{});var Eee=s(ac);L1r=r(Eee,`Note:
Loading a model from its configuration file does `),q4e=n(Eee,"STRONG",{});var X7t=s(q4e);x1r=r(X7t,"not"),X7t.forEach(t),$1r=r(Eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=n(Eee,"A",{href:!0});var z7t=s(tH);k1r=r(z7t,"from_pretrained()"),z7t.forEach(t),S1r=r(Eee," to load the model weights."),Eee.forEach(t),R1r=i(R6),T(O7.$$.fragment,R6),R6.forEach(t),P1r=i(Cl),xr=n(Cl,"DIV",{class:!0});var wl=s(xr);T(S8.$$.fragment,wl),B1r=i(wl),N4e=n(wl,"P",{});var W7t=s(N4e);I1r=r(W7t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),W7t.forEach(t),q1r=i(wl),tn=n(wl,"P",{});var P6=s(tn);N1r=r(P6,"The model class to instantiate is selected based on the "),j4e=n(P6,"CODE",{});var Q7t=s(j4e);j1r=r(Q7t,"model_type"),Q7t.forEach(t),D1r=r(P6,` property of the config object (either
passed as an argument or loaded from `),D4e=n(P6,"CODE",{});var H7t=s(D4e);G1r=r(H7t,"pretrained_model_name_or_path"),H7t.forEach(t),O1r=r(P6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G4e=n(P6,"CODE",{});var U7t=s(G4e);V1r=r(U7t,"pretrained_model_name_or_path"),U7t.forEach(t),X1r=r(P6,":"),P6.forEach(t),z1r=i(wl),ie=n(wl,"UL",{});var fe=s(ie);V7=n(fe,"LI",{});var HRe=s(V7);O4e=n(HRe,"STRONG",{});var J7t=s(O4e);W1r=r(J7t,"albert"),J7t.forEach(t),Q1r=r(HRe," \u2014 "),aH=n(HRe,"A",{href:!0});var Y7t=s(aH);H1r=r(Y7t,"TFAlbertForMaskedLM"),Y7t.forEach(t),U1r=r(HRe," (ALBERT model)"),HRe.forEach(t),J1r=i(fe),X7=n(fe,"LI",{});var URe=s(X7);V4e=n(URe,"STRONG",{});var K7t=s(V4e);Y1r=r(K7t,"bert"),K7t.forEach(t),K1r=r(URe," \u2014 "),nH=n(URe,"A",{href:!0});var Z7t=s(nH);Z1r=r(Z7t,"TFBertForMaskedLM"),Z7t.forEach(t),ebr=r(URe," (BERT model)"),URe.forEach(t),obr=i(fe),z7=n(fe,"LI",{});var JRe=s(z7);X4e=n(JRe,"STRONG",{});var eMt=s(X4e);rbr=r(eMt,"camembert"),eMt.forEach(t),tbr=r(JRe," \u2014 "),sH=n(JRe,"A",{href:!0});var oMt=s(sH);abr=r(oMt,"TFCamembertForMaskedLM"),oMt.forEach(t),nbr=r(JRe," (CamemBERT model)"),JRe.forEach(t),sbr=i(fe),W7=n(fe,"LI",{});var YRe=s(W7);z4e=n(YRe,"STRONG",{});var rMt=s(z4e);lbr=r(rMt,"convbert"),rMt.forEach(t),ibr=r(YRe," \u2014 "),lH=n(YRe,"A",{href:!0});var tMt=s(lH);dbr=r(tMt,"TFConvBertForMaskedLM"),tMt.forEach(t),cbr=r(YRe," (ConvBERT model)"),YRe.forEach(t),fbr=i(fe),Q7=n(fe,"LI",{});var KRe=s(Q7);W4e=n(KRe,"STRONG",{});var aMt=s(W4e);mbr=r(aMt,"deberta"),aMt.forEach(t),gbr=r(KRe," \u2014 "),iH=n(KRe,"A",{href:!0});var nMt=s(iH);hbr=r(nMt,"TFDebertaForMaskedLM"),nMt.forEach(t),pbr=r(KRe," (DeBERTa model)"),KRe.forEach(t),ubr=i(fe),H7=n(fe,"LI",{});var ZRe=s(H7);Q4e=n(ZRe,"STRONG",{});var sMt=s(Q4e);_br=r(sMt,"deberta-v2"),sMt.forEach(t),bbr=r(ZRe," \u2014 "),dH=n(ZRe,"A",{href:!0});var lMt=s(dH);vbr=r(lMt,"TFDebertaV2ForMaskedLM"),lMt.forEach(t),Fbr=r(ZRe," (DeBERTa-v2 model)"),ZRe.forEach(t),Tbr=i(fe),U7=n(fe,"LI",{});var ePe=s(U7);H4e=n(ePe,"STRONG",{});var iMt=s(H4e);Mbr=r(iMt,"distilbert"),iMt.forEach(t),Ebr=r(ePe," \u2014 "),cH=n(ePe,"A",{href:!0});var dMt=s(cH);Cbr=r(dMt,"TFDistilBertForMaskedLM"),dMt.forEach(t),wbr=r(ePe," (DistilBERT model)"),ePe.forEach(t),Abr=i(fe),J7=n(fe,"LI",{});var oPe=s(J7);U4e=n(oPe,"STRONG",{});var cMt=s(U4e);ybr=r(cMt,"electra"),cMt.forEach(t),Lbr=r(oPe," \u2014 "),fH=n(oPe,"A",{href:!0});var fMt=s(fH);xbr=r(fMt,"TFElectraForMaskedLM"),fMt.forEach(t),$br=r(oPe," (ELECTRA model)"),oPe.forEach(t),kbr=i(fe),Y7=n(fe,"LI",{});var rPe=s(Y7);J4e=n(rPe,"STRONG",{});var mMt=s(J4e);Sbr=r(mMt,"flaubert"),mMt.forEach(t),Rbr=r(rPe," \u2014 "),mH=n(rPe,"A",{href:!0});var gMt=s(mH);Pbr=r(gMt,"TFFlaubertWithLMHeadModel"),gMt.forEach(t),Bbr=r(rPe," (FlauBERT model)"),rPe.forEach(t),Ibr=i(fe),K7=n(fe,"LI",{});var tPe=s(K7);Y4e=n(tPe,"STRONG",{});var hMt=s(Y4e);qbr=r(hMt,"funnel"),hMt.forEach(t),Nbr=r(tPe," \u2014 "),gH=n(tPe,"A",{href:!0});var pMt=s(gH);jbr=r(pMt,"TFFunnelForMaskedLM"),pMt.forEach(t),Dbr=r(tPe," (Funnel Transformer model)"),tPe.forEach(t),Gbr=i(fe),Z7=n(fe,"LI",{});var aPe=s(Z7);K4e=n(aPe,"STRONG",{});var uMt=s(K4e);Obr=r(uMt,"layoutlm"),uMt.forEach(t),Vbr=r(aPe," \u2014 "),hH=n(aPe,"A",{href:!0});var _Mt=s(hH);Xbr=r(_Mt,"TFLayoutLMForMaskedLM"),_Mt.forEach(t),zbr=r(aPe," (LayoutLM model)"),aPe.forEach(t),Wbr=i(fe),eM=n(fe,"LI",{});var nPe=s(eM);Z4e=n(nPe,"STRONG",{});var bMt=s(Z4e);Qbr=r(bMt,"longformer"),bMt.forEach(t),Hbr=r(nPe," \u2014 "),pH=n(nPe,"A",{href:!0});var vMt=s(pH);Ubr=r(vMt,"TFLongformerForMaskedLM"),vMt.forEach(t),Jbr=r(nPe," (Longformer model)"),nPe.forEach(t),Ybr=i(fe),oM=n(fe,"LI",{});var sPe=s(oM);eve=n(sPe,"STRONG",{});var FMt=s(eve);Kbr=r(FMt,"mobilebert"),FMt.forEach(t),Zbr=r(sPe," \u2014 "),uH=n(sPe,"A",{href:!0});var TMt=s(uH);e4r=r(TMt,"TFMobileBertForMaskedLM"),TMt.forEach(t),o4r=r(sPe," (MobileBERT model)"),sPe.forEach(t),r4r=i(fe),rM=n(fe,"LI",{});var lPe=s(rM);ove=n(lPe,"STRONG",{});var MMt=s(ove);t4r=r(MMt,"mpnet"),MMt.forEach(t),a4r=r(lPe," \u2014 "),_H=n(lPe,"A",{href:!0});var EMt=s(_H);n4r=r(EMt,"TFMPNetForMaskedLM"),EMt.forEach(t),s4r=r(lPe," (MPNet model)"),lPe.forEach(t),l4r=i(fe),tM=n(fe,"LI",{});var iPe=s(tM);rve=n(iPe,"STRONG",{});var CMt=s(rve);i4r=r(CMt,"rembert"),CMt.forEach(t),d4r=r(iPe," \u2014 "),bH=n(iPe,"A",{href:!0});var wMt=s(bH);c4r=r(wMt,"TFRemBertForMaskedLM"),wMt.forEach(t),f4r=r(iPe," (RemBERT model)"),iPe.forEach(t),m4r=i(fe),aM=n(fe,"LI",{});var dPe=s(aM);tve=n(dPe,"STRONG",{});var AMt=s(tve);g4r=r(AMt,"roberta"),AMt.forEach(t),h4r=r(dPe," \u2014 "),vH=n(dPe,"A",{href:!0});var yMt=s(vH);p4r=r(yMt,"TFRobertaForMaskedLM"),yMt.forEach(t),u4r=r(dPe," (RoBERTa model)"),dPe.forEach(t),_4r=i(fe),nM=n(fe,"LI",{});var cPe=s(nM);ave=n(cPe,"STRONG",{});var LMt=s(ave);b4r=r(LMt,"roformer"),LMt.forEach(t),v4r=r(cPe," \u2014 "),FH=n(cPe,"A",{href:!0});var xMt=s(FH);F4r=r(xMt,"TFRoFormerForMaskedLM"),xMt.forEach(t),T4r=r(cPe," (RoFormer model)"),cPe.forEach(t),M4r=i(fe),sM=n(fe,"LI",{});var fPe=s(sM);nve=n(fPe,"STRONG",{});var $Mt=s(nve);E4r=r($Mt,"tapas"),$Mt.forEach(t),C4r=r(fPe," \u2014 "),TH=n(fPe,"A",{href:!0});var kMt=s(TH);w4r=r(kMt,"TFTapasForMaskedLM"),kMt.forEach(t),A4r=r(fPe," (TAPAS model)"),fPe.forEach(t),y4r=i(fe),lM=n(fe,"LI",{});var mPe=s(lM);sve=n(mPe,"STRONG",{});var SMt=s(sve);L4r=r(SMt,"xlm"),SMt.forEach(t),x4r=r(mPe," \u2014 "),MH=n(mPe,"A",{href:!0});var RMt=s(MH);$4r=r(RMt,"TFXLMWithLMHeadModel"),RMt.forEach(t),k4r=r(mPe," (XLM model)"),mPe.forEach(t),S4r=i(fe),iM=n(fe,"LI",{});var gPe=s(iM);lve=n(gPe,"STRONG",{});var PMt=s(lve);R4r=r(PMt,"xlm-roberta"),PMt.forEach(t),P4r=r(gPe," \u2014 "),EH=n(gPe,"A",{href:!0});var BMt=s(EH);B4r=r(BMt,"TFXLMRobertaForMaskedLM"),BMt.forEach(t),I4r=r(gPe," (XLM-RoBERTa model)"),gPe.forEach(t),fe.forEach(t),q4r=i(wl),T(dM.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),uje=i(f),nc=n(f,"H2",{class:!0});var MGe=s(nc);cM=n(MGe,"A",{id:!0,class:!0,href:!0});var IMt=s(cM);ive=n(IMt,"SPAN",{});var qMt=s(ive);T(R8.$$.fragment,qMt),qMt.forEach(t),IMt.forEach(t),N4r=i(MGe),dve=n(MGe,"SPAN",{});var NMt=s(dve);j4r=r(NMt,"TFAutoModelForSeq2SeqLM"),NMt.forEach(t),MGe.forEach(t),_je=i(f),rr=n(f,"DIV",{class:!0});var Al=s(rr);T(P8.$$.fragment,Al),D4r=i(Al),sc=n(Al,"P",{});var Cee=s(sc);G4r=r(Cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),CH=n(Cee,"A",{href:!0});var jMt=s(CH);O4r=r(jMt,"from_pretrained()"),jMt.forEach(t),V4r=r(Cee," class method or the "),wH=n(Cee,"A",{href:!0});var DMt=s(wH);X4r=r(DMt,"from_config()"),DMt.forEach(t),z4r=r(Cee,` class
method.`),Cee.forEach(t),W4r=i(Al),B8=n(Al,"P",{});var EGe=s(B8);Q4r=r(EGe,"This class cannot be instantiated directly using "),cve=n(EGe,"CODE",{});var GMt=s(cve);H4r=r(GMt,"__init__()"),GMt.forEach(t),U4r=r(EGe," (throws an error)."),EGe.forEach(t),J4r=i(Al),St=n(Al,"DIV",{class:!0});var B6=s(St);T(I8.$$.fragment,B6),Y4r=i(B6),fve=n(B6,"P",{});var OMt=s(fve);K4r=r(OMt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),OMt.forEach(t),Z4r=i(B6),lc=n(B6,"P",{});var wee=s(lc);evr=r(wee,`Note:
Loading a model from its configuration file does `),mve=n(wee,"STRONG",{});var VMt=s(mve);ovr=r(VMt,"not"),VMt.forEach(t),rvr=r(wee,` load the model weights. It only affects the
model\u2019s configuration. Use `),AH=n(wee,"A",{href:!0});var XMt=s(AH);tvr=r(XMt,"from_pretrained()"),XMt.forEach(t),avr=r(wee," to load the model weights."),wee.forEach(t),nvr=i(B6),T(fM.$$.fragment,B6),B6.forEach(t),svr=i(Al),$r=n(Al,"DIV",{class:!0});var yl=s($r);T(q8.$$.fragment,yl),lvr=i(yl),gve=n(yl,"P",{});var zMt=s(gve);ivr=r(zMt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),zMt.forEach(t),dvr=i(yl),an=n(yl,"P",{});var I6=s(an);cvr=r(I6,"The model class to instantiate is selected based on the "),hve=n(I6,"CODE",{});var WMt=s(hve);fvr=r(WMt,"model_type"),WMt.forEach(t),mvr=r(I6,` property of the config object (either
passed as an argument or loaded from `),pve=n(I6,"CODE",{});var QMt=s(pve);gvr=r(QMt,"pretrained_model_name_or_path"),QMt.forEach(t),hvr=r(I6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=n(I6,"CODE",{});var HMt=s(uve);pvr=r(HMt,"pretrained_model_name_or_path"),HMt.forEach(t),uvr=r(I6,":"),I6.forEach(t),_vr=i(yl),ye=n(yl,"UL",{});var Be=s(ye);mM=n(Be,"LI",{});var hPe=s(mM);_ve=n(hPe,"STRONG",{});var UMt=s(_ve);bvr=r(UMt,"bart"),UMt.forEach(t),vvr=r(hPe," \u2014 "),yH=n(hPe,"A",{href:!0});var JMt=s(yH);Fvr=r(JMt,"TFBartForConditionalGeneration"),JMt.forEach(t),Tvr=r(hPe," (BART model)"),hPe.forEach(t),Mvr=i(Be),gM=n(Be,"LI",{});var pPe=s(gM);bve=n(pPe,"STRONG",{});var YMt=s(bve);Evr=r(YMt,"blenderbot"),YMt.forEach(t),Cvr=r(pPe," \u2014 "),LH=n(pPe,"A",{href:!0});var KMt=s(LH);wvr=r(KMt,"TFBlenderbotForConditionalGeneration"),KMt.forEach(t),Avr=r(pPe," (Blenderbot model)"),pPe.forEach(t),yvr=i(Be),hM=n(Be,"LI",{});var uPe=s(hM);vve=n(uPe,"STRONG",{});var ZMt=s(vve);Lvr=r(ZMt,"blenderbot-small"),ZMt.forEach(t),xvr=r(uPe," \u2014 "),xH=n(uPe,"A",{href:!0});var eEt=s(xH);$vr=r(eEt,"TFBlenderbotSmallForConditionalGeneration"),eEt.forEach(t),kvr=r(uPe," (BlenderbotSmall model)"),uPe.forEach(t),Svr=i(Be),pM=n(Be,"LI",{});var _Pe=s(pM);Fve=n(_Pe,"STRONG",{});var oEt=s(Fve);Rvr=r(oEt,"encoder-decoder"),oEt.forEach(t),Pvr=r(_Pe," \u2014 "),$H=n(_Pe,"A",{href:!0});var rEt=s($H);Bvr=r(rEt,"TFEncoderDecoderModel"),rEt.forEach(t),Ivr=r(_Pe," (Encoder decoder model)"),_Pe.forEach(t),qvr=i(Be),uM=n(Be,"LI",{});var bPe=s(uM);Tve=n(bPe,"STRONG",{});var tEt=s(Tve);Nvr=r(tEt,"led"),tEt.forEach(t),jvr=r(bPe," \u2014 "),kH=n(bPe,"A",{href:!0});var aEt=s(kH);Dvr=r(aEt,"TFLEDForConditionalGeneration"),aEt.forEach(t),Gvr=r(bPe," (LED model)"),bPe.forEach(t),Ovr=i(Be),_M=n(Be,"LI",{});var vPe=s(_M);Mve=n(vPe,"STRONG",{});var nEt=s(Mve);Vvr=r(nEt,"marian"),nEt.forEach(t),Xvr=r(vPe," \u2014 "),SH=n(vPe,"A",{href:!0});var sEt=s(SH);zvr=r(sEt,"TFMarianMTModel"),sEt.forEach(t),Wvr=r(vPe," (Marian model)"),vPe.forEach(t),Qvr=i(Be),bM=n(Be,"LI",{});var FPe=s(bM);Eve=n(FPe,"STRONG",{});var lEt=s(Eve);Hvr=r(lEt,"mbart"),lEt.forEach(t),Uvr=r(FPe," \u2014 "),RH=n(FPe,"A",{href:!0});var iEt=s(RH);Jvr=r(iEt,"TFMBartForConditionalGeneration"),iEt.forEach(t),Yvr=r(FPe," (mBART model)"),FPe.forEach(t),Kvr=i(Be),vM=n(Be,"LI",{});var TPe=s(vM);Cve=n(TPe,"STRONG",{});var dEt=s(Cve);Zvr=r(dEt,"mt5"),dEt.forEach(t),e5r=r(TPe," \u2014 "),PH=n(TPe,"A",{href:!0});var cEt=s(PH);o5r=r(cEt,"TFMT5ForConditionalGeneration"),cEt.forEach(t),r5r=r(TPe," (mT5 model)"),TPe.forEach(t),t5r=i(Be),FM=n(Be,"LI",{});var MPe=s(FM);wve=n(MPe,"STRONG",{});var fEt=s(wve);a5r=r(fEt,"pegasus"),fEt.forEach(t),n5r=r(MPe," \u2014 "),BH=n(MPe,"A",{href:!0});var mEt=s(BH);s5r=r(mEt,"TFPegasusForConditionalGeneration"),mEt.forEach(t),l5r=r(MPe," (Pegasus model)"),MPe.forEach(t),i5r=i(Be),TM=n(Be,"LI",{});var EPe=s(TM);Ave=n(EPe,"STRONG",{});var gEt=s(Ave);d5r=r(gEt,"t5"),gEt.forEach(t),c5r=r(EPe," \u2014 "),IH=n(EPe,"A",{href:!0});var hEt=s(IH);f5r=r(hEt,"TFT5ForConditionalGeneration"),hEt.forEach(t),m5r=r(EPe," (T5 model)"),EPe.forEach(t),Be.forEach(t),g5r=i(yl),T(MM.$$.fragment,yl),yl.forEach(t),Al.forEach(t),bje=i(f),ic=n(f,"H2",{class:!0});var CGe=s(ic);EM=n(CGe,"A",{id:!0,class:!0,href:!0});var pEt=s(EM);yve=n(pEt,"SPAN",{});var uEt=s(yve);T(N8.$$.fragment,uEt),uEt.forEach(t),pEt.forEach(t),h5r=i(CGe),Lve=n(CGe,"SPAN",{});var _Et=s(Lve);p5r=r(_Et,"TFAutoModelForSequenceClassification"),_Et.forEach(t),CGe.forEach(t),vje=i(f),tr=n(f,"DIV",{class:!0});var Ll=s(tr);T(j8.$$.fragment,Ll),u5r=i(Ll),dc=n(Ll,"P",{});var Aee=s(dc);_5r=r(Aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qH=n(Aee,"A",{href:!0});var bEt=s(qH);b5r=r(bEt,"from_pretrained()"),bEt.forEach(t),v5r=r(Aee," class method or the "),NH=n(Aee,"A",{href:!0});var vEt=s(NH);F5r=r(vEt,"from_config()"),vEt.forEach(t),T5r=r(Aee,` class
method.`),Aee.forEach(t),M5r=i(Ll),D8=n(Ll,"P",{});var wGe=s(D8);E5r=r(wGe,"This class cannot be instantiated directly using "),xve=n(wGe,"CODE",{});var FEt=s(xve);C5r=r(FEt,"__init__()"),FEt.forEach(t),w5r=r(wGe," (throws an error)."),wGe.forEach(t),A5r=i(Ll),Rt=n(Ll,"DIV",{class:!0});var q6=s(Rt);T(G8.$$.fragment,q6),y5r=i(q6),$ve=n(q6,"P",{});var TEt=s($ve);L5r=r(TEt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),TEt.forEach(t),x5r=i(q6),cc=n(q6,"P",{});var yee=s(cc);$5r=r(yee,`Note:
Loading a model from its configuration file does `),kve=n(yee,"STRONG",{});var MEt=s(kve);k5r=r(MEt,"not"),MEt.forEach(t),S5r=r(yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=n(yee,"A",{href:!0});var EEt=s(jH);R5r=r(EEt,"from_pretrained()"),EEt.forEach(t),P5r=r(yee," to load the model weights."),yee.forEach(t),B5r=i(q6),T(CM.$$.fragment,q6),q6.forEach(t),I5r=i(Ll),kr=n(Ll,"DIV",{class:!0});var xl=s(kr);T(O8.$$.fragment,xl),q5r=i(xl),Sve=n(xl,"P",{});var CEt=s(Sve);N5r=r(CEt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),CEt.forEach(t),j5r=i(xl),nn=n(xl,"P",{});var N6=s(nn);D5r=r(N6,"The model class to instantiate is selected based on the "),Rve=n(N6,"CODE",{});var wEt=s(Rve);G5r=r(wEt,"model_type"),wEt.forEach(t),O5r=r(N6,` property of the config object (either
passed as an argument or loaded from `),Pve=n(N6,"CODE",{});var AEt=s(Pve);V5r=r(AEt,"pretrained_model_name_or_path"),AEt.forEach(t),X5r=r(N6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bve=n(N6,"CODE",{});var yEt=s(Bve);z5r=r(yEt,"pretrained_model_name_or_path"),yEt.forEach(t),W5r=r(N6,":"),N6.forEach(t),Q5r=i(xl),oe=n(xl,"UL",{});var ae=s(oe);wM=n(ae,"LI",{});var CPe=s(wM);Ive=n(CPe,"STRONG",{});var LEt=s(Ive);H5r=r(LEt,"albert"),LEt.forEach(t),U5r=r(CPe," \u2014 "),DH=n(CPe,"A",{href:!0});var xEt=s(DH);J5r=r(xEt,"TFAlbertForSequenceClassification"),xEt.forEach(t),Y5r=r(CPe," (ALBERT model)"),CPe.forEach(t),K5r=i(ae),AM=n(ae,"LI",{});var wPe=s(AM);qve=n(wPe,"STRONG",{});var $Et=s(qve);Z5r=r($Et,"bert"),$Et.forEach(t),eFr=r(wPe," \u2014 "),GH=n(wPe,"A",{href:!0});var kEt=s(GH);oFr=r(kEt,"TFBertForSequenceClassification"),kEt.forEach(t),rFr=r(wPe," (BERT model)"),wPe.forEach(t),tFr=i(ae),yM=n(ae,"LI",{});var APe=s(yM);Nve=n(APe,"STRONG",{});var SEt=s(Nve);aFr=r(SEt,"camembert"),SEt.forEach(t),nFr=r(APe," \u2014 "),OH=n(APe,"A",{href:!0});var REt=s(OH);sFr=r(REt,"TFCamembertForSequenceClassification"),REt.forEach(t),lFr=r(APe," (CamemBERT model)"),APe.forEach(t),iFr=i(ae),LM=n(ae,"LI",{});var yPe=s(LM);jve=n(yPe,"STRONG",{});var PEt=s(jve);dFr=r(PEt,"convbert"),PEt.forEach(t),cFr=r(yPe," \u2014 "),VH=n(yPe,"A",{href:!0});var BEt=s(VH);fFr=r(BEt,"TFConvBertForSequenceClassification"),BEt.forEach(t),mFr=r(yPe," (ConvBERT model)"),yPe.forEach(t),gFr=i(ae),xM=n(ae,"LI",{});var LPe=s(xM);Dve=n(LPe,"STRONG",{});var IEt=s(Dve);hFr=r(IEt,"ctrl"),IEt.forEach(t),pFr=r(LPe," \u2014 "),XH=n(LPe,"A",{href:!0});var qEt=s(XH);uFr=r(qEt,"TFCTRLForSequenceClassification"),qEt.forEach(t),_Fr=r(LPe," (CTRL model)"),LPe.forEach(t),bFr=i(ae),$M=n(ae,"LI",{});var xPe=s($M);Gve=n(xPe,"STRONG",{});var NEt=s(Gve);vFr=r(NEt,"deberta"),NEt.forEach(t),FFr=r(xPe," \u2014 "),zH=n(xPe,"A",{href:!0});var jEt=s(zH);TFr=r(jEt,"TFDebertaForSequenceClassification"),jEt.forEach(t),MFr=r(xPe," (DeBERTa model)"),xPe.forEach(t),EFr=i(ae),kM=n(ae,"LI",{});var $Pe=s(kM);Ove=n($Pe,"STRONG",{});var DEt=s(Ove);CFr=r(DEt,"deberta-v2"),DEt.forEach(t),wFr=r($Pe," \u2014 "),WH=n($Pe,"A",{href:!0});var GEt=s(WH);AFr=r(GEt,"TFDebertaV2ForSequenceClassification"),GEt.forEach(t),yFr=r($Pe," (DeBERTa-v2 model)"),$Pe.forEach(t),LFr=i(ae),SM=n(ae,"LI",{});var kPe=s(SM);Vve=n(kPe,"STRONG",{});var OEt=s(Vve);xFr=r(OEt,"distilbert"),OEt.forEach(t),$Fr=r(kPe," \u2014 "),QH=n(kPe,"A",{href:!0});var VEt=s(QH);kFr=r(VEt,"TFDistilBertForSequenceClassification"),VEt.forEach(t),SFr=r(kPe," (DistilBERT model)"),kPe.forEach(t),RFr=i(ae),RM=n(ae,"LI",{});var SPe=s(RM);Xve=n(SPe,"STRONG",{});var XEt=s(Xve);PFr=r(XEt,"electra"),XEt.forEach(t),BFr=r(SPe," \u2014 "),HH=n(SPe,"A",{href:!0});var zEt=s(HH);IFr=r(zEt,"TFElectraForSequenceClassification"),zEt.forEach(t),qFr=r(SPe," (ELECTRA model)"),SPe.forEach(t),NFr=i(ae),PM=n(ae,"LI",{});var RPe=s(PM);zve=n(RPe,"STRONG",{});var WEt=s(zve);jFr=r(WEt,"flaubert"),WEt.forEach(t),DFr=r(RPe," \u2014 "),UH=n(RPe,"A",{href:!0});var QEt=s(UH);GFr=r(QEt,"TFFlaubertForSequenceClassification"),QEt.forEach(t),OFr=r(RPe," (FlauBERT model)"),RPe.forEach(t),VFr=i(ae),BM=n(ae,"LI",{});var PPe=s(BM);Wve=n(PPe,"STRONG",{});var HEt=s(Wve);XFr=r(HEt,"funnel"),HEt.forEach(t),zFr=r(PPe," \u2014 "),JH=n(PPe,"A",{href:!0});var UEt=s(JH);WFr=r(UEt,"TFFunnelForSequenceClassification"),UEt.forEach(t),QFr=r(PPe," (Funnel Transformer model)"),PPe.forEach(t),HFr=i(ae),IM=n(ae,"LI",{});var BPe=s(IM);Qve=n(BPe,"STRONG",{});var JEt=s(Qve);UFr=r(JEt,"gpt2"),JEt.forEach(t),JFr=r(BPe," \u2014 "),YH=n(BPe,"A",{href:!0});var YEt=s(YH);YFr=r(YEt,"TFGPT2ForSequenceClassification"),YEt.forEach(t),KFr=r(BPe," (OpenAI GPT-2 model)"),BPe.forEach(t),ZFr=i(ae),qM=n(ae,"LI",{});var IPe=s(qM);Hve=n(IPe,"STRONG",{});var KEt=s(Hve);eTr=r(KEt,"gptj"),KEt.forEach(t),oTr=r(IPe," \u2014 "),KH=n(IPe,"A",{href:!0});var ZEt=s(KH);rTr=r(ZEt,"TFGPTJForSequenceClassification"),ZEt.forEach(t),tTr=r(IPe," (GPT-J model)"),IPe.forEach(t),aTr=i(ae),NM=n(ae,"LI",{});var qPe=s(NM);Uve=n(qPe,"STRONG",{});var eCt=s(Uve);nTr=r(eCt,"layoutlm"),eCt.forEach(t),sTr=r(qPe," \u2014 "),ZH=n(qPe,"A",{href:!0});var oCt=s(ZH);lTr=r(oCt,"TFLayoutLMForSequenceClassification"),oCt.forEach(t),iTr=r(qPe," (LayoutLM model)"),qPe.forEach(t),dTr=i(ae),jM=n(ae,"LI",{});var NPe=s(jM);Jve=n(NPe,"STRONG",{});var rCt=s(Jve);cTr=r(rCt,"longformer"),rCt.forEach(t),fTr=r(NPe," \u2014 "),eU=n(NPe,"A",{href:!0});var tCt=s(eU);mTr=r(tCt,"TFLongformerForSequenceClassification"),tCt.forEach(t),gTr=r(NPe," (Longformer model)"),NPe.forEach(t),hTr=i(ae),DM=n(ae,"LI",{});var jPe=s(DM);Yve=n(jPe,"STRONG",{});var aCt=s(Yve);pTr=r(aCt,"mobilebert"),aCt.forEach(t),uTr=r(jPe," \u2014 "),oU=n(jPe,"A",{href:!0});var nCt=s(oU);_Tr=r(nCt,"TFMobileBertForSequenceClassification"),nCt.forEach(t),bTr=r(jPe," (MobileBERT model)"),jPe.forEach(t),vTr=i(ae),GM=n(ae,"LI",{});var DPe=s(GM);Kve=n(DPe,"STRONG",{});var sCt=s(Kve);FTr=r(sCt,"mpnet"),sCt.forEach(t),TTr=r(DPe," \u2014 "),rU=n(DPe,"A",{href:!0});var lCt=s(rU);MTr=r(lCt,"TFMPNetForSequenceClassification"),lCt.forEach(t),ETr=r(DPe," (MPNet model)"),DPe.forEach(t),CTr=i(ae),OM=n(ae,"LI",{});var GPe=s(OM);Zve=n(GPe,"STRONG",{});var iCt=s(Zve);wTr=r(iCt,"openai-gpt"),iCt.forEach(t),ATr=r(GPe," \u2014 "),tU=n(GPe,"A",{href:!0});var dCt=s(tU);yTr=r(dCt,"TFOpenAIGPTForSequenceClassification"),dCt.forEach(t),LTr=r(GPe," (OpenAI GPT model)"),GPe.forEach(t),xTr=i(ae),VM=n(ae,"LI",{});var OPe=s(VM);e5e=n(OPe,"STRONG",{});var cCt=s(e5e);$Tr=r(cCt,"rembert"),cCt.forEach(t),kTr=r(OPe," \u2014 "),aU=n(OPe,"A",{href:!0});var fCt=s(aU);STr=r(fCt,"TFRemBertForSequenceClassification"),fCt.forEach(t),RTr=r(OPe," (RemBERT model)"),OPe.forEach(t),PTr=i(ae),XM=n(ae,"LI",{});var VPe=s(XM);o5e=n(VPe,"STRONG",{});var mCt=s(o5e);BTr=r(mCt,"roberta"),mCt.forEach(t),ITr=r(VPe," \u2014 "),nU=n(VPe,"A",{href:!0});var gCt=s(nU);qTr=r(gCt,"TFRobertaForSequenceClassification"),gCt.forEach(t),NTr=r(VPe," (RoBERTa model)"),VPe.forEach(t),jTr=i(ae),zM=n(ae,"LI",{});var XPe=s(zM);r5e=n(XPe,"STRONG",{});var hCt=s(r5e);DTr=r(hCt,"roformer"),hCt.forEach(t),GTr=r(XPe," \u2014 "),sU=n(XPe,"A",{href:!0});var pCt=s(sU);OTr=r(pCt,"TFRoFormerForSequenceClassification"),pCt.forEach(t),VTr=r(XPe," (RoFormer model)"),XPe.forEach(t),XTr=i(ae),WM=n(ae,"LI",{});var zPe=s(WM);t5e=n(zPe,"STRONG",{});var uCt=s(t5e);zTr=r(uCt,"tapas"),uCt.forEach(t),WTr=r(zPe," \u2014 "),lU=n(zPe,"A",{href:!0});var _Ct=s(lU);QTr=r(_Ct,"TFTapasForSequenceClassification"),_Ct.forEach(t),HTr=r(zPe," (TAPAS model)"),zPe.forEach(t),UTr=i(ae),QM=n(ae,"LI",{});var WPe=s(QM);a5e=n(WPe,"STRONG",{});var bCt=s(a5e);JTr=r(bCt,"transfo-xl"),bCt.forEach(t),YTr=r(WPe," \u2014 "),iU=n(WPe,"A",{href:!0});var vCt=s(iU);KTr=r(vCt,"TFTransfoXLForSequenceClassification"),vCt.forEach(t),ZTr=r(WPe," (Transformer-XL model)"),WPe.forEach(t),e7r=i(ae),HM=n(ae,"LI",{});var QPe=s(HM);n5e=n(QPe,"STRONG",{});var FCt=s(n5e);o7r=r(FCt,"xlm"),FCt.forEach(t),r7r=r(QPe," \u2014 "),dU=n(QPe,"A",{href:!0});var TCt=s(dU);t7r=r(TCt,"TFXLMForSequenceClassification"),TCt.forEach(t),a7r=r(QPe," (XLM model)"),QPe.forEach(t),n7r=i(ae),UM=n(ae,"LI",{});var HPe=s(UM);s5e=n(HPe,"STRONG",{});var MCt=s(s5e);s7r=r(MCt,"xlm-roberta"),MCt.forEach(t),l7r=r(HPe," \u2014 "),cU=n(HPe,"A",{href:!0});var ECt=s(cU);i7r=r(ECt,"TFXLMRobertaForSequenceClassification"),ECt.forEach(t),d7r=r(HPe," (XLM-RoBERTa model)"),HPe.forEach(t),c7r=i(ae),JM=n(ae,"LI",{});var UPe=s(JM);l5e=n(UPe,"STRONG",{});var CCt=s(l5e);f7r=r(CCt,"xlnet"),CCt.forEach(t),m7r=r(UPe," \u2014 "),fU=n(UPe,"A",{href:!0});var wCt=s(fU);g7r=r(wCt,"TFXLNetForSequenceClassification"),wCt.forEach(t),h7r=r(UPe," (XLNet model)"),UPe.forEach(t),ae.forEach(t),p7r=i(xl),T(YM.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),Fje=i(f),fc=n(f,"H2",{class:!0});var AGe=s(fc);KM=n(AGe,"A",{id:!0,class:!0,href:!0});var ACt=s(KM);i5e=n(ACt,"SPAN",{});var yCt=s(i5e);T(V8.$$.fragment,yCt),yCt.forEach(t),ACt.forEach(t),u7r=i(AGe),d5e=n(AGe,"SPAN",{});var LCt=s(d5e);_7r=r(LCt,"TFAutoModelForMultipleChoice"),LCt.forEach(t),AGe.forEach(t),Tje=i(f),ar=n(f,"DIV",{class:!0});var $l=s(ar);T(X8.$$.fragment,$l),b7r=i($l),mc=n($l,"P",{});var Lee=s(mc);v7r=r(Lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),mU=n(Lee,"A",{href:!0});var xCt=s(mU);F7r=r(xCt,"from_pretrained()"),xCt.forEach(t),T7r=r(Lee," class method or the "),gU=n(Lee,"A",{href:!0});var $Ct=s(gU);M7r=r($Ct,"from_config()"),$Ct.forEach(t),E7r=r(Lee,` class
method.`),Lee.forEach(t),C7r=i($l),z8=n($l,"P",{});var yGe=s(z8);w7r=r(yGe,"This class cannot be instantiated directly using "),c5e=n(yGe,"CODE",{});var kCt=s(c5e);A7r=r(kCt,"__init__()"),kCt.forEach(t),y7r=r(yGe," (throws an error)."),yGe.forEach(t),L7r=i($l),Pt=n($l,"DIV",{class:!0});var j6=s(Pt);T(W8.$$.fragment,j6),x7r=i(j6),f5e=n(j6,"P",{});var SCt=s(f5e);$7r=r(SCt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),SCt.forEach(t),k7r=i(j6),gc=n(j6,"P",{});var xee=s(gc);S7r=r(xee,`Note:
Loading a model from its configuration file does `),m5e=n(xee,"STRONG",{});var RCt=s(m5e);R7r=r(RCt,"not"),RCt.forEach(t),P7r=r(xee,` load the model weights. It only affects the
model\u2019s configuration. Use `),hU=n(xee,"A",{href:!0});var PCt=s(hU);B7r=r(PCt,"from_pretrained()"),PCt.forEach(t),I7r=r(xee," to load the model weights."),xee.forEach(t),q7r=i(j6),T(ZM.$$.fragment,j6),j6.forEach(t),N7r=i($l),Sr=n($l,"DIV",{class:!0});var kl=s(Sr);T(Q8.$$.fragment,kl),j7r=i(kl),g5e=n(kl,"P",{});var BCt=s(g5e);D7r=r(BCt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),BCt.forEach(t),G7r=i(kl),sn=n(kl,"P",{});var D6=s(sn);O7r=r(D6,"The model class to instantiate is selected based on the "),h5e=n(D6,"CODE",{});var ICt=s(h5e);V7r=r(ICt,"model_type"),ICt.forEach(t),X7r=r(D6,` property of the config object (either
passed as an argument or loaded from `),p5e=n(D6,"CODE",{});var qCt=s(p5e);z7r=r(qCt,"pretrained_model_name_or_path"),qCt.forEach(t),W7r=r(D6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u5e=n(D6,"CODE",{});var NCt=s(u5e);Q7r=r(NCt,"pretrained_model_name_or_path"),NCt.forEach(t),H7r=r(D6,":"),D6.forEach(t),U7r=i(kl),pe=n(kl,"UL",{});var be=s(pe);eE=n(be,"LI",{});var JPe=s(eE);_5e=n(JPe,"STRONG",{});var jCt=s(_5e);J7r=r(jCt,"albert"),jCt.forEach(t),Y7r=r(JPe," \u2014 "),pU=n(JPe,"A",{href:!0});var DCt=s(pU);K7r=r(DCt,"TFAlbertForMultipleChoice"),DCt.forEach(t),Z7r=r(JPe," (ALBERT model)"),JPe.forEach(t),eMr=i(be),oE=n(be,"LI",{});var YPe=s(oE);b5e=n(YPe,"STRONG",{});var GCt=s(b5e);oMr=r(GCt,"bert"),GCt.forEach(t),rMr=r(YPe," \u2014 "),uU=n(YPe,"A",{href:!0});var OCt=s(uU);tMr=r(OCt,"TFBertForMultipleChoice"),OCt.forEach(t),aMr=r(YPe," (BERT model)"),YPe.forEach(t),nMr=i(be),rE=n(be,"LI",{});var KPe=s(rE);v5e=n(KPe,"STRONG",{});var VCt=s(v5e);sMr=r(VCt,"camembert"),VCt.forEach(t),lMr=r(KPe," \u2014 "),_U=n(KPe,"A",{href:!0});var XCt=s(_U);iMr=r(XCt,"TFCamembertForMultipleChoice"),XCt.forEach(t),dMr=r(KPe," (CamemBERT model)"),KPe.forEach(t),cMr=i(be),tE=n(be,"LI",{});var ZPe=s(tE);F5e=n(ZPe,"STRONG",{});var zCt=s(F5e);fMr=r(zCt,"convbert"),zCt.forEach(t),mMr=r(ZPe," \u2014 "),bU=n(ZPe,"A",{href:!0});var WCt=s(bU);gMr=r(WCt,"TFConvBertForMultipleChoice"),WCt.forEach(t),hMr=r(ZPe," (ConvBERT model)"),ZPe.forEach(t),pMr=i(be),aE=n(be,"LI",{});var eBe=s(aE);T5e=n(eBe,"STRONG",{});var QCt=s(T5e);uMr=r(QCt,"distilbert"),QCt.forEach(t),_Mr=r(eBe," \u2014 "),vU=n(eBe,"A",{href:!0});var HCt=s(vU);bMr=r(HCt,"TFDistilBertForMultipleChoice"),HCt.forEach(t),vMr=r(eBe," (DistilBERT model)"),eBe.forEach(t),FMr=i(be),nE=n(be,"LI",{});var oBe=s(nE);M5e=n(oBe,"STRONG",{});var UCt=s(M5e);TMr=r(UCt,"electra"),UCt.forEach(t),MMr=r(oBe," \u2014 "),FU=n(oBe,"A",{href:!0});var JCt=s(FU);EMr=r(JCt,"TFElectraForMultipleChoice"),JCt.forEach(t),CMr=r(oBe," (ELECTRA model)"),oBe.forEach(t),wMr=i(be),sE=n(be,"LI",{});var rBe=s(sE);E5e=n(rBe,"STRONG",{});var YCt=s(E5e);AMr=r(YCt,"flaubert"),YCt.forEach(t),yMr=r(rBe," \u2014 "),TU=n(rBe,"A",{href:!0});var KCt=s(TU);LMr=r(KCt,"TFFlaubertForMultipleChoice"),KCt.forEach(t),xMr=r(rBe," (FlauBERT model)"),rBe.forEach(t),$Mr=i(be),lE=n(be,"LI",{});var tBe=s(lE);C5e=n(tBe,"STRONG",{});var ZCt=s(C5e);kMr=r(ZCt,"funnel"),ZCt.forEach(t),SMr=r(tBe," \u2014 "),MU=n(tBe,"A",{href:!0});var e3t=s(MU);RMr=r(e3t,"TFFunnelForMultipleChoice"),e3t.forEach(t),PMr=r(tBe," (Funnel Transformer model)"),tBe.forEach(t),BMr=i(be),iE=n(be,"LI",{});var aBe=s(iE);w5e=n(aBe,"STRONG",{});var o3t=s(w5e);IMr=r(o3t,"longformer"),o3t.forEach(t),qMr=r(aBe," \u2014 "),EU=n(aBe,"A",{href:!0});var r3t=s(EU);NMr=r(r3t,"TFLongformerForMultipleChoice"),r3t.forEach(t),jMr=r(aBe," (Longformer model)"),aBe.forEach(t),DMr=i(be),dE=n(be,"LI",{});var nBe=s(dE);A5e=n(nBe,"STRONG",{});var t3t=s(A5e);GMr=r(t3t,"mobilebert"),t3t.forEach(t),OMr=r(nBe," \u2014 "),CU=n(nBe,"A",{href:!0});var a3t=s(CU);VMr=r(a3t,"TFMobileBertForMultipleChoice"),a3t.forEach(t),XMr=r(nBe," (MobileBERT model)"),nBe.forEach(t),zMr=i(be),cE=n(be,"LI",{});var sBe=s(cE);y5e=n(sBe,"STRONG",{});var n3t=s(y5e);WMr=r(n3t,"mpnet"),n3t.forEach(t),QMr=r(sBe," \u2014 "),wU=n(sBe,"A",{href:!0});var s3t=s(wU);HMr=r(s3t,"TFMPNetForMultipleChoice"),s3t.forEach(t),UMr=r(sBe," (MPNet model)"),sBe.forEach(t),JMr=i(be),fE=n(be,"LI",{});var lBe=s(fE);L5e=n(lBe,"STRONG",{});var l3t=s(L5e);YMr=r(l3t,"rembert"),l3t.forEach(t),KMr=r(lBe," \u2014 "),AU=n(lBe,"A",{href:!0});var i3t=s(AU);ZMr=r(i3t,"TFRemBertForMultipleChoice"),i3t.forEach(t),eEr=r(lBe," (RemBERT model)"),lBe.forEach(t),oEr=i(be),mE=n(be,"LI",{});var iBe=s(mE);x5e=n(iBe,"STRONG",{});var d3t=s(x5e);rEr=r(d3t,"roberta"),d3t.forEach(t),tEr=r(iBe," \u2014 "),yU=n(iBe,"A",{href:!0});var c3t=s(yU);aEr=r(c3t,"TFRobertaForMultipleChoice"),c3t.forEach(t),nEr=r(iBe," (RoBERTa model)"),iBe.forEach(t),sEr=i(be),gE=n(be,"LI",{});var dBe=s(gE);$5e=n(dBe,"STRONG",{});var f3t=s($5e);lEr=r(f3t,"roformer"),f3t.forEach(t),iEr=r(dBe," \u2014 "),LU=n(dBe,"A",{href:!0});var m3t=s(LU);dEr=r(m3t,"TFRoFormerForMultipleChoice"),m3t.forEach(t),cEr=r(dBe," (RoFormer model)"),dBe.forEach(t),fEr=i(be),hE=n(be,"LI",{});var cBe=s(hE);k5e=n(cBe,"STRONG",{});var g3t=s(k5e);mEr=r(g3t,"xlm"),g3t.forEach(t),gEr=r(cBe," \u2014 "),xU=n(cBe,"A",{href:!0});var h3t=s(xU);hEr=r(h3t,"TFXLMForMultipleChoice"),h3t.forEach(t),pEr=r(cBe," (XLM model)"),cBe.forEach(t),uEr=i(be),pE=n(be,"LI",{});var fBe=s(pE);S5e=n(fBe,"STRONG",{});var p3t=s(S5e);_Er=r(p3t,"xlm-roberta"),p3t.forEach(t),bEr=r(fBe," \u2014 "),$U=n(fBe,"A",{href:!0});var u3t=s($U);vEr=r(u3t,"TFXLMRobertaForMultipleChoice"),u3t.forEach(t),FEr=r(fBe," (XLM-RoBERTa model)"),fBe.forEach(t),TEr=i(be),uE=n(be,"LI",{});var mBe=s(uE);R5e=n(mBe,"STRONG",{});var _3t=s(R5e);MEr=r(_3t,"xlnet"),_3t.forEach(t),EEr=r(mBe," \u2014 "),kU=n(mBe,"A",{href:!0});var b3t=s(kU);CEr=r(b3t,"TFXLNetForMultipleChoice"),b3t.forEach(t),wEr=r(mBe," (XLNet model)"),mBe.forEach(t),be.forEach(t),AEr=i(kl),T(_E.$$.fragment,kl),kl.forEach(t),$l.forEach(t),Mje=i(f),hc=n(f,"H2",{class:!0});var LGe=s(hc);bE=n(LGe,"A",{id:!0,class:!0,href:!0});var v3t=s(bE);P5e=n(v3t,"SPAN",{});var F3t=s(P5e);T(H8.$$.fragment,F3t),F3t.forEach(t),v3t.forEach(t),yEr=i(LGe),B5e=n(LGe,"SPAN",{});var T3t=s(B5e);LEr=r(T3t,"TFAutoModelForNextSentencePrediction"),T3t.forEach(t),LGe.forEach(t),Eje=i(f),nr=n(f,"DIV",{class:!0});var Sl=s(nr);T(U8.$$.fragment,Sl),xEr=i(Sl),pc=n(Sl,"P",{});var $ee=s(pc);$Er=r($ee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),SU=n($ee,"A",{href:!0});var M3t=s(SU);kEr=r(M3t,"from_pretrained()"),M3t.forEach(t),SEr=r($ee," class method or the "),RU=n($ee,"A",{href:!0});var E3t=s(RU);REr=r(E3t,"from_config()"),E3t.forEach(t),PEr=r($ee,` class
method.`),$ee.forEach(t),BEr=i(Sl),J8=n(Sl,"P",{});var xGe=s(J8);IEr=r(xGe,"This class cannot be instantiated directly using "),I5e=n(xGe,"CODE",{});var C3t=s(I5e);qEr=r(C3t,"__init__()"),C3t.forEach(t),NEr=r(xGe," (throws an error)."),xGe.forEach(t),jEr=i(Sl),Bt=n(Sl,"DIV",{class:!0});var G6=s(Bt);T(Y8.$$.fragment,G6),DEr=i(G6),q5e=n(G6,"P",{});var w3t=s(q5e);GEr=r(w3t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),w3t.forEach(t),OEr=i(G6),uc=n(G6,"P",{});var kee=s(uc);VEr=r(kee,`Note:
Loading a model from its configuration file does `),N5e=n(kee,"STRONG",{});var A3t=s(N5e);XEr=r(A3t,"not"),A3t.forEach(t),zEr=r(kee,` load the model weights. It only affects the
model\u2019s configuration. Use `),PU=n(kee,"A",{href:!0});var y3t=s(PU);WEr=r(y3t,"from_pretrained()"),y3t.forEach(t),QEr=r(kee," to load the model weights."),kee.forEach(t),HEr=i(G6),T(vE.$$.fragment,G6),G6.forEach(t),UEr=i(Sl),Rr=n(Sl,"DIV",{class:!0});var Rl=s(Rr);T(K8.$$.fragment,Rl),JEr=i(Rl),j5e=n(Rl,"P",{});var L3t=s(j5e);YEr=r(L3t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),L3t.forEach(t),KEr=i(Rl),ln=n(Rl,"P",{});var O6=s(ln);ZEr=r(O6,"The model class to instantiate is selected based on the "),D5e=n(O6,"CODE",{});var x3t=s(D5e);eCr=r(x3t,"model_type"),x3t.forEach(t),oCr=r(O6,` property of the config object (either
passed as an argument or loaded from `),G5e=n(O6,"CODE",{});var $3t=s(G5e);rCr=r($3t,"pretrained_model_name_or_path"),$3t.forEach(t),tCr=r(O6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O5e=n(O6,"CODE",{});var k3t=s(O5e);aCr=r(k3t,"pretrained_model_name_or_path"),k3t.forEach(t),nCr=r(O6,":"),O6.forEach(t),sCr=i(Rl),Z8=n(Rl,"UL",{});var $Ge=s(Z8);FE=n($Ge,"LI",{});var gBe=s(FE);V5e=n(gBe,"STRONG",{});var S3t=s(V5e);lCr=r(S3t,"bert"),S3t.forEach(t),iCr=r(gBe," \u2014 "),BU=n(gBe,"A",{href:!0});var R3t=s(BU);dCr=r(R3t,"TFBertForNextSentencePrediction"),R3t.forEach(t),cCr=r(gBe," (BERT model)"),gBe.forEach(t),fCr=i($Ge),TE=n($Ge,"LI",{});var hBe=s(TE);X5e=n(hBe,"STRONG",{});var P3t=s(X5e);mCr=r(P3t,"mobilebert"),P3t.forEach(t),gCr=r(hBe," \u2014 "),IU=n(hBe,"A",{href:!0});var B3t=s(IU);hCr=r(B3t,"TFMobileBertForNextSentencePrediction"),B3t.forEach(t),pCr=r(hBe," (MobileBERT model)"),hBe.forEach(t),$Ge.forEach(t),uCr=i(Rl),T(ME.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),Cje=i(f),_c=n(f,"H2",{class:!0});var kGe=s(_c);EE=n(kGe,"A",{id:!0,class:!0,href:!0});var I3t=s(EE);z5e=n(I3t,"SPAN",{});var q3t=s(z5e);T(e9.$$.fragment,q3t),q3t.forEach(t),I3t.forEach(t),_Cr=i(kGe),W5e=n(kGe,"SPAN",{});var N3t=s(W5e);bCr=r(N3t,"TFAutoModelForTableQuestionAnswering"),N3t.forEach(t),kGe.forEach(t),wje=i(f),sr=n(f,"DIV",{class:!0});var Pl=s(sr);T(o9.$$.fragment,Pl),vCr=i(Pl),bc=n(Pl,"P",{});var See=s(bc);FCr=r(See,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qU=n(See,"A",{href:!0});var j3t=s(qU);TCr=r(j3t,"from_pretrained()"),j3t.forEach(t),MCr=r(See," class method or the "),NU=n(See,"A",{href:!0});var D3t=s(NU);ECr=r(D3t,"from_config()"),D3t.forEach(t),CCr=r(See,` class
method.`),See.forEach(t),wCr=i(Pl),r9=n(Pl,"P",{});var SGe=s(r9);ACr=r(SGe,"This class cannot be instantiated directly using "),Q5e=n(SGe,"CODE",{});var G3t=s(Q5e);yCr=r(G3t,"__init__()"),G3t.forEach(t),LCr=r(SGe," (throws an error)."),SGe.forEach(t),xCr=i(Pl),It=n(Pl,"DIV",{class:!0});var V6=s(It);T(t9.$$.fragment,V6),$Cr=i(V6),H5e=n(V6,"P",{});var O3t=s(H5e);kCr=r(O3t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),O3t.forEach(t),SCr=i(V6),vc=n(V6,"P",{});var Ree=s(vc);RCr=r(Ree,`Note:
Loading a model from its configuration file does `),U5e=n(Ree,"STRONG",{});var V3t=s(U5e);PCr=r(V3t,"not"),V3t.forEach(t),BCr=r(Ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),jU=n(Ree,"A",{href:!0});var X3t=s(jU);ICr=r(X3t,"from_pretrained()"),X3t.forEach(t),qCr=r(Ree," to load the model weights."),Ree.forEach(t),NCr=i(V6),T(CE.$$.fragment,V6),V6.forEach(t),jCr=i(Pl),Pr=n(Pl,"DIV",{class:!0});var Bl=s(Pr);T(a9.$$.fragment,Bl),DCr=i(Bl),J5e=n(Bl,"P",{});var z3t=s(J5e);GCr=r(z3t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),z3t.forEach(t),OCr=i(Bl),dn=n(Bl,"P",{});var X6=s(dn);VCr=r(X6,"The model class to instantiate is selected based on the "),Y5e=n(X6,"CODE",{});var W3t=s(Y5e);XCr=r(W3t,"model_type"),W3t.forEach(t),zCr=r(X6,` property of the config object (either
passed as an argument or loaded from `),K5e=n(X6,"CODE",{});var Q3t=s(K5e);WCr=r(Q3t,"pretrained_model_name_or_path"),Q3t.forEach(t),QCr=r(X6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z5e=n(X6,"CODE",{});var H3t=s(Z5e);HCr=r(H3t,"pretrained_model_name_or_path"),H3t.forEach(t),UCr=r(X6,":"),X6.forEach(t),JCr=i(Bl),eFe=n(Bl,"UL",{});var U3t=s(eFe);wE=n(U3t,"LI",{});var pBe=s(wE);oFe=n(pBe,"STRONG",{});var J3t=s(oFe);YCr=r(J3t,"tapas"),J3t.forEach(t),KCr=r(pBe," \u2014 "),DU=n(pBe,"A",{href:!0});var Y3t=s(DU);ZCr=r(Y3t,"TFTapasForQuestionAnswering"),Y3t.forEach(t),e3r=r(pBe," (TAPAS model)"),pBe.forEach(t),U3t.forEach(t),o3r=i(Bl),T(AE.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),Aje=i(f),Fc=n(f,"H2",{class:!0});var RGe=s(Fc);yE=n(RGe,"A",{id:!0,class:!0,href:!0});var K3t=s(yE);rFe=n(K3t,"SPAN",{});var Z3t=s(rFe);T(n9.$$.fragment,Z3t),Z3t.forEach(t),K3t.forEach(t),r3r=i(RGe),tFe=n(RGe,"SPAN",{});var ewt=s(tFe);t3r=r(ewt,"TFAutoModelForTokenClassification"),ewt.forEach(t),RGe.forEach(t),yje=i(f),lr=n(f,"DIV",{class:!0});var Il=s(lr);T(s9.$$.fragment,Il),a3r=i(Il),Tc=n(Il,"P",{});var Pee=s(Tc);n3r=r(Pee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),GU=n(Pee,"A",{href:!0});var owt=s(GU);s3r=r(owt,"from_pretrained()"),owt.forEach(t),l3r=r(Pee," class method or the "),OU=n(Pee,"A",{href:!0});var rwt=s(OU);i3r=r(rwt,"from_config()"),rwt.forEach(t),d3r=r(Pee,` class
method.`),Pee.forEach(t),c3r=i(Il),l9=n(Il,"P",{});var PGe=s(l9);f3r=r(PGe,"This class cannot be instantiated directly using "),aFe=n(PGe,"CODE",{});var twt=s(aFe);m3r=r(twt,"__init__()"),twt.forEach(t),g3r=r(PGe," (throws an error)."),PGe.forEach(t),h3r=i(Il),qt=n(Il,"DIV",{class:!0});var z6=s(qt);T(i9.$$.fragment,z6),p3r=i(z6),nFe=n(z6,"P",{});var awt=s(nFe);u3r=r(awt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),awt.forEach(t),_3r=i(z6),Mc=n(z6,"P",{});var Bee=s(Mc);b3r=r(Bee,`Note:
Loading a model from its configuration file does `),sFe=n(Bee,"STRONG",{});var nwt=s(sFe);v3r=r(nwt,"not"),nwt.forEach(t),F3r=r(Bee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Bee,"A",{href:!0});var swt=s(VU);T3r=r(swt,"from_pretrained()"),swt.forEach(t),M3r=r(Bee," to load the model weights."),Bee.forEach(t),E3r=i(z6),T(LE.$$.fragment,z6),z6.forEach(t),C3r=i(Il),Br=n(Il,"DIV",{class:!0});var ql=s(Br);T(d9.$$.fragment,ql),w3r=i(ql),lFe=n(ql,"P",{});var lwt=s(lFe);A3r=r(lwt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),lwt.forEach(t),y3r=i(ql),cn=n(ql,"P",{});var W6=s(cn);L3r=r(W6,"The model class to instantiate is selected based on the "),iFe=n(W6,"CODE",{});var iwt=s(iFe);x3r=r(iwt,"model_type"),iwt.forEach(t),$3r=r(W6,` property of the config object (either
passed as an argument or loaded from `),dFe=n(W6,"CODE",{});var dwt=s(dFe);k3r=r(dwt,"pretrained_model_name_or_path"),dwt.forEach(t),S3r=r(W6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cFe=n(W6,"CODE",{});var cwt=s(cFe);R3r=r(cwt,"pretrained_model_name_or_path"),cwt.forEach(t),P3r=r(W6,":"),W6.forEach(t),B3r=i(ql),de=n(ql,"UL",{});var me=s(de);xE=n(me,"LI",{});var uBe=s(xE);fFe=n(uBe,"STRONG",{});var fwt=s(fFe);I3r=r(fwt,"albert"),fwt.forEach(t),q3r=r(uBe," \u2014 "),XU=n(uBe,"A",{href:!0});var mwt=s(XU);N3r=r(mwt,"TFAlbertForTokenClassification"),mwt.forEach(t),j3r=r(uBe," (ALBERT model)"),uBe.forEach(t),D3r=i(me),$E=n(me,"LI",{});var _Be=s($E);mFe=n(_Be,"STRONG",{});var gwt=s(mFe);G3r=r(gwt,"bert"),gwt.forEach(t),O3r=r(_Be," \u2014 "),zU=n(_Be,"A",{href:!0});var hwt=s(zU);V3r=r(hwt,"TFBertForTokenClassification"),hwt.forEach(t),X3r=r(_Be," (BERT model)"),_Be.forEach(t),z3r=i(me),kE=n(me,"LI",{});var bBe=s(kE);gFe=n(bBe,"STRONG",{});var pwt=s(gFe);W3r=r(pwt,"camembert"),pwt.forEach(t),Q3r=r(bBe," \u2014 "),WU=n(bBe,"A",{href:!0});var uwt=s(WU);H3r=r(uwt,"TFCamembertForTokenClassification"),uwt.forEach(t),U3r=r(bBe," (CamemBERT model)"),bBe.forEach(t),J3r=i(me),SE=n(me,"LI",{});var vBe=s(SE);hFe=n(vBe,"STRONG",{});var _wt=s(hFe);Y3r=r(_wt,"convbert"),_wt.forEach(t),K3r=r(vBe," \u2014 "),QU=n(vBe,"A",{href:!0});var bwt=s(QU);Z3r=r(bwt,"TFConvBertForTokenClassification"),bwt.forEach(t),ewr=r(vBe," (ConvBERT model)"),vBe.forEach(t),owr=i(me),RE=n(me,"LI",{});var FBe=s(RE);pFe=n(FBe,"STRONG",{});var vwt=s(pFe);rwr=r(vwt,"deberta"),vwt.forEach(t),twr=r(FBe," \u2014 "),HU=n(FBe,"A",{href:!0});var Fwt=s(HU);awr=r(Fwt,"TFDebertaForTokenClassification"),Fwt.forEach(t),nwr=r(FBe," (DeBERTa model)"),FBe.forEach(t),swr=i(me),PE=n(me,"LI",{});var TBe=s(PE);uFe=n(TBe,"STRONG",{});var Twt=s(uFe);lwr=r(Twt,"deberta-v2"),Twt.forEach(t),iwr=r(TBe," \u2014 "),UU=n(TBe,"A",{href:!0});var Mwt=s(UU);dwr=r(Mwt,"TFDebertaV2ForTokenClassification"),Mwt.forEach(t),cwr=r(TBe," (DeBERTa-v2 model)"),TBe.forEach(t),fwr=i(me),BE=n(me,"LI",{});var MBe=s(BE);_Fe=n(MBe,"STRONG",{});var Ewt=s(_Fe);mwr=r(Ewt,"distilbert"),Ewt.forEach(t),gwr=r(MBe," \u2014 "),JU=n(MBe,"A",{href:!0});var Cwt=s(JU);hwr=r(Cwt,"TFDistilBertForTokenClassification"),Cwt.forEach(t),pwr=r(MBe," (DistilBERT model)"),MBe.forEach(t),uwr=i(me),IE=n(me,"LI",{});var EBe=s(IE);bFe=n(EBe,"STRONG",{});var wwt=s(bFe);_wr=r(wwt,"electra"),wwt.forEach(t),bwr=r(EBe," \u2014 "),YU=n(EBe,"A",{href:!0});var Awt=s(YU);vwr=r(Awt,"TFElectraForTokenClassification"),Awt.forEach(t),Fwr=r(EBe," (ELECTRA model)"),EBe.forEach(t),Twr=i(me),qE=n(me,"LI",{});var CBe=s(qE);vFe=n(CBe,"STRONG",{});var ywt=s(vFe);Mwr=r(ywt,"flaubert"),ywt.forEach(t),Ewr=r(CBe," \u2014 "),KU=n(CBe,"A",{href:!0});var Lwt=s(KU);Cwr=r(Lwt,"TFFlaubertForTokenClassification"),Lwt.forEach(t),wwr=r(CBe," (FlauBERT model)"),CBe.forEach(t),Awr=i(me),NE=n(me,"LI",{});var wBe=s(NE);FFe=n(wBe,"STRONG",{});var xwt=s(FFe);ywr=r(xwt,"funnel"),xwt.forEach(t),Lwr=r(wBe," \u2014 "),ZU=n(wBe,"A",{href:!0});var $wt=s(ZU);xwr=r($wt,"TFFunnelForTokenClassification"),$wt.forEach(t),$wr=r(wBe," (Funnel Transformer model)"),wBe.forEach(t),kwr=i(me),jE=n(me,"LI",{});var ABe=s(jE);TFe=n(ABe,"STRONG",{});var kwt=s(TFe);Swr=r(kwt,"layoutlm"),kwt.forEach(t),Rwr=r(ABe," \u2014 "),eJ=n(ABe,"A",{href:!0});var Swt=s(eJ);Pwr=r(Swt,"TFLayoutLMForTokenClassification"),Swt.forEach(t),Bwr=r(ABe," (LayoutLM model)"),ABe.forEach(t),Iwr=i(me),DE=n(me,"LI",{});var yBe=s(DE);MFe=n(yBe,"STRONG",{});var Rwt=s(MFe);qwr=r(Rwt,"longformer"),Rwt.forEach(t),Nwr=r(yBe," \u2014 "),oJ=n(yBe,"A",{href:!0});var Pwt=s(oJ);jwr=r(Pwt,"TFLongformerForTokenClassification"),Pwt.forEach(t),Dwr=r(yBe," (Longformer model)"),yBe.forEach(t),Gwr=i(me),GE=n(me,"LI",{});var LBe=s(GE);EFe=n(LBe,"STRONG",{});var Bwt=s(EFe);Owr=r(Bwt,"mobilebert"),Bwt.forEach(t),Vwr=r(LBe," \u2014 "),rJ=n(LBe,"A",{href:!0});var Iwt=s(rJ);Xwr=r(Iwt,"TFMobileBertForTokenClassification"),Iwt.forEach(t),zwr=r(LBe," (MobileBERT model)"),LBe.forEach(t),Wwr=i(me),OE=n(me,"LI",{});var xBe=s(OE);CFe=n(xBe,"STRONG",{});var qwt=s(CFe);Qwr=r(qwt,"mpnet"),qwt.forEach(t),Hwr=r(xBe," \u2014 "),tJ=n(xBe,"A",{href:!0});var Nwt=s(tJ);Uwr=r(Nwt,"TFMPNetForTokenClassification"),Nwt.forEach(t),Jwr=r(xBe," (MPNet model)"),xBe.forEach(t),Ywr=i(me),VE=n(me,"LI",{});var $Be=s(VE);wFe=n($Be,"STRONG",{});var jwt=s(wFe);Kwr=r(jwt,"rembert"),jwt.forEach(t),Zwr=r($Be," \u2014 "),aJ=n($Be,"A",{href:!0});var Dwt=s(aJ);e0r=r(Dwt,"TFRemBertForTokenClassification"),Dwt.forEach(t),o0r=r($Be," (RemBERT model)"),$Be.forEach(t),r0r=i(me),XE=n(me,"LI",{});var kBe=s(XE);AFe=n(kBe,"STRONG",{});var Gwt=s(AFe);t0r=r(Gwt,"roberta"),Gwt.forEach(t),a0r=r(kBe," \u2014 "),nJ=n(kBe,"A",{href:!0});var Owt=s(nJ);n0r=r(Owt,"TFRobertaForTokenClassification"),Owt.forEach(t),s0r=r(kBe," (RoBERTa model)"),kBe.forEach(t),l0r=i(me),zE=n(me,"LI",{});var SBe=s(zE);yFe=n(SBe,"STRONG",{});var Vwt=s(yFe);i0r=r(Vwt,"roformer"),Vwt.forEach(t),d0r=r(SBe," \u2014 "),sJ=n(SBe,"A",{href:!0});var Xwt=s(sJ);c0r=r(Xwt,"TFRoFormerForTokenClassification"),Xwt.forEach(t),f0r=r(SBe," (RoFormer model)"),SBe.forEach(t),m0r=i(me),WE=n(me,"LI",{});var RBe=s(WE);LFe=n(RBe,"STRONG",{});var zwt=s(LFe);g0r=r(zwt,"xlm"),zwt.forEach(t),h0r=r(RBe," \u2014 "),lJ=n(RBe,"A",{href:!0});var Wwt=s(lJ);p0r=r(Wwt,"TFXLMForTokenClassification"),Wwt.forEach(t),u0r=r(RBe," (XLM model)"),RBe.forEach(t),_0r=i(me),QE=n(me,"LI",{});var PBe=s(QE);xFe=n(PBe,"STRONG",{});var Qwt=s(xFe);b0r=r(Qwt,"xlm-roberta"),Qwt.forEach(t),v0r=r(PBe," \u2014 "),iJ=n(PBe,"A",{href:!0});var Hwt=s(iJ);F0r=r(Hwt,"TFXLMRobertaForTokenClassification"),Hwt.forEach(t),T0r=r(PBe," (XLM-RoBERTa model)"),PBe.forEach(t),M0r=i(me),HE=n(me,"LI",{});var BBe=s(HE);$Fe=n(BBe,"STRONG",{});var Uwt=s($Fe);E0r=r(Uwt,"xlnet"),Uwt.forEach(t),C0r=r(BBe," \u2014 "),dJ=n(BBe,"A",{href:!0});var Jwt=s(dJ);w0r=r(Jwt,"TFXLNetForTokenClassification"),Jwt.forEach(t),A0r=r(BBe," (XLNet model)"),BBe.forEach(t),me.forEach(t),y0r=i(ql),T(UE.$$.fragment,ql),ql.forEach(t),Il.forEach(t),Lje=i(f),Ec=n(f,"H2",{class:!0});var BGe=s(Ec);JE=n(BGe,"A",{id:!0,class:!0,href:!0});var Ywt=s(JE);kFe=n(Ywt,"SPAN",{});var Kwt=s(kFe);T(c9.$$.fragment,Kwt),Kwt.forEach(t),Ywt.forEach(t),L0r=i(BGe),SFe=n(BGe,"SPAN",{});var Zwt=s(SFe);x0r=r(Zwt,"TFAutoModelForQuestionAnswering"),Zwt.forEach(t),BGe.forEach(t),xje=i(f),ir=n(f,"DIV",{class:!0});var Nl=s(ir);T(f9.$$.fragment,Nl),$0r=i(Nl),Cc=n(Nl,"P",{});var Iee=s(Cc);k0r=r(Iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cJ=n(Iee,"A",{href:!0});var e0t=s(cJ);S0r=r(e0t,"from_pretrained()"),e0t.forEach(t),R0r=r(Iee," class method or the "),fJ=n(Iee,"A",{href:!0});var o0t=s(fJ);P0r=r(o0t,"from_config()"),o0t.forEach(t),B0r=r(Iee,` class
method.`),Iee.forEach(t),I0r=i(Nl),m9=n(Nl,"P",{});var IGe=s(m9);q0r=r(IGe,"This class cannot be instantiated directly using "),RFe=n(IGe,"CODE",{});var r0t=s(RFe);N0r=r(r0t,"__init__()"),r0t.forEach(t),j0r=r(IGe," (throws an error)."),IGe.forEach(t),D0r=i(Nl),Nt=n(Nl,"DIV",{class:!0});var Q6=s(Nt);T(g9.$$.fragment,Q6),G0r=i(Q6),PFe=n(Q6,"P",{});var t0t=s(PFe);O0r=r(t0t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),t0t.forEach(t),V0r=i(Q6),wc=n(Q6,"P",{});var qee=s(wc);X0r=r(qee,`Note:
Loading a model from its configuration file does `),BFe=n(qee,"STRONG",{});var a0t=s(BFe);z0r=r(a0t,"not"),a0t.forEach(t),W0r=r(qee,` load the model weights. It only affects the
model\u2019s configuration. Use `),mJ=n(qee,"A",{href:!0});var n0t=s(mJ);Q0r=r(n0t,"from_pretrained()"),n0t.forEach(t),H0r=r(qee," to load the model weights."),qee.forEach(t),U0r=i(Q6),T(YE.$$.fragment,Q6),Q6.forEach(t),J0r=i(Nl),Ir=n(Nl,"DIV",{class:!0});var jl=s(Ir);T(h9.$$.fragment,jl),Y0r=i(jl),IFe=n(jl,"P",{});var s0t=s(IFe);K0r=r(s0t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),s0t.forEach(t),Z0r=i(jl),fn=n(jl,"P",{});var H6=s(fn);e6r=r(H6,"The model class to instantiate is selected based on the "),qFe=n(H6,"CODE",{});var l0t=s(qFe);o6r=r(l0t,"model_type"),l0t.forEach(t),r6r=r(H6,` property of the config object (either
passed as an argument or loaded from `),NFe=n(H6,"CODE",{});var i0t=s(NFe);t6r=r(i0t,"pretrained_model_name_or_path"),i0t.forEach(t),a6r=r(H6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jFe=n(H6,"CODE",{});var d0t=s(jFe);n6r=r(d0t,"pretrained_model_name_or_path"),d0t.forEach(t),s6r=r(H6,":"),H6.forEach(t),l6r=i(jl),ce=n(jl,"UL",{});var ge=s(ce);KE=n(ge,"LI",{});var IBe=s(KE);DFe=n(IBe,"STRONG",{});var c0t=s(DFe);i6r=r(c0t,"albert"),c0t.forEach(t),d6r=r(IBe," \u2014 "),gJ=n(IBe,"A",{href:!0});var f0t=s(gJ);c6r=r(f0t,"TFAlbertForQuestionAnswering"),f0t.forEach(t),f6r=r(IBe," (ALBERT model)"),IBe.forEach(t),m6r=i(ge),ZE=n(ge,"LI",{});var qBe=s(ZE);GFe=n(qBe,"STRONG",{});var m0t=s(GFe);g6r=r(m0t,"bert"),m0t.forEach(t),h6r=r(qBe," \u2014 "),hJ=n(qBe,"A",{href:!0});var g0t=s(hJ);p6r=r(g0t,"TFBertForQuestionAnswering"),g0t.forEach(t),u6r=r(qBe," (BERT model)"),qBe.forEach(t),_6r=i(ge),eC=n(ge,"LI",{});var NBe=s(eC);OFe=n(NBe,"STRONG",{});var h0t=s(OFe);b6r=r(h0t,"camembert"),h0t.forEach(t),v6r=r(NBe," \u2014 "),pJ=n(NBe,"A",{href:!0});var p0t=s(pJ);F6r=r(p0t,"TFCamembertForQuestionAnswering"),p0t.forEach(t),T6r=r(NBe," (CamemBERT model)"),NBe.forEach(t),M6r=i(ge),oC=n(ge,"LI",{});var jBe=s(oC);VFe=n(jBe,"STRONG",{});var u0t=s(VFe);E6r=r(u0t,"convbert"),u0t.forEach(t),C6r=r(jBe," \u2014 "),uJ=n(jBe,"A",{href:!0});var _0t=s(uJ);w6r=r(_0t,"TFConvBertForQuestionAnswering"),_0t.forEach(t),A6r=r(jBe," (ConvBERT model)"),jBe.forEach(t),y6r=i(ge),rC=n(ge,"LI",{});var DBe=s(rC);XFe=n(DBe,"STRONG",{});var b0t=s(XFe);L6r=r(b0t,"deberta"),b0t.forEach(t),x6r=r(DBe," \u2014 "),_J=n(DBe,"A",{href:!0});var v0t=s(_J);$6r=r(v0t,"TFDebertaForQuestionAnswering"),v0t.forEach(t),k6r=r(DBe," (DeBERTa model)"),DBe.forEach(t),S6r=i(ge),tC=n(ge,"LI",{});var GBe=s(tC);zFe=n(GBe,"STRONG",{});var F0t=s(zFe);R6r=r(F0t,"deberta-v2"),F0t.forEach(t),P6r=r(GBe," \u2014 "),bJ=n(GBe,"A",{href:!0});var T0t=s(bJ);B6r=r(T0t,"TFDebertaV2ForQuestionAnswering"),T0t.forEach(t),I6r=r(GBe," (DeBERTa-v2 model)"),GBe.forEach(t),q6r=i(ge),aC=n(ge,"LI",{});var OBe=s(aC);WFe=n(OBe,"STRONG",{});var M0t=s(WFe);N6r=r(M0t,"distilbert"),M0t.forEach(t),j6r=r(OBe," \u2014 "),vJ=n(OBe,"A",{href:!0});var E0t=s(vJ);D6r=r(E0t,"TFDistilBertForQuestionAnswering"),E0t.forEach(t),G6r=r(OBe," (DistilBERT model)"),OBe.forEach(t),O6r=i(ge),nC=n(ge,"LI",{});var VBe=s(nC);QFe=n(VBe,"STRONG",{});var C0t=s(QFe);V6r=r(C0t,"electra"),C0t.forEach(t),X6r=r(VBe," \u2014 "),FJ=n(VBe,"A",{href:!0});var w0t=s(FJ);z6r=r(w0t,"TFElectraForQuestionAnswering"),w0t.forEach(t),W6r=r(VBe," (ELECTRA model)"),VBe.forEach(t),Q6r=i(ge),sC=n(ge,"LI",{});var XBe=s(sC);HFe=n(XBe,"STRONG",{});var A0t=s(HFe);H6r=r(A0t,"flaubert"),A0t.forEach(t),U6r=r(XBe," \u2014 "),TJ=n(XBe,"A",{href:!0});var y0t=s(TJ);J6r=r(y0t,"TFFlaubertForQuestionAnsweringSimple"),y0t.forEach(t),Y6r=r(XBe," (FlauBERT model)"),XBe.forEach(t),K6r=i(ge),lC=n(ge,"LI",{});var zBe=s(lC);UFe=n(zBe,"STRONG",{});var L0t=s(UFe);Z6r=r(L0t,"funnel"),L0t.forEach(t),eAr=r(zBe," \u2014 "),MJ=n(zBe,"A",{href:!0});var x0t=s(MJ);oAr=r(x0t,"TFFunnelForQuestionAnswering"),x0t.forEach(t),rAr=r(zBe," (Funnel Transformer model)"),zBe.forEach(t),tAr=i(ge),iC=n(ge,"LI",{});var WBe=s(iC);JFe=n(WBe,"STRONG",{});var $0t=s(JFe);aAr=r($0t,"gptj"),$0t.forEach(t),nAr=r(WBe," \u2014 "),EJ=n(WBe,"A",{href:!0});var k0t=s(EJ);sAr=r(k0t,"TFGPTJForQuestionAnswering"),k0t.forEach(t),lAr=r(WBe," (GPT-J model)"),WBe.forEach(t),iAr=i(ge),dC=n(ge,"LI",{});var QBe=s(dC);YFe=n(QBe,"STRONG",{});var S0t=s(YFe);dAr=r(S0t,"longformer"),S0t.forEach(t),cAr=r(QBe," \u2014 "),CJ=n(QBe,"A",{href:!0});var R0t=s(CJ);fAr=r(R0t,"TFLongformerForQuestionAnswering"),R0t.forEach(t),mAr=r(QBe," (Longformer model)"),QBe.forEach(t),gAr=i(ge),cC=n(ge,"LI",{});var HBe=s(cC);KFe=n(HBe,"STRONG",{});var P0t=s(KFe);hAr=r(P0t,"mobilebert"),P0t.forEach(t),pAr=r(HBe," \u2014 "),wJ=n(HBe,"A",{href:!0});var B0t=s(wJ);uAr=r(B0t,"TFMobileBertForQuestionAnswering"),B0t.forEach(t),_Ar=r(HBe," (MobileBERT model)"),HBe.forEach(t),bAr=i(ge),fC=n(ge,"LI",{});var UBe=s(fC);ZFe=n(UBe,"STRONG",{});var I0t=s(ZFe);vAr=r(I0t,"mpnet"),I0t.forEach(t),FAr=r(UBe," \u2014 "),AJ=n(UBe,"A",{href:!0});var q0t=s(AJ);TAr=r(q0t,"TFMPNetForQuestionAnswering"),q0t.forEach(t),MAr=r(UBe," (MPNet model)"),UBe.forEach(t),EAr=i(ge),mC=n(ge,"LI",{});var JBe=s(mC);eTe=n(JBe,"STRONG",{});var N0t=s(eTe);CAr=r(N0t,"rembert"),N0t.forEach(t),wAr=r(JBe," \u2014 "),yJ=n(JBe,"A",{href:!0});var j0t=s(yJ);AAr=r(j0t,"TFRemBertForQuestionAnswering"),j0t.forEach(t),yAr=r(JBe," (RemBERT model)"),JBe.forEach(t),LAr=i(ge),gC=n(ge,"LI",{});var YBe=s(gC);oTe=n(YBe,"STRONG",{});var D0t=s(oTe);xAr=r(D0t,"roberta"),D0t.forEach(t),$Ar=r(YBe," \u2014 "),LJ=n(YBe,"A",{href:!0});var G0t=s(LJ);kAr=r(G0t,"TFRobertaForQuestionAnswering"),G0t.forEach(t),SAr=r(YBe," (RoBERTa model)"),YBe.forEach(t),RAr=i(ge),hC=n(ge,"LI",{});var KBe=s(hC);rTe=n(KBe,"STRONG",{});var O0t=s(rTe);PAr=r(O0t,"roformer"),O0t.forEach(t),BAr=r(KBe," \u2014 "),xJ=n(KBe,"A",{href:!0});var V0t=s(xJ);IAr=r(V0t,"TFRoFormerForQuestionAnswering"),V0t.forEach(t),qAr=r(KBe," (RoFormer model)"),KBe.forEach(t),NAr=i(ge),pC=n(ge,"LI",{});var ZBe=s(pC);tTe=n(ZBe,"STRONG",{});var X0t=s(tTe);jAr=r(X0t,"xlm"),X0t.forEach(t),DAr=r(ZBe," \u2014 "),$J=n(ZBe,"A",{href:!0});var z0t=s($J);GAr=r(z0t,"TFXLMForQuestionAnsweringSimple"),z0t.forEach(t),OAr=r(ZBe," (XLM model)"),ZBe.forEach(t),VAr=i(ge),uC=n(ge,"LI",{});var eIe=s(uC);aTe=n(eIe,"STRONG",{});var W0t=s(aTe);XAr=r(W0t,"xlm-roberta"),W0t.forEach(t),zAr=r(eIe," \u2014 "),kJ=n(eIe,"A",{href:!0});var Q0t=s(kJ);WAr=r(Q0t,"TFXLMRobertaForQuestionAnswering"),Q0t.forEach(t),QAr=r(eIe," (XLM-RoBERTa model)"),eIe.forEach(t),HAr=i(ge),_C=n(ge,"LI",{});var oIe=s(_C);nTe=n(oIe,"STRONG",{});var H0t=s(nTe);UAr=r(H0t,"xlnet"),H0t.forEach(t),JAr=r(oIe," \u2014 "),SJ=n(oIe,"A",{href:!0});var U0t=s(SJ);YAr=r(U0t,"TFXLNetForQuestionAnsweringSimple"),U0t.forEach(t),KAr=r(oIe," (XLNet model)"),oIe.forEach(t),ge.forEach(t),ZAr=i(jl),T(bC.$$.fragment,jl),jl.forEach(t),Nl.forEach(t),$je=i(f),Ac=n(f,"H2",{class:!0});var qGe=s(Ac);vC=n(qGe,"A",{id:!0,class:!0,href:!0});var J0t=s(vC);sTe=n(J0t,"SPAN",{});var Y0t=s(sTe);T(p9.$$.fragment,Y0t),Y0t.forEach(t),J0t.forEach(t),eyr=i(qGe),lTe=n(qGe,"SPAN",{});var K0t=s(lTe);oyr=r(K0t,"TFAutoModelForVision2Seq"),K0t.forEach(t),qGe.forEach(t),kje=i(f),dr=n(f,"DIV",{class:!0});var Dl=s(dr);T(u9.$$.fragment,Dl),ryr=i(Dl),yc=n(Dl,"P",{});var Nee=s(yc);tyr=r(Nee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),RJ=n(Nee,"A",{href:!0});var Z0t=s(RJ);ayr=r(Z0t,"from_pretrained()"),Z0t.forEach(t),nyr=r(Nee," class method or the "),PJ=n(Nee,"A",{href:!0});var e6t=s(PJ);syr=r(e6t,"from_config()"),e6t.forEach(t),lyr=r(Nee,` class
method.`),Nee.forEach(t),iyr=i(Dl),_9=n(Dl,"P",{});var NGe=s(_9);dyr=r(NGe,"This class cannot be instantiated directly using "),iTe=n(NGe,"CODE",{});var o6t=s(iTe);cyr=r(o6t,"__init__()"),o6t.forEach(t),fyr=r(NGe," (throws an error)."),NGe.forEach(t),myr=i(Dl),jt=n(Dl,"DIV",{class:!0});var U6=s(jt);T(b9.$$.fragment,U6),gyr=i(U6),dTe=n(U6,"P",{});var r6t=s(dTe);hyr=r(r6t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),r6t.forEach(t),pyr=i(U6),Lc=n(U6,"P",{});var jee=s(Lc);uyr=r(jee,`Note:
Loading a model from its configuration file does `),cTe=n(jee,"STRONG",{});var t6t=s(cTe);_yr=r(t6t,"not"),t6t.forEach(t),byr=r(jee,` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=n(jee,"A",{href:!0});var a6t=s(BJ);vyr=r(a6t,"from_pretrained()"),a6t.forEach(t),Fyr=r(jee," to load the model weights."),jee.forEach(t),Tyr=i(U6),T(FC.$$.fragment,U6),U6.forEach(t),Myr=i(Dl),qr=n(Dl,"DIV",{class:!0});var Gl=s(qr);T(v9.$$.fragment,Gl),Eyr=i(Gl),fTe=n(Gl,"P",{});var n6t=s(fTe);Cyr=r(n6t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),n6t.forEach(t),wyr=i(Gl),mn=n(Gl,"P",{});var J6=s(mn);Ayr=r(J6,"The model class to instantiate is selected based on the "),mTe=n(J6,"CODE",{});var s6t=s(mTe);yyr=r(s6t,"model_type"),s6t.forEach(t),Lyr=r(J6,` property of the config object (either
passed as an argument or loaded from `),gTe=n(J6,"CODE",{});var l6t=s(gTe);xyr=r(l6t,"pretrained_model_name_or_path"),l6t.forEach(t),$yr=r(J6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hTe=n(J6,"CODE",{});var i6t=s(hTe);kyr=r(i6t,"pretrained_model_name_or_path"),i6t.forEach(t),Syr=r(J6,":"),J6.forEach(t),Ryr=i(Gl),pTe=n(Gl,"UL",{});var d6t=s(pTe);TC=n(d6t,"LI",{});var rIe=s(TC);uTe=n(rIe,"STRONG",{});var c6t=s(uTe);Pyr=r(c6t,"vision-encoder-decoder"),c6t.forEach(t),Byr=r(rIe," \u2014 "),IJ=n(rIe,"A",{href:!0});var f6t=s(IJ);Iyr=r(f6t,"TFVisionEncoderDecoderModel"),f6t.forEach(t),qyr=r(rIe," (Vision Encoder decoder model)"),rIe.forEach(t),d6t.forEach(t),Nyr=i(Gl),T(MC.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),Sje=i(f),xc=n(f,"H2",{class:!0});var jGe=s(xc);EC=n(jGe,"A",{id:!0,class:!0,href:!0});var m6t=s(EC);_Te=n(m6t,"SPAN",{});var g6t=s(_Te);T(F9.$$.fragment,g6t),g6t.forEach(t),m6t.forEach(t),jyr=i(jGe),bTe=n(jGe,"SPAN",{});var h6t=s(bTe);Dyr=r(h6t,"TFAutoModelForSpeechSeq2Seq"),h6t.forEach(t),jGe.forEach(t),Rje=i(f),cr=n(f,"DIV",{class:!0});var Ol=s(cr);T(T9.$$.fragment,Ol),Gyr=i(Ol),$c=n(Ol,"P",{});var Dee=s($c);Oyr=r(Dee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),qJ=n(Dee,"A",{href:!0});var p6t=s(qJ);Vyr=r(p6t,"from_pretrained()"),p6t.forEach(t),Xyr=r(Dee," class method or the "),NJ=n(Dee,"A",{href:!0});var u6t=s(NJ);zyr=r(u6t,"from_config()"),u6t.forEach(t),Wyr=r(Dee,` class
method.`),Dee.forEach(t),Qyr=i(Ol),M9=n(Ol,"P",{});var DGe=s(M9);Hyr=r(DGe,"This class cannot be instantiated directly using "),vTe=n(DGe,"CODE",{});var _6t=s(vTe);Uyr=r(_6t,"__init__()"),_6t.forEach(t),Jyr=r(DGe," (throws an error)."),DGe.forEach(t),Yyr=i(Ol),Dt=n(Ol,"DIV",{class:!0});var Y6=s(Dt);T(E9.$$.fragment,Y6),Kyr=i(Y6),FTe=n(Y6,"P",{});var b6t=s(FTe);Zyr=r(b6t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),b6t.forEach(t),eLr=i(Y6),kc=n(Y6,"P",{});var Gee=s(kc);oLr=r(Gee,`Note:
Loading a model from its configuration file does `),TTe=n(Gee,"STRONG",{});var v6t=s(TTe);rLr=r(v6t,"not"),v6t.forEach(t),tLr=r(Gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),jJ=n(Gee,"A",{href:!0});var F6t=s(jJ);aLr=r(F6t,"from_pretrained()"),F6t.forEach(t),nLr=r(Gee," to load the model weights."),Gee.forEach(t),sLr=i(Y6),T(CC.$$.fragment,Y6),Y6.forEach(t),lLr=i(Ol),Nr=n(Ol,"DIV",{class:!0});var Vl=s(Nr);T(C9.$$.fragment,Vl),iLr=i(Vl),MTe=n(Vl,"P",{});var T6t=s(MTe);dLr=r(T6t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),T6t.forEach(t),cLr=i(Vl),gn=n(Vl,"P",{});var K6=s(gn);fLr=r(K6,"The model class to instantiate is selected based on the "),ETe=n(K6,"CODE",{});var M6t=s(ETe);mLr=r(M6t,"model_type"),M6t.forEach(t),gLr=r(K6,` property of the config object (either
passed as an argument or loaded from `),CTe=n(K6,"CODE",{});var E6t=s(CTe);hLr=r(E6t,"pretrained_model_name_or_path"),E6t.forEach(t),pLr=r(K6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wTe=n(K6,"CODE",{});var C6t=s(wTe);uLr=r(C6t,"pretrained_model_name_or_path"),C6t.forEach(t),_Lr=r(K6,":"),K6.forEach(t),bLr=i(Vl),ATe=n(Vl,"UL",{});var w6t=s(ATe);wC=n(w6t,"LI",{});var tIe=s(wC);yTe=n(tIe,"STRONG",{});var A6t=s(yTe);vLr=r(A6t,"speech_to_text"),A6t.forEach(t),FLr=r(tIe," \u2014 "),DJ=n(tIe,"A",{href:!0});var y6t=s(DJ);TLr=r(y6t,"TFSpeech2TextForConditionalGeneration"),y6t.forEach(t),MLr=r(tIe," (Speech2Text model)"),tIe.forEach(t),w6t.forEach(t),ELr=i(Vl),T(AC.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),Pje=i(f),Sc=n(f,"H2",{class:!0});var GGe=s(Sc);yC=n(GGe,"A",{id:!0,class:!0,href:!0});var L6t=s(yC);LTe=n(L6t,"SPAN",{});var x6t=s(LTe);T(w9.$$.fragment,x6t),x6t.forEach(t),L6t.forEach(t),CLr=i(GGe),xTe=n(GGe,"SPAN",{});var $6t=s(xTe);wLr=r($6t,"FlaxAutoModel"),$6t.forEach(t),GGe.forEach(t),Bje=i(f),fr=n(f,"DIV",{class:!0});var Xl=s(fr);T(A9.$$.fragment,Xl),ALr=i(Xl),Rc=n(Xl,"P",{});var Oee=s(Rc);yLr=r(Oee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),GJ=n(Oee,"A",{href:!0});var k6t=s(GJ);LLr=r(k6t,"from_pretrained()"),k6t.forEach(t),xLr=r(Oee," class method or the "),OJ=n(Oee,"A",{href:!0});var S6t=s(OJ);$Lr=r(S6t,"from_config()"),S6t.forEach(t),kLr=r(Oee,` class
method.`),Oee.forEach(t),SLr=i(Xl),y9=n(Xl,"P",{});var OGe=s(y9);RLr=r(OGe,"This class cannot be instantiated directly using "),$Te=n(OGe,"CODE",{});var R6t=s($Te);PLr=r(R6t,"__init__()"),R6t.forEach(t),BLr=r(OGe," (throws an error)."),OGe.forEach(t),ILr=i(Xl),Gt=n(Xl,"DIV",{class:!0});var Z6=s(Gt);T(L9.$$.fragment,Z6),qLr=i(Z6),kTe=n(Z6,"P",{});var P6t=s(kTe);NLr=r(P6t,"Instantiates one of the base model classes of the library from a configuration."),P6t.forEach(t),jLr=i(Z6),Pc=n(Z6,"P",{});var Vee=s(Pc);DLr=r(Vee,`Note:
Loading a model from its configuration file does `),STe=n(Vee,"STRONG",{});var B6t=s(STe);GLr=r(B6t,"not"),B6t.forEach(t),OLr=r(Vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VJ=n(Vee,"A",{href:!0});var I6t=s(VJ);VLr=r(I6t,"from_pretrained()"),I6t.forEach(t),XLr=r(Vee," to load the model weights."),Vee.forEach(t),zLr=i(Z6),T(LC.$$.fragment,Z6),Z6.forEach(t),WLr=i(Xl),jr=n(Xl,"DIV",{class:!0});var zl=s(jr);T(x9.$$.fragment,zl),QLr=i(zl),RTe=n(zl,"P",{});var q6t=s(RTe);HLr=r(q6t,"Instantiate one of the base model classes of the library from a pretrained model."),q6t.forEach(t),ULr=i(zl),hn=n(zl,"P",{});var eA=s(hn);JLr=r(eA,"The model class to instantiate is selected based on the "),PTe=n(eA,"CODE",{});var N6t=s(PTe);YLr=r(N6t,"model_type"),N6t.forEach(t),KLr=r(eA,` property of the config object (either
passed as an argument or loaded from `),BTe=n(eA,"CODE",{});var j6t=s(BTe);ZLr=r(j6t,"pretrained_model_name_or_path"),j6t.forEach(t),e8r=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ITe=n(eA,"CODE",{});var D6t=s(ITe);o8r=r(D6t,"pretrained_model_name_or_path"),D6t.forEach(t),r8r=r(eA,":"),eA.forEach(t),t8r=i(zl),te=n(zl,"UL",{});var ne=s(te);xC=n(ne,"LI",{});var aIe=s(xC);qTe=n(aIe,"STRONG",{});var G6t=s(qTe);a8r=r(G6t,"albert"),G6t.forEach(t),n8r=r(aIe," \u2014 "),XJ=n(aIe,"A",{href:!0});var O6t=s(XJ);s8r=r(O6t,"FlaxAlbertModel"),O6t.forEach(t),l8r=r(aIe," (ALBERT model)"),aIe.forEach(t),i8r=i(ne),$C=n(ne,"LI",{});var nIe=s($C);NTe=n(nIe,"STRONG",{});var V6t=s(NTe);d8r=r(V6t,"bart"),V6t.forEach(t),c8r=r(nIe," \u2014 "),zJ=n(nIe,"A",{href:!0});var X6t=s(zJ);f8r=r(X6t,"FlaxBartModel"),X6t.forEach(t),m8r=r(nIe," (BART model)"),nIe.forEach(t),g8r=i(ne),kC=n(ne,"LI",{});var sIe=s(kC);jTe=n(sIe,"STRONG",{});var z6t=s(jTe);h8r=r(z6t,"beit"),z6t.forEach(t),p8r=r(sIe," \u2014 "),WJ=n(sIe,"A",{href:!0});var W6t=s(WJ);u8r=r(W6t,"FlaxBeitModel"),W6t.forEach(t),_8r=r(sIe," (BEiT model)"),sIe.forEach(t),b8r=i(ne),SC=n(ne,"LI",{});var lIe=s(SC);DTe=n(lIe,"STRONG",{});var Q6t=s(DTe);v8r=r(Q6t,"bert"),Q6t.forEach(t),F8r=r(lIe," \u2014 "),QJ=n(lIe,"A",{href:!0});var H6t=s(QJ);T8r=r(H6t,"FlaxBertModel"),H6t.forEach(t),M8r=r(lIe," (BERT model)"),lIe.forEach(t),E8r=i(ne),RC=n(ne,"LI",{});var iIe=s(RC);GTe=n(iIe,"STRONG",{});var U6t=s(GTe);C8r=r(U6t,"big_bird"),U6t.forEach(t),w8r=r(iIe," \u2014 "),HJ=n(iIe,"A",{href:!0});var J6t=s(HJ);A8r=r(J6t,"FlaxBigBirdModel"),J6t.forEach(t),y8r=r(iIe," (BigBird model)"),iIe.forEach(t),L8r=i(ne),PC=n(ne,"LI",{});var dIe=s(PC);OTe=n(dIe,"STRONG",{});var Y6t=s(OTe);x8r=r(Y6t,"blenderbot"),Y6t.forEach(t),$8r=r(dIe," \u2014 "),UJ=n(dIe,"A",{href:!0});var K6t=s(UJ);k8r=r(K6t,"FlaxBlenderbotModel"),K6t.forEach(t),S8r=r(dIe," (Blenderbot model)"),dIe.forEach(t),R8r=i(ne),BC=n(ne,"LI",{});var cIe=s(BC);VTe=n(cIe,"STRONG",{});var Z6t=s(VTe);P8r=r(Z6t,"blenderbot-small"),Z6t.forEach(t),B8r=r(cIe," \u2014 "),JJ=n(cIe,"A",{href:!0});var eAt=s(JJ);I8r=r(eAt,"FlaxBlenderbotSmallModel"),eAt.forEach(t),q8r=r(cIe," (BlenderbotSmall model)"),cIe.forEach(t),N8r=i(ne),IC=n(ne,"LI",{});var fIe=s(IC);XTe=n(fIe,"STRONG",{});var oAt=s(XTe);j8r=r(oAt,"clip"),oAt.forEach(t),D8r=r(fIe," \u2014 "),YJ=n(fIe,"A",{href:!0});var rAt=s(YJ);G8r=r(rAt,"FlaxCLIPModel"),rAt.forEach(t),O8r=r(fIe," (CLIP model)"),fIe.forEach(t),V8r=i(ne),qC=n(ne,"LI",{});var mIe=s(qC);zTe=n(mIe,"STRONG",{});var tAt=s(zTe);X8r=r(tAt,"distilbert"),tAt.forEach(t),z8r=r(mIe," \u2014 "),KJ=n(mIe,"A",{href:!0});var aAt=s(KJ);W8r=r(aAt,"FlaxDistilBertModel"),aAt.forEach(t),Q8r=r(mIe," (DistilBERT model)"),mIe.forEach(t),H8r=i(ne),NC=n(ne,"LI",{});var gIe=s(NC);WTe=n(gIe,"STRONG",{});var nAt=s(WTe);U8r=r(nAt,"electra"),nAt.forEach(t),J8r=r(gIe," \u2014 "),ZJ=n(gIe,"A",{href:!0});var sAt=s(ZJ);Y8r=r(sAt,"FlaxElectraModel"),sAt.forEach(t),K8r=r(gIe," (ELECTRA model)"),gIe.forEach(t),Z8r=i(ne),jC=n(ne,"LI",{});var hIe=s(jC);QTe=n(hIe,"STRONG",{});var lAt=s(QTe);e9r=r(lAt,"gpt2"),lAt.forEach(t),o9r=r(hIe," \u2014 "),eY=n(hIe,"A",{href:!0});var iAt=s(eY);r9r=r(iAt,"FlaxGPT2Model"),iAt.forEach(t),t9r=r(hIe," (OpenAI GPT-2 model)"),hIe.forEach(t),a9r=i(ne),DC=n(ne,"LI",{});var pIe=s(DC);HTe=n(pIe,"STRONG",{});var dAt=s(HTe);n9r=r(dAt,"gpt_neo"),dAt.forEach(t),s9r=r(pIe," \u2014 "),oY=n(pIe,"A",{href:!0});var cAt=s(oY);l9r=r(cAt,"FlaxGPTNeoModel"),cAt.forEach(t),i9r=r(pIe," (GPT Neo model)"),pIe.forEach(t),d9r=i(ne),GC=n(ne,"LI",{});var uIe=s(GC);UTe=n(uIe,"STRONG",{});var fAt=s(UTe);c9r=r(fAt,"gptj"),fAt.forEach(t),f9r=r(uIe," \u2014 "),rY=n(uIe,"A",{href:!0});var mAt=s(rY);m9r=r(mAt,"FlaxGPTJModel"),mAt.forEach(t),g9r=r(uIe," (GPT-J model)"),uIe.forEach(t),h9r=i(ne),OC=n(ne,"LI",{});var _Ie=s(OC);JTe=n(_Ie,"STRONG",{});var gAt=s(JTe);p9r=r(gAt,"marian"),gAt.forEach(t),u9r=r(_Ie," \u2014 "),tY=n(_Ie,"A",{href:!0});var hAt=s(tY);_9r=r(hAt,"FlaxMarianModel"),hAt.forEach(t),b9r=r(_Ie," (Marian model)"),_Ie.forEach(t),v9r=i(ne),VC=n(ne,"LI",{});var bIe=s(VC);YTe=n(bIe,"STRONG",{});var pAt=s(YTe);F9r=r(pAt,"mbart"),pAt.forEach(t),T9r=r(bIe," \u2014 "),aY=n(bIe,"A",{href:!0});var uAt=s(aY);M9r=r(uAt,"FlaxMBartModel"),uAt.forEach(t),E9r=r(bIe," (mBART model)"),bIe.forEach(t),C9r=i(ne),XC=n(ne,"LI",{});var vIe=s(XC);KTe=n(vIe,"STRONG",{});var _At=s(KTe);w9r=r(_At,"mt5"),_At.forEach(t),A9r=r(vIe," \u2014 "),nY=n(vIe,"A",{href:!0});var bAt=s(nY);y9r=r(bAt,"FlaxMT5Model"),bAt.forEach(t),L9r=r(vIe," (mT5 model)"),vIe.forEach(t),x9r=i(ne),zC=n(ne,"LI",{});var FIe=s(zC);ZTe=n(FIe,"STRONG",{});var vAt=s(ZTe);$9r=r(vAt,"pegasus"),vAt.forEach(t),k9r=r(FIe," \u2014 "),sY=n(FIe,"A",{href:!0});var FAt=s(sY);S9r=r(FAt,"FlaxPegasusModel"),FAt.forEach(t),R9r=r(FIe," (Pegasus model)"),FIe.forEach(t),P9r=i(ne),WC=n(ne,"LI",{});var TIe=s(WC);e7e=n(TIe,"STRONG",{});var TAt=s(e7e);B9r=r(TAt,"roberta"),TAt.forEach(t),I9r=r(TIe," \u2014 "),lY=n(TIe,"A",{href:!0});var MAt=s(lY);q9r=r(MAt,"FlaxRobertaModel"),MAt.forEach(t),N9r=r(TIe," (RoBERTa model)"),TIe.forEach(t),j9r=i(ne),QC=n(ne,"LI",{});var MIe=s(QC);o7e=n(MIe,"STRONG",{});var EAt=s(o7e);D9r=r(EAt,"roformer"),EAt.forEach(t),G9r=r(MIe," \u2014 "),iY=n(MIe,"A",{href:!0});var CAt=s(iY);O9r=r(CAt,"FlaxRoFormerModel"),CAt.forEach(t),V9r=r(MIe," (RoFormer model)"),MIe.forEach(t),X9r=i(ne),HC=n(ne,"LI",{});var EIe=s(HC);r7e=n(EIe,"STRONG",{});var wAt=s(r7e);z9r=r(wAt,"t5"),wAt.forEach(t),W9r=r(EIe," \u2014 "),dY=n(EIe,"A",{href:!0});var AAt=s(dY);Q9r=r(AAt,"FlaxT5Model"),AAt.forEach(t),H9r=r(EIe," (T5 model)"),EIe.forEach(t),U9r=i(ne),UC=n(ne,"LI",{});var CIe=s(UC);t7e=n(CIe,"STRONG",{});var yAt=s(t7e);J9r=r(yAt,"vision-text-dual-encoder"),yAt.forEach(t),Y9r=r(CIe," \u2014 "),cY=n(CIe,"A",{href:!0});var LAt=s(cY);K9r=r(LAt,"FlaxVisionTextDualEncoderModel"),LAt.forEach(t),Z9r=r(CIe," (VisionTextDualEncoder model)"),CIe.forEach(t),exr=i(ne),JC=n(ne,"LI",{});var wIe=s(JC);a7e=n(wIe,"STRONG",{});var xAt=s(a7e);oxr=r(xAt,"vit"),xAt.forEach(t),rxr=r(wIe," \u2014 "),fY=n(wIe,"A",{href:!0});var $At=s(fY);txr=r($At,"FlaxViTModel"),$At.forEach(t),axr=r(wIe," (ViT model)"),wIe.forEach(t),nxr=i(ne),YC=n(ne,"LI",{});var AIe=s(YC);n7e=n(AIe,"STRONG",{});var kAt=s(n7e);sxr=r(kAt,"wav2vec2"),kAt.forEach(t),lxr=r(AIe," \u2014 "),mY=n(AIe,"A",{href:!0});var SAt=s(mY);ixr=r(SAt,"FlaxWav2Vec2Model"),SAt.forEach(t),dxr=r(AIe," (Wav2Vec2 model)"),AIe.forEach(t),cxr=i(ne),KC=n(ne,"LI",{});var yIe=s(KC);s7e=n(yIe,"STRONG",{});var RAt=s(s7e);fxr=r(RAt,"xglm"),RAt.forEach(t),mxr=r(yIe," \u2014 "),gY=n(yIe,"A",{href:!0});var PAt=s(gY);gxr=r(PAt,"FlaxXGLMModel"),PAt.forEach(t),hxr=r(yIe," (XGLM model)"),yIe.forEach(t),pxr=i(ne),ZC=n(ne,"LI",{});var LIe=s(ZC);l7e=n(LIe,"STRONG",{});var BAt=s(l7e);uxr=r(BAt,"xlm-roberta"),BAt.forEach(t),_xr=r(LIe," \u2014 "),hY=n(LIe,"A",{href:!0});var IAt=s(hY);bxr=r(IAt,"FlaxXLMRobertaModel"),IAt.forEach(t),vxr=r(LIe," (XLM-RoBERTa model)"),LIe.forEach(t),ne.forEach(t),Fxr=i(zl),T(e3.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),Ije=i(f),Bc=n(f,"H2",{class:!0});var VGe=s(Bc);o3=n(VGe,"A",{id:!0,class:!0,href:!0});var qAt=s(o3);i7e=n(qAt,"SPAN",{});var NAt=s(i7e);T($9.$$.fragment,NAt),NAt.forEach(t),qAt.forEach(t),Txr=i(VGe),d7e=n(VGe,"SPAN",{});var jAt=s(d7e);Mxr=r(jAt,"FlaxAutoModelForCausalLM"),jAt.forEach(t),VGe.forEach(t),qje=i(f),mr=n(f,"DIV",{class:!0});var Wl=s(mr);T(k9.$$.fragment,Wl),Exr=i(Wl),Ic=n(Wl,"P",{});var Xee=s(Ic);Cxr=r(Xee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),pY=n(Xee,"A",{href:!0});var DAt=s(pY);wxr=r(DAt,"from_pretrained()"),DAt.forEach(t),Axr=r(Xee," class method or the "),uY=n(Xee,"A",{href:!0});var GAt=s(uY);yxr=r(GAt,"from_config()"),GAt.forEach(t),Lxr=r(Xee,` class
method.`),Xee.forEach(t),xxr=i(Wl),S9=n(Wl,"P",{});var XGe=s(S9);$xr=r(XGe,"This class cannot be instantiated directly using "),c7e=n(XGe,"CODE",{});var OAt=s(c7e);kxr=r(OAt,"__init__()"),OAt.forEach(t),Sxr=r(XGe," (throws an error)."),XGe.forEach(t),Rxr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var oA=s(Ot);T(R9.$$.fragment,oA),Pxr=i(oA),f7e=n(oA,"P",{});var VAt=s(f7e);Bxr=r(VAt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),VAt.forEach(t),Ixr=i(oA),qc=n(oA,"P",{});var zee=s(qc);qxr=r(zee,`Note:
Loading a model from its configuration file does `),m7e=n(zee,"STRONG",{});var XAt=s(m7e);Nxr=r(XAt,"not"),XAt.forEach(t),jxr=r(zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Y=n(zee,"A",{href:!0});var zAt=s(_Y);Dxr=r(zAt,"from_pretrained()"),zAt.forEach(t),Gxr=r(zee," to load the model weights."),zee.forEach(t),Oxr=i(oA),T(r3.$$.fragment,oA),oA.forEach(t),Vxr=i(Wl),Dr=n(Wl,"DIV",{class:!0});var Ql=s(Dr);T(P9.$$.fragment,Ql),Xxr=i(Ql),g7e=n(Ql,"P",{});var WAt=s(g7e);zxr=r(WAt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),WAt.forEach(t),Wxr=i(Ql),pn=n(Ql,"P",{});var rA=s(pn);Qxr=r(rA,"The model class to instantiate is selected based on the "),h7e=n(rA,"CODE",{});var QAt=s(h7e);Hxr=r(QAt,"model_type"),QAt.forEach(t),Uxr=r(rA,` property of the config object (either
passed as an argument or loaded from `),p7e=n(rA,"CODE",{});var HAt=s(p7e);Jxr=r(HAt,"pretrained_model_name_or_path"),HAt.forEach(t),Yxr=r(rA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u7e=n(rA,"CODE",{});var UAt=s(u7e);Kxr=r(UAt,"pretrained_model_name_or_path"),UAt.forEach(t),Zxr=r(rA,":"),rA.forEach(t),e$r=i(Ql),Re=n(Ql,"UL",{});var Xe=s(Re);t3=n(Xe,"LI",{});var xIe=s(t3);_7e=n(xIe,"STRONG",{});var JAt=s(_7e);o$r=r(JAt,"bart"),JAt.forEach(t),r$r=r(xIe," \u2014 "),bY=n(xIe,"A",{href:!0});var YAt=s(bY);t$r=r(YAt,"FlaxBartForCausalLM"),YAt.forEach(t),a$r=r(xIe," (BART model)"),xIe.forEach(t),n$r=i(Xe),a3=n(Xe,"LI",{});var $Ie=s(a3);b7e=n($Ie,"STRONG",{});var KAt=s(b7e);s$r=r(KAt,"bert"),KAt.forEach(t),l$r=r($Ie," \u2014 "),vY=n($Ie,"A",{href:!0});var ZAt=s(vY);i$r=r(ZAt,"FlaxBertForCausalLM"),ZAt.forEach(t),d$r=r($Ie," (BERT model)"),$Ie.forEach(t),c$r=i(Xe),n3=n(Xe,"LI",{});var kIe=s(n3);v7e=n(kIe,"STRONG",{});var eyt=s(v7e);f$r=r(eyt,"big_bird"),eyt.forEach(t),m$r=r(kIe," \u2014 "),FY=n(kIe,"A",{href:!0});var oyt=s(FY);g$r=r(oyt,"FlaxBigBirdForCausalLM"),oyt.forEach(t),h$r=r(kIe," (BigBird model)"),kIe.forEach(t),p$r=i(Xe),s3=n(Xe,"LI",{});var SIe=s(s3);F7e=n(SIe,"STRONG",{});var ryt=s(F7e);u$r=r(ryt,"electra"),ryt.forEach(t),_$r=r(SIe," \u2014 "),TY=n(SIe,"A",{href:!0});var tyt=s(TY);b$r=r(tyt,"FlaxElectraForCausalLM"),tyt.forEach(t),v$r=r(SIe," (ELECTRA model)"),SIe.forEach(t),F$r=i(Xe),l3=n(Xe,"LI",{});var RIe=s(l3);T7e=n(RIe,"STRONG",{});var ayt=s(T7e);T$r=r(ayt,"gpt2"),ayt.forEach(t),M$r=r(RIe," \u2014 "),MY=n(RIe,"A",{href:!0});var nyt=s(MY);E$r=r(nyt,"FlaxGPT2LMHeadModel"),nyt.forEach(t),C$r=r(RIe," (OpenAI GPT-2 model)"),RIe.forEach(t),w$r=i(Xe),i3=n(Xe,"LI",{});var PIe=s(i3);M7e=n(PIe,"STRONG",{});var syt=s(M7e);A$r=r(syt,"gpt_neo"),syt.forEach(t),y$r=r(PIe," \u2014 "),EY=n(PIe,"A",{href:!0});var lyt=s(EY);L$r=r(lyt,"FlaxGPTNeoForCausalLM"),lyt.forEach(t),x$r=r(PIe," (GPT Neo model)"),PIe.forEach(t),$$r=i(Xe),d3=n(Xe,"LI",{});var BIe=s(d3);E7e=n(BIe,"STRONG",{});var iyt=s(E7e);k$r=r(iyt,"gptj"),iyt.forEach(t),S$r=r(BIe," \u2014 "),CY=n(BIe,"A",{href:!0});var dyt=s(CY);R$r=r(dyt,"FlaxGPTJForCausalLM"),dyt.forEach(t),P$r=r(BIe," (GPT-J model)"),BIe.forEach(t),B$r=i(Xe),c3=n(Xe,"LI",{});var IIe=s(c3);C7e=n(IIe,"STRONG",{});var cyt=s(C7e);I$r=r(cyt,"roberta"),cyt.forEach(t),q$r=r(IIe," \u2014 "),wY=n(IIe,"A",{href:!0});var fyt=s(wY);N$r=r(fyt,"FlaxRobertaForCausalLM"),fyt.forEach(t),j$r=r(IIe," (RoBERTa model)"),IIe.forEach(t),D$r=i(Xe),f3=n(Xe,"LI",{});var qIe=s(f3);w7e=n(qIe,"STRONG",{});var myt=s(w7e);G$r=r(myt,"xglm"),myt.forEach(t),O$r=r(qIe," \u2014 "),AY=n(qIe,"A",{href:!0});var gyt=s(AY);V$r=r(gyt,"FlaxXGLMForCausalLM"),gyt.forEach(t),X$r=r(qIe," (XGLM model)"),qIe.forEach(t),Xe.forEach(t),z$r=i(Ql),T(m3.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),Nje=i(f),Nc=n(f,"H2",{class:!0});var zGe=s(Nc);g3=n(zGe,"A",{id:!0,class:!0,href:!0});var hyt=s(g3);A7e=n(hyt,"SPAN",{});var pyt=s(A7e);T(B9.$$.fragment,pyt),pyt.forEach(t),hyt.forEach(t),W$r=i(zGe),y7e=n(zGe,"SPAN",{});var uyt=s(y7e);Q$r=r(uyt,"FlaxAutoModelForPreTraining"),uyt.forEach(t),zGe.forEach(t),jje=i(f),gr=n(f,"DIV",{class:!0});var Hl=s(gr);T(I9.$$.fragment,Hl),H$r=i(Hl),jc=n(Hl,"P",{});var Wee=s(jc);U$r=r(Wee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yY=n(Wee,"A",{href:!0});var _yt=s(yY);J$r=r(_yt,"from_pretrained()"),_yt.forEach(t),Y$r=r(Wee," class method or the "),LY=n(Wee,"A",{href:!0});var byt=s(LY);K$r=r(byt,"from_config()"),byt.forEach(t),Z$r=r(Wee,` class
method.`),Wee.forEach(t),ekr=i(Hl),q9=n(Hl,"P",{});var WGe=s(q9);okr=r(WGe,"This class cannot be instantiated directly using "),L7e=n(WGe,"CODE",{});var vyt=s(L7e);rkr=r(vyt,"__init__()"),vyt.forEach(t),tkr=r(WGe," (throws an error)."),WGe.forEach(t),akr=i(Hl),Vt=n(Hl,"DIV",{class:!0});var tA=s(Vt);T(N9.$$.fragment,tA),nkr=i(tA),x7e=n(tA,"P",{});var Fyt=s(x7e);skr=r(Fyt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Fyt.forEach(t),lkr=i(tA),Dc=n(tA,"P",{});var Qee=s(Dc);ikr=r(Qee,`Note:
Loading a model from its configuration file does `),$7e=n(Qee,"STRONG",{});var Tyt=s($7e);dkr=r(Tyt,"not"),Tyt.forEach(t),ckr=r(Qee,` load the model weights. It only affects the
model\u2019s configuration. Use `),xY=n(Qee,"A",{href:!0});var Myt=s(xY);fkr=r(Myt,"from_pretrained()"),Myt.forEach(t),mkr=r(Qee," to load the model weights."),Qee.forEach(t),gkr=i(tA),T(h3.$$.fragment,tA),tA.forEach(t),hkr=i(Hl),Gr=n(Hl,"DIV",{class:!0});var Ul=s(Gr);T(j9.$$.fragment,Ul),pkr=i(Ul),k7e=n(Ul,"P",{});var Eyt=s(k7e);ukr=r(Eyt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Eyt.forEach(t),_kr=i(Ul),un=n(Ul,"P",{});var aA=s(un);bkr=r(aA,"The model class to instantiate is selected based on the "),S7e=n(aA,"CODE",{});var Cyt=s(S7e);vkr=r(Cyt,"model_type"),Cyt.forEach(t),Fkr=r(aA,` property of the config object (either
passed as an argument or loaded from `),R7e=n(aA,"CODE",{});var wyt=s(R7e);Tkr=r(wyt,"pretrained_model_name_or_path"),wyt.forEach(t),Mkr=r(aA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P7e=n(aA,"CODE",{});var Ayt=s(P7e);Ekr=r(Ayt,"pretrained_model_name_or_path"),Ayt.forEach(t),Ckr=r(aA,":"),aA.forEach(t),wkr=i(Ul),Ee=n(Ul,"UL",{});var we=s(Ee);p3=n(we,"LI",{});var NIe=s(p3);B7e=n(NIe,"STRONG",{});var yyt=s(B7e);Akr=r(yyt,"albert"),yyt.forEach(t),ykr=r(NIe," \u2014 "),$Y=n(NIe,"A",{href:!0});var Lyt=s($Y);Lkr=r(Lyt,"FlaxAlbertForPreTraining"),Lyt.forEach(t),xkr=r(NIe," (ALBERT model)"),NIe.forEach(t),$kr=i(we),u3=n(we,"LI",{});var jIe=s(u3);I7e=n(jIe,"STRONG",{});var xyt=s(I7e);kkr=r(xyt,"bart"),xyt.forEach(t),Skr=r(jIe," \u2014 "),kY=n(jIe,"A",{href:!0});var $yt=s(kY);Rkr=r($yt,"FlaxBartForConditionalGeneration"),$yt.forEach(t),Pkr=r(jIe," (BART model)"),jIe.forEach(t),Bkr=i(we),_3=n(we,"LI",{});var DIe=s(_3);q7e=n(DIe,"STRONG",{});var kyt=s(q7e);Ikr=r(kyt,"bert"),kyt.forEach(t),qkr=r(DIe," \u2014 "),SY=n(DIe,"A",{href:!0});var Syt=s(SY);Nkr=r(Syt,"FlaxBertForPreTraining"),Syt.forEach(t),jkr=r(DIe," (BERT model)"),DIe.forEach(t),Dkr=i(we),b3=n(we,"LI",{});var GIe=s(b3);N7e=n(GIe,"STRONG",{});var Ryt=s(N7e);Gkr=r(Ryt,"big_bird"),Ryt.forEach(t),Okr=r(GIe," \u2014 "),RY=n(GIe,"A",{href:!0});var Pyt=s(RY);Vkr=r(Pyt,"FlaxBigBirdForPreTraining"),Pyt.forEach(t),Xkr=r(GIe," (BigBird model)"),GIe.forEach(t),zkr=i(we),v3=n(we,"LI",{});var OIe=s(v3);j7e=n(OIe,"STRONG",{});var Byt=s(j7e);Wkr=r(Byt,"electra"),Byt.forEach(t),Qkr=r(OIe," \u2014 "),PY=n(OIe,"A",{href:!0});var Iyt=s(PY);Hkr=r(Iyt,"FlaxElectraForPreTraining"),Iyt.forEach(t),Ukr=r(OIe," (ELECTRA model)"),OIe.forEach(t),Jkr=i(we),F3=n(we,"LI",{});var VIe=s(F3);D7e=n(VIe,"STRONG",{});var qyt=s(D7e);Ykr=r(qyt,"mbart"),qyt.forEach(t),Kkr=r(VIe," \u2014 "),BY=n(VIe,"A",{href:!0});var Nyt=s(BY);Zkr=r(Nyt,"FlaxMBartForConditionalGeneration"),Nyt.forEach(t),eSr=r(VIe," (mBART model)"),VIe.forEach(t),oSr=i(we),T3=n(we,"LI",{});var XIe=s(T3);G7e=n(XIe,"STRONG",{});var jyt=s(G7e);rSr=r(jyt,"mt5"),jyt.forEach(t),tSr=r(XIe," \u2014 "),IY=n(XIe,"A",{href:!0});var Dyt=s(IY);aSr=r(Dyt,"FlaxMT5ForConditionalGeneration"),Dyt.forEach(t),nSr=r(XIe," (mT5 model)"),XIe.forEach(t),sSr=i(we),M3=n(we,"LI",{});var zIe=s(M3);O7e=n(zIe,"STRONG",{});var Gyt=s(O7e);lSr=r(Gyt,"roberta"),Gyt.forEach(t),iSr=r(zIe," \u2014 "),qY=n(zIe,"A",{href:!0});var Oyt=s(qY);dSr=r(Oyt,"FlaxRobertaForMaskedLM"),Oyt.forEach(t),cSr=r(zIe," (RoBERTa model)"),zIe.forEach(t),fSr=i(we),E3=n(we,"LI",{});var WIe=s(E3);V7e=n(WIe,"STRONG",{});var Vyt=s(V7e);mSr=r(Vyt,"roformer"),Vyt.forEach(t),gSr=r(WIe," \u2014 "),NY=n(WIe,"A",{href:!0});var Xyt=s(NY);hSr=r(Xyt,"FlaxRoFormerForMaskedLM"),Xyt.forEach(t),pSr=r(WIe," (RoFormer model)"),WIe.forEach(t),uSr=i(we),C3=n(we,"LI",{});var QIe=s(C3);X7e=n(QIe,"STRONG",{});var zyt=s(X7e);_Sr=r(zyt,"t5"),zyt.forEach(t),bSr=r(QIe," \u2014 "),jY=n(QIe,"A",{href:!0});var Wyt=s(jY);vSr=r(Wyt,"FlaxT5ForConditionalGeneration"),Wyt.forEach(t),FSr=r(QIe," (T5 model)"),QIe.forEach(t),TSr=i(we),w3=n(we,"LI",{});var HIe=s(w3);z7e=n(HIe,"STRONG",{});var Qyt=s(z7e);MSr=r(Qyt,"wav2vec2"),Qyt.forEach(t),ESr=r(HIe," \u2014 "),DY=n(HIe,"A",{href:!0});var Hyt=s(DY);CSr=r(Hyt,"FlaxWav2Vec2ForPreTraining"),Hyt.forEach(t),wSr=r(HIe," (Wav2Vec2 model)"),HIe.forEach(t),ASr=i(we),A3=n(we,"LI",{});var UIe=s(A3);W7e=n(UIe,"STRONG",{});var Uyt=s(W7e);ySr=r(Uyt,"xlm-roberta"),Uyt.forEach(t),LSr=r(UIe," \u2014 "),GY=n(UIe,"A",{href:!0});var Jyt=s(GY);xSr=r(Jyt,"FlaxXLMRobertaForMaskedLM"),Jyt.forEach(t),$Sr=r(UIe," (XLM-RoBERTa model)"),UIe.forEach(t),we.forEach(t),kSr=i(Ul),T(y3.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),Dje=i(f),Gc=n(f,"H2",{class:!0});var QGe=s(Gc);L3=n(QGe,"A",{id:!0,class:!0,href:!0});var Yyt=s(L3);Q7e=n(Yyt,"SPAN",{});var Kyt=s(Q7e);T(D9.$$.fragment,Kyt),Kyt.forEach(t),Yyt.forEach(t),SSr=i(QGe),H7e=n(QGe,"SPAN",{});var Zyt=s(H7e);RSr=r(Zyt,"FlaxAutoModelForMaskedLM"),Zyt.forEach(t),QGe.forEach(t),Gje=i(f),hr=n(f,"DIV",{class:!0});var Jl=s(hr);T(G9.$$.fragment,Jl),PSr=i(Jl),Oc=n(Jl,"P",{});var Hee=s(Oc);BSr=r(Hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),OY=n(Hee,"A",{href:!0});var eLt=s(OY);ISr=r(eLt,"from_pretrained()"),eLt.forEach(t),qSr=r(Hee," class method or the "),VY=n(Hee,"A",{href:!0});var oLt=s(VY);NSr=r(oLt,"from_config()"),oLt.forEach(t),jSr=r(Hee,` class
method.`),Hee.forEach(t),DSr=i(Jl),O9=n(Jl,"P",{});var HGe=s(O9);GSr=r(HGe,"This class cannot be instantiated directly using "),U7e=n(HGe,"CODE",{});var rLt=s(U7e);OSr=r(rLt,"__init__()"),rLt.forEach(t),VSr=r(HGe," (throws an error)."),HGe.forEach(t),XSr=i(Jl),Xt=n(Jl,"DIV",{class:!0});var nA=s(Xt);T(V9.$$.fragment,nA),zSr=i(nA),J7e=n(nA,"P",{});var tLt=s(J7e);WSr=r(tLt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),tLt.forEach(t),QSr=i(nA),Vc=n(nA,"P",{});var Uee=s(Vc);HSr=r(Uee,`Note:
Loading a model from its configuration file does `),Y7e=n(Uee,"STRONG",{});var aLt=s(Y7e);USr=r(aLt,"not"),aLt.forEach(t),JSr=r(Uee,` load the model weights. It only affects the
model\u2019s configuration. Use `),XY=n(Uee,"A",{href:!0});var nLt=s(XY);YSr=r(nLt,"from_pretrained()"),nLt.forEach(t),KSr=r(Uee," to load the model weights."),Uee.forEach(t),ZSr=i(nA),T(x3.$$.fragment,nA),nA.forEach(t),eRr=i(Jl),Or=n(Jl,"DIV",{class:!0});var Yl=s(Or);T(X9.$$.fragment,Yl),oRr=i(Yl),K7e=n(Yl,"P",{});var sLt=s(K7e);rRr=r(sLt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),sLt.forEach(t),tRr=i(Yl),_n=n(Yl,"P",{});var sA=s(_n);aRr=r(sA,"The model class to instantiate is selected based on the "),Z7e=n(sA,"CODE",{});var lLt=s(Z7e);nRr=r(lLt,"model_type"),lLt.forEach(t),sRr=r(sA,` property of the config object (either
passed as an argument or loaded from `),eMe=n(sA,"CODE",{});var iLt=s(eMe);lRr=r(iLt,"pretrained_model_name_or_path"),iLt.forEach(t),iRr=r(sA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oMe=n(sA,"CODE",{});var dLt=s(oMe);dRr=r(dLt,"pretrained_model_name_or_path"),dLt.forEach(t),cRr=r(sA,":"),sA.forEach(t),fRr=i(Yl),Le=n(Yl,"UL",{});var Ie=s(Le);$3=n(Ie,"LI",{});var JIe=s($3);rMe=n(JIe,"STRONG",{});var cLt=s(rMe);mRr=r(cLt,"albert"),cLt.forEach(t),gRr=r(JIe," \u2014 "),zY=n(JIe,"A",{href:!0});var fLt=s(zY);hRr=r(fLt,"FlaxAlbertForMaskedLM"),fLt.forEach(t),pRr=r(JIe," (ALBERT model)"),JIe.forEach(t),uRr=i(Ie),k3=n(Ie,"LI",{});var YIe=s(k3);tMe=n(YIe,"STRONG",{});var mLt=s(tMe);_Rr=r(mLt,"bart"),mLt.forEach(t),bRr=r(YIe," \u2014 "),WY=n(YIe,"A",{href:!0});var gLt=s(WY);vRr=r(gLt,"FlaxBartForConditionalGeneration"),gLt.forEach(t),FRr=r(YIe," (BART model)"),YIe.forEach(t),TRr=i(Ie),S3=n(Ie,"LI",{});var KIe=s(S3);aMe=n(KIe,"STRONG",{});var hLt=s(aMe);MRr=r(hLt,"bert"),hLt.forEach(t),ERr=r(KIe," \u2014 "),QY=n(KIe,"A",{href:!0});var pLt=s(QY);CRr=r(pLt,"FlaxBertForMaskedLM"),pLt.forEach(t),wRr=r(KIe," (BERT model)"),KIe.forEach(t),ARr=i(Ie),R3=n(Ie,"LI",{});var ZIe=s(R3);nMe=n(ZIe,"STRONG",{});var uLt=s(nMe);yRr=r(uLt,"big_bird"),uLt.forEach(t),LRr=r(ZIe," \u2014 "),HY=n(ZIe,"A",{href:!0});var _Lt=s(HY);xRr=r(_Lt,"FlaxBigBirdForMaskedLM"),_Lt.forEach(t),$Rr=r(ZIe," (BigBird model)"),ZIe.forEach(t),kRr=i(Ie),P3=n(Ie,"LI",{});var eqe=s(P3);sMe=n(eqe,"STRONG",{});var bLt=s(sMe);SRr=r(bLt,"distilbert"),bLt.forEach(t),RRr=r(eqe," \u2014 "),UY=n(eqe,"A",{href:!0});var vLt=s(UY);PRr=r(vLt,"FlaxDistilBertForMaskedLM"),vLt.forEach(t),BRr=r(eqe," (DistilBERT model)"),eqe.forEach(t),IRr=i(Ie),B3=n(Ie,"LI",{});var oqe=s(B3);lMe=n(oqe,"STRONG",{});var FLt=s(lMe);qRr=r(FLt,"electra"),FLt.forEach(t),NRr=r(oqe," \u2014 "),JY=n(oqe,"A",{href:!0});var TLt=s(JY);jRr=r(TLt,"FlaxElectraForMaskedLM"),TLt.forEach(t),DRr=r(oqe," (ELECTRA model)"),oqe.forEach(t),GRr=i(Ie),I3=n(Ie,"LI",{});var rqe=s(I3);iMe=n(rqe,"STRONG",{});var MLt=s(iMe);ORr=r(MLt,"mbart"),MLt.forEach(t),VRr=r(rqe," \u2014 "),YY=n(rqe,"A",{href:!0});var ELt=s(YY);XRr=r(ELt,"FlaxMBartForConditionalGeneration"),ELt.forEach(t),zRr=r(rqe," (mBART model)"),rqe.forEach(t),WRr=i(Ie),q3=n(Ie,"LI",{});var tqe=s(q3);dMe=n(tqe,"STRONG",{});var CLt=s(dMe);QRr=r(CLt,"roberta"),CLt.forEach(t),HRr=r(tqe," \u2014 "),KY=n(tqe,"A",{href:!0});var wLt=s(KY);URr=r(wLt,"FlaxRobertaForMaskedLM"),wLt.forEach(t),JRr=r(tqe," (RoBERTa model)"),tqe.forEach(t),YRr=i(Ie),N3=n(Ie,"LI",{});var aqe=s(N3);cMe=n(aqe,"STRONG",{});var ALt=s(cMe);KRr=r(ALt,"roformer"),ALt.forEach(t),ZRr=r(aqe," \u2014 "),ZY=n(aqe,"A",{href:!0});var yLt=s(ZY);ePr=r(yLt,"FlaxRoFormerForMaskedLM"),yLt.forEach(t),oPr=r(aqe," (RoFormer model)"),aqe.forEach(t),rPr=i(Ie),j3=n(Ie,"LI",{});var nqe=s(j3);fMe=n(nqe,"STRONG",{});var LLt=s(fMe);tPr=r(LLt,"xlm-roberta"),LLt.forEach(t),aPr=r(nqe," \u2014 "),eK=n(nqe,"A",{href:!0});var xLt=s(eK);nPr=r(xLt,"FlaxXLMRobertaForMaskedLM"),xLt.forEach(t),sPr=r(nqe," (XLM-RoBERTa model)"),nqe.forEach(t),Ie.forEach(t),lPr=i(Yl),T(D3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),Oje=i(f),Xc=n(f,"H2",{class:!0});var UGe=s(Xc);G3=n(UGe,"A",{id:!0,class:!0,href:!0});var $Lt=s(G3);mMe=n($Lt,"SPAN",{});var kLt=s(mMe);T(z9.$$.fragment,kLt),kLt.forEach(t),$Lt.forEach(t),iPr=i(UGe),gMe=n(UGe,"SPAN",{});var SLt=s(gMe);dPr=r(SLt,"FlaxAutoModelForSeq2SeqLM"),SLt.forEach(t),UGe.forEach(t),Vje=i(f),pr=n(f,"DIV",{class:!0});var Kl=s(pr);T(W9.$$.fragment,Kl),cPr=i(Kl),zc=n(Kl,"P",{});var Jee=s(zc);fPr=r(Jee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),oK=n(Jee,"A",{href:!0});var RLt=s(oK);mPr=r(RLt,"from_pretrained()"),RLt.forEach(t),gPr=r(Jee," class method or the "),rK=n(Jee,"A",{href:!0});var PLt=s(rK);hPr=r(PLt,"from_config()"),PLt.forEach(t),pPr=r(Jee,` class
method.`),Jee.forEach(t),uPr=i(Kl),Q9=n(Kl,"P",{});var JGe=s(Q9);_Pr=r(JGe,"This class cannot be instantiated directly using "),hMe=n(JGe,"CODE",{});var BLt=s(hMe);bPr=r(BLt,"__init__()"),BLt.forEach(t),vPr=r(JGe," (throws an error)."),JGe.forEach(t),FPr=i(Kl),zt=n(Kl,"DIV",{class:!0});var lA=s(zt);T(H9.$$.fragment,lA),TPr=i(lA),pMe=n(lA,"P",{});var ILt=s(pMe);MPr=r(ILt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ILt.forEach(t),EPr=i(lA),Wc=n(lA,"P",{});var Yee=s(Wc);CPr=r(Yee,`Note:
Loading a model from its configuration file does `),uMe=n(Yee,"STRONG",{});var qLt=s(uMe);wPr=r(qLt,"not"),qLt.forEach(t),APr=r(Yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=n(Yee,"A",{href:!0});var NLt=s(tK);yPr=r(NLt,"from_pretrained()"),NLt.forEach(t),LPr=r(Yee," to load the model weights."),Yee.forEach(t),xPr=i(lA),T(O3.$$.fragment,lA),lA.forEach(t),$Pr=i(Kl),Vr=n(Kl,"DIV",{class:!0});var Zl=s(Vr);T(U9.$$.fragment,Zl),kPr=i(Zl),_Me=n(Zl,"P",{});var jLt=s(_Me);SPr=r(jLt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),jLt.forEach(t),RPr=i(Zl),bn=n(Zl,"P",{});var iA=s(bn);PPr=r(iA,"The model class to instantiate is selected based on the "),bMe=n(iA,"CODE",{});var DLt=s(bMe);BPr=r(DLt,"model_type"),DLt.forEach(t),IPr=r(iA,` property of the config object (either
passed as an argument or loaded from `),vMe=n(iA,"CODE",{});var GLt=s(vMe);qPr=r(GLt,"pretrained_model_name_or_path"),GLt.forEach(t),NPr=r(iA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FMe=n(iA,"CODE",{});var OLt=s(FMe);jPr=r(OLt,"pretrained_model_name_or_path"),OLt.forEach(t),DPr=r(iA,":"),iA.forEach(t),GPr=i(Zl),Pe=n(Zl,"UL",{});var ze=s(Pe);V3=n(ze,"LI",{});var sqe=s(V3);TMe=n(sqe,"STRONG",{});var VLt=s(TMe);OPr=r(VLt,"bart"),VLt.forEach(t),VPr=r(sqe," \u2014 "),aK=n(sqe,"A",{href:!0});var XLt=s(aK);XPr=r(XLt,"FlaxBartForConditionalGeneration"),XLt.forEach(t),zPr=r(sqe," (BART model)"),sqe.forEach(t),WPr=i(ze),X3=n(ze,"LI",{});var lqe=s(X3);MMe=n(lqe,"STRONG",{});var zLt=s(MMe);QPr=r(zLt,"blenderbot"),zLt.forEach(t),HPr=r(lqe," \u2014 "),nK=n(lqe,"A",{href:!0});var WLt=s(nK);UPr=r(WLt,"FlaxBlenderbotForConditionalGeneration"),WLt.forEach(t),JPr=r(lqe," (Blenderbot model)"),lqe.forEach(t),YPr=i(ze),z3=n(ze,"LI",{});var iqe=s(z3);EMe=n(iqe,"STRONG",{});var QLt=s(EMe);KPr=r(QLt,"blenderbot-small"),QLt.forEach(t),ZPr=r(iqe," \u2014 "),sK=n(iqe,"A",{href:!0});var HLt=s(sK);eBr=r(HLt,"FlaxBlenderbotSmallForConditionalGeneration"),HLt.forEach(t),oBr=r(iqe," (BlenderbotSmall model)"),iqe.forEach(t),rBr=i(ze),W3=n(ze,"LI",{});var dqe=s(W3);CMe=n(dqe,"STRONG",{});var ULt=s(CMe);tBr=r(ULt,"encoder-decoder"),ULt.forEach(t),aBr=r(dqe," \u2014 "),lK=n(dqe,"A",{href:!0});var JLt=s(lK);nBr=r(JLt,"FlaxEncoderDecoderModel"),JLt.forEach(t),sBr=r(dqe," (Encoder decoder model)"),dqe.forEach(t),lBr=i(ze),Q3=n(ze,"LI",{});var cqe=s(Q3);wMe=n(cqe,"STRONG",{});var YLt=s(wMe);iBr=r(YLt,"marian"),YLt.forEach(t),dBr=r(cqe," \u2014 "),iK=n(cqe,"A",{href:!0});var KLt=s(iK);cBr=r(KLt,"FlaxMarianMTModel"),KLt.forEach(t),fBr=r(cqe," (Marian model)"),cqe.forEach(t),mBr=i(ze),H3=n(ze,"LI",{});var fqe=s(H3);AMe=n(fqe,"STRONG",{});var ZLt=s(AMe);gBr=r(ZLt,"mbart"),ZLt.forEach(t),hBr=r(fqe," \u2014 "),dK=n(fqe,"A",{href:!0});var e8t=s(dK);pBr=r(e8t,"FlaxMBartForConditionalGeneration"),e8t.forEach(t),uBr=r(fqe," (mBART model)"),fqe.forEach(t),_Br=i(ze),U3=n(ze,"LI",{});var mqe=s(U3);yMe=n(mqe,"STRONG",{});var o8t=s(yMe);bBr=r(o8t,"mt5"),o8t.forEach(t),vBr=r(mqe," \u2014 "),cK=n(mqe,"A",{href:!0});var r8t=s(cK);FBr=r(r8t,"FlaxMT5ForConditionalGeneration"),r8t.forEach(t),TBr=r(mqe," (mT5 model)"),mqe.forEach(t),MBr=i(ze),J3=n(ze,"LI",{});var gqe=s(J3);LMe=n(gqe,"STRONG",{});var t8t=s(LMe);EBr=r(t8t,"pegasus"),t8t.forEach(t),CBr=r(gqe," \u2014 "),fK=n(gqe,"A",{href:!0});var a8t=s(fK);wBr=r(a8t,"FlaxPegasusForConditionalGeneration"),a8t.forEach(t),ABr=r(gqe," (Pegasus model)"),gqe.forEach(t),yBr=i(ze),Y3=n(ze,"LI",{});var hqe=s(Y3);xMe=n(hqe,"STRONG",{});var n8t=s(xMe);LBr=r(n8t,"t5"),n8t.forEach(t),xBr=r(hqe," \u2014 "),mK=n(hqe,"A",{href:!0});var s8t=s(mK);$Br=r(s8t,"FlaxT5ForConditionalGeneration"),s8t.forEach(t),kBr=r(hqe," (T5 model)"),hqe.forEach(t),ze.forEach(t),SBr=i(Zl),T(K3.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),Xje=i(f),Qc=n(f,"H2",{class:!0});var YGe=s(Qc);Z3=n(YGe,"A",{id:!0,class:!0,href:!0});var l8t=s(Z3);$Me=n(l8t,"SPAN",{});var i8t=s($Me);T(J9.$$.fragment,i8t),i8t.forEach(t),l8t.forEach(t),RBr=i(YGe),kMe=n(YGe,"SPAN",{});var d8t=s(kMe);PBr=r(d8t,"FlaxAutoModelForSequenceClassification"),d8t.forEach(t),YGe.forEach(t),zje=i(f),ur=n(f,"DIV",{class:!0});var ei=s(ur);T(Y9.$$.fragment,ei),BBr=i(ei),Hc=n(ei,"P",{});var Kee=s(Hc);IBr=r(Kee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gK=n(Kee,"A",{href:!0});var c8t=s(gK);qBr=r(c8t,"from_pretrained()"),c8t.forEach(t),NBr=r(Kee," class method or the "),hK=n(Kee,"A",{href:!0});var f8t=s(hK);jBr=r(f8t,"from_config()"),f8t.forEach(t),DBr=r(Kee,` class
method.`),Kee.forEach(t),GBr=i(ei),K9=n(ei,"P",{});var KGe=s(K9);OBr=r(KGe,"This class cannot be instantiated directly using "),SMe=n(KGe,"CODE",{});var m8t=s(SMe);VBr=r(m8t,"__init__()"),m8t.forEach(t),XBr=r(KGe," (throws an error)."),KGe.forEach(t),zBr=i(ei),Wt=n(ei,"DIV",{class:!0});var dA=s(Wt);T(Z9.$$.fragment,dA),WBr=i(dA),RMe=n(dA,"P",{});var g8t=s(RMe);QBr=r(g8t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),g8t.forEach(t),HBr=i(dA),Uc=n(dA,"P",{});var Zee=s(Uc);UBr=r(Zee,`Note:
Loading a model from its configuration file does `),PMe=n(Zee,"STRONG",{});var h8t=s(PMe);JBr=r(h8t,"not"),h8t.forEach(t),YBr=r(Zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),pK=n(Zee,"A",{href:!0});var p8t=s(pK);KBr=r(p8t,"from_pretrained()"),p8t.forEach(t),ZBr=r(Zee," to load the model weights."),Zee.forEach(t),eIr=i(dA),T(ew.$$.fragment,dA),dA.forEach(t),oIr=i(ei),Xr=n(ei,"DIV",{class:!0});var oi=s(Xr);T(ex.$$.fragment,oi),rIr=i(oi),BMe=n(oi,"P",{});var u8t=s(BMe);tIr=r(u8t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),u8t.forEach(t),aIr=i(oi),vn=n(oi,"P",{});var cA=s(vn);nIr=r(cA,"The model class to instantiate is selected based on the "),IMe=n(cA,"CODE",{});var _8t=s(IMe);sIr=r(_8t,"model_type"),_8t.forEach(t),lIr=r(cA,` property of the config object (either
passed as an argument or loaded from `),qMe=n(cA,"CODE",{});var b8t=s(qMe);iIr=r(b8t,"pretrained_model_name_or_path"),b8t.forEach(t),dIr=r(cA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NMe=n(cA,"CODE",{});var v8t=s(NMe);cIr=r(v8t,"pretrained_model_name_or_path"),v8t.forEach(t),fIr=r(cA,":"),cA.forEach(t),mIr=i(oi),xe=n(oi,"UL",{});var qe=s(xe);ow=n(qe,"LI",{});var pqe=s(ow);jMe=n(pqe,"STRONG",{});var F8t=s(jMe);gIr=r(F8t,"albert"),F8t.forEach(t),hIr=r(pqe," \u2014 "),uK=n(pqe,"A",{href:!0});var T8t=s(uK);pIr=r(T8t,"FlaxAlbertForSequenceClassification"),T8t.forEach(t),uIr=r(pqe," (ALBERT model)"),pqe.forEach(t),_Ir=i(qe),rw=n(qe,"LI",{});var uqe=s(rw);DMe=n(uqe,"STRONG",{});var M8t=s(DMe);bIr=r(M8t,"bart"),M8t.forEach(t),vIr=r(uqe," \u2014 "),_K=n(uqe,"A",{href:!0});var E8t=s(_K);FIr=r(E8t,"FlaxBartForSequenceClassification"),E8t.forEach(t),TIr=r(uqe," (BART model)"),uqe.forEach(t),MIr=i(qe),tw=n(qe,"LI",{});var _qe=s(tw);GMe=n(_qe,"STRONG",{});var C8t=s(GMe);EIr=r(C8t,"bert"),C8t.forEach(t),CIr=r(_qe," \u2014 "),bK=n(_qe,"A",{href:!0});var w8t=s(bK);wIr=r(w8t,"FlaxBertForSequenceClassification"),w8t.forEach(t),AIr=r(_qe," (BERT model)"),_qe.forEach(t),yIr=i(qe),aw=n(qe,"LI",{});var bqe=s(aw);OMe=n(bqe,"STRONG",{});var A8t=s(OMe);LIr=r(A8t,"big_bird"),A8t.forEach(t),xIr=r(bqe," \u2014 "),vK=n(bqe,"A",{href:!0});var y8t=s(vK);$Ir=r(y8t,"FlaxBigBirdForSequenceClassification"),y8t.forEach(t),kIr=r(bqe," (BigBird model)"),bqe.forEach(t),SIr=i(qe),nw=n(qe,"LI",{});var vqe=s(nw);VMe=n(vqe,"STRONG",{});var L8t=s(VMe);RIr=r(L8t,"distilbert"),L8t.forEach(t),PIr=r(vqe," \u2014 "),FK=n(vqe,"A",{href:!0});var x8t=s(FK);BIr=r(x8t,"FlaxDistilBertForSequenceClassification"),x8t.forEach(t),IIr=r(vqe," (DistilBERT model)"),vqe.forEach(t),qIr=i(qe),sw=n(qe,"LI",{});var Fqe=s(sw);XMe=n(Fqe,"STRONG",{});var $8t=s(XMe);NIr=r($8t,"electra"),$8t.forEach(t),jIr=r(Fqe," \u2014 "),TK=n(Fqe,"A",{href:!0});var k8t=s(TK);DIr=r(k8t,"FlaxElectraForSequenceClassification"),k8t.forEach(t),GIr=r(Fqe," (ELECTRA model)"),Fqe.forEach(t),OIr=i(qe),lw=n(qe,"LI",{});var Tqe=s(lw);zMe=n(Tqe,"STRONG",{});var S8t=s(zMe);VIr=r(S8t,"mbart"),S8t.forEach(t),XIr=r(Tqe," \u2014 "),MK=n(Tqe,"A",{href:!0});var R8t=s(MK);zIr=r(R8t,"FlaxMBartForSequenceClassification"),R8t.forEach(t),WIr=r(Tqe," (mBART model)"),Tqe.forEach(t),QIr=i(qe),iw=n(qe,"LI",{});var Mqe=s(iw);WMe=n(Mqe,"STRONG",{});var P8t=s(WMe);HIr=r(P8t,"roberta"),P8t.forEach(t),UIr=r(Mqe," \u2014 "),EK=n(Mqe,"A",{href:!0});var B8t=s(EK);JIr=r(B8t,"FlaxRobertaForSequenceClassification"),B8t.forEach(t),YIr=r(Mqe," (RoBERTa model)"),Mqe.forEach(t),KIr=i(qe),dw=n(qe,"LI",{});var Eqe=s(dw);QMe=n(Eqe,"STRONG",{});var I8t=s(QMe);ZIr=r(I8t,"roformer"),I8t.forEach(t),eqr=r(Eqe," \u2014 "),CK=n(Eqe,"A",{href:!0});var q8t=s(CK);oqr=r(q8t,"FlaxRoFormerForSequenceClassification"),q8t.forEach(t),rqr=r(Eqe," (RoFormer model)"),Eqe.forEach(t),tqr=i(qe),cw=n(qe,"LI",{});var Cqe=s(cw);HMe=n(Cqe,"STRONG",{});var N8t=s(HMe);aqr=r(N8t,"xlm-roberta"),N8t.forEach(t),nqr=r(Cqe," \u2014 "),wK=n(Cqe,"A",{href:!0});var j8t=s(wK);sqr=r(j8t,"FlaxXLMRobertaForSequenceClassification"),j8t.forEach(t),lqr=r(Cqe," (XLM-RoBERTa model)"),Cqe.forEach(t),qe.forEach(t),iqr=i(oi),T(fw.$$.fragment,oi),oi.forEach(t),ei.forEach(t),Wje=i(f),Jc=n(f,"H2",{class:!0});var ZGe=s(Jc);mw=n(ZGe,"A",{id:!0,class:!0,href:!0});var D8t=s(mw);UMe=n(D8t,"SPAN",{});var G8t=s(UMe);T(ox.$$.fragment,G8t),G8t.forEach(t),D8t.forEach(t),dqr=i(ZGe),JMe=n(ZGe,"SPAN",{});var O8t=s(JMe);cqr=r(O8t,"FlaxAutoModelForQuestionAnswering"),O8t.forEach(t),ZGe.forEach(t),Qje=i(f),_r=n(f,"DIV",{class:!0});var ri=s(_r);T(rx.$$.fragment,ri),fqr=i(ri),Yc=n(ri,"P",{});var eoe=s(Yc);mqr=r(eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),AK=n(eoe,"A",{href:!0});var V8t=s(AK);gqr=r(V8t,"from_pretrained()"),V8t.forEach(t),hqr=r(eoe," class method or the "),yK=n(eoe,"A",{href:!0});var X8t=s(yK);pqr=r(X8t,"from_config()"),X8t.forEach(t),uqr=r(eoe,` class
method.`),eoe.forEach(t),_qr=i(ri),tx=n(ri,"P",{});var eOe=s(tx);bqr=r(eOe,"This class cannot be instantiated directly using "),YMe=n(eOe,"CODE",{});var z8t=s(YMe);vqr=r(z8t,"__init__()"),z8t.forEach(t),Fqr=r(eOe," (throws an error)."),eOe.forEach(t),Tqr=i(ri),Qt=n(ri,"DIV",{class:!0});var fA=s(Qt);T(ax.$$.fragment,fA),Mqr=i(fA),KMe=n(fA,"P",{});var W8t=s(KMe);Eqr=r(W8t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),W8t.forEach(t),Cqr=i(fA),Kc=n(fA,"P",{});var ooe=s(Kc);wqr=r(ooe,`Note:
Loading a model from its configuration file does `),ZMe=n(ooe,"STRONG",{});var Q8t=s(ZMe);Aqr=r(Q8t,"not"),Q8t.forEach(t),yqr=r(ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),LK=n(ooe,"A",{href:!0});var H8t=s(LK);Lqr=r(H8t,"from_pretrained()"),H8t.forEach(t),xqr=r(ooe," to load the model weights."),ooe.forEach(t),$qr=i(fA),T(gw.$$.fragment,fA),fA.forEach(t),kqr=i(ri),zr=n(ri,"DIV",{class:!0});var ti=s(zr);T(nx.$$.fragment,ti),Sqr=i(ti),eEe=n(ti,"P",{});var U8t=s(eEe);Rqr=r(U8t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),U8t.forEach(t),Pqr=i(ti),Fn=n(ti,"P",{});var mA=s(Fn);Bqr=r(mA,"The model class to instantiate is selected based on the "),oEe=n(mA,"CODE",{});var J8t=s(oEe);Iqr=r(J8t,"model_type"),J8t.forEach(t),qqr=r(mA,` property of the config object (either
passed as an argument or loaded from `),rEe=n(mA,"CODE",{});var Y8t=s(rEe);Nqr=r(Y8t,"pretrained_model_name_or_path"),Y8t.forEach(t),jqr=r(mA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=n(mA,"CODE",{});var K8t=s(tEe);Dqr=r(K8t,"pretrained_model_name_or_path"),K8t.forEach(t),Gqr=r(mA,":"),mA.forEach(t),Oqr=i(ti),$e=n(ti,"UL",{});var Ne=s($e);hw=n(Ne,"LI",{});var wqe=s(hw);aEe=n(wqe,"STRONG",{});var Z8t=s(aEe);Vqr=r(Z8t,"albert"),Z8t.forEach(t),Xqr=r(wqe," \u2014 "),xK=n(wqe,"A",{href:!0});var e9t=s(xK);zqr=r(e9t,"FlaxAlbertForQuestionAnswering"),e9t.forEach(t),Wqr=r(wqe," (ALBERT model)"),wqe.forEach(t),Qqr=i(Ne),pw=n(Ne,"LI",{});var Aqe=s(pw);nEe=n(Aqe,"STRONG",{});var o9t=s(nEe);Hqr=r(o9t,"bart"),o9t.forEach(t),Uqr=r(Aqe," \u2014 "),$K=n(Aqe,"A",{href:!0});var r9t=s($K);Jqr=r(r9t,"FlaxBartForQuestionAnswering"),r9t.forEach(t),Yqr=r(Aqe," (BART model)"),Aqe.forEach(t),Kqr=i(Ne),uw=n(Ne,"LI",{});var yqe=s(uw);sEe=n(yqe,"STRONG",{});var t9t=s(sEe);Zqr=r(t9t,"bert"),t9t.forEach(t),eNr=r(yqe," \u2014 "),kK=n(yqe,"A",{href:!0});var a9t=s(kK);oNr=r(a9t,"FlaxBertForQuestionAnswering"),a9t.forEach(t),rNr=r(yqe," (BERT model)"),yqe.forEach(t),tNr=i(Ne),_w=n(Ne,"LI",{});var Lqe=s(_w);lEe=n(Lqe,"STRONG",{});var n9t=s(lEe);aNr=r(n9t,"big_bird"),n9t.forEach(t),nNr=r(Lqe," \u2014 "),SK=n(Lqe,"A",{href:!0});var s9t=s(SK);sNr=r(s9t,"FlaxBigBirdForQuestionAnswering"),s9t.forEach(t),lNr=r(Lqe," (BigBird model)"),Lqe.forEach(t),iNr=i(Ne),bw=n(Ne,"LI",{});var xqe=s(bw);iEe=n(xqe,"STRONG",{});var l9t=s(iEe);dNr=r(l9t,"distilbert"),l9t.forEach(t),cNr=r(xqe," \u2014 "),RK=n(xqe,"A",{href:!0});var i9t=s(RK);fNr=r(i9t,"FlaxDistilBertForQuestionAnswering"),i9t.forEach(t),mNr=r(xqe," (DistilBERT model)"),xqe.forEach(t),gNr=i(Ne),vw=n(Ne,"LI",{});var $qe=s(vw);dEe=n($qe,"STRONG",{});var d9t=s(dEe);hNr=r(d9t,"electra"),d9t.forEach(t),pNr=r($qe," \u2014 "),PK=n($qe,"A",{href:!0});var c9t=s(PK);uNr=r(c9t,"FlaxElectraForQuestionAnswering"),c9t.forEach(t),_Nr=r($qe," (ELECTRA model)"),$qe.forEach(t),bNr=i(Ne),Fw=n(Ne,"LI",{});var kqe=s(Fw);cEe=n(kqe,"STRONG",{});var f9t=s(cEe);vNr=r(f9t,"mbart"),f9t.forEach(t),FNr=r(kqe," \u2014 "),BK=n(kqe,"A",{href:!0});var m9t=s(BK);TNr=r(m9t,"FlaxMBartForQuestionAnswering"),m9t.forEach(t),MNr=r(kqe," (mBART model)"),kqe.forEach(t),ENr=i(Ne),Tw=n(Ne,"LI",{});var Sqe=s(Tw);fEe=n(Sqe,"STRONG",{});var g9t=s(fEe);CNr=r(g9t,"roberta"),g9t.forEach(t),wNr=r(Sqe," \u2014 "),IK=n(Sqe,"A",{href:!0});var h9t=s(IK);ANr=r(h9t,"FlaxRobertaForQuestionAnswering"),h9t.forEach(t),yNr=r(Sqe," (RoBERTa model)"),Sqe.forEach(t),LNr=i(Ne),Mw=n(Ne,"LI",{});var Rqe=s(Mw);mEe=n(Rqe,"STRONG",{});var p9t=s(mEe);xNr=r(p9t,"roformer"),p9t.forEach(t),$Nr=r(Rqe," \u2014 "),qK=n(Rqe,"A",{href:!0});var u9t=s(qK);kNr=r(u9t,"FlaxRoFormerForQuestionAnswering"),u9t.forEach(t),SNr=r(Rqe," (RoFormer model)"),Rqe.forEach(t),RNr=i(Ne),Ew=n(Ne,"LI",{});var Pqe=s(Ew);gEe=n(Pqe,"STRONG",{});var _9t=s(gEe);PNr=r(_9t,"xlm-roberta"),_9t.forEach(t),BNr=r(Pqe," \u2014 "),NK=n(Pqe,"A",{href:!0});var b9t=s(NK);INr=r(b9t,"FlaxXLMRobertaForQuestionAnswering"),b9t.forEach(t),qNr=r(Pqe," (XLM-RoBERTa model)"),Pqe.forEach(t),Ne.forEach(t),NNr=i(ti),T(Cw.$$.fragment,ti),ti.forEach(t),ri.forEach(t),Hje=i(f),Zc=n(f,"H2",{class:!0});var oOe=s(Zc);ww=n(oOe,"A",{id:!0,class:!0,href:!0});var v9t=s(ww);hEe=n(v9t,"SPAN",{});var F9t=s(hEe);T(sx.$$.fragment,F9t),F9t.forEach(t),v9t.forEach(t),jNr=i(oOe),pEe=n(oOe,"SPAN",{});var T9t=s(pEe);DNr=r(T9t,"FlaxAutoModelForTokenClassification"),T9t.forEach(t),oOe.forEach(t),Uje=i(f),br=n(f,"DIV",{class:!0});var ai=s(br);T(lx.$$.fragment,ai),GNr=i(ai),ef=n(ai,"P",{});var roe=s(ef);ONr=r(roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),jK=n(roe,"A",{href:!0});var M9t=s(jK);VNr=r(M9t,"from_pretrained()"),M9t.forEach(t),XNr=r(roe," class method or the "),DK=n(roe,"A",{href:!0});var E9t=s(DK);zNr=r(E9t,"from_config()"),E9t.forEach(t),WNr=r(roe,` class
method.`),roe.forEach(t),QNr=i(ai),ix=n(ai,"P",{});var rOe=s(ix);HNr=r(rOe,"This class cannot be instantiated directly using "),uEe=n(rOe,"CODE",{});var C9t=s(uEe);UNr=r(C9t,"__init__()"),C9t.forEach(t),JNr=r(rOe," (throws an error)."),rOe.forEach(t),YNr=i(ai),Ht=n(ai,"DIV",{class:!0});var gA=s(Ht);T(dx.$$.fragment,gA),KNr=i(gA),_Ee=n(gA,"P",{});var w9t=s(_Ee);ZNr=r(w9t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),w9t.forEach(t),ejr=i(gA),of=n(gA,"P",{});var toe=s(of);ojr=r(toe,`Note:
Loading a model from its configuration file does `),bEe=n(toe,"STRONG",{});var A9t=s(bEe);rjr=r(A9t,"not"),A9t.forEach(t),tjr=r(toe,` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=n(toe,"A",{href:!0});var y9t=s(GK);ajr=r(y9t,"from_pretrained()"),y9t.forEach(t),njr=r(toe," to load the model weights."),toe.forEach(t),sjr=i(gA),T(Aw.$$.fragment,gA),gA.forEach(t),ljr=i(ai),Wr=n(ai,"DIV",{class:!0});var ni=s(Wr);T(cx.$$.fragment,ni),ijr=i(ni),vEe=n(ni,"P",{});var L9t=s(vEe);djr=r(L9t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),L9t.forEach(t),cjr=i(ni),Tn=n(ni,"P",{});var hA=s(Tn);fjr=r(hA,"The model class to instantiate is selected based on the "),FEe=n(hA,"CODE",{});var x9t=s(FEe);mjr=r(x9t,"model_type"),x9t.forEach(t),gjr=r(hA,` property of the config object (either
passed as an argument or loaded from `),TEe=n(hA,"CODE",{});var $9t=s(TEe);hjr=r($9t,"pretrained_model_name_or_path"),$9t.forEach(t),pjr=r(hA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MEe=n(hA,"CODE",{});var k9t=s(MEe);ujr=r(k9t,"pretrained_model_name_or_path"),k9t.forEach(t),_jr=r(hA,":"),hA.forEach(t),bjr=i(ni),De=n(ni,"UL",{});var Fo=s(De);yw=n(Fo,"LI",{});var Bqe=s(yw);EEe=n(Bqe,"STRONG",{});var S9t=s(EEe);vjr=r(S9t,"albert"),S9t.forEach(t),Fjr=r(Bqe," \u2014 "),OK=n(Bqe,"A",{href:!0});var R9t=s(OK);Tjr=r(R9t,"FlaxAlbertForTokenClassification"),R9t.forEach(t),Mjr=r(Bqe," (ALBERT model)"),Bqe.forEach(t),Ejr=i(Fo),Lw=n(Fo,"LI",{});var Iqe=s(Lw);CEe=n(Iqe,"STRONG",{});var P9t=s(CEe);Cjr=r(P9t,"bert"),P9t.forEach(t),wjr=r(Iqe," \u2014 "),VK=n(Iqe,"A",{href:!0});var B9t=s(VK);Ajr=r(B9t,"FlaxBertForTokenClassification"),B9t.forEach(t),yjr=r(Iqe," (BERT model)"),Iqe.forEach(t),Ljr=i(Fo),xw=n(Fo,"LI",{});var qqe=s(xw);wEe=n(qqe,"STRONG",{});var I9t=s(wEe);xjr=r(I9t,"big_bird"),I9t.forEach(t),$jr=r(qqe," \u2014 "),XK=n(qqe,"A",{href:!0});var q9t=s(XK);kjr=r(q9t,"FlaxBigBirdForTokenClassification"),q9t.forEach(t),Sjr=r(qqe," (BigBird model)"),qqe.forEach(t),Rjr=i(Fo),$w=n(Fo,"LI",{});var Nqe=s($w);AEe=n(Nqe,"STRONG",{});var N9t=s(AEe);Pjr=r(N9t,"distilbert"),N9t.forEach(t),Bjr=r(Nqe," \u2014 "),zK=n(Nqe,"A",{href:!0});var j9t=s(zK);Ijr=r(j9t,"FlaxDistilBertForTokenClassification"),j9t.forEach(t),qjr=r(Nqe," (DistilBERT model)"),Nqe.forEach(t),Njr=i(Fo),kw=n(Fo,"LI",{});var jqe=s(kw);yEe=n(jqe,"STRONG",{});var D9t=s(yEe);jjr=r(D9t,"electra"),D9t.forEach(t),Djr=r(jqe," \u2014 "),WK=n(jqe,"A",{href:!0});var G9t=s(WK);Gjr=r(G9t,"FlaxElectraForTokenClassification"),G9t.forEach(t),Ojr=r(jqe," (ELECTRA model)"),jqe.forEach(t),Vjr=i(Fo),Sw=n(Fo,"LI",{});var Dqe=s(Sw);LEe=n(Dqe,"STRONG",{});var O9t=s(LEe);Xjr=r(O9t,"roberta"),O9t.forEach(t),zjr=r(Dqe," \u2014 "),QK=n(Dqe,"A",{href:!0});var V9t=s(QK);Wjr=r(V9t,"FlaxRobertaForTokenClassification"),V9t.forEach(t),Qjr=r(Dqe," (RoBERTa model)"),Dqe.forEach(t),Hjr=i(Fo),Rw=n(Fo,"LI",{});var Gqe=s(Rw);xEe=n(Gqe,"STRONG",{});var X9t=s(xEe);Ujr=r(X9t,"roformer"),X9t.forEach(t),Jjr=r(Gqe," \u2014 "),HK=n(Gqe,"A",{href:!0});var z9t=s(HK);Yjr=r(z9t,"FlaxRoFormerForTokenClassification"),z9t.forEach(t),Kjr=r(Gqe," (RoFormer model)"),Gqe.forEach(t),Zjr=i(Fo),Pw=n(Fo,"LI",{});var Oqe=s(Pw);$Ee=n(Oqe,"STRONG",{});var W9t=s($Ee);eDr=r(W9t,"xlm-roberta"),W9t.forEach(t),oDr=r(Oqe," \u2014 "),UK=n(Oqe,"A",{href:!0});var Q9t=s(UK);rDr=r(Q9t,"FlaxXLMRobertaForTokenClassification"),Q9t.forEach(t),tDr=r(Oqe," (XLM-RoBERTa model)"),Oqe.forEach(t),Fo.forEach(t),aDr=i(ni),T(Bw.$$.fragment,ni),ni.forEach(t),ai.forEach(t),Jje=i(f),rf=n(f,"H2",{class:!0});var tOe=s(rf);Iw=n(tOe,"A",{id:!0,class:!0,href:!0});var H9t=s(Iw);kEe=n(H9t,"SPAN",{});var U9t=s(kEe);T(fx.$$.fragment,U9t),U9t.forEach(t),H9t.forEach(t),nDr=i(tOe),SEe=n(tOe,"SPAN",{});var J9t=s(SEe);sDr=r(J9t,"FlaxAutoModelForMultipleChoice"),J9t.forEach(t),tOe.forEach(t),Yje=i(f),vr=n(f,"DIV",{class:!0});var si=s(vr);T(mx.$$.fragment,si),lDr=i(si),tf=n(si,"P",{});var aoe=s(tf);iDr=r(aoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),JK=n(aoe,"A",{href:!0});var Y9t=s(JK);dDr=r(Y9t,"from_pretrained()"),Y9t.forEach(t),cDr=r(aoe," class method or the "),YK=n(aoe,"A",{href:!0});var K9t=s(YK);fDr=r(K9t,"from_config()"),K9t.forEach(t),mDr=r(aoe,` class
method.`),aoe.forEach(t),gDr=i(si),gx=n(si,"P",{});var aOe=s(gx);hDr=r(aOe,"This class cannot be instantiated directly using "),REe=n(aOe,"CODE",{});var Z9t=s(REe);pDr=r(Z9t,"__init__()"),Z9t.forEach(t),uDr=r(aOe," (throws an error)."),aOe.forEach(t),_Dr=i(si),Ut=n(si,"DIV",{class:!0});var pA=s(Ut);T(hx.$$.fragment,pA),bDr=i(pA),PEe=n(pA,"P",{});var ext=s(PEe);vDr=r(ext,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ext.forEach(t),FDr=i(pA),af=n(pA,"P",{});var noe=s(af);TDr=r(noe,`Note:
Loading a model from its configuration file does `),BEe=n(noe,"STRONG",{});var oxt=s(BEe);MDr=r(oxt,"not"),oxt.forEach(t),EDr=r(noe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KK=n(noe,"A",{href:!0});var rxt=s(KK);CDr=r(rxt,"from_pretrained()"),rxt.forEach(t),wDr=r(noe," to load the model weights."),noe.forEach(t),ADr=i(pA),T(qw.$$.fragment,pA),pA.forEach(t),yDr=i(si),Qr=n(si,"DIV",{class:!0});var li=s(Qr);T(px.$$.fragment,li),LDr=i(li),IEe=n(li,"P",{});var txt=s(IEe);xDr=r(txt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),txt.forEach(t),$Dr=i(li),Mn=n(li,"P",{});var uA=s(Mn);kDr=r(uA,"The model class to instantiate is selected based on the "),qEe=n(uA,"CODE",{});var axt=s(qEe);SDr=r(axt,"model_type"),axt.forEach(t),RDr=r(uA,` property of the config object (either
passed as an argument or loaded from `),NEe=n(uA,"CODE",{});var nxt=s(NEe);PDr=r(nxt,"pretrained_model_name_or_path"),nxt.forEach(t),BDr=r(uA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jEe=n(uA,"CODE",{});var sxt=s(jEe);IDr=r(sxt,"pretrained_model_name_or_path"),sxt.forEach(t),qDr=r(uA,":"),uA.forEach(t),NDr=i(li),Ge=n(li,"UL",{});var To=s(Ge);Nw=n(To,"LI",{});var Vqe=s(Nw);DEe=n(Vqe,"STRONG",{});var lxt=s(DEe);jDr=r(lxt,"albert"),lxt.forEach(t),DDr=r(Vqe," \u2014 "),ZK=n(Vqe,"A",{href:!0});var ixt=s(ZK);GDr=r(ixt,"FlaxAlbertForMultipleChoice"),ixt.forEach(t),ODr=r(Vqe," (ALBERT model)"),Vqe.forEach(t),VDr=i(To),jw=n(To,"LI",{});var Xqe=s(jw);GEe=n(Xqe,"STRONG",{});var dxt=s(GEe);XDr=r(dxt,"bert"),dxt.forEach(t),zDr=r(Xqe," \u2014 "),eZ=n(Xqe,"A",{href:!0});var cxt=s(eZ);WDr=r(cxt,"FlaxBertForMultipleChoice"),cxt.forEach(t),QDr=r(Xqe," (BERT model)"),Xqe.forEach(t),HDr=i(To),Dw=n(To,"LI",{});var zqe=s(Dw);OEe=n(zqe,"STRONG",{});var fxt=s(OEe);UDr=r(fxt,"big_bird"),fxt.forEach(t),JDr=r(zqe," \u2014 "),oZ=n(zqe,"A",{href:!0});var mxt=s(oZ);YDr=r(mxt,"FlaxBigBirdForMultipleChoice"),mxt.forEach(t),KDr=r(zqe," (BigBird model)"),zqe.forEach(t),ZDr=i(To),Gw=n(To,"LI",{});var Wqe=s(Gw);VEe=n(Wqe,"STRONG",{});var gxt=s(VEe);eGr=r(gxt,"distilbert"),gxt.forEach(t),oGr=r(Wqe," \u2014 "),rZ=n(Wqe,"A",{href:!0});var hxt=s(rZ);rGr=r(hxt,"FlaxDistilBertForMultipleChoice"),hxt.forEach(t),tGr=r(Wqe," (DistilBERT model)"),Wqe.forEach(t),aGr=i(To),Ow=n(To,"LI",{});var Qqe=s(Ow);XEe=n(Qqe,"STRONG",{});var pxt=s(XEe);nGr=r(pxt,"electra"),pxt.forEach(t),sGr=r(Qqe," \u2014 "),tZ=n(Qqe,"A",{href:!0});var uxt=s(tZ);lGr=r(uxt,"FlaxElectraForMultipleChoice"),uxt.forEach(t),iGr=r(Qqe," (ELECTRA model)"),Qqe.forEach(t),dGr=i(To),Vw=n(To,"LI",{});var Hqe=s(Vw);zEe=n(Hqe,"STRONG",{});var _xt=s(zEe);cGr=r(_xt,"roberta"),_xt.forEach(t),fGr=r(Hqe," \u2014 "),aZ=n(Hqe,"A",{href:!0});var bxt=s(aZ);mGr=r(bxt,"FlaxRobertaForMultipleChoice"),bxt.forEach(t),gGr=r(Hqe," (RoBERTa model)"),Hqe.forEach(t),hGr=i(To),Xw=n(To,"LI",{});var Uqe=s(Xw);WEe=n(Uqe,"STRONG",{});var vxt=s(WEe);pGr=r(vxt,"roformer"),vxt.forEach(t),uGr=r(Uqe," \u2014 "),nZ=n(Uqe,"A",{href:!0});var Fxt=s(nZ);_Gr=r(Fxt,"FlaxRoFormerForMultipleChoice"),Fxt.forEach(t),bGr=r(Uqe," (RoFormer model)"),Uqe.forEach(t),vGr=i(To),zw=n(To,"LI",{});var Jqe=s(zw);QEe=n(Jqe,"STRONG",{});var Txt=s(QEe);FGr=r(Txt,"xlm-roberta"),Txt.forEach(t),TGr=r(Jqe," \u2014 "),sZ=n(Jqe,"A",{href:!0});var Mxt=s(sZ);MGr=r(Mxt,"FlaxXLMRobertaForMultipleChoice"),Mxt.forEach(t),EGr=r(Jqe," (XLM-RoBERTa model)"),Jqe.forEach(t),To.forEach(t),CGr=i(li),T(Ww.$$.fragment,li),li.forEach(t),si.forEach(t),Kje=i(f),nf=n(f,"H2",{class:!0});var nOe=s(nf);Qw=n(nOe,"A",{id:!0,class:!0,href:!0});var Ext=s(Qw);HEe=n(Ext,"SPAN",{});var Cxt=s(HEe);T(ux.$$.fragment,Cxt),Cxt.forEach(t),Ext.forEach(t),wGr=i(nOe),UEe=n(nOe,"SPAN",{});var wxt=s(UEe);AGr=r(wxt,"FlaxAutoModelForNextSentencePrediction"),wxt.forEach(t),nOe.forEach(t),Zje=i(f),Fr=n(f,"DIV",{class:!0});var ii=s(Fr);T(_x.$$.fragment,ii),yGr=i(ii),sf=n(ii,"P",{});var soe=s(sf);LGr=r(soe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),lZ=n(soe,"A",{href:!0});var Axt=s(lZ);xGr=r(Axt,"from_pretrained()"),Axt.forEach(t),$Gr=r(soe," class method or the "),iZ=n(soe,"A",{href:!0});var yxt=s(iZ);kGr=r(yxt,"from_config()"),yxt.forEach(t),SGr=r(soe,` class
method.`),soe.forEach(t),RGr=i(ii),bx=n(ii,"P",{});var sOe=s(bx);PGr=r(sOe,"This class cannot be instantiated directly using "),JEe=n(sOe,"CODE",{});var Lxt=s(JEe);BGr=r(Lxt,"__init__()"),Lxt.forEach(t),IGr=r(sOe," (throws an error)."),sOe.forEach(t),qGr=i(ii),Jt=n(ii,"DIV",{class:!0});var _A=s(Jt);T(vx.$$.fragment,_A),NGr=i(_A),YEe=n(_A,"P",{});var xxt=s(YEe);jGr=r(xxt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),xxt.forEach(t),DGr=i(_A),lf=n(_A,"P",{});var loe=s(lf);GGr=r(loe,`Note:
Loading a model from its configuration file does `),KEe=n(loe,"STRONG",{});var $xt=s(KEe);OGr=r($xt,"not"),$xt.forEach(t),VGr=r(loe,` load the model weights. It only affects the
model\u2019s configuration. Use `),dZ=n(loe,"A",{href:!0});var kxt=s(dZ);XGr=r(kxt,"from_pretrained()"),kxt.forEach(t),zGr=r(loe," to load the model weights."),loe.forEach(t),WGr=i(_A),T(Hw.$$.fragment,_A),_A.forEach(t),QGr=i(ii),Hr=n(ii,"DIV",{class:!0});var di=s(Hr);T(Fx.$$.fragment,di),HGr=i(di),ZEe=n(di,"P",{});var Sxt=s(ZEe);UGr=r(Sxt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Sxt.forEach(t),JGr=i(di),En=n(di,"P",{});var bA=s(En);YGr=r(bA,"The model class to instantiate is selected based on the "),eCe=n(bA,"CODE",{});var Rxt=s(eCe);KGr=r(Rxt,"model_type"),Rxt.forEach(t),ZGr=r(bA,` property of the config object (either
passed as an argument or loaded from `),oCe=n(bA,"CODE",{});var Pxt=s(oCe);eOr=r(Pxt,"pretrained_model_name_or_path"),Pxt.forEach(t),oOr=r(bA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rCe=n(bA,"CODE",{});var Bxt=s(rCe);rOr=r(Bxt,"pretrained_model_name_or_path"),Bxt.forEach(t),tOr=r(bA,":"),bA.forEach(t),aOr=i(di),tCe=n(di,"UL",{});var Ixt=s(tCe);Uw=n(Ixt,"LI",{});var Yqe=s(Uw);aCe=n(Yqe,"STRONG",{});var qxt=s(aCe);nOr=r(qxt,"bert"),qxt.forEach(t),sOr=r(Yqe," \u2014 "),cZ=n(Yqe,"A",{href:!0});var Nxt=s(cZ);lOr=r(Nxt,"FlaxBertForNextSentencePrediction"),Nxt.forEach(t),iOr=r(Yqe," (BERT model)"),Yqe.forEach(t),Ixt.forEach(t),dOr=i(di),T(Jw.$$.fragment,di),di.forEach(t),ii.forEach(t),eDe=i(f),df=n(f,"H2",{class:!0});var lOe=s(df);Yw=n(lOe,"A",{id:!0,class:!0,href:!0});var jxt=s(Yw);nCe=n(jxt,"SPAN",{});var Dxt=s(nCe);T(Tx.$$.fragment,Dxt),Dxt.forEach(t),jxt.forEach(t),cOr=i(lOe),sCe=n(lOe,"SPAN",{});var Gxt=s(sCe);fOr=r(Gxt,"FlaxAutoModelForImageClassification"),Gxt.forEach(t),lOe.forEach(t),oDe=i(f),Tr=n(f,"DIV",{class:!0});var ci=s(Tr);T(Mx.$$.fragment,ci),mOr=i(ci),cf=n(ci,"P",{});var ioe=s(cf);gOr=r(ioe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),fZ=n(ioe,"A",{href:!0});var Oxt=s(fZ);hOr=r(Oxt,"from_pretrained()"),Oxt.forEach(t),pOr=r(ioe," class method or the "),mZ=n(ioe,"A",{href:!0});var Vxt=s(mZ);uOr=r(Vxt,"from_config()"),Vxt.forEach(t),_Or=r(ioe,` class
method.`),ioe.forEach(t),bOr=i(ci),Ex=n(ci,"P",{});var iOe=s(Ex);vOr=r(iOe,"This class cannot be instantiated directly using "),lCe=n(iOe,"CODE",{});var Xxt=s(lCe);FOr=r(Xxt,"__init__()"),Xxt.forEach(t),TOr=r(iOe," (throws an error)."),iOe.forEach(t),MOr=i(ci),Yt=n(ci,"DIV",{class:!0});var vA=s(Yt);T(Cx.$$.fragment,vA),EOr=i(vA),iCe=n(vA,"P",{});var zxt=s(iCe);COr=r(zxt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),zxt.forEach(t),wOr=i(vA),ff=n(vA,"P",{});var doe=s(ff);AOr=r(doe,`Note:
Loading a model from its configuration file does `),dCe=n(doe,"STRONG",{});var Wxt=s(dCe);yOr=r(Wxt,"not"),Wxt.forEach(t),LOr=r(doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=n(doe,"A",{href:!0});var Qxt=s(gZ);xOr=r(Qxt,"from_pretrained()"),Qxt.forEach(t),$Or=r(doe," to load the model weights."),doe.forEach(t),kOr=i(vA),T(Kw.$$.fragment,vA),vA.forEach(t),SOr=i(ci),Ur=n(ci,"DIV",{class:!0});var fi=s(Ur);T(wx.$$.fragment,fi),ROr=i(fi),cCe=n(fi,"P",{});var Hxt=s(cCe);POr=r(Hxt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Hxt.forEach(t),BOr=i(fi),Cn=n(fi,"P",{});var FA=s(Cn);IOr=r(FA,"The model class to instantiate is selected based on the "),fCe=n(FA,"CODE",{});var Uxt=s(fCe);qOr=r(Uxt,"model_type"),Uxt.forEach(t),NOr=r(FA,` property of the config object (either
passed as an argument or loaded from `),mCe=n(FA,"CODE",{});var Jxt=s(mCe);jOr=r(Jxt,"pretrained_model_name_or_path"),Jxt.forEach(t),DOr=r(FA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gCe=n(FA,"CODE",{});var Yxt=s(gCe);GOr=r(Yxt,"pretrained_model_name_or_path"),Yxt.forEach(t),OOr=r(FA,":"),FA.forEach(t),VOr=i(fi),Ax=n(fi,"UL",{});var dOe=s(Ax);Zw=n(dOe,"LI",{});var Kqe=s(Zw);hCe=n(Kqe,"STRONG",{});var Kxt=s(hCe);XOr=r(Kxt,"beit"),Kxt.forEach(t),zOr=r(Kqe," \u2014 "),hZ=n(Kqe,"A",{href:!0});var Zxt=s(hZ);WOr=r(Zxt,"FlaxBeitForImageClassification"),Zxt.forEach(t),QOr=r(Kqe," (BEiT model)"),Kqe.forEach(t),HOr=i(dOe),e0=n(dOe,"LI",{});var Zqe=s(e0);pCe=n(Zqe,"STRONG",{});var e$t=s(pCe);UOr=r(e$t,"vit"),e$t.forEach(t),JOr=r(Zqe," \u2014 "),pZ=n(Zqe,"A",{href:!0});var o$t=s(pZ);YOr=r(o$t,"FlaxViTForImageClassification"),o$t.forEach(t),KOr=r(Zqe," (ViT model)"),Zqe.forEach(t),dOe.forEach(t),ZOr=i(fi),T(o0.$$.fragment,fi),fi.forEach(t),ci.forEach(t),rDe=i(f),mf=n(f,"H2",{class:!0});var cOe=s(mf);r0=n(cOe,"A",{id:!0,class:!0,href:!0});var r$t=s(r0);uCe=n(r$t,"SPAN",{});var t$t=s(uCe);T(yx.$$.fragment,t$t),t$t.forEach(t),r$t.forEach(t),eVr=i(cOe),_Ce=n(cOe,"SPAN",{});var a$t=s(_Ce);oVr=r(a$t,"FlaxAutoModelForVision2Seq"),a$t.forEach(t),cOe.forEach(t),tDe=i(f),Mr=n(f,"DIV",{class:!0});var mi=s(Mr);T(Lx.$$.fragment,mi),rVr=i(mi),gf=n(mi,"P",{});var coe=s(gf);tVr=r(coe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),uZ=n(coe,"A",{href:!0});var n$t=s(uZ);aVr=r(n$t,"from_pretrained()"),n$t.forEach(t),nVr=r(coe," class method or the "),_Z=n(coe,"A",{href:!0});var s$t=s(_Z);sVr=r(s$t,"from_config()"),s$t.forEach(t),lVr=r(coe,` class
method.`),coe.forEach(t),iVr=i(mi),xx=n(mi,"P",{});var fOe=s(xx);dVr=r(fOe,"This class cannot be instantiated directly using "),bCe=n(fOe,"CODE",{});var l$t=s(bCe);cVr=r(l$t,"__init__()"),l$t.forEach(t),fVr=r(fOe," (throws an error)."),fOe.forEach(t),mVr=i(mi),Kt=n(mi,"DIV",{class:!0});var TA=s(Kt);T($x.$$.fragment,TA),gVr=i(TA),vCe=n(TA,"P",{});var i$t=s(vCe);hVr=r(i$t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),i$t.forEach(t),pVr=i(TA),hf=n(TA,"P",{});var foe=s(hf);uVr=r(foe,`Note:
Loading a model from its configuration file does `),FCe=n(foe,"STRONG",{});var d$t=s(FCe);_Vr=r(d$t,"not"),d$t.forEach(t),bVr=r(foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),bZ=n(foe,"A",{href:!0});var c$t=s(bZ);vVr=r(c$t,"from_pretrained()"),c$t.forEach(t),FVr=r(foe," to load the model weights."),foe.forEach(t),TVr=i(TA),T(t0.$$.fragment,TA),TA.forEach(t),MVr=i(mi),Jr=n(mi,"DIV",{class:!0});var gi=s(Jr);T(kx.$$.fragment,gi),EVr=i(gi),TCe=n(gi,"P",{});var f$t=s(TCe);CVr=r(f$t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),f$t.forEach(t),wVr=i(gi),wn=n(gi,"P",{});var MA=s(wn);AVr=r(MA,"The model class to instantiate is selected based on the "),MCe=n(MA,"CODE",{});var m$t=s(MCe);yVr=r(m$t,"model_type"),m$t.forEach(t),LVr=r(MA,` property of the config object (either
passed as an argument or loaded from `),ECe=n(MA,"CODE",{});var g$t=s(ECe);xVr=r(g$t,"pretrained_model_name_or_path"),g$t.forEach(t),$Vr=r(MA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CCe=n(MA,"CODE",{});var h$t=s(CCe);kVr=r(h$t,"pretrained_model_name_or_path"),h$t.forEach(t),SVr=r(MA,":"),MA.forEach(t),RVr=i(gi),wCe=n(gi,"UL",{});var p$t=s(wCe);a0=n(p$t,"LI",{});var eNe=s(a0);ACe=n(eNe,"STRONG",{});var u$t=s(ACe);PVr=r(u$t,"vision-encoder-decoder"),u$t.forEach(t),BVr=r(eNe," \u2014 "),vZ=n(eNe,"A",{href:!0});var _$t=s(vZ);IVr=r(_$t,"FlaxVisionEncoderDecoderModel"),_$t.forEach(t),qVr=r(eNe," (Vision Encoder decoder model)"),eNe.forEach(t),p$t.forEach(t),NVr=i(gi),T(n0.$$.fragment,gi),gi.forEach(t),mi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(TSt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(yn,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoConfig"),c(xn,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoModel"),c($n,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoTokenizer"),c(Fi,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertModel"),c(Mf,"id","extending-the-auto-classes"),c(Mf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mf,"href","#extending-the-auto-classes"),c(Ti,"class","relative group"),c(Cf,"id","transformers.AutoConfig"),c(Cf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Cf,"href","#transformers.AutoConfig"),c(Mi,"class","relative group"),c(ek,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(ok,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertConfig"),c(rk,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartConfig"),c(tk,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitConfig"),c(ak,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertConfig"),c(nk,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(sk,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdConfig"),c(lk,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(ik,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(dk,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(ck,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertConfig"),c(fk,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineConfig"),c(mk,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPConfig"),c(gk,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertConfig"),c(hk,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextConfig"),c(pk,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLConfig"),c(uk,"href","/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtConfig"),c(_k,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(bk,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(vk,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(Fk,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaConfig"),c(Tk,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(Mk,"href","/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(Ek,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTConfig"),c(Ck,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrConfig"),c(wk,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertConfig"),c(Ak,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRConfig"),c(yk,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTConfig"),c(Lk,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraConfig"),c(xk,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c($k,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertConfig"),c(kk,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaConfig"),c(Sk,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetConfig"),c(Rk,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTConfig"),c(Pk,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelConfig"),c(Bk,"href","/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNConfig"),c(Ik,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Config"),c(qk,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(Nk,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(jk,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJConfig"),c(Dk,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertConfig"),c(Gk,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertConfig"),c(Ok,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(Vk,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Xk,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(zk,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(Wk,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDConfig"),c(Qk,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerConfig"),c(Hk,"href","/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeConfig"),c(Uk,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertConfig"),c(Jk,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Config"),c(Yk,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianConfig"),c(Kk,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(Zk,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartConfig"),c(eS,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(oS,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(rS,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetConfig"),c(tS,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Config"),c(aS,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(nS,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(sS,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTConfig"),c(lS,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusConfig"),c(iS,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverConfig"),c(dS,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartConfig"),c(cS,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(fS,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(mS,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(gS,"href","/docs/transformers/pr_17254/en/model_doc/rag#transformers.RagConfig"),c(hS,"href","/docs/transformers/pr_17254/en/model_doc/realm#transformers.RealmConfig"),c(pS,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerConfig"),c(uS,"href","/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetConfig"),c(_S,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertConfig"),c(bS,"href","/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetConfig"),c(vS,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertConfig"),c(FS,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaConfig"),c(TS,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerConfig"),c(MS,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerConfig"),c(ES,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWConfig"),c(CS,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDConfig"),c(wS,"href","/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(AS,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(yS,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(LS,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterConfig"),c(xS,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c($S,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinConfig"),c(kS,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Config"),c(SS,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasConfig"),c(RS,"href","/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(PS,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(BS,"href","/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRConfig"),c(IS,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(qS,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(NS,"href","/docs/transformers/pr_17254/en/model_doc/van#transformers.VanConfig"),c(jS,"href","/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltConfig"),c(DS,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(GS,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(OS,"href","/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(VS,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTConfig"),c(XS,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(zS,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(WS,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(QS,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMConfig"),c(HS,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMConfig"),c(US,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMConfig"),c(JS,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(YS,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(KS,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(ZS,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetConfig"),c(eR,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosConfig"),c(oR,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lg,"id","transformers.AutoTokenizer"),c(Lg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lg,"href","#transformers.AutoTokenizer"),c(Ci,"class","relative group"),c(rR,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(tR,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizer"),c(aR,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(nR,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartTokenizer"),c(sR,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartTokenizerFast"),c(lR,"href","/docs/transformers/pr_17254/en/model_doc/barthez#transformers.BarthezTokenizer"),c(iR,"href","/docs/transformers/pr_17254/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(dR,"href","/docs/transformers/pr_17254/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(cR,"href","/docs/transformers/pr_17254/en/model_doc/bartpho#transformers.BartphoTokenizerFast"),c(fR,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(mR,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(gR,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(hR,"href","/docs/transformers/pr_17254/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(pR,"href","/docs/transformers/pr_17254/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(uR,"href","/docs/transformers/pr_17254/en/model_doc/bertweet#transformers.BertweetTokenizerFast"),c(_R,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(bR,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(vR,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(FR,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(TR,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(MR,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(ER,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(CR,"href","/docs/transformers/pr_17254/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(wR,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertTokenizer"),c(AR,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(yR,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineTokenizer"),c(LR,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPTokenizer"),c(xR,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPTokenizerFast"),c($R,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(kR,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(SR,"href","/docs/transformers/pr_17254/en/model_doc/cpm#transformers.CpmTokenizer"),c(RR,"href","/docs/transformers/pr_17254/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(PR,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(BR,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(IR,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(qR,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaTokenizer"),c(NR,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(jR,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(DR,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(GR,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(OR,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(VR,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(XR,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(zR,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraTokenizer"),c(WR,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(QR,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(HR,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetTokenizer"),c(UR,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(JR,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(YR,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelTokenizer"),c(KR,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(ZR,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(eP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(oP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(rP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(tP,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(aP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(nP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(sP,"href","/docs/transformers/pr_17254/en/model_doc/herbert#transformers.HerbertTokenizer"),c(lP,"href","/docs/transformers/pr_17254/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(iP,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(dP,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(cP,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(fP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(mP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(gP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(hP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(pP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(uP,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(_P,"href","/docs/transformers/pr_17254/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(bP,"href","/docs/transformers/pr_17254/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(vP,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDTokenizer"),c(FP,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDTokenizerFast"),c(TP,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerTokenizer"),c(MP,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(EP,"href","/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeTokenizer"),c(CP,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(wP,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(AP,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(yP,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianTokenizer"),c(LP,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartTokenizer"),c(xP,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartTokenizerFast"),c($P,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(kP,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(SP,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(RP,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(PP,"href","/docs/transformers/pr_17254/en/model_doc/mluke#transformers.MLukeTokenizer"),c(BP,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(IP,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(qP,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(NP,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(jP,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Tokenizer"),c(DP,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5TokenizerFast"),c(GP,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizer"),c(OP,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(VP,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(XP,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(zP,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(WP,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(QP,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(HP,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(UP,"href","/docs/transformers/pr_17254/en/model_doc/phobert#transformers.PhobertTokenizer"),c(JP,"href","/docs/transformers/pr_17254/en/model_doc/phobert#transformers.PhobertTokenizerFast"),c(YP,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartTokenizer"),c(KP,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(ZP,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(eB,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(oB,"href","/docs/transformers/pr_17254/en/model_doc/rag#transformers.RagTokenizer"),c(rB,"href","/docs/transformers/pr_17254/en/model_doc/realm#transformers.RealmTokenizer"),c(tB,"href","/docs/transformers/pr_17254/en/model_doc/realm#transformers.RealmTokenizerFast"),c(aB,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerTokenizer"),c(nB,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(sB,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertTokenizer"),c(lB,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(iB,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(dB,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(cB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(fB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(mB,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(gB,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(hB,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(pB,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(uB,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterTokenizer"),c(_B,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(bB,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(vB,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Tokenizer"),c(TB,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5TokenizerFast"),c(MB,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasTokenizer"),c(EB,"href","/docs/transformers/pr_17254/en/model_doc/tapex#transformers.TapexTokenizer"),c(CB,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(wB,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizer"),c(AB,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertTokenizerFast"),c(yB,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(LB,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(xB,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c($B,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMTokenizer"),c(kB,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(SB,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMTokenizer"),c(RB,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(PB,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(BB,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(IB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizer"),c(qB,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(NB,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(jB,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(DB,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizer"),c(GB,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sh,"id","transformers.AutoFeatureExtractor"),c(sh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sh,"href","#transformers.AutoFeatureExtractor"),c(wi,"class","relative group"),c(OB,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(VB,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(XB,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(zB,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(WB,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(QB,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(HB,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(UB,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(JB,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(YB,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(KB,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(ZB,"href","/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(eI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(oI,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(rI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(tI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(aI,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(nI,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(sI,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(lI,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(iI,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dI,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(cI,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(fI,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(mI,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(gI,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(hI,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(pI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(uI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(_I,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jh,"id","transformers.AutoProcessor"),c(jh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jh,"href","#transformers.AutoProcessor"),c(Ai,"class","relative group"),c(bI,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(vI,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPProcessor"),c(FI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(TI,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(MI,"href","/docs/transformers/pr_17254/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(EI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(CI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(wI,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(AI,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(yI,"href","/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRProcessor"),c(LI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(xI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c($I,"href","/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltProcessor"),c(kI,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(SI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(RI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(PI,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(np,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sp,"id","transformers.AutoModel"),c(sp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sp,"href","#transformers.AutoModel"),c(Li,"class","relative group"),c(BI,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(II,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qI,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NI,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertModel"),c(jI,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartModel"),c(DI,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitModel"),c(GI,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertModel"),c(OI,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(VI,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdModel"),c(XI,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(zI,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(WI,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(QI,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertModel"),c(HI,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineModel"),c(UI,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.CLIPModel"),c(JI,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertModel"),c(YI,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextModel"),c(KI,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLModel"),c(ZI,"href","/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtModel"),c(eq,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(oq,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(rq,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(tq,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaModel"),c(aq,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(nq,"href","/docs/transformers/pr_17254/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(sq,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTModel"),c(lq,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrModel"),c(iq,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertModel"),c(dq,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(cq,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTModel"),c(fq,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraModel"),c(mq,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertModel"),c(gq,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaModel"),c(hq,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetModel"),c(pq,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTModel"),c(uq,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelModel"),c(_q,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelBaseModel"),c(bq,"href","/docs/transformers/pr_17254/en/model_doc/glpn#transformers.GLPNModel"),c(vq,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2Model"),c(Fq,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Tq,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Mq,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJModel"),c(Eq,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertModel"),c(Cq,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertModel"),c(wq,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Aq,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(yq,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Lq,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(xq,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDModel"),c($q,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerModel"),c(kq,"href","/docs/transformers/pr_17254/en/model_doc/luke#transformers.LukeModel"),c(Sq,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertModel"),c(Rq,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100Model"),c(Pq,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianModel"),c(Bq,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerModel"),c(Iq,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartModel"),c(qq,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(Nq,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertModel"),c(jq,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetModel"),c(Dq,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5Model"),c(Gq,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerModel"),c(Oq,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(Vq,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTModel"),c(Xq,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusModel"),c(zq,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverModel"),c(Wq,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartModel"),c(Qq,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerModel"),c(Hq,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Uq,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Jq,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModel"),c(Yq,"href","/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetModel"),c(Kq,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertModel"),c(Zq,"href","/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetModel"),c(eN,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel"),c(oN,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaModel"),c(rN,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerModel"),c(tN,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerModel"),c(aN,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWModel"),c(nN,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDModel"),c(sN,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(lN,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterModel"),c(iN,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(dN,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinModel"),c(cN,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5Model"),c(fN,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasModel"),c(mN,"href","/docs/transformers/pr_17254/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(gN,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(hN,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechModel"),c(pN,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(uN,"href","/docs/transformers/pr_17254/en/model_doc/van#transformers.VanModel"),c(_N,"href","/docs/transformers/pr_17254/en/model_doc/vilt#transformers.ViltModel"),c(bN,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(vN,"href","/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertModel"),c(FN,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTModel"),c(TN,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(MN,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(EN,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(CN,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMModel"),c(wN,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMModel"),c(AN,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMModel"),c(yN,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(LN,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(xN,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c($N,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetModel"),c(kN,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosModel"),c(SN,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t_,"id","transformers.AutoModelForPreTraining"),c(t_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t_,"href","#transformers.AutoModelForPreTraining"),c(ki,"class","relative group"),c(RN,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PN,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BN,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IN,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForPreTraining"),c(qN,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(NN,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForPreTraining"),c(jN,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(DN,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(GN,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(ON,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(VN,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(XN,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(zN,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(WN,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForPreTraining"),c(QN,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(HN,"href","/docs/transformers/pr_17254/en/model_doc/flava#transformers.FlavaForPreTraining"),c(UN,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForPreTraining"),c(JN,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(YN,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(KN,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(ZN,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(ej,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(oj,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(rj,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(tj,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(aj,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(nj,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(sj,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(lj,"href","/docs/transformers/pr_17254/en/model_doc/retribert#transformers.RetriBertModel"),c(ij,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(dj,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(cj,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(fj,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(mj,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(gj,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(hj,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(pj,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(uj,"href","/docs/transformers/pr_17254/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(_j,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(bj,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(vj,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(Fj,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(Tj,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(Mj,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(Ej,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U_,"id","transformers.AutoModelForCausalLM"),c(U_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U_,"href","#transformers.AutoModelForCausalLM"),c(Pi,"class","relative group"),c(Cj,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wj,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aj,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yj,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForCausalLM"),c(Lj,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertLMHeadModel"),c(xj,"href","/docs/transformers/pr_17254/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c($j,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(kj,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Sj,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Rj,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(Pj,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(Bj,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Ij,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(qj,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Nj,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(jj,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Dj,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(Gj,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(Oj,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianForCausalLM"),c(Vj,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Xj,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(zj,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Wj,"href","/docs/transformers/pr_17254/en/model_doc/opt#transformers.OPTForCausalLM"),c(Qj,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Hj,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(Uj,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(Jj,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(Yj,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(Kj,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(Zj,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(eD,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(oD,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(rD,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(tD,"href","/docs/transformers/pr_17254/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(aD,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(nD,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(sD,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(lD,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(iD,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(dD,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I2,"id","transformers.AutoModelForMaskedLM"),c(I2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I2,"href","#transformers.AutoModelForMaskedLM"),c(qi,"class","relative group"),c(cD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gD,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(hD,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(pD,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMaskedLM"),c(uD,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(_D,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(vD,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(FD,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(TD,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(MD,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(ED,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(CD,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(wD,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(AD,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(yD,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(LD,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(xD,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c($D,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(kD,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(SD,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(RD,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(PD,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(BD,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(ID,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(qD,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(ND,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(jD,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(DD,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(GD,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(OD,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(VD,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(XD,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(zD,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(WD,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T1,"id","transformers.AutoModelForSeq2SeqLM"),c(T1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T1,"href","#transformers.AutoModelForSeq2SeqLM"),c(Di,"class","relative group"),c(QD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UD,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JD,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(YD,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(KD,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(ZD,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(eG,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(oG,"href","/docs/transformers/pr_17254/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(rG,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(tG,"href","/docs/transformers/pr_17254/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(aG,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.MarianMTModel"),c(nG,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(sG,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(lG,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(iG,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(dG,"href","/docs/transformers/pr_17254/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(cG,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(fG,"href","/docs/transformers/pr_17254/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G1,"id","transformers.AutoModelForSequenceClassification"),c(G1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G1,"href","#transformers.AutoModelForSequenceClassification"),c(Vi,"class","relative group"),c(mG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hG,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pG,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(uG,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForSequenceClassification"),c(_G,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForSequenceClassification"),c(bG,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(vG,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(FG,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(TG,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(MG,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(EG,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(CG,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(wG,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(AG,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(yG,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(LG,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(xG,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c($G,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(kG,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(SG,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(RG,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(PG,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(BG,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(IG,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(qG,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(NG,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(jG,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForSequenceClassification"),c(DG,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(GG,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(OG,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(VG,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(XG,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(zG,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(WG,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(QG,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(HG,"href","/docs/transformers/pr_17254/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(UG,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(JG,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(YG,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(KG,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(ZG,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(eO,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(oO,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(rO,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(tO,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(aO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(nO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(sO,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(lO,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nb,"id","transformers.AutoModelForMultipleChoice"),c(Nb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nb,"href","#transformers.AutoModelForMultipleChoice"),c(Wi,"class","relative group"),c(iO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fO,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(mO,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForMultipleChoice"),c(gO,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(hO,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(pO,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(uO,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(_O,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(bO,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(vO,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(FO,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(TO,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(MO,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(EO,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(CO,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(wO,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(AO,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(yO,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(LO,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(xO,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c($O,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(kO,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(SO,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(RO,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(PO,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(BO,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(IO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(qO,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(NO,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(jO,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_4,"id","transformers.AutoModelForNextSentencePrediction"),c(_4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_4,"href","#transformers.AutoModelForNextSentencePrediction"),c(Ui,"class","relative group"),c(DO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VO,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(XO,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(zO,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(WO,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(QO,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A4,"id","transformers.AutoModelForTokenClassification"),c(A4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A4,"href","#transformers.AutoModelForTokenClassification"),c(Ki,"class","relative group"),c(HO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JO,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YO,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(KO,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForTokenClassification"),c(ZO,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(eV,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(oV,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForTokenClassification"),c(rV,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(tV,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(aV,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(nV,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(sV,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(lV,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(iV,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(dV,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(cV,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(fV,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(mV,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(gV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(hV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(pV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(uV,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(_V,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(bV,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(vV,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(FV,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(TV,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(MV,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(EV,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(CV,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(wV,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(AV,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(yV,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(LV,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(xV,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c($V,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cv,"id","transformers.AutoModelForQuestionAnswering"),c(cv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cv,"href","#transformers.AutoModelForQuestionAnswering"),c(od,"class","relative group"),c(kV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RV,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PV,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(BV,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(IV,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(qV,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(NV,"href","/docs/transformers/pr_17254/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(jV,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(DV,"href","/docs/transformers/pr_17254/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(GV,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(OV,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(VV,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(XV,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(zV,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(WV,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(QV,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(HV,"href","/docs/transformers/pr_17254/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(UV,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(JV,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(YV,"href","/docs/transformers/pr_17254/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(KV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(ZV,"href","/docs/transformers/pr_17254/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(eX,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(oX,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(rX,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(tX,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(aX,"href","/docs/transformers/pr_17254/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(nX,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(sX,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(lX,"href","/docs/transformers/pr_17254/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(iX,"href","/docs/transformers/pr_17254/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(dX,"href","/docs/transformers/pr_17254/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(cX,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(fX,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(mX,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(gX,"href","/docs/transformers/pr_17254/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(hX,"href","/docs/transformers/pr_17254/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(pX,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(uX,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(_X,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(bX,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(vX,"href","/docs/transformers/pr_17254/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e5,"id","transformers.AutoModelForTableQuestionAnswering"),c(e5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e5,"href","#transformers.AutoModelForTableQuestionAnswering"),c(ad,"class","relative group"),c(FX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EX,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n5,"id","transformers.AutoModelForImageClassification"),c(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n5,"href","#transformers.AutoModelForImageClassification"),c(ld,"class","relative group"),c(CX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yX,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForImageClassification"),c(LX,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(xX,"href","/docs/transformers/pr_17254/en/model_doc/cvt#transformers.CvtForImageClassification"),c($X,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(kX,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassification"),c(SX,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(RX,"href","/docs/transformers/pr_17254/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(PX,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(BX,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(IX,"href","/docs/transformers/pr_17254/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(qX,"href","/docs/transformers/pr_17254/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(NX,"href","/docs/transformers/pr_17254/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(jX,"href","/docs/transformers/pr_17254/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(DX,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(GX,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForImageClassification"),c(OX,"href","/docs/transformers/pr_17254/en/model_doc/van#transformers.VanForImageClassification"),c(VX,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T5,"id","transformers.AutoModelForVision2Seq"),c(T5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T5,"href","#transformers.AutoModelForVision2Seq"),c(cd,"class","relative group"),c(XX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QX,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A5,"id","transformers.AutoModelForAudioClassification"),c(A5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A5,"href","#transformers.AutoModelForAudioClassification"),c(gd,"class","relative group"),c(HX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JX,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YX,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(KX,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(ZX,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(ez,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(oz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(rz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(tz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(az,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(nz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j5,"id","transformers.AutoModelForAudioFrameClassification"),c(j5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j5,"href","#transformers.AutoModelForAudioFrameClassification"),c(ud,"class","relative group"),c(sz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dz,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(cz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(fz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(mz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(gz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H5,"id","transformers.AutoModelForCTC"),c(H5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H5,"href","#transformers.AutoModelForCTC"),c(vd,"class","relative group"),c(hz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_z,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(bz,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.HubertForCTC"),c(vz,"href","/docs/transformers/pr_17254/en/model_doc/sew#transformers.SEWForCTC"),c(Fz,"href","/docs/transformers/pr_17254/en/model_doc/sew-d#transformers.SEWDForCTC"),c(Tz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(Mz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(Ez,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(Cz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(wz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForCTC"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(lF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Md,"class","relative group"),c(Az,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Lz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xz,"href","/docs/transformers/pr_17254/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c($z,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gF,"id","transformers.AutoModelForAudioXVector"),c(gF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gF,"href","#transformers.AutoModelForAudioXVector"),c(wd,"class","relative group"),c(kz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Sz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Rz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pz,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(Bz,"href","/docs/transformers/pr_17254/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(Iz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(qz,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(Nz,"href","/docs/transformers/pr_17254/en/model_doc/wavlm#transformers.WavLMForXVector"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MF,"id","transformers.AutoModelForMaskedImageModeling"),c(MF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(MF,"href","#transformers.AutoModelForMaskedImageModeling"),c(Ld,"class","relative group"),c(jz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oz,"href","/docs/transformers/pr_17254/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(Vz,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(Xz,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xF,"id","transformers.AutoModelForObjectDetection"),c(xF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xF,"href","#transformers.AutoModelForObjectDetection"),c(Sd,"class","relative group"),c(zz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hz,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForObjectDetection"),c(Uz,"href","/docs/transformers/pr_17254/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BF,"id","transformers.AutoModelForImageSegmentation"),c(BF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BF,"href","#transformers.AutoModelForImageSegmentation"),c(Bd,"class","relative group"),c(Jz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kz,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zz,"href","/docs/transformers/pr_17254/en/model_doc/detr#transformers.DetrForSegmentation"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DF,"id","transformers.AutoModelForSemanticSegmentation"),c(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DF,"href","#transformers.AutoModelForSemanticSegmentation"),c(Nd,"class","relative group"),c(eW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tW,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(aW,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(nW,"href","/docs/transformers/pr_17254/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(sW,"href","/docs/transformers/pr_17254/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HF,"id","transformers.AutoModelForInstanceSegmentation"),c(HF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(HF,"href","#transformers.AutoModelForInstanceSegmentation"),c(Gd,"class","relative group"),c(lW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cW,"href","/docs/transformers/pr_17254/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZF,"id","transformers.TFAutoModel"),c(ZF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZF,"href","#transformers.TFAutoModel"),c(Xd,"class","relative group"),c(fW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gW,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hW,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertModel"),c(pW,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartModel"),c(uW,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertModel"),c(_W,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(bW,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(vW,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertModel"),c(FW,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.TFCLIPModel"),c(TW,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertModel"),c(MW,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextModel"),c(EW,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLModel"),c(CW,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(wW,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaModel"),c(AW,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(yW,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(LW,"href","/docs/transformers/pr_17254/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(xW,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraModel"),c($W,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(kW,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelModel"),c(SW,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(RW,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2Model"),c(PW,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJModel"),c(BW,"href","/docs/transformers/pr_17254/en/model_doc/hubert#transformers.TFHubertModel"),c(IW,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(qW,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDModel"),c(NW,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerModel"),c(jW,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertModel"),c(DW,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianModel"),c(GW,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartModel"),c(OW,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(VW,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetModel"),c(XW,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5Model"),c(zW,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(WW,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusModel"),c(QW,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertModel"),c(HW,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaModel"),c(UW,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerModel"),c(JW,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(YW,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinModel"),c(KW,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5Model"),c(ZW,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasModel"),c(eQ,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(oQ,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTModel"),c(rQ,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(tQ,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(aQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMModel"),c(nQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(sQ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QT,"id","transformers.TFAutoModelForPreTraining"),c(QT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QT,"href","#transformers.TFAutoModelForPreTraining"),c(Qd,"class","relative group"),c(lQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cQ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(fQ,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(mQ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForPreTraining"),c(gQ,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(hQ,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(pQ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(uQ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(_Q,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(bQ,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(vQ,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(FQ,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(TQ,"href","/docs/transformers/pr_17254/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(MQ,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(EQ,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(CQ,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(wQ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(AQ,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(yQ,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(LQ,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(xQ,"href","/docs/transformers/pr_17254/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c($Q,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(kQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(SQ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v7,"id","transformers.TFAutoModelForCausalLM"),c(v7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v7,"href","#transformers.TFAutoModelForCausalLM"),c(Jd,"class","relative group"),c(RQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IQ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(qQ,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(NQ,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(jQ,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(DQ,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(GQ,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(OQ,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(VQ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(XQ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(zQ,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(WQ,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(QQ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P7,"id","transformers.TFAutoModelForImageClassification"),c(P7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P7,"href","#transformers.TFAutoModelForImageClassification"),c(Zd,"class","relative group"),c(HQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JQ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YQ,"href","/docs/transformers/pr_17254/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(KQ,"href","/docs/transformers/pr_17254/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(ZQ,"href","/docs/transformers/pr_17254/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(eH,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G7,"id","transformers.TFAutoModelForMaskedLM"),c(G7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G7,"href","#transformers.TFAutoModelForMaskedLM"),c(rc,"class","relative group"),c(oH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aH,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(nH,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(sH,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(lH,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(iH,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(dH,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(cH,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(fH,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(mH,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(gH,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(hH,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(pH,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(uH,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(_H,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(bH,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(vH,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(FH,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(TH,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(MH,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(EH,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cM,"id","transformers.TFAutoModelForSeq2SeqLM"),c(cM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cM,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(nc,"class","relative group"),c(CH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yH,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(LH,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(xH,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c($H,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(kH,"href","/docs/transformers/pr_17254/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(SH,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.TFMarianMTModel"),c(RH,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(PH,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(BH,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(IH,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EM,"id","transformers.TFAutoModelForSequenceClassification"),c(EM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EM,"href","#transformers.TFAutoModelForSequenceClassification"),c(ic,"class","relative group"),c(qH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jH,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DH,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(GH,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(OH,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(VH,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(XH,"href","/docs/transformers/pr_17254/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(zH,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(WH,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(QH,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(HH,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(UH,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(JH,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(YH,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(KH,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(ZH,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(eU,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(oU,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(rU,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(tU,"href","/docs/transformers/pr_17254/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(aU,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(nU,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(sU,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(lU,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(iU,"href","/docs/transformers/pr_17254/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(dU,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(cU,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(fU,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KM,"id","transformers.TFAutoModelForMultipleChoice"),c(KM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KM,"href","#transformers.TFAutoModelForMultipleChoice"),c(fc,"class","relative group"),c(mU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pU,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(uU,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(_U,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(bU,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(vU,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(FU,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(TU,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(MU,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(EU,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(CU,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(wU,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(AU,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(yU,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(LU,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(xU,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c($U,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(kU,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bE,"id","transformers.TFAutoModelForNextSentencePrediction"),c(bE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bE,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(hc,"class","relative group"),c(SU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BU,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(IU,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EE,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(EE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EE,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(_c,"class","relative group"),c(qU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DU,"href","/docs/transformers/pr_17254/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yE,"id","transformers.TFAutoModelForTokenClassification"),c(yE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yE,"href","#transformers.TFAutoModelForTokenClassification"),c(Fc,"class","relative group"),c(GU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(zU,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(WU,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(QU,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(HU,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(UU,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(JU,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(YU,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(KU,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(ZU,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(eJ,"href","/docs/transformers/pr_17254/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(oJ,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(rJ,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(tJ,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(aJ,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(nJ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(sJ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(lJ,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(iJ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(dJ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JE,"id","transformers.TFAutoModelForQuestionAnswering"),c(JE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JE,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Ec,"class","relative group"),c(cJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gJ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(hJ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(pJ,"href","/docs/transformers/pr_17254/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(uJ,"href","/docs/transformers/pr_17254/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(_J,"href","/docs/transformers/pr_17254/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(bJ,"href","/docs/transformers/pr_17254/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(vJ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(FJ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(TJ,"href","/docs/transformers/pr_17254/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(MJ,"href","/docs/transformers/pr_17254/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(EJ,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(CJ,"href","/docs/transformers/pr_17254/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(wJ,"href","/docs/transformers/pr_17254/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(AJ,"href","/docs/transformers/pr_17254/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(yJ,"href","/docs/transformers/pr_17254/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(LJ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(xJ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c($J,"href","/docs/transformers/pr_17254/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(kJ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(SJ,"href","/docs/transformers/pr_17254/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vC,"id","transformers.TFAutoModelForVision2Seq"),c(vC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vC,"href","#transformers.TFAutoModelForVision2Seq"),c(Ac,"class","relative group"),c(RJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IJ,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EC,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(EC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EC,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(xc,"class","relative group"),c(qJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DJ,"href","/docs/transformers/pr_17254/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yC,"id","transformers.FlaxAutoModel"),c(yC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yC,"href","#transformers.FlaxAutoModel"),c(Sc,"class","relative group"),c(GJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VJ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XJ,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertModel"),c(zJ,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartModel"),c(WJ,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitModel"),c(QJ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertModel"),c(HJ,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(UJ,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(JJ,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(YJ,"href","/docs/transformers/pr_17254/en/model_doc/clip#transformers.FlaxCLIPModel"),c(KJ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(ZJ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraModel"),c(eY,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(oY,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(rY,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(tY,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianModel"),c(aY,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartModel"),c(nY,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5Model"),c(sY,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(lY,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(iY,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(dY,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5Model"),c(cY,"href","/docs/transformers/pr_17254/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(fY,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTModel"),c(mY,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(gY,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(hY,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o3,"id","transformers.FlaxAutoModelForCausalLM"),c(o3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o3,"href","#transformers.FlaxAutoModelForCausalLM"),c(Bc,"class","relative group"),c(pY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_Y,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bY,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(vY,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(FY,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(TY,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(MY,"href","/docs/transformers/pr_17254/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(EY,"href","/docs/transformers/pr_17254/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(CY,"href","/docs/transformers/pr_17254/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(wY,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(AY,"href","/docs/transformers/pr_17254/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g3,"id","transformers.FlaxAutoModelForPreTraining"),c(g3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g3,"href","#transformers.FlaxAutoModelForPreTraining"),c(Nc,"class","relative group"),c(yY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($Y,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(kY,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(SY,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(RY,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(PY,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(BY,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(IY,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(qY,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(NY,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(jY,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(DY,"href","/docs/transformers/pr_17254/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(GY,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L3,"id","transformers.FlaxAutoModelForMaskedLM"),c(L3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L3,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Gc,"class","relative group"),c(OY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XY,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zY,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(WY,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(QY,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(HY,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(UY,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(JY,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(YY,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(KY,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(ZY,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(eK,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G3,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(G3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G3,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Xc,"class","relative group"),c(oK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aK,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(nK,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(sK,"href","/docs/transformers/pr_17254/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(lK,"href","/docs/transformers/pr_17254/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(iK,"href","/docs/transformers/pr_17254/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(dK,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(cK,"href","/docs/transformers/pr_17254/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(fK,"href","/docs/transformers/pr_17254/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(mK,"href","/docs/transformers/pr_17254/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z3,"id","transformers.FlaxAutoModelForSequenceClassification"),c(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z3,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Qc,"class","relative group"),c(gK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uK,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(_K,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(bK,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(vK,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(FK,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(TK,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(MK,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(EK,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(CK,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(wK,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mw,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(mw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mw,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Jc,"class","relative group"),c(AK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c($K,"href","/docs/transformers/pr_17254/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(kK,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(SK,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(RK,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(PK,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(BK,"href","/docs/transformers/pr_17254/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(IK,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(qK,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(NK,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ww,"id","transformers.FlaxAutoModelForTokenClassification"),c(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ww,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Zc,"class","relative group"),c(jK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OK,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(VK,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(XK,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(zK,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(WK,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(QK,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(HK,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(UK,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(Iw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Iw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(rf,"class","relative group"),c(JK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KK,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZK,"href","/docs/transformers/pr_17254/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(eZ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(oZ,"href","/docs/transformers/pr_17254/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(rZ,"href","/docs/transformers/pr_17254/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(tZ,"href","/docs/transformers/pr_17254/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(aZ,"href","/docs/transformers/pr_17254/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(nZ,"href","/docs/transformers/pr_17254/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(sZ,"href","/docs/transformers/pr_17254/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Qw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(nf,"class","relative group"),c(lZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cZ,"href","/docs/transformers/pr_17254/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yw,"id","transformers.FlaxAutoModelForImageClassification"),c(Yw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yw,"href","#transformers.FlaxAutoModelForImageClassification"),c(df,"class","relative group"),c(fZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hZ,"href","/docs/transformers/pr_17254/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(pZ,"href","/docs/transformers/pr_17254/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r0,"id","transformers.FlaxAutoModelForVision2Seq"),c(r0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r0,"href","#transformers.FlaxAutoModelForVision2Seq"),c(mf,"class","relative group"),c(uZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_Z,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bZ,"href","/docs/transformers/pr_17254/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vZ,"href","/docs/transformers/pr_17254/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Mo),e(Mo,hi),b(f,bf,_),b(f,rt,_),e(rt,pi),e(rt,ui),e(ui,EA),e(rt,vf),b(f,je,_),b(f,We,_),e(We,_i),e(We,yn),e(yn,CA),e(We,Ln),e(We,xn),e(xn,wA),e(We,bi),e(We,$n),e($n,AA),e(We,vi),b(f,Ff,_),M(Ca,f,_),b(f,Qe,_),b(f,Ae,_),e(Ae,H$),e(Ae,Fi),e(Fi,U$),e(Ae,J$),b(f,Eo,_),b(f,wa,_),e(wa,Y$),e(wa,Tf),e(Tf,K$),e(wa,mOe),b(f,oNe,_),b(f,Ti,_),e(Ti,Mf),e(Mf,moe),M(yA,moe,null),e(Ti,gOe),e(Ti,goe),e(goe,hOe),b(f,rNe,_),b(f,kn,_),e(kn,pOe),e(kn,hoe),e(hoe,uOe),e(kn,_Oe),e(kn,poe),e(poe,bOe),e(kn,vOe),b(f,tNe,_),M(LA,f,_),b(f,aNe,_),b(f,Z$,_),e(Z$,FOe),b(f,nNe,_),M(Ef,f,_),b(f,sNe,_),b(f,Mi,_),e(Mi,Cf),e(Cf,uoe),M(xA,uoe,null),e(Mi,TOe),e(Mi,_oe),e(_oe,MOe),b(f,lNe,_),b(f,Co,_),M($A,Co,null),e(Co,EOe),e(Co,kA),e(kA,COe),e(kA,ek),e(ek,wOe),e(kA,AOe),e(Co,yOe),e(Co,SA),e(SA,LOe),e(SA,boe),e(boe,xOe),e(SA,$Oe),e(Co,kOe),e(Co,Er),M(RA,Er,null),e(Er,SOe),e(Er,voe),e(voe,ROe),e(Er,POe),e(Er,Ei),e(Ei,BOe),e(Ei,Foe),e(Foe,IOe),e(Ei,qOe),e(Ei,Toe),e(Toe,NOe),e(Ei,jOe),e(Er,DOe),e(Er,A),e(A,wf),e(wf,Moe),e(Moe,GOe),e(wf,OOe),e(wf,ok),e(ok,VOe),e(wf,XOe),e(A,zOe),e(A,Af),e(Af,Eoe),e(Eoe,WOe),e(Af,QOe),e(Af,rk),e(rk,HOe),e(Af,UOe),e(A,JOe),e(A,yf),e(yf,Coe),e(Coe,YOe),e(yf,KOe),e(yf,tk),e(tk,ZOe),e(yf,eVe),e(A,oVe),e(A,Lf),e(Lf,woe),e(woe,rVe),e(Lf,tVe),e(Lf,ak),e(ak,aVe),e(Lf,nVe),e(A,sVe),e(A,xf),e(xf,Aoe),e(Aoe,lVe),e(xf,iVe),e(xf,nk),e(nk,dVe),e(xf,cVe),e(A,fVe),e(A,$f),e($f,yoe),e(yoe,mVe),e($f,gVe),e($f,sk),e(sk,hVe),e($f,pVe),e(A,uVe),e(A,kf),e(kf,Loe),e(Loe,_Ve),e(kf,bVe),e(kf,lk),e(lk,vVe),e(kf,FVe),e(A,TVe),e(A,Sf),e(Sf,xoe),e(xoe,MVe),e(Sf,EVe),e(Sf,ik),e(ik,CVe),e(Sf,wVe),e(A,AVe),e(A,Rf),e(Rf,$oe),e($oe,yVe),e(Rf,LVe),e(Rf,dk),e(dk,xVe),e(Rf,$Ve),e(A,kVe),e(A,Pf),e(Pf,koe),e(koe,SVe),e(Pf,RVe),e(Pf,ck),e(ck,PVe),e(Pf,BVe),e(A,IVe),e(A,Bf),e(Bf,Soe),e(Soe,qVe),e(Bf,NVe),e(Bf,fk),e(fk,jVe),e(Bf,DVe),e(A,GVe),e(A,If),e(If,Roe),e(Roe,OVe),e(If,VVe),e(If,mk),e(mk,XVe),e(If,zVe),e(A,WVe),e(A,qf),e(qf,Poe),e(Poe,QVe),e(qf,HVe),e(qf,gk),e(gk,UVe),e(qf,JVe),e(A,YVe),e(A,Nf),e(Nf,Boe),e(Boe,KVe),e(Nf,ZVe),e(Nf,hk),e(hk,eXe),e(Nf,oXe),e(A,rXe),e(A,jf),e(jf,Ioe),e(Ioe,tXe),e(jf,aXe),e(jf,pk),e(pk,nXe),e(jf,sXe),e(A,lXe),e(A,Df),e(Df,qoe),e(qoe,iXe),e(Df,dXe),e(Df,uk),e(uk,cXe),e(Df,fXe),e(A,mXe),e(A,Gf),e(Gf,Noe),e(Noe,gXe),e(Gf,hXe),e(Gf,_k),e(_k,pXe),e(Gf,uXe),e(A,_Xe),e(A,Of),e(Of,joe),e(joe,bXe),e(Of,vXe),e(Of,bk),e(bk,FXe),e(Of,TXe),e(A,MXe),e(A,Vf),e(Vf,Doe),e(Doe,EXe),e(Vf,CXe),e(Vf,vk),e(vk,wXe),e(Vf,AXe),e(A,yXe),e(A,Xf),e(Xf,Goe),e(Goe,LXe),e(Xf,xXe),e(Xf,Fk),e(Fk,$Xe),e(Xf,kXe),e(A,SXe),e(A,zf),e(zf,Ooe),e(Ooe,RXe),e(zf,PXe),e(zf,Tk),e(Tk,BXe),e(zf,IXe),e(A,qXe),e(A,Wf),e(Wf,Voe),e(Voe,NXe),e(Wf,jXe),e(Wf,Mk),e(Mk,DXe),e(Wf,GXe),e(A,OXe),e(A,Qf),e(Qf,Xoe),e(Xoe,VXe),e(Qf,XXe),e(Qf,Ek),e(Ek,zXe),e(Qf,WXe),e(A,QXe),e(A,Hf),e(Hf,zoe),e(zoe,HXe),e(Hf,UXe),e(Hf,Ck),e(Ck,JXe),e(Hf,YXe),e(A,KXe),e(A,Uf),e(Uf,Woe),e(Woe,ZXe),e(Uf,eze),e(Uf,wk),e(wk,oze),e(Uf,rze),e(A,tze),e(A,Jf),e(Jf,Qoe),e(Qoe,aze),e(Jf,nze),e(Jf,Ak),e(Ak,sze),e(Jf,lze),e(A,ize),e(A,Yf),e(Yf,Hoe),e(Hoe,dze),e(Yf,cze),e(Yf,yk),e(yk,fze),e(Yf,mze),e(A,gze),e(A,Kf),e(Kf,Uoe),e(Uoe,hze),e(Kf,pze),e(Kf,Lk),e(Lk,uze),e(Kf,_ze),e(A,bze),e(A,Zf),e(Zf,Joe),e(Joe,vze),e(Zf,Fze),e(Zf,xk),e(xk,Tze),e(Zf,Mze),e(A,Eze),e(A,em),e(em,Yoe),e(Yoe,Cze),e(em,wze),e(em,$k),e($k,Aze),e(em,yze),e(A,Lze),e(A,om),e(om,Koe),e(Koe,xze),e(om,$ze),e(om,kk),e(kk,kze),e(om,Sze),e(A,Rze),e(A,rm),e(rm,Zoe),e(Zoe,Pze),e(rm,Bze),e(rm,Sk),e(Sk,Ize),e(rm,qze),e(A,Nze),e(A,tm),e(tm,ere),e(ere,jze),e(tm,Dze),e(tm,Rk),e(Rk,Gze),e(tm,Oze),e(A,Vze),e(A,am),e(am,ore),e(ore,Xze),e(am,zze),e(am,Pk),e(Pk,Wze),e(am,Qze),e(A,Hze),e(A,nm),e(nm,rre),e(rre,Uze),e(nm,Jze),e(nm,Bk),e(Bk,Yze),e(nm,Kze),e(A,Zze),e(A,sm),e(sm,tre),e(tre,eWe),e(sm,oWe),e(sm,Ik),e(Ik,rWe),e(sm,tWe),e(A,aWe),e(A,lm),e(lm,are),e(are,nWe),e(lm,sWe),e(lm,qk),e(qk,lWe),e(lm,iWe),e(A,dWe),e(A,im),e(im,nre),e(nre,cWe),e(im,fWe),e(im,Nk),e(Nk,mWe),e(im,gWe),e(A,hWe),e(A,dm),e(dm,sre),e(sre,pWe),e(dm,uWe),e(dm,jk),e(jk,_We),e(dm,bWe),e(A,vWe),e(A,cm),e(cm,lre),e(lre,FWe),e(cm,TWe),e(cm,Dk),e(Dk,MWe),e(cm,EWe),e(A,CWe),e(A,fm),e(fm,ire),e(ire,wWe),e(fm,AWe),e(fm,Gk),e(Gk,yWe),e(fm,LWe),e(A,xWe),e(A,mm),e(mm,dre),e(dre,$We),e(mm,kWe),e(mm,Ok),e(Ok,SWe),e(mm,RWe),e(A,PWe),e(A,gm),e(gm,cre),e(cre,BWe),e(gm,IWe),e(gm,Vk),e(Vk,qWe),e(gm,NWe),e(A,jWe),e(A,hm),e(hm,fre),e(fre,DWe),e(hm,GWe),e(hm,Xk),e(Xk,OWe),e(hm,VWe),e(A,XWe),e(A,pm),e(pm,mre),e(mre,zWe),e(pm,WWe),e(pm,zk),e(zk,QWe),e(pm,HWe),e(A,UWe),e(A,um),e(um,gre),e(gre,JWe),e(um,YWe),e(um,Wk),e(Wk,KWe),e(um,ZWe),e(A,eQe),e(A,_m),e(_m,hre),e(hre,oQe),e(_m,rQe),e(_m,Qk),e(Qk,tQe),e(_m,aQe),e(A,nQe),e(A,bm),e(bm,pre),e(pre,sQe),e(bm,lQe),e(bm,Hk),e(Hk,iQe),e(bm,dQe),e(A,cQe),e(A,vm),e(vm,ure),e(ure,fQe),e(vm,mQe),e(vm,Uk),e(Uk,gQe),e(vm,hQe),e(A,pQe),e(A,Fm),e(Fm,_re),e(_re,uQe),e(Fm,_Qe),e(Fm,Jk),e(Jk,bQe),e(Fm,vQe),e(A,FQe),e(A,Tm),e(Tm,bre),e(bre,TQe),e(Tm,MQe),e(Tm,Yk),e(Yk,EQe),e(Tm,CQe),e(A,wQe),e(A,Mm),e(Mm,vre),e(vre,AQe),e(Mm,yQe),e(Mm,Kk),e(Kk,LQe),e(Mm,xQe),e(A,$Qe),e(A,Em),e(Em,Fre),e(Fre,kQe),e(Em,SQe),e(Em,Zk),e(Zk,RQe),e(Em,PQe),e(A,BQe),e(A,Cm),e(Cm,Tre),e(Tre,IQe),e(Cm,qQe),e(Cm,eS),e(eS,NQe),e(Cm,jQe),e(A,DQe),e(A,wm),e(wm,Mre),e(Mre,GQe),e(wm,OQe),e(wm,oS),e(oS,VQe),e(wm,XQe),e(A,zQe),e(A,Am),e(Am,Ere),e(Ere,WQe),e(Am,QQe),e(Am,rS),e(rS,HQe),e(Am,UQe),e(A,JQe),e(A,ym),e(ym,Cre),e(Cre,YQe),e(ym,KQe),e(ym,tS),e(tS,ZQe),e(ym,eHe),e(A,oHe),e(A,Lm),e(Lm,wre),e(wre,rHe),e(Lm,tHe),e(Lm,aS),e(aS,aHe),e(Lm,nHe),e(A,sHe),e(A,xm),e(xm,Are),e(Are,lHe),e(xm,iHe),e(xm,nS),e(nS,dHe),e(xm,cHe),e(A,fHe),e(A,$m),e($m,yre),e(yre,mHe),e($m,gHe),e($m,sS),e(sS,hHe),e($m,pHe),e(A,uHe),e(A,km),e(km,Lre),e(Lre,_He),e(km,bHe),e(km,lS),e(lS,vHe),e(km,FHe),e(A,THe),e(A,Sm),e(Sm,xre),e(xre,MHe),e(Sm,EHe),e(Sm,iS),e(iS,CHe),e(Sm,wHe),e(A,AHe),e(A,Rm),e(Rm,$re),e($re,yHe),e(Rm,LHe),e(Rm,dS),e(dS,xHe),e(Rm,$He),e(A,kHe),e(A,Pm),e(Pm,kre),e(kre,SHe),e(Pm,RHe),e(Pm,cS),e(cS,PHe),e(Pm,BHe),e(A,IHe),e(A,Bm),e(Bm,Sre),e(Sre,qHe),e(Bm,NHe),e(Bm,fS),e(fS,jHe),e(Bm,DHe),e(A,GHe),e(A,Im),e(Im,Rre),e(Rre,OHe),e(Im,VHe),e(Im,mS),e(mS,XHe),e(Im,zHe),e(A,WHe),e(A,qm),e(qm,Pre),e(Pre,QHe),e(qm,HHe),e(qm,gS),e(gS,UHe),e(qm,JHe),e(A,YHe),e(A,Nm),e(Nm,Bre),e(Bre,KHe),e(Nm,ZHe),e(Nm,hS),e(hS,eUe),e(Nm,oUe),e(A,rUe),e(A,jm),e(jm,Ire),e(Ire,tUe),e(jm,aUe),e(jm,pS),e(pS,nUe),e(jm,sUe),e(A,lUe),e(A,Dm),e(Dm,qre),e(qre,iUe),e(Dm,dUe),e(Dm,uS),e(uS,cUe),e(Dm,fUe),e(A,mUe),e(A,Gm),e(Gm,Nre),e(Nre,gUe),e(Gm,hUe),e(Gm,_S),e(_S,pUe),e(Gm,uUe),e(A,_Ue),e(A,Om),e(Om,jre),e(jre,bUe),e(Om,vUe),e(Om,bS),e(bS,FUe),e(Om,TUe),e(A,MUe),e(A,Vm),e(Vm,Dre),e(Dre,EUe),e(Vm,CUe),e(Vm,vS),e(vS,wUe),e(Vm,AUe),e(A,yUe),e(A,Xm),e(Xm,Gre),e(Gre,LUe),e(Xm,xUe),e(Xm,FS),e(FS,$Ue),e(Xm,kUe),e(A,SUe),e(A,zm),e(zm,Ore),e(Ore,RUe),e(zm,PUe),e(zm,TS),e(TS,BUe),e(zm,IUe),e(A,qUe),e(A,Wm),e(Wm,Vre),e(Vre,NUe),e(Wm,jUe),e(Wm,MS),e(MS,DUe),e(Wm,GUe),e(A,OUe),e(A,Qm),e(Qm,Xre),e(Xre,VUe),e(Qm,XUe),e(Qm,ES),e(ES,zUe),e(Qm,WUe),e(A,QUe),e(A,Hm),e(Hm,zre),e(zre,HUe),e(Hm,UUe),e(Hm,CS),e(CS,JUe),e(Hm,YUe),e(A,KUe),e(A,Um),e(Um,Wre),e(Wre,ZUe),e(Um,eJe),e(Um,wS),e(wS,oJe),e(Um,rJe),e(A,tJe),e(A,Jm),e(Jm,Qre),e(Qre,aJe),e(Jm,nJe),e(Jm,AS),e(AS,sJe),e(Jm,lJe),e(A,iJe),e(A,Ym),e(Ym,Hre),e(Hre,dJe),e(Ym,cJe),e(Ym,yS),e(yS,fJe),e(Ym,mJe),e(A,gJe),e(A,Km),e(Km,Ure),e(Ure,hJe),e(Km,pJe),e(Km,LS),e(LS,uJe),e(Km,_Je),e(A,bJe),e(A,Zm),e(Zm,Jre),e(Jre,vJe),e(Zm,FJe),e(Zm,xS),e(xS,TJe),e(Zm,MJe),e(A,EJe),e(A,eg),e(eg,Yre),e(Yre,CJe),e(eg,wJe),e(eg,$S),e($S,AJe),e(eg,yJe),e(A,LJe),e(A,og),e(og,Kre),e(Kre,xJe),e(og,$Je),e(og,kS),e(kS,kJe),e(og,SJe),e(A,RJe),e(A,rg),e(rg,Zre),e(Zre,PJe),e(rg,BJe),e(rg,SS),e(SS,IJe),e(rg,qJe),e(A,NJe),e(A,tg),e(tg,ete),e(ete,jJe),e(tg,DJe),e(tg,RS),e(RS,GJe),e(tg,OJe),e(A,VJe),e(A,ag),e(ag,ote),e(ote,XJe),e(ag,zJe),e(ag,PS),e(PS,WJe),e(ag,QJe),e(A,HJe),e(A,ng),e(ng,rte),e(rte,UJe),e(ng,JJe),e(ng,BS),e(BS,YJe),e(ng,KJe),e(A,ZJe),e(A,sg),e(sg,tte),e(tte,eYe),e(sg,oYe),e(sg,IS),e(IS,rYe),e(sg,tYe),e(A,aYe),e(A,lg),e(lg,ate),e(ate,nYe),e(lg,sYe),e(lg,qS),e(qS,lYe),e(lg,iYe),e(A,dYe),e(A,ig),e(ig,nte),e(nte,cYe),e(ig,fYe),e(ig,NS),e(NS,mYe),e(ig,gYe),e(A,hYe),e(A,dg),e(dg,ste),e(ste,pYe),e(dg,uYe),e(dg,jS),e(jS,_Ye),e(dg,bYe),e(A,vYe),e(A,cg),e(cg,lte),e(lte,FYe),e(cg,TYe),e(cg,DS),e(DS,MYe),e(cg,EYe),e(A,CYe),e(A,fg),e(fg,ite),e(ite,wYe),e(fg,AYe),e(fg,GS),e(GS,yYe),e(fg,LYe),e(A,xYe),e(A,mg),e(mg,dte),e(dte,$Ye),e(mg,kYe),e(mg,OS),e(OS,SYe),e(mg,RYe),e(A,PYe),e(A,gg),e(gg,cte),e(cte,BYe),e(gg,IYe),e(gg,VS),e(VS,qYe),e(gg,NYe),e(A,jYe),e(A,hg),e(hg,fte),e(fte,DYe),e(hg,GYe),e(hg,XS),e(XS,OYe),e(hg,VYe),e(A,XYe),e(A,pg),e(pg,mte),e(mte,zYe),e(pg,WYe),e(pg,zS),e(zS,QYe),e(pg,HYe),e(A,UYe),e(A,ug),e(ug,gte),e(gte,JYe),e(ug,YYe),e(ug,WS),e(WS,KYe),e(ug,ZYe),e(A,eKe),e(A,_g),e(_g,hte),e(hte,oKe),e(_g,rKe),e(_g,QS),e(QS,tKe),e(_g,aKe),e(A,nKe),e(A,bg),e(bg,pte),e(pte,sKe),e(bg,lKe),e(bg,HS),e(HS,iKe),e(bg,dKe),e(A,cKe),e(A,vg),e(vg,ute),e(ute,fKe),e(vg,mKe),e(vg,US),e(US,gKe),e(vg,hKe),e(A,pKe),e(A,Fg),e(Fg,_te),e(_te,uKe),e(Fg,_Ke),e(Fg,JS),e(JS,bKe),e(Fg,vKe),e(A,FKe),e(A,Tg),e(Tg,bte),e(bte,TKe),e(Tg,MKe),e(Tg,YS),e(YS,EKe),e(Tg,CKe),e(A,wKe),e(A,Mg),e(Mg,vte),e(vte,AKe),e(Mg,yKe),e(Mg,KS),e(KS,LKe),e(Mg,xKe),e(A,$Ke),e(A,Eg),e(Eg,Fte),e(Fte,kKe),e(Eg,SKe),e(Eg,ZS),e(ZS,RKe),e(Eg,PKe),e(A,BKe),e(A,Cg),e(Cg,Tte),e(Tte,IKe),e(Cg,qKe),e(Cg,eR),e(eR,NKe),e(Cg,jKe),e(A,DKe),e(A,wg),e(wg,Mte),e(Mte,GKe),e(wg,OKe),e(wg,oR),e(oR,VKe),e(wg,XKe),e(Er,zKe),M(Ag,Er,null),e(Co,WKe),e(Co,yg),M(PA,yg,null),e(yg,QKe),e(yg,Ete),e(Ete,HKe),b(f,iNe,_),b(f,Ci,_),e(Ci,Lg),e(Lg,Cte),M(BA,Cte,null),e(Ci,UKe),e(Ci,wte),e(wte,JKe),b(f,dNe,_),b(f,wo,_),M(IA,wo,null),e(wo,YKe),e(wo,qA),e(qA,KKe),e(qA,rR),e(rR,ZKe),e(qA,eZe),e(wo,oZe),e(wo,NA),e(NA,rZe),e(NA,Ate),e(Ate,tZe),e(NA,aZe),e(wo,nZe),e(wo,Cr),M(jA,Cr,null),e(Cr,sZe),e(Cr,yte),e(yte,lZe),e(Cr,iZe),e(Cr,Aa),e(Aa,dZe),e(Aa,Lte),e(Lte,cZe),e(Aa,fZe),e(Aa,xte),e(xte,mZe),e(Aa,gZe),e(Aa,$te),e($te,hZe),e(Aa,pZe),e(Cr,uZe),e(Cr,k),e(k,Sn),e(Sn,kte),e(kte,_Ze),e(Sn,bZe),e(Sn,tR),e(tR,vZe),e(Sn,FZe),e(Sn,aR),e(aR,TZe),e(Sn,MZe),e(k,EZe),e(k,Rn),e(Rn,Ste),e(Ste,CZe),e(Rn,wZe),e(Rn,nR),e(nR,AZe),e(Rn,yZe),e(Rn,sR),e(sR,LZe),e(Rn,xZe),e(k,$Ze),e(k,Pn),e(Pn,Rte),e(Rte,kZe),e(Pn,SZe),e(Pn,lR),e(lR,RZe),e(Pn,PZe),e(Pn,iR),e(iR,BZe),e(Pn,IZe),e(k,qZe),e(k,Bn),e(Bn,Pte),e(Pte,NZe),e(Bn,jZe),e(Bn,dR),e(dR,DZe),e(Bn,GZe),e(Bn,cR),e(cR,OZe),e(Bn,VZe),e(k,XZe),e(k,In),e(In,Bte),e(Bte,zZe),e(In,WZe),e(In,fR),e(fR,QZe),e(In,HZe),e(In,mR),e(mR,UZe),e(In,JZe),e(k,YZe),e(k,xg),e(xg,Ite),e(Ite,KZe),e(xg,ZZe),e(xg,gR),e(gR,eeo),e(xg,oeo),e(k,reo),e(k,$g),e($g,qte),e(qte,teo),e($g,aeo),e($g,hR),e(hR,neo),e($g,seo),e(k,leo),e(k,qn),e(qn,Nte),e(Nte,ieo),e(qn,deo),e(qn,pR),e(pR,ceo),e(qn,feo),e(qn,uR),e(uR,meo),e(qn,geo),e(k,heo),e(k,Nn),e(Nn,jte),e(jte,peo),e(Nn,ueo),e(Nn,_R),e(_R,_eo),e(Nn,beo),e(Nn,bR),e(bR,veo),e(Nn,Feo),e(k,Teo),e(k,jn),e(jn,Dte),e(Dte,Meo),e(jn,Eeo),e(jn,vR),e(vR,Ceo),e(jn,weo),e(jn,FR),e(FR,Aeo),e(jn,yeo),e(k,Leo),e(k,Dn),e(Dn,Gte),e(Gte,xeo),e(Dn,$eo),e(Dn,TR),e(TR,keo),e(Dn,Seo),e(Dn,MR),e(MR,Reo),e(Dn,Peo),e(k,Beo),e(k,kg),e(kg,Ote),e(Ote,Ieo),e(kg,qeo),e(kg,ER),e(ER,Neo),e(kg,jeo),e(k,Deo),e(k,Sg),e(Sg,Vte),e(Vte,Geo),e(Sg,Oeo),e(Sg,CR),e(CR,Veo),e(Sg,Xeo),e(k,zeo),e(k,Gn),e(Gn,Xte),e(Xte,Weo),e(Gn,Qeo),e(Gn,wR),e(wR,Heo),e(Gn,Ueo),e(Gn,AR),e(AR,Jeo),e(Gn,Yeo),e(k,Keo),e(k,Rg),e(Rg,zte),e(zte,Zeo),e(Rg,eoo),e(Rg,yR),e(yR,ooo),e(Rg,roo),e(k,too),e(k,On),e(On,Wte),e(Wte,aoo),e(On,noo),e(On,LR),e(LR,soo),e(On,loo),e(On,xR),e(xR,ioo),e(On,doo),e(k,coo),e(k,Vn),e(Vn,Qte),e(Qte,foo),e(Vn,moo),e(Vn,$R),e($R,goo),e(Vn,hoo),e(Vn,kR),e(kR,poo),e(Vn,uoo),e(k,_oo),e(k,Xn),e(Xn,Hte),e(Hte,boo),e(Xn,voo),e(Xn,SR),e(SR,Foo),e(Xn,Too),e(Xn,RR),e(RR,Moo),e(Xn,Eoo),e(k,Coo),e(k,Pg),e(Pg,Ute),e(Ute,woo),e(Pg,Aoo),e(Pg,PR),e(PR,yoo),e(Pg,Loo),e(k,xoo),e(k,zn),e(zn,Jte),e(Jte,$oo),e(zn,koo),e(zn,BR),e(BR,Soo),e(zn,Roo),e(zn,IR),e(IR,Poo),e(zn,Boo),e(k,Ioo),e(k,Wn),e(Wn,Yte),e(Yte,qoo),e(Wn,Noo),e(Wn,qR),e(qR,joo),e(Wn,Doo),e(Wn,NR),e(NR,Goo),e(Wn,Ooo),e(k,Voo),e(k,Qn),e(Qn,Kte),e(Kte,Xoo),e(Qn,zoo),e(Qn,jR),e(jR,Woo),e(Qn,Qoo),e(Qn,DR),e(DR,Hoo),e(Qn,Uoo),e(k,Joo),e(k,Hn),e(Hn,Zte),e(Zte,Yoo),e(Hn,Koo),e(Hn,GR),e(GR,Zoo),e(Hn,ero),e(Hn,OR),e(OR,oro),e(Hn,rro),e(k,tro),e(k,Un),e(Un,eae),e(eae,aro),e(Un,nro),e(Un,VR),e(VR,sro),e(Un,lro),e(Un,XR),e(XR,iro),e(Un,dro),e(k,cro),e(k,Jn),e(Jn,oae),e(oae,fro),e(Jn,mro),e(Jn,zR),e(zR,gro),e(Jn,hro),e(Jn,WR),e(WR,pro),e(Jn,uro),e(k,_ro),e(k,Bg),e(Bg,rae),e(rae,bro),e(Bg,vro),e(Bg,QR),e(QR,Fro),e(Bg,Tro),e(k,Mro),e(k,Yn),e(Yn,tae),e(tae,Ero),e(Yn,Cro),e(Yn,HR),e(HR,wro),e(Yn,Aro),e(Yn,UR),e(UR,yro),e(Yn,Lro),e(k,xro),e(k,Ig),e(Ig,aae),e(aae,$ro),e(Ig,kro),e(Ig,JR),e(JR,Sro),e(Ig,Rro),e(k,Pro),e(k,Kn),e(Kn,nae),e(nae,Bro),e(Kn,Iro),e(Kn,YR),e(YR,qro),e(Kn,Nro),e(Kn,KR),e(KR,jro),e(Kn,Dro),e(k,Gro),e(k,Zn),e(Zn,sae),e(sae,Oro),e(Zn,Vro),e(Zn,ZR),e(ZR,Xro),e(Zn,zro),e(Zn,eP),e(eP,Wro),e(Zn,Qro),e(k,Hro),e(k,es),e(es,lae),e(lae,Uro),e(es,Jro),e(es,oP),e(oP,Yro),e(es,Kro),e(es,rP),e(rP,Zro),e(es,eto),e(k,oto),e(k,qg),e(qg,iae),e(iae,rto),e(qg,tto),e(qg,tP),e(tP,ato),e(qg,nto),e(k,sto),e(k,os),e(os,dae),e(dae,lto),e(os,ito),e(os,aP),e(aP,dto),e(os,cto),e(os,nP),e(nP,fto),e(os,mto),e(k,gto),e(k,rs),e(rs,cae),e(cae,hto),e(rs,pto),e(rs,sP),e(sP,uto),e(rs,_to),e(rs,lP),e(lP,bto),e(rs,vto),e(k,Fto),e(k,Ng),e(Ng,fae),e(fae,Tto),e(Ng,Mto),e(Ng,iP),e(iP,Eto),e(Ng,Cto),e(k,wto),e(k,ts),e(ts,mae),e(mae,Ato),e(ts,yto),e(ts,dP),e(dP,Lto),e(ts,xto),e(ts,cP),e(cP,$to),e(ts,kto),e(k,Sto),e(k,as),e(as,gae),e(gae,Rto),e(as,Pto),e(as,fP),e(fP,Bto),e(as,Ito),e(as,mP),e(mP,qto),e(as,Nto),e(k,jto),e(k,ns),e(ns,hae),e(hae,Dto),e(ns,Gto),e(ns,gP),e(gP,Oto),e(ns,Vto),e(ns,hP),e(hP,Xto),e(ns,zto),e(k,Wto),e(k,ss),e(ss,pae),e(pae,Qto),e(ss,Hto),e(ss,pP),e(pP,Uto),e(ss,Jto),e(ss,uP),e(uP,Yto),e(ss,Kto),e(k,Zto),e(k,ls),e(ls,uae),e(uae,eao),e(ls,oao),e(ls,_P),e(_P,rao),e(ls,tao),e(ls,bP),e(bP,aao),e(ls,nao),e(k,sao),e(k,is),e(is,_ae),e(_ae,lao),e(is,iao),e(is,vP),e(vP,dao),e(is,cao),e(is,FP),e(FP,fao),e(is,mao),e(k,gao),e(k,ds),e(ds,bae),e(bae,hao),e(ds,pao),e(ds,TP),e(TP,uao),e(ds,_ao),e(ds,MP),e(MP,bao),e(ds,vao),e(k,Fao),e(k,jg),e(jg,vae),e(vae,Tao),e(jg,Mao),e(jg,EP),e(EP,Eao),e(jg,Cao),e(k,wao),e(k,cs),e(cs,Fae),e(Fae,Aao),e(cs,yao),e(cs,CP),e(CP,Lao),e(cs,xao),e(cs,wP),e(wP,$ao),e(cs,kao),e(k,Sao),e(k,Dg),e(Dg,Tae),e(Tae,Rao),e(Dg,Pao),e(Dg,AP),e(AP,Bao),e(Dg,Iao),e(k,qao),e(k,Gg),e(Gg,Mae),e(Mae,Nao),e(Gg,jao),e(Gg,yP),e(yP,Dao),e(Gg,Gao),e(k,Oao),e(k,fs),e(fs,Eae),e(Eae,Vao),e(fs,Xao),e(fs,LP),e(LP,zao),e(fs,Wao),e(fs,xP),e(xP,Qao),e(fs,Hao),e(k,Uao),e(k,ms),e(ms,Cae),e(Cae,Jao),e(ms,Yao),e(ms,$P),e($P,Kao),e(ms,Zao),e(ms,kP),e(kP,eno),e(ms,ono),e(k,rno),e(k,gs),e(gs,wae),e(wae,tno),e(gs,ano),e(gs,SP),e(SP,nno),e(gs,sno),e(gs,RP),e(RP,lno),e(gs,ino),e(k,dno),e(k,Og),e(Og,Aae),e(Aae,cno),e(Og,fno),e(Og,PP),e(PP,mno),e(Og,gno),e(k,hno),e(k,hs),e(hs,yae),e(yae,pno),e(hs,uno),e(hs,BP),e(BP,_no),e(hs,bno),e(hs,IP),e(IP,vno),e(hs,Fno),e(k,Tno),e(k,ps),e(ps,Lae),e(Lae,Mno),e(ps,Eno),e(ps,qP),e(qP,Cno),e(ps,wno),e(ps,NP),e(NP,Ano),e(ps,yno),e(k,Lno),e(k,us),e(us,xae),e(xae,xno),e(us,$no),e(us,jP),e(jP,kno),e(us,Sno),e(us,DP),e(DP,Rno),e(us,Pno),e(k,Bno),e(k,_s),e(_s,$ae),e($ae,Ino),e(_s,qno),e(_s,GP),e(GP,Nno),e(_s,jno),e(_s,OP),e(OP,Dno),e(_s,Gno),e(k,Ono),e(k,bs),e(bs,kae),e(kae,Vno),e(bs,Xno),e(bs,VP),e(VP,zno),e(bs,Wno),e(bs,XP),e(XP,Qno),e(bs,Hno),e(k,Uno),e(k,Vg),e(Vg,Sae),e(Sae,Jno),e(Vg,Yno),e(Vg,zP),e(zP,Kno),e(Vg,Zno),e(k,eso),e(k,vs),e(vs,Rae),e(Rae,oso),e(vs,rso),e(vs,WP),e(WP,tso),e(vs,aso),e(vs,QP),e(QP,nso),e(vs,sso),e(k,lso),e(k,Xg),e(Xg,Pae),e(Pae,iso),e(Xg,dso),e(Xg,HP),e(HP,cso),e(Xg,fso),e(k,mso),e(k,Fs),e(Fs,Bae),e(Bae,gso),e(Fs,hso),e(Fs,UP),e(UP,pso),e(Fs,uso),e(Fs,JP),e(JP,_so),e(Fs,bso),e(k,vso),e(k,zg),e(zg,Iae),e(Iae,Fso),e(zg,Tso),e(zg,YP),e(YP,Mso),e(zg,Eso),e(k,Cso),e(k,Wg),e(Wg,qae),e(qae,wso),e(Wg,Aso),e(Wg,KP),e(KP,yso),e(Wg,Lso),e(k,xso),e(k,Ts),e(Ts,Nae),e(Nae,$so),e(Ts,kso),e(Ts,ZP),e(ZP,Sso),e(Ts,Rso),e(Ts,eB),e(eB,Pso),e(Ts,Bso),e(k,Iso),e(k,Qg),e(Qg,jae),e(jae,qso),e(Qg,Nso),e(Qg,oB),e(oB,jso),e(Qg,Dso),e(k,Gso),e(k,Ms),e(Ms,Dae),e(Dae,Oso),e(Ms,Vso),e(Ms,rB),e(rB,Xso),e(Ms,zso),e(Ms,tB),e(tB,Wso),e(Ms,Qso),e(k,Hso),e(k,Es),e(Es,Gae),e(Gae,Uso),e(Es,Jso),e(Es,aB),e(aB,Yso),e(Es,Kso),e(Es,nB),e(nB,Zso),e(Es,elo),e(k,olo),e(k,Cs),e(Cs,Oae),e(Oae,rlo),e(Cs,tlo),e(Cs,sB),e(sB,alo),e(Cs,nlo),e(Cs,lB),e(lB,slo),e(Cs,llo),e(k,ilo),e(k,ws),e(ws,Vae),e(Vae,dlo),e(ws,clo),e(ws,iB),e(iB,flo),e(ws,mlo),e(ws,dB),e(dB,glo),e(ws,hlo),e(k,plo),e(k,As),e(As,Xae),e(Xae,ulo),e(As,_lo),e(As,cB),e(cB,blo),e(As,vlo),e(As,fB),e(fB,Flo),e(As,Tlo),e(k,Mlo),e(k,ys),e(ys,zae),e(zae,Elo),e(ys,Clo),e(ys,mB),e(mB,wlo),e(ys,Alo),e(ys,gB),e(gB,ylo),e(ys,Llo),e(k,xlo),e(k,Hg),e(Hg,Wae),e(Wae,$lo),e(Hg,klo),e(Hg,hB),e(hB,Slo),e(Hg,Rlo),e(k,Plo),e(k,Ug),e(Ug,Qae),e(Qae,Blo),e(Ug,Ilo),e(Ug,pB),e(pB,qlo),e(Ug,Nlo),e(k,jlo),e(k,Ls),e(Ls,Hae),e(Hae,Dlo),e(Ls,Glo),e(Ls,uB),e(uB,Olo),e(Ls,Vlo),e(Ls,_B),e(_B,Xlo),e(Ls,zlo),e(k,Wlo),e(k,xs),e(xs,Uae),e(Uae,Qlo),e(xs,Hlo),e(xs,bB),e(bB,Ulo),e(xs,Jlo),e(xs,vB),e(vB,Ylo),e(xs,Klo),e(k,Zlo),e(k,$s),e($s,Jae),e(Jae,eio),e($s,oio),e($s,FB),e(FB,rio),e($s,tio),e($s,TB),e(TB,aio),e($s,nio),e(k,sio),e(k,Jg),e(Jg,Yae),e(Yae,lio),e(Jg,iio),e(Jg,MB),e(MB,dio),e(Jg,cio),e(k,fio),e(k,Yg),e(Yg,Kae),e(Kae,mio),e(Yg,gio),e(Yg,EB),e(EB,hio),e(Yg,pio),e(k,uio),e(k,Kg),e(Kg,Zae),e(Zae,_io),e(Kg,bio),e(Kg,CB),e(CB,vio),e(Kg,Fio),e(k,Tio),e(k,ks),e(ks,ene),e(ene,Mio),e(ks,Eio),e(ks,wB),e(wB,Cio),e(ks,wio),e(ks,AB),e(AB,Aio),e(ks,yio),e(k,Lio),e(k,Zg),e(Zg,one),e(one,xio),e(Zg,$io),e(Zg,yB),e(yB,kio),e(Zg,Sio),e(k,Rio),e(k,eh),e(eh,rne),e(rne,Pio),e(eh,Bio),e(eh,LB),e(LB,Iio),e(eh,qio),e(k,Nio),e(k,oh),e(oh,tne),e(tne,jio),e(oh,Dio),e(oh,xB),e(xB,Gio),e(oh,Oio),e(k,Vio),e(k,Ss),e(Ss,ane),e(ane,Xio),e(Ss,zio),e(Ss,$B),e($B,Wio),e(Ss,Qio),e(Ss,kB),e(kB,Hio),e(Ss,Uio),e(k,Jio),e(k,rh),e(rh,nne),e(nne,Yio),e(rh,Kio),e(rh,SB),e(SB,Zio),e(rh,edo),e(k,odo),e(k,th),e(th,sne),e(sne,rdo),e(th,tdo),e(th,RB),e(RB,ado),e(th,ndo),e(k,sdo),e(k,Rs),e(Rs,lne),e(lne,ldo),e(Rs,ido),e(Rs,PB),e(PB,ddo),e(Rs,cdo),e(Rs,BB),e(BB,fdo),e(Rs,mdo),e(k,gdo),e(k,Ps),e(Ps,ine),e(ine,hdo),e(Ps,pdo),e(Ps,IB),e(IB,udo),e(Ps,_do),e(Ps,qB),e(qB,bdo),e(Ps,vdo),e(k,Fdo),e(k,Bs),e(Bs,dne),e(dne,Tdo),e(Bs,Mdo),e(Bs,NB),e(NB,Edo),e(Bs,Cdo),e(Bs,jB),e(jB,wdo),e(Bs,Ado),e(k,ydo),e(k,Is),e(Is,cne),e(cne,Ldo),e(Is,xdo),e(Is,DB),e(DB,$do),e(Is,kdo),e(Is,GB),e(GB,Sdo),e(Is,Rdo),e(Cr,Pdo),M(ah,Cr,null),e(wo,Bdo),e(wo,nh),M(DA,nh,null),e(nh,Ido),e(nh,fne),e(fne,qdo),b(f,cNe,_),b(f,wi,_),e(wi,sh),e(sh,mne),M(GA,mne,null),e(wi,Ndo),e(wi,gne),e(gne,jdo),b(f,fNe,_),b(f,Ao,_),M(OA,Ao,null),e(Ao,Ddo),e(Ao,VA),e(VA,Gdo),e(VA,OB),e(OB,Odo),e(VA,Vdo),e(Ao,Xdo),e(Ao,XA),e(XA,zdo),e(XA,hne),e(hne,Wdo),e(XA,Qdo),e(Ao,Hdo),e(Ao,He),M(zA,He,null),e(He,Udo),e(He,pne),e(pne,Jdo),e(He,Ydo),e(He,ya),e(ya,Kdo),e(ya,une),e(une,Zdo),e(ya,eco),e(ya,_ne),e(_ne,oco),e(ya,rco),e(ya,bne),e(bne,tco),e(ya,aco),e(He,nco),e(He,Y),e(Y,lh),e(lh,vne),e(vne,sco),e(lh,lco),e(lh,VB),e(VB,ico),e(lh,dco),e(Y,cco),e(Y,ih),e(ih,Fne),e(Fne,fco),e(ih,mco),e(ih,XB),e(XB,gco),e(ih,hco),e(Y,pco),e(Y,dh),e(dh,Tne),e(Tne,uco),e(dh,_co),e(dh,zB),e(zB,bco),e(dh,vco),e(Y,Fco),e(Y,ch),e(ch,Mne),e(Mne,Tco),e(ch,Mco),e(ch,WB),e(WB,Eco),e(ch,Cco),e(Y,wco),e(Y,fh),e(fh,Ene),e(Ene,Aco),e(fh,yco),e(fh,QB),e(QB,Lco),e(fh,xco),e(Y,$co),e(Y,mh),e(mh,Cne),e(Cne,kco),e(mh,Sco),e(mh,HB),e(HB,Rco),e(mh,Pco),e(Y,Bco),e(Y,gh),e(gh,wne),e(wne,Ico),e(gh,qco),e(gh,UB),e(UB,Nco),e(gh,jco),e(Y,Dco),e(Y,hh),e(hh,Ane),e(Ane,Gco),e(hh,Oco),e(hh,JB),e(JB,Vco),e(hh,Xco),e(Y,zco),e(Y,ph),e(ph,yne),e(yne,Wco),e(ph,Qco),e(ph,YB),e(YB,Hco),e(ph,Uco),e(Y,Jco),e(Y,uh),e(uh,Lne),e(Lne,Yco),e(uh,Kco),e(uh,KB),e(KB,Zco),e(uh,efo),e(Y,ofo),e(Y,_h),e(_h,xne),e(xne,rfo),e(_h,tfo),e(_h,ZB),e(ZB,afo),e(_h,nfo),e(Y,sfo),e(Y,bh),e(bh,$ne),e($ne,lfo),e(bh,ifo),e(bh,eI),e(eI,dfo),e(bh,cfo),e(Y,ffo),e(Y,vh),e(vh,kne),e(kne,mfo),e(vh,gfo),e(vh,oI),e(oI,hfo),e(vh,pfo),e(Y,ufo),e(Y,Fh),e(Fh,Sne),e(Sne,_fo),e(Fh,bfo),e(Fh,rI),e(rI,vfo),e(Fh,Ffo),e(Y,Tfo),e(Y,Th),e(Th,Rne),e(Rne,Mfo),e(Th,Efo),e(Th,tI),e(tI,Cfo),e(Th,wfo),e(Y,Afo),e(Y,Mh),e(Mh,Pne),e(Pne,yfo),e(Mh,Lfo),e(Mh,aI),e(aI,xfo),e(Mh,$fo),e(Y,kfo),e(Y,Eh),e(Eh,Bne),e(Bne,Sfo),e(Eh,Rfo),e(Eh,nI),e(nI,Pfo),e(Eh,Bfo),e(Y,Ifo),e(Y,Ch),e(Ch,Ine),e(Ine,qfo),e(Ch,Nfo),e(Ch,sI),e(sI,jfo),e(Ch,Dfo),e(Y,Gfo),e(Y,wh),e(wh,qne),e(qne,Ofo),e(wh,Vfo),e(wh,lI),e(lI,Xfo),e(wh,zfo),e(Y,Wfo),e(Y,Ah),e(Ah,Nne),e(Nne,Qfo),e(Ah,Hfo),e(Ah,iI),e(iI,Ufo),e(Ah,Jfo),e(Y,Yfo),e(Y,yh),e(yh,jne),e(jne,Kfo),e(yh,Zfo),e(yh,dI),e(dI,emo),e(yh,omo),e(Y,rmo),e(Y,Lh),e(Lh,Dne),e(Dne,tmo),e(Lh,amo),e(Lh,cI),e(cI,nmo),e(Lh,smo),e(Y,lmo),e(Y,xh),e(xh,Gne),e(Gne,imo),e(xh,dmo),e(xh,fI),e(fI,cmo),e(xh,fmo),e(Y,mmo),e(Y,$h),e($h,One),e(One,gmo),e($h,hmo),e($h,mI),e(mI,pmo),e($h,umo),e(Y,_mo),e(Y,kh),e(kh,Vne),e(Vne,bmo),e(kh,vmo),e(kh,gI),e(gI,Fmo),e(kh,Tmo),e(Y,Mmo),e(Y,Sh),e(Sh,Xne),e(Xne,Emo),e(Sh,Cmo),e(Sh,hI),e(hI,wmo),e(Sh,Amo),e(Y,ymo),e(Y,Rh),e(Rh,zne),e(zne,Lmo),e(Rh,xmo),e(Rh,pI),e(pI,$mo),e(Rh,kmo),e(Y,Smo),e(Y,Ph),e(Ph,Wne),e(Wne,Rmo),e(Ph,Pmo),e(Ph,uI),e(uI,Bmo),e(Ph,Imo),e(Y,qmo),e(Y,Bh),e(Bh,Qne),e(Qne,Nmo),e(Bh,jmo),e(Bh,_I),e(_I,Dmo),e(Bh,Gmo),e(He,Omo),M(Ih,He,null),e(He,Vmo),M(qh,He,null),e(Ao,Xmo),e(Ao,Nh),M(WA,Nh,null),e(Nh,zmo),e(Nh,Hne),e(Hne,Wmo),b(f,mNe,_),b(f,Ai,_),e(Ai,jh),e(jh,Une),M(QA,Une,null),e(Ai,Qmo),e(Ai,Jne),e(Jne,Hmo),b(f,gNe,_),b(f,yo,_),M(HA,yo,null),e(yo,Umo),e(yo,UA),e(UA,Jmo),e(UA,bI),e(bI,Ymo),e(UA,Kmo),e(yo,Zmo),e(yo,JA),e(JA,ego),e(JA,Yne),e(Yne,ogo),e(JA,rgo),e(yo,tgo),e(yo,Ue),M(YA,Ue,null),e(Ue,ago),e(Ue,Kne),e(Kne,ngo),e(Ue,sgo),e(Ue,yi),e(yi,lgo),e(yi,Zne),e(Zne,igo),e(yi,dgo),e(yi,ese),e(ese,cgo),e(yi,fgo),e(Ue,mgo),e(Ue,he),e(he,Dh),e(Dh,ose),e(ose,ggo),e(Dh,hgo),e(Dh,vI),e(vI,pgo),e(Dh,ugo),e(he,_go),e(he,Gh),e(Gh,rse),e(rse,bgo),e(Gh,vgo),e(Gh,tse),e(tse,Fgo),e(Gh,Tgo),e(he,Mgo),e(he,Oh),e(Oh,ase),e(ase,Ego),e(Oh,Cgo),e(Oh,FI),e(FI,wgo),e(Oh,Ago),e(he,ygo),e(he,Vh),e(Vh,nse),e(nse,Lgo),e(Vh,xgo),e(Vh,TI),e(TI,$go),e(Vh,kgo),e(he,Sgo),e(he,Xh),e(Xh,sse),e(sse,Rgo),e(Xh,Pgo),e(Xh,MI),e(MI,Bgo),e(Xh,Igo),e(he,qgo),e(he,zh),e(zh,lse),e(lse,Ngo),e(zh,jgo),e(zh,EI),e(EI,Dgo),e(zh,Ggo),e(he,Ogo),e(he,Wh),e(Wh,ise),e(ise,Vgo),e(Wh,Xgo),e(Wh,CI),e(CI,zgo),e(Wh,Wgo),e(he,Qgo),e(he,Qh),e(Qh,dse),e(dse,Hgo),e(Qh,Ugo),e(Qh,wI),e(wI,Jgo),e(Qh,Ygo),e(he,Kgo),e(he,Hh),e(Hh,cse),e(cse,Zgo),e(Hh,eho),e(Hh,AI),e(AI,oho),e(Hh,rho),e(he,tho),e(he,Uh),e(Uh,fse),e(fse,aho),e(Uh,nho),e(Uh,yI),e(yI,sho),e(Uh,lho),e(he,iho),e(he,Jh),e(Jh,mse),e(mse,dho),e(Jh,cho),e(Jh,LI),e(LI,fho),e(Jh,mho),e(he,gho),e(he,Yh),e(Yh,gse),e(gse,hho),e(Yh,pho),e(Yh,xI),e(xI,uho),e(Yh,_ho),e(he,bho),e(he,Kh),e(Kh,hse),e(hse,vho),e(Kh,Fho),e(Kh,$I),e($I,Tho),e(Kh,Mho),e(he,Eho),e(he,Zh),e(Zh,pse),e(pse,Cho),e(Zh,who),e(Zh,kI),e(kI,Aho),e(Zh,yho),e(he,Lho),e(he,ep),e(ep,use),e(use,xho),e(ep,$ho),e(ep,SI),e(SI,kho),e(ep,Sho),e(he,Rho),e(he,op),e(op,_se),e(_se,Pho),e(op,Bho),e(op,RI),e(RI,Iho),e(op,qho),e(he,Nho),e(he,rp),e(rp,bse),e(bse,jho),e(rp,Dho),e(rp,PI),e(PI,Gho),e(rp,Oho),e(Ue,Vho),M(tp,Ue,null),e(Ue,Xho),M(ap,Ue,null),e(yo,zho),e(yo,np),M(KA,np,null),e(np,Who),e(np,vse),e(vse,Qho),b(f,hNe,_),b(f,Li,_),e(Li,sp),e(sp,Fse),M(ZA,Fse,null),e(Li,Hho),e(Li,Tse),e(Tse,Uho),b(f,pNe,_),b(f,Lo,_),M(ey,Lo,null),e(Lo,Jho),e(Lo,xi),e(xi,Yho),e(xi,BI),e(BI,Kho),e(xi,Zho),e(xi,II),e(II,epo),e(xi,opo),e(Lo,rpo),e(Lo,oy),e(oy,tpo),e(oy,Mse),e(Mse,apo),e(oy,npo),e(Lo,spo),e(Lo,tt),M(ry,tt,null),e(tt,lpo),e(tt,Ese),e(Ese,ipo),e(tt,dpo),e(tt,$i),e($i,cpo),e($i,Cse),e(Cse,fpo),e($i,mpo),e($i,qI),e(qI,gpo),e($i,hpo),e(tt,ppo),M(lp,tt,null),e(Lo,upo),e(Lo,Je),M(ty,Je,null),e(Je,_po),e(Je,wse),e(wse,bpo),e(Je,vpo),e(Je,La),e(La,Fpo),e(La,Ase),e(Ase,Tpo),e(La,Mpo),e(La,yse),e(yse,Epo),e(La,Cpo),e(La,Lse),e(Lse,wpo),e(La,Apo),e(Je,ypo),e(Je,x),e(x,ip),e(ip,xse),e(xse,Lpo),e(ip,xpo),e(ip,NI),e(NI,$po),e(ip,kpo),e(x,Spo),e(x,dp),e(dp,$se),e($se,Rpo),e(dp,Ppo),e(dp,jI),e(jI,Bpo),e(dp,Ipo),e(x,qpo),e(x,cp),e(cp,kse),e(kse,Npo),e(cp,jpo),e(cp,DI),e(DI,Dpo),e(cp,Gpo),e(x,Opo),e(x,fp),e(fp,Sse),e(Sse,Vpo),e(fp,Xpo),e(fp,GI),e(GI,zpo),e(fp,Wpo),e(x,Qpo),e(x,mp),e(mp,Rse),e(Rse,Hpo),e(mp,Upo),e(mp,OI),e(OI,Jpo),e(mp,Ypo),e(x,Kpo),e(x,gp),e(gp,Pse),e(Pse,Zpo),e(gp,euo),e(gp,VI),e(VI,ouo),e(gp,ruo),e(x,tuo),e(x,hp),e(hp,Bse),e(Bse,auo),e(hp,nuo),e(hp,XI),e(XI,suo),e(hp,luo),e(x,iuo),e(x,pp),e(pp,Ise),e(Ise,duo),e(pp,cuo),e(pp,zI),e(zI,fuo),e(pp,muo),e(x,guo),e(x,up),e(up,qse),e(qse,huo),e(up,puo),e(up,WI),e(WI,uuo),e(up,_uo),e(x,buo),e(x,_p),e(_p,Nse),e(Nse,vuo),e(_p,Fuo),e(_p,QI),e(QI,Tuo),e(_p,Muo),e(x,Euo),e(x,bp),e(bp,jse),e(jse,Cuo),e(bp,wuo),e(bp,HI),e(HI,Auo),e(bp,yuo),e(x,Luo),e(x,vp),e(vp,Dse),e(Dse,xuo),e(vp,$uo),e(vp,UI),e(UI,kuo),e(vp,Suo),e(x,Ruo),e(x,Fp),e(Fp,Gse),e(Gse,Puo),e(Fp,Buo),e(Fp,JI),e(JI,Iuo),e(Fp,quo),e(x,Nuo),e(x,Tp),e(Tp,Ose),e(Ose,juo),e(Tp,Duo),e(Tp,YI),e(YI,Guo),e(Tp,Ouo),e(x,Vuo),e(x,Mp),e(Mp,Vse),e(Vse,Xuo),e(Mp,zuo),e(Mp,KI),e(KI,Wuo),e(Mp,Quo),e(x,Huo),e(x,Ep),e(Ep,Xse),e(Xse,Uuo),e(Ep,Juo),e(Ep,ZI),e(ZI,Yuo),e(Ep,Kuo),e(x,Zuo),e(x,Cp),e(Cp,zse),e(zse,e_o),e(Cp,o_o),e(Cp,eq),e(eq,r_o),e(Cp,t_o),e(x,a_o),e(x,wp),e(wp,Wse),e(Wse,n_o),e(wp,s_o),e(wp,oq),e(oq,l_o),e(wp,i_o),e(x,d_o),e(x,Ap),e(Ap,Qse),e(Qse,c_o),e(Ap,f_o),e(Ap,rq),e(rq,m_o),e(Ap,g_o),e(x,h_o),e(x,yp),e(yp,Hse),e(Hse,p_o),e(yp,u_o),e(yp,tq),e(tq,__o),e(yp,b_o),e(x,v_o),e(x,Lp),e(Lp,Use),e(Use,F_o),e(Lp,T_o),e(Lp,aq),e(aq,M_o),e(Lp,E_o),e(x,C_o),e(x,xp),e(xp,Jse),e(Jse,w_o),e(xp,A_o),e(xp,nq),e(nq,y_o),e(xp,L_o),e(x,x_o),e(x,$p),e($p,Yse),e(Yse,$_o),e($p,k_o),e($p,sq),e(sq,S_o),e($p,R_o),e(x,P_o),e(x,kp),e(kp,Kse),e(Kse,B_o),e(kp,I_o),e(kp,lq),e(lq,q_o),e(kp,N_o),e(x,j_o),e(x,Sp),e(Sp,Zse),e(Zse,D_o),e(Sp,G_o),e(Sp,iq),e(iq,O_o),e(Sp,V_o),e(x,X_o),e(x,Rp),e(Rp,ele),e(ele,z_o),e(Rp,W_o),e(Rp,dq),e(dq,Q_o),e(Rp,H_o),e(x,U_o),e(x,Pp),e(Pp,ole),e(ole,J_o),e(Pp,Y_o),e(Pp,cq),e(cq,K_o),e(Pp,Z_o),e(x,e2o),e(x,Bp),e(Bp,rle),e(rle,o2o),e(Bp,r2o),e(Bp,fq),e(fq,t2o),e(Bp,a2o),e(x,n2o),e(x,Ip),e(Ip,tle),e(tle,s2o),e(Ip,l2o),e(Ip,mq),e(mq,i2o),e(Ip,d2o),e(x,c2o),e(x,qp),e(qp,ale),e(ale,f2o),e(qp,m2o),e(qp,gq),e(gq,g2o),e(qp,h2o),e(x,p2o),e(x,Np),e(Np,nle),e(nle,u2o),e(Np,_2o),e(Np,hq),e(hq,b2o),e(Np,v2o),e(x,F2o),e(x,jp),e(jp,sle),e(sle,T2o),e(jp,M2o),e(jp,pq),e(pq,E2o),e(jp,C2o),e(x,w2o),e(x,qs),e(qs,lle),e(lle,A2o),e(qs,y2o),e(qs,uq),e(uq,L2o),e(qs,x2o),e(qs,_q),e(_q,$2o),e(qs,k2o),e(x,S2o),e(x,Dp),e(Dp,ile),e(ile,R2o),e(Dp,P2o),e(Dp,bq),e(bq,B2o),e(Dp,I2o),e(x,q2o),e(x,Gp),e(Gp,dle),e(dle,N2o),e(Gp,j2o),e(Gp,vq),e(vq,D2o),e(Gp,G2o),e(x,O2o),e(x,Op),e(Op,cle),e(cle,V2o),e(Op,X2o),e(Op,Fq),e(Fq,z2o),e(Op,W2o),e(x,Q2o),e(x,Vp),e(Vp,fle),e(fle,H2o),e(Vp,U2o),e(Vp,Tq),e(Tq,J2o),e(Vp,Y2o),e(x,K2o),e(x,Xp),e(Xp,mle),e(mle,Z2o),e(Xp,e1o),e(Xp,Mq),e(Mq,o1o),e(Xp,r1o),e(x,t1o),e(x,zp),e(zp,gle),e(gle,a1o),e(zp,n1o),e(zp,Eq),e(Eq,s1o),e(zp,l1o),e(x,i1o),e(x,Wp),e(Wp,hle),e(hle,d1o),e(Wp,c1o),e(Wp,Cq),e(Cq,f1o),e(Wp,m1o),e(x,g1o),e(x,Qp),e(Qp,ple),e(ple,h1o),e(Qp,p1o),e(Qp,wq),e(wq,u1o),e(Qp,_1o),e(x,b1o),e(x,Hp),e(Hp,ule),e(ule,v1o),e(Hp,F1o),e(Hp,Aq),e(Aq,T1o),e(Hp,M1o),e(x,E1o),e(x,Up),e(Up,_le),e(_le,C1o),e(Up,w1o),e(Up,yq),e(yq,A1o),e(Up,y1o),e(x,L1o),e(x,Jp),e(Jp,ble),e(ble,x1o),e(Jp,$1o),e(Jp,Lq),e(Lq,k1o),e(Jp,S1o),e(x,R1o),e(x,Yp),e(Yp,vle),e(vle,P1o),e(Yp,B1o),e(Yp,xq),e(xq,I1o),e(Yp,q1o),e(x,N1o),e(x,Kp),e(Kp,Fle),e(Fle,j1o),e(Kp,D1o),e(Kp,$q),e($q,G1o),e(Kp,O1o),e(x,V1o),e(x,Zp),e(Zp,Tle),e(Tle,X1o),e(Zp,z1o),e(Zp,kq),e(kq,W1o),e(Zp,Q1o),e(x,H1o),e(x,eu),e(eu,Mle),e(Mle,U1o),e(eu,J1o),e(eu,Sq),e(Sq,Y1o),e(eu,K1o),e(x,Z1o),e(x,ou),e(ou,Ele),e(Ele,ebo),e(ou,obo),e(ou,Rq),e(Rq,rbo),e(ou,tbo),e(x,abo),e(x,ru),e(ru,Cle),e(Cle,nbo),e(ru,sbo),e(ru,Pq),e(Pq,lbo),e(ru,ibo),e(x,dbo),e(x,tu),e(tu,wle),e(wle,cbo),e(tu,fbo),e(tu,Bq),e(Bq,mbo),e(tu,gbo),e(x,hbo),e(x,au),e(au,Ale),e(Ale,pbo),e(au,ubo),e(au,Iq),e(Iq,_bo),e(au,bbo),e(x,vbo),e(x,nu),e(nu,yle),e(yle,Fbo),e(nu,Tbo),e(nu,qq),e(qq,Mbo),e(nu,Ebo),e(x,Cbo),e(x,su),e(su,Lle),e(Lle,wbo),e(su,Abo),e(su,Nq),e(Nq,ybo),e(su,Lbo),e(x,xbo),e(x,lu),e(lu,xle),e(xle,$bo),e(lu,kbo),e(lu,jq),e(jq,Sbo),e(lu,Rbo),e(x,Pbo),e(x,iu),e(iu,$le),e($le,Bbo),e(iu,Ibo),e(iu,Dq),e(Dq,qbo),e(iu,Nbo),e(x,jbo),e(x,du),e(du,kle),e(kle,Dbo),e(du,Gbo),e(du,Gq),e(Gq,Obo),e(du,Vbo),e(x,Xbo),e(x,cu),e(cu,Sle),e(Sle,zbo),e(cu,Wbo),e(cu,Oq),e(Oq,Qbo),e(cu,Hbo),e(x,Ubo),e(x,fu),e(fu,Rle),e(Rle,Jbo),e(fu,Ybo),e(fu,Vq),e(Vq,Kbo),e(fu,Zbo),e(x,e4o),e(x,mu),e(mu,Ple),e(Ple,o4o),e(mu,r4o),e(mu,Xq),e(Xq,t4o),e(mu,a4o),e(x,n4o),e(x,gu),e(gu,Ble),e(Ble,s4o),e(gu,l4o),e(gu,zq),e(zq,i4o),e(gu,d4o),e(x,c4o),e(x,hu),e(hu,Ile),e(Ile,f4o),e(hu,m4o),e(hu,Wq),e(Wq,g4o),e(hu,h4o),e(x,p4o),e(x,pu),e(pu,qle),e(qle,u4o),e(pu,_4o),e(pu,Qq),e(Qq,b4o),e(pu,v4o),e(x,F4o),e(x,uu),e(uu,Nle),e(Nle,T4o),e(uu,M4o),e(uu,Hq),e(Hq,E4o),e(uu,C4o),e(x,w4o),e(x,_u),e(_u,jle),e(jle,A4o),e(_u,y4o),e(_u,Uq),e(Uq,L4o),e(_u,x4o),e(x,$4o),e(x,bu),e(bu,Dle),e(Dle,k4o),e(bu,S4o),e(bu,Jq),e(Jq,R4o),e(bu,P4o),e(x,B4o),e(x,vu),e(vu,Gle),e(Gle,I4o),e(vu,q4o),e(vu,Yq),e(Yq,N4o),e(vu,j4o),e(x,D4o),e(x,Fu),e(Fu,Ole),e(Ole,G4o),e(Fu,O4o),e(Fu,Kq),e(Kq,V4o),e(Fu,X4o),e(x,z4o),e(x,Tu),e(Tu,Vle),e(Vle,W4o),e(Tu,Q4o),e(Tu,Zq),e(Zq,H4o),e(Tu,U4o),e(x,J4o),e(x,Mu),e(Mu,Xle),e(Xle,Y4o),e(Mu,K4o),e(Mu,eN),e(eN,Z4o),e(Mu,evo),e(x,ovo),e(x,Eu),e(Eu,zle),e(zle,rvo),e(Eu,tvo),e(Eu,oN),e(oN,avo),e(Eu,nvo),e(x,svo),e(x,Cu),e(Cu,Wle),e(Wle,lvo),e(Cu,ivo),e(Cu,rN),e(rN,dvo),e(Cu,cvo),e(x,fvo),e(x,wu),e(wu,Qle),e(Qle,mvo),e(wu,gvo),e(wu,tN),e(tN,hvo),e(wu,pvo),e(x,uvo),e(x,Au),e(Au,Hle),e(Hle,_vo),e(Au,bvo),e(Au,aN),e(aN,vvo),e(Au,Fvo),e(x,Tvo),e(x,yu),e(yu,Ule),e(Ule,Mvo),e(yu,Evo),e(yu,nN),e(nN,Cvo),e(yu,wvo),e(x,Avo),e(x,Lu),e(Lu,Jle),e(Jle,yvo),e(Lu,Lvo),e(Lu,sN),e(sN,xvo),e(Lu,$vo),e(x,kvo),e(x,xu),e(xu,Yle),e(Yle,Svo),e(xu,Rvo),e(xu,lN),e(lN,Pvo),e(xu,Bvo),e(x,Ivo),e(x,$u),e($u,Kle),e(Kle,qvo),e($u,Nvo),e($u,iN),e(iN,jvo),e($u,Dvo),e(x,Gvo),e(x,ku),e(ku,Zle),e(Zle,Ovo),e(ku,Vvo),e(ku,dN),e(dN,Xvo),e(ku,zvo),e(x,Wvo),e(x,Su),e(Su,eie),e(eie,Qvo),e(Su,Hvo),e(Su,cN),e(cN,Uvo),e(Su,Jvo),e(x,Yvo),e(x,Ru),e(Ru,oie),e(oie,Kvo),e(Ru,Zvo),e(Ru,fN),e(fN,e5o),e(Ru,o5o),e(x,r5o),e(x,Pu),e(Pu,rie),e(rie,t5o),e(Pu,a5o),e(Pu,mN),e(mN,n5o),e(Pu,s5o),e(x,l5o),e(x,Bu),e(Bu,tie),e(tie,i5o),e(Bu,d5o),e(Bu,gN),e(gN,c5o),e(Bu,f5o),e(x,m5o),e(x,Iu),e(Iu,aie),e(aie,g5o),e(Iu,h5o),e(Iu,hN),e(hN,p5o),e(Iu,u5o),e(x,_5o),e(x,qu),e(qu,nie),e(nie,b5o),e(qu,v5o),e(qu,pN),e(pN,F5o),e(qu,T5o),e(x,M5o),e(x,Nu),e(Nu,sie),e(sie,E5o),e(Nu,C5o),e(Nu,uN),e(uN,w5o),e(Nu,A5o),e(x,y5o),e(x,ju),e(ju,lie),e(lie,L5o),e(ju,x5o),e(ju,_N),e(_N,$5o),e(ju,k5o),e(x,S5o),e(x,Du),e(Du,iie),e(iie,R5o),e(Du,P5o),e(Du,bN),e(bN,B5o),e(Du,I5o),e(x,q5o),e(x,Gu),e(Gu,die),e(die,N5o),e(Gu,j5o),e(Gu,vN),e(vN,D5o),e(Gu,G5o),e(x,O5o),e(x,Ou),e(Ou,cie),e(cie,V5o),e(Ou,X5o),e(Ou,FN),e(FN,z5o),e(Ou,W5o),e(x,Q5o),e(x,Vu),e(Vu,fie),e(fie,H5o),e(Vu,U5o),e(Vu,TN),e(TN,J5o),e(Vu,Y5o),e(x,K5o),e(x,Xu),e(Xu,mie),e(mie,Z5o),e(Xu,eFo),e(Xu,MN),e(MN,oFo),e(Xu,rFo),e(x,tFo),e(x,zu),e(zu,gie),e(gie,aFo),e(zu,nFo),e(zu,EN),e(EN,sFo),e(zu,lFo),e(x,iFo),e(x,Wu),e(Wu,hie),e(hie,dFo),e(Wu,cFo),e(Wu,CN),e(CN,fFo),e(Wu,mFo),e(x,gFo),e(x,Qu),e(Qu,pie),e(pie,hFo),e(Qu,pFo),e(Qu,wN),e(wN,uFo),e(Qu,_Fo),e(x,bFo),e(x,Hu),e(Hu,uie),e(uie,vFo),e(Hu,FFo),e(Hu,AN),e(AN,TFo),e(Hu,MFo),e(x,EFo),e(x,Uu),e(Uu,_ie),e(_ie,CFo),e(Uu,wFo),e(Uu,yN),e(yN,AFo),e(Uu,yFo),e(x,LFo),e(x,Ju),e(Ju,bie),e(bie,xFo),e(Ju,$Fo),e(Ju,LN),e(LN,kFo),e(Ju,SFo),e(x,RFo),e(x,Yu),e(Yu,vie),e(vie,PFo),e(Yu,BFo),e(Yu,xN),e(xN,IFo),e(Yu,qFo),e(x,NFo),e(x,Ku),e(Ku,Fie),e(Fie,jFo),e(Ku,DFo),e(Ku,$N),e($N,GFo),e(Ku,OFo),e(x,VFo),e(x,Zu),e(Zu,Tie),e(Tie,XFo),e(Zu,zFo),e(Zu,kN),e(kN,WFo),e(Zu,QFo),e(x,HFo),e(x,e_),e(e_,Mie),e(Mie,UFo),e(e_,JFo),e(e_,SN),e(SN,YFo),e(e_,KFo),e(Je,ZFo),e(Je,o_),e(o_,eTo),e(o_,Eie),e(Eie,oTo),e(o_,rTo),e(o_,Cie),e(Cie,tTo),e(Je,aTo),M(r_,Je,null),b(f,uNe,_),b(f,ki,_),e(ki,t_),e(t_,wie),M(ay,wie,null),e(ki,nTo),e(ki,Aie),e(Aie,sTo),b(f,_Ne,_),b(f,xo,_),M(ny,xo,null),e(xo,lTo),e(xo,Si),e(Si,iTo),e(Si,RN),e(RN,dTo),e(Si,cTo),e(Si,PN),e(PN,fTo),e(Si,mTo),e(xo,gTo),e(xo,sy),e(sy,hTo),e(sy,yie),e(yie,pTo),e(sy,uTo),e(xo,_To),e(xo,at),M(ly,at,null),e(at,bTo),e(at,Lie),e(Lie,vTo),e(at,FTo),e(at,Ri),e(Ri,TTo),e(Ri,xie),e(xie,MTo),e(Ri,ETo),e(Ri,BN),e(BN,CTo),e(Ri,wTo),e(at,ATo),M(a_,at,null),e(xo,yTo),e(xo,Ye),M(iy,Ye,null),e(Ye,LTo),e(Ye,$ie),e($ie,xTo),e(Ye,$To),e(Ye,xa),e(xa,kTo),e(xa,kie),e(kie,STo),e(xa,RTo),e(xa,Sie),e(Sie,PTo),e(xa,BTo),e(xa,Rie),e(Rie,ITo),e(xa,qTo),e(Ye,NTo),e(Ye,G),e(G,n_),e(n_,Pie),e(Pie,jTo),e(n_,DTo),e(n_,IN),e(IN,GTo),e(n_,OTo),e(G,VTo),e(G,s_),e(s_,Bie),e(Bie,XTo),e(s_,zTo),e(s_,qN),e(qN,WTo),e(s_,QTo),e(G,HTo),e(G,l_),e(l_,Iie),e(Iie,UTo),e(l_,JTo),e(l_,NN),e(NN,YTo),e(l_,KTo),e(G,ZTo),e(G,i_),e(i_,qie),e(qie,e7o),e(i_,o7o),e(i_,jN),e(jN,r7o),e(i_,t7o),e(G,a7o),e(G,d_),e(d_,Nie),e(Nie,n7o),e(d_,s7o),e(d_,DN),e(DN,l7o),e(d_,i7o),e(G,d7o),e(G,c_),e(c_,jie),e(jie,c7o),e(c_,f7o),e(c_,GN),e(GN,m7o),e(c_,g7o),e(G,h7o),e(G,f_),e(f_,Die),e(Die,p7o),e(f_,u7o),e(f_,ON),e(ON,_7o),e(f_,b7o),e(G,v7o),e(G,m_),e(m_,Gie),e(Gie,F7o),e(m_,T7o),e(m_,VN),e(VN,M7o),e(m_,E7o),e(G,C7o),e(G,g_),e(g_,Oie),e(Oie,w7o),e(g_,A7o),e(g_,XN),e(XN,y7o),e(g_,L7o),e(G,x7o),e(G,h_),e(h_,Vie),e(Vie,$7o),e(h_,k7o),e(h_,zN),e(zN,S7o),e(h_,R7o),e(G,P7o),e(G,p_),e(p_,Xie),e(Xie,B7o),e(p_,I7o),e(p_,WN),e(WN,q7o),e(p_,N7o),e(G,j7o),e(G,u_),e(u_,zie),e(zie,D7o),e(u_,G7o),e(u_,QN),e(QN,O7o),e(u_,V7o),e(G,X7o),e(G,__),e(__,Wie),e(Wie,z7o),e(__,W7o),e(__,HN),e(HN,Q7o),e(__,H7o),e(G,U7o),e(G,b_),e(b_,Qie),e(Qie,J7o),e(b_,Y7o),e(b_,UN),e(UN,K7o),e(b_,Z7o),e(G,eMo),e(G,v_),e(v_,Hie),e(Hie,oMo),e(v_,rMo),e(v_,JN),e(JN,tMo),e(v_,aMo),e(G,nMo),e(G,F_),e(F_,Uie),e(Uie,sMo),e(F_,lMo),e(F_,YN),e(YN,iMo),e(F_,dMo),e(G,cMo),e(G,T_),e(T_,Jie),e(Jie,fMo),e(T_,mMo),e(T_,KN),e(KN,gMo),e(T_,hMo),e(G,pMo),e(G,M_),e(M_,Yie),e(Yie,uMo),e(M_,_Mo),e(M_,ZN),e(ZN,bMo),e(M_,vMo),e(G,FMo),e(G,E_),e(E_,Kie),e(Kie,TMo),e(E_,MMo),e(E_,ej),e(ej,EMo),e(E_,CMo),e(G,wMo),e(G,C_),e(C_,Zie),e(Zie,AMo),e(C_,yMo),e(C_,oj),e(oj,LMo),e(C_,xMo),e(G,$Mo),e(G,w_),e(w_,ede),e(ede,kMo),e(w_,SMo),e(w_,rj),e(rj,RMo),e(w_,PMo),e(G,BMo),e(G,A_),e(A_,ode),e(ode,IMo),e(A_,qMo),e(A_,tj),e(tj,NMo),e(A_,jMo),e(G,DMo),e(G,y_),e(y_,rde),e(rde,GMo),e(y_,OMo),e(y_,aj),e(aj,VMo),e(y_,XMo),e(G,zMo),e(G,L_),e(L_,tde),e(tde,WMo),e(L_,QMo),e(L_,nj),e(nj,HMo),e(L_,UMo),e(G,JMo),e(G,x_),e(x_,ade),e(ade,YMo),e(x_,KMo),e(x_,sj),e(sj,ZMo),e(x_,eEo),e(G,oEo),e(G,$_),e($_,nde),e(nde,rEo),e($_,tEo),e($_,lj),e(lj,aEo),e($_,nEo),e(G,sEo),e(G,k_),e(k_,sde),e(sde,lEo),e(k_,iEo),e(k_,ij),e(ij,dEo),e(k_,cEo),e(G,fEo),e(G,S_),e(S_,lde),e(lde,mEo),e(S_,gEo),e(S_,dj),e(dj,hEo),e(S_,pEo),e(G,uEo),e(G,R_),e(R_,ide),e(ide,_Eo),e(R_,bEo),e(R_,cj),e(cj,vEo),e(R_,FEo),e(G,TEo),e(G,P_),e(P_,dde),e(dde,MEo),e(P_,EEo),e(P_,fj),e(fj,CEo),e(P_,wEo),e(G,AEo),e(G,B_),e(B_,cde),e(cde,yEo),e(B_,LEo),e(B_,mj),e(mj,xEo),e(B_,$Eo),e(G,kEo),e(G,I_),e(I_,fde),e(fde,SEo),e(I_,REo),e(I_,gj),e(gj,PEo),e(I_,BEo),e(G,IEo),e(G,q_),e(q_,mde),e(mde,qEo),e(q_,NEo),e(q_,hj),e(hj,jEo),e(q_,DEo),e(G,GEo),e(G,N_),e(N_,gde),e(gde,OEo),e(N_,VEo),e(N_,pj),e(pj,XEo),e(N_,zEo),e(G,WEo),e(G,j_),e(j_,hde),e(hde,QEo),e(j_,HEo),e(j_,uj),e(uj,UEo),e(j_,JEo),e(G,YEo),e(G,D_),e(D_,pde),e(pde,KEo),e(D_,ZEo),e(D_,_j),e(_j,eCo),e(D_,oCo),e(G,rCo),e(G,G_),e(G_,ude),e(ude,tCo),e(G_,aCo),e(G_,bj),e(bj,nCo),e(G_,sCo),e(G,lCo),e(G,O_),e(O_,_de),e(_de,iCo),e(O_,dCo),e(O_,vj),e(vj,cCo),e(O_,fCo),e(G,mCo),e(G,V_),e(V_,bde),e(bde,gCo),e(V_,hCo),e(V_,Fj),e(Fj,pCo),e(V_,uCo),e(G,_Co),e(G,X_),e(X_,vde),e(vde,bCo),e(X_,vCo),e(X_,Tj),e(Tj,FCo),e(X_,TCo),e(G,MCo),e(G,z_),e(z_,Fde),e(Fde,ECo),e(z_,CCo),e(z_,Mj),e(Mj,wCo),e(z_,ACo),e(G,yCo),e(G,W_),e(W_,Tde),e(Tde,LCo),e(W_,xCo),e(W_,Ej),e(Ej,$Co),e(W_,kCo),e(Ye,SCo),e(Ye,Q_),e(Q_,RCo),e(Q_,Mde),e(Mde,PCo),e(Q_,BCo),e(Q_,Ede),e(Ede,ICo),e(Ye,qCo),M(H_,Ye,null),b(f,bNe,_),b(f,Pi,_),e(Pi,U_),e(U_,Cde),M(dy,Cde,null),e(Pi,NCo),e(Pi,wde),e(wde,jCo),b(f,vNe,_),b(f,$o,_),M(cy,$o,null),e($o,DCo),e($o,Bi),e(Bi,GCo),e(Bi,Cj),e(Cj,OCo),e(Bi,VCo),e(Bi,wj),e(wj,XCo),e(Bi,zCo),e($o,WCo),e($o,fy),e(fy,QCo),e(fy,Ade),e(Ade,HCo),e(fy,UCo),e($o,JCo),e($o,nt),M(my,nt,null),e(nt,YCo),e(nt,yde),e(yde,KCo),e(nt,ZCo),e(nt,Ii),e(Ii,e3o),e(Ii,Lde),e(Lde,o3o),e(Ii,r3o),e(Ii,Aj),e(Aj,t3o),e(Ii,a3o),e(nt,n3o),M(J_,nt,null),e($o,s3o),e($o,Ke),M(gy,Ke,null),e(Ke,l3o),e(Ke,xde),e(xde,i3o),e(Ke,d3o),e(Ke,$a),e($a,c3o),e($a,$de),e($de,f3o),e($a,m3o),e($a,kde),e(kde,g3o),e($a,h3o),e($a,Sde),e(Sde,p3o),e($a,u3o),e(Ke,_3o),e(Ke,z),e(z,Y_),e(Y_,Rde),e(Rde,b3o),e(Y_,v3o),e(Y_,yj),e(yj,F3o),e(Y_,T3o),e(z,M3o),e(z,K_),e(K_,Pde),e(Pde,E3o),e(K_,C3o),e(K_,Lj),e(Lj,w3o),e(K_,A3o),e(z,y3o),e(z,Z_),e(Z_,Bde),e(Bde,L3o),e(Z_,x3o),e(Z_,xj),e(xj,$3o),e(Z_,k3o),e(z,S3o),e(z,e2),e(e2,Ide),e(Ide,R3o),e(e2,P3o),e(e2,$j),e($j,B3o),e(e2,I3o),e(z,q3o),e(z,o2),e(o2,qde),e(qde,N3o),e(o2,j3o),e(o2,kj),e(kj,D3o),e(o2,G3o),e(z,O3o),e(z,r2),e(r2,Nde),e(Nde,V3o),e(r2,X3o),e(r2,Sj),e(Sj,z3o),e(r2,W3o),e(z,Q3o),e(z,t2),e(t2,jde),e(jde,H3o),e(t2,U3o),e(t2,Rj),e(Rj,J3o),e(t2,Y3o),e(z,K3o),e(z,a2),e(a2,Dde),e(Dde,Z3o),e(a2,ewo),e(a2,Pj),e(Pj,owo),e(a2,rwo),e(z,two),e(z,n2),e(n2,Gde),e(Gde,awo),e(n2,nwo),e(n2,Bj),e(Bj,swo),e(n2,lwo),e(z,iwo),e(z,s2),e(s2,Ode),e(Ode,dwo),e(s2,cwo),e(s2,Ij),e(Ij,fwo),e(s2,mwo),e(z,gwo),e(z,l2),e(l2,Vde),e(Vde,hwo),e(l2,pwo),e(l2,qj),e(qj,uwo),e(l2,_wo),e(z,bwo),e(z,i2),e(i2,Xde),e(Xde,vwo),e(i2,Fwo),e(i2,Nj),e(Nj,Two),e(i2,Mwo),e(z,Ewo),e(z,d2),e(d2,zde),e(zde,Cwo),e(d2,wwo),e(d2,jj),e(jj,Awo),e(d2,ywo),e(z,Lwo),e(z,c2),e(c2,Wde),e(Wde,xwo),e(c2,$wo),e(c2,Dj),e(Dj,kwo),e(c2,Swo),e(z,Rwo),e(z,f2),e(f2,Qde),e(Qde,Pwo),e(f2,Bwo),e(f2,Gj),e(Gj,Iwo),e(f2,qwo),e(z,Nwo),e(z,m2),e(m2,Hde),e(Hde,jwo),e(m2,Dwo),e(m2,Oj),e(Oj,Gwo),e(m2,Owo),e(z,Vwo),e(z,g2),e(g2,Ude),e(Ude,Xwo),e(g2,zwo),e(g2,Vj),e(Vj,Wwo),e(g2,Qwo),e(z,Hwo),e(z,h2),e(h2,Jde),e(Jde,Uwo),e(h2,Jwo),e(h2,Xj),e(Xj,Ywo),e(h2,Kwo),e(z,Zwo),e(z,p2),e(p2,Yde),e(Yde,e0o),e(p2,o0o),e(p2,zj),e(zj,r0o),e(p2,t0o),e(z,a0o),e(z,u2),e(u2,Kde),e(Kde,n0o),e(u2,s0o),e(u2,Wj),e(Wj,l0o),e(u2,i0o),e(z,d0o),e(z,_2),e(_2,Zde),e(Zde,c0o),e(_2,f0o),e(_2,Qj),e(Qj,m0o),e(_2,g0o),e(z,h0o),e(z,b2),e(b2,ece),e(ece,p0o),e(b2,u0o),e(b2,Hj),e(Hj,_0o),e(b2,b0o),e(z,v0o),e(z,v2),e(v2,oce),e(oce,F0o),e(v2,T0o),e(v2,Uj),e(Uj,M0o),e(v2,E0o),e(z,C0o),e(z,F2),e(F2,rce),e(rce,w0o),e(F2,A0o),e(F2,Jj),e(Jj,y0o),e(F2,L0o),e(z,x0o),e(z,T2),e(T2,tce),e(tce,$0o),e(T2,k0o),e(T2,Yj),e(Yj,S0o),e(T2,R0o),e(z,P0o),e(z,M2),e(M2,ace),e(ace,B0o),e(M2,I0o),e(M2,Kj),e(Kj,q0o),e(M2,N0o),e(z,j0o),e(z,E2),e(E2,nce),e(nce,D0o),e(E2,G0o),e(E2,Zj),e(Zj,O0o),e(E2,V0o),e(z,X0o),e(z,C2),e(C2,sce),e(sce,z0o),e(C2,W0o),e(C2,eD),e(eD,Q0o),e(C2,H0o),e(z,U0o),e(z,w2),e(w2,lce),e(lce,J0o),e(w2,Y0o),e(w2,oD),e(oD,K0o),e(w2,Z0o),e(z,e6o),e(z,A2),e(A2,ice),e(ice,o6o),e(A2,r6o),e(A2,rD),e(rD,t6o),e(A2,a6o),e(z,n6o),e(z,y2),e(y2,dce),e(dce,s6o),e(y2,l6o),e(y2,tD),e(tD,i6o),e(y2,d6o),e(z,c6o),e(z,L2),e(L2,cce),e(cce,f6o),e(L2,m6o),e(L2,aD),e(aD,g6o),e(L2,h6o),e(z,p6o),e(z,x2),e(x2,fce),e(fce,u6o),e(x2,_6o),e(x2,nD),e(nD,b6o),e(x2,v6o),e(z,F6o),e(z,$2),e($2,mce),e(mce,T6o),e($2,M6o),e($2,sD),e(sD,E6o),e($2,C6o),e(z,w6o),e(z,k2),e(k2,gce),e(gce,A6o),e(k2,y6o),e(k2,lD),e(lD,L6o),e(k2,x6o),e(z,$6o),e(z,S2),e(S2,hce),e(hce,k6o),e(S2,S6o),e(S2,iD),e(iD,R6o),e(S2,P6o),e(z,B6o),e(z,R2),e(R2,pce),e(pce,I6o),e(R2,q6o),e(R2,dD),e(dD,N6o),e(R2,j6o),e(Ke,D6o),e(Ke,P2),e(P2,G6o),e(P2,uce),e(uce,O6o),e(P2,V6o),e(P2,_ce),e(_ce,X6o),e(Ke,z6o),M(B2,Ke,null),b(f,FNe,_),b(f,qi,_),e(qi,I2),e(I2,bce),M(hy,bce,null),e(qi,W6o),e(qi,vce),e(vce,Q6o),b(f,TNe,_),b(f,ko,_),M(py,ko,null),e(ko,H6o),e(ko,Ni),e(Ni,U6o),e(Ni,cD),e(cD,J6o),e(Ni,Y6o),e(Ni,fD),e(fD,K6o),e(Ni,Z6o),e(ko,eAo),e(ko,uy),e(uy,oAo),e(uy,Fce),e(Fce,rAo),e(uy,tAo),e(ko,aAo),e(ko,st),M(_y,st,null),e(st,nAo),e(st,Tce),e(Tce,sAo),e(st,lAo),e(st,ji),e(ji,iAo),e(ji,Mce),e(Mce,dAo),e(ji,cAo),e(ji,mD),e(mD,fAo),e(ji,mAo),e(st,gAo),M(q2,st,null),e(ko,hAo),e(ko,Ze),M(by,Ze,null),e(Ze,pAo),e(Ze,Ece),e(Ece,uAo),e(Ze,_Ao),e(Ze,ka),e(ka,bAo),e(ka,Cce),e(Cce,vAo),e(ka,FAo),e(ka,wce),e(wce,TAo),e(ka,MAo),e(ka,Ace),e(Ace,EAo),e(ka,CAo),e(Ze,wAo),e(Ze,Q),e(Q,N2),e(N2,yce),e(yce,AAo),e(N2,yAo),e(N2,gD),e(gD,LAo),e(N2,xAo),e(Q,$Ao),e(Q,j2),e(j2,Lce),e(Lce,kAo),e(j2,SAo),e(j2,hD),e(hD,RAo),e(j2,PAo),e(Q,BAo),e(Q,D2),e(D2,xce),e(xce,IAo),e(D2,qAo),e(D2,pD),e(pD,NAo),e(D2,jAo),e(Q,DAo),e(Q,G2),e(G2,$ce),e($ce,GAo),e(G2,OAo),e(G2,uD),e(uD,VAo),e(G2,XAo),e(Q,zAo),e(Q,O2),e(O2,kce),e(kce,WAo),e(O2,QAo),e(O2,_D),e(_D,HAo),e(O2,UAo),e(Q,JAo),e(Q,V2),e(V2,Sce),e(Sce,YAo),e(V2,KAo),e(V2,bD),e(bD,ZAo),e(V2,eyo),e(Q,oyo),e(Q,X2),e(X2,Rce),e(Rce,ryo),e(X2,tyo),e(X2,vD),e(vD,ayo),e(X2,nyo),e(Q,syo),e(Q,z2),e(z2,Pce),e(Pce,lyo),e(z2,iyo),e(z2,FD),e(FD,dyo),e(z2,cyo),e(Q,fyo),e(Q,W2),e(W2,Bce),e(Bce,myo),e(W2,gyo),e(W2,TD),e(TD,hyo),e(W2,pyo),e(Q,uyo),e(Q,Q2),e(Q2,Ice),e(Ice,_yo),e(Q2,byo),e(Q2,MD),e(MD,vyo),e(Q2,Fyo),e(Q,Tyo),e(Q,H2),e(H2,qce),e(qce,Myo),e(H2,Eyo),e(H2,ED),e(ED,Cyo),e(H2,wyo),e(Q,Ayo),e(Q,U2),e(U2,Nce),e(Nce,yyo),e(U2,Lyo),e(U2,CD),e(CD,xyo),e(U2,$yo),e(Q,kyo),e(Q,J2),e(J2,jce),e(jce,Syo),e(J2,Ryo),e(J2,wD),e(wD,Pyo),e(J2,Byo),e(Q,Iyo),e(Q,Y2),e(Y2,Dce),e(Dce,qyo),e(Y2,Nyo),e(Y2,AD),e(AD,jyo),e(Y2,Dyo),e(Q,Gyo),e(Q,K2),e(K2,Gce),e(Gce,Oyo),e(K2,Vyo),e(K2,yD),e(yD,Xyo),e(K2,zyo),e(Q,Wyo),e(Q,Z2),e(Z2,Oce),e(Oce,Qyo),e(Z2,Hyo),e(Z2,LD),e(LD,Uyo),e(Z2,Jyo),e(Q,Yyo),e(Q,e1),e(e1,Vce),e(Vce,Kyo),e(e1,Zyo),e(e1,xD),e(xD,eLo),e(e1,oLo),e(Q,rLo),e(Q,o1),e(o1,Xce),e(Xce,tLo),e(o1,aLo),e(o1,$D),e($D,nLo),e(o1,sLo),e(Q,lLo),e(Q,r1),e(r1,zce),e(zce,iLo),e(r1,dLo),e(r1,kD),e(kD,cLo),e(r1,fLo),e(Q,mLo),e(Q,t1),e(t1,Wce),e(Wce,gLo),e(t1,hLo),e(t1,SD),e(SD,pLo),e(t1,uLo),e(Q,_Lo),e(Q,a1),e(a1,Qce),e(Qce,bLo),e(a1,vLo),e(a1,RD),e(RD,FLo),e(a1,TLo),e(Q,MLo),e(Q,n1),e(n1,Hce),e(Hce,ELo),e(n1,CLo),e(n1,PD),e(PD,wLo),e(n1,ALo),e(Q,yLo),e(Q,s1),e(s1,Uce),e(Uce,LLo),e(s1,xLo),e(s1,BD),e(BD,$Lo),e(s1,kLo),e(Q,SLo),e(Q,l1),e(l1,Jce),e(Jce,RLo),e(l1,PLo),e(l1,ID),e(ID,BLo),e(l1,ILo),e(Q,qLo),e(Q,i1),e(i1,Yce),e(Yce,NLo),e(i1,jLo),e(i1,qD),e(qD,DLo),e(i1,GLo),e(Q,OLo),e(Q,d1),e(d1,Kce),e(Kce,VLo),e(d1,XLo),e(d1,ND),e(ND,zLo),e(d1,WLo),e(Q,QLo),e(Q,c1),e(c1,Zce),e(Zce,HLo),e(c1,ULo),e(c1,jD),e(jD,JLo),e(c1,YLo),e(Q,KLo),e(Q,f1),e(f1,efe),e(efe,ZLo),e(f1,e8o),e(f1,DD),e(DD,o8o),e(f1,r8o),e(Q,t8o),e(Q,m1),e(m1,ofe),e(ofe,a8o),e(m1,n8o),e(m1,GD),e(GD,s8o),e(m1,l8o),e(Q,i8o),e(Q,g1),e(g1,rfe),e(rfe,d8o),e(g1,c8o),e(g1,OD),e(OD,f8o),e(g1,m8o),e(Q,g8o),e(Q,h1),e(h1,tfe),e(tfe,h8o),e(h1,p8o),e(h1,afe),e(afe,u8o),e(h1,_8o),e(Q,b8o),e(Q,p1),e(p1,nfe),e(nfe,v8o),e(p1,F8o),e(p1,VD),e(VD,T8o),e(p1,M8o),e(Q,E8o),e(Q,u1),e(u1,sfe),e(sfe,C8o),e(u1,w8o),e(u1,XD),e(XD,A8o),e(u1,y8o),e(Q,L8o),e(Q,_1),e(_1,lfe),e(lfe,x8o),e(_1,$8o),e(_1,zD),e(zD,k8o),e(_1,S8o),e(Q,R8o),e(Q,b1),e(b1,ife),e(ife,P8o),e(b1,B8o),e(b1,WD),e(WD,I8o),e(b1,q8o),e(Ze,N8o),e(Ze,v1),e(v1,j8o),e(v1,dfe),e(dfe,D8o),e(v1,G8o),e(v1,cfe),e(cfe,O8o),e(Ze,V8o),M(F1,Ze,null),b(f,MNe,_),b(f,Di,_),e(Di,T1),e(T1,ffe),M(vy,ffe,null),e(Di,X8o),e(Di,mfe),e(mfe,z8o),b(f,ENe,_),b(f,So,_),M(Fy,So,null),e(So,W8o),e(So,Gi),e(Gi,Q8o),e(Gi,QD),e(QD,H8o),e(Gi,U8o),e(Gi,HD),e(HD,J8o),e(Gi,Y8o),e(So,K8o),e(So,Ty),e(Ty,Z8o),e(Ty,gfe),e(gfe,e9o),e(Ty,o9o),e(So,r9o),e(So,lt),M(My,lt,null),e(lt,t9o),e(lt,hfe),e(hfe,a9o),e(lt,n9o),e(lt,Oi),e(Oi,s9o),e(Oi,pfe),e(pfe,l9o),e(Oi,i9o),e(Oi,UD),e(UD,d9o),e(Oi,c9o),e(lt,f9o),M(M1,lt,null),e(So,m9o),e(So,eo),M(Ey,eo,null),e(eo,g9o),e(eo,ufe),e(ufe,h9o),e(eo,p9o),e(eo,Sa),e(Sa,u9o),e(Sa,_fe),e(_fe,_9o),e(Sa,b9o),e(Sa,bfe),e(bfe,v9o),e(Sa,F9o),e(Sa,vfe),e(vfe,T9o),e(Sa,M9o),e(eo,E9o),e(eo,ue),e(ue,E1),e(E1,Ffe),e(Ffe,C9o),e(E1,w9o),e(E1,JD),e(JD,A9o),e(E1,y9o),e(ue,L9o),e(ue,C1),e(C1,Tfe),e(Tfe,x9o),e(C1,$9o),e(C1,YD),e(YD,k9o),e(C1,S9o),e(ue,R9o),e(ue,w1),e(w1,Mfe),e(Mfe,P9o),e(w1,B9o),e(w1,KD),e(KD,I9o),e(w1,q9o),e(ue,N9o),e(ue,A1),e(A1,Efe),e(Efe,j9o),e(A1,D9o),e(A1,ZD),e(ZD,G9o),e(A1,O9o),e(ue,V9o),e(ue,y1),e(y1,Cfe),e(Cfe,X9o),e(y1,z9o),e(y1,eG),e(eG,W9o),e(y1,Q9o),e(ue,H9o),e(ue,L1),e(L1,wfe),e(wfe,U9o),e(L1,J9o),e(L1,oG),e(oG,Y9o),e(L1,K9o),e(ue,Z9o),e(ue,x1),e(x1,Afe),e(Afe,exo),e(x1,oxo),e(x1,rG),e(rG,rxo),e(x1,txo),e(ue,axo),e(ue,$1),e($1,yfe),e(yfe,nxo),e($1,sxo),e($1,tG),e(tG,lxo),e($1,ixo),e(ue,dxo),e(ue,k1),e(k1,Lfe),e(Lfe,cxo),e(k1,fxo),e(k1,aG),e(aG,mxo),e(k1,gxo),e(ue,hxo),e(ue,S1),e(S1,xfe),e(xfe,pxo),e(S1,uxo),e(S1,nG),e(nG,_xo),e(S1,bxo),e(ue,vxo),e(ue,R1),e(R1,$fe),e($fe,Fxo),e(R1,Txo),e(R1,sG),e(sG,Mxo),e(R1,Exo),e(ue,Cxo),e(ue,P1),e(P1,kfe),e(kfe,wxo),e(P1,Axo),e(P1,lG),e(lG,yxo),e(P1,Lxo),e(ue,xxo),e(ue,B1),e(B1,Sfe),e(Sfe,$xo),e(B1,kxo),e(B1,iG),e(iG,Sxo),e(B1,Rxo),e(ue,Pxo),e(ue,I1),e(I1,Rfe),e(Rfe,Bxo),e(I1,Ixo),e(I1,dG),e(dG,qxo),e(I1,Nxo),e(ue,jxo),e(ue,q1),e(q1,Pfe),e(Pfe,Dxo),e(q1,Gxo),e(q1,cG),e(cG,Oxo),e(q1,Vxo),e(ue,Xxo),e(ue,N1),e(N1,Bfe),e(Bfe,zxo),e(N1,Wxo),e(N1,fG),e(fG,Qxo),e(N1,Hxo),e(eo,Uxo),e(eo,j1),e(j1,Jxo),e(j1,Ife),e(Ife,Yxo),e(j1,Kxo),e(j1,qfe),e(qfe,Zxo),e(eo,e$o),M(D1,eo,null),b(f,CNe,_),b(f,Vi,_),e(Vi,G1),e(G1,Nfe),M(Cy,Nfe,null),e(Vi,o$o),e(Vi,jfe),e(jfe,r$o),b(f,wNe,_),b(f,Ro,_),M(wy,Ro,null),e(Ro,t$o),e(Ro,Xi),e(Xi,a$o),e(Xi,mG),e(mG,n$o),e(Xi,s$o),e(Xi,gG),e(gG,l$o),e(Xi,i$o),e(Ro,d$o),e(Ro,Ay),e(Ay,c$o),e(Ay,Dfe),e(Dfe,f$o),e(Ay,m$o),e(Ro,g$o),e(Ro,it),M(yy,it,null),e(it,h$o),e(it,Gfe),e(Gfe,p$o),e(it,u$o),e(it,zi),e(zi,_$o),e(zi,Ofe),e(Ofe,b$o),e(zi,v$o),e(zi,hG),e(hG,F$o),e(zi,T$o),e(it,M$o),M(O1,it,null),e(Ro,E$o),e(Ro,oo),M(Ly,oo,null),e(oo,C$o),e(oo,Vfe),e(Vfe,w$o),e(oo,A$o),e(oo,Ra),e(Ra,y$o),e(Ra,Xfe),e(Xfe,L$o),e(Ra,x$o),e(Ra,zfe),e(zfe,$$o),e(Ra,k$o),e(Ra,Wfe),e(Wfe,S$o),e(Ra,R$o),e(oo,P$o),e(oo,q),e(q,V1),e(V1,Qfe),e(Qfe,B$o),e(V1,I$o),e(V1,pG),e(pG,q$o),e(V1,N$o),e(q,j$o),e(q,X1),e(X1,Hfe),e(Hfe,D$o),e(X1,G$o),e(X1,uG),e(uG,O$o),e(X1,V$o),e(q,X$o),e(q,z1),e(z1,Ufe),e(Ufe,z$o),e(z1,W$o),e(z1,_G),e(_G,Q$o),e(z1,H$o),e(q,U$o),e(q,W1),e(W1,Jfe),e(Jfe,J$o),e(W1,Y$o),e(W1,bG),e(bG,K$o),e(W1,Z$o),e(q,eko),e(q,Q1),e(Q1,Yfe),e(Yfe,oko),e(Q1,rko),e(Q1,vG),e(vG,tko),e(Q1,ako),e(q,nko),e(q,H1),e(H1,Kfe),e(Kfe,sko),e(H1,lko),e(H1,FG),e(FG,iko),e(H1,dko),e(q,cko),e(q,U1),e(U1,Zfe),e(Zfe,fko),e(U1,mko),e(U1,TG),e(TG,gko),e(U1,hko),e(q,pko),e(q,J1),e(J1,eme),e(eme,uko),e(J1,_ko),e(J1,MG),e(MG,bko),e(J1,vko),e(q,Fko),e(q,Y1),e(Y1,ome),e(ome,Tko),e(Y1,Mko),e(Y1,EG),e(EG,Eko),e(Y1,Cko),e(q,wko),e(q,K1),e(K1,rme),e(rme,Ako),e(K1,yko),e(K1,CG),e(CG,Lko),e(K1,xko),e(q,$ko),e(q,Z1),e(Z1,tme),e(tme,kko),e(Z1,Sko),e(Z1,wG),e(wG,Rko),e(Z1,Pko),e(q,Bko),e(q,eb),e(eb,ame),e(ame,Iko),e(eb,qko),e(eb,AG),e(AG,Nko),e(eb,jko),e(q,Dko),e(q,ob),e(ob,nme),e(nme,Gko),e(ob,Oko),e(ob,yG),e(yG,Vko),e(ob,Xko),e(q,zko),e(q,rb),e(rb,sme),e(sme,Wko),e(rb,Qko),e(rb,LG),e(LG,Hko),e(rb,Uko),e(q,Jko),e(q,tb),e(tb,lme),e(lme,Yko),e(tb,Kko),e(tb,xG),e(xG,Zko),e(tb,eSo),e(q,oSo),e(q,ab),e(ab,ime),e(ime,rSo),e(ab,tSo),e(ab,$G),e($G,aSo),e(ab,nSo),e(q,sSo),e(q,nb),e(nb,dme),e(dme,lSo),e(nb,iSo),e(nb,kG),e(kG,dSo),e(nb,cSo),e(q,fSo),e(q,sb),e(sb,cme),e(cme,mSo),e(sb,gSo),e(sb,SG),e(SG,hSo),e(sb,pSo),e(q,uSo),e(q,lb),e(lb,fme),e(fme,_So),e(lb,bSo),e(lb,RG),e(RG,vSo),e(lb,FSo),e(q,TSo),e(q,ib),e(ib,mme),e(mme,MSo),e(ib,ESo),e(ib,PG),e(PG,CSo),e(ib,wSo),e(q,ASo),e(q,db),e(db,gme),e(gme,ySo),e(db,LSo),e(db,BG),e(BG,xSo),e(db,$So),e(q,kSo),e(q,cb),e(cb,hme),e(hme,SSo),e(cb,RSo),e(cb,IG),e(IG,PSo),e(cb,BSo),e(q,ISo),e(q,fb),e(fb,pme),e(pme,qSo),e(fb,NSo),e(fb,qG),e(qG,jSo),e(fb,DSo),e(q,GSo),e(q,mb),e(mb,ume),e(ume,OSo),e(mb,VSo),e(mb,NG),e(NG,XSo),e(mb,zSo),e(q,WSo),e(q,gb),e(gb,_me),e(_me,QSo),e(gb,HSo),e(gb,jG),e(jG,USo),e(gb,JSo),e(q,YSo),e(q,hb),e(hb,bme),e(bme,KSo),e(hb,ZSo),e(hb,DG),e(DG,eRo),e(hb,oRo),e(q,rRo),e(q,pb),e(pb,vme),e(vme,tRo),e(pb,aRo),e(pb,GG),e(GG,nRo),e(pb,sRo),e(q,lRo),e(q,ub),e(ub,Fme),e(Fme,iRo),e(ub,dRo),e(ub,OG),e(OG,cRo),e(ub,fRo),e(q,mRo),e(q,_b),e(_b,Tme),e(Tme,gRo),e(_b,hRo),e(_b,VG),e(VG,pRo),e(_b,uRo),e(q,_Ro),e(q,bb),e(bb,Mme),e(Mme,bRo),e(bb,vRo),e(bb,XG),e(XG,FRo),e(bb,TRo),e(q,MRo),e(q,vb),e(vb,Eme),e(Eme,ERo),e(vb,CRo),e(vb,zG),e(zG,wRo),e(vb,ARo),e(q,yRo),e(q,Fb),e(Fb,Cme),e(Cme,LRo),e(Fb,xRo),e(Fb,WG),e(WG,$Ro),e(Fb,kRo),e(q,SRo),e(q,Tb),e(Tb,wme),e(wme,RRo),e(Tb,PRo),e(Tb,QG),e(QG,BRo),e(Tb,IRo),e(q,qRo),e(q,Mb),e(Mb,Ame),e(Ame,NRo),e(Mb,jRo),e(Mb,HG),e(HG,DRo),e(Mb,GRo),e(q,ORo),e(q,Eb),e(Eb,yme),e(yme,VRo),e(Eb,XRo),e(Eb,UG),e(UG,zRo),e(Eb,WRo),e(q,QRo),e(q,Cb),e(Cb,Lme),e(Lme,HRo),e(Cb,URo),e(Cb,JG),e(JG,JRo),e(Cb,YRo),e(q,KRo),e(q,wb),e(wb,xme),e(xme,ZRo),e(wb,ePo),e(wb,YG),e(YG,oPo),e(wb,rPo),e(q,tPo),e(q,Ab),e(Ab,$me),e($me,aPo),e(Ab,nPo),e(Ab,KG),e(KG,sPo),e(Ab,lPo),e(q,iPo),e(q,yb),e(yb,kme),e(kme,dPo),e(yb,cPo),e(yb,ZG),e(ZG,fPo),e(yb,mPo),e(q,gPo),e(q,Lb),e(Lb,Sme),e(Sme,hPo),e(Lb,pPo),e(Lb,eO),e(eO,uPo),e(Lb,_Po),e(q,bPo),e(q,xb),e(xb,Rme),e(Rme,vPo),e(xb,FPo),e(xb,oO),e(oO,TPo),e(xb,MPo),e(q,EPo),e(q,$b),e($b,Pme),e(Pme,CPo),e($b,wPo),e($b,rO),e(rO,APo),e($b,yPo),e(q,LPo),e(q,kb),e(kb,Bme),e(Bme,xPo),e(kb,$Po),e(kb,tO),e(tO,kPo),e(kb,SPo),e(q,RPo),e(q,Sb),e(Sb,Ime),e(Ime,PPo),e(Sb,BPo),e(Sb,aO),e(aO,IPo),e(Sb,qPo),e(q,NPo),e(q,Rb),e(Rb,qme),e(qme,jPo),e(Rb,DPo),e(Rb,nO),e(nO,GPo),e(Rb,OPo),e(q,VPo),e(q,Pb),e(Pb,Nme),e(Nme,XPo),e(Pb,zPo),e(Pb,sO),e(sO,WPo),e(Pb,QPo),e(q,HPo),e(q,Bb),e(Bb,jme),e(jme,UPo),e(Bb,JPo),e(Bb,lO),e(lO,YPo),e(Bb,KPo),e(oo,ZPo),e(oo,Ib),e(Ib,eBo),e(Ib,Dme),e(Dme,oBo),e(Ib,rBo),e(Ib,Gme),e(Gme,tBo),e(oo,aBo),M(qb,oo,null),b(f,ANe,_),b(f,Wi,_),e(Wi,Nb),e(Nb,Ome),M(xy,Ome,null),e(Wi,nBo),e(Wi,Vme),e(Vme,sBo),b(f,yNe,_),b(f,Po,_),M($y,Po,null),e(Po,lBo),e(Po,Qi),e(Qi,iBo),e(Qi,iO),e(iO,dBo),e(Qi,cBo),e(Qi,dO),e(dO,fBo),e(Qi,mBo),e(Po,gBo),e(Po,ky),e(ky,hBo),e(ky,Xme),e(Xme,pBo),e(ky,uBo),e(Po,_Bo),e(Po,dt),M(Sy,dt,null),e(dt,bBo),e(dt,zme),e(zme,vBo),e(dt,FBo),e(dt,Hi),e(Hi,TBo),e(Hi,Wme),e(Wme,MBo),e(Hi,EBo),e(Hi,cO),e(cO,CBo),e(Hi,wBo),e(dt,ABo),M(jb,dt,null),e(Po,yBo),e(Po,ro),M(Ry,ro,null),e(ro,LBo),e(ro,Qme),e(Qme,xBo),e(ro,$Bo),e(ro,Pa),e(Pa,kBo),e(Pa,Hme),e(Hme,SBo),e(Pa,RBo),e(Pa,Ume),e(Ume,PBo),e(Pa,BBo),e(Pa,Jme),e(Jme,IBo),e(Pa,qBo),e(ro,NBo),e(ro,K),e(K,Db),e(Db,Yme),e(Yme,jBo),e(Db,DBo),e(Db,fO),e(fO,GBo),e(Db,OBo),e(K,VBo),e(K,Gb),e(Gb,Kme),e(Kme,XBo),e(Gb,zBo),e(Gb,mO),e(mO,WBo),e(Gb,QBo),e(K,HBo),e(K,Ob),e(Ob,Zme),e(Zme,UBo),e(Ob,JBo),e(Ob,gO),e(gO,YBo),e(Ob,KBo),e(K,ZBo),e(K,Vb),e(Vb,ege),e(ege,eIo),e(Vb,oIo),e(Vb,hO),e(hO,rIo),e(Vb,tIo),e(K,aIo),e(K,Xb),e(Xb,oge),e(oge,nIo),e(Xb,sIo),e(Xb,pO),e(pO,lIo),e(Xb,iIo),e(K,dIo),e(K,zb),e(zb,rge),e(rge,cIo),e(zb,fIo),e(zb,uO),e(uO,mIo),e(zb,gIo),e(K,hIo),e(K,Wb),e(Wb,tge),e(tge,pIo),e(Wb,uIo),e(Wb,_O),e(_O,_Io),e(Wb,bIo),e(K,vIo),e(K,Qb),e(Qb,age),e(age,FIo),e(Qb,TIo),e(Qb,bO),e(bO,MIo),e(Qb,EIo),e(K,CIo),e(K,Hb),e(Hb,nge),e(nge,wIo),e(Hb,AIo),e(Hb,vO),e(vO,yIo),e(Hb,LIo),e(K,xIo),e(K,Ub),e(Ub,sge),e(sge,$Io),e(Ub,kIo),e(Ub,FO),e(FO,SIo),e(Ub,RIo),e(K,PIo),e(K,Jb),e(Jb,lge),e(lge,BIo),e(Jb,IIo),e(Jb,TO),e(TO,qIo),e(Jb,NIo),e(K,jIo),e(K,Yb),e(Yb,ige),e(ige,DIo),e(Yb,GIo),e(Yb,MO),e(MO,OIo),e(Yb,VIo),e(K,XIo),e(K,Kb),e(Kb,dge),e(dge,zIo),e(Kb,WIo),e(Kb,EO),e(EO,QIo),e(Kb,HIo),e(K,UIo),e(K,Zb),e(Zb,cge),e(cge,JIo),e(Zb,YIo),e(Zb,CO),e(CO,KIo),e(Zb,ZIo),e(K,eqo),e(K,e4),e(e4,fge),e(fge,oqo),e(e4,rqo),e(e4,wO),e(wO,tqo),e(e4,aqo),e(K,nqo),e(K,o4),e(o4,mge),e(mge,sqo),e(o4,lqo),e(o4,AO),e(AO,iqo),e(o4,dqo),e(K,cqo),e(K,r4),e(r4,gge),e(gge,fqo),e(r4,mqo),e(r4,yO),e(yO,gqo),e(r4,hqo),e(K,pqo),e(K,t4),e(t4,hge),e(hge,uqo),e(t4,_qo),e(t4,LO),e(LO,bqo),e(t4,vqo),e(K,Fqo),e(K,a4),e(a4,pge),e(pge,Tqo),e(a4,Mqo),e(a4,xO),e(xO,Eqo),e(a4,Cqo),e(K,wqo),e(K,n4),e(n4,uge),e(uge,Aqo),e(n4,yqo),e(n4,$O),e($O,Lqo),e(n4,xqo),e(K,$qo),e(K,s4),e(s4,_ge),e(_ge,kqo),e(s4,Sqo),e(s4,kO),e(kO,Rqo),e(s4,Pqo),e(K,Bqo),e(K,l4),e(l4,bge),e(bge,Iqo),e(l4,qqo),e(l4,SO),e(SO,Nqo),e(l4,jqo),e(K,Dqo),e(K,i4),e(i4,vge),e(vge,Gqo),e(i4,Oqo),e(i4,RO),e(RO,Vqo),e(i4,Xqo),e(K,zqo),e(K,d4),e(d4,Fge),e(Fge,Wqo),e(d4,Qqo),e(d4,PO),e(PO,Hqo),e(d4,Uqo),e(K,Jqo),e(K,c4),e(c4,Tge),e(Tge,Yqo),e(c4,Kqo),e(c4,BO),e(BO,Zqo),e(c4,eNo),e(K,oNo),e(K,f4),e(f4,Mge),e(Mge,rNo),e(f4,tNo),e(f4,IO),e(IO,aNo),e(f4,nNo),e(K,sNo),e(K,m4),e(m4,Ege),e(Ege,lNo),e(m4,iNo),e(m4,qO),e(qO,dNo),e(m4,cNo),e(K,fNo),e(K,g4),e(g4,Cge),e(Cge,mNo),e(g4,gNo),e(g4,NO),e(NO,hNo),e(g4,pNo),e(K,uNo),e(K,h4),e(h4,wge),e(wge,_No),e(h4,bNo),e(h4,jO),e(jO,vNo),e(h4,FNo),e(ro,TNo),e(ro,p4),e(p4,MNo),e(p4,Age),e(Age,ENo),e(p4,CNo),e(p4,yge),e(yge,wNo),e(ro,ANo),M(u4,ro,null),b(f,LNe,_),b(f,Ui,_),e(Ui,_4),e(_4,Lge),M(Py,Lge,null),e(Ui,yNo),e(Ui,xge),e(xge,LNo),b(f,xNe,_),b(f,Bo,_),M(By,Bo,null),e(Bo,xNo),e(Bo,Ji),e(Ji,$No),e(Ji,DO),e(DO,kNo),e(Ji,SNo),e(Ji,GO),e(GO,RNo),e(Ji,PNo),e(Bo,BNo),e(Bo,Iy),e(Iy,INo),e(Iy,$ge),e($ge,qNo),e(Iy,NNo),e(Bo,jNo),e(Bo,ct),M(qy,ct,null),e(ct,DNo),e(ct,kge),e(kge,GNo),e(ct,ONo),e(ct,Yi),e(Yi,VNo),e(Yi,Sge),e(Sge,XNo),e(Yi,zNo),e(Yi,OO),e(OO,WNo),e(Yi,QNo),e(ct,HNo),M(b4,ct,null),e(Bo,UNo),e(Bo,to),M(Ny,to,null),e(to,JNo),e(to,Rge),e(Rge,YNo),e(to,KNo),e(to,Ba),e(Ba,ZNo),e(Ba,Pge),e(Pge,ejo),e(Ba,ojo),e(Ba,Bge),e(Bge,rjo),e(Ba,tjo),e(Ba,Ige),e(Ige,ajo),e(Ba,njo),e(to,sjo),e(to,Yr),e(Yr,v4),e(v4,qge),e(qge,ljo),e(v4,ijo),e(v4,VO),e(VO,djo),e(v4,cjo),e(Yr,fjo),e(Yr,F4),e(F4,Nge),e(Nge,mjo),e(F4,gjo),e(F4,XO),e(XO,hjo),e(F4,pjo),e(Yr,ujo),e(Yr,T4),e(T4,jge),e(jge,_jo),e(T4,bjo),e(T4,zO),e(zO,vjo),e(T4,Fjo),e(Yr,Tjo),e(Yr,M4),e(M4,Dge),e(Dge,Mjo),e(M4,Ejo),e(M4,WO),e(WO,Cjo),e(M4,wjo),e(Yr,Ajo),e(Yr,E4),e(E4,Gge),e(Gge,yjo),e(E4,Ljo),e(E4,QO),e(QO,xjo),e(E4,$jo),e(to,kjo),e(to,C4),e(C4,Sjo),e(C4,Oge),e(Oge,Rjo),e(C4,Pjo),e(C4,Vge),e(Vge,Bjo),e(to,Ijo),M(w4,to,null),b(f,$Ne,_),b(f,Ki,_),e(Ki,A4),e(A4,Xge),M(jy,Xge,null),e(Ki,qjo),e(Ki,zge),e(zge,Njo),b(f,kNe,_),b(f,Io,_),M(Dy,Io,null),e(Io,jjo),e(Io,Zi),e(Zi,Djo),e(Zi,HO),e(HO,Gjo),e(Zi,Ojo),e(Zi,UO),e(UO,Vjo),e(Zi,Xjo),e(Io,zjo),e(Io,Gy),e(Gy,Wjo),e(Gy,Wge),e(Wge,Qjo),e(Gy,Hjo),e(Io,Ujo),e(Io,ft),M(Oy,ft,null),e(ft,Jjo),e(ft,Qge),e(Qge,Yjo),e(ft,Kjo),e(ft,ed),e(ed,Zjo),e(ed,Hge),e(Hge,eDo),e(ed,oDo),e(ed,JO),e(JO,rDo),e(ed,tDo),e(ft,aDo),M(y4,ft,null),e(Io,nDo),e(Io,ao),M(Vy,ao,null),e(ao,sDo),e(ao,Uge),e(Uge,lDo),e(ao,iDo),e(ao,Ia),e(Ia,dDo),e(Ia,Jge),e(Jge,cDo),e(Ia,fDo),e(Ia,Yge),e(Yge,mDo),e(Ia,gDo),e(Ia,Kge),e(Kge,hDo),e(Ia,pDo),e(ao,uDo),e(ao,H),e(H,L4),e(L4,Zge),e(Zge,_Do),e(L4,bDo),e(L4,YO),e(YO,vDo),e(L4,FDo),e(H,TDo),e(H,x4),e(x4,ehe),e(ehe,MDo),e(x4,EDo),e(x4,KO),e(KO,CDo),e(x4,wDo),e(H,ADo),e(H,$4),e($4,ohe),e(ohe,yDo),e($4,LDo),e($4,ZO),e(ZO,xDo),e($4,$Do),e(H,kDo),e(H,k4),e(k4,rhe),e(rhe,SDo),e(k4,RDo),e(k4,eV),e(eV,PDo),e(k4,BDo),e(H,IDo),e(H,S4),e(S4,the),e(the,qDo),e(S4,NDo),e(S4,oV),e(oV,jDo),e(S4,DDo),e(H,GDo),e(H,R4),e(R4,ahe),e(ahe,ODo),e(R4,VDo),e(R4,rV),e(rV,XDo),e(R4,zDo),e(H,WDo),e(H,P4),e(P4,nhe),e(nhe,QDo),e(P4,HDo),e(P4,tV),e(tV,UDo),e(P4,JDo),e(H,YDo),e(H,B4),e(B4,she),e(she,KDo),e(B4,ZDo),e(B4,aV),e(aV,eGo),e(B4,oGo),e(H,rGo),e(H,I4),e(I4,lhe),e(lhe,tGo),e(I4,aGo),e(I4,nV),e(nV,nGo),e(I4,sGo),e(H,lGo),e(H,q4),e(q4,ihe),e(ihe,iGo),e(q4,dGo),e(q4,sV),e(sV,cGo),e(q4,fGo),e(H,mGo),e(H,N4),e(N4,dhe),e(dhe,gGo),e(N4,hGo),e(N4,lV),e(lV,pGo),e(N4,uGo),e(H,_Go),e(H,j4),e(j4,che),e(che,bGo),e(j4,vGo),e(j4,iV),e(iV,FGo),e(j4,TGo),e(H,MGo),e(H,D4),e(D4,fhe),e(fhe,EGo),e(D4,CGo),e(D4,dV),e(dV,wGo),e(D4,AGo),e(H,yGo),e(H,G4),e(G4,mhe),e(mhe,LGo),e(G4,xGo),e(G4,cV),e(cV,$Go),e(G4,kGo),e(H,SGo),e(H,O4),e(O4,ghe),e(ghe,RGo),e(O4,PGo),e(O4,fV),e(fV,BGo),e(O4,IGo),e(H,qGo),e(H,V4),e(V4,hhe),e(hhe,NGo),e(V4,jGo),e(V4,mV),e(mV,DGo),e(V4,GGo),e(H,OGo),e(H,X4),e(X4,phe),e(phe,VGo),e(X4,XGo),e(X4,gV),e(gV,zGo),e(X4,WGo),e(H,QGo),e(H,z4),e(z4,uhe),e(uhe,HGo),e(z4,UGo),e(z4,hV),e(hV,JGo),e(z4,YGo),e(H,KGo),e(H,W4),e(W4,_he),e(_he,ZGo),e(W4,eOo),e(W4,pV),e(pV,oOo),e(W4,rOo),e(H,tOo),e(H,Q4),e(Q4,bhe),e(bhe,aOo),e(Q4,nOo),e(Q4,uV),e(uV,sOo),e(Q4,lOo),e(H,iOo),e(H,H4),e(H4,vhe),e(vhe,dOo),e(H4,cOo),e(H4,_V),e(_V,fOo),e(H4,mOo),e(H,gOo),e(H,U4),e(U4,Fhe),e(Fhe,hOo),e(U4,pOo),e(U4,bV),e(bV,uOo),e(U4,_Oo),e(H,bOo),e(H,J4),e(J4,The),e(The,vOo),e(J4,FOo),e(J4,vV),e(vV,TOo),e(J4,MOo),e(H,EOo),e(H,Y4),e(Y4,Mhe),e(Mhe,COo),e(Y4,wOo),e(Y4,FV),e(FV,AOo),e(Y4,yOo),e(H,LOo),e(H,K4),e(K4,Ehe),e(Ehe,xOo),e(K4,$Oo),e(K4,TV),e(TV,kOo),e(K4,SOo),e(H,ROo),e(H,Z4),e(Z4,Che),e(Che,POo),e(Z4,BOo),e(Z4,MV),e(MV,IOo),e(Z4,qOo),e(H,NOo),e(H,ev),e(ev,whe),e(whe,jOo),e(ev,DOo),e(ev,EV),e(EV,GOo),e(ev,OOo),e(H,VOo),e(H,ov),e(ov,Ahe),e(Ahe,XOo),e(ov,zOo),e(ov,CV),e(CV,WOo),e(ov,QOo),e(H,HOo),e(H,rv),e(rv,yhe),e(yhe,UOo),e(rv,JOo),e(rv,wV),e(wV,YOo),e(rv,KOo),e(H,ZOo),e(H,tv),e(tv,Lhe),e(Lhe,eVo),e(tv,oVo),e(tv,AV),e(AV,rVo),e(tv,tVo),e(H,aVo),e(H,av),e(av,xhe),e(xhe,nVo),e(av,sVo),e(av,yV),e(yV,lVo),e(av,iVo),e(H,dVo),e(H,nv),e(nv,$he),e($he,cVo),e(nv,fVo),e(nv,LV),e(LV,mVo),e(nv,gVo),e(H,hVo),e(H,sv),e(sv,khe),e(khe,pVo),e(sv,uVo),e(sv,xV),e(xV,_Vo),e(sv,bVo),e(H,vVo),e(H,lv),e(lv,She),e(She,FVo),e(lv,TVo),e(lv,$V),e($V,MVo),e(lv,EVo),e(ao,CVo),e(ao,iv),e(iv,wVo),e(iv,Rhe),e(Rhe,AVo),e(iv,yVo),e(iv,Phe),e(Phe,LVo),e(ao,xVo),M(dv,ao,null),b(f,SNe,_),b(f,od,_),e(od,cv),e(cv,Bhe),M(Xy,Bhe,null),e(od,$Vo),e(od,Ihe),e(Ihe,kVo),b(f,RNe,_),b(f,qo,_),M(zy,qo,null),e(qo,SVo),e(qo,rd),e(rd,RVo),e(rd,kV),e(kV,PVo),e(rd,BVo),e(rd,SV),e(SV,IVo),e(rd,qVo),e(qo,NVo),e(qo,Wy),e(Wy,jVo),e(Wy,qhe),e(qhe,DVo),e(Wy,GVo),e(qo,OVo),e(qo,mt),M(Qy,mt,null),e(mt,VVo),e(mt,Nhe),e(Nhe,XVo),e(mt,zVo),e(mt,td),e(td,WVo),e(td,jhe),e(jhe,QVo),e(td,HVo),e(td,RV),e(RV,UVo),e(td,JVo),e(mt,YVo),M(fv,mt,null),e(qo,KVo),e(qo,no),M(Hy,no,null),e(no,ZVo),e(no,Dhe),e(Dhe,eXo),e(no,oXo),e(no,qa),e(qa,rXo),e(qa,Ghe),e(Ghe,tXo),e(qa,aXo),e(qa,Ohe),e(Ohe,nXo),e(qa,sXo),e(qa,Vhe),e(Vhe,lXo),e(qa,iXo),e(no,dXo),e(no,V),e(V,mv),e(mv,Xhe),e(Xhe,cXo),e(mv,fXo),e(mv,PV),e(PV,mXo),e(mv,gXo),e(V,hXo),e(V,gv),e(gv,zhe),e(zhe,pXo),e(gv,uXo),e(gv,BV),e(BV,_Xo),e(gv,bXo),e(V,vXo),e(V,hv),e(hv,Whe),e(Whe,FXo),e(hv,TXo),e(hv,IV),e(IV,MXo),e(hv,EXo),e(V,CXo),e(V,pv),e(pv,Qhe),e(Qhe,wXo),e(pv,AXo),e(pv,qV),e(qV,yXo),e(pv,LXo),e(V,xXo),e(V,uv),e(uv,Hhe),e(Hhe,$Xo),e(uv,kXo),e(uv,NV),e(NV,SXo),e(uv,RXo),e(V,PXo),e(V,_v),e(_v,Uhe),e(Uhe,BXo),e(_v,IXo),e(_v,jV),e(jV,qXo),e(_v,NXo),e(V,jXo),e(V,bv),e(bv,Jhe),e(Jhe,DXo),e(bv,GXo),e(bv,DV),e(DV,OXo),e(bv,VXo),e(V,XXo),e(V,vv),e(vv,Yhe),e(Yhe,zXo),e(vv,WXo),e(vv,GV),e(GV,QXo),e(vv,HXo),e(V,UXo),e(V,Fv),e(Fv,Khe),e(Khe,JXo),e(Fv,YXo),e(Fv,OV),e(OV,KXo),e(Fv,ZXo),e(V,ezo),e(V,Tv),e(Tv,Zhe),e(Zhe,ozo),e(Tv,rzo),e(Tv,VV),e(VV,tzo),e(Tv,azo),e(V,nzo),e(V,Mv),e(Mv,epe),e(epe,szo),e(Mv,lzo),e(Mv,XV),e(XV,izo),e(Mv,dzo),e(V,czo),e(V,Ev),e(Ev,ope),e(ope,fzo),e(Ev,mzo),e(Ev,zV),e(zV,gzo),e(Ev,hzo),e(V,pzo),e(V,Cv),e(Cv,rpe),e(rpe,uzo),e(Cv,_zo),e(Cv,WV),e(WV,bzo),e(Cv,vzo),e(V,Fzo),e(V,wv),e(wv,tpe),e(tpe,Tzo),e(wv,Mzo),e(wv,QV),e(QV,Ezo),e(wv,Czo),e(V,wzo),e(V,Av),e(Av,ape),e(ape,Azo),e(Av,yzo),e(Av,HV),e(HV,Lzo),e(Av,xzo),e(V,$zo),e(V,yv),e(yv,npe),e(npe,kzo),e(yv,Szo),e(yv,UV),e(UV,Rzo),e(yv,Pzo),e(V,Bzo),e(V,Lv),e(Lv,spe),e(spe,Izo),e(Lv,qzo),e(Lv,JV),e(JV,Nzo),e(Lv,jzo),e(V,Dzo),e(V,xv),e(xv,lpe),e(lpe,Gzo),e(xv,Ozo),e(xv,YV),e(YV,Vzo),e(xv,Xzo),e(V,zzo),e(V,$v),e($v,ipe),e(ipe,Wzo),e($v,Qzo),e($v,KV),e(KV,Hzo),e($v,Uzo),e(V,Jzo),e(V,kv),e(kv,dpe),e(dpe,Yzo),e(kv,Kzo),e(kv,ZV),e(ZV,Zzo),e(kv,eWo),e(V,oWo),e(V,Sv),e(Sv,cpe),e(cpe,rWo),e(Sv,tWo),e(Sv,eX),e(eX,aWo),e(Sv,nWo),e(V,sWo),e(V,Rv),e(Rv,fpe),e(fpe,lWo),e(Rv,iWo),e(Rv,oX),e(oX,dWo),e(Rv,cWo),e(V,fWo),e(V,Pv),e(Pv,mpe),e(mpe,mWo),e(Pv,gWo),e(Pv,rX),e(rX,hWo),e(Pv,pWo),e(V,uWo),e(V,Bv),e(Bv,gpe),e(gpe,_Wo),e(Bv,bWo),e(Bv,tX),e(tX,vWo),e(Bv,FWo),e(V,TWo),e(V,Iv),e(Iv,hpe),e(hpe,MWo),e(Iv,EWo),e(Iv,aX),e(aX,CWo),e(Iv,wWo),e(V,AWo),e(V,qv),e(qv,ppe),e(ppe,yWo),e(qv,LWo),e(qv,nX),e(nX,xWo),e(qv,$Wo),e(V,kWo),e(V,Nv),e(Nv,upe),e(upe,SWo),e(Nv,RWo),e(Nv,sX),e(sX,PWo),e(Nv,BWo),e(V,IWo),e(V,jv),e(jv,_pe),e(_pe,qWo),e(jv,NWo),e(jv,lX),e(lX,jWo),e(jv,DWo),e(V,GWo),e(V,Dv),e(Dv,bpe),e(bpe,OWo),e(Dv,VWo),e(Dv,iX),e(iX,XWo),e(Dv,zWo),e(V,WWo),e(V,Gv),e(Gv,vpe),e(vpe,QWo),e(Gv,HWo),e(Gv,dX),e(dX,UWo),e(Gv,JWo),e(V,YWo),e(V,Ov),e(Ov,Fpe),e(Fpe,KWo),e(Ov,ZWo),e(Ov,cX),e(cX,eQo),e(Ov,oQo),e(V,rQo),e(V,Vv),e(Vv,Tpe),e(Tpe,tQo),e(Vv,aQo),e(Vv,fX),e(fX,nQo),e(Vv,sQo),e(V,lQo),e(V,Xv),e(Xv,Mpe),e(Mpe,iQo),e(Xv,dQo),e(Xv,mX),e(mX,cQo),e(Xv,fQo),e(V,mQo),e(V,zv),e(zv,Epe),e(Epe,gQo),e(zv,hQo),e(zv,gX),e(gX,pQo),e(zv,uQo),e(V,_Qo),e(V,Wv),e(Wv,Cpe),e(Cpe,bQo),e(Wv,vQo),e(Wv,hX),e(hX,FQo),e(Wv,TQo),e(V,MQo),e(V,Qv),e(Qv,wpe),e(wpe,EQo),e(Qv,CQo),e(Qv,pX),e(pX,wQo),e(Qv,AQo),e(V,yQo),e(V,Hv),e(Hv,Ape),e(Ape,LQo),e(Hv,xQo),e(Hv,uX),e(uX,$Qo),e(Hv,kQo),e(V,SQo),e(V,Uv),e(Uv,ype),e(ype,RQo),e(Uv,PQo),e(Uv,_X),e(_X,BQo),e(Uv,IQo),e(V,qQo),e(V,Jv),e(Jv,Lpe),e(Lpe,NQo),e(Jv,jQo),e(Jv,bX),e(bX,DQo),e(Jv,GQo),e(V,OQo),e(V,Yv),e(Yv,xpe),e(xpe,VQo),e(Yv,XQo),e(Yv,vX),e(vX,zQo),e(Yv,WQo),e(no,QQo),e(no,Kv),e(Kv,HQo),e(Kv,$pe),e($pe,UQo),e(Kv,JQo),e(Kv,kpe),e(kpe,YQo),e(no,KQo),M(Zv,no,null),b(f,PNe,_),b(f,ad,_),e(ad,e5),e(e5,Spe),M(Uy,Spe,null),e(ad,ZQo),e(ad,Rpe),e(Rpe,eHo),b(f,BNe,_),b(f,No,_),M(Jy,No,null),e(No,oHo),e(No,nd),e(nd,rHo),e(nd,FX),e(FX,tHo),e(nd,aHo),e(nd,TX),e(TX,nHo),e(nd,sHo),e(No,lHo),e(No,Yy),e(Yy,iHo),e(Yy,Ppe),e(Ppe,dHo),e(Yy,cHo),e(No,fHo),e(No,gt),M(Ky,gt,null),e(gt,mHo),e(gt,Bpe),e(Bpe,gHo),e(gt,hHo),e(gt,sd),e(sd,pHo),e(sd,Ipe),e(Ipe,uHo),e(sd,_Ho),e(sd,MX),e(MX,bHo),e(sd,vHo),e(gt,FHo),M(o5,gt,null),e(No,THo),e(No,so),M(Zy,so,null),e(so,MHo),e(so,qpe),e(qpe,EHo),e(so,CHo),e(so,Na),e(Na,wHo),e(Na,Npe),e(Npe,AHo),e(Na,yHo),e(Na,jpe),e(jpe,LHo),e(Na,xHo),e(Na,Dpe),e(Dpe,$Ho),e(Na,kHo),e(so,SHo),e(so,Gpe),e(Gpe,r5),e(r5,Ope),e(Ope,RHo),e(r5,PHo),e(r5,EX),e(EX,BHo),e(r5,IHo),e(so,qHo),e(so,t5),e(t5,NHo),e(t5,Vpe),e(Vpe,jHo),e(t5,DHo),e(t5,Xpe),e(Xpe,GHo),e(so,OHo),M(a5,so,null),b(f,INe,_),b(f,ld,_),e(ld,n5),e(n5,zpe),M(eL,zpe,null),e(ld,VHo),e(ld,Wpe),e(Wpe,XHo),b(f,qNe,_),b(f,jo,_),M(oL,jo,null),e(jo,zHo),e(jo,id),e(id,WHo),e(id,CX),e(CX,QHo),e(id,HHo),e(id,wX),e(wX,UHo),e(id,JHo),e(jo,YHo),e(jo,rL),e(rL,KHo),e(rL,Qpe),e(Qpe,ZHo),e(rL,eUo),e(jo,oUo),e(jo,ht),M(tL,ht,null),e(ht,rUo),e(ht,Hpe),e(Hpe,tUo),e(ht,aUo),e(ht,dd),e(dd,nUo),e(dd,Upe),e(Upe,sUo),e(dd,lUo),e(dd,AX),e(AX,iUo),e(dd,dUo),e(ht,cUo),M(s5,ht,null),e(jo,fUo),e(jo,lo),M(aL,lo,null),e(lo,mUo),e(lo,Jpe),e(Jpe,gUo),e(lo,hUo),e(lo,ja),e(ja,pUo),e(ja,Ype),e(Ype,uUo),e(ja,_Uo),e(ja,Kpe),e(Kpe,bUo),e(ja,vUo),e(ja,Zpe),e(Zpe,FUo),e(ja,TUo),e(lo,MUo),e(lo,Fe),e(Fe,l5),e(l5,eue),e(eue,EUo),e(l5,CUo),e(l5,yX),e(yX,wUo),e(l5,AUo),e(Fe,yUo),e(Fe,i5),e(i5,oue),e(oue,LUo),e(i5,xUo),e(i5,LX),e(LX,$Uo),e(i5,kUo),e(Fe,SUo),e(Fe,d5),e(d5,rue),e(rue,RUo),e(d5,PUo),e(d5,xX),e(xX,BUo),e(d5,IUo),e(Fe,qUo),e(Fe,c5),e(c5,tue),e(tue,NUo),e(c5,jUo),e(c5,$X),e($X,DUo),e(c5,GUo),e(Fe,OUo),e(Fe,Ns),e(Ns,aue),e(aue,VUo),e(Ns,XUo),e(Ns,kX),e(kX,zUo),e(Ns,WUo),e(Ns,SX),e(SX,QUo),e(Ns,HUo),e(Fe,UUo),e(Fe,f5),e(f5,nue),e(nue,JUo),e(f5,YUo),e(f5,RX),e(RX,KUo),e(f5,ZUo),e(Fe,eJo),e(Fe,pt),e(pt,sue),e(sue,oJo),e(pt,rJo),e(pt,PX),e(PX,tJo),e(pt,aJo),e(pt,BX),e(BX,nJo),e(pt,sJo),e(pt,IX),e(IX,lJo),e(pt,iJo),e(Fe,dJo),e(Fe,m5),e(m5,lue),e(lue,cJo),e(m5,fJo),e(m5,qX),e(qX,mJo),e(m5,gJo),e(Fe,hJo),e(Fe,g5),e(g5,iue),e(iue,pJo),e(g5,uJo),e(g5,NX),e(NX,_Jo),e(g5,bJo),e(Fe,vJo),e(Fe,h5),e(h5,due),e(due,FJo),e(h5,TJo),e(h5,jX),e(jX,MJo),e(h5,EJo),e(Fe,CJo),e(Fe,p5),e(p5,cue),e(cue,wJo),e(p5,AJo),e(p5,DX),e(DX,yJo),e(p5,LJo),e(Fe,xJo),e(Fe,u5),e(u5,fue),e(fue,$Jo),e(u5,kJo),e(u5,GX),e(GX,SJo),e(u5,RJo),e(Fe,PJo),e(Fe,_5),e(_5,mue),e(mue,BJo),e(_5,IJo),e(_5,OX),e(OX,qJo),e(_5,NJo),e(Fe,jJo),e(Fe,b5),e(b5,gue),e(gue,DJo),e(b5,GJo),e(b5,VX),e(VX,OJo),e(b5,VJo),e(lo,XJo),e(lo,v5),e(v5,zJo),e(v5,hue),e(hue,WJo),e(v5,QJo),e(v5,pue),e(pue,HJo),e(lo,UJo),M(F5,lo,null),b(f,NNe,_),b(f,cd,_),e(cd,T5),e(T5,uue),M(nL,uue,null),e(cd,JJo),e(cd,_ue),e(_ue,YJo),b(f,jNe,_),b(f,Do,_),M(sL,Do,null),e(Do,KJo),e(Do,fd),e(fd,ZJo),e(fd,XX),e(XX,eYo),e(fd,oYo),e(fd,zX),e(zX,rYo),e(fd,tYo),e(Do,aYo),e(Do,lL),e(lL,nYo),e(lL,bue),e(bue,sYo),e(lL,lYo),e(Do,iYo),e(Do,ut),M(iL,ut,null),e(ut,dYo),e(ut,vue),e(vue,cYo),e(ut,fYo),e(ut,md),e(md,mYo),e(md,Fue),e(Fue,gYo),e(md,hYo),e(md,WX),e(WX,pYo),e(md,uYo),e(ut,_Yo),M(M5,ut,null),e(Do,bYo),e(Do,io),M(dL,io,null),e(io,vYo),e(io,Tue),e(Tue,FYo),e(io,TYo),e(io,Da),e(Da,MYo),e(Da,Mue),e(Mue,EYo),e(Da,CYo),e(Da,Eue),e(Eue,wYo),e(Da,AYo),e(Da,Cue),e(Cue,yYo),e(Da,LYo),e(io,xYo),e(io,wue),e(wue,E5),e(E5,Aue),e(Aue,$Yo),e(E5,kYo),e(E5,QX),e(QX,SYo),e(E5,RYo),e(io,PYo),e(io,C5),e(C5,BYo),e(C5,yue),e(yue,IYo),e(C5,qYo),e(C5,Lue),e(Lue,NYo),e(io,jYo),M(w5,io,null),b(f,DNe,_),b(f,gd,_),e(gd,A5),e(A5,xue),M(cL,xue,null),e(gd,DYo),e(gd,$ue),e($ue,GYo),b(f,GNe,_),b(f,Go,_),M(fL,Go,null),e(Go,OYo),e(Go,hd),e(hd,VYo),e(hd,HX),e(HX,XYo),e(hd,zYo),e(hd,UX),e(UX,WYo),e(hd,QYo),e(Go,HYo),e(Go,mL),e(mL,UYo),e(mL,kue),e(kue,JYo),e(mL,YYo),e(Go,KYo),e(Go,_t),M(gL,_t,null),e(_t,ZYo),e(_t,Sue),e(Sue,eKo),e(_t,oKo),e(_t,pd),e(pd,rKo),e(pd,Rue),e(Rue,tKo),e(pd,aKo),e(pd,JX),e(JX,nKo),e(pd,sKo),e(_t,lKo),M(y5,_t,null),e(Go,iKo),e(Go,co),M(hL,co,null),e(co,dKo),e(co,Pue),e(Pue,cKo),e(co,fKo),e(co,Ga),e(Ga,mKo),e(Ga,Bue),e(Bue,gKo),e(Ga,hKo),e(Ga,Iue),e(Iue,pKo),e(Ga,uKo),e(Ga,que),e(que,_Ko),e(Ga,bKo),e(co,vKo),e(co,ke),e(ke,L5),e(L5,Nue),e(Nue,FKo),e(L5,TKo),e(L5,YX),e(YX,MKo),e(L5,EKo),e(ke,CKo),e(ke,x5),e(x5,jue),e(jue,wKo),e(x5,AKo),e(x5,KX),e(KX,yKo),e(x5,LKo),e(ke,xKo),e(ke,$5),e($5,Due),e(Due,$Ko),e($5,kKo),e($5,ZX),e(ZX,SKo),e($5,RKo),e(ke,PKo),e(ke,k5),e(k5,Gue),e(Gue,BKo),e(k5,IKo),e(k5,ez),e(ez,qKo),e(k5,NKo),e(ke,jKo),e(ke,S5),e(S5,Oue),e(Oue,DKo),e(S5,GKo),e(S5,oz),e(oz,OKo),e(S5,VKo),e(ke,XKo),e(ke,R5),e(R5,Vue),e(Vue,zKo),e(R5,WKo),e(R5,rz),e(rz,QKo),e(R5,HKo),e(ke,UKo),e(ke,P5),e(P5,Xue),e(Xue,JKo),e(P5,YKo),e(P5,tz),e(tz,KKo),e(P5,ZKo),e(ke,eZo),e(ke,B5),e(B5,zue),e(zue,oZo),e(B5,rZo),e(B5,az),e(az,tZo),e(B5,aZo),e(ke,nZo),e(ke,I5),e(I5,Wue),e(Wue,sZo),e(I5,lZo),e(I5,nz),e(nz,iZo),e(I5,dZo),e(co,cZo),e(co,q5),e(q5,fZo),e(q5,Que),e(Que,mZo),e(q5,gZo),e(q5,Hue),e(Hue,hZo),e(co,pZo),M(N5,co,null),b(f,ONe,_),b(f,ud,_),e(ud,j5),e(j5,Uue),M(pL,Uue,null),e(ud,uZo),e(ud,Jue),e(Jue,_Zo),b(f,VNe,_),b(f,Oo,_),M(uL,Oo,null),e(Oo,bZo),e(Oo,_d),e(_d,vZo),e(_d,sz),e(sz,FZo),e(_d,TZo),e(_d,lz),e(lz,MZo),e(_d,EZo),e(Oo,CZo),e(Oo,_L),e(_L,wZo),e(_L,Yue),e(Yue,AZo),e(_L,yZo),e(Oo,LZo),e(Oo,bt),M(bL,bt,null),e(bt,xZo),e(bt,Kue),e(Kue,$Zo),e(bt,kZo),e(bt,bd),e(bd,SZo),e(bd,Zue),e(Zue,RZo),e(bd,PZo),e(bd,iz),e(iz,BZo),e(bd,IZo),e(bt,qZo),M(D5,bt,null),e(Oo,NZo),e(Oo,fo),M(vL,fo,null),e(fo,jZo),e(fo,e_e),e(e_e,DZo),e(fo,GZo),e(fo,Oa),e(Oa,OZo),e(Oa,o_e),e(o_e,VZo),e(Oa,XZo),e(Oa,r_e),e(r_e,zZo),e(Oa,WZo),e(Oa,t_e),e(t_e,QZo),e(Oa,HZo),e(fo,UZo),e(fo,Kr),e(Kr,G5),e(G5,a_e),e(a_e,JZo),e(G5,YZo),e(G5,dz),e(dz,KZo),e(G5,ZZo),e(Kr,eer),e(Kr,O5),e(O5,n_e),e(n_e,oer),e(O5,rer),e(O5,cz),e(cz,ter),e(O5,aer),e(Kr,ner),e(Kr,V5),e(V5,s_e),e(s_e,ser),e(V5,ler),e(V5,fz),e(fz,ier),e(V5,der),e(Kr,cer),e(Kr,X5),e(X5,l_e),e(l_e,fer),e(X5,mer),e(X5,mz),e(mz,ger),e(X5,her),e(Kr,per),e(Kr,z5),e(z5,i_e),e(i_e,uer),e(z5,_er),e(z5,gz),e(gz,ber),e(z5,ver),e(fo,Fer),e(fo,W5),e(W5,Ter),e(W5,d_e),e(d_e,Mer),e(W5,Eer),e(W5,c_e),e(c_e,Cer),e(fo,wer),M(Q5,fo,null),b(f,XNe,_),b(f,vd,_),e(vd,H5),e(H5,f_e),M(FL,f_e,null),e(vd,Aer),e(vd,m_e),e(m_e,yer),b(f,zNe,_),b(f,Vo,_),M(TL,Vo,null),e(Vo,Ler),e(Vo,Fd),e(Fd,xer),e(Fd,hz),e(hz,$er),e(Fd,ker),e(Fd,pz),e(pz,Ser),e(Fd,Rer),e(Vo,Per),e(Vo,ML),e(ML,Ber),e(ML,g_e),e(g_e,Ier),e(ML,qer),e(Vo,Ner),e(Vo,vt),M(EL,vt,null),e(vt,jer),e(vt,h_e),e(h_e,Der),e(vt,Ger),e(vt,Td),e(Td,Oer),e(Td,p_e),e(p_e,Ver),e(Td,Xer),e(Td,uz),e(uz,zer),e(Td,Wer),e(vt,Qer),M(U5,vt,null),e(Vo,Her),e(Vo,mo),M(CL,mo,null),e(mo,Uer),e(mo,u_e),e(u_e,Jer),e(mo,Yer),e(mo,Va),e(Va,Ker),e(Va,__e),e(__e,Zer),e(Va,eor),e(Va,b_e),e(b_e,oor),e(Va,ror),e(Va,v_e),e(v_e,tor),e(Va,aor),e(mo,nor),e(mo,Se),e(Se,J5),e(J5,F_e),e(F_e,sor),e(J5,lor),e(J5,_z),e(_z,ior),e(J5,dor),e(Se,cor),e(Se,Y5),e(Y5,T_e),e(T_e,mor),e(Y5,gor),e(Y5,bz),e(bz,hor),e(Y5,por),e(Se,uor),e(Se,K5),e(K5,M_e),e(M_e,_or),e(K5,bor),e(K5,vz),e(vz,vor),e(K5,For),e(Se,Tor),e(Se,Z5),e(Z5,E_e),e(E_e,Mor),e(Z5,Eor),e(Z5,Fz),e(Fz,Cor),e(Z5,wor),e(Se,Aor),e(Se,eF),e(eF,C_e),e(C_e,yor),e(eF,Lor),e(eF,Tz),e(Tz,xor),e(eF,$or),e(Se,kor),e(Se,oF),e(oF,w_e),e(w_e,Sor),e(oF,Ror),e(oF,Mz),e(Mz,Por),e(oF,Bor),e(Se,Ior),e(Se,rF),e(rF,A_e),e(A_e,qor),e(rF,Nor),e(rF,Ez),e(Ez,jor),e(rF,Dor),e(Se,Gor),e(Se,tF),e(tF,y_e),e(y_e,Oor),e(tF,Vor),e(tF,Cz),e(Cz,Xor),e(tF,zor),e(Se,Wor),e(Se,aF),e(aF,L_e),e(L_e,Qor),e(aF,Hor),e(aF,wz),e(wz,Uor),e(aF,Jor),e(mo,Yor),e(mo,nF),e(nF,Kor),e(nF,x_e),e(x_e,Zor),e(nF,err),e(nF,$_e),e($_e,orr),e(mo,rrr),M(sF,mo,null),b(f,WNe,_),b(f,Md,_),e(Md,lF),e(lF,k_e),M(wL,k_e,null),e(Md,trr),e(Md,S_e),e(S_e,arr),b(f,QNe,_),b(f,Xo,_),M(AL,Xo,null),e(Xo,nrr),e(Xo,Ed),e(Ed,srr),e(Ed,Az),e(Az,lrr),e(Ed,irr),e(Ed,yz),e(yz,drr),e(Ed,crr),e(Xo,frr),e(Xo,yL),e(yL,mrr),e(yL,R_e),e(R_e,grr),e(yL,hrr),e(Xo,prr),e(Xo,Ft),M(LL,Ft,null),e(Ft,urr),e(Ft,P_e),e(P_e,_rr),e(Ft,brr),e(Ft,Cd),e(Cd,vrr),e(Cd,B_e),e(B_e,Frr),e(Cd,Trr),e(Cd,Lz),e(Lz,Mrr),e(Cd,Err),e(Ft,Crr),M(iF,Ft,null),e(Xo,wrr),e(Xo,go),M(xL,go,null),e(go,Arr),e(go,I_e),e(I_e,yrr),e(go,Lrr),e(go,Xa),e(Xa,xrr),e(Xa,q_e),e(q_e,$rr),e(Xa,krr),e(Xa,N_e),e(N_e,Srr),e(Xa,Rrr),e(Xa,j_e),e(j_e,Prr),e(Xa,Brr),e(go,Irr),e(go,$L),e($L,dF),e(dF,D_e),e(D_e,qrr),e(dF,Nrr),e(dF,xz),e(xz,jrr),e(dF,Drr),e($L,Grr),e($L,cF),e(cF,G_e),e(G_e,Orr),e(cF,Vrr),e(cF,$z),e($z,Xrr),e(cF,zrr),e(go,Wrr),e(go,fF),e(fF,Qrr),e(fF,O_e),e(O_e,Hrr),e(fF,Urr),e(fF,V_e),e(V_e,Jrr),e(go,Yrr),M(mF,go,null),b(f,HNe,_),b(f,wd,_),e(wd,gF),e(gF,X_e),M(kL,X_e,null),e(wd,Krr),e(wd,z_e),e(z_e,Zrr),b(f,UNe,_),b(f,zo,_),M(SL,zo,null),e(zo,etr),e(zo,Ad),e(Ad,otr),e(Ad,kz),e(kz,rtr),e(Ad,ttr),e(Ad,Sz),e(Sz,atr),e(Ad,ntr),e(zo,str),e(zo,RL),e(RL,ltr),e(RL,W_e),e(W_e,itr),e(RL,dtr),e(zo,ctr),e(zo,Tt),M(PL,Tt,null),e(Tt,ftr),e(Tt,Q_e),e(Q_e,mtr),e(Tt,gtr),e(Tt,yd),e(yd,htr),e(yd,H_e),e(H_e,ptr),e(yd,utr),e(yd,Rz),e(Rz,_tr),e(yd,btr),e(Tt,vtr),M(hF,Tt,null),e(zo,Ftr),e(zo,ho),M(BL,ho,null),e(ho,Ttr),e(ho,U_e),e(U_e,Mtr),e(ho,Etr),e(ho,za),e(za,Ctr),e(za,J_e),e(J_e,wtr),e(za,Atr),e(za,Y_e),e(Y_e,ytr),e(za,Ltr),e(za,K_e),e(K_e,xtr),e(za,$tr),e(ho,ktr),e(ho,Zr),e(Zr,pF),e(pF,Z_e),e(Z_e,Str),e(pF,Rtr),e(pF,Pz),e(Pz,Ptr),e(pF,Btr),e(Zr,Itr),e(Zr,uF),e(uF,e2e),e(e2e,qtr),e(uF,Ntr),e(uF,Bz),e(Bz,jtr),e(uF,Dtr),e(Zr,Gtr),e(Zr,_F),e(_F,o2e),e(o2e,Otr),e(_F,Vtr),e(_F,Iz),e(Iz,Xtr),e(_F,ztr),e(Zr,Wtr),e(Zr,bF),e(bF,r2e),e(r2e,Qtr),e(bF,Htr),e(bF,qz),e(qz,Utr),e(bF,Jtr),e(Zr,Ytr),e(Zr,vF),e(vF,t2e),e(t2e,Ktr),e(vF,Ztr),e(vF,Nz),e(Nz,ear),e(vF,oar),e(ho,rar),e(ho,FF),e(FF,tar),e(FF,a2e),e(a2e,aar),e(FF,nar),e(FF,n2e),e(n2e,sar),e(ho,lar),M(TF,ho,null),b(f,JNe,_),b(f,Ld,_),e(Ld,MF),e(MF,s2e),M(IL,s2e,null),e(Ld,iar),e(Ld,l2e),e(l2e,dar),b(f,YNe,_),b(f,Wo,_),M(qL,Wo,null),e(Wo,car),e(Wo,xd),e(xd,far),e(xd,jz),e(jz,mar),e(xd,gar),e(xd,Dz),e(Dz,har),e(xd,par),e(Wo,uar),e(Wo,NL),e(NL,_ar),e(NL,i2e),e(i2e,bar),e(NL,Far),e(Wo,Tar),e(Wo,Mt),M(jL,Mt,null),e(Mt,Mar),e(Mt,d2e),e(d2e,Ear),e(Mt,Car),e(Mt,$d),e($d,war),e($d,c2e),e(c2e,Aar),e($d,yar),e($d,Gz),e(Gz,Lar),e($d,xar),e(Mt,$ar),M(EF,Mt,null),e(Wo,kar),e(Wo,po),M(DL,po,null),e(po,Sar),e(po,f2e),e(f2e,Rar),e(po,Par),e(po,Wa),e(Wa,Bar),e(Wa,m2e),e(m2e,Iar),e(Wa,qar),e(Wa,g2e),e(g2e,Nar),e(Wa,jar),e(Wa,h2e),e(h2e,Dar),e(Wa,Gar),e(po,Oar),e(po,kd),e(kd,CF),e(CF,p2e),e(p2e,Var),e(CF,Xar),e(CF,Oz),e(Oz,zar),e(CF,War),e(kd,Qar),e(kd,wF),e(wF,u2e),e(u2e,Har),e(wF,Uar),e(wF,Vz),e(Vz,Jar),e(wF,Yar),e(kd,Kar),e(kd,AF),e(AF,_2e),e(_2e,Zar),e(AF,enr),e(AF,Xz),e(Xz,onr),e(AF,rnr),e(po,tnr),e(po,yF),e(yF,anr),e(yF,b2e),e(b2e,nnr),e(yF,snr),e(yF,v2e),e(v2e,lnr),e(po,inr),M(LF,po,null),b(f,KNe,_),b(f,Sd,_),e(Sd,xF),e(xF,F2e),M(GL,F2e,null),e(Sd,dnr),e(Sd,T2e),e(T2e,cnr),b(f,ZNe,_),b(f,Qo,_),M(OL,Qo,null),e(Qo,fnr),e(Qo,Rd),e(Rd,mnr),e(Rd,zz),e(zz,gnr),e(Rd,hnr),e(Rd,Wz),e(Wz,pnr),e(Rd,unr),e(Qo,_nr),e(Qo,VL),e(VL,bnr),e(VL,M2e),e(M2e,vnr),e(VL,Fnr),e(Qo,Tnr),e(Qo,Et),M(XL,Et,null),e(Et,Mnr),e(Et,E2e),e(E2e,Enr),e(Et,Cnr),e(Et,Pd),e(Pd,wnr),e(Pd,C2e),e(C2e,Anr),e(Pd,ynr),e(Pd,Qz),e(Qz,Lnr),e(Pd,xnr),e(Et,$nr),M($F,Et,null),e(Qo,knr),e(Qo,uo),M(zL,uo,null),e(uo,Snr),e(uo,w2e),e(w2e,Rnr),e(uo,Pnr),e(uo,Qa),e(Qa,Bnr),e(Qa,A2e),e(A2e,Inr),e(Qa,qnr),e(Qa,y2e),e(y2e,Nnr),e(Qa,jnr),e(Qa,L2e),e(L2e,Dnr),e(Qa,Gnr),e(uo,Onr),e(uo,WL),e(WL,kF),e(kF,x2e),e(x2e,Vnr),e(kF,Xnr),e(kF,Hz),e(Hz,znr),e(kF,Wnr),e(WL,Qnr),e(WL,SF),e(SF,$2e),e($2e,Hnr),e(SF,Unr),e(SF,Uz),e(Uz,Jnr),e(SF,Ynr),e(uo,Knr),e(uo,RF),e(RF,Znr),e(RF,k2e),e(k2e,esr),e(RF,osr),e(RF,S2e),e(S2e,rsr),e(uo,tsr),M(PF,uo,null),b(f,eje,_),b(f,Bd,_),e(Bd,BF),e(BF,R2e),M(QL,R2e,null),e(Bd,asr),e(Bd,P2e),e(P2e,nsr),b(f,oje,_),b(f,Ho,_),M(HL,Ho,null),e(Ho,ssr),e(Ho,Id),e(Id,lsr),e(Id,Jz),e(Jz,isr),e(Id,dsr),e(Id,Yz),e(Yz,csr),e(Id,fsr),e(Ho,msr),e(Ho,UL),e(UL,gsr),e(UL,B2e),e(B2e,hsr),e(UL,psr),e(Ho,usr),e(Ho,Ct),M(JL,Ct,null),e(Ct,_sr),e(Ct,I2e),e(I2e,bsr),e(Ct,vsr),e(Ct,qd),e(qd,Fsr),e(qd,q2e),e(q2e,Tsr),e(qd,Msr),e(qd,Kz),e(Kz,Esr),e(qd,Csr),e(Ct,wsr),M(IF,Ct,null),e(Ho,Asr),e(Ho,_o),M(YL,_o,null),e(_o,ysr),e(_o,N2e),e(N2e,Lsr),e(_o,xsr),e(_o,Ha),e(Ha,$sr),e(Ha,j2e),e(j2e,ksr),e(Ha,Ssr),e(Ha,D2e),e(D2e,Rsr),e(Ha,Psr),e(Ha,G2e),e(G2e,Bsr),e(Ha,Isr),e(_o,qsr),e(_o,O2e),e(O2e,qF),e(qF,V2e),e(V2e,Nsr),e(qF,jsr),e(qF,Zz),e(Zz,Dsr),e(qF,Gsr),e(_o,Osr),e(_o,NF),e(NF,Vsr),e(NF,X2e),e(X2e,Xsr),e(NF,zsr),e(NF,z2e),e(z2e,Wsr),e(_o,Qsr),M(jF,_o,null),b(f,rje,_),b(f,Nd,_),e(Nd,DF),e(DF,W2e),M(KL,W2e,null),e(Nd,Hsr),e(Nd,Q2e),e(Q2e,Usr),b(f,tje,_),b(f,Uo,_),M(ZL,Uo,null),e(Uo,Jsr),e(Uo,jd),e(jd,Ysr),e(jd,eW),e(eW,Ksr),e(jd,Zsr),e(jd,oW),e(oW,elr),e(jd,olr),e(Uo,rlr),e(Uo,e8),e(e8,tlr),e(e8,H2e),e(H2e,alr),e(e8,nlr),e(Uo,slr),e(Uo,wt),M(o8,wt,null),e(wt,llr),e(wt,U2e),e(U2e,ilr),e(wt,dlr),e(wt,Dd),e(Dd,clr),e(Dd,J2e),e(J2e,flr),e(Dd,mlr),e(Dd,rW),e(rW,glr),e(Dd,hlr),e(wt,plr),M(GF,wt,null),e(Uo,ulr),e(Uo,bo),M(r8,bo,null),e(bo,_lr),e(bo,Y2e),e(Y2e,blr),e(bo,vlr),e(bo,Ua),e(Ua,Flr),e(Ua,K2e),e(K2e,Tlr),e(Ua,Mlr),e(Ua,Z2e),e(Z2e,Elr),e(Ua,Clr),e(Ua,e1e),e(e1e,wlr),e(Ua,Alr),e(bo,ylr),e(bo,Ja),e(Ja,OF),e(OF,o1e),e(o1e,Llr),e(OF,xlr),e(OF,tW),e(tW,$lr),e(OF,klr),e(Ja,Slr),e(Ja,VF),e(VF,r1e),e(r1e,Rlr),e(VF,Plr),e(VF,aW),e(aW,Blr),e(VF,Ilr),e(Ja,qlr),e(Ja,XF),e(XF,t1e),e(t1e,Nlr),e(XF,jlr),e(XF,nW),e(nW,Dlr),e(XF,Glr),e(Ja,Olr),e(Ja,zF),e(zF,a1e),e(a1e,Vlr),e(zF,Xlr),e(zF,sW),e(sW,zlr),e(zF,Wlr),e(bo,Qlr),e(bo,WF),e(WF,Hlr),e(WF,n1e),e(n1e,Ulr),e(WF,Jlr),e(WF,s1e),e(s1e,Ylr),e(bo,Klr),M(QF,bo,null),b(f,aje,_),b(f,Gd,_),e(Gd,HF),e(HF,l1e),M(t8,l1e,null),e(Gd,Zlr),e(Gd,i1e),e(i1e,eir),b(f,nje,_),b(f,Jo,_),M(a8,Jo,null),e(Jo,oir),e(Jo,Od),e(Od,rir),e(Od,lW),e(lW,tir),e(Od,air),e(Od,iW),e(iW,nir),e(Od,sir),e(Jo,lir),e(Jo,n8),e(n8,iir),e(n8,d1e),e(d1e,dir),e(n8,cir),e(Jo,fir),e(Jo,At),M(s8,At,null),e(At,mir),e(At,c1e),e(c1e,gir),e(At,hir),e(At,Vd),e(Vd,pir),e(Vd,f1e),e(f1e,uir),e(Vd,_ir),e(Vd,dW),e(dW,bir),e(Vd,vir),e(At,Fir),M(UF,At,null),e(Jo,Tir),e(Jo,vo),M(l8,vo,null),e(vo,Mir),e(vo,m1e),e(m1e,Eir),e(vo,Cir),e(vo,Ya),e(Ya,wir),e(Ya,g1e),e(g1e,Air),e(Ya,yir),e(Ya,h1e),e(h1e,Lir),e(Ya,xir),e(Ya,p1e),e(p1e,$ir),e(Ya,kir),e(vo,Sir),e(vo,u1e),e(u1e,JF),e(JF,_1e),e(_1e,Rir),e(JF,Pir),e(JF,cW),e(cW,Bir),e(JF,Iir),e(vo,qir),e(vo,YF),e(YF,Nir),e(YF,b1e),e(b1e,jir),e(YF,Dir),e(YF,v1e),e(v1e,Gir),e(vo,Oir),M(KF,vo,null),b(f,sje,_),b(f,Xd,_),e(Xd,ZF),e(ZF,F1e),M(i8,F1e,null),e(Xd,Vir),e(Xd,T1e),e(T1e,Xir),b(f,lje,_),b(f,Yo,_),M(d8,Yo,null),e(Yo,zir),e(Yo,zd),e(zd,Wir),e(zd,fW),e(fW,Qir),e(zd,Hir),e(zd,mW),e(mW,Uir),e(zd,Jir),e(Yo,Yir),e(Yo,c8),e(c8,Kir),e(c8,M1e),e(M1e,Zir),e(c8,edr),e(Yo,odr),e(Yo,yt),M(f8,yt,null),e(yt,rdr),e(yt,E1e),e(E1e,tdr),e(yt,adr),e(yt,Wd),e(Wd,ndr),e(Wd,C1e),e(C1e,sdr),e(Wd,ldr),e(Wd,gW),e(gW,idr),e(Wd,ddr),e(yt,cdr),M(eT,yt,null),e(Yo,fdr),e(Yo,wr),M(m8,wr,null),e(wr,mdr),e(wr,w1e),e(w1e,gdr),e(wr,hdr),e(wr,Ka),e(Ka,pdr),e(Ka,A1e),e(A1e,udr),e(Ka,_dr),e(Ka,y1e),e(y1e,bdr),e(Ka,vdr),e(Ka,L1e),e(L1e,Fdr),e(Ka,Tdr),e(wr,Mdr),e(wr,N),e(N,oT),e(oT,x1e),e(x1e,Edr),e(oT,Cdr),e(oT,hW),e(hW,wdr),e(oT,Adr),e(N,ydr),e(N,rT),e(rT,$1e),e($1e,Ldr),e(rT,xdr),e(rT,pW),e(pW,$dr),e(rT,kdr),e(N,Sdr),e(N,tT),e(tT,k1e),e(k1e,Rdr),e(tT,Pdr),e(tT,uW),e(uW,Bdr),e(tT,Idr),e(N,qdr),e(N,aT),e(aT,S1e),e(S1e,Ndr),e(aT,jdr),e(aT,_W),e(_W,Ddr),e(aT,Gdr),e(N,Odr),e(N,nT),e(nT,R1e),e(R1e,Vdr),e(nT,Xdr),e(nT,bW),e(bW,zdr),e(nT,Wdr),e(N,Qdr),e(N,sT),e(sT,P1e),e(P1e,Hdr),e(sT,Udr),e(sT,vW),e(vW,Jdr),e(sT,Ydr),e(N,Kdr),e(N,lT),e(lT,B1e),e(B1e,Zdr),e(lT,ecr),e(lT,FW),e(FW,ocr),e(lT,rcr),e(N,tcr),e(N,iT),e(iT,I1e),e(I1e,acr),e(iT,ncr),e(iT,TW),e(TW,scr),e(iT,lcr),e(N,icr),e(N,dT),e(dT,q1e),e(q1e,dcr),e(dT,ccr),e(dT,MW),e(MW,fcr),e(dT,mcr),e(N,gcr),e(N,cT),e(cT,N1e),e(N1e,hcr),e(cT,pcr),e(cT,EW),e(EW,ucr),e(cT,_cr),e(N,bcr),e(N,fT),e(fT,j1e),e(j1e,vcr),e(fT,Fcr),e(fT,CW),e(CW,Tcr),e(fT,Mcr),e(N,Ecr),e(N,mT),e(mT,D1e),e(D1e,Ccr),e(mT,wcr),e(mT,wW),e(wW,Acr),e(mT,ycr),e(N,Lcr),e(N,gT),e(gT,G1e),e(G1e,xcr),e(gT,$cr),e(gT,AW),e(AW,kcr),e(gT,Scr),e(N,Rcr),e(N,hT),e(hT,O1e),e(O1e,Pcr),e(hT,Bcr),e(hT,yW),e(yW,Icr),e(hT,qcr),e(N,Ncr),e(N,pT),e(pT,V1e),e(V1e,jcr),e(pT,Dcr),e(pT,LW),e(LW,Gcr),e(pT,Ocr),e(N,Vcr),e(N,uT),e(uT,X1e),e(X1e,Xcr),e(uT,zcr),e(uT,xW),e(xW,Wcr),e(uT,Qcr),e(N,Hcr),e(N,_T),e(_T,z1e),e(z1e,Ucr),e(_T,Jcr),e(_T,$W),e($W,Ycr),e(_T,Kcr),e(N,Zcr),e(N,js),e(js,W1e),e(W1e,efr),e(js,ofr),e(js,kW),e(kW,rfr),e(js,tfr),e(js,SW),e(SW,afr),e(js,nfr),e(N,sfr),e(N,bT),e(bT,Q1e),e(Q1e,lfr),e(bT,ifr),e(bT,RW),e(RW,dfr),e(bT,cfr),e(N,ffr),e(N,vT),e(vT,H1e),e(H1e,mfr),e(vT,gfr),e(vT,PW),e(PW,hfr),e(vT,pfr),e(N,ufr),e(N,FT),e(FT,U1e),e(U1e,_fr),e(FT,bfr),e(FT,BW),e(BW,vfr),e(FT,Ffr),e(N,Tfr),e(N,TT),e(TT,J1e),e(J1e,Mfr),e(TT,Efr),e(TT,IW),e(IW,Cfr),e(TT,wfr),e(N,Afr),e(N,MT),e(MT,Y1e),e(Y1e,yfr),e(MT,Lfr),e(MT,qW),e(qW,xfr),e(MT,$fr),e(N,kfr),e(N,ET),e(ET,K1e),e(K1e,Sfr),e(ET,Rfr),e(ET,NW),e(NW,Pfr),e(ET,Bfr),e(N,Ifr),e(N,CT),e(CT,Z1e),e(Z1e,qfr),e(CT,Nfr),e(CT,jW),e(jW,jfr),e(CT,Dfr),e(N,Gfr),e(N,wT),e(wT,ebe),e(ebe,Ofr),e(wT,Vfr),e(wT,DW),e(DW,Xfr),e(wT,zfr),e(N,Wfr),e(N,AT),e(AT,obe),e(obe,Qfr),e(AT,Hfr),e(AT,GW),e(GW,Ufr),e(AT,Jfr),e(N,Yfr),e(N,yT),e(yT,rbe),e(rbe,Kfr),e(yT,Zfr),e(yT,OW),e(OW,emr),e(yT,omr),e(N,rmr),e(N,LT),e(LT,tbe),e(tbe,tmr),e(LT,amr),e(LT,VW),e(VW,nmr),e(LT,smr),e(N,lmr),e(N,xT),e(xT,abe),e(abe,imr),e(xT,dmr),e(xT,XW),e(XW,cmr),e(xT,fmr),e(N,mmr),e(N,$T),e($T,nbe),e(nbe,gmr),e($T,hmr),e($T,zW),e(zW,pmr),e($T,umr),e(N,_mr),e(N,kT),e(kT,sbe),e(sbe,bmr),e(kT,vmr),e(kT,WW),e(WW,Fmr),e(kT,Tmr),e(N,Mmr),e(N,ST),e(ST,lbe),e(lbe,Emr),e(ST,Cmr),e(ST,QW),e(QW,wmr),e(ST,Amr),e(N,ymr),e(N,RT),e(RT,ibe),e(ibe,Lmr),e(RT,xmr),e(RT,HW),e(HW,$mr),e(RT,kmr),e(N,Smr),e(N,PT),e(PT,dbe),e(dbe,Rmr),e(PT,Pmr),e(PT,UW),e(UW,Bmr),e(PT,Imr),e(N,qmr),e(N,BT),e(BT,cbe),e(cbe,Nmr),e(BT,jmr),e(BT,JW),e(JW,Dmr),e(BT,Gmr),e(N,Omr),e(N,IT),e(IT,fbe),e(fbe,Vmr),e(IT,Xmr),e(IT,YW),e(YW,zmr),e(IT,Wmr),e(N,Qmr),e(N,qT),e(qT,mbe),e(mbe,Hmr),e(qT,Umr),e(qT,KW),e(KW,Jmr),e(qT,Ymr),e(N,Kmr),e(N,NT),e(NT,gbe),e(gbe,Zmr),e(NT,egr),e(NT,ZW),e(ZW,ogr),e(NT,rgr),e(N,tgr),e(N,jT),e(jT,hbe),e(hbe,agr),e(jT,ngr),e(jT,eQ),e(eQ,sgr),e(jT,lgr),e(N,igr),e(N,DT),e(DT,pbe),e(pbe,dgr),e(DT,cgr),e(DT,oQ),e(oQ,fgr),e(DT,mgr),e(N,ggr),e(N,GT),e(GT,ube),e(ube,hgr),e(GT,pgr),e(GT,rQ),e(rQ,ugr),e(GT,_gr),e(N,bgr),e(N,OT),e(OT,_be),e(_be,vgr),e(OT,Fgr),e(OT,tQ),e(tQ,Tgr),e(OT,Mgr),e(N,Egr),e(N,VT),e(VT,bbe),e(bbe,Cgr),e(VT,wgr),e(VT,aQ),e(aQ,Agr),e(VT,ygr),e(N,Lgr),e(N,XT),e(XT,vbe),e(vbe,xgr),e(XT,$gr),e(XT,nQ),e(nQ,kgr),e(XT,Sgr),e(N,Rgr),e(N,zT),e(zT,Fbe),e(Fbe,Pgr),e(zT,Bgr),e(zT,sQ),e(sQ,Igr),e(zT,qgr),e(wr,Ngr),M(WT,wr,null),b(f,ije,_),b(f,Qd,_),e(Qd,QT),e(QT,Tbe),M(g8,Tbe,null),e(Qd,jgr),e(Qd,Mbe),e(Mbe,Dgr),b(f,dje,_),b(f,Ko,_),M(h8,Ko,null),e(Ko,Ggr),e(Ko,Hd),e(Hd,Ogr),e(Hd,lQ),e(lQ,Vgr),e(Hd,Xgr),e(Hd,iQ),e(iQ,zgr),e(Hd,Wgr),e(Ko,Qgr),e(Ko,p8),e(p8,Hgr),e(p8,Ebe),e(Ebe,Ugr),e(p8,Jgr),e(Ko,Ygr),e(Ko,Lt),M(u8,Lt,null),e(Lt,Kgr),e(Lt,Cbe),e(Cbe,Zgr),e(Lt,ehr),e(Lt,Ud),e(Ud,ohr),e(Ud,wbe),e(wbe,rhr),e(Ud,thr),e(Ud,dQ),e(dQ,ahr),e(Ud,nhr),e(Lt,shr),M(HT,Lt,null),e(Ko,lhr),e(Ko,Ar),M(_8,Ar,null),e(Ar,ihr),e(Ar,Abe),e(Abe,dhr),e(Ar,chr),e(Ar,Za),e(Za,fhr),e(Za,ybe),e(ybe,mhr),e(Za,ghr),e(Za,Lbe),e(Lbe,hhr),e(Za,phr),e(Za,xbe),e(xbe,uhr),e(Za,_hr),e(Ar,bhr),e(Ar,se),e(se,UT),e(UT,$be),e($be,vhr),e(UT,Fhr),e(UT,cQ),e(cQ,Thr),e(UT,Mhr),e(se,Ehr),e(se,JT),e(JT,kbe),e(kbe,Chr),e(JT,whr),e(JT,fQ),e(fQ,Ahr),e(JT,yhr),e(se,Lhr),e(se,YT),e(YT,Sbe),e(Sbe,xhr),e(YT,$hr),e(YT,mQ),e(mQ,khr),e(YT,Shr),e(se,Rhr),e(se,KT),e(KT,Rbe),e(Rbe,Phr),e(KT,Bhr),e(KT,gQ),e(gQ,Ihr),e(KT,qhr),e(se,Nhr),e(se,ZT),e(ZT,Pbe),e(Pbe,jhr),e(ZT,Dhr),e(ZT,hQ),e(hQ,Ghr),e(ZT,Ohr),e(se,Vhr),e(se,e7),e(e7,Bbe),e(Bbe,Xhr),e(e7,zhr),e(e7,pQ),e(pQ,Whr),e(e7,Qhr),e(se,Hhr),e(se,o7),e(o7,Ibe),e(Ibe,Uhr),e(o7,Jhr),e(o7,uQ),e(uQ,Yhr),e(o7,Khr),e(se,Zhr),e(se,r7),e(r7,qbe),e(qbe,epr),e(r7,opr),e(r7,_Q),e(_Q,rpr),e(r7,tpr),e(se,apr),e(se,t7),e(t7,Nbe),e(Nbe,npr),e(t7,spr),e(t7,bQ),e(bQ,lpr),e(t7,ipr),e(se,dpr),e(se,a7),e(a7,jbe),e(jbe,cpr),e(a7,fpr),e(a7,vQ),e(vQ,mpr),e(a7,gpr),e(se,hpr),e(se,n7),e(n7,Dbe),e(Dbe,ppr),e(n7,upr),e(n7,FQ),e(FQ,_pr),e(n7,bpr),e(se,vpr),e(se,s7),e(s7,Gbe),e(Gbe,Fpr),e(s7,Tpr),e(s7,TQ),e(TQ,Mpr),e(s7,Epr),e(se,Cpr),e(se,l7),e(l7,Obe),e(Obe,wpr),e(l7,Apr),e(l7,MQ),e(MQ,ypr),e(l7,Lpr),e(se,xpr),e(se,i7),e(i7,Vbe),e(Vbe,$pr),e(i7,kpr),e(i7,EQ),e(EQ,Spr),e(i7,Rpr),e(se,Ppr),e(se,d7),e(d7,Xbe),e(Xbe,Bpr),e(d7,Ipr),e(d7,CQ),e(CQ,qpr),e(d7,Npr),e(se,jpr),e(se,c7),e(c7,zbe),e(zbe,Dpr),e(c7,Gpr),e(c7,wQ),e(wQ,Opr),e(c7,Vpr),e(se,Xpr),e(se,f7),e(f7,Wbe),e(Wbe,zpr),e(f7,Wpr),e(f7,AQ),e(AQ,Qpr),e(f7,Hpr),e(se,Upr),e(se,m7),e(m7,Qbe),e(Qbe,Jpr),e(m7,Ypr),e(m7,yQ),e(yQ,Kpr),e(m7,Zpr),e(se,eur),e(se,g7),e(g7,Hbe),e(Hbe,our),e(g7,rur),e(g7,LQ),e(LQ,tur),e(g7,aur),e(se,nur),e(se,h7),e(h7,Ube),e(Ube,sur),e(h7,lur),e(h7,xQ),e(xQ,iur),e(h7,dur),e(se,cur),e(se,p7),e(p7,Jbe),e(Jbe,fur),e(p7,mur),e(p7,$Q),e($Q,gur),e(p7,hur),e(se,pur),e(se,u7),e(u7,Ybe),e(Ybe,uur),e(u7,_ur),e(u7,kQ),e(kQ,bur),e(u7,vur),e(se,Fur),e(se,_7),e(_7,Kbe),e(Kbe,Tur),e(_7,Mur),e(_7,SQ),e(SQ,Eur),e(_7,Cur),e(Ar,wur),M(b7,Ar,null),b(f,cje,_),b(f,Jd,_),e(Jd,v7),e(v7,Zbe),M(b8,Zbe,null),e(Jd,Aur),e(Jd,e4e),e(e4e,yur),b(f,fje,_),b(f,Zo,_),M(v8,Zo,null),e(Zo,Lur),e(Zo,Yd),e(Yd,xur),e(Yd,RQ),e(RQ,$ur),e(Yd,kur),e(Yd,PQ),e(PQ,Sur),e(Yd,Rur),e(Zo,Pur),e(Zo,F8),e(F8,Bur),e(F8,o4e),e(o4e,Iur),e(F8,qur),e(Zo,Nur),e(Zo,xt),M(T8,xt,null),e(xt,jur),e(xt,r4e),e(r4e,Dur),e(xt,Gur),e(xt,Kd),e(Kd,Our),e(Kd,t4e),e(t4e,Vur),e(Kd,Xur),e(Kd,BQ),e(BQ,zur),e(Kd,Wur),e(xt,Qur),M(F7,xt,null),e(Zo,Hur),e(Zo,yr),M(M8,yr,null),e(yr,Uur),e(yr,a4e),e(a4e,Jur),e(yr,Yur),e(yr,en),e(en,Kur),e(en,n4e),e(n4e,Zur),e(en,e_r),e(en,s4e),e(s4e,o_r),e(en,r_r),e(en,l4e),e(l4e,t_r),e(en,a_r),e(yr,n_r),e(yr,Me),e(Me,T7),e(T7,i4e),e(i4e,s_r),e(T7,l_r),e(T7,IQ),e(IQ,i_r),e(T7,d_r),e(Me,c_r),e(Me,M7),e(M7,d4e),e(d4e,f_r),e(M7,m_r),e(M7,qQ),e(qQ,g_r),e(M7,h_r),e(Me,p_r),e(Me,E7),e(E7,c4e),e(c4e,u_r),e(E7,__r),e(E7,NQ),e(NQ,b_r),e(E7,v_r),e(Me,F_r),e(Me,C7),e(C7,f4e),e(f4e,T_r),e(C7,M_r),e(C7,jQ),e(jQ,E_r),e(C7,C_r),e(Me,w_r),e(Me,w7),e(w7,m4e),e(m4e,A_r),e(w7,y_r),e(w7,DQ),e(DQ,L_r),e(w7,x_r),e(Me,$_r),e(Me,A7),e(A7,g4e),e(g4e,k_r),e(A7,S_r),e(A7,GQ),e(GQ,R_r),e(A7,P_r),e(Me,B_r),e(Me,y7),e(y7,h4e),e(h4e,I_r),e(y7,q_r),e(y7,OQ),e(OQ,N_r),e(y7,j_r),e(Me,D_r),e(Me,L7),e(L7,p4e),e(p4e,G_r),e(L7,O_r),e(L7,VQ),e(VQ,V_r),e(L7,X_r),e(Me,z_r),e(Me,x7),e(x7,u4e),e(u4e,W_r),e(x7,Q_r),e(x7,XQ),e(XQ,H_r),e(x7,U_r),e(Me,J_r),e(Me,$7),e($7,_4e),e(_4e,Y_r),e($7,K_r),e($7,zQ),e(zQ,Z_r),e($7,e2r),e(Me,o2r),e(Me,k7),e(k7,b4e),e(b4e,r2r),e(k7,t2r),e(k7,WQ),e(WQ,a2r),e(k7,n2r),e(Me,s2r),e(Me,S7),e(S7,v4e),e(v4e,l2r),e(S7,i2r),e(S7,QQ),e(QQ,d2r),e(S7,c2r),e(yr,f2r),M(R7,yr,null),b(f,mje,_),b(f,Zd,_),e(Zd,P7),e(P7,F4e),M(E8,F4e,null),e(Zd,m2r),e(Zd,T4e),e(T4e,g2r),b(f,gje,_),b(f,er,_),M(C8,er,null),e(er,h2r),e(er,ec),e(ec,p2r),e(ec,HQ),e(HQ,u2r),e(ec,_2r),e(ec,UQ),e(UQ,b2r),e(ec,v2r),e(er,F2r),e(er,w8),e(w8,T2r),e(w8,M4e),e(M4e,M2r),e(w8,E2r),e(er,C2r),e(er,$t),M(A8,$t,null),e($t,w2r),e($t,E4e),e(E4e,A2r),e($t,y2r),e($t,oc),e(oc,L2r),e(oc,C4e),e(C4e,x2r),e(oc,$2r),e(oc,JQ),e(JQ,k2r),e(oc,S2r),e($t,R2r),M(B7,$t,null),e(er,P2r),e(er,Lr),M(y8,Lr,null),e(Lr,B2r),e(Lr,w4e),e(w4e,I2r),e(Lr,q2r),e(Lr,on),e(on,N2r),e(on,A4e),e(A4e,j2r),e(on,D2r),e(on,y4e),e(y4e,G2r),e(on,O2r),e(on,L4e),e(L4e,V2r),e(on,X2r),e(Lr,z2r),e(Lr,rn),e(rn,I7),e(I7,x4e),e(x4e,W2r),e(I7,Q2r),e(I7,YQ),e(YQ,H2r),e(I7,U2r),e(rn,J2r),e(rn,q7),e(q7,$4e),e($4e,Y2r),e(q7,K2r),e(q7,KQ),e(KQ,Z2r),e(q7,e1r),e(rn,o1r),e(rn,N7),e(N7,k4e),e(k4e,r1r),e(N7,t1r),e(N7,ZQ),e(ZQ,a1r),e(N7,n1r),e(rn,s1r),e(rn,j7),e(j7,S4e),e(S4e,l1r),e(j7,i1r),e(j7,eH),e(eH,d1r),e(j7,c1r),e(Lr,f1r),M(D7,Lr,null),b(f,hje,_),b(f,rc,_),e(rc,G7),e(G7,R4e),M(L8,R4e,null),e(rc,m1r),e(rc,P4e),e(P4e,g1r),b(f,pje,_),b(f,or,_),M(x8,or,null),e(or,h1r),e(or,tc),e(tc,p1r),e(tc,oH),e(oH,u1r),e(tc,_1r),e(tc,rH),e(rH,b1r),e(tc,v1r),e(or,F1r),e(or,$8),e($8,T1r),e($8,B4e),e(B4e,M1r),e($8,E1r),e(or,C1r),e(or,kt),M(k8,kt,null),e(kt,w1r),e(kt,I4e),e(I4e,A1r),e(kt,y1r),e(kt,ac),e(ac,L1r),e(ac,q4e),e(q4e,x1r),e(ac,$1r),e(ac,tH),e(tH,k1r),e(ac,S1r),e(kt,R1r),M(O7,kt,null),e(or,P1r),e(or,xr),M(S8,xr,null),e(xr,B1r),e(xr,N4e),e(N4e,I1r),e(xr,q1r),e(xr,tn),e(tn,N1r),e(tn,j4e),e(j4e,j1r),e(tn,D1r),e(tn,D4e),e(D4e,G1r),e(tn,O1r),e(tn,G4e),e(G4e,V1r),e(tn,X1r),e(xr,z1r),e(xr,ie),e(ie,V7),e(V7,O4e),e(O4e,W1r),e(V7,Q1r),e(V7,aH),e(aH,H1r),e(V7,U1r),e(ie,J1r),e(ie,X7),e(X7,V4e),e(V4e,Y1r),e(X7,K1r),e(X7,nH),e(nH,Z1r),e(X7,ebr),e(ie,obr),e(ie,z7),e(z7,X4e),e(X4e,rbr),e(z7,tbr),e(z7,sH),e(sH,abr),e(z7,nbr),e(ie,sbr),e(ie,W7),e(W7,z4e),e(z4e,lbr),e(W7,ibr),e(W7,lH),e(lH,dbr),e(W7,cbr),e(ie,fbr),e(ie,Q7),e(Q7,W4e),e(W4e,mbr),e(Q7,gbr),e(Q7,iH),e(iH,hbr),e(Q7,pbr),e(ie,ubr),e(ie,H7),e(H7,Q4e),e(Q4e,_br),e(H7,bbr),e(H7,dH),e(dH,vbr),e(H7,Fbr),e(ie,Tbr),e(ie,U7),e(U7,H4e),e(H4e,Mbr),e(U7,Ebr),e(U7,cH),e(cH,Cbr),e(U7,wbr),e(ie,Abr),e(ie,J7),e(J7,U4e),e(U4e,ybr),e(J7,Lbr),e(J7,fH),e(fH,xbr),e(J7,$br),e(ie,kbr),e(ie,Y7),e(Y7,J4e),e(J4e,Sbr),e(Y7,Rbr),e(Y7,mH),e(mH,Pbr),e(Y7,Bbr),e(ie,Ibr),e(ie,K7),e(K7,Y4e),e(Y4e,qbr),e(K7,Nbr),e(K7,gH),e(gH,jbr),e(K7,Dbr),e(ie,Gbr),e(ie,Z7),e(Z7,K4e),e(K4e,Obr),e(Z7,Vbr),e(Z7,hH),e(hH,Xbr),e(Z7,zbr),e(ie,Wbr),e(ie,eM),e(eM,Z4e),e(Z4e,Qbr),e(eM,Hbr),e(eM,pH),e(pH,Ubr),e(eM,Jbr),e(ie,Ybr),e(ie,oM),e(oM,eve),e(eve,Kbr),e(oM,Zbr),e(oM,uH),e(uH,e4r),e(oM,o4r),e(ie,r4r),e(ie,rM),e(rM,ove),e(ove,t4r),e(rM,a4r),e(rM,_H),e(_H,n4r),e(rM,s4r),e(ie,l4r),e(ie,tM),e(tM,rve),e(rve,i4r),e(tM,d4r),e(tM,bH),e(bH,c4r),e(tM,f4r),e(ie,m4r),e(ie,aM),e(aM,tve),e(tve,g4r),e(aM,h4r),e(aM,vH),e(vH,p4r),e(aM,u4r),e(ie,_4r),e(ie,nM),e(nM,ave),e(ave,b4r),e(nM,v4r),e(nM,FH),e(FH,F4r),e(nM,T4r),e(ie,M4r),e(ie,sM),e(sM,nve),e(nve,E4r),e(sM,C4r),e(sM,TH),e(TH,w4r),e(sM,A4r),e(ie,y4r),e(ie,lM),e(lM,sve),e(sve,L4r),e(lM,x4r),e(lM,MH),e(MH,$4r),e(lM,k4r),e(ie,S4r),e(ie,iM),e(iM,lve),e(lve,R4r),e(iM,P4r),e(iM,EH),e(EH,B4r),e(iM,I4r),e(xr,q4r),M(dM,xr,null),b(f,uje,_),b(f,nc,_),e(nc,cM),e(cM,ive),M(R8,ive,null),e(nc,N4r),e(nc,dve),e(dve,j4r),b(f,_je,_),b(f,rr,_),M(P8,rr,null),e(rr,D4r),e(rr,sc),e(sc,G4r),e(sc,CH),e(CH,O4r),e(sc,V4r),e(sc,wH),e(wH,X4r),e(sc,z4r),e(rr,W4r),e(rr,B8),e(B8,Q4r),e(B8,cve),e(cve,H4r),e(B8,U4r),e(rr,J4r),e(rr,St),M(I8,St,null),e(St,Y4r),e(St,fve),e(fve,K4r),e(St,Z4r),e(St,lc),e(lc,evr),e(lc,mve),e(mve,ovr),e(lc,rvr),e(lc,AH),e(AH,tvr),e(lc,avr),e(St,nvr),M(fM,St,null),e(rr,svr),e(rr,$r),M(q8,$r,null),e($r,lvr),e($r,gve),e(gve,ivr),e($r,dvr),e($r,an),e(an,cvr),e(an,hve),e(hve,fvr),e(an,mvr),e(an,pve),e(pve,gvr),e(an,hvr),e(an,uve),e(uve,pvr),e(an,uvr),e($r,_vr),e($r,ye),e(ye,mM),e(mM,_ve),e(_ve,bvr),e(mM,vvr),e(mM,yH),e(yH,Fvr),e(mM,Tvr),e(ye,Mvr),e(ye,gM),e(gM,bve),e(bve,Evr),e(gM,Cvr),e(gM,LH),e(LH,wvr),e(gM,Avr),e(ye,yvr),e(ye,hM),e(hM,vve),e(vve,Lvr),e(hM,xvr),e(hM,xH),e(xH,$vr),e(hM,kvr),e(ye,Svr),e(ye,pM),e(pM,Fve),e(Fve,Rvr),e(pM,Pvr),e(pM,$H),e($H,Bvr),e(pM,Ivr),e(ye,qvr),e(ye,uM),e(uM,Tve),e(Tve,Nvr),e(uM,jvr),e(uM,kH),e(kH,Dvr),e(uM,Gvr),e(ye,Ovr),e(ye,_M),e(_M,Mve),e(Mve,Vvr),e(_M,Xvr),e(_M,SH),e(SH,zvr),e(_M,Wvr),e(ye,Qvr),e(ye,bM),e(bM,Eve),e(Eve,Hvr),e(bM,Uvr),e(bM,RH),e(RH,Jvr),e(bM,Yvr),e(ye,Kvr),e(ye,vM),e(vM,Cve),e(Cve,Zvr),e(vM,e5r),e(vM,PH),e(PH,o5r),e(vM,r5r),e(ye,t5r),e(ye,FM),e(FM,wve),e(wve,a5r),e(FM,n5r),e(FM,BH),e(BH,s5r),e(FM,l5r),e(ye,i5r),e(ye,TM),e(TM,Ave),e(Ave,d5r),e(TM,c5r),e(TM,IH),e(IH,f5r),e(TM,m5r),e($r,g5r),M(MM,$r,null),b(f,bje,_),b(f,ic,_),e(ic,EM),e(EM,yve),M(N8,yve,null),e(ic,h5r),e(ic,Lve),e(Lve,p5r),b(f,vje,_),b(f,tr,_),M(j8,tr,null),e(tr,u5r),e(tr,dc),e(dc,_5r),e(dc,qH),e(qH,b5r),e(dc,v5r),e(dc,NH),e(NH,F5r),e(dc,T5r),e(tr,M5r),e(tr,D8),e(D8,E5r),e(D8,xve),e(xve,C5r),e(D8,w5r),e(tr,A5r),e(tr,Rt),M(G8,Rt,null),e(Rt,y5r),e(Rt,$ve),e($ve,L5r),e(Rt,x5r),e(Rt,cc),e(cc,$5r),e(cc,kve),e(kve,k5r),e(cc,S5r),e(cc,jH),e(jH,R5r),e(cc,P5r),e(Rt,B5r),M(CM,Rt,null),e(tr,I5r),e(tr,kr),M(O8,kr,null),e(kr,q5r),e(kr,Sve),e(Sve,N5r),e(kr,j5r),e(kr,nn),e(nn,D5r),e(nn,Rve),e(Rve,G5r),e(nn,O5r),e(nn,Pve),e(Pve,V5r),e(nn,X5r),e(nn,Bve),e(Bve,z5r),e(nn,W5r),e(kr,Q5r),e(kr,oe),e(oe,wM),e(wM,Ive),e(Ive,H5r),e(wM,U5r),e(wM,DH),e(DH,J5r),e(wM,Y5r),e(oe,K5r),e(oe,AM),e(AM,qve),e(qve,Z5r),e(AM,eFr),e(AM,GH),e(GH,oFr),e(AM,rFr),e(oe,tFr),e(oe,yM),e(yM,Nve),e(Nve,aFr),e(yM,nFr),e(yM,OH),e(OH,sFr),e(yM,lFr),e(oe,iFr),e(oe,LM),e(LM,jve),e(jve,dFr),e(LM,cFr),e(LM,VH),e(VH,fFr),e(LM,mFr),e(oe,gFr),e(oe,xM),e(xM,Dve),e(Dve,hFr),e(xM,pFr),e(xM,XH),e(XH,uFr),e(xM,_Fr),e(oe,bFr),e(oe,$M),e($M,Gve),e(Gve,vFr),e($M,FFr),e($M,zH),e(zH,TFr),e($M,MFr),e(oe,EFr),e(oe,kM),e(kM,Ove),e(Ove,CFr),e(kM,wFr),e(kM,WH),e(WH,AFr),e(kM,yFr),e(oe,LFr),e(oe,SM),e(SM,Vve),e(Vve,xFr),e(SM,$Fr),e(SM,QH),e(QH,kFr),e(SM,SFr),e(oe,RFr),e(oe,RM),e(RM,Xve),e(Xve,PFr),e(RM,BFr),e(RM,HH),e(HH,IFr),e(RM,qFr),e(oe,NFr),e(oe,PM),e(PM,zve),e(zve,jFr),e(PM,DFr),e(PM,UH),e(UH,GFr),e(PM,OFr),e(oe,VFr),e(oe,BM),e(BM,Wve),e(Wve,XFr),e(BM,zFr),e(BM,JH),e(JH,WFr),e(BM,QFr),e(oe,HFr),e(oe,IM),e(IM,Qve),e(Qve,UFr),e(IM,JFr),e(IM,YH),e(YH,YFr),e(IM,KFr),e(oe,ZFr),e(oe,qM),e(qM,Hve),e(Hve,eTr),e(qM,oTr),e(qM,KH),e(KH,rTr),e(qM,tTr),e(oe,aTr),e(oe,NM),e(NM,Uve),e(Uve,nTr),e(NM,sTr),e(NM,ZH),e(ZH,lTr),e(NM,iTr),e(oe,dTr),e(oe,jM),e(jM,Jve),e(Jve,cTr),e(jM,fTr),e(jM,eU),e(eU,mTr),e(jM,gTr),e(oe,hTr),e(oe,DM),e(DM,Yve),e(Yve,pTr),e(DM,uTr),e(DM,oU),e(oU,_Tr),e(DM,bTr),e(oe,vTr),e(oe,GM),e(GM,Kve),e(Kve,FTr),e(GM,TTr),e(GM,rU),e(rU,MTr),e(GM,ETr),e(oe,CTr),e(oe,OM),e(OM,Zve),e(Zve,wTr),e(OM,ATr),e(OM,tU),e(tU,yTr),e(OM,LTr),e(oe,xTr),e(oe,VM),e(VM,e5e),e(e5e,$Tr),e(VM,kTr),e(VM,aU),e(aU,STr),e(VM,RTr),e(oe,PTr),e(oe,XM),e(XM,o5e),e(o5e,BTr),e(XM,ITr),e(XM,nU),e(nU,qTr),e(XM,NTr),e(oe,jTr),e(oe,zM),e(zM,r5e),e(r5e,DTr),e(zM,GTr),e(zM,sU),e(sU,OTr),e(zM,VTr),e(oe,XTr),e(oe,WM),e(WM,t5e),e(t5e,zTr),e(WM,WTr),e(WM,lU),e(lU,QTr),e(WM,HTr),e(oe,UTr),e(oe,QM),e(QM,a5e),e(a5e,JTr),e(QM,YTr),e(QM,iU),e(iU,KTr),e(QM,ZTr),e(oe,e7r),e(oe,HM),e(HM,n5e),e(n5e,o7r),e(HM,r7r),e(HM,dU),e(dU,t7r),e(HM,a7r),e(oe,n7r),e(oe,UM),e(UM,s5e),e(s5e,s7r),e(UM,l7r),e(UM,cU),e(cU,i7r),e(UM,d7r),e(oe,c7r),e(oe,JM),e(JM,l5e),e(l5e,f7r),e(JM,m7r),e(JM,fU),e(fU,g7r),e(JM,h7r),e(kr,p7r),M(YM,kr,null),b(f,Fje,_),b(f,fc,_),e(fc,KM),e(KM,i5e),M(V8,i5e,null),e(fc,u7r),e(fc,d5e),e(d5e,_7r),b(f,Tje,_),b(f,ar,_),M(X8,ar,null),e(ar,b7r),e(ar,mc),e(mc,v7r),e(mc,mU),e(mU,F7r),e(mc,T7r),e(mc,gU),e(gU,M7r),e(mc,E7r),e(ar,C7r),e(ar,z8),e(z8,w7r),e(z8,c5e),e(c5e,A7r),e(z8,y7r),e(ar,L7r),e(ar,Pt),M(W8,Pt,null),e(Pt,x7r),e(Pt,f5e),e(f5e,$7r),e(Pt,k7r),e(Pt,gc),e(gc,S7r),e(gc,m5e),e(m5e,R7r),e(gc,P7r),e(gc,hU),e(hU,B7r),e(gc,I7r),e(Pt,q7r),M(ZM,Pt,null),e(ar,N7r),e(ar,Sr),M(Q8,Sr,null),e(Sr,j7r),e(Sr,g5e),e(g5e,D7r),e(Sr,G7r),e(Sr,sn),e(sn,O7r),e(sn,h5e),e(h5e,V7r),e(sn,X7r),e(sn,p5e),e(p5e,z7r),e(sn,W7r),e(sn,u5e),e(u5e,Q7r),e(sn,H7r),e(Sr,U7r),e(Sr,pe),e(pe,eE),e(eE,_5e),e(_5e,J7r),e(eE,Y7r),e(eE,pU),e(pU,K7r),e(eE,Z7r),e(pe,eMr),e(pe,oE),e(oE,b5e),e(b5e,oMr),e(oE,rMr),e(oE,uU),e(uU,tMr),e(oE,aMr),e(pe,nMr),e(pe,rE),e(rE,v5e),e(v5e,sMr),e(rE,lMr),e(rE,_U),e(_U,iMr),e(rE,dMr),e(pe,cMr),e(pe,tE),e(tE,F5e),e(F5e,fMr),e(tE,mMr),e(tE,bU),e(bU,gMr),e(tE,hMr),e(pe,pMr),e(pe,aE),e(aE,T5e),e(T5e,uMr),e(aE,_Mr),e(aE,vU),e(vU,bMr),e(aE,vMr),e(pe,FMr),e(pe,nE),e(nE,M5e),e(M5e,TMr),e(nE,MMr),e(nE,FU),e(FU,EMr),e(nE,CMr),e(pe,wMr),e(pe,sE),e(sE,E5e),e(E5e,AMr),e(sE,yMr),e(sE,TU),e(TU,LMr),e(sE,xMr),e(pe,$Mr),e(pe,lE),e(lE,C5e),e(C5e,kMr),e(lE,SMr),e(lE,MU),e(MU,RMr),e(lE,PMr),e(pe,BMr),e(pe,iE),e(iE,w5e),e(w5e,IMr),e(iE,qMr),e(iE,EU),e(EU,NMr),e(iE,jMr),e(pe,DMr),e(pe,dE),e(dE,A5e),e(A5e,GMr),e(dE,OMr),e(dE,CU),e(CU,VMr),e(dE,XMr),e(pe,zMr),e(pe,cE),e(cE,y5e),e(y5e,WMr),e(cE,QMr),e(cE,wU),e(wU,HMr),e(cE,UMr),e(pe,JMr),e(pe,fE),e(fE,L5e),e(L5e,YMr),e(fE,KMr),e(fE,AU),e(AU,ZMr),e(fE,eEr),e(pe,oEr),e(pe,mE),e(mE,x5e),e(x5e,rEr),e(mE,tEr),e(mE,yU),e(yU,aEr),e(mE,nEr),e(pe,sEr),e(pe,gE),e(gE,$5e),e($5e,lEr),e(gE,iEr),e(gE,LU),e(LU,dEr),e(gE,cEr),e(pe,fEr),e(pe,hE),e(hE,k5e),e(k5e,mEr),e(hE,gEr),e(hE,xU),e(xU,hEr),e(hE,pEr),e(pe,uEr),e(pe,pE),e(pE,S5e),e(S5e,_Er),e(pE,bEr),e(pE,$U),e($U,vEr),e(pE,FEr),e(pe,TEr),e(pe,uE),e(uE,R5e),e(R5e,MEr),e(uE,EEr),e(uE,kU),e(kU,CEr),e(uE,wEr),e(Sr,AEr),M(_E,Sr,null),b(f,Mje,_),b(f,hc,_),e(hc,bE),e(bE,P5e),M(H8,P5e,null),e(hc,yEr),e(hc,B5e),e(B5e,LEr),b(f,Eje,_),b(f,nr,_),M(U8,nr,null),e(nr,xEr),e(nr,pc),e(pc,$Er),e(pc,SU),e(SU,kEr),e(pc,SEr),e(pc,RU),e(RU,REr),e(pc,PEr),e(nr,BEr),e(nr,J8),e(J8,IEr),e(J8,I5e),e(I5e,qEr),e(J8,NEr),e(nr,jEr),e(nr,Bt),M(Y8,Bt,null),e(Bt,DEr),e(Bt,q5e),e(q5e,GEr),e(Bt,OEr),e(Bt,uc),e(uc,VEr),e(uc,N5e),e(N5e,XEr),e(uc,zEr),e(uc,PU),e(PU,WEr),e(uc,QEr),e(Bt,HEr),M(vE,Bt,null),e(nr,UEr),e(nr,Rr),M(K8,Rr,null),e(Rr,JEr),e(Rr,j5e),e(j5e,YEr),e(Rr,KEr),e(Rr,ln),e(ln,ZEr),e(ln,D5e),e(D5e,eCr),e(ln,oCr),e(ln,G5e),e(G5e,rCr),e(ln,tCr),e(ln,O5e),e(O5e,aCr),e(ln,nCr),e(Rr,sCr),e(Rr,Z8),e(Z8,FE),e(FE,V5e),e(V5e,lCr),e(FE,iCr),e(FE,BU),e(BU,dCr),e(FE,cCr),e(Z8,fCr),e(Z8,TE),e(TE,X5e),e(X5e,mCr),e(TE,gCr),e(TE,IU),e(IU,hCr),e(TE,pCr),e(Rr,uCr),M(ME,Rr,null),b(f,Cje,_),b(f,_c,_),e(_c,EE),e(EE,z5e),M(e9,z5e,null),e(_c,_Cr),e(_c,W5e),e(W5e,bCr),b(f,wje,_),b(f,sr,_),M(o9,sr,null),e(sr,vCr),e(sr,bc),e(bc,FCr),e(bc,qU),e(qU,TCr),e(bc,MCr),e(bc,NU),e(NU,ECr),e(bc,CCr),e(sr,wCr),e(sr,r9),e(r9,ACr),e(r9,Q5e),e(Q5e,yCr),e(r9,LCr),e(sr,xCr),e(sr,It),M(t9,It,null),e(It,$Cr),e(It,H5e),e(H5e,kCr),e(It,SCr),e(It,vc),e(vc,RCr),e(vc,U5e),e(U5e,PCr),e(vc,BCr),e(vc,jU),e(jU,ICr),e(vc,qCr),e(It,NCr),M(CE,It,null),e(sr,jCr),e(sr,Pr),M(a9,Pr,null),e(Pr,DCr),e(Pr,J5e),e(J5e,GCr),e(Pr,OCr),e(Pr,dn),e(dn,VCr),e(dn,Y5e),e(Y5e,XCr),e(dn,zCr),e(dn,K5e),e(K5e,WCr),e(dn,QCr),e(dn,Z5e),e(Z5e,HCr),e(dn,UCr),e(Pr,JCr),e(Pr,eFe),e(eFe,wE),e(wE,oFe),e(oFe,YCr),e(wE,KCr),e(wE,DU),e(DU,ZCr),e(wE,e3r),e(Pr,o3r),M(AE,Pr,null),b(f,Aje,_),b(f,Fc,_),e(Fc,yE),e(yE,rFe),M(n9,rFe,null),e(Fc,r3r),e(Fc,tFe),e(tFe,t3r),b(f,yje,_),b(f,lr,_),M(s9,lr,null),e(lr,a3r),e(lr,Tc),e(Tc,n3r),e(Tc,GU),e(GU,s3r),e(Tc,l3r),e(Tc,OU),e(OU,i3r),e(Tc,d3r),e(lr,c3r),e(lr,l9),e(l9,f3r),e(l9,aFe),e(aFe,m3r),e(l9,g3r),e(lr,h3r),e(lr,qt),M(i9,qt,null),e(qt,p3r),e(qt,nFe),e(nFe,u3r),e(qt,_3r),e(qt,Mc),e(Mc,b3r),e(Mc,sFe),e(sFe,v3r),e(Mc,F3r),e(Mc,VU),e(VU,T3r),e(Mc,M3r),e(qt,E3r),M(LE,qt,null),e(lr,C3r),e(lr,Br),M(d9,Br,null),e(Br,w3r),e(Br,lFe),e(lFe,A3r),e(Br,y3r),e(Br,cn),e(cn,L3r),e(cn,iFe),e(iFe,x3r),e(cn,$3r),e(cn,dFe),e(dFe,k3r),e(cn,S3r),e(cn,cFe),e(cFe,R3r),e(cn,P3r),e(Br,B3r),e(Br,de),e(de,xE),e(xE,fFe),e(fFe,I3r),e(xE,q3r),e(xE,XU),e(XU,N3r),e(xE,j3r),e(de,D3r),e(de,$E),e($E,mFe),e(mFe,G3r),e($E,O3r),e($E,zU),e(zU,V3r),e($E,X3r),e(de,z3r),e(de,kE),e(kE,gFe),e(gFe,W3r),e(kE,Q3r),e(kE,WU),e(WU,H3r),e(kE,U3r),e(de,J3r),e(de,SE),e(SE,hFe),e(hFe,Y3r),e(SE,K3r),e(SE,QU),e(QU,Z3r),e(SE,ewr),e(de,owr),e(de,RE),e(RE,pFe),e(pFe,rwr),e(RE,twr),e(RE,HU),e(HU,awr),e(RE,nwr),e(de,swr),e(de,PE),e(PE,uFe),e(uFe,lwr),e(PE,iwr),e(PE,UU),e(UU,dwr),e(PE,cwr),e(de,fwr),e(de,BE),e(BE,_Fe),e(_Fe,mwr),e(BE,gwr),e(BE,JU),e(JU,hwr),e(BE,pwr),e(de,uwr),e(de,IE),e(IE,bFe),e(bFe,_wr),e(IE,bwr),e(IE,YU),e(YU,vwr),e(IE,Fwr),e(de,Twr),e(de,qE),e(qE,vFe),e(vFe,Mwr),e(qE,Ewr),e(qE,KU),e(KU,Cwr),e(qE,wwr),e(de,Awr),e(de,NE),e(NE,FFe),e(FFe,ywr),e(NE,Lwr),e(NE,ZU),e(ZU,xwr),e(NE,$wr),e(de,kwr),e(de,jE),e(jE,TFe),e(TFe,Swr),e(jE,Rwr),e(jE,eJ),e(eJ,Pwr),e(jE,Bwr),e(de,Iwr),e(de,DE),e(DE,MFe),e(MFe,qwr),e(DE,Nwr),e(DE,oJ),e(oJ,jwr),e(DE,Dwr),e(de,Gwr),e(de,GE),e(GE,EFe),e(EFe,Owr),e(GE,Vwr),e(GE,rJ),e(rJ,Xwr),e(GE,zwr),e(de,Wwr),e(de,OE),e(OE,CFe),e(CFe,Qwr),e(OE,Hwr),e(OE,tJ),e(tJ,Uwr),e(OE,Jwr),e(de,Ywr),e(de,VE),e(VE,wFe),e(wFe,Kwr),e(VE,Zwr),e(VE,aJ),e(aJ,e0r),e(VE,o0r),e(de,r0r),e(de,XE),e(XE,AFe),e(AFe,t0r),e(XE,a0r),e(XE,nJ),e(nJ,n0r),e(XE,s0r),e(de,l0r),e(de,zE),e(zE,yFe),e(yFe,i0r),e(zE,d0r),e(zE,sJ),e(sJ,c0r),e(zE,f0r),e(de,m0r),e(de,WE),e(WE,LFe),e(LFe,g0r),e(WE,h0r),e(WE,lJ),e(lJ,p0r),e(WE,u0r),e(de,_0r),e(de,QE),e(QE,xFe),e(xFe,b0r),e(QE,v0r),e(QE,iJ),e(iJ,F0r),e(QE,T0r),e(de,M0r),e(de,HE),e(HE,$Fe),e($Fe,E0r),e(HE,C0r),e(HE,dJ),e(dJ,w0r),e(HE,A0r),e(Br,y0r),M(UE,Br,null),b(f,Lje,_),b(f,Ec,_),e(Ec,JE),e(JE,kFe),M(c9,kFe,null),e(Ec,L0r),e(Ec,SFe),e(SFe,x0r),b(f,xje,_),b(f,ir,_),M(f9,ir,null),e(ir,$0r),e(ir,Cc),e(Cc,k0r),e(Cc,cJ),e(cJ,S0r),e(Cc,R0r),e(Cc,fJ),e(fJ,P0r),e(Cc,B0r),e(ir,I0r),e(ir,m9),e(m9,q0r),e(m9,RFe),e(RFe,N0r),e(m9,j0r),e(ir,D0r),e(ir,Nt),M(g9,Nt,null),e(Nt,G0r),e(Nt,PFe),e(PFe,O0r),e(Nt,V0r),e(Nt,wc),e(wc,X0r),e(wc,BFe),e(BFe,z0r),e(wc,W0r),e(wc,mJ),e(mJ,Q0r),e(wc,H0r),e(Nt,U0r),M(YE,Nt,null),e(ir,J0r),e(ir,Ir),M(h9,Ir,null),e(Ir,Y0r),e(Ir,IFe),e(IFe,K0r),e(Ir,Z0r),e(Ir,fn),e(fn,e6r),e(fn,qFe),e(qFe,o6r),e(fn,r6r),e(fn,NFe),e(NFe,t6r),e(fn,a6r),e(fn,jFe),e(jFe,n6r),e(fn,s6r),e(Ir,l6r),e(Ir,ce),e(ce,KE),e(KE,DFe),e(DFe,i6r),e(KE,d6r),e(KE,gJ),e(gJ,c6r),e(KE,f6r),e(ce,m6r),e(ce,ZE),e(ZE,GFe),e(GFe,g6r),e(ZE,h6r),e(ZE,hJ),e(hJ,p6r),e(ZE,u6r),e(ce,_6r),e(ce,eC),e(eC,OFe),e(OFe,b6r),e(eC,v6r),e(eC,pJ),e(pJ,F6r),e(eC,T6r),e(ce,M6r),e(ce,oC),e(oC,VFe),e(VFe,E6r),e(oC,C6r),e(oC,uJ),e(uJ,w6r),e(oC,A6r),e(ce,y6r),e(ce,rC),e(rC,XFe),e(XFe,L6r),e(rC,x6r),e(rC,_J),e(_J,$6r),e(rC,k6r),e(ce,S6r),e(ce,tC),e(tC,zFe),e(zFe,R6r),e(tC,P6r),e(tC,bJ),e(bJ,B6r),e(tC,I6r),e(ce,q6r),e(ce,aC),e(aC,WFe),e(WFe,N6r),e(aC,j6r),e(aC,vJ),e(vJ,D6r),e(aC,G6r),e(ce,O6r),e(ce,nC),e(nC,QFe),e(QFe,V6r),e(nC,X6r),e(nC,FJ),e(FJ,z6r),e(nC,W6r),e(ce,Q6r),e(ce,sC),e(sC,HFe),e(HFe,H6r),e(sC,U6r),e(sC,TJ),e(TJ,J6r),e(sC,Y6r),e(ce,K6r),e(ce,lC),e(lC,UFe),e(UFe,Z6r),e(lC,eAr),e(lC,MJ),e(MJ,oAr),e(lC,rAr),e(ce,tAr),e(ce,iC),e(iC,JFe),e(JFe,aAr),e(iC,nAr),e(iC,EJ),e(EJ,sAr),e(iC,lAr),e(ce,iAr),e(ce,dC),e(dC,YFe),e(YFe,dAr),e(dC,cAr),e(dC,CJ),e(CJ,fAr),e(dC,mAr),e(ce,gAr),e(ce,cC),e(cC,KFe),e(KFe,hAr),e(cC,pAr),e(cC,wJ),e(wJ,uAr),e(cC,_Ar),e(ce,bAr),e(ce,fC),e(fC,ZFe),e(ZFe,vAr),e(fC,FAr),e(fC,AJ),e(AJ,TAr),e(fC,MAr),e(ce,EAr),e(ce,mC),e(mC,eTe),e(eTe,CAr),e(mC,wAr),e(mC,yJ),e(yJ,AAr),e(mC,yAr),e(ce,LAr),e(ce,gC),e(gC,oTe),e(oTe,xAr),e(gC,$Ar),e(gC,LJ),e(LJ,kAr),e(gC,SAr),e(ce,RAr),e(ce,hC),e(hC,rTe),e(rTe,PAr),e(hC,BAr),e(hC,xJ),e(xJ,IAr),e(hC,qAr),e(ce,NAr),e(ce,pC),e(pC,tTe),e(tTe,jAr),e(pC,DAr),e(pC,$J),e($J,GAr),e(pC,OAr),e(ce,VAr),e(ce,uC),e(uC,aTe),e(aTe,XAr),e(uC,zAr),e(uC,kJ),e(kJ,WAr),e(uC,QAr),e(ce,HAr),e(ce,_C),e(_C,nTe),e(nTe,UAr),e(_C,JAr),e(_C,SJ),e(SJ,YAr),e(_C,KAr),e(Ir,ZAr),M(bC,Ir,null),b(f,$je,_),b(f,Ac,_),e(Ac,vC),e(vC,sTe),M(p9,sTe,null),e(Ac,eyr),e(Ac,lTe),e(lTe,oyr),b(f,kje,_),b(f,dr,_),M(u9,dr,null),e(dr,ryr),e(dr,yc),e(yc,tyr),e(yc,RJ),e(RJ,ayr),e(yc,nyr),e(yc,PJ),e(PJ,syr),e(yc,lyr),e(dr,iyr),e(dr,_9),e(_9,dyr),e(_9,iTe),e(iTe,cyr),e(_9,fyr),e(dr,myr),e(dr,jt),M(b9,jt,null),e(jt,gyr),e(jt,dTe),e(dTe,hyr),e(jt,pyr),e(jt,Lc),e(Lc,uyr),e(Lc,cTe),e(cTe,_yr),e(Lc,byr),e(Lc,BJ),e(BJ,vyr),e(Lc,Fyr),e(jt,Tyr),M(FC,jt,null),e(dr,Myr),e(dr,qr),M(v9,qr,null),e(qr,Eyr),e(qr,fTe),e(fTe,Cyr),e(qr,wyr),e(qr,mn),e(mn,Ayr),e(mn,mTe),e(mTe,yyr),e(mn,Lyr),e(mn,gTe),e(gTe,xyr),e(mn,$yr),e(mn,hTe),e(hTe,kyr),e(mn,Syr),e(qr,Ryr),e(qr,pTe),e(pTe,TC),e(TC,uTe),e(uTe,Pyr),e(TC,Byr),e(TC,IJ),e(IJ,Iyr),e(TC,qyr),e(qr,Nyr),M(MC,qr,null),b(f,Sje,_),b(f,xc,_),e(xc,EC),e(EC,_Te),M(F9,_Te,null),e(xc,jyr),e(xc,bTe),e(bTe,Dyr),b(f,Rje,_),b(f,cr,_),M(T9,cr,null),e(cr,Gyr),e(cr,$c),e($c,Oyr),e($c,qJ),e(qJ,Vyr),e($c,Xyr),e($c,NJ),e(NJ,zyr),e($c,Wyr),e(cr,Qyr),e(cr,M9),e(M9,Hyr),e(M9,vTe),e(vTe,Uyr),e(M9,Jyr),e(cr,Yyr),e(cr,Dt),M(E9,Dt,null),e(Dt,Kyr),e(Dt,FTe),e(FTe,Zyr),e(Dt,eLr),e(Dt,kc),e(kc,oLr),e(kc,TTe),e(TTe,rLr),e(kc,tLr),e(kc,jJ),e(jJ,aLr),e(kc,nLr),e(Dt,sLr),M(CC,Dt,null),e(cr,lLr),e(cr,Nr),M(C9,Nr,null),e(Nr,iLr),e(Nr,MTe),e(MTe,dLr),e(Nr,cLr),e(Nr,gn),e(gn,fLr),e(gn,ETe),e(ETe,mLr),e(gn,gLr),e(gn,CTe),e(CTe,hLr),e(gn,pLr),e(gn,wTe),e(wTe,uLr),e(gn,_Lr),e(Nr,bLr),e(Nr,ATe),e(ATe,wC),e(wC,yTe),e(yTe,vLr),e(wC,FLr),e(wC,DJ),e(DJ,TLr),e(wC,MLr),e(Nr,ELr),M(AC,Nr,null),b(f,Pje,_),b(f,Sc,_),e(Sc,yC),e(yC,LTe),M(w9,LTe,null),e(Sc,CLr),e(Sc,xTe),e(xTe,wLr),b(f,Bje,_),b(f,fr,_),M(A9,fr,null),e(fr,ALr),e(fr,Rc),e(Rc,yLr),e(Rc,GJ),e(GJ,LLr),e(Rc,xLr),e(Rc,OJ),e(OJ,$Lr),e(Rc,kLr),e(fr,SLr),e(fr,y9),e(y9,RLr),e(y9,$Te),e($Te,PLr),e(y9,BLr),e(fr,ILr),e(fr,Gt),M(L9,Gt,null),e(Gt,qLr),e(Gt,kTe),e(kTe,NLr),e(Gt,jLr),e(Gt,Pc),e(Pc,DLr),e(Pc,STe),e(STe,GLr),e(Pc,OLr),e(Pc,VJ),e(VJ,VLr),e(Pc,XLr),e(Gt,zLr),M(LC,Gt,null),e(fr,WLr),e(fr,jr),M(x9,jr,null),e(jr,QLr),e(jr,RTe),e(RTe,HLr),e(jr,ULr),e(jr,hn),e(hn,JLr),e(hn,PTe),e(PTe,YLr),e(hn,KLr),e(hn,BTe),e(BTe,ZLr),e(hn,e8r),e(hn,ITe),e(ITe,o8r),e(hn,r8r),e(jr,t8r),e(jr,te),e(te,xC),e(xC,qTe),e(qTe,a8r),e(xC,n8r),e(xC,XJ),e(XJ,s8r),e(xC,l8r),e(te,i8r),e(te,$C),e($C,NTe),e(NTe,d8r),e($C,c8r),e($C,zJ),e(zJ,f8r),e($C,m8r),e(te,g8r),e(te,kC),e(kC,jTe),e(jTe,h8r),e(kC,p8r),e(kC,WJ),e(WJ,u8r),e(kC,_8r),e(te,b8r),e(te,SC),e(SC,DTe),e(DTe,v8r),e(SC,F8r),e(SC,QJ),e(QJ,T8r),e(SC,M8r),e(te,E8r),e(te,RC),e(RC,GTe),e(GTe,C8r),e(RC,w8r),e(RC,HJ),e(HJ,A8r),e(RC,y8r),e(te,L8r),e(te,PC),e(PC,OTe),e(OTe,x8r),e(PC,$8r),e(PC,UJ),e(UJ,k8r),e(PC,S8r),e(te,R8r),e(te,BC),e(BC,VTe),e(VTe,P8r),e(BC,B8r),e(BC,JJ),e(JJ,I8r),e(BC,q8r),e(te,N8r),e(te,IC),e(IC,XTe),e(XTe,j8r),e(IC,D8r),e(IC,YJ),e(YJ,G8r),e(IC,O8r),e(te,V8r),e(te,qC),e(qC,zTe),e(zTe,X8r),e(qC,z8r),e(qC,KJ),e(KJ,W8r),e(qC,Q8r),e(te,H8r),e(te,NC),e(NC,WTe),e(WTe,U8r),e(NC,J8r),e(NC,ZJ),e(ZJ,Y8r),e(NC,K8r),e(te,Z8r),e(te,jC),e(jC,QTe),e(QTe,e9r),e(jC,o9r),e(jC,eY),e(eY,r9r),e(jC,t9r),e(te,a9r),e(te,DC),e(DC,HTe),e(HTe,n9r),e(DC,s9r),e(DC,oY),e(oY,l9r),e(DC,i9r),e(te,d9r),e(te,GC),e(GC,UTe),e(UTe,c9r),e(GC,f9r),e(GC,rY),e(rY,m9r),e(GC,g9r),e(te,h9r),e(te,OC),e(OC,JTe),e(JTe,p9r),e(OC,u9r),e(OC,tY),e(tY,_9r),e(OC,b9r),e(te,v9r),e(te,VC),e(VC,YTe),e(YTe,F9r),e(VC,T9r),e(VC,aY),e(aY,M9r),e(VC,E9r),e(te,C9r),e(te,XC),e(XC,KTe),e(KTe,w9r),e(XC,A9r),e(XC,nY),e(nY,y9r),e(XC,L9r),e(te,x9r),e(te,zC),e(zC,ZTe),e(ZTe,$9r),e(zC,k9r),e(zC,sY),e(sY,S9r),e(zC,R9r),e(te,P9r),e(te,WC),e(WC,e7e),e(e7e,B9r),e(WC,I9r),e(WC,lY),e(lY,q9r),e(WC,N9r),e(te,j9r),e(te,QC),e(QC,o7e),e(o7e,D9r),e(QC,G9r),e(QC,iY),e(iY,O9r),e(QC,V9r),e(te,X9r),e(te,HC),e(HC,r7e),e(r7e,z9r),e(HC,W9r),e(HC,dY),e(dY,Q9r),e(HC,H9r),e(te,U9r),e(te,UC),e(UC,t7e),e(t7e,J9r),e(UC,Y9r),e(UC,cY),e(cY,K9r),e(UC,Z9r),e(te,exr),e(te,JC),e(JC,a7e),e(a7e,oxr),e(JC,rxr),e(JC,fY),e(fY,txr),e(JC,axr),e(te,nxr),e(te,YC),e(YC,n7e),e(n7e,sxr),e(YC,lxr),e(YC,mY),e(mY,ixr),e(YC,dxr),e(te,cxr),e(te,KC),e(KC,s7e),e(s7e,fxr),e(KC,mxr),e(KC,gY),e(gY,gxr),e(KC,hxr),e(te,pxr),e(te,ZC),e(ZC,l7e),e(l7e,uxr),e(ZC,_xr),e(ZC,hY),e(hY,bxr),e(ZC,vxr),e(jr,Fxr),M(e3,jr,null),b(f,Ije,_),b(f,Bc,_),e(Bc,o3),e(o3,i7e),M($9,i7e,null),e(Bc,Txr),e(Bc,d7e),e(d7e,Mxr),b(f,qje,_),b(f,mr,_),M(k9,mr,null),e(mr,Exr),e(mr,Ic),e(Ic,Cxr),e(Ic,pY),e(pY,wxr),e(Ic,Axr),e(Ic,uY),e(uY,yxr),e(Ic,Lxr),e(mr,xxr),e(mr,S9),e(S9,$xr),e(S9,c7e),e(c7e,kxr),e(S9,Sxr),e(mr,Rxr),e(mr,Ot),M(R9,Ot,null),e(Ot,Pxr),e(Ot,f7e),e(f7e,Bxr),e(Ot,Ixr),e(Ot,qc),e(qc,qxr),e(qc,m7e),e(m7e,Nxr),e(qc,jxr),e(qc,_Y),e(_Y,Dxr),e(qc,Gxr),e(Ot,Oxr),M(r3,Ot,null),e(mr,Vxr),e(mr,Dr),M(P9,Dr,null),e(Dr,Xxr),e(Dr,g7e),e(g7e,zxr),e(Dr,Wxr),e(Dr,pn),e(pn,Qxr),e(pn,h7e),e(h7e,Hxr),e(pn,Uxr),e(pn,p7e),e(p7e,Jxr),e(pn,Yxr),e(pn,u7e),e(u7e,Kxr),e(pn,Zxr),e(Dr,e$r),e(Dr,Re),e(Re,t3),e(t3,_7e),e(_7e,o$r),e(t3,r$r),e(t3,bY),e(bY,t$r),e(t3,a$r),e(Re,n$r),e(Re,a3),e(a3,b7e),e(b7e,s$r),e(a3,l$r),e(a3,vY),e(vY,i$r),e(a3,d$r),e(Re,c$r),e(Re,n3),e(n3,v7e),e(v7e,f$r),e(n3,m$r),e(n3,FY),e(FY,g$r),e(n3,h$r),e(Re,p$r),e(Re,s3),e(s3,F7e),e(F7e,u$r),e(s3,_$r),e(s3,TY),e(TY,b$r),e(s3,v$r),e(Re,F$r),e(Re,l3),e(l3,T7e),e(T7e,T$r),e(l3,M$r),e(l3,MY),e(MY,E$r),e(l3,C$r),e(Re,w$r),e(Re,i3),e(i3,M7e),e(M7e,A$r),e(i3,y$r),e(i3,EY),e(EY,L$r),e(i3,x$r),e(Re,$$r),e(Re,d3),e(d3,E7e),e(E7e,k$r),e(d3,S$r),e(d3,CY),e(CY,R$r),e(d3,P$r),e(Re,B$r),e(Re,c3),e(c3,C7e),e(C7e,I$r),e(c3,q$r),e(c3,wY),e(wY,N$r),e(c3,j$r),e(Re,D$r),e(Re,f3),e(f3,w7e),e(w7e,G$r),e(f3,O$r),e(f3,AY),e(AY,V$r),e(f3,X$r),e(Dr,z$r),M(m3,Dr,null),b(f,Nje,_),b(f,Nc,_),e(Nc,g3),e(g3,A7e),M(B9,A7e,null),e(Nc,W$r),e(Nc,y7e),e(y7e,Q$r),b(f,jje,_),b(f,gr,_),M(I9,gr,null),e(gr,H$r),e(gr,jc),e(jc,U$r),e(jc,yY),e(yY,J$r),e(jc,Y$r),e(jc,LY),e(LY,K$r),e(jc,Z$r),e(gr,ekr),e(gr,q9),e(q9,okr),e(q9,L7e),e(L7e,rkr),e(q9,tkr),e(gr,akr),e(gr,Vt),M(N9,Vt,null),e(Vt,nkr),e(Vt,x7e),e(x7e,skr),e(Vt,lkr),e(Vt,Dc),e(Dc,ikr),e(Dc,$7e),e($7e,dkr),e(Dc,ckr),e(Dc,xY),e(xY,fkr),e(Dc,mkr),e(Vt,gkr),M(h3,Vt,null),e(gr,hkr),e(gr,Gr),M(j9,Gr,null),e(Gr,pkr),e(Gr,k7e),e(k7e,ukr),e(Gr,_kr),e(Gr,un),e(un,bkr),e(un,S7e),e(S7e,vkr),e(un,Fkr),e(un,R7e),e(R7e,Tkr),e(un,Mkr),e(un,P7e),e(P7e,Ekr),e(un,Ckr),e(Gr,wkr),e(Gr,Ee),e(Ee,p3),e(p3,B7e),e(B7e,Akr),e(p3,ykr),e(p3,$Y),e($Y,Lkr),e(p3,xkr),e(Ee,$kr),e(Ee,u3),e(u3,I7e),e(I7e,kkr),e(u3,Skr),e(u3,kY),e(kY,Rkr),e(u3,Pkr),e(Ee,Bkr),e(Ee,_3),e(_3,q7e),e(q7e,Ikr),e(_3,qkr),e(_3,SY),e(SY,Nkr),e(_3,jkr),e(Ee,Dkr),e(Ee,b3),e(b3,N7e),e(N7e,Gkr),e(b3,Okr),e(b3,RY),e(RY,Vkr),e(b3,Xkr),e(Ee,zkr),e(Ee,v3),e(v3,j7e),e(j7e,Wkr),e(v3,Qkr),e(v3,PY),e(PY,Hkr),e(v3,Ukr),e(Ee,Jkr),e(Ee,F3),e(F3,D7e),e(D7e,Ykr),e(F3,Kkr),e(F3,BY),e(BY,Zkr),e(F3,eSr),e(Ee,oSr),e(Ee,T3),e(T3,G7e),e(G7e,rSr),e(T3,tSr),e(T3,IY),e(IY,aSr),e(T3,nSr),e(Ee,sSr),e(Ee,M3),e(M3,O7e),e(O7e,lSr),e(M3,iSr),e(M3,qY),e(qY,dSr),e(M3,cSr),e(Ee,fSr),e(Ee,E3),e(E3,V7e),e(V7e,mSr),e(E3,gSr),e(E3,NY),e(NY,hSr),e(E3,pSr),e(Ee,uSr),e(Ee,C3),e(C3,X7e),e(X7e,_Sr),e(C3,bSr),e(C3,jY),e(jY,vSr),e(C3,FSr),e(Ee,TSr),e(Ee,w3),e(w3,z7e),e(z7e,MSr),e(w3,ESr),e(w3,DY),e(DY,CSr),e(w3,wSr),e(Ee,ASr),e(Ee,A3),e(A3,W7e),e(W7e,ySr),e(A3,LSr),e(A3,GY),e(GY,xSr),e(A3,$Sr),e(Gr,kSr),M(y3,Gr,null),b(f,Dje,_),b(f,Gc,_),e(Gc,L3),e(L3,Q7e),M(D9,Q7e,null),e(Gc,SSr),e(Gc,H7e),e(H7e,RSr),b(f,Gje,_),b(f,hr,_),M(G9,hr,null),e(hr,PSr),e(hr,Oc),e(Oc,BSr),e(Oc,OY),e(OY,ISr),e(Oc,qSr),e(Oc,VY),e(VY,NSr),e(Oc,jSr),e(hr,DSr),e(hr,O9),e(O9,GSr),e(O9,U7e),e(U7e,OSr),e(O9,VSr),e(hr,XSr),e(hr,Xt),M(V9,Xt,null),e(Xt,zSr),e(Xt,J7e),e(J7e,WSr),e(Xt,QSr),e(Xt,Vc),e(Vc,HSr),e(Vc,Y7e),e(Y7e,USr),e(Vc,JSr),e(Vc,XY),e(XY,YSr),e(Vc,KSr),e(Xt,ZSr),M(x3,Xt,null),e(hr,eRr),e(hr,Or),M(X9,Or,null),e(Or,oRr),e(Or,K7e),e(K7e,rRr),e(Or,tRr),e(Or,_n),e(_n,aRr),e(_n,Z7e),e(Z7e,nRr),e(_n,sRr),e(_n,eMe),e(eMe,lRr),e(_n,iRr),e(_n,oMe),e(oMe,dRr),e(_n,cRr),e(Or,fRr),e(Or,Le),e(Le,$3),e($3,rMe),e(rMe,mRr),e($3,gRr),e($3,zY),e(zY,hRr),e($3,pRr),e(Le,uRr),e(Le,k3),e(k3,tMe),e(tMe,_Rr),e(k3,bRr),e(k3,WY),e(WY,vRr),e(k3,FRr),e(Le,TRr),e(Le,S3),e(S3,aMe),e(aMe,MRr),e(S3,ERr),e(S3,QY),e(QY,CRr),e(S3,wRr),e(Le,ARr),e(Le,R3),e(R3,nMe),e(nMe,yRr),e(R3,LRr),e(R3,HY),e(HY,xRr),e(R3,$Rr),e(Le,kRr),e(Le,P3),e(P3,sMe),e(sMe,SRr),e(P3,RRr),e(P3,UY),e(UY,PRr),e(P3,BRr),e(Le,IRr),e(Le,B3),e(B3,lMe),e(lMe,qRr),e(B3,NRr),e(B3,JY),e(JY,jRr),e(B3,DRr),e(Le,GRr),e(Le,I3),e(I3,iMe),e(iMe,ORr),e(I3,VRr),e(I3,YY),e(YY,XRr),e(I3,zRr),e(Le,WRr),e(Le,q3),e(q3,dMe),e(dMe,QRr),e(q3,HRr),e(q3,KY),e(KY,URr),e(q3,JRr),e(Le,YRr),e(Le,N3),e(N3,cMe),e(cMe,KRr),e(N3,ZRr),e(N3,ZY),e(ZY,ePr),e(N3,oPr),e(Le,rPr),e(Le,j3),e(j3,fMe),e(fMe,tPr),e(j3,aPr),e(j3,eK),e(eK,nPr),e(j3,sPr),e(Or,lPr),M(D3,Or,null),b(f,Oje,_),b(f,Xc,_),e(Xc,G3),e(G3,mMe),M(z9,mMe,null),e(Xc,iPr),e(Xc,gMe),e(gMe,dPr),b(f,Vje,_),b(f,pr,_),M(W9,pr,null),e(pr,cPr),e(pr,zc),e(zc,fPr),e(zc,oK),e(oK,mPr),e(zc,gPr),e(zc,rK),e(rK,hPr),e(zc,pPr),e(pr,uPr),e(pr,Q9),e(Q9,_Pr),e(Q9,hMe),e(hMe,bPr),e(Q9,vPr),e(pr,FPr),e(pr,zt),M(H9,zt,null),e(zt,TPr),e(zt,pMe),e(pMe,MPr),e(zt,EPr),e(zt,Wc),e(Wc,CPr),e(Wc,uMe),e(uMe,wPr),e(Wc,APr),e(Wc,tK),e(tK,yPr),e(Wc,LPr),e(zt,xPr),M(O3,zt,null),e(pr,$Pr),e(pr,Vr),M(U9,Vr,null),e(Vr,kPr),e(Vr,_Me),e(_Me,SPr),e(Vr,RPr),e(Vr,bn),e(bn,PPr),e(bn,bMe),e(bMe,BPr),e(bn,IPr),e(bn,vMe),e(vMe,qPr),e(bn,NPr),e(bn,FMe),e(FMe,jPr),e(bn,DPr),e(Vr,GPr),e(Vr,Pe),e(Pe,V3),e(V3,TMe),e(TMe,OPr),e(V3,VPr),e(V3,aK),e(aK,XPr),e(V3,zPr),e(Pe,WPr),e(Pe,X3),e(X3,MMe),e(MMe,QPr),e(X3,HPr),e(X3,nK),e(nK,UPr),e(X3,JPr),e(Pe,YPr),e(Pe,z3),e(z3,EMe),e(EMe,KPr),e(z3,ZPr),e(z3,sK),e(sK,eBr),e(z3,oBr),e(Pe,rBr),e(Pe,W3),e(W3,CMe),e(CMe,tBr),e(W3,aBr),e(W3,lK),e(lK,nBr),e(W3,sBr),e(Pe,lBr),e(Pe,Q3),e(Q3,wMe),e(wMe,iBr),e(Q3,dBr),e(Q3,iK),e(iK,cBr),e(Q3,fBr),e(Pe,mBr),e(Pe,H3),e(H3,AMe),e(AMe,gBr),e(H3,hBr),e(H3,dK),e(dK,pBr),e(H3,uBr),e(Pe,_Br),e(Pe,U3),e(U3,yMe),e(yMe,bBr),e(U3,vBr),e(U3,cK),e(cK,FBr),e(U3,TBr),e(Pe,MBr),e(Pe,J3),e(J3,LMe),e(LMe,EBr),e(J3,CBr),e(J3,fK),e(fK,wBr),e(J3,ABr),e(Pe,yBr),e(Pe,Y3),e(Y3,xMe),e(xMe,LBr),e(Y3,xBr),e(Y3,mK),e(mK,$Br),e(Y3,kBr),e(Vr,SBr),M(K3,Vr,null),b(f,Xje,_),b(f,Qc,_),e(Qc,Z3),e(Z3,$Me),M(J9,$Me,null),e(Qc,RBr),e(Qc,kMe),e(kMe,PBr),b(f,zje,_),b(f,ur,_),M(Y9,ur,null),e(ur,BBr),e(ur,Hc),e(Hc,IBr),e(Hc,gK),e(gK,qBr),e(Hc,NBr),e(Hc,hK),e(hK,jBr),e(Hc,DBr),e(ur,GBr),e(ur,K9),e(K9,OBr),e(K9,SMe),e(SMe,VBr),e(K9,XBr),e(ur,zBr),e(ur,Wt),M(Z9,Wt,null),e(Wt,WBr),e(Wt,RMe),e(RMe,QBr),e(Wt,HBr),e(Wt,Uc),e(Uc,UBr),e(Uc,PMe),e(PMe,JBr),e(Uc,YBr),e(Uc,pK),e(pK,KBr),e(Uc,ZBr),e(Wt,eIr),M(ew,Wt,null),e(ur,oIr),e(ur,Xr),M(ex,Xr,null),e(Xr,rIr),e(Xr,BMe),e(BMe,tIr),e(Xr,aIr),e(Xr,vn),e(vn,nIr),e(vn,IMe),e(IMe,sIr),e(vn,lIr),e(vn,qMe),e(qMe,iIr),e(vn,dIr),e(vn,NMe),e(NMe,cIr),e(vn,fIr),e(Xr,mIr),e(Xr,xe),e(xe,ow),e(ow,jMe),e(jMe,gIr),e(ow,hIr),e(ow,uK),e(uK,pIr),e(ow,uIr),e(xe,_Ir),e(xe,rw),e(rw,DMe),e(DMe,bIr),e(rw,vIr),e(rw,_K),e(_K,FIr),e(rw,TIr),e(xe,MIr),e(xe,tw),e(tw,GMe),e(GMe,EIr),e(tw,CIr),e(tw,bK),e(bK,wIr),e(tw,AIr),e(xe,yIr),e(xe,aw),e(aw,OMe),e(OMe,LIr),e(aw,xIr),e(aw,vK),e(vK,$Ir),e(aw,kIr),e(xe,SIr),e(xe,nw),e(nw,VMe),e(VMe,RIr),e(nw,PIr),e(nw,FK),e(FK,BIr),e(nw,IIr),e(xe,qIr),e(xe,sw),e(sw,XMe),e(XMe,NIr),e(sw,jIr),e(sw,TK),e(TK,DIr),e(sw,GIr),e(xe,OIr),e(xe,lw),e(lw,zMe),e(zMe,VIr),e(lw,XIr),e(lw,MK),e(MK,zIr),e(lw,WIr),e(xe,QIr),e(xe,iw),e(iw,WMe),e(WMe,HIr),e(iw,UIr),e(iw,EK),e(EK,JIr),e(iw,YIr),e(xe,KIr),e(xe,dw),e(dw,QMe),e(QMe,ZIr),e(dw,eqr),e(dw,CK),e(CK,oqr),e(dw,rqr),e(xe,tqr),e(xe,cw),e(cw,HMe),e(HMe,aqr),e(cw,nqr),e(cw,wK),e(wK,sqr),e(cw,lqr),e(Xr,iqr),M(fw,Xr,null),b(f,Wje,_),b(f,Jc,_),e(Jc,mw),e(mw,UMe),M(ox,UMe,null),e(Jc,dqr),e(Jc,JMe),e(JMe,cqr),b(f,Qje,_),b(f,_r,_),M(rx,_r,null),e(_r,fqr),e(_r,Yc),e(Yc,mqr),e(Yc,AK),e(AK,gqr),e(Yc,hqr),e(Yc,yK),e(yK,pqr),e(Yc,uqr),e(_r,_qr),e(_r,tx),e(tx,bqr),e(tx,YMe),e(YMe,vqr),e(tx,Fqr),e(_r,Tqr),e(_r,Qt),M(ax,Qt,null),e(Qt,Mqr),e(Qt,KMe),e(KMe,Eqr),e(Qt,Cqr),e(Qt,Kc),e(Kc,wqr),e(Kc,ZMe),e(ZMe,Aqr),e(Kc,yqr),e(Kc,LK),e(LK,Lqr),e(Kc,xqr),e(Qt,$qr),M(gw,Qt,null),e(_r,kqr),e(_r,zr),M(nx,zr,null),e(zr,Sqr),e(zr,eEe),e(eEe,Rqr),e(zr,Pqr),e(zr,Fn),e(Fn,Bqr),e(Fn,oEe),e(oEe,Iqr),e(Fn,qqr),e(Fn,rEe),e(rEe,Nqr),e(Fn,jqr),e(Fn,tEe),e(tEe,Dqr),e(Fn,Gqr),e(zr,Oqr),e(zr,$e),e($e,hw),e(hw,aEe),e(aEe,Vqr),e(hw,Xqr),e(hw,xK),e(xK,zqr),e(hw,Wqr),e($e,Qqr),e($e,pw),e(pw,nEe),e(nEe,Hqr),e(pw,Uqr),e(pw,$K),e($K,Jqr),e(pw,Yqr),e($e,Kqr),e($e,uw),e(uw,sEe),e(sEe,Zqr),e(uw,eNr),e(uw,kK),e(kK,oNr),e(uw,rNr),e($e,tNr),e($e,_w),e(_w,lEe),e(lEe,aNr),e(_w,nNr),e(_w,SK),e(SK,sNr),e(_w,lNr),e($e,iNr),e($e,bw),e(bw,iEe),e(iEe,dNr),e(bw,cNr),e(bw,RK),e(RK,fNr),e(bw,mNr),e($e,gNr),e($e,vw),e(vw,dEe),e(dEe,hNr),e(vw,pNr),e(vw,PK),e(PK,uNr),e(vw,_Nr),e($e,bNr),e($e,Fw),e(Fw,cEe),e(cEe,vNr),e(Fw,FNr),e(Fw,BK),e(BK,TNr),e(Fw,MNr),e($e,ENr),e($e,Tw),e(Tw,fEe),e(fEe,CNr),e(Tw,wNr),e(Tw,IK),e(IK,ANr),e(Tw,yNr),e($e,LNr),e($e,Mw),e(Mw,mEe),e(mEe,xNr),e(Mw,$Nr),e(Mw,qK),e(qK,kNr),e(Mw,SNr),e($e,RNr),e($e,Ew),e(Ew,gEe),e(gEe,PNr),e(Ew,BNr),e(Ew,NK),e(NK,INr),e(Ew,qNr),e(zr,NNr),M(Cw,zr,null),b(f,Hje,_),b(f,Zc,_),e(Zc,ww),e(ww,hEe),M(sx,hEe,null),e(Zc,jNr),e(Zc,pEe),e(pEe,DNr),b(f,Uje,_),b(f,br,_),M(lx,br,null),e(br,GNr),e(br,ef),e(ef,ONr),e(ef,jK),e(jK,VNr),e(ef,XNr),e(ef,DK),e(DK,zNr),e(ef,WNr),e(br,QNr),e(br,ix),e(ix,HNr),e(ix,uEe),e(uEe,UNr),e(ix,JNr),e(br,YNr),e(br,Ht),M(dx,Ht,null),e(Ht,KNr),e(Ht,_Ee),e(_Ee,ZNr),e(Ht,ejr),e(Ht,of),e(of,ojr),e(of,bEe),e(bEe,rjr),e(of,tjr),e(of,GK),e(GK,ajr),e(of,njr),e(Ht,sjr),M(Aw,Ht,null),e(br,ljr),e(br,Wr),M(cx,Wr,null),e(Wr,ijr),e(Wr,vEe),e(vEe,djr),e(Wr,cjr),e(Wr,Tn),e(Tn,fjr),e(Tn,FEe),e(FEe,mjr),e(Tn,gjr),e(Tn,TEe),e(TEe,hjr),e(Tn,pjr),e(Tn,MEe),e(MEe,ujr),e(Tn,_jr),e(Wr,bjr),e(Wr,De),e(De,yw),e(yw,EEe),e(EEe,vjr),e(yw,Fjr),e(yw,OK),e(OK,Tjr),e(yw,Mjr),e(De,Ejr),e(De,Lw),e(Lw,CEe),e(CEe,Cjr),e(Lw,wjr),e(Lw,VK),e(VK,Ajr),e(Lw,yjr),e(De,Ljr),e(De,xw),e(xw,wEe),e(wEe,xjr),e(xw,$jr),e(xw,XK),e(XK,kjr),e(xw,Sjr),e(De,Rjr),e(De,$w),e($w,AEe),e(AEe,Pjr),e($w,Bjr),e($w,zK),e(zK,Ijr),e($w,qjr),e(De,Njr),e(De,kw),e(kw,yEe),e(yEe,jjr),e(kw,Djr),e(kw,WK),e(WK,Gjr),e(kw,Ojr),e(De,Vjr),e(De,Sw),e(Sw,LEe),e(LEe,Xjr),e(Sw,zjr),e(Sw,QK),e(QK,Wjr),e(Sw,Qjr),e(De,Hjr),e(De,Rw),e(Rw,xEe),e(xEe,Ujr),e(Rw,Jjr),e(Rw,HK),e(HK,Yjr),e(Rw,Kjr),e(De,Zjr),e(De,Pw),e(Pw,$Ee),e($Ee,eDr),e(Pw,oDr),e(Pw,UK),e(UK,rDr),e(Pw,tDr),e(Wr,aDr),M(Bw,Wr,null),b(f,Jje,_),b(f,rf,_),e(rf,Iw),e(Iw,kEe),M(fx,kEe,null),e(rf,nDr),e(rf,SEe),e(SEe,sDr),b(f,Yje,_),b(f,vr,_),M(mx,vr,null),e(vr,lDr),e(vr,tf),e(tf,iDr),e(tf,JK),e(JK,dDr),e(tf,cDr),e(tf,YK),e(YK,fDr),e(tf,mDr),e(vr,gDr),e(vr,gx),e(gx,hDr),e(gx,REe),e(REe,pDr),e(gx,uDr),e(vr,_Dr),e(vr,Ut),M(hx,Ut,null),e(Ut,bDr),e(Ut,PEe),e(PEe,vDr),e(Ut,FDr),e(Ut,af),e(af,TDr),e(af,BEe),e(BEe,MDr),e(af,EDr),e(af,KK),e(KK,CDr),e(af,wDr),e(Ut,ADr),M(qw,Ut,null),e(vr,yDr),e(vr,Qr),M(px,Qr,null),e(Qr,LDr),e(Qr,IEe),e(IEe,xDr),e(Qr,$Dr),e(Qr,Mn),e(Mn,kDr),e(Mn,qEe),e(qEe,SDr),e(Mn,RDr),e(Mn,NEe),e(NEe,PDr),e(Mn,BDr),e(Mn,jEe),e(jEe,IDr),e(Mn,qDr),e(Qr,NDr),e(Qr,Ge),e(Ge,Nw),e(Nw,DEe),e(DEe,jDr),e(Nw,DDr),e(Nw,ZK),e(ZK,GDr),e(Nw,ODr),e(Ge,VDr),e(Ge,jw),e(jw,GEe),e(GEe,XDr),e(jw,zDr),e(jw,eZ),e(eZ,WDr),e(jw,QDr),e(Ge,HDr),e(Ge,Dw),e(Dw,OEe),e(OEe,UDr),e(Dw,JDr),e(Dw,oZ),e(oZ,YDr),e(Dw,KDr),e(Ge,ZDr),e(Ge,Gw),e(Gw,VEe),e(VEe,eGr),e(Gw,oGr),e(Gw,rZ),e(rZ,rGr),e(Gw,tGr),e(Ge,aGr),e(Ge,Ow),e(Ow,XEe),e(XEe,nGr),e(Ow,sGr),e(Ow,tZ),e(tZ,lGr),e(Ow,iGr),e(Ge,dGr),e(Ge,Vw),e(Vw,zEe),e(zEe,cGr),e(Vw,fGr),e(Vw,aZ),e(aZ,mGr),e(Vw,gGr),e(Ge,hGr),e(Ge,Xw),e(Xw,WEe),e(WEe,pGr),e(Xw,uGr),e(Xw,nZ),e(nZ,_Gr),e(Xw,bGr),e(Ge,vGr),e(Ge,zw),e(zw,QEe),e(QEe,FGr),e(zw,TGr),e(zw,sZ),e(sZ,MGr),e(zw,EGr),e(Qr,CGr),M(Ww,Qr,null),b(f,Kje,_),b(f,nf,_),e(nf,Qw),e(Qw,HEe),M(ux,HEe,null),e(nf,wGr),e(nf,UEe),e(UEe,AGr),b(f,Zje,_),b(f,Fr,_),M(_x,Fr,null),e(Fr,yGr),e(Fr,sf),e(sf,LGr),e(sf,lZ),e(lZ,xGr),e(sf,$Gr),e(sf,iZ),e(iZ,kGr),e(sf,SGr),e(Fr,RGr),e(Fr,bx),e(bx,PGr),e(bx,JEe),e(JEe,BGr),e(bx,IGr),e(Fr,qGr),e(Fr,Jt),M(vx,Jt,null),e(Jt,NGr),e(Jt,YEe),e(YEe,jGr),e(Jt,DGr),e(Jt,lf),e(lf,GGr),e(lf,KEe),e(KEe,OGr),e(lf,VGr),e(lf,dZ),e(dZ,XGr),e(lf,zGr),e(Jt,WGr),M(Hw,Jt,null),e(Fr,QGr),e(Fr,Hr),M(Fx,Hr,null),e(Hr,HGr),e(Hr,ZEe),e(ZEe,UGr),e(Hr,JGr),e(Hr,En),e(En,YGr),e(En,eCe),e(eCe,KGr),e(En,ZGr),e(En,oCe),e(oCe,eOr),e(En,oOr),e(En,rCe),e(rCe,rOr),e(En,tOr),e(Hr,aOr),e(Hr,tCe),e(tCe,Uw),e(Uw,aCe),e(aCe,nOr),e(Uw,sOr),e(Uw,cZ),e(cZ,lOr),e(Uw,iOr),e(Hr,dOr),M(Jw,Hr,null),b(f,eDe,_),b(f,df,_),e(df,Yw),e(Yw,nCe),M(Tx,nCe,null),e(df,cOr),e(df,sCe),e(sCe,fOr),b(f,oDe,_),b(f,Tr,_),M(Mx,Tr,null),e(Tr,mOr),e(Tr,cf),e(cf,gOr),e(cf,fZ),e(fZ,hOr),e(cf,pOr),e(cf,mZ),e(mZ,uOr),e(cf,_Or),e(Tr,bOr),e(Tr,Ex),e(Ex,vOr),e(Ex,lCe),e(lCe,FOr),e(Ex,TOr),e(Tr,MOr),e(Tr,Yt),M(Cx,Yt,null),e(Yt,EOr),e(Yt,iCe),e(iCe,COr),e(Yt,wOr),e(Yt,ff),e(ff,AOr),e(ff,dCe),e(dCe,yOr),e(ff,LOr),e(ff,gZ),e(gZ,xOr),e(ff,$Or),e(Yt,kOr),M(Kw,Yt,null),e(Tr,SOr),e(Tr,Ur),M(wx,Ur,null),e(Ur,ROr),e(Ur,cCe),e(cCe,POr),e(Ur,BOr),e(Ur,Cn),e(Cn,IOr),e(Cn,fCe),e(fCe,qOr),e(Cn,NOr),e(Cn,mCe),e(mCe,jOr),e(Cn,DOr),e(Cn,gCe),e(gCe,GOr),e(Cn,OOr),e(Ur,VOr),e(Ur,Ax),e(Ax,Zw),e(Zw,hCe),e(hCe,XOr),e(Zw,zOr),e(Zw,hZ),e(hZ,WOr),e(Zw,QOr),e(Ax,HOr),e(Ax,e0),e(e0,pCe),e(pCe,UOr),e(e0,JOr),e(e0,pZ),e(pZ,YOr),e(e0,KOr),e(Ur,ZOr),M(o0,Ur,null),b(f,rDe,_),b(f,mf,_),e(mf,r0),e(r0,uCe),M(yx,uCe,null),e(mf,eVr),e(mf,_Ce),e(_Ce,oVr),b(f,tDe,_),b(f,Mr,_),M(Lx,Mr,null),e(Mr,rVr),e(Mr,gf),e(gf,tVr),e(gf,uZ),e(uZ,aVr),e(gf,nVr),e(gf,_Z),e(_Z,sVr),e(gf,lVr),e(Mr,iVr),e(Mr,xx),e(xx,dVr),e(xx,bCe),e(bCe,cVr),e(xx,fVr),e(Mr,mVr),e(Mr,Kt),M($x,Kt,null),e(Kt,gVr),e(Kt,vCe),e(vCe,hVr),e(Kt,pVr),e(Kt,hf),e(hf,uVr),e(hf,FCe),e(FCe,_Vr),e(hf,bVr),e(hf,bZ),e(bZ,vVr),e(hf,FVr),e(Kt,TVr),M(t0,Kt,null),e(Mr,MVr),e(Mr,Jr),M(kx,Jr,null),e(Jr,EVr),e(Jr,TCe),e(TCe,CVr),e(Jr,wVr),e(Jr,wn),e(wn,AVr),e(wn,MCe),e(MCe,yVr),e(wn,LVr),e(wn,ECe),e(ECe,xVr),e(wn,$Vr),e(wn,CCe),e(CCe,kVr),e(wn,SVr),e(Jr,RVr),e(Jr,wCe),e(wCe,a0),e(a0,ACe),e(ACe,PVr),e(a0,BVr),e(a0,vZ),e(vZ,IVr),e(a0,qVr),e(Jr,NVr),M(n0,Jr,null),aDe=!0},p(f,[_]){const Sx={};_&2&&(Sx.$$scope={dirty:_,ctx:f}),Ef.$set(Sx);const yCe={};_&2&&(yCe.$$scope={dirty:_,ctx:f}),Ag.$set(yCe);const LCe={};_&2&&(LCe.$$scope={dirty:_,ctx:f}),ah.$set(LCe);const xCe={};_&2&&(xCe.$$scope={dirty:_,ctx:f}),Ih.$set(xCe);const Rx={};_&2&&(Rx.$$scope={dirty:_,ctx:f}),qh.$set(Rx);const $Ce={};_&2&&($Ce.$$scope={dirty:_,ctx:f}),tp.$set($Ce);const An={};_&2&&(An.$$scope={dirty:_,ctx:f}),ap.$set(An);const kCe={};_&2&&(kCe.$$scope={dirty:_,ctx:f}),lp.$set(kCe);const SCe={};_&2&&(SCe.$$scope={dirty:_,ctx:f}),r_.$set(SCe);const RCe={};_&2&&(RCe.$$scope={dirty:_,ctx:f}),a_.$set(RCe);const Px={};_&2&&(Px.$$scope={dirty:_,ctx:f}),H_.$set(Px);const PCe={};_&2&&(PCe.$$scope={dirty:_,ctx:f}),J_.$set(PCe);const Bx={};_&2&&(Bx.$$scope={dirty:_,ctx:f}),B2.$set(Bx);const BCe={};_&2&&(BCe.$$scope={dirty:_,ctx:f}),q2.$set(BCe);const Ix={};_&2&&(Ix.$$scope={dirty:_,ctx:f}),F1.$set(Ix);const ICe={};_&2&&(ICe.$$scope={dirty:_,ctx:f}),M1.$set(ICe);const qCe={};_&2&&(qCe.$$scope={dirty:_,ctx:f}),D1.$set(qCe);const NCe={};_&2&&(NCe.$$scope={dirty:_,ctx:f}),O1.$set(NCe);const pf={};_&2&&(pf.$$scope={dirty:_,ctx:f}),qb.$set(pf);const jCe={};_&2&&(jCe.$$scope={dirty:_,ctx:f}),jb.$set(jCe);const DCe={};_&2&&(DCe.$$scope={dirty:_,ctx:f}),u4.$set(DCe);const GCe={};_&2&&(GCe.$$scope={dirty:_,ctx:f}),b4.$set(GCe);const qx={};_&2&&(qx.$$scope={dirty:_,ctx:f}),w4.$set(qx);const OCe={};_&2&&(OCe.$$scope={dirty:_,ctx:f}),y4.$set(OCe);const VCe={};_&2&&(VCe.$$scope={dirty:_,ctx:f}),dv.$set(VCe);const XCe={};_&2&&(XCe.$$scope={dirty:_,ctx:f}),fv.$set(XCe);const et={};_&2&&(et.$$scope={dirty:_,ctx:f}),Zv.$set(et);const Nx={};_&2&&(Nx.$$scope={dirty:_,ctx:f}),o5.$set(Nx);const zCe={};_&2&&(zCe.$$scope={dirty:_,ctx:f}),a5.$set(zCe);const jx={};_&2&&(jx.$$scope={dirty:_,ctx:f}),s5.$set(jx);const WCe={};_&2&&(WCe.$$scope={dirty:_,ctx:f}),F5.$set(WCe);const ot={};_&2&&(ot.$$scope={dirty:_,ctx:f}),M5.$set(ot);const QCe={};_&2&&(QCe.$$scope={dirty:_,ctx:f}),w5.$set(QCe);const uf={};_&2&&(uf.$$scope={dirty:_,ctx:f}),y5.$set(uf);const HCe={};_&2&&(HCe.$$scope={dirty:_,ctx:f}),N5.$set(HCe);const UCe={};_&2&&(UCe.$$scope={dirty:_,ctx:f}),D5.$set(UCe);const y={};_&2&&(y.$$scope={dirty:_,ctx:f}),Q5.$set(y);const s0={};_&2&&(s0.$$scope={dirty:_,ctx:f}),U5.$set(s0);const JCe={};_&2&&(JCe.$$scope={dirty:_,ctx:f}),sF.$set(JCe);const YCe={};_&2&&(YCe.$$scope={dirty:_,ctx:f}),iF.$set(YCe);const l0={};_&2&&(l0.$$scope={dirty:_,ctx:f}),mF.$set(l0);const KCe={};_&2&&(KCe.$$scope={dirty:_,ctx:f}),hF.$set(KCe);const ZCe={};_&2&&(ZCe.$$scope={dirty:_,ctx:f}),TF.$set(ZCe);const i0={};_&2&&(i0.$$scope={dirty:_,ctx:f}),EF.$set(i0);const e3e={};_&2&&(e3e.$$scope={dirty:_,ctx:f}),LF.$set(e3e);const o3e={};_&2&&(o3e.$$scope={dirty:_,ctx:f}),$F.$set(o3e);const d0={};_&2&&(d0.$$scope={dirty:_,ctx:f}),PF.$set(d0);const r3e={};_&2&&(r3e.$$scope={dirty:_,ctx:f}),IF.$set(r3e);const t3e={};_&2&&(t3e.$$scope={dirty:_,ctx:f}),jF.$set(t3e);const c0={};_&2&&(c0.$$scope={dirty:_,ctx:f}),GF.$set(c0);const a3e={};_&2&&(a3e.$$scope={dirty:_,ctx:f}),QF.$set(a3e);const n3e={};_&2&&(n3e.$$scope={dirty:_,ctx:f}),UF.$set(n3e);const f0={};_&2&&(f0.$$scope={dirty:_,ctx:f}),KF.$set(f0);const s3e={};_&2&&(s3e.$$scope={dirty:_,ctx:f}),eT.$set(s3e);const l3e={};_&2&&(l3e.$$scope={dirty:_,ctx:f}),WT.$set(l3e);const m0={};_&2&&(m0.$$scope={dirty:_,ctx:f}),HT.$set(m0);const i3e={};_&2&&(i3e.$$scope={dirty:_,ctx:f}),b7.$set(i3e);const d3e={};_&2&&(d3e.$$scope={dirty:_,ctx:f}),F7.$set(d3e);const g0={};_&2&&(g0.$$scope={dirty:_,ctx:f}),R7.$set(g0);const c3e={};_&2&&(c3e.$$scope={dirty:_,ctx:f}),B7.$set(c3e);const f3e={};_&2&&(f3e.$$scope={dirty:_,ctx:f}),D7.$set(f3e);const h0={};_&2&&(h0.$$scope={dirty:_,ctx:f}),O7.$set(h0);const m3e={};_&2&&(m3e.$$scope={dirty:_,ctx:f}),dM.$set(m3e);const g3e={};_&2&&(g3e.$$scope={dirty:_,ctx:f}),fM.$set(g3e);const p0={};_&2&&(p0.$$scope={dirty:_,ctx:f}),MM.$set(p0);const h3e={};_&2&&(h3e.$$scope={dirty:_,ctx:f}),CM.$set(h3e);const p3e={};_&2&&(p3e.$$scope={dirty:_,ctx:f}),YM.$set(p3e);const u0={};_&2&&(u0.$$scope={dirty:_,ctx:f}),ZM.$set(u0);const u3e={};_&2&&(u3e.$$scope={dirty:_,ctx:f}),_E.$set(u3e);const _3e={};_&2&&(_3e.$$scope={dirty:_,ctx:f}),vE.$set(_3e);const _0={};_&2&&(_0.$$scope={dirty:_,ctx:f}),ME.$set(_0);const b3e={};_&2&&(b3e.$$scope={dirty:_,ctx:f}),CE.$set(b3e);const v3e={};_&2&&(v3e.$$scope={dirty:_,ctx:f}),AE.$set(v3e);const b0={};_&2&&(b0.$$scope={dirty:_,ctx:f}),LE.$set(b0);const F3e={};_&2&&(F3e.$$scope={dirty:_,ctx:f}),UE.$set(F3e);const T3e={};_&2&&(T3e.$$scope={dirty:_,ctx:f}),YE.$set(T3e);const v0={};_&2&&(v0.$$scope={dirty:_,ctx:f}),bC.$set(v0);const M3e={};_&2&&(M3e.$$scope={dirty:_,ctx:f}),FC.$set(M3e);const E3e={};_&2&&(E3e.$$scope={dirty:_,ctx:f}),MC.$set(E3e);const F0={};_&2&&(F0.$$scope={dirty:_,ctx:f}),CC.$set(F0);const C3e={};_&2&&(C3e.$$scope={dirty:_,ctx:f}),AC.$set(C3e);const w3e={};_&2&&(w3e.$$scope={dirty:_,ctx:f}),LC.$set(w3e);const T0={};_&2&&(T0.$$scope={dirty:_,ctx:f}),e3.$set(T0);const A3e={};_&2&&(A3e.$$scope={dirty:_,ctx:f}),r3.$set(A3e);const y3e={};_&2&&(y3e.$$scope={dirty:_,ctx:f}),m3.$set(y3e);const M0={};_&2&&(M0.$$scope={dirty:_,ctx:f}),h3.$set(M0);const L3e={};_&2&&(L3e.$$scope={dirty:_,ctx:f}),y3.$set(L3e);const x3e={};_&2&&(x3e.$$scope={dirty:_,ctx:f}),x3.$set(x3e);const E0={};_&2&&(E0.$$scope={dirty:_,ctx:f}),D3.$set(E0);const $3e={};_&2&&($3e.$$scope={dirty:_,ctx:f}),O3.$set($3e);const k3e={};_&2&&(k3e.$$scope={dirty:_,ctx:f}),K3.$set(k3e);const C0={};_&2&&(C0.$$scope={dirty:_,ctx:f}),ew.$set(C0);const S3e={};_&2&&(S3e.$$scope={dirty:_,ctx:f}),fw.$set(S3e);const R3e={};_&2&&(R3e.$$scope={dirty:_,ctx:f}),gw.$set(R3e);const w0={};_&2&&(w0.$$scope={dirty:_,ctx:f}),Cw.$set(w0);const P3e={};_&2&&(P3e.$$scope={dirty:_,ctx:f}),Aw.$set(P3e);const B3e={};_&2&&(B3e.$$scope={dirty:_,ctx:f}),Bw.$set(B3e);const A0={};_&2&&(A0.$$scope={dirty:_,ctx:f}),qw.$set(A0);const I3e={};_&2&&(I3e.$$scope={dirty:_,ctx:f}),Ww.$set(I3e);const q3e={};_&2&&(q3e.$$scope={dirty:_,ctx:f}),Hw.$set(q3e);const y0={};_&2&&(y0.$$scope={dirty:_,ctx:f}),Jw.$set(y0);const N3e={};_&2&&(N3e.$$scope={dirty:_,ctx:f}),Kw.$set(N3e);const j3e={};_&2&&(j3e.$$scope={dirty:_,ctx:f}),o0.$set(j3e);const L0={};_&2&&(L0.$$scope={dirty:_,ctx:f}),t0.$set(L0);const D3e={};_&2&&(D3e.$$scope={dirty:_,ctx:f}),n0.$set(D3e)},i(f){aDe||(E(d.$$.fragment,f),E(Ca.$$.fragment,f),E(yA.$$.fragment,f),E(LA.$$.fragment,f),E(Ef.$$.fragment,f),E(xA.$$.fragment,f),E($A.$$.fragment,f),E(RA.$$.fragment,f),E(Ag.$$.fragment,f),E(PA.$$.fragment,f),E(BA.$$.fragment,f),E(IA.$$.fragment,f),E(jA.$$.fragment,f),E(ah.$$.fragment,f),E(DA.$$.fragment,f),E(GA.$$.fragment,f),E(OA.$$.fragment,f),E(zA.$$.fragment,f),E(Ih.$$.fragment,f),E(qh.$$.fragment,f),E(WA.$$.fragment,f),E(QA.$$.fragment,f),E(HA.$$.fragment,f),E(YA.$$.fragment,f),E(tp.$$.fragment,f),E(ap.$$.fragment,f),E(KA.$$.fragment,f),E(ZA.$$.fragment,f),E(ey.$$.fragment,f),E(ry.$$.fragment,f),E(lp.$$.fragment,f),E(ty.$$.fragment,f),E(r_.$$.fragment,f),E(ay.$$.fragment,f),E(ny.$$.fragment,f),E(ly.$$.fragment,f),E(a_.$$.fragment,f),E(iy.$$.fragment,f),E(H_.$$.fragment,f),E(dy.$$.fragment,f),E(cy.$$.fragment,f),E(my.$$.fragment,f),E(J_.$$.fragment,f),E(gy.$$.fragment,f),E(B2.$$.fragment,f),E(hy.$$.fragment,f),E(py.$$.fragment,f),E(_y.$$.fragment,f),E(q2.$$.fragment,f),E(by.$$.fragment,f),E(F1.$$.fragment,f),E(vy.$$.fragment,f),E(Fy.$$.fragment,f),E(My.$$.fragment,f),E(M1.$$.fragment,f),E(Ey.$$.fragment,f),E(D1.$$.fragment,f),E(Cy.$$.fragment,f),E(wy.$$.fragment,f),E(yy.$$.fragment,f),E(O1.$$.fragment,f),E(Ly.$$.fragment,f),E(qb.$$.fragment,f),E(xy.$$.fragment,f),E($y.$$.fragment,f),E(Sy.$$.fragment,f),E(jb.$$.fragment,f),E(Ry.$$.fragment,f),E(u4.$$.fragment,f),E(Py.$$.fragment,f),E(By.$$.fragment,f),E(qy.$$.fragment,f),E(b4.$$.fragment,f),E(Ny.$$.fragment,f),E(w4.$$.fragment,f),E(jy.$$.fragment,f),E(Dy.$$.fragment,f),E(Oy.$$.fragment,f),E(y4.$$.fragment,f),E(Vy.$$.fragment,f),E(dv.$$.fragment,f),E(Xy.$$.fragment,f),E(zy.$$.fragment,f),E(Qy.$$.fragment,f),E(fv.$$.fragment,f),E(Hy.$$.fragment,f),E(Zv.$$.fragment,f),E(Uy.$$.fragment,f),E(Jy.$$.fragment,f),E(Ky.$$.fragment,f),E(o5.$$.fragment,f),E(Zy.$$.fragment,f),E(a5.$$.fragment,f),E(eL.$$.fragment,f),E(oL.$$.fragment,f),E(tL.$$.fragment,f),E(s5.$$.fragment,f),E(aL.$$.fragment,f),E(F5.$$.fragment,f),E(nL.$$.fragment,f),E(sL.$$.fragment,f),E(iL.$$.fragment,f),E(M5.$$.fragment,f),E(dL.$$.fragment,f),E(w5.$$.fragment,f),E(cL.$$.fragment,f),E(fL.$$.fragment,f),E(gL.$$.fragment,f),E(y5.$$.fragment,f),E(hL.$$.fragment,f),E(N5.$$.fragment,f),E(pL.$$.fragment,f),E(uL.$$.fragment,f),E(bL.$$.fragment,f),E(D5.$$.fragment,f),E(vL.$$.fragment,f),E(Q5.$$.fragment,f),E(FL.$$.fragment,f),E(TL.$$.fragment,f),E(EL.$$.fragment,f),E(U5.$$.fragment,f),E(CL.$$.fragment,f),E(sF.$$.fragment,f),E(wL.$$.fragment,f),E(AL.$$.fragment,f),E(LL.$$.fragment,f),E(iF.$$.fragment,f),E(xL.$$.fragment,f),E(mF.$$.fragment,f),E(kL.$$.fragment,f),E(SL.$$.fragment,f),E(PL.$$.fragment,f),E(hF.$$.fragment,f),E(BL.$$.fragment,f),E(TF.$$.fragment,f),E(IL.$$.fragment,f),E(qL.$$.fragment,f),E(jL.$$.fragment,f),E(EF.$$.fragment,f),E(DL.$$.fragment,f),E(LF.$$.fragment,f),E(GL.$$.fragment,f),E(OL.$$.fragment,f),E(XL.$$.fragment,f),E($F.$$.fragment,f),E(zL.$$.fragment,f),E(PF.$$.fragment,f),E(QL.$$.fragment,f),E(HL.$$.fragment,f),E(JL.$$.fragment,f),E(IF.$$.fragment,f),E(YL.$$.fragment,f),E(jF.$$.fragment,f),E(KL.$$.fragment,f),E(ZL.$$.fragment,f),E(o8.$$.fragment,f),E(GF.$$.fragment,f),E(r8.$$.fragment,f),E(QF.$$.fragment,f),E(t8.$$.fragment,f),E(a8.$$.fragment,f),E(s8.$$.fragment,f),E(UF.$$.fragment,f),E(l8.$$.fragment,f),E(KF.$$.fragment,f),E(i8.$$.fragment,f),E(d8.$$.fragment,f),E(f8.$$.fragment,f),E(eT.$$.fragment,f),E(m8.$$.fragment,f),E(WT.$$.fragment,f),E(g8.$$.fragment,f),E(h8.$$.fragment,f),E(u8.$$.fragment,f),E(HT.$$.fragment,f),E(_8.$$.fragment,f),E(b7.$$.fragment,f),E(b8.$$.fragment,f),E(v8.$$.fragment,f),E(T8.$$.fragment,f),E(F7.$$.fragment,f),E(M8.$$.fragment,f),E(R7.$$.fragment,f),E(E8.$$.fragment,f),E(C8.$$.fragment,f),E(A8.$$.fragment,f),E(B7.$$.fragment,f),E(y8.$$.fragment,f),E(D7.$$.fragment,f),E(L8.$$.fragment,f),E(x8.$$.fragment,f),E(k8.$$.fragment,f),E(O7.$$.fragment,f),E(S8.$$.fragment,f),E(dM.$$.fragment,f),E(R8.$$.fragment,f),E(P8.$$.fragment,f),E(I8.$$.fragment,f),E(fM.$$.fragment,f),E(q8.$$.fragment,f),E(MM.$$.fragment,f),E(N8.$$.fragment,f),E(j8.$$.fragment,f),E(G8.$$.fragment,f),E(CM.$$.fragment,f),E(O8.$$.fragment,f),E(YM.$$.fragment,f),E(V8.$$.fragment,f),E(X8.$$.fragment,f),E(W8.$$.fragment,f),E(ZM.$$.fragment,f),E(Q8.$$.fragment,f),E(_E.$$.fragment,f),E(H8.$$.fragment,f),E(U8.$$.fragment,f),E(Y8.$$.fragment,f),E(vE.$$.fragment,f),E(K8.$$.fragment,f),E(ME.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(CE.$$.fragment,f),E(a9.$$.fragment,f),E(AE.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(LE.$$.fragment,f),E(d9.$$.fragment,f),E(UE.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(YE.$$.fragment,f),E(h9.$$.fragment,f),E(bC.$$.fragment,f),E(p9.$$.fragment,f),E(u9.$$.fragment,f),E(b9.$$.fragment,f),E(FC.$$.fragment,f),E(v9.$$.fragment,f),E(MC.$$.fragment,f),E(F9.$$.fragment,f),E(T9.$$.fragment,f),E(E9.$$.fragment,f),E(CC.$$.fragment,f),E(C9.$$.fragment,f),E(AC.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(L9.$$.fragment,f),E(LC.$$.fragment,f),E(x9.$$.fragment,f),E(e3.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(R9.$$.fragment,f),E(r3.$$.fragment,f),E(P9.$$.fragment,f),E(m3.$$.fragment,f),E(B9.$$.fragment,f),E(I9.$$.fragment,f),E(N9.$$.fragment,f),E(h3.$$.fragment,f),E(j9.$$.fragment,f),E(y3.$$.fragment,f),E(D9.$$.fragment,f),E(G9.$$.fragment,f),E(V9.$$.fragment,f),E(x3.$$.fragment,f),E(X9.$$.fragment,f),E(D3.$$.fragment,f),E(z9.$$.fragment,f),E(W9.$$.fragment,f),E(H9.$$.fragment,f),E(O3.$$.fragment,f),E(U9.$$.fragment,f),E(K3.$$.fragment,f),E(J9.$$.fragment,f),E(Y9.$$.fragment,f),E(Z9.$$.fragment,f),E(ew.$$.fragment,f),E(ex.$$.fragment,f),E(fw.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(gw.$$.fragment,f),E(nx.$$.fragment,f),E(Cw.$$.fragment,f),E(sx.$$.fragment,f),E(lx.$$.fragment,f),E(dx.$$.fragment,f),E(Aw.$$.fragment,f),E(cx.$$.fragment,f),E(Bw.$$.fragment,f),E(fx.$$.fragment,f),E(mx.$$.fragment,f),E(hx.$$.fragment,f),E(qw.$$.fragment,f),E(px.$$.fragment,f),E(Ww.$$.fragment,f),E(ux.$$.fragment,f),E(_x.$$.fragment,f),E(vx.$$.fragment,f),E(Hw.$$.fragment,f),E(Fx.$$.fragment,f),E(Jw.$$.fragment,f),E(Tx.$$.fragment,f),E(Mx.$$.fragment,f),E(Cx.$$.fragment,f),E(Kw.$$.fragment,f),E(wx.$$.fragment,f),E(o0.$$.fragment,f),E(yx.$$.fragment,f),E(Lx.$$.fragment,f),E($x.$$.fragment,f),E(t0.$$.fragment,f),E(kx.$$.fragment,f),E(n0.$$.fragment,f),aDe=!0)},o(f){C(d.$$.fragment,f),C(Ca.$$.fragment,f),C(yA.$$.fragment,f),C(LA.$$.fragment,f),C(Ef.$$.fragment,f),C(xA.$$.fragment,f),C($A.$$.fragment,f),C(RA.$$.fragment,f),C(Ag.$$.fragment,f),C(PA.$$.fragment,f),C(BA.$$.fragment,f),C(IA.$$.fragment,f),C(jA.$$.fragment,f),C(ah.$$.fragment,f),C(DA.$$.fragment,f),C(GA.$$.fragment,f),C(OA.$$.fragment,f),C(zA.$$.fragment,f),C(Ih.$$.fragment,f),C(qh.$$.fragment,f),C(WA.$$.fragment,f),C(QA.$$.fragment,f),C(HA.$$.fragment,f),C(YA.$$.fragment,f),C(tp.$$.fragment,f),C(ap.$$.fragment,f),C(KA.$$.fragment,f),C(ZA.$$.fragment,f),C(ey.$$.fragment,f),C(ry.$$.fragment,f),C(lp.$$.fragment,f),C(ty.$$.fragment,f),C(r_.$$.fragment,f),C(ay.$$.fragment,f),C(ny.$$.fragment,f),C(ly.$$.fragment,f),C(a_.$$.fragment,f),C(iy.$$.fragment,f),C(H_.$$.fragment,f),C(dy.$$.fragment,f),C(cy.$$.fragment,f),C(my.$$.fragment,f),C(J_.$$.fragment,f),C(gy.$$.fragment,f),C(B2.$$.fragment,f),C(hy.$$.fragment,f),C(py.$$.fragment,f),C(_y.$$.fragment,f),C(q2.$$.fragment,f),C(by.$$.fragment,f),C(F1.$$.fragment,f),C(vy.$$.fragment,f),C(Fy.$$.fragment,f),C(My.$$.fragment,f),C(M1.$$.fragment,f),C(Ey.$$.fragment,f),C(D1.$$.fragment,f),C(Cy.$$.fragment,f),C(wy.$$.fragment,f),C(yy.$$.fragment,f),C(O1.$$.fragment,f),C(Ly.$$.fragment,f),C(qb.$$.fragment,f),C(xy.$$.fragment,f),C($y.$$.fragment,f),C(Sy.$$.fragment,f),C(jb.$$.fragment,f),C(Ry.$$.fragment,f),C(u4.$$.fragment,f),C(Py.$$.fragment,f),C(By.$$.fragment,f),C(qy.$$.fragment,f),C(b4.$$.fragment,f),C(Ny.$$.fragment,f),C(w4.$$.fragment,f),C(jy.$$.fragment,f),C(Dy.$$.fragment,f),C(Oy.$$.fragment,f),C(y4.$$.fragment,f),C(Vy.$$.fragment,f),C(dv.$$.fragment,f),C(Xy.$$.fragment,f),C(zy.$$.fragment,f),C(Qy.$$.fragment,f),C(fv.$$.fragment,f),C(Hy.$$.fragment,f),C(Zv.$$.fragment,f),C(Uy.$$.fragment,f),C(Jy.$$.fragment,f),C(Ky.$$.fragment,f),C(o5.$$.fragment,f),C(Zy.$$.fragment,f),C(a5.$$.fragment,f),C(eL.$$.fragment,f),C(oL.$$.fragment,f),C(tL.$$.fragment,f),C(s5.$$.fragment,f),C(aL.$$.fragment,f),C(F5.$$.fragment,f),C(nL.$$.fragment,f),C(sL.$$.fragment,f),C(iL.$$.fragment,f),C(M5.$$.fragment,f),C(dL.$$.fragment,f),C(w5.$$.fragment,f),C(cL.$$.fragment,f),C(fL.$$.fragment,f),C(gL.$$.fragment,f),C(y5.$$.fragment,f),C(hL.$$.fragment,f),C(N5.$$.fragment,f),C(pL.$$.fragment,f),C(uL.$$.fragment,f),C(bL.$$.fragment,f),C(D5.$$.fragment,f),C(vL.$$.fragment,f),C(Q5.$$.fragment,f),C(FL.$$.fragment,f),C(TL.$$.fragment,f),C(EL.$$.fragment,f),C(U5.$$.fragment,f),C(CL.$$.fragment,f),C(sF.$$.fragment,f),C(wL.$$.fragment,f),C(AL.$$.fragment,f),C(LL.$$.fragment,f),C(iF.$$.fragment,f),C(xL.$$.fragment,f),C(mF.$$.fragment,f),C(kL.$$.fragment,f),C(SL.$$.fragment,f),C(PL.$$.fragment,f),C(hF.$$.fragment,f),C(BL.$$.fragment,f),C(TF.$$.fragment,f),C(IL.$$.fragment,f),C(qL.$$.fragment,f),C(jL.$$.fragment,f),C(EF.$$.fragment,f),C(DL.$$.fragment,f),C(LF.$$.fragment,f),C(GL.$$.fragment,f),C(OL.$$.fragment,f),C(XL.$$.fragment,f),C($F.$$.fragment,f),C(zL.$$.fragment,f),C(PF.$$.fragment,f),C(QL.$$.fragment,f),C(HL.$$.fragment,f),C(JL.$$.fragment,f),C(IF.$$.fragment,f),C(YL.$$.fragment,f),C(jF.$$.fragment,f),C(KL.$$.fragment,f),C(ZL.$$.fragment,f),C(o8.$$.fragment,f),C(GF.$$.fragment,f),C(r8.$$.fragment,f),C(QF.$$.fragment,f),C(t8.$$.fragment,f),C(a8.$$.fragment,f),C(s8.$$.fragment,f),C(UF.$$.fragment,f),C(l8.$$.fragment,f),C(KF.$$.fragment,f),C(i8.$$.fragment,f),C(d8.$$.fragment,f),C(f8.$$.fragment,f),C(eT.$$.fragment,f),C(m8.$$.fragment,f),C(WT.$$.fragment,f),C(g8.$$.fragment,f),C(h8.$$.fragment,f),C(u8.$$.fragment,f),C(HT.$$.fragment,f),C(_8.$$.fragment,f),C(b7.$$.fragment,f),C(b8.$$.fragment,f),C(v8.$$.fragment,f),C(T8.$$.fragment,f),C(F7.$$.fragment,f),C(M8.$$.fragment,f),C(R7.$$.fragment,f),C(E8.$$.fragment,f),C(C8.$$.fragment,f),C(A8.$$.fragment,f),C(B7.$$.fragment,f),C(y8.$$.fragment,f),C(D7.$$.fragment,f),C(L8.$$.fragment,f),C(x8.$$.fragment,f),C(k8.$$.fragment,f),C(O7.$$.fragment,f),C(S8.$$.fragment,f),C(dM.$$.fragment,f),C(R8.$$.fragment,f),C(P8.$$.fragment,f),C(I8.$$.fragment,f),C(fM.$$.fragment,f),C(q8.$$.fragment,f),C(MM.$$.fragment,f),C(N8.$$.fragment,f),C(j8.$$.fragment,f),C(G8.$$.fragment,f),C(CM.$$.fragment,f),C(O8.$$.fragment,f),C(YM.$$.fragment,f),C(V8.$$.fragment,f),C(X8.$$.fragment,f),C(W8.$$.fragment,f),C(ZM.$$.fragment,f),C(Q8.$$.fragment,f),C(_E.$$.fragment,f),C(H8.$$.fragment,f),C(U8.$$.fragment,f),C(Y8.$$.fragment,f),C(vE.$$.fragment,f),C(K8.$$.fragment,f),C(ME.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(CE.$$.fragment,f),C(a9.$$.fragment,f),C(AE.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(LE.$$.fragment,f),C(d9.$$.fragment,f),C(UE.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(YE.$$.fragment,f),C(h9.$$.fragment,f),C(bC.$$.fragment,f),C(p9.$$.fragment,f),C(u9.$$.fragment,f),C(b9.$$.fragment,f),C(FC.$$.fragment,f),C(v9.$$.fragment,f),C(MC.$$.fragment,f),C(F9.$$.fragment,f),C(T9.$$.fragment,f),C(E9.$$.fragment,f),C(CC.$$.fragment,f),C(C9.$$.fragment,f),C(AC.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(L9.$$.fragment,f),C(LC.$$.fragment,f),C(x9.$$.fragment,f),C(e3.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(R9.$$.fragment,f),C(r3.$$.fragment,f),C(P9.$$.fragment,f),C(m3.$$.fragment,f),C(B9.$$.fragment,f),C(I9.$$.fragment,f),C(N9.$$.fragment,f),C(h3.$$.fragment,f),C(j9.$$.fragment,f),C(y3.$$.fragment,f),C(D9.$$.fragment,f),C(G9.$$.fragment,f),C(V9.$$.fragment,f),C(x3.$$.fragment,f),C(X9.$$.fragment,f),C(D3.$$.fragment,f),C(z9.$$.fragment,f),C(W9.$$.fragment,f),C(H9.$$.fragment,f),C(O3.$$.fragment,f),C(U9.$$.fragment,f),C(K3.$$.fragment,f),C(J9.$$.fragment,f),C(Y9.$$.fragment,f),C(Z9.$$.fragment,f),C(ew.$$.fragment,f),C(ex.$$.fragment,f),C(fw.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(gw.$$.fragment,f),C(nx.$$.fragment,f),C(Cw.$$.fragment,f),C(sx.$$.fragment,f),C(lx.$$.fragment,f),C(dx.$$.fragment,f),C(Aw.$$.fragment,f),C(cx.$$.fragment,f),C(Bw.$$.fragment,f),C(fx.$$.fragment,f),C(mx.$$.fragment,f),C(hx.$$.fragment,f),C(qw.$$.fragment,f),C(px.$$.fragment,f),C(Ww.$$.fragment,f),C(ux.$$.fragment,f),C(_x.$$.fragment,f),C(vx.$$.fragment,f),C(Hw.$$.fragment,f),C(Fx.$$.fragment,f),C(Jw.$$.fragment,f),C(Tx.$$.fragment,f),C(Mx.$$.fragment,f),C(Cx.$$.fragment,f),C(Kw.$$.fragment,f),C(wx.$$.fragment,f),C(o0.$$.fragment,f),C(yx.$$.fragment,f),C(Lx.$$.fragment,f),C($x.$$.fragment,f),C(t0.$$.fragment,f),C(kx.$$.fragment,f),C(n0.$$.fragment,f),aDe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(bf),f&&t(rt),f&&t(je),f&&t(We),f&&t(Ff),w(Ca,f),f&&t(Qe),f&&t(Ae),f&&t(Eo),f&&t(wa),f&&t(oNe),f&&t(Ti),w(yA),f&&t(rNe),f&&t(kn),f&&t(tNe),w(LA,f),f&&t(aNe),f&&t(Z$),f&&t(nNe),w(Ef,f),f&&t(sNe),f&&t(Mi),w(xA),f&&t(lNe),f&&t(Co),w($A),w(RA),w(Ag),w(PA),f&&t(iNe),f&&t(Ci),w(BA),f&&t(dNe),f&&t(wo),w(IA),w(jA),w(ah),w(DA),f&&t(cNe),f&&t(wi),w(GA),f&&t(fNe),f&&t(Ao),w(OA),w(zA),w(Ih),w(qh),w(WA),f&&t(mNe),f&&t(Ai),w(QA),f&&t(gNe),f&&t(yo),w(HA),w(YA),w(tp),w(ap),w(KA),f&&t(hNe),f&&t(Li),w(ZA),f&&t(pNe),f&&t(Lo),w(ey),w(ry),w(lp),w(ty),w(r_),f&&t(uNe),f&&t(ki),w(ay),f&&t(_Ne),f&&t(xo),w(ny),w(ly),w(a_),w(iy),w(H_),f&&t(bNe),f&&t(Pi),w(dy),f&&t(vNe),f&&t($o),w(cy),w(my),w(J_),w(gy),w(B2),f&&t(FNe),f&&t(qi),w(hy),f&&t(TNe),f&&t(ko),w(py),w(_y),w(q2),w(by),w(F1),f&&t(MNe),f&&t(Di),w(vy),f&&t(ENe),f&&t(So),w(Fy),w(My),w(M1),w(Ey),w(D1),f&&t(CNe),f&&t(Vi),w(Cy),f&&t(wNe),f&&t(Ro),w(wy),w(yy),w(O1),w(Ly),w(qb),f&&t(ANe),f&&t(Wi),w(xy),f&&t(yNe),f&&t(Po),w($y),w(Sy),w(jb),w(Ry),w(u4),f&&t(LNe),f&&t(Ui),w(Py),f&&t(xNe),f&&t(Bo),w(By),w(qy),w(b4),w(Ny),w(w4),f&&t($Ne),f&&t(Ki),w(jy),f&&t(kNe),f&&t(Io),w(Dy),w(Oy),w(y4),w(Vy),w(dv),f&&t(SNe),f&&t(od),w(Xy),f&&t(RNe),f&&t(qo),w(zy),w(Qy),w(fv),w(Hy),w(Zv),f&&t(PNe),f&&t(ad),w(Uy),f&&t(BNe),f&&t(No),w(Jy),w(Ky),w(o5),w(Zy),w(a5),f&&t(INe),f&&t(ld),w(eL),f&&t(qNe),f&&t(jo),w(oL),w(tL),w(s5),w(aL),w(F5),f&&t(NNe),f&&t(cd),w(nL),f&&t(jNe),f&&t(Do),w(sL),w(iL),w(M5),w(dL),w(w5),f&&t(DNe),f&&t(gd),w(cL),f&&t(GNe),f&&t(Go),w(fL),w(gL),w(y5),w(hL),w(N5),f&&t(ONe),f&&t(ud),w(pL),f&&t(VNe),f&&t(Oo),w(uL),w(bL),w(D5),w(vL),w(Q5),f&&t(XNe),f&&t(vd),w(FL),f&&t(zNe),f&&t(Vo),w(TL),w(EL),w(U5),w(CL),w(sF),f&&t(WNe),f&&t(Md),w(wL),f&&t(QNe),f&&t(Xo),w(AL),w(LL),w(iF),w(xL),w(mF),f&&t(HNe),f&&t(wd),w(kL),f&&t(UNe),f&&t(zo),w(SL),w(PL),w(hF),w(BL),w(TF),f&&t(JNe),f&&t(Ld),w(IL),f&&t(YNe),f&&t(Wo),w(qL),w(jL),w(EF),w(DL),w(LF),f&&t(KNe),f&&t(Sd),w(GL),f&&t(ZNe),f&&t(Qo),w(OL),w(XL),w($F),w(zL),w(PF),f&&t(eje),f&&t(Bd),w(QL),f&&t(oje),f&&t(Ho),w(HL),w(JL),w(IF),w(YL),w(jF),f&&t(rje),f&&t(Nd),w(KL),f&&t(tje),f&&t(Uo),w(ZL),w(o8),w(GF),w(r8),w(QF),f&&t(aje),f&&t(Gd),w(t8),f&&t(nje),f&&t(Jo),w(a8),w(s8),w(UF),w(l8),w(KF),f&&t(sje),f&&t(Xd),w(i8),f&&t(lje),f&&t(Yo),w(d8),w(f8),w(eT),w(m8),w(WT),f&&t(ije),f&&t(Qd),w(g8),f&&t(dje),f&&t(Ko),w(h8),w(u8),w(HT),w(_8),w(b7),f&&t(cje),f&&t(Jd),w(b8),f&&t(fje),f&&t(Zo),w(v8),w(T8),w(F7),w(M8),w(R7),f&&t(mje),f&&t(Zd),w(E8),f&&t(gje),f&&t(er),w(C8),w(A8),w(B7),w(y8),w(D7),f&&t(hje),f&&t(rc),w(L8),f&&t(pje),f&&t(or),w(x8),w(k8),w(O7),w(S8),w(dM),f&&t(uje),f&&t(nc),w(R8),f&&t(_je),f&&t(rr),w(P8),w(I8),w(fM),w(q8),w(MM),f&&t(bje),f&&t(ic),w(N8),f&&t(vje),f&&t(tr),w(j8),w(G8),w(CM),w(O8),w(YM),f&&t(Fje),f&&t(fc),w(V8),f&&t(Tje),f&&t(ar),w(X8),w(W8),w(ZM),w(Q8),w(_E),f&&t(Mje),f&&t(hc),w(H8),f&&t(Eje),f&&t(nr),w(U8),w(Y8),w(vE),w(K8),w(ME),f&&t(Cje),f&&t(_c),w(e9),f&&t(wje),f&&t(sr),w(o9),w(t9),w(CE),w(a9),w(AE),f&&t(Aje),f&&t(Fc),w(n9),f&&t(yje),f&&t(lr),w(s9),w(i9),w(LE),w(d9),w(UE),f&&t(Lje),f&&t(Ec),w(c9),f&&t(xje),f&&t(ir),w(f9),w(g9),w(YE),w(h9),w(bC),f&&t($je),f&&t(Ac),w(p9),f&&t(kje),f&&t(dr),w(u9),w(b9),w(FC),w(v9),w(MC),f&&t(Sje),f&&t(xc),w(F9),f&&t(Rje),f&&t(cr),w(T9),w(E9),w(CC),w(C9),w(AC),f&&t(Pje),f&&t(Sc),w(w9),f&&t(Bje),f&&t(fr),w(A9),w(L9),w(LC),w(x9),w(e3),f&&t(Ije),f&&t(Bc),w($9),f&&t(qje),f&&t(mr),w(k9),w(R9),w(r3),w(P9),w(m3),f&&t(Nje),f&&t(Nc),w(B9),f&&t(jje),f&&t(gr),w(I9),w(N9),w(h3),w(j9),w(y3),f&&t(Dje),f&&t(Gc),w(D9),f&&t(Gje),f&&t(hr),w(G9),w(V9),w(x3),w(X9),w(D3),f&&t(Oje),f&&t(Xc),w(z9),f&&t(Vje),f&&t(pr),w(W9),w(H9),w(O3),w(U9),w(K3),f&&t(Xje),f&&t(Qc),w(J9),f&&t(zje),f&&t(ur),w(Y9),w(Z9),w(ew),w(ex),w(fw),f&&t(Wje),f&&t(Jc),w(ox),f&&t(Qje),f&&t(_r),w(rx),w(ax),w(gw),w(nx),w(Cw),f&&t(Hje),f&&t(Zc),w(sx),f&&t(Uje),f&&t(br),w(lx),w(dx),w(Aw),w(cx),w(Bw),f&&t(Jje),f&&t(rf),w(fx),f&&t(Yje),f&&t(vr),w(mx),w(hx),w(qw),w(px),w(Ww),f&&t(Kje),f&&t(nf),w(ux),f&&t(Zje),f&&t(Fr),w(_x),w(vx),w(Hw),w(Fx),w(Jw),f&&t(eDe),f&&t(df),w(Tx),f&&t(oDe),f&&t(Tr),w(Mx),w(Cx),w(Kw),w(wx),w(o0),f&&t(rDe),f&&t(mf),w(yx),f&&t(tDe),f&&t(Mr),w(Lx),w($x),w(t0),w(kx),w(n0)}}}const TSt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function MSt(L){return M$t(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xSt extends b$t{constructor(g){super();v$t(this,g,MSt,FSt,F$t,{})}}export{xSt as default,TSt as metadata};
