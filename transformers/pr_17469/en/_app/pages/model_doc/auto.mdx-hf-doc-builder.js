import{S as WHt,i as HHt,s as UHt,e as a,k as l,w as F,t as o,M as JHt,c as n,d as t,m as i,a as s,x as T,h as r,b as d,G as e,g as b,y as M,q as E,o as C,B as w,v as YHt,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as Jat}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function KHt($){let g,v,p,m,_,c,h,wo,xi,Bf,lt,$i,ki,mL,If,Oe,We,Si,Bn,gL,In,Nn,hL,Ri,qn,pL,Pi,Nf,Sa;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),c=a("code"),h=o("PretrainedConfig"),wo=o(`, make sure its
`),xi=a("code"),Bf=o("model_type"),lt=o(" attribute is set to the same key you use when registering the config (here "),$i=a("code"),ki=o('"new-model"'),mL=o(")."),If=l(),Oe=a("p"),We=o("Likewise, if your "),Si=a("code"),Bn=o("NewModel"),gL=o(" is a subclass of "),In=a("a"),Nn=o("PreTrainedModel"),hL=o(`, make sure its
`),Ri=a("code"),qn=o("config_class"),pL=o(` attribute is set to the same class you use when registering the model (here
`),Pi=a("code"),Nf=o("NewModelConfig"),Sa=o(")."),this.h()},l(He){g=n(He,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var HS=s(p);m=r(HS,"NewModelConfig"),HS.forEach(t),_=r(Ae," is a subclass of "),c=n(Ae,"CODE",{});var Bi=s(c);h=r(Bi,"PretrainedConfig"),Bi.forEach(t),wo=r(Ae,`, make sure its
`),xi=n(Ae,"CODE",{});var US=s(xi);Bf=r(US,"model_type"),US.forEach(t),lt=r(Ae," attribute is set to the same key you use when registering the config (here "),$i=n(Ae,"CODE",{});var JS=s($i);ki=r(JS,'"new-model"'),JS.forEach(t),mL=r(Ae,")."),Ae.forEach(t),If=i(He),Oe=n(He,"P",{});var Ao=s(Oe);We=r(Ao,"Likewise, if your "),Si=n(Ao,"CODE",{});var Ra=s(Si);Bn=r(Ra,"NewModel"),Ra.forEach(t),gL=r(Ao," is a subclass of "),In=n(Ao,"A",{href:!0});var YS=s(In);Nn=r(YS,"PreTrainedModel"),YS.forEach(t),hL=r(Ao,`, make sure its
`),Ri=n(Ao,"CODE",{});var qf=s(Ri);qn=r(qf,"config_class"),qf.forEach(t),pL=r(Ao,` attribute is set to the same class you use when registering the model (here
`),Pi=n(Ao,"CODE",{});var KS=s(Pi);Nf=r(KS,"NewModelConfig"),KS.forEach(t),Sa=r(Ao,")."),Ao.forEach(t),this.h()},h(){d(In,"href","/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel")},m(He,Ae){b(He,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,c),e(c,h),e(g,wo),e(g,xi),e(xi,Bf),e(g,lt),e(g,$i),e($i,ki),e(g,mL),b(He,If,Ae),b(He,Oe,Ae),e(Oe,We),e(Oe,Si),e(Si,Bn),e(Oe,gL),e(Oe,In),e(In,Nn),e(Oe,hL),e(Oe,Ri),e(Ri,qn),e(Oe,pL),e(Oe,Pi),e(Pi,Nf),e(Oe,Sa)},d(He){He&&t(g),He&&t(If),He&&t(Oe)}}}function ZHt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function eUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function oUt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var wo=s(p);m=r(wo,"use_auth_token=True"),wo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(c,h){b(c,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(c){c&&t(g)}}}function rUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function tUt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var wo=s(p);m=r(wo,"use_auth_token=True"),wo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(c,h){b(c,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(c){c&&t(g)}}}function aUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function nUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function sUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function lUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function iUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function dUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function cUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function fUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function mUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function gUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function hUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function pUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function _Ut($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function uUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function bUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function vUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function FUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function TUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function MUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function EUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function CUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function wUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function AUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function LUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function yUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function xUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function $Ut($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function kUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function SUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function RUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function PUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function BUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function IUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function NUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function qUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function jUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function DUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function GUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function OUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function VUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function XUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function zUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function QUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function WUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function HUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function UUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function JUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function YUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function KUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function ZUt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function eJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function oJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function rJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function tJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function aJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function nJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function sJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function lJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function iJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function dJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function cJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function fJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function mJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function gJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function hJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function pJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function _Jt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function uJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function bJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function vJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function FJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function TJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function MJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function EJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function CJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function wJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function AJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function LJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function yJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function xJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function $Jt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function kJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function SJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function RJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function PJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function BJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function IJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function NJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function qJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function jJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function DJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function GJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function OJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function VJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function XJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function zJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function QJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function WJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function HJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function UJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function JJt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(c){g=n(c,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(c),T(m.$$.fragment,c)},m(c,h){b(c,g,h),e(g,v),b(c,p,h),M(m,c,h),_=!0},p:q,i(c){_||(E(m.$$.fragment,c),_=!0)},o(c){C(m.$$.fragment,c),_=!1},d(c){c&&t(g),c&&t(p),w(m,c)}}}function YJt($){let g,v,p,m,_,c,h,wo,xi,Bf,lt,$i,ki,mL,If,Oe,We,Si,Bn,gL,In,Nn,hL,Ri,qn,pL,Pi,Nf,Sa,He,Ae,HS,Bi,US,JS,Ao,Ra,YS,qf,KS,tUe,OXe,Ii,jf,Uae,_L,aUe,Jae,nUe,VXe,jn,sUe,Yae,lUe,iUe,Kae,dUe,cUe,XXe,uL,zXe,ZS,fUe,QXe,Df,WXe,Ni,Gf,Zae,bL,mUe,ene,gUe,HXe,Lo,vL,hUe,FL,pUe,eR,_Ue,uUe,bUe,TL,vUe,one,FUe,TUe,MUe,yr,ML,EUe,rne,CUe,wUe,qi,AUe,tne,LUe,yUe,ane,xUe,$Ue,kUe,A,Of,nne,SUe,RUe,oR,PUe,BUe,IUe,Vf,sne,NUe,qUe,rR,jUe,DUe,GUe,Xf,lne,OUe,VUe,tR,XUe,zUe,QUe,zf,ine,WUe,HUe,aR,UUe,JUe,YUe,Qf,dne,KUe,ZUe,nR,eJe,oJe,rJe,Wf,cne,tJe,aJe,sR,nJe,sJe,lJe,Hf,fne,iJe,dJe,lR,cJe,fJe,mJe,Uf,mne,gJe,hJe,iR,pJe,_Je,uJe,Jf,gne,bJe,vJe,dR,FJe,TJe,MJe,Yf,hne,EJe,CJe,cR,wJe,AJe,LJe,Kf,pne,yJe,xJe,fR,$Je,kJe,SJe,Zf,_ne,RJe,PJe,mR,BJe,IJe,NJe,em,une,qJe,jJe,gR,DJe,GJe,OJe,om,bne,VJe,XJe,hR,zJe,QJe,WJe,rm,vne,HJe,UJe,pR,JJe,YJe,KJe,tm,Fne,ZJe,eYe,_R,oYe,rYe,tYe,am,Tne,aYe,nYe,uR,sYe,lYe,iYe,nm,Mne,dYe,cYe,bR,fYe,mYe,gYe,sm,Ene,hYe,pYe,vR,_Ye,uYe,bYe,lm,Cne,vYe,FYe,FR,TYe,MYe,EYe,im,wne,CYe,wYe,TR,AYe,LYe,yYe,dm,Ane,xYe,$Ye,MR,kYe,SYe,RYe,cm,Lne,PYe,BYe,ER,IYe,NYe,qYe,fm,yne,jYe,DYe,CR,GYe,OYe,VYe,mm,xne,XYe,zYe,wR,QYe,WYe,HYe,gm,$ne,UYe,JYe,AR,YYe,KYe,ZYe,hm,kne,eKe,oKe,LR,rKe,tKe,aKe,pm,Sne,nKe,sKe,yR,lKe,iKe,dKe,_m,Rne,cKe,fKe,xR,mKe,gKe,hKe,um,Pne,pKe,_Ke,$R,uKe,bKe,vKe,bm,Bne,FKe,TKe,kR,MKe,EKe,CKe,vm,Ine,wKe,AKe,SR,LKe,yKe,xKe,Fm,Nne,$Ke,kKe,RR,SKe,RKe,PKe,Tm,qne,BKe,IKe,PR,NKe,qKe,jKe,Mm,jne,DKe,GKe,BR,OKe,VKe,XKe,Em,Dne,zKe,QKe,IR,WKe,HKe,UKe,Cm,Gne,JKe,YKe,NR,KKe,ZKe,eZe,wm,One,oZe,rZe,qR,tZe,aZe,nZe,Am,Vne,sZe,lZe,jR,iZe,dZe,cZe,Lm,Xne,fZe,mZe,DR,gZe,hZe,pZe,ym,zne,_Ze,uZe,GR,bZe,vZe,FZe,xm,Qne,TZe,MZe,OR,EZe,CZe,wZe,$m,Wne,AZe,LZe,VR,yZe,xZe,$Ze,km,Hne,kZe,SZe,XR,RZe,PZe,BZe,Sm,Une,IZe,NZe,zR,qZe,jZe,DZe,Rm,Jne,GZe,OZe,QR,VZe,XZe,zZe,Pm,Yne,QZe,WZe,WR,HZe,UZe,JZe,Bm,Kne,YZe,KZe,HR,ZZe,eeo,oeo,Im,Zne,reo,teo,UR,aeo,neo,seo,Nm,ese,leo,ieo,JR,deo,ceo,feo,qm,ose,meo,geo,YR,heo,peo,_eo,jm,rse,ueo,beo,KR,veo,Feo,Teo,Dm,tse,Meo,Eeo,ZR,Ceo,weo,Aeo,Gm,ase,Leo,yeo,eP,xeo,$eo,keo,Om,nse,Seo,Reo,oP,Peo,Beo,Ieo,Vm,sse,Neo,qeo,rP,jeo,Deo,Geo,Xm,lse,Oeo,Veo,tP,Xeo,zeo,Qeo,zm,ise,Weo,Heo,aP,Ueo,Jeo,Yeo,Qm,dse,Keo,Zeo,nP,eoo,ooo,roo,Wm,cse,too,aoo,sP,noo,soo,loo,Hm,fse,ioo,doo,lP,coo,foo,moo,Um,mse,goo,hoo,iP,poo,_oo,uoo,Jm,gse,boo,voo,dP,Foo,Too,Moo,Ym,hse,Eoo,Coo,cP,woo,Aoo,Loo,Km,pse,yoo,xoo,fP,$oo,koo,Soo,Zm,_se,Roo,Poo,mP,Boo,Ioo,Noo,eg,use,qoo,joo,gP,Doo,Goo,Ooo,og,bse,Voo,Xoo,hP,zoo,Qoo,Woo,rg,vse,Hoo,Uoo,pP,Joo,Yoo,Koo,tg,Fse,Zoo,ero,_P,oro,rro,tro,ag,Tse,aro,nro,uP,sro,lro,iro,ng,Mse,dro,cro,bP,fro,mro,gro,sg,Ese,hro,pro,vP,_ro,uro,bro,lg,Cse,vro,Fro,FP,Tro,Mro,Ero,ig,wse,Cro,wro,TP,Aro,Lro,yro,dg,Ase,xro,$ro,MP,kro,Sro,Rro,cg,Lse,Pro,Bro,EP,Iro,Nro,qro,fg,yse,jro,Dro,CP,Gro,Oro,Vro,mg,xse,Xro,zro,wP,Qro,Wro,Hro,gg,$se,Uro,Jro,AP,Yro,Kro,Zro,hg,kse,eto,oto,LP,rto,tto,ato,pg,Sse,nto,sto,yP,lto,ito,dto,_g,Rse,cto,fto,xP,mto,gto,hto,ug,Pse,pto,_to,$P,uto,bto,vto,bg,Bse,Fto,Tto,kP,Mto,Eto,Cto,vg,Ise,wto,Ato,SP,Lto,yto,xto,Fg,Nse,$to,kto,RP,Sto,Rto,Pto,Tg,qse,Bto,Ito,PP,Nto,qto,jto,Mg,jse,Dto,Gto,BP,Oto,Vto,Xto,Eg,Dse,zto,Qto,IP,Wto,Hto,Uto,Cg,Gse,Jto,Yto,NP,Kto,Zto,eao,wg,Ose,oao,rao,qP,tao,aao,nao,Ag,Vse,sao,lao,jP,iao,dao,cao,Lg,Xse,fao,mao,DP,gao,hao,pao,yg,zse,_ao,uao,GP,bao,vao,Fao,xg,Qse,Tao,Mao,OP,Eao,Cao,wao,$g,Wse,Aao,Lao,VP,yao,xao,$ao,kg,Hse,kao,Sao,XP,Rao,Pao,Bao,Sg,Use,Iao,Nao,zP,qao,jao,Dao,Rg,Jse,Gao,Oao,QP,Vao,Xao,zao,Pg,Yse,Qao,Wao,WP,Hao,Uao,Jao,Bg,Kse,Yao,Kao,HP,Zao,eno,ono,Ig,Zse,rno,tno,UP,ano,nno,sno,Ng,ele,lno,ino,JP,dno,cno,fno,qg,ole,mno,gno,YP,hno,pno,_no,jg,rle,uno,bno,KP,vno,Fno,Tno,Dg,tle,Mno,Eno,ZP,Cno,wno,Ano,Gg,ale,Lno,yno,eB,xno,$no,kno,Og,nle,Sno,Rno,oB,Pno,Bno,Ino,Vg,sle,Nno,qno,rB,jno,Dno,Gno,Xg,lle,Ono,Vno,tB,Xno,zno,Qno,zg,ile,Wno,Hno,aB,Uno,Jno,Yno,Qg,dle,Kno,Zno,nB,eso,oso,rso,Wg,cle,tso,aso,sB,nso,sso,lso,Hg,fle,iso,dso,lB,cso,fso,mso,Ug,mle,gso,hso,iB,pso,_so,uso,Jg,gle,bso,vso,dB,Fso,Tso,Mso,Yg,hle,Eso,Cso,cB,wso,Aso,Lso,Kg,ple,yso,xso,fB,$so,kso,Sso,Zg,Rso,eh,EL,Pso,_le,Bso,UXe,ji,oh,ule,CL,Iso,ble,Nso,JXe,yo,wL,qso,AL,jso,mB,Dso,Gso,Oso,LL,Vso,vle,Xso,zso,Qso,xr,yL,Wso,Fle,Hso,Uso,Pa,Jso,Tle,Yso,Kso,Mle,Zso,elo,Ele,olo,rlo,tlo,k,Dn,Cle,alo,nlo,gB,slo,llo,hB,ilo,dlo,clo,Gn,wle,flo,mlo,pB,glo,hlo,_B,plo,_lo,ulo,On,Ale,blo,vlo,uB,Flo,Tlo,bB,Mlo,Elo,Clo,rh,Lle,wlo,Alo,vB,Llo,ylo,xlo,Vn,yle,$lo,klo,FB,Slo,Rlo,TB,Plo,Blo,Ilo,th,xle,Nlo,qlo,MB,jlo,Dlo,Glo,ah,$le,Olo,Vlo,EB,Xlo,zlo,Qlo,nh,kle,Wlo,Hlo,CB,Ulo,Jlo,Ylo,Xn,Sle,Klo,Zlo,wB,eio,oio,AB,rio,tio,aio,zn,Rle,nio,sio,LB,lio,iio,yB,dio,cio,fio,Qn,Ple,mio,gio,xB,hio,pio,$B,_io,uio,bio,sh,Ble,vio,Fio,kB,Tio,Mio,Eio,lh,Ile,Cio,wio,SB,Aio,Lio,yio,ih,Nle,xio,$io,RB,kio,Sio,Rio,Wn,qle,Pio,Bio,PB,Iio,Nio,BB,qio,jio,Dio,dh,jle,Gio,Oio,IB,Vio,Xio,zio,Hn,Dle,Qio,Wio,NB,Hio,Uio,qB,Jio,Yio,Kio,Un,Gle,Zio,edo,jB,odo,rdo,DB,tdo,ado,ndo,Jn,Ole,sdo,ldo,GB,ido,ddo,OB,cdo,fdo,mdo,Yn,Vle,gdo,hdo,VB,pdo,_do,XB,udo,bdo,vdo,ch,Xle,Fdo,Tdo,zB,Mdo,Edo,Cdo,Kn,zle,wdo,Ado,QB,Ldo,ydo,WB,xdo,$do,kdo,Zn,Qle,Sdo,Rdo,HB,Pdo,Bdo,UB,Ido,Ndo,qdo,es,Wle,jdo,Ddo,JB,Gdo,Odo,YB,Vdo,Xdo,zdo,os,Hle,Qdo,Wdo,KB,Hdo,Udo,ZB,Jdo,Ydo,Kdo,rs,Ule,Zdo,eco,eI,oco,rco,oI,tco,aco,nco,ts,Jle,sco,lco,rI,ico,dco,tI,cco,fco,mco,fh,Yle,gco,hco,aI,pco,_co,uco,as,Kle,bco,vco,nI,Fco,Tco,sI,Mco,Eco,Cco,mh,Zle,wco,Aco,lI,Lco,yco,xco,ns,eie,$co,kco,iI,Sco,Rco,dI,Pco,Bco,Ico,ss,oie,Nco,qco,cI,jco,Dco,fI,Gco,Oco,Vco,ls,rie,Xco,zco,mI,Qco,Wco,gI,Hco,Uco,Jco,gh,tie,Yco,Kco,hI,Zco,efo,ofo,is,aie,rfo,tfo,pI,afo,nfo,_I,sfo,lfo,ifo,ds,nie,dfo,cfo,uI,ffo,mfo,bI,gfo,hfo,pfo,cs,sie,_fo,ufo,vI,bfo,vfo,FI,Ffo,Tfo,Mfo,hh,lie,Efo,Cfo,TI,wfo,Afo,Lfo,fs,iie,yfo,xfo,MI,$fo,kfo,EI,Sfo,Rfo,Pfo,ms,die,Bfo,Ifo,CI,Nfo,qfo,wI,jfo,Dfo,Gfo,gs,cie,Ofo,Vfo,AI,Xfo,zfo,LI,Qfo,Wfo,Hfo,hs,fie,Ufo,Jfo,yI,Yfo,Kfo,xI,Zfo,emo,omo,ps,mie,rmo,tmo,$I,amo,nmo,kI,smo,lmo,imo,_s,gie,dmo,cmo,SI,fmo,mmo,RI,gmo,hmo,pmo,us,hie,_mo,umo,PI,bmo,vmo,BI,Fmo,Tmo,Mmo,bs,pie,Emo,Cmo,II,wmo,Amo,NI,Lmo,ymo,xmo,ph,_ie,$mo,kmo,qI,Smo,Rmo,Pmo,vs,uie,Bmo,Imo,jI,Nmo,qmo,DI,jmo,Dmo,Gmo,_h,bie,Omo,Vmo,GI,Xmo,zmo,Qmo,uh,vie,Wmo,Hmo,OI,Umo,Jmo,Ymo,Fs,Fie,Kmo,Zmo,VI,ego,ogo,XI,rgo,tgo,ago,Ts,Tie,ngo,sgo,zI,lgo,igo,QI,dgo,cgo,fgo,Ms,Mie,mgo,ggo,WI,hgo,pgo,HI,_go,ugo,bgo,bh,Eie,vgo,Fgo,UI,Tgo,Mgo,Ego,Es,Cie,Cgo,wgo,JI,Ago,Lgo,YI,ygo,xgo,$go,Cs,wie,kgo,Sgo,KI,Rgo,Pgo,ZI,Bgo,Igo,Ngo,ws,Aie,qgo,jgo,eN,Dgo,Ggo,oN,Ogo,Vgo,Xgo,As,Lie,zgo,Qgo,rN,Wgo,Hgo,tN,Ugo,Jgo,Ygo,Ls,yie,Kgo,Zgo,aN,eho,oho,nN,rho,tho,aho,ys,xie,nho,sho,sN,lho,iho,lN,dho,cho,fho,xs,$ie,mho,gho,iN,hho,pho,dN,_ho,uho,bho,$s,kie,vho,Fho,cN,Tho,Mho,fN,Eho,Cho,who,vh,Sie,Aho,Lho,mN,yho,xho,$ho,ks,Rie,kho,Sho,gN,Rho,Pho,hN,Bho,Iho,Nho,Fh,Pie,qho,jho,pN,Dho,Gho,Oho,Th,Bie,Vho,Xho,_N,zho,Qho,Who,Mh,Iie,Hho,Uho,uN,Jho,Yho,Kho,Eh,Nie,Zho,epo,bN,opo,rpo,tpo,Ss,qie,apo,npo,vN,spo,lpo,FN,ipo,dpo,cpo,Ch,jie,fpo,mpo,TN,gpo,hpo,ppo,Rs,Die,_po,upo,MN,bpo,vpo,EN,Fpo,Tpo,Mpo,Ps,Gie,Epo,Cpo,CN,wpo,Apo,wN,Lpo,ypo,xpo,Bs,Oie,$po,kpo,AN,Spo,Rpo,LN,Ppo,Bpo,Ipo,Is,Vie,Npo,qpo,yN,jpo,Dpo,xN,Gpo,Opo,Vpo,Ns,Xie,Xpo,zpo,$N,Qpo,Wpo,kN,Hpo,Upo,Jpo,qs,zie,Ypo,Kpo,SN,Zpo,e_o,RN,o_o,r_o,t_o,wh,Qie,a_o,n_o,PN,s_o,l_o,i_o,Ah,Wie,d_o,c_o,BN,f_o,m_o,g_o,js,Hie,h_o,p_o,IN,__o,u_o,NN,b_o,v_o,F_o,Ds,Uie,T_o,M_o,qN,E_o,C_o,jN,w_o,A_o,L_o,Gs,Jie,y_o,x_o,DN,$_o,k_o,GN,S_o,R_o,P_o,Lh,Yie,B_o,I_o,ON,N_o,q_o,j_o,yh,Kie,D_o,G_o,VN,O_o,V_o,X_o,xh,Zie,z_o,Q_o,XN,W_o,H_o,U_o,Os,ede,J_o,Y_o,zN,K_o,Z_o,QN,euo,ouo,ruo,Vs,ode,tuo,auo,WN,nuo,suo,HN,luo,iuo,duo,$h,rde,cuo,fuo,UN,muo,guo,huo,kh,tde,puo,_uo,JN,uuo,buo,vuo,Sh,ade,Fuo,Tuo,YN,Muo,Euo,Cuo,Xs,nde,wuo,Auo,KN,Luo,yuo,ZN,xuo,$uo,kuo,Rh,sde,Suo,Ruo,eq,Puo,Buo,Iuo,Ph,lde,Nuo,quo,oq,juo,Duo,Guo,zs,ide,Ouo,Vuo,rq,Xuo,zuo,tq,Quo,Wuo,Huo,Qs,dde,Uuo,Juo,aq,Yuo,Kuo,nq,Zuo,e1o,o1o,Ws,cde,r1o,t1o,sq,a1o,n1o,lq,s1o,l1o,i1o,Hs,fde,d1o,c1o,iq,f1o,m1o,dq,g1o,h1o,p1o,Bh,_1o,Ih,xL,u1o,mde,b1o,YXe,Di,Nh,gde,$L,v1o,hde,F1o,KXe,xo,kL,T1o,SL,M1o,cq,E1o,C1o,w1o,RL,A1o,pde,L1o,y1o,x1o,Ue,PL,$1o,_de,k1o,S1o,Ba,R1o,ude,P1o,B1o,bde,I1o,N1o,vde,q1o,j1o,D1o,J,qh,Fde,G1o,O1o,fq,V1o,X1o,z1o,jh,Tde,Q1o,W1o,mq,H1o,U1o,J1o,Dh,Mde,Y1o,K1o,gq,Z1o,e4o,o4o,Gh,Ede,r4o,t4o,hq,a4o,n4o,s4o,Oh,Cde,l4o,i4o,pq,d4o,c4o,f4o,Vh,wde,m4o,g4o,_q,h4o,p4o,_4o,Xh,Ade,u4o,b4o,uq,v4o,F4o,T4o,zh,Lde,M4o,E4o,bq,C4o,w4o,A4o,Qh,yde,L4o,y4o,vq,x4o,$4o,k4o,Wh,xde,S4o,R4o,Fq,P4o,B4o,I4o,Hh,$de,N4o,q4o,Tq,j4o,D4o,G4o,Uh,kde,O4o,V4o,Mq,X4o,z4o,Q4o,Jh,Sde,W4o,H4o,Eq,U4o,J4o,Y4o,Yh,Rde,K4o,Z4o,Cq,e2o,o2o,r2o,Kh,Pde,t2o,a2o,wq,n2o,s2o,l2o,Zh,Bde,i2o,d2o,Aq,c2o,f2o,m2o,ep,Ide,g2o,h2o,Lq,p2o,_2o,u2o,op,Nde,b2o,v2o,yq,F2o,T2o,M2o,rp,qde,E2o,C2o,xq,w2o,A2o,L2o,tp,jde,y2o,x2o,$q,$2o,k2o,S2o,ap,Dde,R2o,P2o,kq,B2o,I2o,N2o,np,Gde,q2o,j2o,Sq,D2o,G2o,O2o,sp,Ode,V2o,X2o,Rq,z2o,Q2o,W2o,lp,Vde,H2o,U2o,Pq,J2o,Y2o,K2o,ip,Xde,Z2o,ebo,Bq,obo,rbo,tbo,dp,zde,abo,nbo,Iq,sbo,lbo,ibo,cp,Qde,dbo,cbo,Nq,fbo,mbo,gbo,fp,Wde,hbo,pbo,qq,_bo,ubo,bbo,mp,Hde,vbo,Fbo,jq,Tbo,Mbo,Ebo,gp,Ude,Cbo,wbo,Dq,Abo,Lbo,ybo,hp,Jde,xbo,$bo,Gq,kbo,Sbo,Rbo,pp,Yde,Pbo,Bbo,Oq,Ibo,Nbo,qbo,_p,Kde,jbo,Dbo,Vq,Gbo,Obo,Vbo,up,Zde,Xbo,zbo,Xq,Qbo,Wbo,Hbo,bp,ece,Ubo,Jbo,zq,Ybo,Kbo,Zbo,vp,evo,Fp,ovo,Tp,BL,rvo,oce,tvo,ZXe,Gi,Mp,rce,IL,avo,tce,nvo,eze,$o,NL,svo,qL,lvo,Qq,ivo,dvo,cvo,jL,fvo,ace,mvo,gvo,hvo,Je,DL,pvo,nce,_vo,uvo,Oi,bvo,sce,vvo,Fvo,lce,Tvo,Mvo,Evo,pe,Ep,ice,Cvo,wvo,Wq,Avo,Lvo,yvo,Cp,dce,xvo,$vo,Hq,kvo,Svo,Rvo,wp,cce,Pvo,Bvo,Uq,Ivo,Nvo,qvo,Ap,fce,jvo,Dvo,Jq,Gvo,Ovo,Vvo,Lp,mce,Xvo,zvo,Yq,Qvo,Wvo,Hvo,yp,gce,Uvo,Jvo,Kq,Yvo,Kvo,Zvo,xp,hce,eFo,oFo,Zq,rFo,tFo,aFo,$p,pce,nFo,sFo,ej,lFo,iFo,dFo,kp,_ce,cFo,fFo,oj,mFo,gFo,hFo,Sp,uce,pFo,_Fo,rj,uFo,bFo,vFo,Rp,bce,FFo,TFo,tj,MFo,EFo,CFo,Pp,vce,wFo,AFo,aj,LFo,yFo,xFo,Bp,Fce,$Fo,kFo,nj,SFo,RFo,PFo,Ip,Tce,BFo,IFo,sj,NFo,qFo,jFo,Np,Mce,DFo,GFo,lj,OFo,VFo,XFo,qp,Ece,zFo,QFo,ij,WFo,HFo,UFo,jp,Cce,JFo,YFo,dj,KFo,ZFo,e6o,Dp,wce,o6o,r6o,cj,t6o,a6o,n6o,Gp,s6o,Op,l6o,Vp,GL,i6o,Ace,d6o,oze,Vi,Xp,Lce,OL,c6o,yce,f6o,rze,ko,VL,m6o,Xi,g6o,fj,h6o,p6o,mj,_6o,u6o,b6o,XL,v6o,xce,F6o,T6o,M6o,it,zL,E6o,$ce,C6o,w6o,zi,A6o,kce,L6o,y6o,gj,x6o,$6o,k6o,zp,S6o,Ye,QL,R6o,Sce,P6o,B6o,Ia,I6o,Rce,N6o,q6o,Pce,j6o,D6o,Bce,G6o,O6o,V6o,y,Qp,Ice,X6o,z6o,hj,Q6o,W6o,H6o,Wp,Nce,U6o,J6o,pj,Y6o,K6o,Z6o,Hp,qce,eTo,oTo,_j,rTo,tTo,aTo,Up,jce,nTo,sTo,uj,lTo,iTo,dTo,Jp,Dce,cTo,fTo,bj,mTo,gTo,hTo,Yp,Gce,pTo,_To,vj,uTo,bTo,vTo,Kp,Oce,FTo,TTo,Fj,MTo,ETo,CTo,Zp,Vce,wTo,ATo,Tj,LTo,yTo,xTo,e_,Xce,$To,kTo,Mj,STo,RTo,PTo,o_,zce,BTo,ITo,Ej,NTo,qTo,jTo,r_,Qce,DTo,GTo,Cj,OTo,VTo,XTo,t_,Wce,zTo,QTo,wj,WTo,HTo,UTo,a_,Hce,JTo,YTo,Aj,KTo,ZTo,e7o,n_,Uce,o7o,r7o,Lj,t7o,a7o,n7o,s_,Jce,s7o,l7o,yj,i7o,d7o,c7o,l_,Yce,f7o,m7o,xj,g7o,h7o,p7o,i_,Kce,_7o,u7o,$j,b7o,v7o,F7o,d_,Zce,T7o,M7o,kj,E7o,C7o,w7o,c_,efe,A7o,L7o,Sj,y7o,x7o,$7o,f_,ofe,k7o,S7o,Rj,R7o,P7o,B7o,m_,rfe,I7o,N7o,Pj,q7o,j7o,D7o,g_,tfe,G7o,O7o,Bj,V7o,X7o,z7o,h_,afe,Q7o,W7o,Ij,H7o,U7o,J7o,p_,nfe,Y7o,K7o,Nj,Z7o,e9o,o9o,__,sfe,r9o,t9o,qj,a9o,n9o,s9o,u_,lfe,l9o,i9o,jj,d9o,c9o,f9o,b_,ife,m9o,g9o,Dj,h9o,p9o,_9o,v_,dfe,u9o,b9o,Gj,v9o,F9o,T9o,F_,cfe,M9o,E9o,Oj,C9o,w9o,A9o,T_,ffe,L9o,y9o,Vj,x9o,$9o,k9o,M_,mfe,S9o,R9o,Xj,P9o,B9o,I9o,E_,gfe,N9o,q9o,zj,j9o,D9o,G9o,C_,hfe,O9o,V9o,Qj,X9o,z9o,Q9o,w_,pfe,W9o,H9o,Wj,U9o,J9o,Y9o,Us,_fe,K9o,Z9o,Hj,eMo,oMo,Uj,rMo,tMo,aMo,A_,ufe,nMo,sMo,Jj,lMo,iMo,dMo,L_,bfe,cMo,fMo,Yj,mMo,gMo,hMo,y_,vfe,pMo,_Mo,Kj,uMo,bMo,vMo,x_,Ffe,FMo,TMo,Zj,MMo,EMo,CMo,$_,Tfe,wMo,AMo,eD,LMo,yMo,xMo,k_,Mfe,$Mo,kMo,oD,SMo,RMo,PMo,S_,Efe,BMo,IMo,rD,NMo,qMo,jMo,R_,Cfe,DMo,GMo,tD,OMo,VMo,XMo,P_,wfe,zMo,QMo,aD,WMo,HMo,UMo,B_,Afe,JMo,YMo,nD,KMo,ZMo,eEo,I_,Lfe,oEo,rEo,sD,tEo,aEo,nEo,N_,yfe,sEo,lEo,lD,iEo,dEo,cEo,q_,xfe,fEo,mEo,iD,gEo,hEo,pEo,j_,$fe,_Eo,uEo,dD,bEo,vEo,FEo,D_,kfe,TEo,MEo,cD,EEo,CEo,wEo,G_,Sfe,AEo,LEo,fD,yEo,xEo,$Eo,O_,Rfe,kEo,SEo,mD,REo,PEo,BEo,V_,Pfe,IEo,NEo,gD,qEo,jEo,DEo,X_,Bfe,GEo,OEo,hD,VEo,XEo,zEo,z_,Ife,QEo,WEo,pD,HEo,UEo,JEo,Q_,Nfe,YEo,KEo,_D,ZEo,eCo,oCo,W_,qfe,rCo,tCo,uD,aCo,nCo,sCo,H_,jfe,lCo,iCo,bD,dCo,cCo,fCo,U_,Dfe,mCo,gCo,vD,hCo,pCo,_Co,J_,Gfe,uCo,bCo,FD,vCo,FCo,TCo,Y_,Ofe,MCo,ECo,TD,CCo,wCo,ACo,K_,Vfe,LCo,yCo,MD,xCo,$Co,kCo,Z_,Xfe,SCo,RCo,ED,PCo,BCo,ICo,eu,zfe,NCo,qCo,CD,jCo,DCo,GCo,ou,Qfe,OCo,VCo,wD,XCo,zCo,QCo,ru,Wfe,WCo,HCo,AD,UCo,JCo,YCo,tu,Hfe,KCo,ZCo,LD,e5o,o5o,r5o,au,Ufe,t5o,a5o,yD,n5o,s5o,l5o,nu,Jfe,i5o,d5o,xD,c5o,f5o,m5o,su,Yfe,g5o,h5o,$D,p5o,_5o,u5o,lu,Kfe,b5o,v5o,kD,F5o,T5o,M5o,iu,Zfe,E5o,C5o,SD,w5o,A5o,L5o,du,eme,y5o,x5o,RD,$5o,k5o,S5o,cu,ome,R5o,P5o,PD,B5o,I5o,N5o,fu,rme,q5o,j5o,BD,D5o,G5o,O5o,mu,tme,V5o,X5o,ID,z5o,Q5o,W5o,gu,ame,H5o,U5o,ND,J5o,Y5o,K5o,hu,nme,Z5o,e3o,qD,o3o,r3o,t3o,pu,sme,a3o,n3o,jD,s3o,l3o,i3o,_u,lme,d3o,c3o,DD,f3o,m3o,g3o,uu,ime,h3o,p3o,GD,_3o,u3o,b3o,bu,dme,v3o,F3o,OD,T3o,M3o,E3o,vu,cme,C3o,w3o,VD,A3o,L3o,y3o,Fu,fme,x3o,$3o,XD,k3o,S3o,R3o,Tu,mme,P3o,B3o,zD,I3o,N3o,q3o,Mu,gme,j3o,D3o,QD,G3o,O3o,V3o,Eu,hme,X3o,z3o,WD,Q3o,W3o,H3o,Cu,pme,U3o,J3o,HD,Y3o,K3o,Z3o,wu,_me,e0o,o0o,UD,r0o,t0o,a0o,Au,ume,n0o,s0o,JD,l0o,i0o,d0o,Lu,bme,c0o,f0o,YD,m0o,g0o,h0o,yu,vme,p0o,_0o,KD,u0o,b0o,v0o,xu,Fme,F0o,T0o,ZD,M0o,E0o,C0o,$u,Tme,w0o,A0o,eG,L0o,y0o,x0o,ku,Mme,$0o,k0o,oG,S0o,R0o,P0o,Su,Eme,B0o,I0o,rG,N0o,q0o,j0o,Ru,Cme,D0o,G0o,tG,O0o,V0o,X0o,Pu,wme,z0o,Q0o,aG,W0o,H0o,U0o,Bu,Ame,J0o,Y0o,nG,K0o,Z0o,ewo,Iu,Lme,owo,rwo,sG,two,awo,nwo,Nu,yme,swo,lwo,lG,iwo,dwo,cwo,qu,xme,fwo,mwo,iG,gwo,hwo,pwo,ju,$me,_wo,uwo,dG,bwo,vwo,Fwo,Du,kme,Two,Mwo,cG,Ewo,Cwo,wwo,Gu,Sme,Awo,Lwo,fG,ywo,xwo,$wo,Ou,Rme,kwo,Swo,mG,Rwo,Pwo,Bwo,Vu,Pme,Iwo,Nwo,gG,qwo,jwo,Dwo,Xu,Bme,Gwo,Owo,hG,Vwo,Xwo,zwo,zu,Ime,Qwo,Wwo,pG,Hwo,Uwo,Jwo,Qu,Nme,Ywo,Kwo,_G,Zwo,eAo,oAo,Wu,qme,rAo,tAo,uG,aAo,nAo,sAo,Hu,jme,lAo,iAo,bG,dAo,cAo,fAo,Uu,Dme,mAo,gAo,vG,hAo,pAo,_Ao,Ju,uAo,Gme,bAo,vAo,Ome,FAo,TAo,Yu,tze,Qi,Ku,Vme,WL,MAo,Xme,EAo,aze,So,HL,CAo,Wi,wAo,FG,AAo,LAo,TG,yAo,xAo,$Ao,UL,kAo,zme,SAo,RAo,PAo,dt,JL,BAo,Qme,IAo,NAo,Hi,qAo,Wme,jAo,DAo,MG,GAo,OAo,VAo,Zu,XAo,Ke,YL,zAo,Hme,QAo,WAo,Na,HAo,Ume,UAo,JAo,Jme,YAo,KAo,Yme,ZAo,eLo,oLo,G,e1,Kme,rLo,tLo,EG,aLo,nLo,sLo,o1,Zme,lLo,iLo,CG,dLo,cLo,fLo,r1,ege,mLo,gLo,wG,hLo,pLo,_Lo,t1,oge,uLo,bLo,AG,vLo,FLo,TLo,a1,rge,MLo,ELo,LG,CLo,wLo,ALo,n1,tge,LLo,yLo,yG,xLo,$Lo,kLo,s1,age,SLo,RLo,xG,PLo,BLo,ILo,l1,nge,NLo,qLo,$G,jLo,DLo,GLo,i1,sge,OLo,VLo,kG,XLo,zLo,QLo,d1,lge,WLo,HLo,SG,ULo,JLo,YLo,c1,ige,KLo,ZLo,RG,eyo,oyo,ryo,f1,dge,tyo,ayo,PG,nyo,syo,lyo,m1,cge,iyo,dyo,BG,cyo,fyo,myo,g1,fge,gyo,hyo,IG,pyo,_yo,uyo,h1,mge,byo,vyo,NG,Fyo,Tyo,Myo,p1,gge,Eyo,Cyo,qG,wyo,Ayo,Lyo,_1,hge,yyo,xyo,jG,$yo,kyo,Syo,u1,pge,Ryo,Pyo,DG,Byo,Iyo,Nyo,b1,_ge,qyo,jyo,GG,Dyo,Gyo,Oyo,v1,uge,Vyo,Xyo,OG,zyo,Qyo,Wyo,F1,bge,Hyo,Uyo,VG,Jyo,Yyo,Kyo,T1,vge,Zyo,e8o,XG,o8o,r8o,t8o,M1,Fge,a8o,n8o,zG,s8o,l8o,i8o,E1,Tge,d8o,c8o,QG,f8o,m8o,g8o,C1,Mge,h8o,p8o,WG,_8o,u8o,b8o,w1,Ege,v8o,F8o,HG,T8o,M8o,E8o,A1,Cge,C8o,w8o,UG,A8o,L8o,y8o,L1,wge,x8o,$8o,JG,k8o,S8o,R8o,y1,Age,P8o,B8o,YG,I8o,N8o,q8o,x1,Lge,j8o,D8o,KG,G8o,O8o,V8o,$1,yge,X8o,z8o,ZG,Q8o,W8o,H8o,k1,xge,U8o,J8o,eO,Y8o,K8o,Z8o,S1,$ge,exo,oxo,oO,rxo,txo,axo,R1,kge,nxo,sxo,rO,lxo,ixo,dxo,P1,Sge,cxo,fxo,tO,mxo,gxo,hxo,B1,Rge,pxo,_xo,aO,uxo,bxo,vxo,I1,Pge,Fxo,Txo,nO,Mxo,Exo,Cxo,N1,Bge,wxo,Axo,sO,Lxo,yxo,xxo,q1,Ige,$xo,kxo,lO,Sxo,Rxo,Pxo,j1,Nge,Bxo,Ixo,iO,Nxo,qxo,jxo,D1,qge,Dxo,Gxo,dO,Oxo,Vxo,Xxo,G1,jge,zxo,Qxo,cO,Wxo,Hxo,Uxo,O1,Dge,Jxo,Yxo,fO,Kxo,Zxo,e$o,V1,Gge,o$o,r$o,mO,t$o,a$o,n$o,X1,Oge,s$o,l$o,gO,i$o,d$o,c$o,z1,f$o,Vge,m$o,g$o,Xge,h$o,p$o,Q1,nze,Ui,W1,zge,KL,_$o,Qge,u$o,sze,Ro,ZL,b$o,Ji,v$o,hO,F$o,T$o,pO,M$o,E$o,C$o,ey,w$o,Wge,A$o,L$o,y$o,ct,oy,x$o,Hge,$$o,k$o,Yi,S$o,Uge,R$o,P$o,_O,B$o,I$o,N$o,H1,q$o,Ze,ry,j$o,Jge,D$o,G$o,qa,O$o,Yge,V$o,X$o,Kge,z$o,Q$o,Zge,W$o,H$o,U$o,z,U1,ehe,J$o,Y$o,uO,K$o,Z$o,eko,J1,ohe,oko,rko,bO,tko,ako,nko,Y1,rhe,sko,lko,vO,iko,dko,cko,K1,the,fko,mko,FO,gko,hko,pko,Z1,ahe,_ko,uko,TO,bko,vko,Fko,e4,nhe,Tko,Mko,MO,Eko,Cko,wko,o4,she,Ako,Lko,EO,yko,xko,$ko,r4,lhe,kko,Sko,CO,Rko,Pko,Bko,t4,ihe,Iko,Nko,wO,qko,jko,Dko,a4,dhe,Gko,Oko,AO,Vko,Xko,zko,n4,che,Qko,Wko,LO,Hko,Uko,Jko,s4,fhe,Yko,Kko,yO,Zko,eSo,oSo,l4,mhe,rSo,tSo,xO,aSo,nSo,sSo,i4,ghe,lSo,iSo,$O,dSo,cSo,fSo,d4,hhe,mSo,gSo,kO,hSo,pSo,_So,c4,phe,uSo,bSo,SO,vSo,FSo,TSo,f4,_he,MSo,ESo,RO,CSo,wSo,ASo,m4,uhe,LSo,ySo,PO,xSo,$So,kSo,g4,bhe,SSo,RSo,BO,PSo,BSo,ISo,h4,vhe,NSo,qSo,IO,jSo,DSo,GSo,p4,Fhe,OSo,VSo,NO,XSo,zSo,QSo,_4,The,WSo,HSo,qO,USo,JSo,YSo,u4,Mhe,KSo,ZSo,jO,eRo,oRo,rRo,b4,Ehe,tRo,aRo,DO,nRo,sRo,lRo,v4,Che,iRo,dRo,GO,cRo,fRo,mRo,F4,whe,gRo,hRo,OO,pRo,_Ro,uRo,T4,Ahe,bRo,vRo,VO,FRo,TRo,MRo,M4,Lhe,ERo,CRo,XO,wRo,ARo,LRo,E4,yhe,yRo,xRo,zO,$Ro,kRo,SRo,C4,xhe,RRo,PRo,QO,BRo,IRo,NRo,w4,$he,qRo,jRo,WO,DRo,GRo,ORo,A4,khe,VRo,XRo,HO,zRo,QRo,WRo,L4,She,HRo,URo,UO,JRo,YRo,KRo,y4,Rhe,ZRo,ePo,JO,oPo,rPo,tPo,x4,Phe,aPo,nPo,YO,sPo,lPo,iPo,$4,Bhe,dPo,cPo,KO,fPo,mPo,gPo,k4,Ihe,hPo,pPo,ZO,_Po,uPo,bPo,S4,Nhe,vPo,FPo,eV,TPo,MPo,EPo,R4,qhe,CPo,wPo,oV,APo,LPo,yPo,P4,jhe,xPo,$Po,rV,kPo,SPo,RPo,B4,PPo,Dhe,BPo,IPo,Ghe,NPo,qPo,I4,lze,Ki,N4,Ohe,ty,jPo,Vhe,DPo,ize,Po,ay,GPo,Zi,OPo,tV,VPo,XPo,aV,zPo,QPo,WPo,ny,HPo,Xhe,UPo,JPo,YPo,ft,sy,KPo,zhe,ZPo,eBo,ed,oBo,Qhe,rBo,tBo,nV,aBo,nBo,sBo,q4,lBo,eo,ly,iBo,Whe,dBo,cBo,ja,fBo,Hhe,mBo,gBo,Uhe,hBo,pBo,Jhe,_Bo,uBo,bBo,W,j4,Yhe,vBo,FBo,sV,TBo,MBo,EBo,D4,Khe,CBo,wBo,lV,ABo,LBo,yBo,G4,Zhe,xBo,$Bo,iV,kBo,SBo,RBo,O4,epe,PBo,BBo,dV,IBo,NBo,qBo,V4,ope,jBo,DBo,cV,GBo,OBo,VBo,X4,rpe,XBo,zBo,fV,QBo,WBo,HBo,z4,tpe,UBo,JBo,mV,YBo,KBo,ZBo,Q4,ape,eIo,oIo,gV,rIo,tIo,aIo,W4,npe,nIo,sIo,hV,lIo,iIo,dIo,H4,spe,cIo,fIo,pV,mIo,gIo,hIo,U4,lpe,pIo,_Io,_V,uIo,bIo,vIo,J4,ipe,FIo,TIo,uV,MIo,EIo,CIo,Y4,dpe,wIo,AIo,bV,LIo,yIo,xIo,K4,cpe,$Io,kIo,vV,SIo,RIo,PIo,Z4,fpe,BIo,IIo,FV,NIo,qIo,jIo,e2,mpe,DIo,GIo,TV,OIo,VIo,XIo,o2,gpe,zIo,QIo,MV,WIo,HIo,UIo,r2,hpe,JIo,YIo,EV,KIo,ZIo,eNo,t2,ppe,oNo,rNo,CV,tNo,aNo,nNo,a2,_pe,sNo,lNo,wV,iNo,dNo,cNo,n2,upe,fNo,mNo,AV,gNo,hNo,pNo,s2,bpe,_No,uNo,LV,bNo,vNo,FNo,l2,vpe,TNo,MNo,yV,ENo,CNo,wNo,i2,Fpe,ANo,LNo,xV,yNo,xNo,$No,d2,Tpe,kNo,SNo,$V,RNo,PNo,BNo,c2,Mpe,INo,NNo,kV,qNo,jNo,DNo,f2,Epe,GNo,ONo,SV,VNo,XNo,zNo,m2,Cpe,QNo,WNo,RV,HNo,UNo,JNo,g2,wpe,YNo,KNo,PV,ZNo,eqo,oqo,h2,Ape,rqo,tqo,BV,aqo,nqo,sqo,p2,Lpe,lqo,iqo,IV,dqo,cqo,fqo,_2,ype,mqo,gqo,NV,hqo,pqo,_qo,u2,xpe,uqo,bqo,qV,vqo,Fqo,Tqo,b2,$pe,Mqo,Eqo,kpe,Cqo,wqo,Aqo,v2,Spe,Lqo,yqo,jV,xqo,$qo,kqo,F2,Rpe,Sqo,Rqo,DV,Pqo,Bqo,Iqo,T2,Ppe,Nqo,qqo,GV,jqo,Dqo,Gqo,M2,Bpe,Oqo,Vqo,OV,Xqo,zqo,Qqo,E2,Wqo,Ipe,Hqo,Uqo,Npe,Jqo,Yqo,C2,dze,od,w2,qpe,iy,Kqo,jpe,Zqo,cze,Bo,dy,ejo,rd,ojo,VV,rjo,tjo,XV,ajo,njo,sjo,cy,ljo,Dpe,ijo,djo,cjo,mt,fy,fjo,Gpe,mjo,gjo,td,hjo,Ope,pjo,_jo,zV,ujo,bjo,vjo,A2,Fjo,oo,my,Tjo,Vpe,Mjo,Ejo,Da,Cjo,Xpe,wjo,Ajo,zpe,Ljo,yjo,Qpe,xjo,$jo,kjo,fe,L2,Wpe,Sjo,Rjo,QV,Pjo,Bjo,Ijo,y2,Hpe,Njo,qjo,WV,jjo,Djo,Gjo,x2,Upe,Ojo,Vjo,HV,Xjo,zjo,Qjo,$2,Jpe,Wjo,Hjo,UV,Ujo,Jjo,Yjo,k2,Ype,Kjo,Zjo,JV,eDo,oDo,rDo,S2,Kpe,tDo,aDo,YV,nDo,sDo,lDo,R2,Zpe,iDo,dDo,KV,cDo,fDo,mDo,P2,e_e,gDo,hDo,ZV,pDo,_Do,uDo,B2,o_e,bDo,vDo,eX,FDo,TDo,MDo,I2,r_e,EDo,CDo,oX,wDo,ADo,LDo,N2,t_e,yDo,xDo,rX,$Do,kDo,SDo,q2,a_e,RDo,PDo,tX,BDo,IDo,NDo,j2,n_e,qDo,jDo,aX,DDo,GDo,ODo,D2,s_e,VDo,XDo,nX,zDo,QDo,WDo,G2,l_e,HDo,UDo,sX,JDo,YDo,KDo,O2,i_e,ZDo,eGo,lX,oGo,rGo,tGo,V2,d_e,aGo,nGo,iX,sGo,lGo,iGo,X2,c_e,dGo,cGo,dX,fGo,mGo,gGo,z2,f_e,hGo,pGo,cX,_Go,uGo,bGo,Q2,vGo,m_e,FGo,TGo,g_e,MGo,EGo,W2,fze,ad,H2,h_e,gy,CGo,p_e,wGo,mze,Io,hy,AGo,nd,LGo,fX,yGo,xGo,mX,$Go,kGo,SGo,py,RGo,__e,PGo,BGo,IGo,gt,_y,NGo,u_e,qGo,jGo,sd,DGo,b_e,GGo,OGo,gX,VGo,XGo,zGo,U2,QGo,ro,uy,WGo,v_e,HGo,UGo,Ga,JGo,F_e,YGo,KGo,T_e,ZGo,eOo,M_e,oOo,rOo,tOo,B,J2,E_e,aOo,nOo,hX,sOo,lOo,iOo,Y2,C_e,dOo,cOo,pX,fOo,mOo,gOo,K2,w_e,hOo,pOo,_X,_Oo,uOo,bOo,Z2,A_e,vOo,FOo,uX,TOo,MOo,EOo,eb,L_e,COo,wOo,bX,AOo,LOo,yOo,ob,y_e,xOo,$Oo,vX,kOo,SOo,ROo,rb,x_e,POo,BOo,FX,IOo,NOo,qOo,tb,$_e,jOo,DOo,TX,GOo,OOo,VOo,ab,k_e,XOo,zOo,MX,QOo,WOo,HOo,nb,S_e,UOo,JOo,EX,YOo,KOo,ZOo,sb,R_e,eVo,oVo,CX,rVo,tVo,aVo,lb,P_e,nVo,sVo,wX,lVo,iVo,dVo,ib,B_e,cVo,fVo,AX,mVo,gVo,hVo,db,I_e,pVo,_Vo,LX,uVo,bVo,vVo,cb,N_e,FVo,TVo,yX,MVo,EVo,CVo,fb,q_e,wVo,AVo,xX,LVo,yVo,xVo,mb,j_e,$Vo,kVo,$X,SVo,RVo,PVo,gb,D_e,BVo,IVo,kX,NVo,qVo,jVo,hb,G_e,DVo,GVo,SX,OVo,VVo,XVo,pb,O_e,zVo,QVo,RX,WVo,HVo,UVo,_b,V_e,JVo,YVo,PX,KVo,ZVo,eXo,ub,X_e,oXo,rXo,BX,tXo,aXo,nXo,bb,z_e,sXo,lXo,IX,iXo,dXo,cXo,vb,Q_e,fXo,mXo,NX,gXo,hXo,pXo,Fb,W_e,_Xo,uXo,qX,bXo,vXo,FXo,Tb,H_e,TXo,MXo,jX,EXo,CXo,wXo,Mb,U_e,AXo,LXo,DX,yXo,xXo,$Xo,Eb,J_e,kXo,SXo,GX,RXo,PXo,BXo,Cb,Y_e,IXo,NXo,OX,qXo,jXo,DXo,wb,K_e,GXo,OXo,VX,VXo,XXo,zXo,Ab,Z_e,QXo,WXo,XX,HXo,UXo,JXo,Lb,eue,YXo,KXo,zX,ZXo,ezo,ozo,yb,oue,rzo,tzo,QX,azo,nzo,szo,xb,rue,lzo,izo,WX,dzo,czo,fzo,$b,tue,mzo,gzo,HX,hzo,pzo,_zo,kb,aue,uzo,bzo,UX,vzo,Fzo,Tzo,Sb,nue,Mzo,Ezo,JX,Czo,wzo,Azo,Rb,sue,Lzo,yzo,YX,xzo,$zo,kzo,Pb,lue,Szo,Rzo,KX,Pzo,Bzo,Izo,Bb,iue,Nzo,qzo,ZX,jzo,Dzo,Gzo,Ib,due,Ozo,Vzo,ez,Xzo,zzo,Qzo,Nb,cue,Wzo,Hzo,oz,Uzo,Jzo,Yzo,qb,fue,Kzo,Zzo,rz,eQo,oQo,rQo,jb,mue,tQo,aQo,tz,nQo,sQo,lQo,Db,gue,iQo,dQo,az,cQo,fQo,mQo,Gb,hue,gQo,hQo,nz,pQo,_Qo,uQo,Ob,pue,bQo,vQo,sz,FQo,TQo,MQo,Vb,_ue,EQo,CQo,lz,wQo,AQo,LQo,Xb,uue,yQo,xQo,iz,$Qo,kQo,SQo,zb,bue,RQo,PQo,dz,BQo,IQo,NQo,Qb,vue,qQo,jQo,cz,DQo,GQo,OQo,Wb,VQo,Fue,XQo,zQo,Tue,QQo,WQo,Hb,gze,ld,Ub,Mue,by,HQo,Eue,UQo,hze,No,vy,JQo,id,YQo,fz,KQo,ZQo,mz,eWo,oWo,rWo,Fy,tWo,Cue,aWo,nWo,sWo,ht,Ty,lWo,wue,iWo,dWo,dd,cWo,Aue,fWo,mWo,gz,gWo,hWo,pWo,Jb,_Wo,to,My,uWo,Lue,bWo,vWo,Oa,FWo,yue,TWo,MWo,xue,EWo,CWo,$ue,wWo,AWo,LWo,Z,Yb,kue,yWo,xWo,hz,$Wo,kWo,SWo,Kb,Sue,RWo,PWo,pz,BWo,IWo,NWo,Zb,Rue,qWo,jWo,_z,DWo,GWo,OWo,ev,Pue,VWo,XWo,uz,zWo,QWo,WWo,ov,Bue,HWo,UWo,bz,JWo,YWo,KWo,rv,Iue,ZWo,eHo,vz,oHo,rHo,tHo,tv,Nue,aHo,nHo,Fz,sHo,lHo,iHo,av,que,dHo,cHo,Tz,fHo,mHo,gHo,nv,jue,hHo,pHo,Mz,_Ho,uHo,bHo,sv,Due,vHo,FHo,Ez,THo,MHo,EHo,lv,Gue,CHo,wHo,Cz,AHo,LHo,yHo,iv,Oue,xHo,$Ho,wz,kHo,SHo,RHo,dv,Vue,PHo,BHo,Az,IHo,NHo,qHo,cv,Xue,jHo,DHo,Lz,GHo,OHo,VHo,fv,zue,XHo,zHo,yz,QHo,WHo,HHo,mv,Que,UHo,JHo,xz,YHo,KHo,ZHo,gv,Wue,eUo,oUo,$z,rUo,tUo,aUo,hv,Hue,nUo,sUo,kz,lUo,iUo,dUo,pv,Uue,cUo,fUo,Sz,mUo,gUo,hUo,_v,Jue,pUo,_Uo,Rz,uUo,bUo,vUo,uv,Yue,FUo,TUo,Pz,MUo,EUo,CUo,bv,Kue,wUo,AUo,Bz,LUo,yUo,xUo,vv,Zue,$Uo,kUo,Iz,SUo,RUo,PUo,Fv,e1e,BUo,IUo,Nz,NUo,qUo,jUo,Tv,o1e,DUo,GUo,qz,OUo,VUo,XUo,Mv,r1e,zUo,QUo,jz,WUo,HUo,UUo,Ev,t1e,JUo,YUo,Dz,KUo,ZUo,eJo,Cv,a1e,oJo,rJo,Gz,tJo,aJo,nJo,wv,n1e,sJo,lJo,Oz,iJo,dJo,cJo,Av,s1e,fJo,mJo,Vz,gJo,hJo,pJo,Lv,_Jo,l1e,uJo,bJo,i1e,vJo,FJo,yv,pze,cd,xv,d1e,Ey,TJo,c1e,MJo,_ze,qo,Cy,EJo,fd,CJo,Xz,wJo,AJo,zz,LJo,yJo,xJo,wy,$Jo,f1e,kJo,SJo,RJo,pt,Ay,PJo,m1e,BJo,IJo,md,NJo,g1e,qJo,jJo,Qz,DJo,GJo,OJo,$v,VJo,ao,Ly,XJo,h1e,zJo,QJo,Va,WJo,p1e,HJo,UJo,_1e,JJo,YJo,u1e,KJo,ZJo,eYo,jo,kv,b1e,oYo,rYo,Wz,tYo,aYo,nYo,Sv,v1e,sYo,lYo,Hz,iYo,dYo,cYo,Rv,F1e,fYo,mYo,Uz,gYo,hYo,pYo,Pv,T1e,_Yo,uYo,Jz,bYo,vYo,FYo,Bv,M1e,TYo,MYo,Yz,EYo,CYo,wYo,Iv,E1e,AYo,LYo,Kz,yYo,xYo,$Yo,Nv,kYo,C1e,SYo,RYo,w1e,PYo,BYo,qv,uze,gd,jv,A1e,yy,IYo,L1e,NYo,bze,Do,xy,qYo,hd,jYo,Zz,DYo,GYo,eQ,OYo,VYo,XYo,$y,zYo,y1e,QYo,WYo,HYo,_t,ky,UYo,x1e,JYo,YYo,pd,KYo,$1e,ZYo,eKo,oQ,oKo,rKo,tKo,Dv,aKo,no,Sy,nKo,k1e,sKo,lKo,Xa,iKo,S1e,dKo,cKo,R1e,fKo,mKo,P1e,gKo,hKo,pKo,U,Gv,B1e,_Ko,uKo,rQ,bKo,vKo,FKo,Ov,I1e,TKo,MKo,tQ,EKo,CKo,wKo,Vv,N1e,AKo,LKo,aQ,yKo,xKo,$Ko,Xv,q1e,kKo,SKo,nQ,RKo,PKo,BKo,zv,j1e,IKo,NKo,sQ,qKo,jKo,DKo,Qv,D1e,GKo,OKo,lQ,VKo,XKo,zKo,Wv,G1e,QKo,WKo,iQ,HKo,UKo,JKo,Hv,O1e,YKo,KKo,dQ,ZKo,eZo,oZo,Uv,V1e,rZo,tZo,cQ,aZo,nZo,sZo,Jv,X1e,lZo,iZo,fQ,dZo,cZo,fZo,Yv,z1e,mZo,gZo,mQ,hZo,pZo,_Zo,Kv,Q1e,uZo,bZo,gQ,vZo,FZo,TZo,Zv,W1e,MZo,EZo,hQ,CZo,wZo,AZo,eF,H1e,LZo,yZo,pQ,xZo,$Zo,kZo,oF,U1e,SZo,RZo,_Q,PZo,BZo,IZo,rF,J1e,NZo,qZo,uQ,jZo,DZo,GZo,tF,Y1e,OZo,VZo,bQ,XZo,zZo,QZo,aF,K1e,WZo,HZo,vQ,UZo,JZo,YZo,nF,Z1e,KZo,ZZo,FQ,eer,oer,rer,sF,e4e,ter,aer,TQ,ner,ser,ler,lF,o4e,ier,der,MQ,cer,fer,mer,iF,r4e,ger,her,EQ,per,_er,uer,dF,t4e,ber,ver,CQ,Fer,Ter,Mer,cF,a4e,Eer,Cer,wQ,wer,Aer,Ler,fF,n4e,yer,xer,AQ,$er,ker,Ser,mF,s4e,Rer,Per,LQ,Ber,Ier,Ner,gF,l4e,qer,jer,yQ,Der,Ger,Oer,hF,i4e,Ver,Xer,xQ,zer,Qer,Wer,pF,d4e,Her,Uer,$Q,Jer,Yer,Ker,_F,c4e,Zer,eor,kQ,oor,ror,tor,uF,f4e,aor,nor,SQ,sor,lor,ior,bF,m4e,dor,cor,RQ,mor,gor,hor,vF,g4e,por,_or,PQ,uor,bor,vor,FF,h4e,For,Tor,BQ,Mor,Eor,Cor,TF,p4e,wor,Aor,IQ,Lor,yor,xor,MF,_4e,$or,kor,NQ,Sor,Ror,Por,EF,Bor,u4e,Ior,Nor,b4e,qor,jor,CF,vze,_d,wF,v4e,Ry,Dor,F4e,Gor,Fze,Go,Py,Oor,ud,Vor,qQ,Xor,zor,jQ,Qor,Wor,Hor,By,Uor,T4e,Jor,Yor,Kor,ut,Iy,Zor,M4e,err,orr,bd,rrr,E4e,trr,arr,DQ,nrr,srr,lrr,AF,irr,so,Ny,drr,C4e,crr,frr,za,mrr,w4e,grr,hrr,A4e,prr,_rr,L4e,urr,brr,vrr,V,LF,y4e,Frr,Trr,GQ,Mrr,Err,Crr,yF,x4e,wrr,Arr,OQ,Lrr,yrr,xrr,xF,$4e,$rr,krr,VQ,Srr,Rrr,Prr,$F,k4e,Brr,Irr,XQ,Nrr,qrr,jrr,kF,S4e,Drr,Grr,zQ,Orr,Vrr,Xrr,SF,R4e,zrr,Qrr,QQ,Wrr,Hrr,Urr,RF,P4e,Jrr,Yrr,WQ,Krr,Zrr,etr,PF,B4e,otr,rtr,HQ,ttr,atr,ntr,BF,I4e,str,ltr,UQ,itr,dtr,ctr,IF,N4e,ftr,mtr,JQ,gtr,htr,ptr,NF,q4e,_tr,utr,YQ,btr,vtr,Ftr,qF,j4e,Ttr,Mtr,KQ,Etr,Ctr,wtr,jF,D4e,Atr,Ltr,ZQ,ytr,xtr,$tr,DF,G4e,ktr,Str,eW,Rtr,Ptr,Btr,GF,O4e,Itr,Ntr,oW,qtr,jtr,Dtr,OF,V4e,Gtr,Otr,rW,Vtr,Xtr,ztr,VF,X4e,Qtr,Wtr,tW,Htr,Utr,Jtr,XF,z4e,Ytr,Ktr,aW,Ztr,ear,oar,zF,Q4e,rar,tar,nW,aar,nar,sar,QF,W4e,lar,iar,sW,dar,car,far,WF,H4e,mar,gar,lW,har,par,_ar,HF,U4e,uar,bar,iW,Far,Tar,Mar,UF,J4e,Ear,Car,dW,war,Aar,Lar,JF,Y4e,yar,xar,cW,$ar,kar,Sar,YF,K4e,Rar,Par,fW,Bar,Iar,Nar,KF,Z4e,qar,jar,mW,Dar,Gar,Oar,ZF,e2e,Var,Xar,gW,zar,Qar,War,e6,o2e,Har,Uar,hW,Jar,Yar,Kar,o6,r2e,Zar,enr,pW,onr,rnr,tnr,r6,t2e,anr,nnr,_W,snr,lnr,inr,t6,a2e,dnr,cnr,uW,fnr,mnr,gnr,a6,n2e,hnr,pnr,bW,_nr,unr,bnr,n6,s2e,vnr,Fnr,vW,Tnr,Mnr,Enr,s6,l2e,Cnr,wnr,FW,Anr,Lnr,ynr,l6,i2e,xnr,$nr,TW,knr,Snr,Rnr,i6,d2e,Pnr,Bnr,MW,Inr,Nnr,qnr,d6,c2e,jnr,Dnr,EW,Gnr,Onr,Vnr,c6,f2e,Xnr,znr,CW,Qnr,Wnr,Hnr,f6,m2e,Unr,Jnr,wW,Ynr,Knr,Znr,m6,g2e,esr,osr,AW,rsr,tsr,asr,g6,h2e,nsr,ssr,LW,lsr,isr,dsr,h6,p2e,csr,fsr,yW,msr,gsr,hsr,p6,psr,_2e,_sr,usr,u2e,bsr,vsr,_6,Tze,vd,u6,b2e,qy,Fsr,v2e,Tsr,Mze,Oo,jy,Msr,Fd,Esr,xW,Csr,wsr,$W,Asr,Lsr,ysr,Dy,xsr,F2e,$sr,ksr,Ssr,bt,Gy,Rsr,T2e,Psr,Bsr,Td,Isr,M2e,Nsr,qsr,kW,jsr,Dsr,Gsr,b6,Osr,lo,Oy,Vsr,E2e,Xsr,zsr,Qa,Qsr,C2e,Wsr,Hsr,w2e,Usr,Jsr,A2e,Ysr,Ksr,Zsr,L2e,v6,y2e,elr,olr,SW,rlr,tlr,alr,F6,nlr,x2e,slr,llr,$2e,ilr,dlr,T6,Eze,Md,M6,k2e,Vy,clr,S2e,flr,Cze,Vo,Xy,mlr,Ed,glr,RW,hlr,plr,PW,_lr,ulr,blr,zy,vlr,R2e,Flr,Tlr,Mlr,vt,Qy,Elr,P2e,Clr,wlr,Cd,Alr,B2e,Llr,ylr,BW,xlr,$lr,klr,E6,Slr,io,Wy,Rlr,I2e,Plr,Blr,Wa,Ilr,N2e,Nlr,qlr,q2e,jlr,Dlr,j2e,Glr,Olr,Vlr,ue,C6,D2e,Xlr,zlr,IW,Qlr,Wlr,Hlr,w6,G2e,Ulr,Jlr,NW,Ylr,Klr,Zlr,A6,O2e,eir,oir,qW,rir,tir,air,L6,V2e,nir,sir,jW,lir,iir,dir,Js,X2e,cir,fir,DW,mir,gir,GW,hir,pir,_ir,y6,z2e,uir,bir,OW,vir,Fir,Tir,Ys,Q2e,Mir,Eir,VW,Cir,wir,XW,Air,Lir,yir,x6,W2e,xir,$ir,zW,kir,Sir,Rir,Ft,H2e,Pir,Bir,QW,Iir,Nir,WW,qir,jir,HW,Dir,Gir,Oir,$6,U2e,Vir,Xir,UW,zir,Qir,Wir,k6,J2e,Hir,Uir,JW,Jir,Yir,Kir,S6,Y2e,Zir,edr,YW,odr,rdr,tdr,R6,K2e,adr,ndr,KW,sdr,ldr,idr,P6,Z2e,ddr,cdr,ZW,fdr,mdr,gdr,B6,ebe,hdr,pdr,eH,_dr,udr,bdr,I6,obe,vdr,Fdr,oH,Tdr,Mdr,Edr,N6,rbe,Cdr,wdr,rH,Adr,Ldr,ydr,q6,xdr,tbe,$dr,kdr,abe,Sdr,Rdr,j6,wze,wd,D6,nbe,Hy,Pdr,sbe,Bdr,Aze,Xo,Uy,Idr,Ad,Ndr,tH,qdr,jdr,aH,Ddr,Gdr,Odr,Jy,Vdr,lbe,Xdr,zdr,Qdr,Tt,Yy,Wdr,ibe,Hdr,Udr,Ld,Jdr,dbe,Ydr,Kdr,nH,Zdr,ecr,ocr,G6,rcr,co,Ky,tcr,cbe,acr,ncr,Ha,scr,fbe,lcr,icr,mbe,dcr,ccr,gbe,fcr,mcr,gcr,hbe,O6,pbe,hcr,pcr,sH,_cr,ucr,bcr,V6,vcr,_be,Fcr,Tcr,ube,Mcr,Ecr,X6,Lze,yd,z6,bbe,Zy,Ccr,vbe,wcr,yze,zo,e8,Acr,xd,Lcr,lH,ycr,xcr,iH,$cr,kcr,Scr,o8,Rcr,Fbe,Pcr,Bcr,Icr,Mt,r8,Ncr,Tbe,qcr,jcr,$d,Dcr,Mbe,Gcr,Ocr,dH,Vcr,Xcr,zcr,Q6,Qcr,fo,t8,Wcr,Ebe,Hcr,Ucr,Ua,Jcr,Cbe,Ycr,Kcr,wbe,Zcr,efr,Abe,ofr,rfr,tfr,Lbe,W6,ybe,afr,nfr,cH,sfr,lfr,ifr,H6,dfr,xbe,cfr,ffr,$be,mfr,gfr,U6,xze,kd,J6,kbe,a8,hfr,Sbe,pfr,$ze,Qo,n8,_fr,Sd,ufr,fH,bfr,vfr,mH,Ffr,Tfr,Mfr,s8,Efr,Rbe,Cfr,wfr,Afr,Et,l8,Lfr,Pbe,yfr,xfr,Rd,$fr,Bbe,kfr,Sfr,gH,Rfr,Pfr,Bfr,Y6,Ifr,mo,i8,Nfr,Ibe,qfr,jfr,Ja,Dfr,Nbe,Gfr,Ofr,qbe,Vfr,Xfr,jbe,zfr,Qfr,Wfr,Pe,K6,Dbe,Hfr,Ufr,hH,Jfr,Yfr,Kfr,Z6,Gbe,Zfr,emr,pH,omr,rmr,tmr,eT,Obe,amr,nmr,_H,smr,lmr,imr,oT,Vbe,dmr,cmr,uH,fmr,mmr,gmr,rT,Xbe,hmr,pmr,bH,_mr,umr,bmr,tT,zbe,vmr,Fmr,vH,Tmr,Mmr,Emr,aT,Qbe,Cmr,wmr,FH,Amr,Lmr,ymr,nT,Wbe,xmr,$mr,TH,kmr,Smr,Rmr,sT,Hbe,Pmr,Bmr,MH,Imr,Nmr,qmr,lT,jmr,Ube,Dmr,Gmr,Jbe,Omr,Vmr,iT,kze,Pd,dT,Ybe,d8,Xmr,Kbe,zmr,Sze,Wo,c8,Qmr,Bd,Wmr,EH,Hmr,Umr,CH,Jmr,Ymr,Kmr,f8,Zmr,Zbe,egr,ogr,rgr,Ct,m8,tgr,eve,agr,ngr,Id,sgr,ove,lgr,igr,wH,dgr,cgr,fgr,cT,mgr,go,g8,ggr,rve,hgr,pgr,Ya,_gr,tve,ugr,bgr,ave,vgr,Fgr,nve,Tgr,Mgr,Egr,rt,fT,sve,Cgr,wgr,AH,Agr,Lgr,ygr,mT,lve,xgr,$gr,LH,kgr,Sgr,Rgr,gT,ive,Pgr,Bgr,yH,Igr,Ngr,qgr,hT,dve,jgr,Dgr,xH,Ggr,Ogr,Vgr,pT,cve,Xgr,zgr,$H,Qgr,Wgr,Hgr,_T,Ugr,fve,Jgr,Ygr,mve,Kgr,Zgr,uT,Rze,Nd,bT,gve,h8,ehr,hve,ohr,Pze,Ho,p8,rhr,qd,thr,kH,ahr,nhr,SH,shr,lhr,ihr,_8,dhr,pve,chr,fhr,mhr,wt,u8,ghr,_ve,hhr,phr,jd,_hr,uve,uhr,bhr,RH,vhr,Fhr,Thr,vT,Mhr,ho,b8,Ehr,bve,Chr,whr,Ka,Ahr,vve,Lhr,yhr,Fve,xhr,$hr,Tve,khr,Shr,Rhr,Le,FT,Mve,Phr,Bhr,PH,Ihr,Nhr,qhr,TT,Eve,jhr,Dhr,BH,Ghr,Ohr,Vhr,MT,Cve,Xhr,zhr,IH,Qhr,Whr,Hhr,ET,wve,Uhr,Jhr,NH,Yhr,Khr,Zhr,CT,Ave,epr,opr,qH,rpr,tpr,apr,wT,Lve,npr,spr,jH,lpr,ipr,dpr,AT,yve,cpr,fpr,DH,mpr,gpr,hpr,LT,xve,ppr,_pr,GH,upr,bpr,vpr,yT,$ve,Fpr,Tpr,OH,Mpr,Epr,Cpr,xT,kve,wpr,Apr,VH,Lpr,ypr,xpr,$T,$pr,Sve,kpr,Spr,Rve,Rpr,Ppr,kT,Bze,Dd,ST,Pve,v8,Bpr,Bve,Ipr,Ize,Uo,F8,Npr,Gd,qpr,XH,jpr,Dpr,zH,Gpr,Opr,Vpr,T8,Xpr,Ive,zpr,Qpr,Wpr,At,M8,Hpr,Nve,Upr,Jpr,Od,Ypr,qve,Kpr,Zpr,QH,e_r,o_r,r_r,RT,t_r,po,E8,a_r,jve,n_r,s_r,Za,l_r,Dve,i_r,d_r,Gve,c_r,f_r,Ove,m_r,g_r,h_r,C8,PT,Vve,p_r,__r,WH,u_r,b_r,v_r,BT,Xve,F_r,T_r,HH,M_r,E_r,C_r,IT,w_r,zve,A_r,L_r,Qve,y_r,x_r,NT,Nze,Vd,qT,Wve,w8,$_r,Hve,k_r,qze,Jo,A8,S_r,Xd,R_r,UH,P_r,B_r,JH,I_r,N_r,q_r,L8,j_r,Uve,D_r,G_r,O_r,Lt,y8,V_r,Jve,X_r,z_r,zd,Q_r,Yve,W_r,H_r,YH,U_r,J_r,Y_r,jT,K_r,_o,x8,Z_r,Kve,eur,our,en,rur,Zve,tur,aur,eFe,nur,sur,oFe,lur,iur,dur,tt,DT,rFe,cur,fur,KH,mur,gur,hur,GT,tFe,pur,_ur,ZH,uur,bur,vur,OT,aFe,Fur,Tur,eU,Mur,Eur,Cur,VT,nFe,wur,Aur,oU,Lur,yur,xur,XT,sFe,$ur,kur,rU,Sur,Rur,Pur,zT,Bur,lFe,Iur,Nur,iFe,qur,jur,QT,jze,Qd,WT,dFe,$8,Dur,cFe,Gur,Dze,Yo,k8,Our,Wd,Vur,tU,Xur,zur,aU,Qur,Wur,Hur,S8,Uur,fFe,Jur,Yur,Kur,yt,R8,Zur,mFe,e1r,o1r,Hd,r1r,gFe,t1r,a1r,nU,n1r,s1r,l1r,HT,i1r,uo,P8,d1r,hFe,c1r,f1r,on,m1r,pFe,g1r,h1r,_Fe,p1r,_1r,uFe,u1r,b1r,v1r,rn,UT,bFe,F1r,T1r,sU,M1r,E1r,C1r,JT,vFe,w1r,A1r,lU,L1r,y1r,x1r,YT,FFe,$1r,k1r,iU,S1r,R1r,P1r,KT,TFe,B1r,I1r,dU,N1r,q1r,j1r,ZT,D1r,MFe,G1r,O1r,EFe,V1r,X1r,e7,Gze,Ud,o7,CFe,B8,z1r,wFe,Q1r,Oze,Ko,I8,W1r,Jd,H1r,cU,U1r,J1r,fU,Y1r,K1r,Z1r,N8,e4r,AFe,o4r,r4r,t4r,xt,q8,a4r,LFe,n4r,s4r,Yd,l4r,yFe,i4r,d4r,mU,c4r,f4r,m4r,r7,g4r,bo,j8,h4r,xFe,p4r,_4r,tn,u4r,$Fe,b4r,v4r,kFe,F4r,T4r,SFe,M4r,E4r,C4r,D8,t7,RFe,w4r,A4r,gU,L4r,y4r,x4r,a7,PFe,$4r,k4r,hU,S4r,R4r,P4r,n7,B4r,BFe,I4r,N4r,IFe,q4r,j4r,s7,Vze,Kd,l7,NFe,G8,D4r,qFe,G4r,Xze,Zo,O8,O4r,Zd,V4r,pU,X4r,z4r,_U,Q4r,W4r,H4r,V8,U4r,jFe,J4r,Y4r,K4r,$t,X8,Z4r,DFe,e2r,o2r,ec,r2r,GFe,t2r,a2r,uU,n2r,s2r,l2r,i7,i2r,vo,z8,d2r,OFe,c2r,f2r,an,m2r,VFe,g2r,h2r,XFe,p2r,_2r,zFe,u2r,b2r,v2r,QFe,d7,WFe,F2r,T2r,bU,M2r,E2r,C2r,c7,w2r,HFe,A2r,L2r,UFe,y2r,x2r,f7,zze,oc,m7,JFe,Q8,$2r,YFe,k2r,Qze,er,W8,S2r,rc,R2r,vU,P2r,B2r,FU,I2r,N2r,q2r,H8,j2r,KFe,D2r,G2r,O2r,kt,U8,V2r,ZFe,X2r,z2r,tc,Q2r,e6e,W2r,H2r,TU,U2r,J2r,Y2r,g7,K2r,Fo,J8,Z2r,o6e,ebr,obr,nn,rbr,r6e,tbr,abr,t6e,nbr,sbr,a6e,lbr,ibr,dbr,at,h7,n6e,cbr,fbr,MU,mbr,gbr,hbr,p7,s6e,pbr,_br,EU,ubr,bbr,vbr,_7,l6e,Fbr,Tbr,CU,Mbr,Ebr,Cbr,u7,i6e,wbr,Abr,wU,Lbr,ybr,xbr,b7,d6e,$br,kbr,AU,Sbr,Rbr,Pbr,v7,Bbr,c6e,Ibr,Nbr,f6e,qbr,jbr,F7,Wze,ac,T7,m6e,Y8,Dbr,g6e,Gbr,Hze,or,K8,Obr,nc,Vbr,LU,Xbr,zbr,yU,Qbr,Wbr,Hbr,Z8,Ubr,h6e,Jbr,Ybr,Kbr,St,ex,Zbr,p6e,evr,ovr,sc,rvr,_6e,tvr,avr,xU,nvr,svr,lvr,M7,ivr,To,ox,dvr,u6e,cvr,fvr,sn,mvr,b6e,gvr,hvr,v6e,pvr,_vr,F6e,uvr,bvr,vvr,T6e,E7,M6e,Fvr,Tvr,$U,Mvr,Evr,Cvr,C7,wvr,E6e,Avr,Lvr,C6e,yvr,xvr,w7,Uze,lc,A7,w6e,rx,$vr,A6e,kvr,Jze,rr,tx,Svr,ic,Rvr,kU,Pvr,Bvr,SU,Ivr,Nvr,qvr,ax,jvr,L6e,Dvr,Gvr,Ovr,Rt,nx,Vvr,y6e,Xvr,zvr,dc,Qvr,x6e,Wvr,Hvr,RU,Uvr,Jvr,Yvr,L7,Kvr,$r,sx,Zvr,$6e,eFr,oFr,ln,rFr,k6e,tFr,aFr,S6e,nFr,sFr,R6e,lFr,iFr,dFr,I,y7,P6e,cFr,fFr,PU,mFr,gFr,hFr,x7,B6e,pFr,_Fr,BU,uFr,bFr,vFr,$7,I6e,FFr,TFr,IU,MFr,EFr,CFr,k7,N6e,wFr,AFr,NU,LFr,yFr,xFr,S7,q6e,$Fr,kFr,qU,SFr,RFr,PFr,R7,j6e,BFr,IFr,jU,NFr,qFr,jFr,P7,D6e,DFr,GFr,DU,OFr,VFr,XFr,B7,G6e,zFr,QFr,GU,WFr,HFr,UFr,I7,O6e,JFr,YFr,OU,KFr,ZFr,e6r,N7,V6e,o6r,r6r,VU,t6r,a6r,n6r,q7,X6e,s6r,l6r,XU,i6r,d6r,c6r,j7,z6e,f6r,m6r,zU,g6r,h6r,p6r,D7,Q6e,_6r,u6r,QU,b6r,v6r,F6r,G7,W6e,T6r,M6r,WU,E6r,C6r,w6r,O7,H6e,A6r,L6r,HU,y6r,x6r,$6r,V7,U6e,k6r,S6r,UU,R6r,P6r,B6r,X7,J6e,I6r,N6r,JU,q6r,j6r,D6r,z7,Y6e,G6r,O6r,YU,V6r,X6r,z6r,Ks,K6e,Q6r,W6r,KU,H6r,U6r,ZU,J6r,Y6r,K6r,Q7,Z6e,Z6r,eTr,eJ,oTr,rTr,tTr,W7,eTe,aTr,nTr,oJ,sTr,lTr,iTr,H7,oTe,dTr,cTr,rJ,fTr,mTr,gTr,U7,rTe,hTr,pTr,tJ,_Tr,uTr,bTr,J7,tTe,vTr,FTr,aJ,TTr,MTr,ETr,Y7,aTe,CTr,wTr,nJ,ATr,LTr,yTr,K7,nTe,xTr,$Tr,sJ,kTr,STr,RTr,Z7,sTe,PTr,BTr,lJ,ITr,NTr,qTr,e9,lTe,jTr,DTr,iJ,GTr,OTr,VTr,o9,iTe,XTr,zTr,dJ,QTr,WTr,HTr,r9,dTe,UTr,JTr,cJ,YTr,KTr,ZTr,t9,cTe,e7r,o7r,fJ,r7r,t7r,a7r,a9,fTe,n7r,s7r,mJ,l7r,i7r,d7r,n9,mTe,c7r,f7r,gJ,m7r,g7r,h7r,s9,gTe,p7r,_7r,hJ,u7r,b7r,v7r,l9,hTe,F7r,T7r,pJ,M7r,E7r,C7r,i9,pTe,w7r,A7r,_J,L7r,y7r,x7r,d9,_Te,$7r,k7r,uJ,S7r,R7r,P7r,c9,uTe,B7r,I7r,bJ,N7r,q7r,j7r,f9,bTe,D7r,G7r,vJ,O7r,V7r,X7r,m9,vTe,z7r,Q7r,FJ,W7r,H7r,U7r,g9,FTe,J7r,Y7r,TJ,K7r,Z7r,e9r,h9,TTe,o9r,r9r,MJ,t9r,a9r,n9r,p9,MTe,s9r,l9r,EJ,i9r,d9r,c9r,_9,ETe,f9r,m9r,CJ,g9r,h9r,p9r,u9,CTe,_9r,u9r,wJ,b9r,v9r,F9r,b9,wTe,T9r,M9r,AJ,E9r,C9r,w9r,v9,ATe,A9r,L9r,LJ,y9r,x9r,$9r,F9,LTe,k9r,S9r,yJ,R9r,P9r,B9r,T9,yTe,I9r,N9r,xJ,q9r,j9r,D9r,M9,xTe,G9r,O9r,$J,V9r,X9r,z9r,E9,$Te,Q9r,W9r,kJ,H9r,U9r,J9r,C9,Yze,cc,w9,kTe,lx,Y9r,STe,K9r,Kze,tr,ix,Z9r,fc,eMr,SJ,oMr,rMr,RJ,tMr,aMr,nMr,dx,sMr,RTe,lMr,iMr,dMr,Pt,cx,cMr,PTe,fMr,mMr,mc,gMr,BTe,hMr,pMr,PJ,_Mr,uMr,bMr,A9,vMr,kr,fx,FMr,ITe,TMr,MMr,dn,EMr,NTe,CMr,wMr,qTe,AMr,LMr,jTe,yMr,xMr,$Mr,se,L9,DTe,kMr,SMr,BJ,RMr,PMr,BMr,y9,GTe,IMr,NMr,IJ,qMr,jMr,DMr,x9,OTe,GMr,OMr,NJ,VMr,XMr,zMr,$9,VTe,QMr,WMr,qJ,HMr,UMr,JMr,k9,XTe,YMr,KMr,jJ,ZMr,eEr,oEr,S9,zTe,rEr,tEr,DJ,aEr,nEr,sEr,R9,QTe,lEr,iEr,GJ,dEr,cEr,fEr,P9,WTe,mEr,gEr,OJ,hEr,pEr,_Er,B9,HTe,uEr,bEr,VJ,vEr,FEr,TEr,I9,UTe,MEr,EEr,XJ,CEr,wEr,AEr,N9,JTe,LEr,yEr,zJ,xEr,$Er,kEr,q9,YTe,SEr,REr,QJ,PEr,BEr,IEr,j9,KTe,NEr,qEr,WJ,jEr,DEr,GEr,D9,ZTe,OEr,VEr,HJ,XEr,zEr,QEr,G9,e7e,WEr,HEr,UJ,UEr,JEr,YEr,O9,o7e,KEr,ZEr,JJ,eCr,oCr,rCr,V9,r7e,tCr,aCr,YJ,nCr,sCr,lCr,X9,t7e,iCr,dCr,KJ,cCr,fCr,mCr,z9,a7e,gCr,hCr,ZJ,pCr,_Cr,uCr,Q9,n7e,bCr,vCr,eY,FCr,TCr,MCr,W9,s7e,ECr,CCr,oY,wCr,ACr,LCr,H9,l7e,yCr,xCr,rY,$Cr,kCr,SCr,U9,i7e,RCr,PCr,tY,BCr,ICr,NCr,J9,Zze,gc,Y9,d7e,mx,qCr,c7e,jCr,eQe,ar,gx,DCr,hc,GCr,aY,OCr,VCr,nY,XCr,zCr,QCr,hx,WCr,f7e,HCr,UCr,JCr,Bt,px,YCr,m7e,KCr,ZCr,pc,e5r,g7e,o5r,r5r,sY,t5r,a5r,n5r,K9,s5r,Sr,_x,l5r,h7e,i5r,d5r,cn,c5r,p7e,f5r,m5r,_7e,g5r,h5r,u7e,p5r,_5r,u5r,Me,Z9,b7e,b5r,v5r,lY,F5r,T5r,M5r,eM,v7e,E5r,C5r,iY,w5r,A5r,L5r,oM,F7e,y5r,x5r,dY,$5r,k5r,S5r,rM,T7e,R5r,P5r,cY,B5r,I5r,N5r,tM,M7e,q5r,j5r,fY,D5r,G5r,O5r,aM,E7e,V5r,X5r,mY,z5r,Q5r,W5r,nM,C7e,H5r,U5r,gY,J5r,Y5r,K5r,sM,w7e,Z5r,e3r,hY,o3r,r3r,t3r,lM,A7e,a3r,n3r,pY,s3r,l3r,i3r,iM,L7e,d3r,c3r,_Y,f3r,m3r,g3r,dM,y7e,h3r,p3r,uY,_3r,u3r,b3r,cM,x7e,v3r,F3r,bY,T3r,M3r,E3r,fM,$7e,C3r,w3r,vY,A3r,L3r,y3r,mM,oQe,_c,gM,k7e,ux,x3r,S7e,$3r,rQe,nr,bx,k3r,uc,S3r,FY,R3r,P3r,TY,B3r,I3r,N3r,vx,q3r,R7e,j3r,D3r,G3r,It,Fx,O3r,P7e,V3r,X3r,bc,z3r,B7e,Q3r,W3r,MY,H3r,U3r,J3r,hM,Y3r,Rr,Tx,K3r,I7e,Z3r,e0r,fn,o0r,N7e,r0r,t0r,q7e,a0r,n0r,j7e,s0r,l0r,i0r,Ve,pM,D7e,d0r,c0r,EY,f0r,m0r,g0r,_M,G7e,h0r,p0r,CY,_0r,u0r,b0r,Zs,O7e,v0r,F0r,wY,T0r,M0r,AY,E0r,C0r,w0r,uM,V7e,A0r,L0r,LY,y0r,x0r,$0r,bM,X7e,k0r,S0r,yY,R0r,P0r,B0r,vM,z7e,I0r,N0r,xY,q0r,j0r,D0r,FM,Q7e,G0r,O0r,$Y,V0r,X0r,z0r,TM,W7e,Q0r,W0r,kY,H0r,U0r,J0r,MM,tQe,vc,EM,H7e,Mx,Y0r,U7e,K0r,aQe,sr,Ex,Z0r,Fc,ewr,SY,owr,rwr,RY,twr,awr,nwr,Cx,swr,J7e,lwr,iwr,dwr,Nt,wx,cwr,Y7e,fwr,mwr,Tc,gwr,K7e,hwr,pwr,PY,_wr,uwr,bwr,CM,vwr,Pr,Ax,Fwr,Z7e,Twr,Mwr,mn,Ewr,e9e,Cwr,wwr,o9e,Awr,Lwr,r9e,ywr,xwr,$wr,ie,wM,t9e,kwr,Swr,BY,Rwr,Pwr,Bwr,AM,a9e,Iwr,Nwr,IY,qwr,jwr,Dwr,LM,n9e,Gwr,Owr,NY,Vwr,Xwr,zwr,yM,s9e,Qwr,Wwr,qY,Hwr,Uwr,Jwr,xM,l9e,Ywr,Kwr,jY,Zwr,eAr,oAr,$M,i9e,rAr,tAr,DY,aAr,nAr,sAr,kM,d9e,lAr,iAr,GY,dAr,cAr,fAr,SM,c9e,mAr,gAr,OY,hAr,pAr,_Ar,RM,f9e,uAr,bAr,VY,vAr,FAr,TAr,PM,m9e,MAr,EAr,XY,CAr,wAr,AAr,BM,g9e,LAr,yAr,zY,xAr,$Ar,kAr,IM,h9e,SAr,RAr,QY,PAr,BAr,IAr,NM,p9e,NAr,qAr,WY,jAr,DAr,GAr,qM,_9e,OAr,VAr,HY,XAr,zAr,QAr,jM,u9e,WAr,HAr,UY,UAr,JAr,YAr,DM,b9e,KAr,ZAr,JY,eLr,oLr,rLr,GM,v9e,tLr,aLr,YY,nLr,sLr,lLr,OM,F9e,iLr,dLr,KY,cLr,fLr,mLr,VM,T9e,gLr,hLr,ZY,pLr,_Lr,uLr,XM,M9e,bLr,vLr,eK,FLr,TLr,MLr,zM,nQe,Mc,QM,E9e,Lx,ELr,C9e,CLr,sQe,lr,yx,wLr,Ec,ALr,oK,LLr,yLr,rK,xLr,$Lr,kLr,xx,SLr,w9e,RLr,PLr,BLr,qt,$x,ILr,A9e,NLr,qLr,Cc,jLr,L9e,DLr,GLr,tK,OLr,VLr,XLr,WM,zLr,Br,kx,QLr,y9e,WLr,HLr,gn,ULr,x9e,JLr,YLr,$9e,KLr,ZLr,k9e,eyr,oyr,ryr,ye,HM,S9e,tyr,ayr,aK,nyr,syr,lyr,UM,R9e,iyr,dyr,nK,cyr,fyr,myr,JM,P9e,gyr,hyr,sK,pyr,_yr,uyr,YM,B9e,byr,vyr,lK,Fyr,Tyr,Myr,KM,I9e,Eyr,Cyr,iK,wyr,Ayr,Lyr,ZM,N9e,yyr,xyr,dK,$yr,kyr,Syr,eE,q9e,Ryr,Pyr,cK,Byr,Iyr,Nyr,oE,j9e,qyr,jyr,fK,Dyr,Gyr,Oyr,rE,D9e,Vyr,Xyr,mK,zyr,Qyr,Wyr,tE,G9e,Hyr,Uyr,gK,Jyr,Yyr,Kyr,aE,lQe,wc,nE,O9e,Sx,Zyr,V9e,e8r,iQe,ir,Rx,o8r,Ac,r8r,hK,t8r,a8r,pK,n8r,s8r,l8r,Px,i8r,X9e,d8r,c8r,f8r,jt,Bx,m8r,z9e,g8r,h8r,Lc,p8r,Q9e,_8r,u8r,_K,b8r,v8r,F8r,sE,T8r,Ir,Ix,M8r,W9e,E8r,C8r,hn,w8r,H9e,A8r,L8r,U9e,y8r,x8r,J9e,$8r,k8r,S8r,te,lE,Y9e,R8r,P8r,uK,B8r,I8r,N8r,iE,K9e,q8r,j8r,bK,D8r,G8r,O8r,dE,Z9e,V8r,X8r,vK,z8r,Q8r,W8r,cE,eMe,H8r,U8r,FK,J8r,Y8r,K8r,fE,oMe,Z8r,exr,TK,oxr,rxr,txr,mE,rMe,axr,nxr,MK,sxr,lxr,ixr,gE,tMe,dxr,cxr,EK,fxr,mxr,gxr,hE,aMe,hxr,pxr,CK,_xr,uxr,bxr,pE,nMe,vxr,Fxr,wK,Txr,Mxr,Exr,_E,sMe,Cxr,wxr,AK,Axr,Lxr,yxr,uE,lMe,xxr,$xr,LK,kxr,Sxr,Rxr,bE,iMe,Pxr,Bxr,yK,Ixr,Nxr,qxr,vE,dMe,jxr,Dxr,xK,Gxr,Oxr,Vxr,FE,cMe,Xxr,zxr,$K,Qxr,Wxr,Hxr,TE,fMe,Uxr,Jxr,kK,Yxr,Kxr,Zxr,ME,mMe,e$r,o$r,SK,r$r,t$r,a$r,EE,gMe,n$r,s$r,RK,l$r,i$r,d$r,CE,hMe,c$r,f$r,PK,m$r,g$r,h$r,wE,pMe,p$r,_$r,BK,u$r,b$r,v$r,AE,_Me,F$r,T$r,IK,M$r,E$r,C$r,LE,uMe,w$r,A$r,NK,L$r,y$r,x$r,yE,bMe,$$r,k$r,qK,S$r,R$r,P$r,xE,vMe,B$r,I$r,jK,N$r,q$r,j$r,$E,FMe,D$r,G$r,DK,O$r,V$r,X$r,kE,TMe,z$r,Q$r,GK,W$r,H$r,U$r,SE,MMe,J$r,Y$r,OK,K$r,Z$r,ekr,RE,dQe,yc,PE,EMe,Nx,okr,CMe,rkr,cQe,dr,qx,tkr,xc,akr,VK,nkr,skr,XK,lkr,ikr,dkr,jx,ckr,wMe,fkr,mkr,gkr,Dt,Dx,hkr,AMe,pkr,_kr,$c,ukr,LMe,bkr,vkr,zK,Fkr,Tkr,Mkr,BE,Ekr,Nr,Gx,Ckr,yMe,wkr,Akr,pn,Lkr,xMe,ykr,xkr,$Me,$kr,kkr,kMe,Skr,Rkr,Pkr,be,IE,SMe,Bkr,Ikr,QK,Nkr,qkr,jkr,NE,RMe,Dkr,Gkr,WK,Okr,Vkr,Xkr,qE,PMe,zkr,Qkr,HK,Wkr,Hkr,Ukr,jE,BMe,Jkr,Ykr,UK,Kkr,Zkr,eSr,DE,IMe,oSr,rSr,JK,tSr,aSr,nSr,GE,NMe,sSr,lSr,YK,iSr,dSr,cSr,OE,qMe,fSr,mSr,KK,gSr,hSr,pSr,VE,jMe,_Sr,uSr,ZK,bSr,vSr,FSr,XE,DMe,TSr,MSr,eZ,ESr,CSr,wSr,zE,GMe,ASr,LSr,oZ,ySr,xSr,$Sr,QE,OMe,kSr,SSr,rZ,RSr,PSr,BSr,WE,VMe,ISr,NSr,tZ,qSr,jSr,DSr,HE,XMe,GSr,OSr,aZ,VSr,XSr,zSr,UE,zMe,QSr,WSr,nZ,HSr,USr,JSr,JE,QMe,YSr,KSr,sZ,ZSr,eRr,oRr,YE,WMe,rRr,tRr,lZ,aRr,nRr,sRr,KE,HMe,lRr,iRr,iZ,dRr,cRr,fRr,ZE,fQe,kc,eC,UMe,Ox,mRr,JMe,gRr,mQe,cr,Vx,hRr,Sc,pRr,dZ,_Rr,uRr,cZ,bRr,vRr,FRr,Xx,TRr,YMe,MRr,ERr,CRr,Gt,zx,wRr,KMe,ARr,LRr,Rc,yRr,ZMe,xRr,$Rr,fZ,kRr,SRr,RRr,oC,PRr,qr,Qx,BRr,eEe,IRr,NRr,_n,qRr,oEe,jRr,DRr,rEe,GRr,ORr,tEe,VRr,XRr,zRr,Wx,rC,aEe,QRr,WRr,mZ,HRr,URr,JRr,tC,nEe,YRr,KRr,gZ,ZRr,ePr,oPr,aC,gQe,Pc,nC,sEe,Hx,rPr,lEe,tPr,hQe,fr,Ux,aPr,Bc,nPr,hZ,sPr,lPr,pZ,iPr,dPr,cPr,Jx,fPr,iEe,mPr,gPr,hPr,Ot,Yx,pPr,dEe,_Pr,uPr,Ic,bPr,cEe,vPr,FPr,_Z,TPr,MPr,EPr,sC,CPr,jr,Kx,wPr,fEe,APr,LPr,un,yPr,mEe,xPr,$Pr,gEe,kPr,SPr,hEe,RPr,PPr,BPr,pEe,lC,_Ee,IPr,NPr,uZ,qPr,jPr,DPr,iC,pQe,Nc,dC,uEe,Zx,GPr,bEe,OPr,_Qe,mr,e$,VPr,qc,XPr,bZ,zPr,QPr,vZ,WPr,HPr,UPr,o$,JPr,vEe,YPr,KPr,ZPr,Vt,r$,eBr,FEe,oBr,rBr,jc,tBr,TEe,aBr,nBr,FZ,sBr,lBr,iBr,cC,dBr,Dr,t$,cBr,MEe,fBr,mBr,bn,gBr,EEe,hBr,pBr,CEe,_Br,uBr,wEe,bBr,vBr,FBr,de,fC,AEe,TBr,MBr,TZ,EBr,CBr,wBr,mC,LEe,ABr,LBr,MZ,yBr,xBr,$Br,gC,yEe,kBr,SBr,EZ,RBr,PBr,BBr,hC,xEe,IBr,NBr,CZ,qBr,jBr,DBr,pC,$Ee,GBr,OBr,wZ,VBr,XBr,zBr,_C,kEe,QBr,WBr,AZ,HBr,UBr,JBr,uC,SEe,YBr,KBr,LZ,ZBr,eIr,oIr,bC,REe,rIr,tIr,yZ,aIr,nIr,sIr,vC,PEe,lIr,iIr,xZ,dIr,cIr,fIr,FC,BEe,mIr,gIr,$Z,hIr,pIr,_Ir,TC,IEe,uIr,bIr,kZ,vIr,FIr,TIr,MC,NEe,MIr,EIr,SZ,CIr,wIr,AIr,EC,qEe,LIr,yIr,RZ,xIr,$Ir,kIr,CC,jEe,SIr,RIr,PZ,PIr,BIr,IIr,wC,DEe,NIr,qIr,BZ,jIr,DIr,GIr,AC,GEe,OIr,VIr,IZ,XIr,zIr,QIr,LC,OEe,WIr,HIr,NZ,UIr,JIr,YIr,yC,VEe,KIr,ZIr,qZ,eNr,oNr,rNr,xC,XEe,tNr,aNr,jZ,nNr,sNr,lNr,$C,zEe,iNr,dNr,DZ,cNr,fNr,mNr,kC,uQe,Dc,SC,QEe,a$,gNr,WEe,hNr,bQe,gr,n$,pNr,Gc,_Nr,GZ,uNr,bNr,OZ,vNr,FNr,TNr,s$,MNr,HEe,ENr,CNr,wNr,Xt,l$,ANr,UEe,LNr,yNr,Oc,xNr,JEe,$Nr,kNr,VZ,SNr,RNr,PNr,RC,BNr,Gr,i$,INr,YEe,NNr,qNr,vn,jNr,KEe,DNr,GNr,ZEe,ONr,VNr,eCe,XNr,zNr,QNr,ce,PC,oCe,WNr,HNr,XZ,UNr,JNr,YNr,BC,rCe,KNr,ZNr,zZ,eqr,oqr,rqr,IC,tCe,tqr,aqr,QZ,nqr,sqr,lqr,NC,aCe,iqr,dqr,WZ,cqr,fqr,mqr,qC,nCe,gqr,hqr,HZ,pqr,_qr,uqr,jC,sCe,bqr,vqr,UZ,Fqr,Tqr,Mqr,DC,lCe,Eqr,Cqr,JZ,wqr,Aqr,Lqr,GC,iCe,yqr,xqr,YZ,$qr,kqr,Sqr,OC,dCe,Rqr,Pqr,KZ,Bqr,Iqr,Nqr,VC,cCe,qqr,jqr,ZZ,Dqr,Gqr,Oqr,XC,fCe,Vqr,Xqr,eee,zqr,Qqr,Wqr,zC,mCe,Hqr,Uqr,oee,Jqr,Yqr,Kqr,QC,gCe,Zqr,ejr,ree,ojr,rjr,tjr,WC,hCe,ajr,njr,tee,sjr,ljr,ijr,HC,pCe,djr,cjr,aee,fjr,mjr,gjr,UC,_Ce,hjr,pjr,nee,_jr,ujr,bjr,JC,uCe,vjr,Fjr,see,Tjr,Mjr,Ejr,YC,bCe,Cjr,wjr,lee,Ajr,Ljr,yjr,KC,vCe,xjr,$jr,iee,kjr,Sjr,Rjr,ZC,FCe,Pjr,Bjr,dee,Ijr,Njr,qjr,e5,vQe,Vc,o5,TCe,d$,jjr,MCe,Djr,FQe,hr,c$,Gjr,Xc,Ojr,cee,Vjr,Xjr,fee,zjr,Qjr,Wjr,f$,Hjr,ECe,Ujr,Jjr,Yjr,zt,m$,Kjr,CCe,Zjr,eDr,zc,oDr,wCe,rDr,tDr,mee,aDr,nDr,sDr,r5,lDr,Or,g$,iDr,ACe,dDr,cDr,Fn,fDr,LCe,mDr,gDr,yCe,hDr,pDr,xCe,_Dr,uDr,bDr,$Ce,t5,kCe,vDr,FDr,gee,TDr,MDr,EDr,a5,TQe,Qc,n5,SCe,h$,CDr,RCe,wDr,MQe,pr,p$,ADr,Wc,LDr,hee,yDr,xDr,pee,$Dr,kDr,SDr,_$,RDr,PCe,PDr,BDr,IDr,Qt,u$,NDr,BCe,qDr,jDr,Hc,DDr,ICe,GDr,ODr,_ee,VDr,XDr,zDr,s5,QDr,Vr,b$,WDr,NCe,HDr,UDr,Tn,JDr,qCe,YDr,KDr,jCe,ZDr,eGr,DCe,oGr,rGr,tGr,GCe,l5,OCe,aGr,nGr,uee,sGr,lGr,iGr,i5,EQe,Uc,d5,VCe,v$,dGr,XCe,cGr,CQe,_r,F$,fGr,Jc,mGr,bee,gGr,hGr,vee,pGr,_Gr,uGr,T$,bGr,zCe,vGr,FGr,TGr,Wt,M$,MGr,QCe,EGr,CGr,Yc,wGr,WCe,AGr,LGr,Fee,yGr,xGr,$Gr,c5,kGr,Xr,E$,SGr,HCe,RGr,PGr,Mn,BGr,UCe,IGr,NGr,JCe,qGr,jGr,YCe,DGr,GGr,OGr,oe,f5,KCe,VGr,XGr,Tee,zGr,QGr,WGr,m5,ZCe,HGr,UGr,Mee,JGr,YGr,KGr,g5,e5e,ZGr,eOr,Eee,oOr,rOr,tOr,h5,o5e,aOr,nOr,Cee,sOr,lOr,iOr,p5,r5e,dOr,cOr,wee,fOr,mOr,gOr,_5,t5e,hOr,pOr,Aee,_Or,uOr,bOr,u5,a5e,vOr,FOr,Lee,TOr,MOr,EOr,b5,n5e,COr,wOr,yee,AOr,LOr,yOr,v5,s5e,xOr,$Or,xee,kOr,SOr,ROr,F5,l5e,POr,BOr,$ee,IOr,NOr,qOr,T5,i5e,jOr,DOr,kee,GOr,OOr,VOr,M5,d5e,XOr,zOr,See,QOr,WOr,HOr,E5,c5e,UOr,JOr,Ree,YOr,KOr,ZOr,C5,f5e,eVr,oVr,Pee,rVr,tVr,aVr,w5,m5e,nVr,sVr,Bee,lVr,iVr,dVr,A5,g5e,cVr,fVr,Iee,mVr,gVr,hVr,L5,h5e,pVr,_Vr,Nee,uVr,bVr,vVr,y5,p5e,FVr,TVr,qee,MVr,EVr,CVr,x5,_5e,wVr,AVr,jee,LVr,yVr,xVr,$5,u5e,$Vr,kVr,Dee,SVr,RVr,PVr,k5,b5e,BVr,IVr,Gee,NVr,qVr,jVr,S5,v5e,DVr,GVr,Oee,OVr,VVr,XVr,R5,F5e,zVr,QVr,Vee,WVr,HVr,UVr,P5,T5e,JVr,YVr,Xee,KVr,ZVr,eXr,B5,M5e,oXr,rXr,zee,tXr,aXr,nXr,I5,E5e,sXr,lXr,Qee,iXr,dXr,cXr,N5,C5e,fXr,mXr,Wee,gXr,hXr,pXr,q5,wQe,Kc,j5,w5e,C$,_Xr,A5e,uXr,AQe,ur,w$,bXr,Zc,vXr,Hee,FXr,TXr,Uee,MXr,EXr,CXr,A$,wXr,L5e,AXr,LXr,yXr,Ht,L$,xXr,y5e,$Xr,kXr,ef,SXr,x5e,RXr,PXr,Jee,BXr,IXr,NXr,D5,qXr,zr,y$,jXr,$5e,DXr,GXr,En,OXr,k5e,VXr,XXr,S5e,zXr,QXr,R5e,WXr,HXr,UXr,xe,G5,P5e,JXr,YXr,Yee,KXr,ZXr,ezr,O5,B5e,ozr,rzr,Kee,tzr,azr,nzr,V5,I5e,szr,lzr,Zee,izr,dzr,czr,X5,N5e,fzr,mzr,eoe,gzr,hzr,pzr,z5,q5e,_zr,uzr,ooe,bzr,vzr,Fzr,Q5,j5e,Tzr,Mzr,roe,Ezr,Czr,wzr,W5,D5e,Azr,Lzr,toe,yzr,xzr,$zr,H5,G5e,kzr,Szr,aoe,Rzr,Pzr,Bzr,U5,O5e,Izr,Nzr,noe,qzr,jzr,Dzr,J5,V5e,Gzr,Ozr,soe,Vzr,Xzr,zzr,Y5,LQe,of,K5,X5e,x$,Qzr,z5e,Wzr,yQe,br,$$,Hzr,rf,Uzr,loe,Jzr,Yzr,ioe,Kzr,Zzr,eQr,k$,oQr,Q5e,rQr,tQr,aQr,Ut,S$,nQr,W5e,sQr,lQr,tf,iQr,H5e,dQr,cQr,doe,fQr,mQr,gQr,Z5,hQr,Qr,R$,pQr,U5e,_Qr,uQr,Cn,bQr,J5e,vQr,FQr,Y5e,TQr,MQr,K5e,EQr,CQr,wQr,Ee,e3,Z5e,AQr,LQr,coe,yQr,xQr,$Qr,o3,e3e,kQr,SQr,foe,RQr,PQr,BQr,r3,o3e,IQr,NQr,moe,qQr,jQr,DQr,t3,r3e,GQr,OQr,goe,VQr,XQr,zQr,a3,t3e,QQr,WQr,hoe,HQr,UQr,JQr,n3,a3e,YQr,KQr,poe,ZQr,eWr,oWr,s3,n3e,rWr,tWr,_oe,aWr,nWr,sWr,l3,s3e,lWr,iWr,uoe,dWr,cWr,fWr,i3,l3e,mWr,gWr,boe,hWr,pWr,_Wr,d3,i3e,uWr,bWr,voe,vWr,FWr,TWr,c3,d3e,MWr,EWr,Foe,CWr,wWr,AWr,f3,c3e,LWr,yWr,Toe,xWr,$Wr,kWr,m3,f3e,SWr,RWr,Moe,PWr,BWr,IWr,g3,xQe,af,h3,m3e,P$,NWr,g3e,qWr,$Qe,vr,B$,jWr,nf,DWr,Eoe,GWr,OWr,Coe,VWr,XWr,zWr,I$,QWr,h3e,WWr,HWr,UWr,Jt,N$,JWr,p3e,YWr,KWr,sf,ZWr,_3e,eHr,oHr,woe,rHr,tHr,aHr,p3,nHr,Wr,q$,sHr,u3e,lHr,iHr,wn,dHr,b3e,cHr,fHr,v3e,mHr,gHr,F3e,hHr,pHr,_Hr,$e,_3,T3e,uHr,bHr,Aoe,vHr,FHr,THr,u3,M3e,MHr,EHr,Loe,CHr,wHr,AHr,b3,E3e,LHr,yHr,yoe,xHr,$Hr,kHr,v3,C3e,SHr,RHr,xoe,PHr,BHr,IHr,F3,w3e,NHr,qHr,$oe,jHr,DHr,GHr,T3,A3e,OHr,VHr,koe,XHr,zHr,QHr,M3,L3e,WHr,HHr,Soe,UHr,JHr,YHr,E3,y3e,KHr,ZHr,Roe,eUr,oUr,rUr,C3,x3e,tUr,aUr,Poe,nUr,sUr,lUr,w3,$3e,iUr,dUr,Boe,cUr,fUr,mUr,A3,kQe,lf,L3,k3e,j$,gUr,S3e,hUr,SQe,Fr,D$,pUr,df,_Ur,Ioe,uUr,bUr,Noe,vUr,FUr,TUr,G$,MUr,R3e,EUr,CUr,wUr,Yt,O$,AUr,P3e,LUr,yUr,cf,xUr,B3e,$Ur,kUr,qoe,SUr,RUr,PUr,y3,BUr,Hr,V$,IUr,I3e,NUr,qUr,An,jUr,N3e,DUr,GUr,q3e,OUr,VUr,j3e,XUr,zUr,QUr,ke,x3,D3e,WUr,HUr,joe,UUr,JUr,YUr,$3,G3e,KUr,ZUr,Doe,eJr,oJr,rJr,k3,O3e,tJr,aJr,Goe,nJr,sJr,lJr,S3,V3e,iJr,dJr,Ooe,cJr,fJr,mJr,R3,X3e,gJr,hJr,Voe,pJr,_Jr,uJr,P3,z3e,bJr,vJr,Xoe,FJr,TJr,MJr,B3,Q3e,EJr,CJr,zoe,wJr,AJr,LJr,I3,W3e,yJr,xJr,Qoe,$Jr,kJr,SJr,N3,H3e,RJr,PJr,Woe,BJr,IJr,NJr,q3,U3e,qJr,jJr,Hoe,DJr,GJr,OJr,j3,RQe,ff,D3,J3e,X$,VJr,Y3e,XJr,PQe,Tr,z$,zJr,mf,QJr,Uoe,WJr,HJr,Joe,UJr,JJr,YJr,Q$,KJr,K3e,ZJr,eYr,oYr,Kt,W$,rYr,Z3e,tYr,aYr,gf,nYr,e0e,sYr,lYr,Yoe,iYr,dYr,cYr,G3,fYr,Ur,H$,mYr,o0e,gYr,hYr,Ln,pYr,r0e,_Yr,uYr,t0e,bYr,vYr,a0e,FYr,TYr,MYr,Se,O3,n0e,EYr,CYr,Koe,wYr,AYr,LYr,V3,s0e,yYr,xYr,Zoe,$Yr,kYr,SYr,X3,l0e,RYr,PYr,ere,BYr,IYr,NYr,z3,i0e,qYr,jYr,ore,DYr,GYr,OYr,Q3,d0e,VYr,XYr,rre,zYr,QYr,WYr,W3,c0e,HYr,UYr,tre,JYr,YYr,KYr,H3,f0e,ZYr,eKr,are,oKr,rKr,tKr,U3,m0e,aKr,nKr,nre,sKr,lKr,iKr,J3,g0e,dKr,cKr,sre,fKr,mKr,gKr,Y3,h0e,hKr,pKr,lre,_Kr,uKr,bKr,K3,BQe,hf,Z3,p0e,U$,vKr,_0e,FKr,IQe,Mr,J$,TKr,pf,MKr,ire,EKr,CKr,dre,wKr,AKr,LKr,Y$,yKr,u0e,xKr,$Kr,kKr,Zt,K$,SKr,b0e,RKr,PKr,_f,BKr,v0e,IKr,NKr,cre,qKr,jKr,DKr,e0,GKr,Jr,Z$,OKr,F0e,VKr,XKr,yn,zKr,T0e,QKr,WKr,M0e,HKr,UKr,E0e,JKr,YKr,KKr,Re,o0,C0e,ZKr,eZr,fre,oZr,rZr,tZr,r0,w0e,aZr,nZr,mre,sZr,lZr,iZr,t0,A0e,dZr,cZr,gre,fZr,mZr,gZr,a0,L0e,hZr,pZr,hre,_Zr,uZr,bZr,n0,y0e,vZr,FZr,pre,TZr,MZr,EZr,s0,x0e,CZr,wZr,_re,AZr,LZr,yZr,l0,$0e,xZr,$Zr,ure,kZr,SZr,RZr,i0,k0e,PZr,BZr,bre,IZr,NZr,qZr,d0,S0e,jZr,DZr,vre,GZr,OZr,VZr,c0,R0e,XZr,zZr,Fre,QZr,WZr,HZr,f0,NQe,uf,m0,P0e,ek,UZr,B0e,JZr,qQe,Er,ok,YZr,bf,KZr,Tre,ZZr,eet,Mre,oet,ret,tet,rk,aet,I0e,net,set,iet,ea,tk,det,N0e,cet,fet,vf,met,q0e,get,het,Ere,pet,_et,uet,g0,bet,Yr,ak,vet,j0e,Fet,Tet,xn,Met,D0e,Eet,Cet,G0e,wet,Aet,O0e,Let,yet,xet,Xe,h0,V0e,$et,ket,Cre,Set,Ret,Pet,p0,X0e,Bet,Iet,wre,Net,qet,jet,_0,z0e,Det,Get,Are,Oet,Vet,Xet,u0,Q0e,zet,Qet,Lre,Wet,Het,Uet,b0,W0e,Jet,Yet,yre,Ket,Zet,eot,v0,H0e,oot,rot,xre,tot,aot,not,F0,U0e,sot,lot,$re,iot,dot,cot,T0,J0e,fot,mot,kre,got,hot,pot,M0,jQe,Ff,E0,Y0e,nk,_ot,K0e,uot,DQe,Cr,sk,bot,Tf,vot,Sre,Fot,Tot,Rre,Mot,Eot,Cot,lk,wot,Z0e,Aot,Lot,yot,oa,ik,xot,ewe,$ot,kot,Mf,Sot,owe,Rot,Pot,Pre,Bot,Iot,Not,C0,qot,Kr,dk,jot,rwe,Dot,Got,$n,Oot,twe,Vot,Xot,awe,zot,Qot,nwe,Wot,Hot,Uot,ze,w0,swe,Jot,Yot,Bre,Kot,Zot,ert,A0,lwe,ort,rrt,Ire,trt,art,nrt,L0,iwe,srt,lrt,Nre,irt,drt,crt,y0,dwe,frt,mrt,qre,grt,hrt,prt,x0,cwe,_rt,urt,jre,brt,vrt,Frt,$0,fwe,Trt,Mrt,Dre,Ert,Crt,wrt,k0,mwe,Art,Lrt,Gre,yrt,xrt,$rt,S0,gwe,krt,Srt,Ore,Rrt,Prt,Brt,R0,GQe,Ef,P0,hwe,ck,Irt,pwe,Nrt,OQe,wr,fk,qrt,Cf,jrt,Vre,Drt,Grt,Xre,Ort,Vrt,Xrt,mk,zrt,_we,Qrt,Wrt,Hrt,ra,gk,Urt,uwe,Jrt,Yrt,wf,Krt,bwe,Zrt,ett,zre,ott,rtt,ttt,B0,att,Zr,hk,ntt,vwe,stt,ltt,kn,itt,Fwe,dtt,ctt,Twe,ftt,mtt,Mwe,gtt,htt,ptt,Ewe,I0,Cwe,_tt,utt,Qre,btt,vtt,Ftt,N0,VQe,Af,q0,wwe,pk,Ttt,Awe,Mtt,XQe,Ar,_k,Ett,Lf,Ctt,Wre,wtt,Att,Hre,Ltt,ytt,xtt,uk,$tt,Lwe,ktt,Stt,Rtt,ta,bk,Ptt,ywe,Btt,Itt,yf,Ntt,xwe,qtt,jtt,Ure,Dtt,Gtt,Ott,j0,Vtt,et,vk,Xtt,$we,ztt,Qtt,Sn,Wtt,kwe,Htt,Utt,Swe,Jtt,Ytt,Rwe,Ktt,Ztt,eat,Fk,D0,Pwe,oat,rat,Jre,tat,aat,nat,G0,Bwe,sat,lat,Yre,iat,dat,cat,O0,zQe,xf,V0,Iwe,Tk,fat,Nwe,mat,QQe,Lr,Mk,gat,$f,hat,Kre,pat,_at,Zre,uat,bat,vat,Ek,Fat,qwe,Tat,Mat,Eat,aa,Ck,Cat,jwe,wat,Aat,kf,Lat,Dwe,yat,xat,ete,$at,kat,Sat,X0,Rat,ot,wk,Pat,Gwe,Bat,Iat,Rn,Nat,Owe,qat,jat,Vwe,Dat,Gat,Xwe,Oat,Vat,Xat,zwe,z0,Qwe,zat,Qat,ote,Wat,Hat,Uat,Q0,WQe;return c=new re({}),Sa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),_L=new re({}),uL=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Df=new Jat({props:{warning:!0,$$slots:{default:[KHt]},$$scope:{ctx:$}}}),bL=new re({}),vL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/configuration_auto.py#L614"}}),ML=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/configuration_auto.py#L637"}}),Zg=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[ZHt]},$$scope:{ctx:$}}}),EL=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/configuration_auto.py#L760"}}),CL=new re({}),wL=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/tokenization_auto.py#L410"}}),yL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17469/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/tokenization_auto.py#L424"}}),Bh=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[eUt]},$$scope:{ctx:$}}}),xL=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/tokenization_auto.py#L623"}}),$L=new re({}),kL=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/feature_extraction_auto.py#L196"}}),PL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17469/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/feature_extraction_auto.py#L210"}}),vp=new Jat({props:{$$slots:{default:[oUt]},$$scope:{ctx:$}}}),Fp=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[rUt]},$$scope:{ctx:$}}}),BL=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/feature_extraction_auto.py#L337"}}),IL=new re({}),NL=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/processing_auto.py#L89"}}),DL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/processing_auto.py#L103"}}),Gp=new Jat({props:{$$slots:{default:[tUt]},$$scope:{ctx:$}}}),Op=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[aUt]},$$scope:{ctx:$}}}),GL=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/processing_auto.py#L256"}}),OL=new re({}),VL=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L789"}}),zL=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),zp=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[nUt]},$$scope:{ctx:$}}}),QL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),Yu=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[sUt]},$$scope:{ctx:$}}}),WL=new re({}),HL=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L796"}}),JL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),Zu=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[lUt]},$$scope:{ctx:$}}}),YL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),Q1=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[iUt]},$$scope:{ctx:$}}}),KL=new re({}),ZL=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L811"}}),oy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),H1=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[dUt]},$$scope:{ctx:$}}}),ry=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),I4=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[cUt]},$$scope:{ctx:$}}}),ty=new re({}),ay=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L818"}}),sy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),q4=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[fUt]},$$scope:{ctx:$}}}),ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),C2=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[mUt]},$$scope:{ctx:$}}}),iy=new re({}),dy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L825"}}),fy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),A2=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[gUt]},$$scope:{ctx:$}}}),my=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),W2=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[hUt]},$$scope:{ctx:$}}}),gy=new re({}),hy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L834"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),U2=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[pUt]},$$scope:{ctx:$}}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),Hb=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[_Ut]},$$scope:{ctx:$}}}),by=new re({}),vy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L879"}}),Ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),Jb=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[uUt]},$$scope:{ctx:$}}}),My=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),yv=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[bUt]},$$scope:{ctx:$}}}),Ey=new re({}),Cy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L886"}}),Ay=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),$v=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[vUt]},$$scope:{ctx:$}}}),Ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),qv=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[FUt]},$$scope:{ctx:$}}}),yy=new re({}),xy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L872"}}),ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),Dv=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[TUt]},$$scope:{ctx:$}}}),Sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),CF=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[MUt]},$$scope:{ctx:$}}}),Ry=new re({}),Py=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L843"}}),Iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),AF=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[EUt]},$$scope:{ctx:$}}}),Ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),_6=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[CUt]},$$scope:{ctx:$}}}),qy=new re({}),jy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L850"}}),Gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),b6=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[wUt]},$$scope:{ctx:$}}}),Oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),T6=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[AUt]},$$scope:{ctx:$}}}),Vy=new re({}),Xy=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L895"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),E6=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[LUt]},$$scope:{ctx:$}}}),Wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),j6=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[yUt]},$$scope:{ctx:$}}}),Hy=new re({}),Uy=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L934"}}),Yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),G6=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[xUt]},$$scope:{ctx:$}}}),Ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),X6=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[$Ut]},$$scope:{ctx:$}}}),Zy=new re({}),e8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L861"}}),r8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),Q6=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[kUt]},$$scope:{ctx:$}}}),t8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),U6=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[SUt]},$$scope:{ctx:$}}}),a8=new re({}),n8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L941"}}),l8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),Y6=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[RUt]},$$scope:{ctx:$}}}),i8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),iT=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[PUt]},$$scope:{ctx:$}}}),d8=new re({}),c8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L964"}}),m8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),cT=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[BUt]},$$scope:{ctx:$}}}),g8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),uT=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[IUt]},$$scope:{ctx:$}}}),h8=new re({}),p8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L948"}}),u8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),vT=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[NUt]},$$scope:{ctx:$}}}),b8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),kT=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[qUt]},$$scope:{ctx:$}}}),v8=new re({}),F8=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L955"}}),M8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),RT=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[jUt]},$$scope:{ctx:$}}}),E8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),NT=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[DUt]},$$scope:{ctx:$}}}),w8=new re({}),A8=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L973"}}),y8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),jT=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[GUt]},$$scope:{ctx:$}}}),x8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),QT=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[OUt]},$$scope:{ctx:$}}}),$8=new re({}),k8=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L980"}}),R8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),HT=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[VUt]},$$scope:{ctx:$}}}),P8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),e7=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[XUt]},$$scope:{ctx:$}}}),B8=new re({}),I8=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L927"}}),q8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),r7=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[zUt]},$$scope:{ctx:$}}}),j8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),s7=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[QUt]},$$scope:{ctx:$}}}),G8=new re({}),O8=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L902"}}),X8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),i7=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[WUt]},$$scope:{ctx:$}}}),z8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),f7=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[HUt]},$$scope:{ctx:$}}}),Q8=new re({}),W8=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L909"}}),U8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),g7=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[UUt]},$$scope:{ctx:$}}}),J8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),F7=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[JUt]},$$scope:{ctx:$}}}),Y8=new re({}),K8=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_auto.py#L918"}}),ex=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),M7=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[YUt]},$$scope:{ctx:$}}}),ox=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),w7=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[KUt]},$$scope:{ctx:$}}}),rx=new re({}),tx=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),nx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),L7=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[ZUt]},$$scope:{ctx:$}}}),sx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),C9=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[eJt]},$$scope:{ctx:$}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L423"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),A9=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[oJt]},$$scope:{ctx:$}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),J9=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[rJt]},$$scope:{ctx:$}}}),mx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L438"}}),px=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),K9=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[tJt]},$$scope:{ctx:$}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),mM=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[aJt]},$$scope:{ctx:$}}}),ux=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L454"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/pr_17469/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),hM=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[nJt]},$$scope:{ctx:$}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),MM=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[sJt]},$$scope:{ctx:$}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L479"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),CM=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[lJt]},$$scope:{ctx:$}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),zM=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[iJt]},$$scope:{ctx:$}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L486"}}),$x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),WM=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[dJt]},$$scope:{ctx:$}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),aE=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[cJt]},$$scope:{ctx:$}}}),Sx=new re({}),Rx=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L495"}}),Bx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),sE=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[fJt]},$$scope:{ctx:$}}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),RE=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[mJt]},$$scope:{ctx:$}}}),Nx=new re({}),qx=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L531"}}),Dx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),BE=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[gJt]},$$scope:{ctx:$}}}),Gx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),ZE=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[hJt]},$$scope:{ctx:$}}}),Ox=new re({}),Vx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L538"}}),zx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),oC=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[pJt]},$$scope:{ctx:$}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),aC=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[_Jt]},$$scope:{ctx:$}}}),Hx=new re({}),Ux=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L511"}}),Yx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),sC=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[uJt]},$$scope:{ctx:$}}}),Kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[bJt]},$$scope:{ctx:$}}}),Zx=new re({}),e$=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),r$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),cC=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[vJt]},$$scope:{ctx:$}}}),t$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),kC=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[FJt]},$$scope:{ctx:$}}}),a$=new re({}),n$=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),l$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),RC=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[TJt]},$$scope:{ctx:$}}}),i$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),e5=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[MJt]},$$scope:{ctx:$}}}),d$=new re({}),c$=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),m$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),r5=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[EJt]},$$scope:{ctx:$}}}),g$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[CJt]},$$scope:{ctx:$}}}),h$=new re({}),p$=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_tf_auto.py#L547"}}),u$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[wJt]},$$scope:{ctx:$}}}),b$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),i5=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[AJt]},$$scope:{ctx:$}}}),v$=new re({}),F$=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),M$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),c5=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[LJt]},$$scope:{ctx:$}}}),E$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),q5=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[yJt]},$$scope:{ctx:$}}}),C$=new re({}),w$=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),L$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),D5=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[xJt]},$$scope:{ctx:$}}}),y$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),Y5=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[$Jt]},$$scope:{ctx:$}}}),x$=new re({}),$$=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),S$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),Z5=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[kJt]},$$scope:{ctx:$}}}),R$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),g3=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[SJt]},$$scope:{ctx:$}}}),P$=new re({}),B$=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),N$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),p3=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[RJt]},$$scope:{ctx:$}}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),A3=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PJt]},$$scope:{ctx:$}}}),j$=new re({}),D$=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),O$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),y3=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BJt]},$$scope:{ctx:$}}}),V$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),j3=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[IJt]},$$scope:{ctx:$}}}),X$=new re({}),z$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),W$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),G3=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NJt]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),K3=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qJt]},$$scope:{ctx:$}}}),U$=new re({}),J$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),K$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),e0=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[jJt]},$$scope:{ctx:$}}}),Z$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),f0=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[DJt]},$$scope:{ctx:$}}}),ek=new re({}),ok=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),tk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),g0=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[GJt]},$$scope:{ctx:$}}}),ak=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),M0=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[OJt]},$$scope:{ctx:$}}}),nk=new re({}),sk=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),ik=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),C0=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[VJt]},$$scope:{ctx:$}}}),dk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),R0=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[XJt]},$$scope:{ctx:$}}}),ck=new re({}),fk=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),gk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),B0=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[zJt]},$$scope:{ctx:$}}}),hk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),N0=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[QJt]},$$scope:{ctx:$}}}),pk=new re({}),_k=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),bk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),j0=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[WJt]},$$scope:{ctx:$}}}),vk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),O0=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[HJt]},$$scope:{ctx:$}}}),Tk=new re({}),Mk=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),Ck=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L389"}}),X0=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[UJt]},$$scope:{ctx:$}}}),wk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17469/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17469/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17469/src/transformers/models/auto/auto_factory.py#L417"}}),Q0=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[JJt]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(c.$$.fragment),h=l(),wo=a("span"),xi=o("Auto Classes"),Bf=l(),lt=a("p"),$i=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ki=a("code"),mL=o("from_pretrained()"),If=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),We=a("p"),Si=o("Instantiating one of "),Bn=a("a"),gL=o("AutoConfig"),In=o(", "),Nn=a("a"),hL=o("AutoModel"),Ri=o(`, and
`),qn=a("a"),pL=o("AutoTokenizer"),Pi=o(" will directly create a class of the relevant architecture. For instance"),Nf=l(),F(Sa.$$.fragment),He=l(),Ae=a("p"),HS=o("will create a model that is an instance of "),Bi=a("a"),US=o("BertModel"),JS=o("."),Ao=l(),Ra=a("p"),YS=o("There is one class of "),qf=a("code"),KS=o("AutoModel"),tUe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),OXe=l(),Ii=a("h2"),jf=a("a"),Uae=a("span"),F(_L.$$.fragment),aUe=l(),Jae=a("span"),nUe=o("Extending the Auto Classes"),VXe=l(),jn=a("p"),sUe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yae=a("code"),lUe=o("NewModel"),iUe=o(", make sure you have a "),Kae=a("code"),dUe=o("NewModelConfig"),cUe=o(` then you can add those to the auto
classes like this:`),XXe=l(),F(uL.$$.fragment),zXe=l(),ZS=a("p"),fUe=o("You will then be able to use the auto classes like you would usually do!"),QXe=l(),F(Df.$$.fragment),WXe=l(),Ni=a("h2"),Gf=a("a"),Zae=a("span"),F(bL.$$.fragment),mUe=l(),ene=a("span"),gUe=o("AutoConfig"),HXe=l(),Lo=a("div"),F(vL.$$.fragment),hUe=l(),FL=a("p"),pUe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),eR=a("a"),_Ue=o("from_pretrained()"),uUe=o(" class method."),bUe=l(),TL=a("p"),vUe=o("This class cannot be instantiated directly using "),one=a("code"),FUe=o("__init__()"),TUe=o(" (throws an error)."),MUe=l(),yr=a("div"),F(ML.$$.fragment),EUe=l(),rne=a("p"),CUe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),wUe=l(),qi=a("p"),AUe=o("The configuration class to instantiate is selected based on the "),tne=a("code"),LUe=o("model_type"),yUe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ane=a("code"),xUe=o("pretrained_model_name_or_path"),$Ue=o(":"),kUe=l(),A=a("ul"),Of=a("li"),nne=a("strong"),SUe=o("albert"),RUe=o(" \u2014 "),oR=a("a"),PUe=o("AlbertConfig"),BUe=o(" (ALBERT model)"),IUe=l(),Vf=a("li"),sne=a("strong"),NUe=o("bart"),qUe=o(" \u2014 "),rR=a("a"),jUe=o("BartConfig"),DUe=o(" (BART model)"),GUe=l(),Xf=a("li"),lne=a("strong"),OUe=o("beit"),VUe=o(" \u2014 "),tR=a("a"),XUe=o("BeitConfig"),zUe=o(" (BEiT model)"),QUe=l(),zf=a("li"),ine=a("strong"),WUe=o("bert"),HUe=o(" \u2014 "),aR=a("a"),UUe=o("BertConfig"),JUe=o(" (BERT model)"),YUe=l(),Qf=a("li"),dne=a("strong"),KUe=o("bert-generation"),ZUe=o(" \u2014 "),nR=a("a"),eJe=o("BertGenerationConfig"),oJe=o(" (Bert Generation model)"),rJe=l(),Wf=a("li"),cne=a("strong"),tJe=o("big_bird"),aJe=o(" \u2014 "),sR=a("a"),nJe=o("BigBirdConfig"),sJe=o(" (BigBird model)"),lJe=l(),Hf=a("li"),fne=a("strong"),iJe=o("bigbird_pegasus"),dJe=o(" \u2014 "),lR=a("a"),cJe=o("BigBirdPegasusConfig"),fJe=o(" (BigBird-Pegasus model)"),mJe=l(),Uf=a("li"),mne=a("strong"),gJe=o("blenderbot"),hJe=o(" \u2014 "),iR=a("a"),pJe=o("BlenderbotConfig"),_Je=o(" (Blenderbot model)"),uJe=l(),Jf=a("li"),gne=a("strong"),bJe=o("blenderbot-small"),vJe=o(" \u2014 "),dR=a("a"),FJe=o("BlenderbotSmallConfig"),TJe=o(" (BlenderbotSmall model)"),MJe=l(),Yf=a("li"),hne=a("strong"),EJe=o("bloom"),CJe=o(" \u2014 "),cR=a("a"),wJe=o("BloomConfig"),AJe=o(" (BLOOM model)"),LJe=l(),Kf=a("li"),pne=a("strong"),yJe=o("camembert"),xJe=o(" \u2014 "),fR=a("a"),$Je=o("CamembertConfig"),kJe=o(" (CamemBERT model)"),SJe=l(),Zf=a("li"),_ne=a("strong"),RJe=o("canine"),PJe=o(" \u2014 "),mR=a("a"),BJe=o("CanineConfig"),IJe=o(" (CANINE model)"),NJe=l(),em=a("li"),une=a("strong"),qJe=o("clip"),jJe=o(" \u2014 "),gR=a("a"),DJe=o("CLIPConfig"),GJe=o(" (CLIP model)"),OJe=l(),om=a("li"),bne=a("strong"),VJe=o("codegen"),XJe=o(" \u2014 "),hR=a("a"),zJe=o("CodeGenConfig"),QJe=o(" (CodeGen model)"),WJe=l(),rm=a("li"),vne=a("strong"),HJe=o("convbert"),UJe=o(" \u2014 "),pR=a("a"),JJe=o("ConvBertConfig"),YJe=o(" (ConvBERT model)"),KJe=l(),tm=a("li"),Fne=a("strong"),ZJe=o("convnext"),eYe=o(" \u2014 "),_R=a("a"),oYe=o("ConvNextConfig"),rYe=o(" (ConvNeXT model)"),tYe=l(),am=a("li"),Tne=a("strong"),aYe=o("ctrl"),nYe=o(" \u2014 "),uR=a("a"),sYe=o("CTRLConfig"),lYe=o(" (CTRL model)"),iYe=l(),nm=a("li"),Mne=a("strong"),dYe=o("cvt"),cYe=o(" \u2014 "),bR=a("a"),fYe=o("CvtConfig"),mYe=o(" (CvT model)"),gYe=l(),sm=a("li"),Ene=a("strong"),hYe=o("data2vec-audio"),pYe=o(" \u2014 "),vR=a("a"),_Ye=o("Data2VecAudioConfig"),uYe=o(" (Data2VecAudio model)"),bYe=l(),lm=a("li"),Cne=a("strong"),vYe=o("data2vec-text"),FYe=o(" \u2014 "),FR=a("a"),TYe=o("Data2VecTextConfig"),MYe=o(" (Data2VecText model)"),EYe=l(),im=a("li"),wne=a("strong"),CYe=o("data2vec-vision"),wYe=o(" \u2014 "),TR=a("a"),AYe=o("Data2VecVisionConfig"),LYe=o(" (Data2VecVision model)"),yYe=l(),dm=a("li"),Ane=a("strong"),xYe=o("deberta"),$Ye=o(" \u2014 "),MR=a("a"),kYe=o("DebertaConfig"),SYe=o(" (DeBERTa model)"),RYe=l(),cm=a("li"),Lne=a("strong"),PYe=o("deberta-v2"),BYe=o(" \u2014 "),ER=a("a"),IYe=o("DebertaV2Config"),NYe=o(" (DeBERTa-v2 model)"),qYe=l(),fm=a("li"),yne=a("strong"),jYe=o("decision_transformer"),DYe=o(" \u2014 "),CR=a("a"),GYe=o("DecisionTransformerConfig"),OYe=o(" (Decision Transformer model)"),VYe=l(),mm=a("li"),xne=a("strong"),XYe=o("deit"),zYe=o(" \u2014 "),wR=a("a"),QYe=o("DeiTConfig"),WYe=o(" (DeiT model)"),HYe=l(),gm=a("li"),$ne=a("strong"),UYe=o("detr"),JYe=o(" \u2014 "),AR=a("a"),YYe=o("DetrConfig"),KYe=o(" (DETR model)"),ZYe=l(),hm=a("li"),kne=a("strong"),eKe=o("distilbert"),oKe=o(" \u2014 "),LR=a("a"),rKe=o("DistilBertConfig"),tKe=o(" (DistilBERT model)"),aKe=l(),pm=a("li"),Sne=a("strong"),nKe=o("dpr"),sKe=o(" \u2014 "),yR=a("a"),lKe=o("DPRConfig"),iKe=o(" (DPR model)"),dKe=l(),_m=a("li"),Rne=a("strong"),cKe=o("dpt"),fKe=o(" \u2014 "),xR=a("a"),mKe=o("DPTConfig"),gKe=o(" (DPT model)"),hKe=l(),um=a("li"),Pne=a("strong"),pKe=o("electra"),_Ke=o(" \u2014 "),$R=a("a"),uKe=o("ElectraConfig"),bKe=o(" (ELECTRA model)"),vKe=l(),bm=a("li"),Bne=a("strong"),FKe=o("encoder-decoder"),TKe=o(" \u2014 "),kR=a("a"),MKe=o("EncoderDecoderConfig"),EKe=o(" (Encoder decoder model)"),CKe=l(),vm=a("li"),Ine=a("strong"),wKe=o("flaubert"),AKe=o(" \u2014 "),SR=a("a"),LKe=o("FlaubertConfig"),yKe=o(" (FlauBERT model)"),xKe=l(),Fm=a("li"),Nne=a("strong"),$Ke=o("flava"),kKe=o(" \u2014 "),RR=a("a"),SKe=o("FlavaConfig"),RKe=o(" (FLAVA model)"),PKe=l(),Tm=a("li"),qne=a("strong"),BKe=o("fnet"),IKe=o(" \u2014 "),PR=a("a"),NKe=o("FNetConfig"),qKe=o(" (FNet model)"),jKe=l(),Mm=a("li"),jne=a("strong"),DKe=o("fsmt"),GKe=o(" \u2014 "),BR=a("a"),OKe=o("FSMTConfig"),VKe=o(" (FairSeq Machine-Translation model)"),XKe=l(),Em=a("li"),Dne=a("strong"),zKe=o("funnel"),QKe=o(" \u2014 "),IR=a("a"),WKe=o("FunnelConfig"),HKe=o(" (Funnel Transformer model)"),UKe=l(),Cm=a("li"),Gne=a("strong"),JKe=o("glpn"),YKe=o(" \u2014 "),NR=a("a"),KKe=o("GLPNConfig"),ZKe=o(" (GLPN model)"),eZe=l(),wm=a("li"),One=a("strong"),oZe=o("gpt2"),rZe=o(" \u2014 "),qR=a("a"),tZe=o("GPT2Config"),aZe=o(" (OpenAI GPT-2 model)"),nZe=l(),Am=a("li"),Vne=a("strong"),sZe=o("gpt_neo"),lZe=o(" \u2014 "),jR=a("a"),iZe=o("GPTNeoConfig"),dZe=o(" (GPT Neo model)"),cZe=l(),Lm=a("li"),Xne=a("strong"),fZe=o("gpt_neox"),mZe=o(" \u2014 "),DR=a("a"),gZe=o("GPTNeoXConfig"),hZe=o(" (GPT NeoX model)"),pZe=l(),ym=a("li"),zne=a("strong"),_Ze=o("gptj"),uZe=o(" \u2014 "),GR=a("a"),bZe=o("GPTJConfig"),vZe=o(" (GPT-J model)"),FZe=l(),xm=a("li"),Qne=a("strong"),TZe=o("groupvit"),MZe=o(" \u2014 "),OR=a("a"),EZe=o("GroupViTConfig"),CZe=o(" (GroupViT model)"),wZe=l(),$m=a("li"),Wne=a("strong"),AZe=o("hubert"),LZe=o(" \u2014 "),VR=a("a"),yZe=o("HubertConfig"),xZe=o(" (Hubert model)"),$Ze=l(),km=a("li"),Hne=a("strong"),kZe=o("ibert"),SZe=o(" \u2014 "),XR=a("a"),RZe=o("IBertConfig"),PZe=o(" (I-BERT model)"),BZe=l(),Sm=a("li"),Une=a("strong"),IZe=o("imagegpt"),NZe=o(" \u2014 "),zR=a("a"),qZe=o("ImageGPTConfig"),jZe=o(" (ImageGPT model)"),DZe=l(),Rm=a("li"),Jne=a("strong"),GZe=o("layoutlm"),OZe=o(" \u2014 "),QR=a("a"),VZe=o("LayoutLMConfig"),XZe=o(" (LayoutLM model)"),zZe=l(),Pm=a("li"),Yne=a("strong"),QZe=o("layoutlmv2"),WZe=o(" \u2014 "),WR=a("a"),HZe=o("LayoutLMv2Config"),UZe=o(" (LayoutLMv2 model)"),JZe=l(),Bm=a("li"),Kne=a("strong"),YZe=o("layoutlmv3"),KZe=o(" \u2014 "),HR=a("a"),ZZe=o("LayoutLMv3Config"),eeo=o(" (LayoutLMv3 model)"),oeo=l(),Im=a("li"),Zne=a("strong"),reo=o("led"),teo=o(" \u2014 "),UR=a("a"),aeo=o("LEDConfig"),neo=o(" (LED model)"),seo=l(),Nm=a("li"),ese=a("strong"),leo=o("levit"),ieo=o(" \u2014 "),JR=a("a"),deo=o("LevitConfig"),ceo=o(" (LeViT model)"),feo=l(),qm=a("li"),ose=a("strong"),meo=o("longformer"),geo=o(" \u2014 "),YR=a("a"),heo=o("LongformerConfig"),peo=o(" (Longformer model)"),_eo=l(),jm=a("li"),rse=a("strong"),ueo=o("longt5"),beo=o(" \u2014 "),KR=a("a"),veo=o("LongT5Config"),Feo=o(" (LongT5 model)"),Teo=l(),Dm=a("li"),tse=a("strong"),Meo=o("luke"),Eeo=o(" \u2014 "),ZR=a("a"),Ceo=o("LukeConfig"),weo=o(" (LUKE model)"),Aeo=l(),Gm=a("li"),ase=a("strong"),Leo=o("lxmert"),yeo=o(" \u2014 "),eP=a("a"),xeo=o("LxmertConfig"),$eo=o(" (LXMERT model)"),keo=l(),Om=a("li"),nse=a("strong"),Seo=o("m2m_100"),Reo=o(" \u2014 "),oP=a("a"),Peo=o("M2M100Config"),Beo=o(" (M2M100 model)"),Ieo=l(),Vm=a("li"),sse=a("strong"),Neo=o("marian"),qeo=o(" \u2014 "),rP=a("a"),jeo=o("MarianConfig"),Deo=o(" (Marian model)"),Geo=l(),Xm=a("li"),lse=a("strong"),Oeo=o("maskformer"),Veo=o(" \u2014 "),tP=a("a"),Xeo=o("MaskFormerConfig"),zeo=o(" (MaskFormer model)"),Qeo=l(),zm=a("li"),ise=a("strong"),Weo=o("mbart"),Heo=o(" \u2014 "),aP=a("a"),Ueo=o("MBartConfig"),Jeo=o(" (mBART model)"),Yeo=l(),Qm=a("li"),dse=a("strong"),Keo=o("mctct"),Zeo=o(" \u2014 "),nP=a("a"),eoo=o("MCTCTConfig"),ooo=o(" (M-CTC-T model)"),roo=l(),Wm=a("li"),cse=a("strong"),too=o("megatron-bert"),aoo=o(" \u2014 "),sP=a("a"),noo=o("MegatronBertConfig"),soo=o(" (Megatron-BERT model)"),loo=l(),Hm=a("li"),fse=a("strong"),ioo=o("mobilebert"),doo=o(" \u2014 "),lP=a("a"),coo=o("MobileBertConfig"),foo=o(" (MobileBERT model)"),moo=l(),Um=a("li"),mse=a("strong"),goo=o("mobilevit"),hoo=o(" \u2014 "),iP=a("a"),poo=o("MobileViTConfig"),_oo=o(" (MobileViT model)"),uoo=l(),Jm=a("li"),gse=a("strong"),boo=o("mpnet"),voo=o(" \u2014 "),dP=a("a"),Foo=o("MPNetConfig"),Too=o(" (MPNet model)"),Moo=l(),Ym=a("li"),hse=a("strong"),Eoo=o("mt5"),Coo=o(" \u2014 "),cP=a("a"),woo=o("MT5Config"),Aoo=o(" (MT5 model)"),Loo=l(),Km=a("li"),pse=a("strong"),yoo=o("mvp"),xoo=o(" \u2014 "),fP=a("a"),$oo=o("MvpConfig"),koo=o(" (MVP model)"),Soo=l(),Zm=a("li"),_se=a("strong"),Roo=o("nezha"),Poo=o(" \u2014 "),mP=a("a"),Boo=o("NezhaConfig"),Ioo=o(" (Nezha model)"),Noo=l(),eg=a("li"),use=a("strong"),qoo=o("nystromformer"),joo=o(" \u2014 "),gP=a("a"),Doo=o("NystromformerConfig"),Goo=o(" (Nystr\xF6mformer model)"),Ooo=l(),og=a("li"),bse=a("strong"),Voo=o("openai-gpt"),Xoo=o(" \u2014 "),hP=a("a"),zoo=o("OpenAIGPTConfig"),Qoo=o(" (OpenAI GPT model)"),Woo=l(),rg=a("li"),vse=a("strong"),Hoo=o("opt"),Uoo=o(" \u2014 "),pP=a("a"),Joo=o("OPTConfig"),Yoo=o(" (OPT model)"),Koo=l(),tg=a("li"),Fse=a("strong"),Zoo=o("pegasus"),ero=o(" \u2014 "),_P=a("a"),oro=o("PegasusConfig"),rro=o(" (Pegasus model)"),tro=l(),ag=a("li"),Tse=a("strong"),aro=o("perceiver"),nro=o(" \u2014 "),uP=a("a"),sro=o("PerceiverConfig"),lro=o(" (Perceiver model)"),iro=l(),ng=a("li"),Mse=a("strong"),dro=o("plbart"),cro=o(" \u2014 "),bP=a("a"),fro=o("PLBartConfig"),mro=o(" (PLBart model)"),gro=l(),sg=a("li"),Ese=a("strong"),hro=o("poolformer"),pro=o(" \u2014 "),vP=a("a"),_ro=o("PoolFormerConfig"),uro=o(" (PoolFormer model)"),bro=l(),lg=a("li"),Cse=a("strong"),vro=o("prophetnet"),Fro=o(" \u2014 "),FP=a("a"),Tro=o("ProphetNetConfig"),Mro=o(" (ProphetNet model)"),Ero=l(),ig=a("li"),wse=a("strong"),Cro=o("qdqbert"),wro=o(" \u2014 "),TP=a("a"),Aro=o("QDQBertConfig"),Lro=o(" (QDQBert model)"),yro=l(),dg=a("li"),Ase=a("strong"),xro=o("rag"),$ro=o(" \u2014 "),MP=a("a"),kro=o("RagConfig"),Sro=o(" (RAG model)"),Rro=l(),cg=a("li"),Lse=a("strong"),Pro=o("realm"),Bro=o(" \u2014 "),EP=a("a"),Iro=o("RealmConfig"),Nro=o(" (REALM model)"),qro=l(),fg=a("li"),yse=a("strong"),jro=o("reformer"),Dro=o(" \u2014 "),CP=a("a"),Gro=o("ReformerConfig"),Oro=o(" (Reformer model)"),Vro=l(),mg=a("li"),xse=a("strong"),Xro=o("regnet"),zro=o(" \u2014 "),wP=a("a"),Qro=o("RegNetConfig"),Wro=o(" (RegNet model)"),Hro=l(),gg=a("li"),$se=a("strong"),Uro=o("rembert"),Jro=o(" \u2014 "),AP=a("a"),Yro=o("RemBertConfig"),Kro=o(" (RemBERT model)"),Zro=l(),hg=a("li"),kse=a("strong"),eto=o("resnet"),oto=o(" \u2014 "),LP=a("a"),rto=o("ResNetConfig"),tto=o(" (ResNet model)"),ato=l(),pg=a("li"),Sse=a("strong"),nto=o("retribert"),sto=o(" \u2014 "),yP=a("a"),lto=o("RetriBertConfig"),ito=o(" (RetriBERT model)"),dto=l(),_g=a("li"),Rse=a("strong"),cto=o("roberta"),fto=o(" \u2014 "),xP=a("a"),mto=o("RobertaConfig"),gto=o(" (RoBERTa model)"),hto=l(),ug=a("li"),Pse=a("strong"),pto=o("roformer"),_to=o(" \u2014 "),$P=a("a"),uto=o("RoFormerConfig"),bto=o(" (RoFormer model)"),vto=l(),bg=a("li"),Bse=a("strong"),Fto=o("segformer"),Tto=o(" \u2014 "),kP=a("a"),Mto=o("SegformerConfig"),Eto=o(" (SegFormer model)"),Cto=l(),vg=a("li"),Ise=a("strong"),wto=o("sew"),Ato=o(" \u2014 "),SP=a("a"),Lto=o("SEWConfig"),yto=o(" (SEW model)"),xto=l(),Fg=a("li"),Nse=a("strong"),$to=o("sew-d"),kto=o(" \u2014 "),RP=a("a"),Sto=o("SEWDConfig"),Rto=o(" (SEW-D model)"),Pto=l(),Tg=a("li"),qse=a("strong"),Bto=o("speech-encoder-decoder"),Ito=o(" \u2014 "),PP=a("a"),Nto=o("SpeechEncoderDecoderConfig"),qto=o(" (Speech Encoder decoder model)"),jto=l(),Mg=a("li"),jse=a("strong"),Dto=o("speech_to_text"),Gto=o(" \u2014 "),BP=a("a"),Oto=o("Speech2TextConfig"),Vto=o(" (Speech2Text model)"),Xto=l(),Eg=a("li"),Dse=a("strong"),zto=o("speech_to_text_2"),Qto=o(" \u2014 "),IP=a("a"),Wto=o("Speech2Text2Config"),Hto=o(" (Speech2Text2 model)"),Uto=l(),Cg=a("li"),Gse=a("strong"),Jto=o("splinter"),Yto=o(" \u2014 "),NP=a("a"),Kto=o("SplinterConfig"),Zto=o(" (Splinter model)"),eao=l(),wg=a("li"),Ose=a("strong"),oao=o("squeezebert"),rao=o(" \u2014 "),qP=a("a"),tao=o("SqueezeBertConfig"),aao=o(" (SqueezeBERT model)"),nao=l(),Ag=a("li"),Vse=a("strong"),sao=o("swin"),lao=o(" \u2014 "),jP=a("a"),iao=o("SwinConfig"),dao=o(" (Swin Transformer model)"),cao=l(),Lg=a("li"),Xse=a("strong"),fao=o("swinv2"),mao=o(" \u2014 "),DP=a("a"),gao=o("Swinv2Config"),hao=o(" (Swin Transformer V2 model)"),pao=l(),yg=a("li"),zse=a("strong"),_ao=o("t5"),uao=o(" \u2014 "),GP=a("a"),bao=o("T5Config"),vao=o(" (T5 model)"),Fao=l(),xg=a("li"),Qse=a("strong"),Tao=o("tapas"),Mao=o(" \u2014 "),OP=a("a"),Eao=o("TapasConfig"),Cao=o(" (TAPAS model)"),wao=l(),$g=a("li"),Wse=a("strong"),Aao=o("trajectory_transformer"),Lao=o(" \u2014 "),VP=a("a"),yao=o("TrajectoryTransformerConfig"),xao=o(" (Trajectory Transformer model)"),$ao=l(),kg=a("li"),Hse=a("strong"),kao=o("transfo-xl"),Sao=o(" \u2014 "),XP=a("a"),Rao=o("TransfoXLConfig"),Pao=o(" (Transformer-XL model)"),Bao=l(),Sg=a("li"),Use=a("strong"),Iao=o("trocr"),Nao=o(" \u2014 "),zP=a("a"),qao=o("TrOCRConfig"),jao=o(" (TrOCR model)"),Dao=l(),Rg=a("li"),Jse=a("strong"),Gao=o("unispeech"),Oao=o(" \u2014 "),QP=a("a"),Vao=o("UniSpeechConfig"),Xao=o(" (UniSpeech model)"),zao=l(),Pg=a("li"),Yse=a("strong"),Qao=o("unispeech-sat"),Wao=o(" \u2014 "),WP=a("a"),Hao=o("UniSpeechSatConfig"),Uao=o(" (UniSpeechSat model)"),Jao=l(),Bg=a("li"),Kse=a("strong"),Yao=o("van"),Kao=o(" \u2014 "),HP=a("a"),Zao=o("VanConfig"),eno=o(" (VAN model)"),ono=l(),Ig=a("li"),Zse=a("strong"),rno=o("vilt"),tno=o(" \u2014 "),UP=a("a"),ano=o("ViltConfig"),nno=o(" (ViLT model)"),sno=l(),Ng=a("li"),ele=a("strong"),lno=o("vision-encoder-decoder"),ino=o(" \u2014 "),JP=a("a"),dno=o("VisionEncoderDecoderConfig"),cno=o(" (Vision Encoder decoder model)"),fno=l(),qg=a("li"),ole=a("strong"),mno=o("vision-text-dual-encoder"),gno=o(" \u2014 "),YP=a("a"),hno=o("VisionTextDualEncoderConfig"),pno=o(" (VisionTextDualEncoder model)"),_no=l(),jg=a("li"),rle=a("strong"),uno=o("visual_bert"),bno=o(" \u2014 "),KP=a("a"),vno=o("VisualBertConfig"),Fno=o(" (VisualBERT model)"),Tno=l(),Dg=a("li"),tle=a("strong"),Mno=o("vit"),Eno=o(" \u2014 "),ZP=a("a"),Cno=o("ViTConfig"),wno=o(" (ViT model)"),Ano=l(),Gg=a("li"),ale=a("strong"),Lno=o("vit_mae"),yno=o(" \u2014 "),eB=a("a"),xno=o("ViTMAEConfig"),$no=o(" (ViTMAE model)"),kno=l(),Og=a("li"),nle=a("strong"),Sno=o("wav2vec2"),Rno=o(" \u2014 "),oB=a("a"),Pno=o("Wav2Vec2Config"),Bno=o(" (Wav2Vec2 model)"),Ino=l(),Vg=a("li"),sle=a("strong"),Nno=o("wav2vec2-conformer"),qno=o(" \u2014 "),rB=a("a"),jno=o("Wav2Vec2ConformerConfig"),Dno=o(" (Wav2Vec2-Conformer model)"),Gno=l(),Xg=a("li"),lle=a("strong"),Ono=o("wavlm"),Vno=o(" \u2014 "),tB=a("a"),Xno=o("WavLMConfig"),zno=o(" (WavLM model)"),Qno=l(),zg=a("li"),ile=a("strong"),Wno=o("xglm"),Hno=o(" \u2014 "),aB=a("a"),Uno=o("XGLMConfig"),Jno=o(" (XGLM model)"),Yno=l(),Qg=a("li"),dle=a("strong"),Kno=o("xlm"),Zno=o(" \u2014 "),nB=a("a"),eso=o("XLMConfig"),oso=o(" (XLM model)"),rso=l(),Wg=a("li"),cle=a("strong"),tso=o("xlm-prophetnet"),aso=o(" \u2014 "),sB=a("a"),nso=o("XLMProphetNetConfig"),sso=o(" (XLM-ProphetNet model)"),lso=l(),Hg=a("li"),fle=a("strong"),iso=o("xlm-roberta"),dso=o(" \u2014 "),lB=a("a"),cso=o("XLMRobertaConfig"),fso=o(" (XLM-RoBERTa model)"),mso=l(),Ug=a("li"),mle=a("strong"),gso=o("xlm-roberta-xl"),hso=o(" \u2014 "),iB=a("a"),pso=o("XLMRobertaXLConfig"),_so=o(" (XLM-RoBERTa-XL model)"),uso=l(),Jg=a("li"),gle=a("strong"),bso=o("xlnet"),vso=o(" \u2014 "),dB=a("a"),Fso=o("XLNetConfig"),Tso=o(" (XLNet model)"),Mso=l(),Yg=a("li"),hle=a("strong"),Eso=o("yolos"),Cso=o(" \u2014 "),cB=a("a"),wso=o("YolosConfig"),Aso=o(" (YOLOS model)"),Lso=l(),Kg=a("li"),ple=a("strong"),yso=o("yoso"),xso=o(" \u2014 "),fB=a("a"),$so=o("YosoConfig"),kso=o(" (YOSO model)"),Sso=l(),F(Zg.$$.fragment),Rso=l(),eh=a("div"),F(EL.$$.fragment),Pso=l(),_le=a("p"),Bso=o("Register a new configuration for this class."),UXe=l(),ji=a("h2"),oh=a("a"),ule=a("span"),F(CL.$$.fragment),Iso=l(),ble=a("span"),Nso=o("AutoTokenizer"),JXe=l(),yo=a("div"),F(wL.$$.fragment),qso=l(),AL=a("p"),jso=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),mB=a("a"),Dso=o("AutoTokenizer.from_pretrained()"),Gso=o(" class method."),Oso=l(),LL=a("p"),Vso=o("This class cannot be instantiated directly using "),vle=a("code"),Xso=o("__init__()"),zso=o(" (throws an error)."),Qso=l(),xr=a("div"),F(yL.$$.fragment),Wso=l(),Fle=a("p"),Hso=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Uso=l(),Pa=a("p"),Jso=o("The tokenizer class to instantiate is selected based on the "),Tle=a("code"),Yso=o("model_type"),Kso=o(` property of the config object (either
passed as an argument or loaded from `),Mle=a("code"),Zso=o("pretrained_model_name_or_path"),elo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ele=a("code"),olo=o("pretrained_model_name_or_path"),rlo=o(":"),tlo=l(),k=a("ul"),Dn=a("li"),Cle=a("strong"),alo=o("albert"),nlo=o(" \u2014 "),gB=a("a"),slo=o("AlbertTokenizer"),llo=o(" or "),hB=a("a"),ilo=o("AlbertTokenizerFast"),dlo=o(" (ALBERT model)"),clo=l(),Gn=a("li"),wle=a("strong"),flo=o("bart"),mlo=o(" \u2014 "),pB=a("a"),glo=o("BartTokenizer"),hlo=o(" or "),_B=a("a"),plo=o("BartTokenizerFast"),_lo=o(" (BART model)"),ulo=l(),On=a("li"),Ale=a("strong"),blo=o("barthez"),vlo=o(" \u2014 "),uB=a("a"),Flo=o("BarthezTokenizer"),Tlo=o(" or "),bB=a("a"),Mlo=o("BarthezTokenizerFast"),Elo=o(" (BARThez model)"),Clo=l(),rh=a("li"),Lle=a("strong"),wlo=o("bartpho"),Alo=o(" \u2014 "),vB=a("a"),Llo=o("BartphoTokenizer"),ylo=o(" (BARTpho model)"),xlo=l(),Vn=a("li"),yle=a("strong"),$lo=o("bert"),klo=o(" \u2014 "),FB=a("a"),Slo=o("BertTokenizer"),Rlo=o(" or "),TB=a("a"),Plo=o("BertTokenizerFast"),Blo=o(" (BERT model)"),Ilo=l(),th=a("li"),xle=a("strong"),Nlo=o("bert-generation"),qlo=o(" \u2014 "),MB=a("a"),jlo=o("BertGenerationTokenizer"),Dlo=o(" (Bert Generation model)"),Glo=l(),ah=a("li"),$le=a("strong"),Olo=o("bert-japanese"),Vlo=o(" \u2014 "),EB=a("a"),Xlo=o("BertJapaneseTokenizer"),zlo=o(" (BertJapanese model)"),Qlo=l(),nh=a("li"),kle=a("strong"),Wlo=o("bertweet"),Hlo=o(" \u2014 "),CB=a("a"),Ulo=o("BertweetTokenizer"),Jlo=o(" (BERTweet model)"),Ylo=l(),Xn=a("li"),Sle=a("strong"),Klo=o("big_bird"),Zlo=o(" \u2014 "),wB=a("a"),eio=o("BigBirdTokenizer"),oio=o(" or "),AB=a("a"),rio=o("BigBirdTokenizerFast"),tio=o(" (BigBird model)"),aio=l(),zn=a("li"),Rle=a("strong"),nio=o("bigbird_pegasus"),sio=o(" \u2014 "),LB=a("a"),lio=o("PegasusTokenizer"),iio=o(" or "),yB=a("a"),dio=o("PegasusTokenizerFast"),cio=o(" (BigBird-Pegasus model)"),fio=l(),Qn=a("li"),Ple=a("strong"),mio=o("blenderbot"),gio=o(" \u2014 "),xB=a("a"),hio=o("BlenderbotTokenizer"),pio=o(" or "),$B=a("a"),_io=o("BlenderbotTokenizerFast"),uio=o(" (Blenderbot model)"),bio=l(),sh=a("li"),Ble=a("strong"),vio=o("blenderbot-small"),Fio=o(" \u2014 "),kB=a("a"),Tio=o("BlenderbotSmallTokenizer"),Mio=o(" (BlenderbotSmall model)"),Eio=l(),lh=a("li"),Ile=a("strong"),Cio=o("bloom"),wio=o(" \u2014 "),SB=a("a"),Aio=o("BloomTokenizerFast"),Lio=o(" (BLOOM model)"),yio=l(),ih=a("li"),Nle=a("strong"),xio=o("byt5"),$io=o(" \u2014 "),RB=a("a"),kio=o("ByT5Tokenizer"),Sio=o(" (ByT5 model)"),Rio=l(),Wn=a("li"),qle=a("strong"),Pio=o("camembert"),Bio=o(" \u2014 "),PB=a("a"),Iio=o("CamembertTokenizer"),Nio=o(" or "),BB=a("a"),qio=o("CamembertTokenizerFast"),jio=o(" (CamemBERT model)"),Dio=l(),dh=a("li"),jle=a("strong"),Gio=o("canine"),Oio=o(" \u2014 "),IB=a("a"),Vio=o("CanineTokenizer"),Xio=o(" (CANINE model)"),zio=l(),Hn=a("li"),Dle=a("strong"),Qio=o("clip"),Wio=o(" \u2014 "),NB=a("a"),Hio=o("CLIPTokenizer"),Uio=o(" or "),qB=a("a"),Jio=o("CLIPTokenizerFast"),Yio=o(" (CLIP model)"),Kio=l(),Un=a("li"),Gle=a("strong"),Zio=o("codegen"),edo=o(" \u2014 "),jB=a("a"),odo=o("CodeGenTokenizer"),rdo=o(" or "),DB=a("a"),tdo=o("CodeGenTokenizerFast"),ado=o(" (CodeGen model)"),ndo=l(),Jn=a("li"),Ole=a("strong"),sdo=o("convbert"),ldo=o(" \u2014 "),GB=a("a"),ido=o("ConvBertTokenizer"),ddo=o(" or "),OB=a("a"),cdo=o("ConvBertTokenizerFast"),fdo=o(" (ConvBERT model)"),mdo=l(),Yn=a("li"),Vle=a("strong"),gdo=o("cpm"),hdo=o(" \u2014 "),VB=a("a"),pdo=o("CpmTokenizer"),_do=o(" or "),XB=a("a"),udo=o("CpmTokenizerFast"),bdo=o(" (CPM model)"),vdo=l(),ch=a("li"),Xle=a("strong"),Fdo=o("ctrl"),Tdo=o(" \u2014 "),zB=a("a"),Mdo=o("CTRLTokenizer"),Edo=o(" (CTRL model)"),Cdo=l(),Kn=a("li"),zle=a("strong"),wdo=o("data2vec-text"),Ado=o(" \u2014 "),QB=a("a"),Ldo=o("RobertaTokenizer"),ydo=o(" or "),WB=a("a"),xdo=o("RobertaTokenizerFast"),$do=o(" (Data2VecText model)"),kdo=l(),Zn=a("li"),Qle=a("strong"),Sdo=o("deberta"),Rdo=o(" \u2014 "),HB=a("a"),Pdo=o("DebertaTokenizer"),Bdo=o(" or "),UB=a("a"),Ido=o("DebertaTokenizerFast"),Ndo=o(" (DeBERTa model)"),qdo=l(),es=a("li"),Wle=a("strong"),jdo=o("deberta-v2"),Ddo=o(" \u2014 "),JB=a("a"),Gdo=o("DebertaV2Tokenizer"),Odo=o(" or "),YB=a("a"),Vdo=o("DebertaV2TokenizerFast"),Xdo=o(" (DeBERTa-v2 model)"),zdo=l(),os=a("li"),Hle=a("strong"),Qdo=o("distilbert"),Wdo=o(" \u2014 "),KB=a("a"),Hdo=o("DistilBertTokenizer"),Udo=o(" or "),ZB=a("a"),Jdo=o("DistilBertTokenizerFast"),Ydo=o(" (DistilBERT model)"),Kdo=l(),rs=a("li"),Ule=a("strong"),Zdo=o("dpr"),eco=o(" \u2014 "),eI=a("a"),oco=o("DPRQuestionEncoderTokenizer"),rco=o(" or "),oI=a("a"),tco=o("DPRQuestionEncoderTokenizerFast"),aco=o(" (DPR model)"),nco=l(),ts=a("li"),Jle=a("strong"),sco=o("electra"),lco=o(" \u2014 "),rI=a("a"),ico=o("ElectraTokenizer"),dco=o(" or "),tI=a("a"),cco=o("ElectraTokenizerFast"),fco=o(" (ELECTRA model)"),mco=l(),fh=a("li"),Yle=a("strong"),gco=o("flaubert"),hco=o(" \u2014 "),aI=a("a"),pco=o("FlaubertTokenizer"),_co=o(" (FlauBERT model)"),uco=l(),as=a("li"),Kle=a("strong"),bco=o("fnet"),vco=o(" \u2014 "),nI=a("a"),Fco=o("FNetTokenizer"),Tco=o(" or "),sI=a("a"),Mco=o("FNetTokenizerFast"),Eco=o(" (FNet model)"),Cco=l(),mh=a("li"),Zle=a("strong"),wco=o("fsmt"),Aco=o(" \u2014 "),lI=a("a"),Lco=o("FSMTTokenizer"),yco=o(" (FairSeq Machine-Translation model)"),xco=l(),ns=a("li"),eie=a("strong"),$co=o("funnel"),kco=o(" \u2014 "),iI=a("a"),Sco=o("FunnelTokenizer"),Rco=o(" or "),dI=a("a"),Pco=o("FunnelTokenizerFast"),Bco=o(" (Funnel Transformer model)"),Ico=l(),ss=a("li"),oie=a("strong"),Nco=o("gpt2"),qco=o(" \u2014 "),cI=a("a"),jco=o("GPT2Tokenizer"),Dco=o(" or "),fI=a("a"),Gco=o("GPT2TokenizerFast"),Oco=o(" (OpenAI GPT-2 model)"),Vco=l(),ls=a("li"),rie=a("strong"),Xco=o("gpt_neo"),zco=o(" \u2014 "),mI=a("a"),Qco=o("GPT2Tokenizer"),Wco=o(" or "),gI=a("a"),Hco=o("GPT2TokenizerFast"),Uco=o(" (GPT Neo model)"),Jco=l(),gh=a("li"),tie=a("strong"),Yco=o("gpt_neox"),Kco=o(" \u2014 "),hI=a("a"),Zco=o("GPTNeoXTokenizerFast"),efo=o(" (GPT NeoX model)"),ofo=l(),is=a("li"),aie=a("strong"),rfo=o("gptj"),tfo=o(" \u2014 "),pI=a("a"),afo=o("GPT2Tokenizer"),nfo=o(" or "),_I=a("a"),sfo=o("GPT2TokenizerFast"),lfo=o(" (GPT-J model)"),ifo=l(),ds=a("li"),nie=a("strong"),dfo=o("groupvit"),cfo=o(" \u2014 "),uI=a("a"),ffo=o("CLIPTokenizer"),mfo=o(" or "),bI=a("a"),gfo=o("CLIPTokenizerFast"),hfo=o(" (GroupViT model)"),pfo=l(),cs=a("li"),sie=a("strong"),_fo=o("herbert"),ufo=o(" \u2014 "),vI=a("a"),bfo=o("HerbertTokenizer"),vfo=o(" or "),FI=a("a"),Ffo=o("HerbertTokenizerFast"),Tfo=o(" (HerBERT model)"),Mfo=l(),hh=a("li"),lie=a("strong"),Efo=o("hubert"),Cfo=o(" \u2014 "),TI=a("a"),wfo=o("Wav2Vec2CTCTokenizer"),Afo=o(" (Hubert model)"),Lfo=l(),fs=a("li"),iie=a("strong"),yfo=o("ibert"),xfo=o(" \u2014 "),MI=a("a"),$fo=o("RobertaTokenizer"),kfo=o(" or "),EI=a("a"),Sfo=o("RobertaTokenizerFast"),Rfo=o(" (I-BERT model)"),Pfo=l(),ms=a("li"),die=a("strong"),Bfo=o("layoutlm"),Ifo=o(" \u2014 "),CI=a("a"),Nfo=o("LayoutLMTokenizer"),qfo=o(" or "),wI=a("a"),jfo=o("LayoutLMTokenizerFast"),Dfo=o(" (LayoutLM model)"),Gfo=l(),gs=a("li"),cie=a("strong"),Ofo=o("layoutlmv2"),Vfo=o(" \u2014 "),AI=a("a"),Xfo=o("LayoutLMv2Tokenizer"),zfo=o(" or "),LI=a("a"),Qfo=o("LayoutLMv2TokenizerFast"),Wfo=o(" (LayoutLMv2 model)"),Hfo=l(),hs=a("li"),fie=a("strong"),Ufo=o("layoutlmv3"),Jfo=o(" \u2014 "),yI=a("a"),Yfo=o("LayoutLMv3Tokenizer"),Kfo=o(" or "),xI=a("a"),Zfo=o("LayoutLMv3TokenizerFast"),emo=o(" (LayoutLMv3 model)"),omo=l(),ps=a("li"),mie=a("strong"),rmo=o("layoutxlm"),tmo=o(" \u2014 "),$I=a("a"),amo=o("LayoutXLMTokenizer"),nmo=o(" or "),kI=a("a"),smo=o("LayoutXLMTokenizerFast"),lmo=o(" (LayoutXLM model)"),imo=l(),_s=a("li"),gie=a("strong"),dmo=o("led"),cmo=o(" \u2014 "),SI=a("a"),fmo=o("LEDTokenizer"),mmo=o(" or "),RI=a("a"),gmo=o("LEDTokenizerFast"),hmo=o(" (LED model)"),pmo=l(),us=a("li"),hie=a("strong"),_mo=o("longformer"),umo=o(" \u2014 "),PI=a("a"),bmo=o("LongformerTokenizer"),vmo=o(" or "),BI=a("a"),Fmo=o("LongformerTokenizerFast"),Tmo=o(" (Longformer model)"),Mmo=l(),bs=a("li"),pie=a("strong"),Emo=o("longt5"),Cmo=o(" \u2014 "),II=a("a"),wmo=o("T5Tokenizer"),Amo=o(" or "),NI=a("a"),Lmo=o("T5TokenizerFast"),ymo=o(" (LongT5 model)"),xmo=l(),ph=a("li"),_ie=a("strong"),$mo=o("luke"),kmo=o(" \u2014 "),qI=a("a"),Smo=o("LukeTokenizer"),Rmo=o(" (LUKE model)"),Pmo=l(),vs=a("li"),uie=a("strong"),Bmo=o("lxmert"),Imo=o(" \u2014 "),jI=a("a"),Nmo=o("LxmertTokenizer"),qmo=o(" or "),DI=a("a"),jmo=o("LxmertTokenizerFast"),Dmo=o(" (LXMERT model)"),Gmo=l(),_h=a("li"),bie=a("strong"),Omo=o("m2m_100"),Vmo=o(" \u2014 "),GI=a("a"),Xmo=o("M2M100Tokenizer"),zmo=o(" (M2M100 model)"),Qmo=l(),uh=a("li"),vie=a("strong"),Wmo=o("marian"),Hmo=o(" \u2014 "),OI=a("a"),Umo=o("MarianTokenizer"),Jmo=o(" (Marian model)"),Ymo=l(),Fs=a("li"),Fie=a("strong"),Kmo=o("mbart"),Zmo=o(" \u2014 "),VI=a("a"),ego=o("MBartTokenizer"),ogo=o(" or "),XI=a("a"),rgo=o("MBartTokenizerFast"),tgo=o(" (mBART model)"),ago=l(),Ts=a("li"),Tie=a("strong"),ngo=o("mbart50"),sgo=o(" \u2014 "),zI=a("a"),lgo=o("MBart50Tokenizer"),igo=o(" or "),QI=a("a"),dgo=o("MBart50TokenizerFast"),cgo=o(" (mBART-50 model)"),fgo=l(),Ms=a("li"),Mie=a("strong"),mgo=o("megatron-bert"),ggo=o(" \u2014 "),WI=a("a"),hgo=o("BertTokenizer"),pgo=o(" or "),HI=a("a"),_go=o("BertTokenizerFast"),ugo=o(" (Megatron-BERT model)"),bgo=l(),bh=a("li"),Eie=a("strong"),vgo=o("mluke"),Fgo=o(" \u2014 "),UI=a("a"),Tgo=o("MLukeTokenizer"),Mgo=o(" (mLUKE model)"),Ego=l(),Es=a("li"),Cie=a("strong"),Cgo=o("mobilebert"),wgo=o(" \u2014 "),JI=a("a"),Ago=o("MobileBertTokenizer"),Lgo=o(" or "),YI=a("a"),ygo=o("MobileBertTokenizerFast"),xgo=o(" (MobileBERT model)"),$go=l(),Cs=a("li"),wie=a("strong"),kgo=o("mpnet"),Sgo=o(" \u2014 "),KI=a("a"),Rgo=o("MPNetTokenizer"),Pgo=o(" or "),ZI=a("a"),Bgo=o("MPNetTokenizerFast"),Igo=o(" (MPNet model)"),Ngo=l(),ws=a("li"),Aie=a("strong"),qgo=o("mt5"),jgo=o(" \u2014 "),eN=a("a"),Dgo=o("MT5Tokenizer"),Ggo=o(" or "),oN=a("a"),Ogo=o("MT5TokenizerFast"),Vgo=o(" (MT5 model)"),Xgo=l(),As=a("li"),Lie=a("strong"),zgo=o("mvp"),Qgo=o(" \u2014 "),rN=a("a"),Wgo=o("MvpTokenizer"),Hgo=o(" or "),tN=a("a"),Ugo=o("MvpTokenizerFast"),Jgo=o(" (MVP model)"),Ygo=l(),Ls=a("li"),yie=a("strong"),Kgo=o("nezha"),Zgo=o(" \u2014 "),aN=a("a"),eho=o("BertTokenizer"),oho=o(" or "),nN=a("a"),rho=o("BertTokenizerFast"),tho=o(" (Nezha model)"),aho=l(),ys=a("li"),xie=a("strong"),nho=o("nllb"),sho=o(" \u2014 "),sN=a("a"),lho=o("NllbTokenizer"),iho=o(" or "),lN=a("a"),dho=o("NllbTokenizerFast"),cho=o(" (NLLB model)"),fho=l(),xs=a("li"),$ie=a("strong"),mho=o("nystromformer"),gho=o(" \u2014 "),iN=a("a"),hho=o("AlbertTokenizer"),pho=o(" or "),dN=a("a"),_ho=o("AlbertTokenizerFast"),uho=o(" (Nystr\xF6mformer model)"),bho=l(),$s=a("li"),kie=a("strong"),vho=o("openai-gpt"),Fho=o(" \u2014 "),cN=a("a"),Tho=o("OpenAIGPTTokenizer"),Mho=o(" or "),fN=a("a"),Eho=o("OpenAIGPTTokenizerFast"),Cho=o(" (OpenAI GPT model)"),who=l(),vh=a("li"),Sie=a("strong"),Aho=o("opt"),Lho=o(" \u2014 "),mN=a("a"),yho=o("GPT2Tokenizer"),xho=o(" (OPT model)"),$ho=l(),ks=a("li"),Rie=a("strong"),kho=o("pegasus"),Sho=o(" \u2014 "),gN=a("a"),Rho=o("PegasusTokenizer"),Pho=o(" or "),hN=a("a"),Bho=o("PegasusTokenizerFast"),Iho=o(" (Pegasus model)"),Nho=l(),Fh=a("li"),Pie=a("strong"),qho=o("perceiver"),jho=o(" \u2014 "),pN=a("a"),Dho=o("PerceiverTokenizer"),Gho=o(" (Perceiver model)"),Oho=l(),Th=a("li"),Bie=a("strong"),Vho=o("phobert"),Xho=o(" \u2014 "),_N=a("a"),zho=o("PhobertTokenizer"),Qho=o(" (PhoBERT model)"),Who=l(),Mh=a("li"),Iie=a("strong"),Hho=o("plbart"),Uho=o(" \u2014 "),uN=a("a"),Jho=o("PLBartTokenizer"),Yho=o(" (PLBart model)"),Kho=l(),Eh=a("li"),Nie=a("strong"),Zho=o("prophetnet"),epo=o(" \u2014 "),bN=a("a"),opo=o("ProphetNetTokenizer"),rpo=o(" (ProphetNet model)"),tpo=l(),Ss=a("li"),qie=a("strong"),apo=o("qdqbert"),npo=o(" \u2014 "),vN=a("a"),spo=o("BertTokenizer"),lpo=o(" or "),FN=a("a"),ipo=o("BertTokenizerFast"),dpo=o(" (QDQBert model)"),cpo=l(),Ch=a("li"),jie=a("strong"),fpo=o("rag"),mpo=o(" \u2014 "),TN=a("a"),gpo=o("RagTokenizer"),hpo=o(" (RAG model)"),ppo=l(),Rs=a("li"),Die=a("strong"),_po=o("realm"),upo=o(" \u2014 "),MN=a("a"),bpo=o("RealmTokenizer"),vpo=o(" or "),EN=a("a"),Fpo=o("RealmTokenizerFast"),Tpo=o(" (REALM model)"),Mpo=l(),Ps=a("li"),Gie=a("strong"),Epo=o("reformer"),Cpo=o(" \u2014 "),CN=a("a"),wpo=o("ReformerTokenizer"),Apo=o(" or "),wN=a("a"),Lpo=o("ReformerTokenizerFast"),ypo=o(" (Reformer model)"),xpo=l(),Bs=a("li"),Oie=a("strong"),$po=o("rembert"),kpo=o(" \u2014 "),AN=a("a"),Spo=o("RemBertTokenizer"),Rpo=o(" or "),LN=a("a"),Ppo=o("RemBertTokenizerFast"),Bpo=o(" (RemBERT model)"),Ipo=l(),Is=a("li"),Vie=a("strong"),Npo=o("retribert"),qpo=o(" \u2014 "),yN=a("a"),jpo=o("RetriBertTokenizer"),Dpo=o(" or "),xN=a("a"),Gpo=o("RetriBertTokenizerFast"),Opo=o(" (RetriBERT model)"),Vpo=l(),Ns=a("li"),Xie=a("strong"),Xpo=o("roberta"),zpo=o(" \u2014 "),$N=a("a"),Qpo=o("RobertaTokenizer"),Wpo=o(" or "),kN=a("a"),Hpo=o("RobertaTokenizerFast"),Upo=o(" (RoBERTa model)"),Jpo=l(),qs=a("li"),zie=a("strong"),Ypo=o("roformer"),Kpo=o(" \u2014 "),SN=a("a"),Zpo=o("RoFormerTokenizer"),e_o=o(" or "),RN=a("a"),o_o=o("RoFormerTokenizerFast"),r_o=o(" (RoFormer model)"),t_o=l(),wh=a("li"),Qie=a("strong"),a_o=o("speech_to_text"),n_o=o(" \u2014 "),PN=a("a"),s_o=o("Speech2TextTokenizer"),l_o=o(" (Speech2Text model)"),i_o=l(),Ah=a("li"),Wie=a("strong"),d_o=o("speech_to_text_2"),c_o=o(" \u2014 "),BN=a("a"),f_o=o("Speech2Text2Tokenizer"),m_o=o(" (Speech2Text2 model)"),g_o=l(),js=a("li"),Hie=a("strong"),h_o=o("splinter"),p_o=o(" \u2014 "),IN=a("a"),__o=o("SplinterTokenizer"),u_o=o(" or "),NN=a("a"),b_o=o("SplinterTokenizerFast"),v_o=o(" (Splinter model)"),F_o=l(),Ds=a("li"),Uie=a("strong"),T_o=o("squeezebert"),M_o=o(" \u2014 "),qN=a("a"),E_o=o("SqueezeBertTokenizer"),C_o=o(" or "),jN=a("a"),w_o=o("SqueezeBertTokenizerFast"),A_o=o(" (SqueezeBERT model)"),L_o=l(),Gs=a("li"),Jie=a("strong"),y_o=o("t5"),x_o=o(" \u2014 "),DN=a("a"),$_o=o("T5Tokenizer"),k_o=o(" or "),GN=a("a"),S_o=o("T5TokenizerFast"),R_o=o(" (T5 model)"),P_o=l(),Lh=a("li"),Yie=a("strong"),B_o=o("tapas"),I_o=o(" \u2014 "),ON=a("a"),N_o=o("TapasTokenizer"),q_o=o(" (TAPAS model)"),j_o=l(),yh=a("li"),Kie=a("strong"),D_o=o("tapex"),G_o=o(" \u2014 "),VN=a("a"),O_o=o("TapexTokenizer"),V_o=o(" (TAPEX model)"),X_o=l(),xh=a("li"),Zie=a("strong"),z_o=o("transfo-xl"),Q_o=o(" \u2014 "),XN=a("a"),W_o=o("TransfoXLTokenizer"),H_o=o(" (Transformer-XL model)"),U_o=l(),Os=a("li"),ede=a("strong"),J_o=o("vilt"),Y_o=o(" \u2014 "),zN=a("a"),K_o=o("BertTokenizer"),Z_o=o(" or "),QN=a("a"),euo=o("BertTokenizerFast"),ouo=o(" (ViLT model)"),ruo=l(),Vs=a("li"),ode=a("strong"),tuo=o("visual_bert"),auo=o(" \u2014 "),WN=a("a"),nuo=o("BertTokenizer"),suo=o(" or "),HN=a("a"),luo=o("BertTokenizerFast"),iuo=o(" (VisualBERT model)"),duo=l(),$h=a("li"),rde=a("strong"),cuo=o("wav2vec2"),fuo=o(" \u2014 "),UN=a("a"),muo=o("Wav2Vec2CTCTokenizer"),guo=o(" (Wav2Vec2 model)"),huo=l(),kh=a("li"),tde=a("strong"),puo=o("wav2vec2-conformer"),_uo=o(" \u2014 "),JN=a("a"),uuo=o("Wav2Vec2CTCTokenizer"),buo=o(" (Wav2Vec2-Conformer model)"),vuo=l(),Sh=a("li"),ade=a("strong"),Fuo=o("wav2vec2_phoneme"),Tuo=o(" \u2014 "),YN=a("a"),Muo=o("Wav2Vec2PhonemeCTCTokenizer"),Euo=o(" (Wav2Vec2Phoneme model)"),Cuo=l(),Xs=a("li"),nde=a("strong"),wuo=o("xglm"),Auo=o(" \u2014 "),KN=a("a"),Luo=o("XGLMTokenizer"),yuo=o(" or "),ZN=a("a"),xuo=o("XGLMTokenizerFast"),$uo=o(" (XGLM model)"),kuo=l(),Rh=a("li"),sde=a("strong"),Suo=o("xlm"),Ruo=o(" \u2014 "),eq=a("a"),Puo=o("XLMTokenizer"),Buo=o(" (XLM model)"),Iuo=l(),Ph=a("li"),lde=a("strong"),Nuo=o("xlm-prophetnet"),quo=o(" \u2014 "),oq=a("a"),juo=o("XLMProphetNetTokenizer"),Duo=o(" (XLM-ProphetNet model)"),Guo=l(),zs=a("li"),ide=a("strong"),Ouo=o("xlm-roberta"),Vuo=o(" \u2014 "),rq=a("a"),Xuo=o("XLMRobertaTokenizer"),zuo=o(" or "),tq=a("a"),Quo=o("XLMRobertaTokenizerFast"),Wuo=o(" (XLM-RoBERTa model)"),Huo=l(),Qs=a("li"),dde=a("strong"),Uuo=o("xlm-roberta-xl"),Juo=o(" \u2014 "),aq=a("a"),Yuo=o("RobertaTokenizer"),Kuo=o(" or "),nq=a("a"),Zuo=o("RobertaTokenizerFast"),e1o=o(" (XLM-RoBERTa-XL model)"),o1o=l(),Ws=a("li"),cde=a("strong"),r1o=o("xlnet"),t1o=o(" \u2014 "),sq=a("a"),a1o=o("XLNetTokenizer"),n1o=o(" or "),lq=a("a"),s1o=o("XLNetTokenizerFast"),l1o=o(" (XLNet model)"),i1o=l(),Hs=a("li"),fde=a("strong"),d1o=o("yoso"),c1o=o(" \u2014 "),iq=a("a"),f1o=o("AlbertTokenizer"),m1o=o(" or "),dq=a("a"),g1o=o("AlbertTokenizerFast"),h1o=o(" (YOSO model)"),p1o=l(),F(Bh.$$.fragment),_1o=l(),Ih=a("div"),F(xL.$$.fragment),u1o=l(),mde=a("p"),b1o=o("Register a new tokenizer in this mapping."),YXe=l(),Di=a("h2"),Nh=a("a"),gde=a("span"),F($L.$$.fragment),v1o=l(),hde=a("span"),F1o=o("AutoFeatureExtractor"),KXe=l(),xo=a("div"),F(kL.$$.fragment),T1o=l(),SL=a("p"),M1o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),cq=a("a"),E1o=o("AutoFeatureExtractor.from_pretrained()"),C1o=o(" class method."),w1o=l(),RL=a("p"),A1o=o("This class cannot be instantiated directly using "),pde=a("code"),L1o=o("__init__()"),y1o=o(" (throws an error)."),x1o=l(),Ue=a("div"),F(PL.$$.fragment),$1o=l(),_de=a("p"),k1o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),S1o=l(),Ba=a("p"),R1o=o("The feature extractor class to instantiate is selected based on the "),ude=a("code"),P1o=o("model_type"),B1o=o(` property of the config object
(either passed as an argument or loaded from `),bde=a("code"),I1o=o("pretrained_model_name_or_path"),N1o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),vde=a("code"),q1o=o("pretrained_model_name_or_path"),j1o=o(":"),D1o=l(),J=a("ul"),qh=a("li"),Fde=a("strong"),G1o=o("beit"),O1o=o(" \u2014 "),fq=a("a"),V1o=o("BeitFeatureExtractor"),X1o=o(" (BEiT model)"),z1o=l(),jh=a("li"),Tde=a("strong"),Q1o=o("clip"),W1o=o(" \u2014 "),mq=a("a"),H1o=o("CLIPFeatureExtractor"),U1o=o(" (CLIP model)"),J1o=l(),Dh=a("li"),Mde=a("strong"),Y1o=o("convnext"),K1o=o(" \u2014 "),gq=a("a"),Z1o=o("ConvNextFeatureExtractor"),e4o=o(" (ConvNeXT model)"),o4o=l(),Gh=a("li"),Ede=a("strong"),r4o=o("cvt"),t4o=o(" \u2014 "),hq=a("a"),a4o=o("ConvNextFeatureExtractor"),n4o=o(" (CvT model)"),s4o=l(),Oh=a("li"),Cde=a("strong"),l4o=o("data2vec-audio"),i4o=o(" \u2014 "),pq=a("a"),d4o=o("Wav2Vec2FeatureExtractor"),c4o=o(" (Data2VecAudio model)"),f4o=l(),Vh=a("li"),wde=a("strong"),m4o=o("data2vec-vision"),g4o=o(" \u2014 "),_q=a("a"),h4o=o("BeitFeatureExtractor"),p4o=o(" (Data2VecVision model)"),_4o=l(),Xh=a("li"),Ade=a("strong"),u4o=o("deit"),b4o=o(" \u2014 "),uq=a("a"),v4o=o("DeiTFeatureExtractor"),F4o=o(" (DeiT model)"),T4o=l(),zh=a("li"),Lde=a("strong"),M4o=o("detr"),E4o=o(" \u2014 "),bq=a("a"),C4o=o("DetrFeatureExtractor"),w4o=o(" (DETR model)"),A4o=l(),Qh=a("li"),yde=a("strong"),L4o=o("dpt"),y4o=o(" \u2014 "),vq=a("a"),x4o=o("DPTFeatureExtractor"),$4o=o(" (DPT model)"),k4o=l(),Wh=a("li"),xde=a("strong"),S4o=o("flava"),R4o=o(" \u2014 "),Fq=a("a"),P4o=o("FlavaFeatureExtractor"),B4o=o(" (FLAVA model)"),I4o=l(),Hh=a("li"),$de=a("strong"),N4o=o("glpn"),q4o=o(" \u2014 "),Tq=a("a"),j4o=o("GLPNFeatureExtractor"),D4o=o(" (GLPN model)"),G4o=l(),Uh=a("li"),kde=a("strong"),O4o=o("groupvit"),V4o=o(" \u2014 "),Mq=a("a"),X4o=o("CLIPFeatureExtractor"),z4o=o(" (GroupViT model)"),Q4o=l(),Jh=a("li"),Sde=a("strong"),W4o=o("hubert"),H4o=o(" \u2014 "),Eq=a("a"),U4o=o("Wav2Vec2FeatureExtractor"),J4o=o(" (Hubert model)"),Y4o=l(),Yh=a("li"),Rde=a("strong"),K4o=o("imagegpt"),Z4o=o(" \u2014 "),Cq=a("a"),e2o=o("ImageGPTFeatureExtractor"),o2o=o(" (ImageGPT model)"),r2o=l(),Kh=a("li"),Pde=a("strong"),t2o=o("layoutlmv2"),a2o=o(" \u2014 "),wq=a("a"),n2o=o("LayoutLMv2FeatureExtractor"),s2o=o(" (LayoutLMv2 model)"),l2o=l(),Zh=a("li"),Bde=a("strong"),i2o=o("layoutlmv3"),d2o=o(" \u2014 "),Aq=a("a"),c2o=o("LayoutLMv3FeatureExtractor"),f2o=o(" (LayoutLMv3 model)"),m2o=l(),ep=a("li"),Ide=a("strong"),g2o=o("levit"),h2o=o(" \u2014 "),Lq=a("a"),p2o=o("LevitFeatureExtractor"),_2o=o(" (LeViT model)"),u2o=l(),op=a("li"),Nde=a("strong"),b2o=o("maskformer"),v2o=o(" \u2014 "),yq=a("a"),F2o=o("MaskFormerFeatureExtractor"),T2o=o(" (MaskFormer model)"),M2o=l(),rp=a("li"),qde=a("strong"),E2o=o("mctct"),C2o=o(" \u2014 "),xq=a("a"),w2o=o("MCTCTFeatureExtractor"),A2o=o(" (M-CTC-T model)"),L2o=l(),tp=a("li"),jde=a("strong"),y2o=o("mobilevit"),x2o=o(" \u2014 "),$q=a("a"),$2o=o("MobileViTFeatureExtractor"),k2o=o(" (MobileViT model)"),S2o=l(),ap=a("li"),Dde=a("strong"),R2o=o("perceiver"),P2o=o(" \u2014 "),kq=a("a"),B2o=o("PerceiverFeatureExtractor"),I2o=o(" (Perceiver model)"),N2o=l(),np=a("li"),Gde=a("strong"),q2o=o("poolformer"),j2o=o(" \u2014 "),Sq=a("a"),D2o=o("PoolFormerFeatureExtractor"),G2o=o(" (PoolFormer model)"),O2o=l(),sp=a("li"),Ode=a("strong"),V2o=o("regnet"),X2o=o(" \u2014 "),Rq=a("a"),z2o=o("ConvNextFeatureExtractor"),Q2o=o(" (RegNet model)"),W2o=l(),lp=a("li"),Vde=a("strong"),H2o=o("resnet"),U2o=o(" \u2014 "),Pq=a("a"),J2o=o("ConvNextFeatureExtractor"),Y2o=o(" (ResNet model)"),K2o=l(),ip=a("li"),Xde=a("strong"),Z2o=o("segformer"),ebo=o(" \u2014 "),Bq=a("a"),obo=o("SegformerFeatureExtractor"),rbo=o(" (SegFormer model)"),tbo=l(),dp=a("li"),zde=a("strong"),abo=o("speech_to_text"),nbo=o(" \u2014 "),Iq=a("a"),sbo=o("Speech2TextFeatureExtractor"),lbo=o(" (Speech2Text model)"),ibo=l(),cp=a("li"),Qde=a("strong"),dbo=o("swin"),cbo=o(" \u2014 "),Nq=a("a"),fbo=o("ViTFeatureExtractor"),mbo=o(" (Swin Transformer model)"),gbo=l(),fp=a("li"),Wde=a("strong"),hbo=o("swinv2"),pbo=o(" \u2014 "),qq=a("a"),_bo=o("ViTFeatureExtractor"),ubo=o(" (Swin Transformer V2 model)"),bbo=l(),mp=a("li"),Hde=a("strong"),vbo=o("van"),Fbo=o(" \u2014 "),jq=a("a"),Tbo=o("ConvNextFeatureExtractor"),Mbo=o(" (VAN model)"),Ebo=l(),gp=a("li"),Ude=a("strong"),Cbo=o("vilt"),wbo=o(" \u2014 "),Dq=a("a"),Abo=o("ViltFeatureExtractor"),Lbo=o(" (ViLT model)"),ybo=l(),hp=a("li"),Jde=a("strong"),xbo=o("vit"),$bo=o(" \u2014 "),Gq=a("a"),kbo=o("ViTFeatureExtractor"),Sbo=o(" (ViT model)"),Rbo=l(),pp=a("li"),Yde=a("strong"),Pbo=o("vit_mae"),Bbo=o(" \u2014 "),Oq=a("a"),Ibo=o("ViTFeatureExtractor"),Nbo=o(" (ViTMAE model)"),qbo=l(),_p=a("li"),Kde=a("strong"),jbo=o("wav2vec2"),Dbo=o(" \u2014 "),Vq=a("a"),Gbo=o("Wav2Vec2FeatureExtractor"),Obo=o(" (Wav2Vec2 model)"),Vbo=l(),up=a("li"),Zde=a("strong"),Xbo=o("wav2vec2-conformer"),zbo=o(" \u2014 "),Xq=a("a"),Qbo=o("Wav2Vec2FeatureExtractor"),Wbo=o(" (Wav2Vec2-Conformer model)"),Hbo=l(),bp=a("li"),ece=a("strong"),Ubo=o("yolos"),Jbo=o(" \u2014 "),zq=a("a"),Ybo=o("YolosFeatureExtractor"),Kbo=o(" (YOLOS model)"),Zbo=l(),F(vp.$$.fragment),evo=l(),F(Fp.$$.fragment),ovo=l(),Tp=a("div"),F(BL.$$.fragment),rvo=l(),oce=a("p"),tvo=o("Register a new feature extractor for this class."),ZXe=l(),Gi=a("h2"),Mp=a("a"),rce=a("span"),F(IL.$$.fragment),avo=l(),tce=a("span"),nvo=o("AutoProcessor"),eze=l(),$o=a("div"),F(NL.$$.fragment),svo=l(),qL=a("p"),lvo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Qq=a("a"),ivo=o("AutoProcessor.from_pretrained()"),dvo=o(" class method."),cvo=l(),jL=a("p"),fvo=o("This class cannot be instantiated directly using "),ace=a("code"),mvo=o("__init__()"),gvo=o(" (throws an error)."),hvo=l(),Je=a("div"),F(DL.$$.fragment),pvo=l(),nce=a("p"),_vo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),uvo=l(),Oi=a("p"),bvo=o("The processor class to instantiate is selected based on the "),sce=a("code"),vvo=o("model_type"),Fvo=o(` property of the config object (either
passed as an argument or loaded from `),lce=a("code"),Tvo=o("pretrained_model_name_or_path"),Mvo=o(" if possible):"),Evo=l(),pe=a("ul"),Ep=a("li"),ice=a("strong"),Cvo=o("clip"),wvo=o(" \u2014 "),Wq=a("a"),Avo=o("CLIPProcessor"),Lvo=o(" (CLIP model)"),yvo=l(),Cp=a("li"),dce=a("strong"),xvo=o("flava"),$vo=o(" \u2014 "),Hq=a("a"),kvo=o("FlavaProcessor"),Svo=o(" (FLAVA model)"),Rvo=l(),wp=a("li"),cce=a("strong"),Pvo=o("groupvit"),Bvo=o(" \u2014 "),Uq=a("a"),Ivo=o("CLIPProcessor"),Nvo=o(" (GroupViT model)"),qvo=l(),Ap=a("li"),fce=a("strong"),jvo=o("layoutlmv2"),Dvo=o(" \u2014 "),Jq=a("a"),Gvo=o("LayoutLMv2Processor"),Ovo=o(" (LayoutLMv2 model)"),Vvo=l(),Lp=a("li"),mce=a("strong"),Xvo=o("layoutlmv3"),zvo=o(" \u2014 "),Yq=a("a"),Qvo=o("LayoutLMv3Processor"),Wvo=o(" (LayoutLMv3 model)"),Hvo=l(),yp=a("li"),gce=a("strong"),Uvo=o("layoutxlm"),Jvo=o(" \u2014 "),Kq=a("a"),Yvo=o("LayoutXLMProcessor"),Kvo=o(" (LayoutXLM model)"),Zvo=l(),xp=a("li"),hce=a("strong"),eFo=o("sew"),oFo=o(" \u2014 "),Zq=a("a"),rFo=o("Wav2Vec2Processor"),tFo=o(" (SEW model)"),aFo=l(),$p=a("li"),pce=a("strong"),nFo=o("sew-d"),sFo=o(" \u2014 "),ej=a("a"),lFo=o("Wav2Vec2Processor"),iFo=o(" (SEW-D model)"),dFo=l(),kp=a("li"),_ce=a("strong"),cFo=o("speech_to_text"),fFo=o(" \u2014 "),oj=a("a"),mFo=o("Speech2TextProcessor"),gFo=o(" (Speech2Text model)"),hFo=l(),Sp=a("li"),uce=a("strong"),pFo=o("speech_to_text_2"),_Fo=o(" \u2014 "),rj=a("a"),uFo=o("Speech2Text2Processor"),bFo=o(" (Speech2Text2 model)"),vFo=l(),Rp=a("li"),bce=a("strong"),FFo=o("trocr"),TFo=o(" \u2014 "),tj=a("a"),MFo=o("TrOCRProcessor"),EFo=o(" (TrOCR model)"),CFo=l(),Pp=a("li"),vce=a("strong"),wFo=o("unispeech"),AFo=o(" \u2014 "),aj=a("a"),LFo=o("Wav2Vec2Processor"),yFo=o(" (UniSpeech model)"),xFo=l(),Bp=a("li"),Fce=a("strong"),$Fo=o("unispeech-sat"),kFo=o(" \u2014 "),nj=a("a"),SFo=o("Wav2Vec2Processor"),RFo=o(" (UniSpeechSat model)"),PFo=l(),Ip=a("li"),Tce=a("strong"),BFo=o("vilt"),IFo=o(" \u2014 "),sj=a("a"),NFo=o("ViltProcessor"),qFo=o(" (ViLT model)"),jFo=l(),Np=a("li"),Mce=a("strong"),DFo=o("vision-text-dual-encoder"),GFo=o(" \u2014 "),lj=a("a"),OFo=o("VisionTextDualEncoderProcessor"),VFo=o(" (VisionTextDualEncoder model)"),XFo=l(),qp=a("li"),Ece=a("strong"),zFo=o("wav2vec2"),QFo=o(" \u2014 "),ij=a("a"),WFo=o("Wav2Vec2Processor"),HFo=o(" (Wav2Vec2 model)"),UFo=l(),jp=a("li"),Cce=a("strong"),JFo=o("wav2vec2-conformer"),YFo=o(" \u2014 "),dj=a("a"),KFo=o("Wav2Vec2Processor"),ZFo=o(" (Wav2Vec2-Conformer model)"),e6o=l(),Dp=a("li"),wce=a("strong"),o6o=o("wavlm"),r6o=o(" \u2014 "),cj=a("a"),t6o=o("Wav2Vec2Processor"),a6o=o(" (WavLM model)"),n6o=l(),F(Gp.$$.fragment),s6o=l(),F(Op.$$.fragment),l6o=l(),Vp=a("div"),F(GL.$$.fragment),i6o=l(),Ace=a("p"),d6o=o("Register a new processor for this class."),oze=l(),Vi=a("h2"),Xp=a("a"),Lce=a("span"),F(OL.$$.fragment),c6o=l(),yce=a("span"),f6o=o("AutoModel"),rze=l(),ko=a("div"),F(VL.$$.fragment),m6o=l(),Xi=a("p"),g6o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),fj=a("a"),h6o=o("from_pretrained()"),p6o=o(" class method or the "),mj=a("a"),_6o=o("from_config()"),u6o=o(` class
method.`),b6o=l(),XL=a("p"),v6o=o("This class cannot be instantiated directly using "),xce=a("code"),F6o=o("__init__()"),T6o=o(" (throws an error)."),M6o=l(),it=a("div"),F(zL.$$.fragment),E6o=l(),$ce=a("p"),C6o=o("Instantiates one of the base model classes of the library from a configuration."),w6o=l(),zi=a("p"),A6o=o(`Note:
Loading a model from its configuration file does `),kce=a("strong"),L6o=o("not"),y6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gj=a("a"),x6o=o("from_pretrained()"),$6o=o(" to load the model weights."),k6o=l(),F(zp.$$.fragment),S6o=l(),Ye=a("div"),F(QL.$$.fragment),R6o=l(),Sce=a("p"),P6o=o("Instantiate one of the base model classes of the library from a pretrained model."),B6o=l(),Ia=a("p"),I6o=o("The model class to instantiate is selected based on the "),Rce=a("code"),N6o=o("model_type"),q6o=o(` property of the config object (either
passed as an argument or loaded from `),Pce=a("code"),j6o=o("pretrained_model_name_or_path"),D6o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bce=a("code"),G6o=o("pretrained_model_name_or_path"),O6o=o(":"),V6o=l(),y=a("ul"),Qp=a("li"),Ice=a("strong"),X6o=o("albert"),z6o=o(" \u2014 "),hj=a("a"),Q6o=o("AlbertModel"),W6o=o(" (ALBERT model)"),H6o=l(),Wp=a("li"),Nce=a("strong"),U6o=o("bart"),J6o=o(" \u2014 "),pj=a("a"),Y6o=o("BartModel"),K6o=o(" (BART model)"),Z6o=l(),Hp=a("li"),qce=a("strong"),eTo=o("beit"),oTo=o(" \u2014 "),_j=a("a"),rTo=o("BeitModel"),tTo=o(" (BEiT model)"),aTo=l(),Up=a("li"),jce=a("strong"),nTo=o("bert"),sTo=o(" \u2014 "),uj=a("a"),lTo=o("BertModel"),iTo=o(" (BERT model)"),dTo=l(),Jp=a("li"),Dce=a("strong"),cTo=o("bert-generation"),fTo=o(" \u2014 "),bj=a("a"),mTo=o("BertGenerationEncoder"),gTo=o(" (Bert Generation model)"),hTo=l(),Yp=a("li"),Gce=a("strong"),pTo=o("big_bird"),_To=o(" \u2014 "),vj=a("a"),uTo=o("BigBirdModel"),bTo=o(" (BigBird model)"),vTo=l(),Kp=a("li"),Oce=a("strong"),FTo=o("bigbird_pegasus"),TTo=o(" \u2014 "),Fj=a("a"),MTo=o("BigBirdPegasusModel"),ETo=o(" (BigBird-Pegasus model)"),CTo=l(),Zp=a("li"),Vce=a("strong"),wTo=o("blenderbot"),ATo=o(" \u2014 "),Tj=a("a"),LTo=o("BlenderbotModel"),yTo=o(" (Blenderbot model)"),xTo=l(),e_=a("li"),Xce=a("strong"),$To=o("blenderbot-small"),kTo=o(" \u2014 "),Mj=a("a"),STo=o("BlenderbotSmallModel"),RTo=o(" (BlenderbotSmall model)"),PTo=l(),o_=a("li"),zce=a("strong"),BTo=o("bloom"),ITo=o(" \u2014 "),Ej=a("a"),NTo=o("BloomModel"),qTo=o(" (BLOOM model)"),jTo=l(),r_=a("li"),Qce=a("strong"),DTo=o("camembert"),GTo=o(" \u2014 "),Cj=a("a"),OTo=o("CamembertModel"),VTo=o(" (CamemBERT model)"),XTo=l(),t_=a("li"),Wce=a("strong"),zTo=o("canine"),QTo=o(" \u2014 "),wj=a("a"),WTo=o("CanineModel"),HTo=o(" (CANINE model)"),UTo=l(),a_=a("li"),Hce=a("strong"),JTo=o("clip"),YTo=o(" \u2014 "),Aj=a("a"),KTo=o("CLIPModel"),ZTo=o(" (CLIP model)"),e7o=l(),n_=a("li"),Uce=a("strong"),o7o=o("codegen"),r7o=o(" \u2014 "),Lj=a("a"),t7o=o("CodeGenModel"),a7o=o(" (CodeGen model)"),n7o=l(),s_=a("li"),Jce=a("strong"),s7o=o("convbert"),l7o=o(" \u2014 "),yj=a("a"),i7o=o("ConvBertModel"),d7o=o(" (ConvBERT model)"),c7o=l(),l_=a("li"),Yce=a("strong"),f7o=o("convnext"),m7o=o(" \u2014 "),xj=a("a"),g7o=o("ConvNextModel"),h7o=o(" (ConvNeXT model)"),p7o=l(),i_=a("li"),Kce=a("strong"),_7o=o("ctrl"),u7o=o(" \u2014 "),$j=a("a"),b7o=o("CTRLModel"),v7o=o(" (CTRL model)"),F7o=l(),d_=a("li"),Zce=a("strong"),T7o=o("cvt"),M7o=o(" \u2014 "),kj=a("a"),E7o=o("CvtModel"),C7o=o(" (CvT model)"),w7o=l(),c_=a("li"),efe=a("strong"),A7o=o("data2vec-audio"),L7o=o(" \u2014 "),Sj=a("a"),y7o=o("Data2VecAudioModel"),x7o=o(" (Data2VecAudio model)"),$7o=l(),f_=a("li"),ofe=a("strong"),k7o=o("data2vec-text"),S7o=o(" \u2014 "),Rj=a("a"),R7o=o("Data2VecTextModel"),P7o=o(" (Data2VecText model)"),B7o=l(),m_=a("li"),rfe=a("strong"),I7o=o("data2vec-vision"),N7o=o(" \u2014 "),Pj=a("a"),q7o=o("Data2VecVisionModel"),j7o=o(" (Data2VecVision model)"),D7o=l(),g_=a("li"),tfe=a("strong"),G7o=o("deberta"),O7o=o(" \u2014 "),Bj=a("a"),V7o=o("DebertaModel"),X7o=o(" (DeBERTa model)"),z7o=l(),h_=a("li"),afe=a("strong"),Q7o=o("deberta-v2"),W7o=o(" \u2014 "),Ij=a("a"),H7o=o("DebertaV2Model"),U7o=o(" (DeBERTa-v2 model)"),J7o=l(),p_=a("li"),nfe=a("strong"),Y7o=o("decision_transformer"),K7o=o(" \u2014 "),Nj=a("a"),Z7o=o("DecisionTransformerModel"),e9o=o(" (Decision Transformer model)"),o9o=l(),__=a("li"),sfe=a("strong"),r9o=o("deit"),t9o=o(" \u2014 "),qj=a("a"),a9o=o("DeiTModel"),n9o=o(" (DeiT model)"),s9o=l(),u_=a("li"),lfe=a("strong"),l9o=o("detr"),i9o=o(" \u2014 "),jj=a("a"),d9o=o("DetrModel"),c9o=o(" (DETR model)"),f9o=l(),b_=a("li"),ife=a("strong"),m9o=o("distilbert"),g9o=o(" \u2014 "),Dj=a("a"),h9o=o("DistilBertModel"),p9o=o(" (DistilBERT model)"),_9o=l(),v_=a("li"),dfe=a("strong"),u9o=o("dpr"),b9o=o(" \u2014 "),Gj=a("a"),v9o=o("DPRQuestionEncoder"),F9o=o(" (DPR model)"),T9o=l(),F_=a("li"),cfe=a("strong"),M9o=o("dpt"),E9o=o(" \u2014 "),Oj=a("a"),C9o=o("DPTModel"),w9o=o(" (DPT model)"),A9o=l(),T_=a("li"),ffe=a("strong"),L9o=o("electra"),y9o=o(" \u2014 "),Vj=a("a"),x9o=o("ElectraModel"),$9o=o(" (ELECTRA model)"),k9o=l(),M_=a("li"),mfe=a("strong"),S9o=o("flaubert"),R9o=o(" \u2014 "),Xj=a("a"),P9o=o("FlaubertModel"),B9o=o(" (FlauBERT model)"),I9o=l(),E_=a("li"),gfe=a("strong"),N9o=o("flava"),q9o=o(" \u2014 "),zj=a("a"),j9o=o("FlavaModel"),D9o=o(" (FLAVA model)"),G9o=l(),C_=a("li"),hfe=a("strong"),O9o=o("fnet"),V9o=o(" \u2014 "),Qj=a("a"),X9o=o("FNetModel"),z9o=o(" (FNet model)"),Q9o=l(),w_=a("li"),pfe=a("strong"),W9o=o("fsmt"),H9o=o(" \u2014 "),Wj=a("a"),U9o=o("FSMTModel"),J9o=o(" (FairSeq Machine-Translation model)"),Y9o=l(),Us=a("li"),_fe=a("strong"),K9o=o("funnel"),Z9o=o(" \u2014 "),Hj=a("a"),eMo=o("FunnelModel"),oMo=o(" or "),Uj=a("a"),rMo=o("FunnelBaseModel"),tMo=o(" (Funnel Transformer model)"),aMo=l(),A_=a("li"),ufe=a("strong"),nMo=o("glpn"),sMo=o(" \u2014 "),Jj=a("a"),lMo=o("GLPNModel"),iMo=o(" (GLPN model)"),dMo=l(),L_=a("li"),bfe=a("strong"),cMo=o("gpt2"),fMo=o(" \u2014 "),Yj=a("a"),mMo=o("GPT2Model"),gMo=o(" (OpenAI GPT-2 model)"),hMo=l(),y_=a("li"),vfe=a("strong"),pMo=o("gpt_neo"),_Mo=o(" \u2014 "),Kj=a("a"),uMo=o("GPTNeoModel"),bMo=o(" (GPT Neo model)"),vMo=l(),x_=a("li"),Ffe=a("strong"),FMo=o("gpt_neox"),TMo=o(" \u2014 "),Zj=a("a"),MMo=o("GPTNeoXModel"),EMo=o(" (GPT NeoX model)"),CMo=l(),$_=a("li"),Tfe=a("strong"),wMo=o("gptj"),AMo=o(" \u2014 "),eD=a("a"),LMo=o("GPTJModel"),yMo=o(" (GPT-J model)"),xMo=l(),k_=a("li"),Mfe=a("strong"),$Mo=o("groupvit"),kMo=o(" \u2014 "),oD=a("a"),SMo=o("GroupViTModel"),RMo=o(" (GroupViT model)"),PMo=l(),S_=a("li"),Efe=a("strong"),BMo=o("hubert"),IMo=o(" \u2014 "),rD=a("a"),NMo=o("HubertModel"),qMo=o(" (Hubert model)"),jMo=l(),R_=a("li"),Cfe=a("strong"),DMo=o("ibert"),GMo=o(" \u2014 "),tD=a("a"),OMo=o("IBertModel"),VMo=o(" (I-BERT model)"),XMo=l(),P_=a("li"),wfe=a("strong"),zMo=o("imagegpt"),QMo=o(" \u2014 "),aD=a("a"),WMo=o("ImageGPTModel"),HMo=o(" (ImageGPT model)"),UMo=l(),B_=a("li"),Afe=a("strong"),JMo=o("layoutlm"),YMo=o(" \u2014 "),nD=a("a"),KMo=o("LayoutLMModel"),ZMo=o(" (LayoutLM model)"),eEo=l(),I_=a("li"),Lfe=a("strong"),oEo=o("layoutlmv2"),rEo=o(" \u2014 "),sD=a("a"),tEo=o("LayoutLMv2Model"),aEo=o(" (LayoutLMv2 model)"),nEo=l(),N_=a("li"),yfe=a("strong"),sEo=o("layoutlmv3"),lEo=o(" \u2014 "),lD=a("a"),iEo=o("LayoutLMv3Model"),dEo=o(" (LayoutLMv3 model)"),cEo=l(),q_=a("li"),xfe=a("strong"),fEo=o("led"),mEo=o(" \u2014 "),iD=a("a"),gEo=o("LEDModel"),hEo=o(" (LED model)"),pEo=l(),j_=a("li"),$fe=a("strong"),_Eo=o("levit"),uEo=o(" \u2014 "),dD=a("a"),bEo=o("LevitModel"),vEo=o(" (LeViT model)"),FEo=l(),D_=a("li"),kfe=a("strong"),TEo=o("longformer"),MEo=o(" \u2014 "),cD=a("a"),EEo=o("LongformerModel"),CEo=o(" (Longformer model)"),wEo=l(),G_=a("li"),Sfe=a("strong"),AEo=o("longt5"),LEo=o(" \u2014 "),fD=a("a"),yEo=o("LongT5Model"),xEo=o(" (LongT5 model)"),$Eo=l(),O_=a("li"),Rfe=a("strong"),kEo=o("luke"),SEo=o(" \u2014 "),mD=a("a"),REo=o("LukeModel"),PEo=o(" (LUKE model)"),BEo=l(),V_=a("li"),Pfe=a("strong"),IEo=o("lxmert"),NEo=o(" \u2014 "),gD=a("a"),qEo=o("LxmertModel"),jEo=o(" (LXMERT model)"),DEo=l(),X_=a("li"),Bfe=a("strong"),GEo=o("m2m_100"),OEo=o(" \u2014 "),hD=a("a"),VEo=o("M2M100Model"),XEo=o(" (M2M100 model)"),zEo=l(),z_=a("li"),Ife=a("strong"),QEo=o("marian"),WEo=o(" \u2014 "),pD=a("a"),HEo=o("MarianModel"),UEo=o(" (Marian model)"),JEo=l(),Q_=a("li"),Nfe=a("strong"),YEo=o("maskformer"),KEo=o(" \u2014 "),_D=a("a"),ZEo=o("MaskFormerModel"),eCo=o(" (MaskFormer model)"),oCo=l(),W_=a("li"),qfe=a("strong"),rCo=o("mbart"),tCo=o(" \u2014 "),uD=a("a"),aCo=o("MBartModel"),nCo=o(" (mBART model)"),sCo=l(),H_=a("li"),jfe=a("strong"),lCo=o("mctct"),iCo=o(" \u2014 "),bD=a("a"),dCo=o("MCTCTModel"),cCo=o(" (M-CTC-T model)"),fCo=l(),U_=a("li"),Dfe=a("strong"),mCo=o("megatron-bert"),gCo=o(" \u2014 "),vD=a("a"),hCo=o("MegatronBertModel"),pCo=o(" (Megatron-BERT model)"),_Co=l(),J_=a("li"),Gfe=a("strong"),uCo=o("mobilebert"),bCo=o(" \u2014 "),FD=a("a"),vCo=o("MobileBertModel"),FCo=o(" (MobileBERT model)"),TCo=l(),Y_=a("li"),Ofe=a("strong"),MCo=o("mobilevit"),ECo=o(" \u2014 "),TD=a("a"),CCo=o("MobileViTModel"),wCo=o(" (MobileViT model)"),ACo=l(),K_=a("li"),Vfe=a("strong"),LCo=o("mpnet"),yCo=o(" \u2014 "),MD=a("a"),xCo=o("MPNetModel"),$Co=o(" (MPNet model)"),kCo=l(),Z_=a("li"),Xfe=a("strong"),SCo=o("mt5"),RCo=o(" \u2014 "),ED=a("a"),PCo=o("MT5Model"),BCo=o(" (MT5 model)"),ICo=l(),eu=a("li"),zfe=a("strong"),NCo=o("mvp"),qCo=o(" \u2014 "),CD=a("a"),jCo=o("MvpModel"),DCo=o(" (MVP model)"),GCo=l(),ou=a("li"),Qfe=a("strong"),OCo=o("nezha"),VCo=o(" \u2014 "),wD=a("a"),XCo=o("NezhaModel"),zCo=o(" (Nezha model)"),QCo=l(),ru=a("li"),Wfe=a("strong"),WCo=o("nllb"),HCo=o(" \u2014 "),AD=a("a"),UCo=o("M2M100Model"),JCo=o(" (NLLB model)"),YCo=l(),tu=a("li"),Hfe=a("strong"),KCo=o("nystromformer"),ZCo=o(" \u2014 "),LD=a("a"),e5o=o("NystromformerModel"),o5o=o(" (Nystr\xF6mformer model)"),r5o=l(),au=a("li"),Ufe=a("strong"),t5o=o("openai-gpt"),a5o=o(" \u2014 "),yD=a("a"),n5o=o("OpenAIGPTModel"),s5o=o(" (OpenAI GPT model)"),l5o=l(),nu=a("li"),Jfe=a("strong"),i5o=o("opt"),d5o=o(" \u2014 "),xD=a("a"),c5o=o("OPTModel"),f5o=o(" (OPT model)"),m5o=l(),su=a("li"),Yfe=a("strong"),g5o=o("pegasus"),h5o=o(" \u2014 "),$D=a("a"),p5o=o("PegasusModel"),_5o=o(" (Pegasus model)"),u5o=l(),lu=a("li"),Kfe=a("strong"),b5o=o("perceiver"),v5o=o(" \u2014 "),kD=a("a"),F5o=o("PerceiverModel"),T5o=o(" (Perceiver model)"),M5o=l(),iu=a("li"),Zfe=a("strong"),E5o=o("plbart"),C5o=o(" \u2014 "),SD=a("a"),w5o=o("PLBartModel"),A5o=o(" (PLBart model)"),L5o=l(),du=a("li"),eme=a("strong"),y5o=o("poolformer"),x5o=o(" \u2014 "),RD=a("a"),$5o=o("PoolFormerModel"),k5o=o(" (PoolFormer model)"),S5o=l(),cu=a("li"),ome=a("strong"),R5o=o("prophetnet"),P5o=o(" \u2014 "),PD=a("a"),B5o=o("ProphetNetModel"),I5o=o(" (ProphetNet model)"),N5o=l(),fu=a("li"),rme=a("strong"),q5o=o("qdqbert"),j5o=o(" \u2014 "),BD=a("a"),D5o=o("QDQBertModel"),G5o=o(" (QDQBert model)"),O5o=l(),mu=a("li"),tme=a("strong"),V5o=o("reformer"),X5o=o(" \u2014 "),ID=a("a"),z5o=o("ReformerModel"),Q5o=o(" (Reformer model)"),W5o=l(),gu=a("li"),ame=a("strong"),H5o=o("regnet"),U5o=o(" \u2014 "),ND=a("a"),J5o=o("RegNetModel"),Y5o=o(" (RegNet model)"),K5o=l(),hu=a("li"),nme=a("strong"),Z5o=o("rembert"),e3o=o(" \u2014 "),qD=a("a"),o3o=o("RemBertModel"),r3o=o(" (RemBERT model)"),t3o=l(),pu=a("li"),sme=a("strong"),a3o=o("resnet"),n3o=o(" \u2014 "),jD=a("a"),s3o=o("ResNetModel"),l3o=o(" (ResNet model)"),i3o=l(),_u=a("li"),lme=a("strong"),d3o=o("retribert"),c3o=o(" \u2014 "),DD=a("a"),f3o=o("RetriBertModel"),m3o=o(" (RetriBERT model)"),g3o=l(),uu=a("li"),ime=a("strong"),h3o=o("roberta"),p3o=o(" \u2014 "),GD=a("a"),_3o=o("RobertaModel"),u3o=o(" (RoBERTa model)"),b3o=l(),bu=a("li"),dme=a("strong"),v3o=o("roformer"),F3o=o(" \u2014 "),OD=a("a"),T3o=o("RoFormerModel"),M3o=o(" (RoFormer model)"),E3o=l(),vu=a("li"),cme=a("strong"),C3o=o("segformer"),w3o=o(" \u2014 "),VD=a("a"),A3o=o("SegformerModel"),L3o=o(" (SegFormer model)"),y3o=l(),Fu=a("li"),fme=a("strong"),x3o=o("sew"),$3o=o(" \u2014 "),XD=a("a"),k3o=o("SEWModel"),S3o=o(" (SEW model)"),R3o=l(),Tu=a("li"),mme=a("strong"),P3o=o("sew-d"),B3o=o(" \u2014 "),zD=a("a"),I3o=o("SEWDModel"),N3o=o(" (SEW-D model)"),q3o=l(),Mu=a("li"),gme=a("strong"),j3o=o("speech_to_text"),D3o=o(" \u2014 "),QD=a("a"),G3o=o("Speech2TextModel"),O3o=o(" (Speech2Text model)"),V3o=l(),Eu=a("li"),hme=a("strong"),X3o=o("splinter"),z3o=o(" \u2014 "),WD=a("a"),Q3o=o("SplinterModel"),W3o=o(" (Splinter model)"),H3o=l(),Cu=a("li"),pme=a("strong"),U3o=o("squeezebert"),J3o=o(" \u2014 "),HD=a("a"),Y3o=o("SqueezeBertModel"),K3o=o(" (SqueezeBERT model)"),Z3o=l(),wu=a("li"),_me=a("strong"),e0o=o("swin"),o0o=o(" \u2014 "),UD=a("a"),r0o=o("SwinModel"),t0o=o(" (Swin Transformer model)"),a0o=l(),Au=a("li"),ume=a("strong"),n0o=o("swinv2"),s0o=o(" \u2014 "),JD=a("a"),l0o=o("Swinv2Model"),i0o=o(" (Swin Transformer V2 model)"),d0o=l(),Lu=a("li"),bme=a("strong"),c0o=o("t5"),f0o=o(" \u2014 "),YD=a("a"),m0o=o("T5Model"),g0o=o(" (T5 model)"),h0o=l(),yu=a("li"),vme=a("strong"),p0o=o("tapas"),_0o=o(" \u2014 "),KD=a("a"),u0o=o("TapasModel"),b0o=o(" (TAPAS model)"),v0o=l(),xu=a("li"),Fme=a("strong"),F0o=o("trajectory_transformer"),T0o=o(" \u2014 "),ZD=a("a"),M0o=o("TrajectoryTransformerModel"),E0o=o(" (Trajectory Transformer model)"),C0o=l(),$u=a("li"),Tme=a("strong"),w0o=o("transfo-xl"),A0o=o(" \u2014 "),eG=a("a"),L0o=o("TransfoXLModel"),y0o=o(" (Transformer-XL model)"),x0o=l(),ku=a("li"),Mme=a("strong"),$0o=o("unispeech"),k0o=o(" \u2014 "),oG=a("a"),S0o=o("UniSpeechModel"),R0o=o(" (UniSpeech model)"),P0o=l(),Su=a("li"),Eme=a("strong"),B0o=o("unispeech-sat"),I0o=o(" \u2014 "),rG=a("a"),N0o=o("UniSpeechSatModel"),q0o=o(" (UniSpeechSat model)"),j0o=l(),Ru=a("li"),Cme=a("strong"),D0o=o("van"),G0o=o(" \u2014 "),tG=a("a"),O0o=o("VanModel"),V0o=o(" (VAN model)"),X0o=l(),Pu=a("li"),wme=a("strong"),z0o=o("vilt"),Q0o=o(" \u2014 "),aG=a("a"),W0o=o("ViltModel"),H0o=o(" (ViLT model)"),U0o=l(),Bu=a("li"),Ame=a("strong"),J0o=o("vision-text-dual-encoder"),Y0o=o(" \u2014 "),nG=a("a"),K0o=o("VisionTextDualEncoderModel"),Z0o=o(" (VisionTextDualEncoder model)"),ewo=l(),Iu=a("li"),Lme=a("strong"),owo=o("visual_bert"),rwo=o(" \u2014 "),sG=a("a"),two=o("VisualBertModel"),awo=o(" (VisualBERT model)"),nwo=l(),Nu=a("li"),yme=a("strong"),swo=o("vit"),lwo=o(" \u2014 "),lG=a("a"),iwo=o("ViTModel"),dwo=o(" (ViT model)"),cwo=l(),qu=a("li"),xme=a("strong"),fwo=o("vit_mae"),mwo=o(" \u2014 "),iG=a("a"),gwo=o("ViTMAEModel"),hwo=o(" (ViTMAE model)"),pwo=l(),ju=a("li"),$me=a("strong"),_wo=o("wav2vec2"),uwo=o(" \u2014 "),dG=a("a"),bwo=o("Wav2Vec2Model"),vwo=o(" (Wav2Vec2 model)"),Fwo=l(),Du=a("li"),kme=a("strong"),Two=o("wav2vec2-conformer"),Mwo=o(" \u2014 "),cG=a("a"),Ewo=o("Wav2Vec2ConformerModel"),Cwo=o(" (Wav2Vec2-Conformer model)"),wwo=l(),Gu=a("li"),Sme=a("strong"),Awo=o("wavlm"),Lwo=o(" \u2014 "),fG=a("a"),ywo=o("WavLMModel"),xwo=o(" (WavLM model)"),$wo=l(),Ou=a("li"),Rme=a("strong"),kwo=o("xglm"),Swo=o(" \u2014 "),mG=a("a"),Rwo=o("XGLMModel"),Pwo=o(" (XGLM model)"),Bwo=l(),Vu=a("li"),Pme=a("strong"),Iwo=o("xlm"),Nwo=o(" \u2014 "),gG=a("a"),qwo=o("XLMModel"),jwo=o(" (XLM model)"),Dwo=l(),Xu=a("li"),Bme=a("strong"),Gwo=o("xlm-prophetnet"),Owo=o(" \u2014 "),hG=a("a"),Vwo=o("XLMProphetNetModel"),Xwo=o(" (XLM-ProphetNet model)"),zwo=l(),zu=a("li"),Ime=a("strong"),Qwo=o("xlm-roberta"),Wwo=o(" \u2014 "),pG=a("a"),Hwo=o("XLMRobertaModel"),Uwo=o(" (XLM-RoBERTa model)"),Jwo=l(),Qu=a("li"),Nme=a("strong"),Ywo=o("xlm-roberta-xl"),Kwo=o(" \u2014 "),_G=a("a"),Zwo=o("XLMRobertaXLModel"),eAo=o(" (XLM-RoBERTa-XL model)"),oAo=l(),Wu=a("li"),qme=a("strong"),rAo=o("xlnet"),tAo=o(" \u2014 "),uG=a("a"),aAo=o("XLNetModel"),nAo=o(" (XLNet model)"),sAo=l(),Hu=a("li"),jme=a("strong"),lAo=o("yolos"),iAo=o(" \u2014 "),bG=a("a"),dAo=o("YolosModel"),cAo=o(" (YOLOS model)"),fAo=l(),Uu=a("li"),Dme=a("strong"),mAo=o("yoso"),gAo=o(" \u2014 "),vG=a("a"),hAo=o("YosoModel"),pAo=o(" (YOSO model)"),_Ao=l(),Ju=a("p"),uAo=o("The model is set in evaluation mode by default using "),Gme=a("code"),bAo=o("model.eval()"),vAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ome=a("code"),FAo=o("model.train()"),TAo=l(),F(Yu.$$.fragment),tze=l(),Qi=a("h2"),Ku=a("a"),Vme=a("span"),F(WL.$$.fragment),MAo=l(),Xme=a("span"),EAo=o("AutoModelForPreTraining"),aze=l(),So=a("div"),F(HL.$$.fragment),CAo=l(),Wi=a("p"),wAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),FG=a("a"),AAo=o("from_pretrained()"),LAo=o(" class method or the "),TG=a("a"),yAo=o("from_config()"),xAo=o(` class
method.`),$Ao=l(),UL=a("p"),kAo=o("This class cannot be instantiated directly using "),zme=a("code"),SAo=o("__init__()"),RAo=o(" (throws an error)."),PAo=l(),dt=a("div"),F(JL.$$.fragment),BAo=l(),Qme=a("p"),IAo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),NAo=l(),Hi=a("p"),qAo=o(`Note:
Loading a model from its configuration file does `),Wme=a("strong"),jAo=o("not"),DAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MG=a("a"),GAo=o("from_pretrained()"),OAo=o(" to load the model weights."),VAo=l(),F(Zu.$$.fragment),XAo=l(),Ke=a("div"),F(YL.$$.fragment),zAo=l(),Hme=a("p"),QAo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),WAo=l(),Na=a("p"),HAo=o("The model class to instantiate is selected based on the "),Ume=a("code"),UAo=o("model_type"),JAo=o(` property of the config object (either
passed as an argument or loaded from `),Jme=a("code"),YAo=o("pretrained_model_name_or_path"),KAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yme=a("code"),ZAo=o("pretrained_model_name_or_path"),eLo=o(":"),oLo=l(),G=a("ul"),e1=a("li"),Kme=a("strong"),rLo=o("albert"),tLo=o(" \u2014 "),EG=a("a"),aLo=o("AlbertForPreTraining"),nLo=o(" (ALBERT model)"),sLo=l(),o1=a("li"),Zme=a("strong"),lLo=o("bart"),iLo=o(" \u2014 "),CG=a("a"),dLo=o("BartForConditionalGeneration"),cLo=o(" (BART model)"),fLo=l(),r1=a("li"),ege=a("strong"),mLo=o("bert"),gLo=o(" \u2014 "),wG=a("a"),hLo=o("BertForPreTraining"),pLo=o(" (BERT model)"),_Lo=l(),t1=a("li"),oge=a("strong"),uLo=o("big_bird"),bLo=o(" \u2014 "),AG=a("a"),vLo=o("BigBirdForPreTraining"),FLo=o(" (BigBird model)"),TLo=l(),a1=a("li"),rge=a("strong"),MLo=o("bloom"),ELo=o(" \u2014 "),LG=a("a"),CLo=o("BloomForCausalLM"),wLo=o(" (BLOOM model)"),ALo=l(),n1=a("li"),tge=a("strong"),LLo=o("camembert"),yLo=o(" \u2014 "),yG=a("a"),xLo=o("CamembertForMaskedLM"),$Lo=o(" (CamemBERT model)"),kLo=l(),s1=a("li"),age=a("strong"),SLo=o("ctrl"),RLo=o(" \u2014 "),xG=a("a"),PLo=o("CTRLLMHeadModel"),BLo=o(" (CTRL model)"),ILo=l(),l1=a("li"),nge=a("strong"),NLo=o("data2vec-text"),qLo=o(" \u2014 "),$G=a("a"),jLo=o("Data2VecTextForMaskedLM"),DLo=o(" (Data2VecText model)"),GLo=l(),i1=a("li"),sge=a("strong"),OLo=o("deberta"),VLo=o(" \u2014 "),kG=a("a"),XLo=o("DebertaForMaskedLM"),zLo=o(" (DeBERTa model)"),QLo=l(),d1=a("li"),lge=a("strong"),WLo=o("deberta-v2"),HLo=o(" \u2014 "),SG=a("a"),ULo=o("DebertaV2ForMaskedLM"),JLo=o(" (DeBERTa-v2 model)"),YLo=l(),c1=a("li"),ige=a("strong"),KLo=o("distilbert"),ZLo=o(" \u2014 "),RG=a("a"),eyo=o("DistilBertForMaskedLM"),oyo=o(" (DistilBERT model)"),ryo=l(),f1=a("li"),dge=a("strong"),tyo=o("electra"),ayo=o(" \u2014 "),PG=a("a"),nyo=o("ElectraForPreTraining"),syo=o(" (ELECTRA model)"),lyo=l(),m1=a("li"),cge=a("strong"),iyo=o("flaubert"),dyo=o(" \u2014 "),BG=a("a"),cyo=o("FlaubertWithLMHeadModel"),fyo=o(" (FlauBERT model)"),myo=l(),g1=a("li"),fge=a("strong"),gyo=o("flava"),hyo=o(" \u2014 "),IG=a("a"),pyo=o("FlavaForPreTraining"),_yo=o(" (FLAVA model)"),uyo=l(),h1=a("li"),mge=a("strong"),byo=o("fnet"),vyo=o(" \u2014 "),NG=a("a"),Fyo=o("FNetForPreTraining"),Tyo=o(" (FNet model)"),Myo=l(),p1=a("li"),gge=a("strong"),Eyo=o("fsmt"),Cyo=o(" \u2014 "),qG=a("a"),wyo=o("FSMTForConditionalGeneration"),Ayo=o(" (FairSeq Machine-Translation model)"),Lyo=l(),_1=a("li"),hge=a("strong"),yyo=o("funnel"),xyo=o(" \u2014 "),jG=a("a"),$yo=o("FunnelForPreTraining"),kyo=o(" (Funnel Transformer model)"),Syo=l(),u1=a("li"),pge=a("strong"),Ryo=o("gpt2"),Pyo=o(" \u2014 "),DG=a("a"),Byo=o("GPT2LMHeadModel"),Iyo=o(" (OpenAI GPT-2 model)"),Nyo=l(),b1=a("li"),_ge=a("strong"),qyo=o("ibert"),jyo=o(" \u2014 "),GG=a("a"),Dyo=o("IBertForMaskedLM"),Gyo=o(" (I-BERT model)"),Oyo=l(),v1=a("li"),uge=a("strong"),Vyo=o("layoutlm"),Xyo=o(" \u2014 "),OG=a("a"),zyo=o("LayoutLMForMaskedLM"),Qyo=o(" (LayoutLM model)"),Wyo=l(),F1=a("li"),bge=a("strong"),Hyo=o("longformer"),Uyo=o(" \u2014 "),VG=a("a"),Jyo=o("LongformerForMaskedLM"),Yyo=o(" (Longformer model)"),Kyo=l(),T1=a("li"),vge=a("strong"),Zyo=o("lxmert"),e8o=o(" \u2014 "),XG=a("a"),o8o=o("LxmertForPreTraining"),r8o=o(" (LXMERT model)"),t8o=l(),M1=a("li"),Fge=a("strong"),a8o=o("megatron-bert"),n8o=o(" \u2014 "),zG=a("a"),s8o=o("MegatronBertForPreTraining"),l8o=o(" (Megatron-BERT model)"),i8o=l(),E1=a("li"),Tge=a("strong"),d8o=o("mobilebert"),c8o=o(" \u2014 "),QG=a("a"),f8o=o("MobileBertForPreTraining"),m8o=o(" (MobileBERT model)"),g8o=l(),C1=a("li"),Mge=a("strong"),h8o=o("mpnet"),p8o=o(" \u2014 "),WG=a("a"),_8o=o("MPNetForMaskedLM"),u8o=o(" (MPNet model)"),b8o=l(),w1=a("li"),Ege=a("strong"),v8o=o("mvp"),F8o=o(" \u2014 "),HG=a("a"),T8o=o("MvpForConditionalGeneration"),M8o=o(" (MVP model)"),E8o=l(),A1=a("li"),Cge=a("strong"),C8o=o("nezha"),w8o=o(" \u2014 "),UG=a("a"),A8o=o("NezhaForPreTraining"),L8o=o(" (Nezha model)"),y8o=l(),L1=a("li"),wge=a("strong"),x8o=o("openai-gpt"),$8o=o(" \u2014 "),JG=a("a"),k8o=o("OpenAIGPTLMHeadModel"),S8o=o(" (OpenAI GPT model)"),R8o=l(),y1=a("li"),Age=a("strong"),P8o=o("retribert"),B8o=o(" \u2014 "),YG=a("a"),I8o=o("RetriBertModel"),N8o=o(" (RetriBERT model)"),q8o=l(),x1=a("li"),Lge=a("strong"),j8o=o("roberta"),D8o=o(" \u2014 "),KG=a("a"),G8o=o("RobertaForMaskedLM"),O8o=o(" (RoBERTa model)"),V8o=l(),$1=a("li"),yge=a("strong"),X8o=o("splinter"),z8o=o(" \u2014 "),ZG=a("a"),Q8o=o("SplinterForPreTraining"),W8o=o(" (Splinter model)"),H8o=l(),k1=a("li"),xge=a("strong"),U8o=o("squeezebert"),J8o=o(" \u2014 "),eO=a("a"),Y8o=o("SqueezeBertForMaskedLM"),K8o=o(" (SqueezeBERT model)"),Z8o=l(),S1=a("li"),$ge=a("strong"),exo=o("t5"),oxo=o(" \u2014 "),oO=a("a"),rxo=o("T5ForConditionalGeneration"),txo=o(" (T5 model)"),axo=l(),R1=a("li"),kge=a("strong"),nxo=o("tapas"),sxo=o(" \u2014 "),rO=a("a"),lxo=o("TapasForMaskedLM"),ixo=o(" (TAPAS model)"),dxo=l(),P1=a("li"),Sge=a("strong"),cxo=o("transfo-xl"),fxo=o(" \u2014 "),tO=a("a"),mxo=o("TransfoXLLMHeadModel"),gxo=o(" (Transformer-XL model)"),hxo=l(),B1=a("li"),Rge=a("strong"),pxo=o("unispeech"),_xo=o(" \u2014 "),aO=a("a"),uxo=o("UniSpeechForPreTraining"),bxo=o(" (UniSpeech model)"),vxo=l(),I1=a("li"),Pge=a("strong"),Fxo=o("unispeech-sat"),Txo=o(" \u2014 "),nO=a("a"),Mxo=o("UniSpeechSatForPreTraining"),Exo=o(" (UniSpeechSat model)"),Cxo=l(),N1=a("li"),Bge=a("strong"),wxo=o("visual_bert"),Axo=o(" \u2014 "),sO=a("a"),Lxo=o("VisualBertForPreTraining"),yxo=o(" (VisualBERT model)"),xxo=l(),q1=a("li"),Ige=a("strong"),$xo=o("vit_mae"),kxo=o(" \u2014 "),lO=a("a"),Sxo=o("ViTMAEForPreTraining"),Rxo=o(" (ViTMAE model)"),Pxo=l(),j1=a("li"),Nge=a("strong"),Bxo=o("wav2vec2"),Ixo=o(" \u2014 "),iO=a("a"),Nxo=o("Wav2Vec2ForPreTraining"),qxo=o(" (Wav2Vec2 model)"),jxo=l(),D1=a("li"),qge=a("strong"),Dxo=o("wav2vec2-conformer"),Gxo=o(" \u2014 "),dO=a("a"),Oxo=o("Wav2Vec2ConformerForPreTraining"),Vxo=o(" (Wav2Vec2-Conformer model)"),Xxo=l(),G1=a("li"),jge=a("strong"),zxo=o("xlm"),Qxo=o(" \u2014 "),cO=a("a"),Wxo=o("XLMWithLMHeadModel"),Hxo=o(" (XLM model)"),Uxo=l(),O1=a("li"),Dge=a("strong"),Jxo=o("xlm-roberta"),Yxo=o(" \u2014 "),fO=a("a"),Kxo=o("XLMRobertaForMaskedLM"),Zxo=o(" (XLM-RoBERTa model)"),e$o=l(),V1=a("li"),Gge=a("strong"),o$o=o("xlm-roberta-xl"),r$o=o(" \u2014 "),mO=a("a"),t$o=o("XLMRobertaXLForMaskedLM"),a$o=o(" (XLM-RoBERTa-XL model)"),n$o=l(),X1=a("li"),Oge=a("strong"),s$o=o("xlnet"),l$o=o(" \u2014 "),gO=a("a"),i$o=o("XLNetLMHeadModel"),d$o=o(" (XLNet model)"),c$o=l(),z1=a("p"),f$o=o("The model is set in evaluation mode by default using "),Vge=a("code"),m$o=o("model.eval()"),g$o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xge=a("code"),h$o=o("model.train()"),p$o=l(),F(Q1.$$.fragment),nze=l(),Ui=a("h2"),W1=a("a"),zge=a("span"),F(KL.$$.fragment),_$o=l(),Qge=a("span"),u$o=o("AutoModelForCausalLM"),sze=l(),Ro=a("div"),F(ZL.$$.fragment),b$o=l(),Ji=a("p"),v$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hO=a("a"),F$o=o("from_pretrained()"),T$o=o(" class method or the "),pO=a("a"),M$o=o("from_config()"),E$o=o(` class
method.`),C$o=l(),ey=a("p"),w$o=o("This class cannot be instantiated directly using "),Wge=a("code"),A$o=o("__init__()"),L$o=o(" (throws an error)."),y$o=l(),ct=a("div"),F(oy.$$.fragment),x$o=l(),Hge=a("p"),$$o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),k$o=l(),Yi=a("p"),S$o=o(`Note:
Loading a model from its configuration file does `),Uge=a("strong"),R$o=o("not"),P$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_O=a("a"),B$o=o("from_pretrained()"),I$o=o(" to load the model weights."),N$o=l(),F(H1.$$.fragment),q$o=l(),Ze=a("div"),F(ry.$$.fragment),j$o=l(),Jge=a("p"),D$o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),G$o=l(),qa=a("p"),O$o=o("The model class to instantiate is selected based on the "),Yge=a("code"),V$o=o("model_type"),X$o=o(` property of the config object (either
passed as an argument or loaded from `),Kge=a("code"),z$o=o("pretrained_model_name_or_path"),Q$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zge=a("code"),W$o=o("pretrained_model_name_or_path"),H$o=o(":"),U$o=l(),z=a("ul"),U1=a("li"),ehe=a("strong"),J$o=o("bart"),Y$o=o(" \u2014 "),uO=a("a"),K$o=o("BartForCausalLM"),Z$o=o(" (BART model)"),eko=l(),J1=a("li"),ohe=a("strong"),oko=o("bert"),rko=o(" \u2014 "),bO=a("a"),tko=o("BertLMHeadModel"),ako=o(" (BERT model)"),nko=l(),Y1=a("li"),rhe=a("strong"),sko=o("bert-generation"),lko=o(" \u2014 "),vO=a("a"),iko=o("BertGenerationDecoder"),dko=o(" (Bert Generation model)"),cko=l(),K1=a("li"),the=a("strong"),fko=o("big_bird"),mko=o(" \u2014 "),FO=a("a"),gko=o("BigBirdForCausalLM"),hko=o(" (BigBird model)"),pko=l(),Z1=a("li"),ahe=a("strong"),_ko=o("bigbird_pegasus"),uko=o(" \u2014 "),TO=a("a"),bko=o("BigBirdPegasusForCausalLM"),vko=o(" (BigBird-Pegasus model)"),Fko=l(),e4=a("li"),nhe=a("strong"),Tko=o("blenderbot"),Mko=o(" \u2014 "),MO=a("a"),Eko=o("BlenderbotForCausalLM"),Cko=o(" (Blenderbot model)"),wko=l(),o4=a("li"),she=a("strong"),Ako=o("blenderbot-small"),Lko=o(" \u2014 "),EO=a("a"),yko=o("BlenderbotSmallForCausalLM"),xko=o(" (BlenderbotSmall model)"),$ko=l(),r4=a("li"),lhe=a("strong"),kko=o("bloom"),Sko=o(" \u2014 "),CO=a("a"),Rko=o("BloomForCausalLM"),Pko=o(" (BLOOM model)"),Bko=l(),t4=a("li"),ihe=a("strong"),Iko=o("camembert"),Nko=o(" \u2014 "),wO=a("a"),qko=o("CamembertForCausalLM"),jko=o(" (CamemBERT model)"),Dko=l(),a4=a("li"),dhe=a("strong"),Gko=o("codegen"),Oko=o(" \u2014 "),AO=a("a"),Vko=o("CodeGenForCausalLM"),Xko=o(" (CodeGen model)"),zko=l(),n4=a("li"),che=a("strong"),Qko=o("ctrl"),Wko=o(" \u2014 "),LO=a("a"),Hko=o("CTRLLMHeadModel"),Uko=o(" (CTRL model)"),Jko=l(),s4=a("li"),fhe=a("strong"),Yko=o("data2vec-text"),Kko=o(" \u2014 "),yO=a("a"),Zko=o("Data2VecTextForCausalLM"),eSo=o(" (Data2VecText model)"),oSo=l(),l4=a("li"),mhe=a("strong"),rSo=o("electra"),tSo=o(" \u2014 "),xO=a("a"),aSo=o("ElectraForCausalLM"),nSo=o(" (ELECTRA model)"),sSo=l(),i4=a("li"),ghe=a("strong"),lSo=o("gpt2"),iSo=o(" \u2014 "),$O=a("a"),dSo=o("GPT2LMHeadModel"),cSo=o(" (OpenAI GPT-2 model)"),fSo=l(),d4=a("li"),hhe=a("strong"),mSo=o("gpt_neo"),gSo=o(" \u2014 "),kO=a("a"),hSo=o("GPTNeoForCausalLM"),pSo=o(" (GPT Neo model)"),_So=l(),c4=a("li"),phe=a("strong"),uSo=o("gpt_neox"),bSo=o(" \u2014 "),SO=a("a"),vSo=o("GPTNeoXForCausalLM"),FSo=o(" (GPT NeoX model)"),TSo=l(),f4=a("li"),_he=a("strong"),MSo=o("gptj"),ESo=o(" \u2014 "),RO=a("a"),CSo=o("GPTJForCausalLM"),wSo=o(" (GPT-J model)"),ASo=l(),m4=a("li"),uhe=a("strong"),LSo=o("marian"),ySo=o(" \u2014 "),PO=a("a"),xSo=o("MarianForCausalLM"),$So=o(" (Marian model)"),kSo=l(),g4=a("li"),bhe=a("strong"),SSo=o("mbart"),RSo=o(" \u2014 "),BO=a("a"),PSo=o("MBartForCausalLM"),BSo=o(" (mBART model)"),ISo=l(),h4=a("li"),vhe=a("strong"),NSo=o("megatron-bert"),qSo=o(" \u2014 "),IO=a("a"),jSo=o("MegatronBertForCausalLM"),DSo=o(" (Megatron-BERT model)"),GSo=l(),p4=a("li"),Fhe=a("strong"),OSo=o("mvp"),VSo=o(" \u2014 "),NO=a("a"),XSo=o("MvpForCausalLM"),zSo=o(" (MVP model)"),QSo=l(),_4=a("li"),The=a("strong"),WSo=o("openai-gpt"),HSo=o(" \u2014 "),qO=a("a"),USo=o("OpenAIGPTLMHeadModel"),JSo=o(" (OpenAI GPT model)"),YSo=l(),u4=a("li"),Mhe=a("strong"),KSo=o("opt"),ZSo=o(" \u2014 "),jO=a("a"),eRo=o("OPTForCausalLM"),oRo=o(" (OPT model)"),rRo=l(),b4=a("li"),Ehe=a("strong"),tRo=o("pegasus"),aRo=o(" \u2014 "),DO=a("a"),nRo=o("PegasusForCausalLM"),sRo=o(" (Pegasus model)"),lRo=l(),v4=a("li"),Che=a("strong"),iRo=o("plbart"),dRo=o(" \u2014 "),GO=a("a"),cRo=o("PLBartForCausalLM"),fRo=o(" (PLBart model)"),mRo=l(),F4=a("li"),whe=a("strong"),gRo=o("prophetnet"),hRo=o(" \u2014 "),OO=a("a"),pRo=o("ProphetNetForCausalLM"),_Ro=o(" (ProphetNet model)"),uRo=l(),T4=a("li"),Ahe=a("strong"),bRo=o("qdqbert"),vRo=o(" \u2014 "),VO=a("a"),FRo=o("QDQBertLMHeadModel"),TRo=o(" (QDQBert model)"),MRo=l(),M4=a("li"),Lhe=a("strong"),ERo=o("reformer"),CRo=o(" \u2014 "),XO=a("a"),wRo=o("ReformerModelWithLMHead"),ARo=o(" (Reformer model)"),LRo=l(),E4=a("li"),yhe=a("strong"),yRo=o("rembert"),xRo=o(" \u2014 "),zO=a("a"),$Ro=o("RemBertForCausalLM"),kRo=o(" (RemBERT model)"),SRo=l(),C4=a("li"),xhe=a("strong"),RRo=o("roberta"),PRo=o(" \u2014 "),QO=a("a"),BRo=o("RobertaForCausalLM"),IRo=o(" (RoBERTa model)"),NRo=l(),w4=a("li"),$he=a("strong"),qRo=o("roformer"),jRo=o(" \u2014 "),WO=a("a"),DRo=o("RoFormerForCausalLM"),GRo=o(" (RoFormer model)"),ORo=l(),A4=a("li"),khe=a("strong"),VRo=o("speech_to_text_2"),XRo=o(" \u2014 "),HO=a("a"),zRo=o("Speech2Text2ForCausalLM"),QRo=o(" (Speech2Text2 model)"),WRo=l(),L4=a("li"),She=a("strong"),HRo=o("transfo-xl"),URo=o(" \u2014 "),UO=a("a"),JRo=o("TransfoXLLMHeadModel"),YRo=o(" (Transformer-XL model)"),KRo=l(),y4=a("li"),Rhe=a("strong"),ZRo=o("trocr"),ePo=o(" \u2014 "),JO=a("a"),oPo=o("TrOCRForCausalLM"),rPo=o(" (TrOCR model)"),tPo=l(),x4=a("li"),Phe=a("strong"),aPo=o("xglm"),nPo=o(" \u2014 "),YO=a("a"),sPo=o("XGLMForCausalLM"),lPo=o(" (XGLM model)"),iPo=l(),$4=a("li"),Bhe=a("strong"),dPo=o("xlm"),cPo=o(" \u2014 "),KO=a("a"),fPo=o("XLMWithLMHeadModel"),mPo=o(" (XLM model)"),gPo=l(),k4=a("li"),Ihe=a("strong"),hPo=o("xlm-prophetnet"),pPo=o(" \u2014 "),ZO=a("a"),_Po=o("XLMProphetNetForCausalLM"),uPo=o(" (XLM-ProphetNet model)"),bPo=l(),S4=a("li"),Nhe=a("strong"),vPo=o("xlm-roberta"),FPo=o(" \u2014 "),eV=a("a"),TPo=o("XLMRobertaForCausalLM"),MPo=o(" (XLM-RoBERTa model)"),EPo=l(),R4=a("li"),qhe=a("strong"),CPo=o("xlm-roberta-xl"),wPo=o(" \u2014 "),oV=a("a"),APo=o("XLMRobertaXLForCausalLM"),LPo=o(" (XLM-RoBERTa-XL model)"),yPo=l(),P4=a("li"),jhe=a("strong"),xPo=o("xlnet"),$Po=o(" \u2014 "),rV=a("a"),kPo=o("XLNetLMHeadModel"),SPo=o(" (XLNet model)"),RPo=l(),B4=a("p"),PPo=o("The model is set in evaluation mode by default using "),Dhe=a("code"),BPo=o("model.eval()"),IPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ghe=a("code"),NPo=o("model.train()"),qPo=l(),F(I4.$$.fragment),lze=l(),Ki=a("h2"),N4=a("a"),Ohe=a("span"),F(ty.$$.fragment),jPo=l(),Vhe=a("span"),DPo=o("AutoModelForMaskedLM"),ize=l(),Po=a("div"),F(ay.$$.fragment),GPo=l(),Zi=a("p"),OPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),tV=a("a"),VPo=o("from_pretrained()"),XPo=o(" class method or the "),aV=a("a"),zPo=o("from_config()"),QPo=o(` class
method.`),WPo=l(),ny=a("p"),HPo=o("This class cannot be instantiated directly using "),Xhe=a("code"),UPo=o("__init__()"),JPo=o(" (throws an error)."),YPo=l(),ft=a("div"),F(sy.$$.fragment),KPo=l(),zhe=a("p"),ZPo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),eBo=l(),ed=a("p"),oBo=o(`Note:
Loading a model from its configuration file does `),Qhe=a("strong"),rBo=o("not"),tBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nV=a("a"),aBo=o("from_pretrained()"),nBo=o(" to load the model weights."),sBo=l(),F(q4.$$.fragment),lBo=l(),eo=a("div"),F(ly.$$.fragment),iBo=l(),Whe=a("p"),dBo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),cBo=l(),ja=a("p"),fBo=o("The model class to instantiate is selected based on the "),Hhe=a("code"),mBo=o("model_type"),gBo=o(` property of the config object (either
passed as an argument or loaded from `),Uhe=a("code"),hBo=o("pretrained_model_name_or_path"),pBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jhe=a("code"),_Bo=o("pretrained_model_name_or_path"),uBo=o(":"),bBo=l(),W=a("ul"),j4=a("li"),Yhe=a("strong"),vBo=o("albert"),FBo=o(" \u2014 "),sV=a("a"),TBo=o("AlbertForMaskedLM"),MBo=o(" (ALBERT model)"),EBo=l(),D4=a("li"),Khe=a("strong"),CBo=o("bart"),wBo=o(" \u2014 "),lV=a("a"),ABo=o("BartForConditionalGeneration"),LBo=o(" (BART model)"),yBo=l(),G4=a("li"),Zhe=a("strong"),xBo=o("bert"),$Bo=o(" \u2014 "),iV=a("a"),kBo=o("BertForMaskedLM"),SBo=o(" (BERT model)"),RBo=l(),O4=a("li"),epe=a("strong"),PBo=o("big_bird"),BBo=o(" \u2014 "),dV=a("a"),IBo=o("BigBirdForMaskedLM"),NBo=o(" (BigBird model)"),qBo=l(),V4=a("li"),ope=a("strong"),jBo=o("camembert"),DBo=o(" \u2014 "),cV=a("a"),GBo=o("CamembertForMaskedLM"),OBo=o(" (CamemBERT model)"),VBo=l(),X4=a("li"),rpe=a("strong"),XBo=o("convbert"),zBo=o(" \u2014 "),fV=a("a"),QBo=o("ConvBertForMaskedLM"),WBo=o(" (ConvBERT model)"),HBo=l(),z4=a("li"),tpe=a("strong"),UBo=o("data2vec-text"),JBo=o(" \u2014 "),mV=a("a"),YBo=o("Data2VecTextForMaskedLM"),KBo=o(" (Data2VecText model)"),ZBo=l(),Q4=a("li"),ape=a("strong"),eIo=o("deberta"),oIo=o(" \u2014 "),gV=a("a"),rIo=o("DebertaForMaskedLM"),tIo=o(" (DeBERTa model)"),aIo=l(),W4=a("li"),npe=a("strong"),nIo=o("deberta-v2"),sIo=o(" \u2014 "),hV=a("a"),lIo=o("DebertaV2ForMaskedLM"),iIo=o(" (DeBERTa-v2 model)"),dIo=l(),H4=a("li"),spe=a("strong"),cIo=o("distilbert"),fIo=o(" \u2014 "),pV=a("a"),mIo=o("DistilBertForMaskedLM"),gIo=o(" (DistilBERT model)"),hIo=l(),U4=a("li"),lpe=a("strong"),pIo=o("electra"),_Io=o(" \u2014 "),_V=a("a"),uIo=o("ElectraForMaskedLM"),bIo=o(" (ELECTRA model)"),vIo=l(),J4=a("li"),ipe=a("strong"),FIo=o("flaubert"),TIo=o(" \u2014 "),uV=a("a"),MIo=o("FlaubertWithLMHeadModel"),EIo=o(" (FlauBERT model)"),CIo=l(),Y4=a("li"),dpe=a("strong"),wIo=o("fnet"),AIo=o(" \u2014 "),bV=a("a"),LIo=o("FNetForMaskedLM"),yIo=o(" (FNet model)"),xIo=l(),K4=a("li"),cpe=a("strong"),$Io=o("funnel"),kIo=o(" \u2014 "),vV=a("a"),SIo=o("FunnelForMaskedLM"),RIo=o(" (Funnel Transformer model)"),PIo=l(),Z4=a("li"),fpe=a("strong"),BIo=o("ibert"),IIo=o(" \u2014 "),FV=a("a"),NIo=o("IBertForMaskedLM"),qIo=o(" (I-BERT model)"),jIo=l(),e2=a("li"),mpe=a("strong"),DIo=o("layoutlm"),GIo=o(" \u2014 "),TV=a("a"),OIo=o("LayoutLMForMaskedLM"),VIo=o(" (LayoutLM model)"),XIo=l(),o2=a("li"),gpe=a("strong"),zIo=o("longformer"),QIo=o(" \u2014 "),MV=a("a"),WIo=o("LongformerForMaskedLM"),HIo=o(" (Longformer model)"),UIo=l(),r2=a("li"),hpe=a("strong"),JIo=o("luke"),YIo=o(" \u2014 "),EV=a("a"),KIo=o("LukeForMaskedLM"),ZIo=o(" (LUKE model)"),eNo=l(),t2=a("li"),ppe=a("strong"),oNo=o("mbart"),rNo=o(" \u2014 "),CV=a("a"),tNo=o("MBartForConditionalGeneration"),aNo=o(" (mBART model)"),nNo=l(),a2=a("li"),_pe=a("strong"),sNo=o("megatron-bert"),lNo=o(" \u2014 "),wV=a("a"),iNo=o("MegatronBertForMaskedLM"),dNo=o(" (Megatron-BERT model)"),cNo=l(),n2=a("li"),upe=a("strong"),fNo=o("mobilebert"),mNo=o(" \u2014 "),AV=a("a"),gNo=o("MobileBertForMaskedLM"),hNo=o(" (MobileBERT model)"),pNo=l(),s2=a("li"),bpe=a("strong"),_No=o("mpnet"),uNo=o(" \u2014 "),LV=a("a"),bNo=o("MPNetForMaskedLM"),vNo=o(" (MPNet model)"),FNo=l(),l2=a("li"),vpe=a("strong"),TNo=o("mvp"),MNo=o(" \u2014 "),yV=a("a"),ENo=o("MvpForConditionalGeneration"),CNo=o(" (MVP model)"),wNo=l(),i2=a("li"),Fpe=a("strong"),ANo=o("nezha"),LNo=o(" \u2014 "),xV=a("a"),yNo=o("NezhaForMaskedLM"),xNo=o(" (Nezha model)"),$No=l(),d2=a("li"),Tpe=a("strong"),kNo=o("nystromformer"),SNo=o(" \u2014 "),$V=a("a"),RNo=o("NystromformerForMaskedLM"),PNo=o(" (Nystr\xF6mformer model)"),BNo=l(),c2=a("li"),Mpe=a("strong"),INo=o("perceiver"),NNo=o(" \u2014 "),kV=a("a"),qNo=o("PerceiverForMaskedLM"),jNo=o(" (Perceiver model)"),DNo=l(),f2=a("li"),Epe=a("strong"),GNo=o("qdqbert"),ONo=o(" \u2014 "),SV=a("a"),VNo=o("QDQBertForMaskedLM"),XNo=o(" (QDQBert model)"),zNo=l(),m2=a("li"),Cpe=a("strong"),QNo=o("reformer"),WNo=o(" \u2014 "),RV=a("a"),HNo=o("ReformerForMaskedLM"),UNo=o(" (Reformer model)"),JNo=l(),g2=a("li"),wpe=a("strong"),YNo=o("rembert"),KNo=o(" \u2014 "),PV=a("a"),ZNo=o("RemBertForMaskedLM"),eqo=o(" (RemBERT model)"),oqo=l(),h2=a("li"),Ape=a("strong"),rqo=o("roberta"),tqo=o(" \u2014 "),BV=a("a"),aqo=o("RobertaForMaskedLM"),nqo=o(" (RoBERTa model)"),sqo=l(),p2=a("li"),Lpe=a("strong"),lqo=o("roformer"),iqo=o(" \u2014 "),IV=a("a"),dqo=o("RoFormerForMaskedLM"),cqo=o(" (RoFormer model)"),fqo=l(),_2=a("li"),ype=a("strong"),mqo=o("squeezebert"),gqo=o(" \u2014 "),NV=a("a"),hqo=o("SqueezeBertForMaskedLM"),pqo=o(" (SqueezeBERT model)"),_qo=l(),u2=a("li"),xpe=a("strong"),uqo=o("tapas"),bqo=o(" \u2014 "),qV=a("a"),vqo=o("TapasForMaskedLM"),Fqo=o(" (TAPAS model)"),Tqo=l(),b2=a("li"),$pe=a("strong"),Mqo=o("wav2vec2"),Eqo=o(" \u2014 "),kpe=a("code"),Cqo=o("Wav2Vec2ForMaskedLM"),wqo=o(" (Wav2Vec2 model)"),Aqo=l(),v2=a("li"),Spe=a("strong"),Lqo=o("xlm"),yqo=o(" \u2014 "),jV=a("a"),xqo=o("XLMWithLMHeadModel"),$qo=o(" (XLM model)"),kqo=l(),F2=a("li"),Rpe=a("strong"),Sqo=o("xlm-roberta"),Rqo=o(" \u2014 "),DV=a("a"),Pqo=o("XLMRobertaForMaskedLM"),Bqo=o(" (XLM-RoBERTa model)"),Iqo=l(),T2=a("li"),Ppe=a("strong"),Nqo=o("xlm-roberta-xl"),qqo=o(" \u2014 "),GV=a("a"),jqo=o("XLMRobertaXLForMaskedLM"),Dqo=o(" (XLM-RoBERTa-XL model)"),Gqo=l(),M2=a("li"),Bpe=a("strong"),Oqo=o("yoso"),Vqo=o(" \u2014 "),OV=a("a"),Xqo=o("YosoForMaskedLM"),zqo=o(" (YOSO model)"),Qqo=l(),E2=a("p"),Wqo=o("The model is set in evaluation mode by default using "),Ipe=a("code"),Hqo=o("model.eval()"),Uqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Npe=a("code"),Jqo=o("model.train()"),Yqo=l(),F(C2.$$.fragment),dze=l(),od=a("h2"),w2=a("a"),qpe=a("span"),F(iy.$$.fragment),Kqo=l(),jpe=a("span"),Zqo=o("AutoModelForSeq2SeqLM"),cze=l(),Bo=a("div"),F(dy.$$.fragment),ejo=l(),rd=a("p"),ojo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),VV=a("a"),rjo=o("from_pretrained()"),tjo=o(" class method or the "),XV=a("a"),ajo=o("from_config()"),njo=o(` class
method.`),sjo=l(),cy=a("p"),ljo=o("This class cannot be instantiated directly using "),Dpe=a("code"),ijo=o("__init__()"),djo=o(" (throws an error)."),cjo=l(),mt=a("div"),F(fy.$$.fragment),fjo=l(),Gpe=a("p"),mjo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),gjo=l(),td=a("p"),hjo=o(`Note:
Loading a model from its configuration file does `),Ope=a("strong"),pjo=o("not"),_jo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zV=a("a"),ujo=o("from_pretrained()"),bjo=o(" to load the model weights."),vjo=l(),F(A2.$$.fragment),Fjo=l(),oo=a("div"),F(my.$$.fragment),Tjo=l(),Vpe=a("p"),Mjo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ejo=l(),Da=a("p"),Cjo=o("The model class to instantiate is selected based on the "),Xpe=a("code"),wjo=o("model_type"),Ajo=o(` property of the config object (either
passed as an argument or loaded from `),zpe=a("code"),Ljo=o("pretrained_model_name_or_path"),yjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qpe=a("code"),xjo=o("pretrained_model_name_or_path"),$jo=o(":"),kjo=l(),fe=a("ul"),L2=a("li"),Wpe=a("strong"),Sjo=o("bart"),Rjo=o(" \u2014 "),QV=a("a"),Pjo=o("BartForConditionalGeneration"),Bjo=o(" (BART model)"),Ijo=l(),y2=a("li"),Hpe=a("strong"),Njo=o("bigbird_pegasus"),qjo=o(" \u2014 "),WV=a("a"),jjo=o("BigBirdPegasusForConditionalGeneration"),Djo=o(" (BigBird-Pegasus model)"),Gjo=l(),x2=a("li"),Upe=a("strong"),Ojo=o("blenderbot"),Vjo=o(" \u2014 "),HV=a("a"),Xjo=o("BlenderbotForConditionalGeneration"),zjo=o(" (Blenderbot model)"),Qjo=l(),$2=a("li"),Jpe=a("strong"),Wjo=o("blenderbot-small"),Hjo=o(" \u2014 "),UV=a("a"),Ujo=o("BlenderbotSmallForConditionalGeneration"),Jjo=o(" (BlenderbotSmall model)"),Yjo=l(),k2=a("li"),Ype=a("strong"),Kjo=o("encoder-decoder"),Zjo=o(" \u2014 "),JV=a("a"),eDo=o("EncoderDecoderModel"),oDo=o(" (Encoder decoder model)"),rDo=l(),S2=a("li"),Kpe=a("strong"),tDo=o("fsmt"),aDo=o(" \u2014 "),YV=a("a"),nDo=o("FSMTForConditionalGeneration"),sDo=o(" (FairSeq Machine-Translation model)"),lDo=l(),R2=a("li"),Zpe=a("strong"),iDo=o("led"),dDo=o(" \u2014 "),KV=a("a"),cDo=o("LEDForConditionalGeneration"),fDo=o(" (LED model)"),mDo=l(),P2=a("li"),e_e=a("strong"),gDo=o("longt5"),hDo=o(" \u2014 "),ZV=a("a"),pDo=o("LongT5ForConditionalGeneration"),_Do=o(" (LongT5 model)"),uDo=l(),B2=a("li"),o_e=a("strong"),bDo=o("m2m_100"),vDo=o(" \u2014 "),eX=a("a"),FDo=o("M2M100ForConditionalGeneration"),TDo=o(" (M2M100 model)"),MDo=l(),I2=a("li"),r_e=a("strong"),EDo=o("marian"),CDo=o(" \u2014 "),oX=a("a"),wDo=o("MarianMTModel"),ADo=o(" (Marian model)"),LDo=l(),N2=a("li"),t_e=a("strong"),yDo=o("mbart"),xDo=o(" \u2014 "),rX=a("a"),$Do=o("MBartForConditionalGeneration"),kDo=o(" (mBART model)"),SDo=l(),q2=a("li"),a_e=a("strong"),RDo=o("mt5"),PDo=o(" \u2014 "),tX=a("a"),BDo=o("MT5ForConditionalGeneration"),IDo=o(" (MT5 model)"),NDo=l(),j2=a("li"),n_e=a("strong"),qDo=o("mvp"),jDo=o(" \u2014 "),aX=a("a"),DDo=o("MvpForConditionalGeneration"),GDo=o(" (MVP model)"),ODo=l(),D2=a("li"),s_e=a("strong"),VDo=o("nllb"),XDo=o(" \u2014 "),nX=a("a"),zDo=o("M2M100ForConditionalGeneration"),QDo=o(" (NLLB model)"),WDo=l(),G2=a("li"),l_e=a("strong"),HDo=o("pegasus"),UDo=o(" \u2014 "),sX=a("a"),JDo=o("PegasusForConditionalGeneration"),YDo=o(" (Pegasus model)"),KDo=l(),O2=a("li"),i_e=a("strong"),ZDo=o("plbart"),eGo=o(" \u2014 "),lX=a("a"),oGo=o("PLBartForConditionalGeneration"),rGo=o(" (PLBart model)"),tGo=l(),V2=a("li"),d_e=a("strong"),aGo=o("prophetnet"),nGo=o(" \u2014 "),iX=a("a"),sGo=o("ProphetNetForConditionalGeneration"),lGo=o(" (ProphetNet model)"),iGo=l(),X2=a("li"),c_e=a("strong"),dGo=o("t5"),cGo=o(" \u2014 "),dX=a("a"),fGo=o("T5ForConditionalGeneration"),mGo=o(" (T5 model)"),gGo=l(),z2=a("li"),f_e=a("strong"),hGo=o("xlm-prophetnet"),pGo=o(" \u2014 "),cX=a("a"),_Go=o("XLMProphetNetForConditionalGeneration"),uGo=o(" (XLM-ProphetNet model)"),bGo=l(),Q2=a("p"),vGo=o("The model is set in evaluation mode by default using "),m_e=a("code"),FGo=o("model.eval()"),TGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g_e=a("code"),MGo=o("model.train()"),EGo=l(),F(W2.$$.fragment),fze=l(),ad=a("h2"),H2=a("a"),h_e=a("span"),F(gy.$$.fragment),CGo=l(),p_e=a("span"),wGo=o("AutoModelForSequenceClassification"),mze=l(),Io=a("div"),F(hy.$$.fragment),AGo=l(),nd=a("p"),LGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fX=a("a"),yGo=o("from_pretrained()"),xGo=o(" class method or the "),mX=a("a"),$Go=o("from_config()"),kGo=o(` class
method.`),SGo=l(),py=a("p"),RGo=o("This class cannot be instantiated directly using "),__e=a("code"),PGo=o("__init__()"),BGo=o(" (throws an error)."),IGo=l(),gt=a("div"),F(_y.$$.fragment),NGo=l(),u_e=a("p"),qGo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),jGo=l(),sd=a("p"),DGo=o(`Note:
Loading a model from its configuration file does `),b_e=a("strong"),GGo=o("not"),OGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gX=a("a"),VGo=o("from_pretrained()"),XGo=o(" to load the model weights."),zGo=l(),F(U2.$$.fragment),QGo=l(),ro=a("div"),F(uy.$$.fragment),WGo=l(),v_e=a("p"),HGo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),UGo=l(),Ga=a("p"),JGo=o("The model class to instantiate is selected based on the "),F_e=a("code"),YGo=o("model_type"),KGo=o(` property of the config object (either
passed as an argument or loaded from `),T_e=a("code"),ZGo=o("pretrained_model_name_or_path"),eOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M_e=a("code"),oOo=o("pretrained_model_name_or_path"),rOo=o(":"),tOo=l(),B=a("ul"),J2=a("li"),E_e=a("strong"),aOo=o("albert"),nOo=o(" \u2014 "),hX=a("a"),sOo=o("AlbertForSequenceClassification"),lOo=o(" (ALBERT model)"),iOo=l(),Y2=a("li"),C_e=a("strong"),dOo=o("bart"),cOo=o(" \u2014 "),pX=a("a"),fOo=o("BartForSequenceClassification"),mOo=o(" (BART model)"),gOo=l(),K2=a("li"),w_e=a("strong"),hOo=o("bert"),pOo=o(" \u2014 "),_X=a("a"),_Oo=o("BertForSequenceClassification"),uOo=o(" (BERT model)"),bOo=l(),Z2=a("li"),A_e=a("strong"),vOo=o("big_bird"),FOo=o(" \u2014 "),uX=a("a"),TOo=o("BigBirdForSequenceClassification"),MOo=o(" (BigBird model)"),EOo=l(),eb=a("li"),L_e=a("strong"),COo=o("bigbird_pegasus"),wOo=o(" \u2014 "),bX=a("a"),AOo=o("BigBirdPegasusForSequenceClassification"),LOo=o(" (BigBird-Pegasus model)"),yOo=l(),ob=a("li"),y_e=a("strong"),xOo=o("bloom"),$Oo=o(" \u2014 "),vX=a("a"),kOo=o("BloomForSequenceClassification"),SOo=o(" (BLOOM model)"),ROo=l(),rb=a("li"),x_e=a("strong"),POo=o("camembert"),BOo=o(" \u2014 "),FX=a("a"),IOo=o("CamembertForSequenceClassification"),NOo=o(" (CamemBERT model)"),qOo=l(),tb=a("li"),$_e=a("strong"),jOo=o("canine"),DOo=o(" \u2014 "),TX=a("a"),GOo=o("CanineForSequenceClassification"),OOo=o(" (CANINE model)"),VOo=l(),ab=a("li"),k_e=a("strong"),XOo=o("convbert"),zOo=o(" \u2014 "),MX=a("a"),QOo=o("ConvBertForSequenceClassification"),WOo=o(" (ConvBERT model)"),HOo=l(),nb=a("li"),S_e=a("strong"),UOo=o("ctrl"),JOo=o(" \u2014 "),EX=a("a"),YOo=o("CTRLForSequenceClassification"),KOo=o(" (CTRL model)"),ZOo=l(),sb=a("li"),R_e=a("strong"),eVo=o("data2vec-text"),oVo=o(" \u2014 "),CX=a("a"),rVo=o("Data2VecTextForSequenceClassification"),tVo=o(" (Data2VecText model)"),aVo=l(),lb=a("li"),P_e=a("strong"),nVo=o("deberta"),sVo=o(" \u2014 "),wX=a("a"),lVo=o("DebertaForSequenceClassification"),iVo=o(" (DeBERTa model)"),dVo=l(),ib=a("li"),B_e=a("strong"),cVo=o("deberta-v2"),fVo=o(" \u2014 "),AX=a("a"),mVo=o("DebertaV2ForSequenceClassification"),gVo=o(" (DeBERTa-v2 model)"),hVo=l(),db=a("li"),I_e=a("strong"),pVo=o("distilbert"),_Vo=o(" \u2014 "),LX=a("a"),uVo=o("DistilBertForSequenceClassification"),bVo=o(" (DistilBERT model)"),vVo=l(),cb=a("li"),N_e=a("strong"),FVo=o("electra"),TVo=o(" \u2014 "),yX=a("a"),MVo=o("ElectraForSequenceClassification"),EVo=o(" (ELECTRA model)"),CVo=l(),fb=a("li"),q_e=a("strong"),wVo=o("flaubert"),AVo=o(" \u2014 "),xX=a("a"),LVo=o("FlaubertForSequenceClassification"),yVo=o(" (FlauBERT model)"),xVo=l(),mb=a("li"),j_e=a("strong"),$Vo=o("fnet"),kVo=o(" \u2014 "),$X=a("a"),SVo=o("FNetForSequenceClassification"),RVo=o(" (FNet model)"),PVo=l(),gb=a("li"),D_e=a("strong"),BVo=o("funnel"),IVo=o(" \u2014 "),kX=a("a"),NVo=o("FunnelForSequenceClassification"),qVo=o(" (Funnel Transformer model)"),jVo=l(),hb=a("li"),G_e=a("strong"),DVo=o("gpt2"),GVo=o(" \u2014 "),SX=a("a"),OVo=o("GPT2ForSequenceClassification"),VVo=o(" (OpenAI GPT-2 model)"),XVo=l(),pb=a("li"),O_e=a("strong"),zVo=o("gpt_neo"),QVo=o(" \u2014 "),RX=a("a"),WVo=o("GPTNeoForSequenceClassification"),HVo=o(" (GPT Neo model)"),UVo=l(),_b=a("li"),V_e=a("strong"),JVo=o("gptj"),YVo=o(" \u2014 "),PX=a("a"),KVo=o("GPTJForSequenceClassification"),ZVo=o(" (GPT-J model)"),eXo=l(),ub=a("li"),X_e=a("strong"),oXo=o("ibert"),rXo=o(" \u2014 "),BX=a("a"),tXo=o("IBertForSequenceClassification"),aXo=o(" (I-BERT model)"),nXo=l(),bb=a("li"),z_e=a("strong"),sXo=o("layoutlm"),lXo=o(" \u2014 "),IX=a("a"),iXo=o("LayoutLMForSequenceClassification"),dXo=o(" (LayoutLM model)"),cXo=l(),vb=a("li"),Q_e=a("strong"),fXo=o("layoutlmv2"),mXo=o(" \u2014 "),NX=a("a"),gXo=o("LayoutLMv2ForSequenceClassification"),hXo=o(" (LayoutLMv2 model)"),pXo=l(),Fb=a("li"),W_e=a("strong"),_Xo=o("layoutlmv3"),uXo=o(" \u2014 "),qX=a("a"),bXo=o("LayoutLMv3ForSequenceClassification"),vXo=o(" (LayoutLMv3 model)"),FXo=l(),Tb=a("li"),H_e=a("strong"),TXo=o("led"),MXo=o(" \u2014 "),jX=a("a"),EXo=o("LEDForSequenceClassification"),CXo=o(" (LED model)"),wXo=l(),Mb=a("li"),U_e=a("strong"),AXo=o("longformer"),LXo=o(" \u2014 "),DX=a("a"),yXo=o("LongformerForSequenceClassification"),xXo=o(" (Longformer model)"),$Xo=l(),Eb=a("li"),J_e=a("strong"),kXo=o("mbart"),SXo=o(" \u2014 "),GX=a("a"),RXo=o("MBartForSequenceClassification"),PXo=o(" (mBART model)"),BXo=l(),Cb=a("li"),Y_e=a("strong"),IXo=o("megatron-bert"),NXo=o(" \u2014 "),OX=a("a"),qXo=o("MegatronBertForSequenceClassification"),jXo=o(" (Megatron-BERT model)"),DXo=l(),wb=a("li"),K_e=a("strong"),GXo=o("mobilebert"),OXo=o(" \u2014 "),VX=a("a"),VXo=o("MobileBertForSequenceClassification"),XXo=o(" (MobileBERT model)"),zXo=l(),Ab=a("li"),Z_e=a("strong"),QXo=o("mpnet"),WXo=o(" \u2014 "),XX=a("a"),HXo=o("MPNetForSequenceClassification"),UXo=o(" (MPNet model)"),JXo=l(),Lb=a("li"),eue=a("strong"),YXo=o("mvp"),KXo=o(" \u2014 "),zX=a("a"),ZXo=o("MvpForSequenceClassification"),ezo=o(" (MVP model)"),ozo=l(),yb=a("li"),oue=a("strong"),rzo=o("nezha"),tzo=o(" \u2014 "),QX=a("a"),azo=o("NezhaForSequenceClassification"),nzo=o(" (Nezha model)"),szo=l(),xb=a("li"),rue=a("strong"),lzo=o("nystromformer"),izo=o(" \u2014 "),WX=a("a"),dzo=o("NystromformerForSequenceClassification"),czo=o(" (Nystr\xF6mformer model)"),fzo=l(),$b=a("li"),tue=a("strong"),mzo=o("openai-gpt"),gzo=o(" \u2014 "),HX=a("a"),hzo=o("OpenAIGPTForSequenceClassification"),pzo=o(" (OpenAI GPT model)"),_zo=l(),kb=a("li"),aue=a("strong"),uzo=o("opt"),bzo=o(" \u2014 "),UX=a("a"),vzo=o("OPTForSequenceClassification"),Fzo=o(" (OPT model)"),Tzo=l(),Sb=a("li"),nue=a("strong"),Mzo=o("perceiver"),Ezo=o(" \u2014 "),JX=a("a"),Czo=o("PerceiverForSequenceClassification"),wzo=o(" (Perceiver model)"),Azo=l(),Rb=a("li"),sue=a("strong"),Lzo=o("plbart"),yzo=o(" \u2014 "),YX=a("a"),xzo=o("PLBartForSequenceClassification"),$zo=o(" (PLBart model)"),kzo=l(),Pb=a("li"),lue=a("strong"),Szo=o("qdqbert"),Rzo=o(" \u2014 "),KX=a("a"),Pzo=o("QDQBertForSequenceClassification"),Bzo=o(" (QDQBert model)"),Izo=l(),Bb=a("li"),iue=a("strong"),Nzo=o("reformer"),qzo=o(" \u2014 "),ZX=a("a"),jzo=o("ReformerForSequenceClassification"),Dzo=o(" (Reformer model)"),Gzo=l(),Ib=a("li"),due=a("strong"),Ozo=o("rembert"),Vzo=o(" \u2014 "),ez=a("a"),Xzo=o("RemBertForSequenceClassification"),zzo=o(" (RemBERT model)"),Qzo=l(),Nb=a("li"),cue=a("strong"),Wzo=o("roberta"),Hzo=o(" \u2014 "),oz=a("a"),Uzo=o("RobertaForSequenceClassification"),Jzo=o(" (RoBERTa model)"),Yzo=l(),qb=a("li"),fue=a("strong"),Kzo=o("roformer"),Zzo=o(" \u2014 "),rz=a("a"),eQo=o("RoFormerForSequenceClassification"),oQo=o(" (RoFormer model)"),rQo=l(),jb=a("li"),mue=a("strong"),tQo=o("squeezebert"),aQo=o(" \u2014 "),tz=a("a"),nQo=o("SqueezeBertForSequenceClassification"),sQo=o(" (SqueezeBERT model)"),lQo=l(),Db=a("li"),gue=a("strong"),iQo=o("tapas"),dQo=o(" \u2014 "),az=a("a"),cQo=o("TapasForSequenceClassification"),fQo=o(" (TAPAS model)"),mQo=l(),Gb=a("li"),hue=a("strong"),gQo=o("transfo-xl"),hQo=o(" \u2014 "),nz=a("a"),pQo=o("TransfoXLForSequenceClassification"),_Qo=o(" (Transformer-XL model)"),uQo=l(),Ob=a("li"),pue=a("strong"),bQo=o("xlm"),vQo=o(" \u2014 "),sz=a("a"),FQo=o("XLMForSequenceClassification"),TQo=o(" (XLM model)"),MQo=l(),Vb=a("li"),_ue=a("strong"),EQo=o("xlm-roberta"),CQo=o(" \u2014 "),lz=a("a"),wQo=o("XLMRobertaForSequenceClassification"),AQo=o(" (XLM-RoBERTa model)"),LQo=l(),Xb=a("li"),uue=a("strong"),yQo=o("xlm-roberta-xl"),xQo=o(" \u2014 "),iz=a("a"),$Qo=o("XLMRobertaXLForSequenceClassification"),kQo=o(" (XLM-RoBERTa-XL model)"),SQo=l(),zb=a("li"),bue=a("strong"),RQo=o("xlnet"),PQo=o(" \u2014 "),dz=a("a"),BQo=o("XLNetForSequenceClassification"),IQo=o(" (XLNet model)"),NQo=l(),Qb=a("li"),vue=a("strong"),qQo=o("yoso"),jQo=o(" \u2014 "),cz=a("a"),DQo=o("YosoForSequenceClassification"),GQo=o(" (YOSO model)"),OQo=l(),Wb=a("p"),VQo=o("The model is set in evaluation mode by default using "),Fue=a("code"),XQo=o("model.eval()"),zQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tue=a("code"),QQo=o("model.train()"),WQo=l(),F(Hb.$$.fragment),gze=l(),ld=a("h2"),Ub=a("a"),Mue=a("span"),F(by.$$.fragment),HQo=l(),Eue=a("span"),UQo=o("AutoModelForMultipleChoice"),hze=l(),No=a("div"),F(vy.$$.fragment),JQo=l(),id=a("p"),YQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),fz=a("a"),KQo=o("from_pretrained()"),ZQo=o(" class method or the "),mz=a("a"),eWo=o("from_config()"),oWo=o(` class
method.`),rWo=l(),Fy=a("p"),tWo=o("This class cannot be instantiated directly using "),Cue=a("code"),aWo=o("__init__()"),nWo=o(" (throws an error)."),sWo=l(),ht=a("div"),F(Ty.$$.fragment),lWo=l(),wue=a("p"),iWo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),dWo=l(),dd=a("p"),cWo=o(`Note:
Loading a model from its configuration file does `),Aue=a("strong"),fWo=o("not"),mWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gz=a("a"),gWo=o("from_pretrained()"),hWo=o(" to load the model weights."),pWo=l(),F(Jb.$$.fragment),_Wo=l(),to=a("div"),F(My.$$.fragment),uWo=l(),Lue=a("p"),bWo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),vWo=l(),Oa=a("p"),FWo=o("The model class to instantiate is selected based on the "),yue=a("code"),TWo=o("model_type"),MWo=o(` property of the config object (either
passed as an argument or loaded from `),xue=a("code"),EWo=o("pretrained_model_name_or_path"),CWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ue=a("code"),wWo=o("pretrained_model_name_or_path"),AWo=o(":"),LWo=l(),Z=a("ul"),Yb=a("li"),kue=a("strong"),yWo=o("albert"),xWo=o(" \u2014 "),hz=a("a"),$Wo=o("AlbertForMultipleChoice"),kWo=o(" (ALBERT model)"),SWo=l(),Kb=a("li"),Sue=a("strong"),RWo=o("bert"),PWo=o(" \u2014 "),pz=a("a"),BWo=o("BertForMultipleChoice"),IWo=o(" (BERT model)"),NWo=l(),Zb=a("li"),Rue=a("strong"),qWo=o("big_bird"),jWo=o(" \u2014 "),_z=a("a"),DWo=o("BigBirdForMultipleChoice"),GWo=o(" (BigBird model)"),OWo=l(),ev=a("li"),Pue=a("strong"),VWo=o("camembert"),XWo=o(" \u2014 "),uz=a("a"),zWo=o("CamembertForMultipleChoice"),QWo=o(" (CamemBERT model)"),WWo=l(),ov=a("li"),Bue=a("strong"),HWo=o("canine"),UWo=o(" \u2014 "),bz=a("a"),JWo=o("CanineForMultipleChoice"),YWo=o(" (CANINE model)"),KWo=l(),rv=a("li"),Iue=a("strong"),ZWo=o("convbert"),eHo=o(" \u2014 "),vz=a("a"),oHo=o("ConvBertForMultipleChoice"),rHo=o(" (ConvBERT model)"),tHo=l(),tv=a("li"),Nue=a("strong"),aHo=o("data2vec-text"),nHo=o(" \u2014 "),Fz=a("a"),sHo=o("Data2VecTextForMultipleChoice"),lHo=o(" (Data2VecText model)"),iHo=l(),av=a("li"),que=a("strong"),dHo=o("deberta-v2"),cHo=o(" \u2014 "),Tz=a("a"),fHo=o("DebertaV2ForMultipleChoice"),mHo=o(" (DeBERTa-v2 model)"),gHo=l(),nv=a("li"),jue=a("strong"),hHo=o("distilbert"),pHo=o(" \u2014 "),Mz=a("a"),_Ho=o("DistilBertForMultipleChoice"),uHo=o(" (DistilBERT model)"),bHo=l(),sv=a("li"),Due=a("strong"),vHo=o("electra"),FHo=o(" \u2014 "),Ez=a("a"),THo=o("ElectraForMultipleChoice"),MHo=o(" (ELECTRA model)"),EHo=l(),lv=a("li"),Gue=a("strong"),CHo=o("flaubert"),wHo=o(" \u2014 "),Cz=a("a"),AHo=o("FlaubertForMultipleChoice"),LHo=o(" (FlauBERT model)"),yHo=l(),iv=a("li"),Oue=a("strong"),xHo=o("fnet"),$Ho=o(" \u2014 "),wz=a("a"),kHo=o("FNetForMultipleChoice"),SHo=o(" (FNet model)"),RHo=l(),dv=a("li"),Vue=a("strong"),PHo=o("funnel"),BHo=o(" \u2014 "),Az=a("a"),IHo=o("FunnelForMultipleChoice"),NHo=o(" (Funnel Transformer model)"),qHo=l(),cv=a("li"),Xue=a("strong"),jHo=o("ibert"),DHo=o(" \u2014 "),Lz=a("a"),GHo=o("IBertForMultipleChoice"),OHo=o(" (I-BERT model)"),VHo=l(),fv=a("li"),zue=a("strong"),XHo=o("longformer"),zHo=o(" \u2014 "),yz=a("a"),QHo=o("LongformerForMultipleChoice"),WHo=o(" (Longformer model)"),HHo=l(),mv=a("li"),Que=a("strong"),UHo=o("megatron-bert"),JHo=o(" \u2014 "),xz=a("a"),YHo=o("MegatronBertForMultipleChoice"),KHo=o(" (Megatron-BERT model)"),ZHo=l(),gv=a("li"),Wue=a("strong"),eUo=o("mobilebert"),oUo=o(" \u2014 "),$z=a("a"),rUo=o("MobileBertForMultipleChoice"),tUo=o(" (MobileBERT model)"),aUo=l(),hv=a("li"),Hue=a("strong"),nUo=o("mpnet"),sUo=o(" \u2014 "),kz=a("a"),lUo=o("MPNetForMultipleChoice"),iUo=o(" (MPNet model)"),dUo=l(),pv=a("li"),Uue=a("strong"),cUo=o("nezha"),fUo=o(" \u2014 "),Sz=a("a"),mUo=o("NezhaForMultipleChoice"),gUo=o(" (Nezha model)"),hUo=l(),_v=a("li"),Jue=a("strong"),pUo=o("nystromformer"),_Uo=o(" \u2014 "),Rz=a("a"),uUo=o("NystromformerForMultipleChoice"),bUo=o(" (Nystr\xF6mformer model)"),vUo=l(),uv=a("li"),Yue=a("strong"),FUo=o("qdqbert"),TUo=o(" \u2014 "),Pz=a("a"),MUo=o("QDQBertForMultipleChoice"),EUo=o(" (QDQBert model)"),CUo=l(),bv=a("li"),Kue=a("strong"),wUo=o("rembert"),AUo=o(" \u2014 "),Bz=a("a"),LUo=o("RemBertForMultipleChoice"),yUo=o(" (RemBERT model)"),xUo=l(),vv=a("li"),Zue=a("strong"),$Uo=o("roberta"),kUo=o(" \u2014 "),Iz=a("a"),SUo=o("RobertaForMultipleChoice"),RUo=o(" (RoBERTa model)"),PUo=l(),Fv=a("li"),e1e=a("strong"),BUo=o("roformer"),IUo=o(" \u2014 "),Nz=a("a"),NUo=o("RoFormerForMultipleChoice"),qUo=o(" (RoFormer model)"),jUo=l(),Tv=a("li"),o1e=a("strong"),DUo=o("squeezebert"),GUo=o(" \u2014 "),qz=a("a"),OUo=o("SqueezeBertForMultipleChoice"),VUo=o(" (SqueezeBERT model)"),XUo=l(),Mv=a("li"),r1e=a("strong"),zUo=o("xlm"),QUo=o(" \u2014 "),jz=a("a"),WUo=o("XLMForMultipleChoice"),HUo=o(" (XLM model)"),UUo=l(),Ev=a("li"),t1e=a("strong"),JUo=o("xlm-roberta"),YUo=o(" \u2014 "),Dz=a("a"),KUo=o("XLMRobertaForMultipleChoice"),ZUo=o(" (XLM-RoBERTa model)"),eJo=l(),Cv=a("li"),a1e=a("strong"),oJo=o("xlm-roberta-xl"),rJo=o(" \u2014 "),Gz=a("a"),tJo=o("XLMRobertaXLForMultipleChoice"),aJo=o(" (XLM-RoBERTa-XL model)"),nJo=l(),wv=a("li"),n1e=a("strong"),sJo=o("xlnet"),lJo=o(" \u2014 "),Oz=a("a"),iJo=o("XLNetForMultipleChoice"),dJo=o(" (XLNet model)"),cJo=l(),Av=a("li"),s1e=a("strong"),fJo=o("yoso"),mJo=o(" \u2014 "),Vz=a("a"),gJo=o("YosoForMultipleChoice"),hJo=o(" (YOSO model)"),pJo=l(),Lv=a("p"),_Jo=o("The model is set in evaluation mode by default using "),l1e=a("code"),uJo=o("model.eval()"),bJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),i1e=a("code"),vJo=o("model.train()"),FJo=l(),F(yv.$$.fragment),pze=l(),cd=a("h2"),xv=a("a"),d1e=a("span"),F(Ey.$$.fragment),TJo=l(),c1e=a("span"),MJo=o("AutoModelForNextSentencePrediction"),_ze=l(),qo=a("div"),F(Cy.$$.fragment),EJo=l(),fd=a("p"),CJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xz=a("a"),wJo=o("from_pretrained()"),AJo=o(" class method or the "),zz=a("a"),LJo=o("from_config()"),yJo=o(` class
method.`),xJo=l(),wy=a("p"),$Jo=o("This class cannot be instantiated directly using "),f1e=a("code"),kJo=o("__init__()"),SJo=o(" (throws an error)."),RJo=l(),pt=a("div"),F(Ay.$$.fragment),PJo=l(),m1e=a("p"),BJo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),IJo=l(),md=a("p"),NJo=o(`Note:
Loading a model from its configuration file does `),g1e=a("strong"),qJo=o("not"),jJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qz=a("a"),DJo=o("from_pretrained()"),GJo=o(" to load the model weights."),OJo=l(),F($v.$$.fragment),VJo=l(),ao=a("div"),F(Ly.$$.fragment),XJo=l(),h1e=a("p"),zJo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),QJo=l(),Va=a("p"),WJo=o("The model class to instantiate is selected based on the "),p1e=a("code"),HJo=o("model_type"),UJo=o(` property of the config object (either
passed as an argument or loaded from `),_1e=a("code"),JJo=o("pretrained_model_name_or_path"),YJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u1e=a("code"),KJo=o("pretrained_model_name_or_path"),ZJo=o(":"),eYo=l(),jo=a("ul"),kv=a("li"),b1e=a("strong"),oYo=o("bert"),rYo=o(" \u2014 "),Wz=a("a"),tYo=o("BertForNextSentencePrediction"),aYo=o(" (BERT model)"),nYo=l(),Sv=a("li"),v1e=a("strong"),sYo=o("fnet"),lYo=o(" \u2014 "),Hz=a("a"),iYo=o("FNetForNextSentencePrediction"),dYo=o(" (FNet model)"),cYo=l(),Rv=a("li"),F1e=a("strong"),fYo=o("megatron-bert"),mYo=o(" \u2014 "),Uz=a("a"),gYo=o("MegatronBertForNextSentencePrediction"),hYo=o(" (Megatron-BERT model)"),pYo=l(),Pv=a("li"),T1e=a("strong"),_Yo=o("mobilebert"),uYo=o(" \u2014 "),Jz=a("a"),bYo=o("MobileBertForNextSentencePrediction"),vYo=o(" (MobileBERT model)"),FYo=l(),Bv=a("li"),M1e=a("strong"),TYo=o("nezha"),MYo=o(" \u2014 "),Yz=a("a"),EYo=o("NezhaForNextSentencePrediction"),CYo=o(" (Nezha model)"),wYo=l(),Iv=a("li"),E1e=a("strong"),AYo=o("qdqbert"),LYo=o(" \u2014 "),Kz=a("a"),yYo=o("QDQBertForNextSentencePrediction"),xYo=o(" (QDQBert model)"),$Yo=l(),Nv=a("p"),kYo=o("The model is set in evaluation mode by default using "),C1e=a("code"),SYo=o("model.eval()"),RYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w1e=a("code"),PYo=o("model.train()"),BYo=l(),F(qv.$$.fragment),uze=l(),gd=a("h2"),jv=a("a"),A1e=a("span"),F(yy.$$.fragment),IYo=l(),L1e=a("span"),NYo=o("AutoModelForTokenClassification"),bze=l(),Do=a("div"),F(xy.$$.fragment),qYo=l(),hd=a("p"),jYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Zz=a("a"),DYo=o("from_pretrained()"),GYo=o(" class method or the "),eQ=a("a"),OYo=o("from_config()"),VYo=o(` class
method.`),XYo=l(),$y=a("p"),zYo=o("This class cannot be instantiated directly using "),y1e=a("code"),QYo=o("__init__()"),WYo=o(" (throws an error)."),HYo=l(),_t=a("div"),F(ky.$$.fragment),UYo=l(),x1e=a("p"),JYo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),YYo=l(),pd=a("p"),KYo=o(`Note:
Loading a model from its configuration file does `),$1e=a("strong"),ZYo=o("not"),eKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oQ=a("a"),oKo=o("from_pretrained()"),rKo=o(" to load the model weights."),tKo=l(),F(Dv.$$.fragment),aKo=l(),no=a("div"),F(Sy.$$.fragment),nKo=l(),k1e=a("p"),sKo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),lKo=l(),Xa=a("p"),iKo=o("The model class to instantiate is selected based on the "),S1e=a("code"),dKo=o("model_type"),cKo=o(` property of the config object (either
passed as an argument or loaded from `),R1e=a("code"),fKo=o("pretrained_model_name_or_path"),mKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P1e=a("code"),gKo=o("pretrained_model_name_or_path"),hKo=o(":"),pKo=l(),U=a("ul"),Gv=a("li"),B1e=a("strong"),_Ko=o("albert"),uKo=o(" \u2014 "),rQ=a("a"),bKo=o("AlbertForTokenClassification"),vKo=o(" (ALBERT model)"),FKo=l(),Ov=a("li"),I1e=a("strong"),TKo=o("bert"),MKo=o(" \u2014 "),tQ=a("a"),EKo=o("BertForTokenClassification"),CKo=o(" (BERT model)"),wKo=l(),Vv=a("li"),N1e=a("strong"),AKo=o("big_bird"),LKo=o(" \u2014 "),aQ=a("a"),yKo=o("BigBirdForTokenClassification"),xKo=o(" (BigBird model)"),$Ko=l(),Xv=a("li"),q1e=a("strong"),kKo=o("bloom"),SKo=o(" \u2014 "),nQ=a("a"),RKo=o("BloomForTokenClassification"),PKo=o(" (BLOOM model)"),BKo=l(),zv=a("li"),j1e=a("strong"),IKo=o("camembert"),NKo=o(" \u2014 "),sQ=a("a"),qKo=o("CamembertForTokenClassification"),jKo=o(" (CamemBERT model)"),DKo=l(),Qv=a("li"),D1e=a("strong"),GKo=o("canine"),OKo=o(" \u2014 "),lQ=a("a"),VKo=o("CanineForTokenClassification"),XKo=o(" (CANINE model)"),zKo=l(),Wv=a("li"),G1e=a("strong"),QKo=o("convbert"),WKo=o(" \u2014 "),iQ=a("a"),HKo=o("ConvBertForTokenClassification"),UKo=o(" (ConvBERT model)"),JKo=l(),Hv=a("li"),O1e=a("strong"),YKo=o("data2vec-text"),KKo=o(" \u2014 "),dQ=a("a"),ZKo=o("Data2VecTextForTokenClassification"),eZo=o(" (Data2VecText model)"),oZo=l(),Uv=a("li"),V1e=a("strong"),rZo=o("deberta"),tZo=o(" \u2014 "),cQ=a("a"),aZo=o("DebertaForTokenClassification"),nZo=o(" (DeBERTa model)"),sZo=l(),Jv=a("li"),X1e=a("strong"),lZo=o("deberta-v2"),iZo=o(" \u2014 "),fQ=a("a"),dZo=o("DebertaV2ForTokenClassification"),cZo=o(" (DeBERTa-v2 model)"),fZo=l(),Yv=a("li"),z1e=a("strong"),mZo=o("distilbert"),gZo=o(" \u2014 "),mQ=a("a"),hZo=o("DistilBertForTokenClassification"),pZo=o(" (DistilBERT model)"),_Zo=l(),Kv=a("li"),Q1e=a("strong"),uZo=o("electra"),bZo=o(" \u2014 "),gQ=a("a"),vZo=o("ElectraForTokenClassification"),FZo=o(" (ELECTRA model)"),TZo=l(),Zv=a("li"),W1e=a("strong"),MZo=o("flaubert"),EZo=o(" \u2014 "),hQ=a("a"),CZo=o("FlaubertForTokenClassification"),wZo=o(" (FlauBERT model)"),AZo=l(),eF=a("li"),H1e=a("strong"),LZo=o("fnet"),yZo=o(" \u2014 "),pQ=a("a"),xZo=o("FNetForTokenClassification"),$Zo=o(" (FNet model)"),kZo=l(),oF=a("li"),U1e=a("strong"),SZo=o("funnel"),RZo=o(" \u2014 "),_Q=a("a"),PZo=o("FunnelForTokenClassification"),BZo=o(" (Funnel Transformer model)"),IZo=l(),rF=a("li"),J1e=a("strong"),NZo=o("gpt2"),qZo=o(" \u2014 "),uQ=a("a"),jZo=o("GPT2ForTokenClassification"),DZo=o(" (OpenAI GPT-2 model)"),GZo=l(),tF=a("li"),Y1e=a("strong"),OZo=o("ibert"),VZo=o(" \u2014 "),bQ=a("a"),XZo=o("IBertForTokenClassification"),zZo=o(" (I-BERT model)"),QZo=l(),aF=a("li"),K1e=a("strong"),WZo=o("layoutlm"),HZo=o(" \u2014 "),vQ=a("a"),UZo=o("LayoutLMForTokenClassification"),JZo=o(" (LayoutLM model)"),YZo=l(),nF=a("li"),Z1e=a("strong"),KZo=o("layoutlmv2"),ZZo=o(" \u2014 "),FQ=a("a"),eer=o("LayoutLMv2ForTokenClassification"),oer=o(" (LayoutLMv2 model)"),rer=l(),sF=a("li"),e4e=a("strong"),ter=o("layoutlmv3"),aer=o(" \u2014 "),TQ=a("a"),ner=o("LayoutLMv3ForTokenClassification"),ser=o(" (LayoutLMv3 model)"),ler=l(),lF=a("li"),o4e=a("strong"),ier=o("longformer"),der=o(" \u2014 "),MQ=a("a"),cer=o("LongformerForTokenClassification"),fer=o(" (Longformer model)"),mer=l(),iF=a("li"),r4e=a("strong"),ger=o("megatron-bert"),her=o(" \u2014 "),EQ=a("a"),per=o("MegatronBertForTokenClassification"),_er=o(" (Megatron-BERT model)"),uer=l(),dF=a("li"),t4e=a("strong"),ber=o("mobilebert"),ver=o(" \u2014 "),CQ=a("a"),Fer=o("MobileBertForTokenClassification"),Ter=o(" (MobileBERT model)"),Mer=l(),cF=a("li"),a4e=a("strong"),Eer=o("mpnet"),Cer=o(" \u2014 "),wQ=a("a"),wer=o("MPNetForTokenClassification"),Aer=o(" (MPNet model)"),Ler=l(),fF=a("li"),n4e=a("strong"),yer=o("nezha"),xer=o(" \u2014 "),AQ=a("a"),$er=o("NezhaForTokenClassification"),ker=o(" (Nezha model)"),Ser=l(),mF=a("li"),s4e=a("strong"),Rer=o("nystromformer"),Per=o(" \u2014 "),LQ=a("a"),Ber=o("NystromformerForTokenClassification"),Ier=o(" (Nystr\xF6mformer model)"),Ner=l(),gF=a("li"),l4e=a("strong"),qer=o("qdqbert"),jer=o(" \u2014 "),yQ=a("a"),Der=o("QDQBertForTokenClassification"),Ger=o(" (QDQBert model)"),Oer=l(),hF=a("li"),i4e=a("strong"),Ver=o("rembert"),Xer=o(" \u2014 "),xQ=a("a"),zer=o("RemBertForTokenClassification"),Qer=o(" (RemBERT model)"),Wer=l(),pF=a("li"),d4e=a("strong"),Her=o("roberta"),Uer=o(" \u2014 "),$Q=a("a"),Jer=o("RobertaForTokenClassification"),Yer=o(" (RoBERTa model)"),Ker=l(),_F=a("li"),c4e=a("strong"),Zer=o("roformer"),eor=o(" \u2014 "),kQ=a("a"),oor=o("RoFormerForTokenClassification"),ror=o(" (RoFormer model)"),tor=l(),uF=a("li"),f4e=a("strong"),aor=o("squeezebert"),nor=o(" \u2014 "),SQ=a("a"),sor=o("SqueezeBertForTokenClassification"),lor=o(" (SqueezeBERT model)"),ior=l(),bF=a("li"),m4e=a("strong"),dor=o("xlm"),cor=o(" \u2014 "),RQ=a("a"),mor=o("XLMForTokenClassification"),gor=o(" (XLM model)"),hor=l(),vF=a("li"),g4e=a("strong"),por=o("xlm-roberta"),_or=o(" \u2014 "),PQ=a("a"),uor=o("XLMRobertaForTokenClassification"),bor=o(" (XLM-RoBERTa model)"),vor=l(),FF=a("li"),h4e=a("strong"),For=o("xlm-roberta-xl"),Tor=o(" \u2014 "),BQ=a("a"),Mor=o("XLMRobertaXLForTokenClassification"),Eor=o(" (XLM-RoBERTa-XL model)"),Cor=l(),TF=a("li"),p4e=a("strong"),wor=o("xlnet"),Aor=o(" \u2014 "),IQ=a("a"),Lor=o("XLNetForTokenClassification"),yor=o(" (XLNet model)"),xor=l(),MF=a("li"),_4e=a("strong"),$or=o("yoso"),kor=o(" \u2014 "),NQ=a("a"),Sor=o("YosoForTokenClassification"),Ror=o(" (YOSO model)"),Por=l(),EF=a("p"),Bor=o("The model is set in evaluation mode by default using "),u4e=a("code"),Ior=o("model.eval()"),Nor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b4e=a("code"),qor=o("model.train()"),jor=l(),F(CF.$$.fragment),vze=l(),_d=a("h2"),wF=a("a"),v4e=a("span"),F(Ry.$$.fragment),Dor=l(),F4e=a("span"),Gor=o("AutoModelForQuestionAnswering"),Fze=l(),Go=a("div"),F(Py.$$.fragment),Oor=l(),ud=a("p"),Vor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qQ=a("a"),Xor=o("from_pretrained()"),zor=o(" class method or the "),jQ=a("a"),Qor=o("from_config()"),Wor=o(` class
method.`),Hor=l(),By=a("p"),Uor=o("This class cannot be instantiated directly using "),T4e=a("code"),Jor=o("__init__()"),Yor=o(" (throws an error)."),Kor=l(),ut=a("div"),F(Iy.$$.fragment),Zor=l(),M4e=a("p"),err=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),orr=l(),bd=a("p"),rrr=o(`Note:
Loading a model from its configuration file does `),E4e=a("strong"),trr=o("not"),arr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),nrr=o("from_pretrained()"),srr=o(" to load the model weights."),lrr=l(),F(AF.$$.fragment),irr=l(),so=a("div"),F(Ny.$$.fragment),drr=l(),C4e=a("p"),crr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),frr=l(),za=a("p"),mrr=o("The model class to instantiate is selected based on the "),w4e=a("code"),grr=o("model_type"),hrr=o(` property of the config object (either
passed as an argument or loaded from `),A4e=a("code"),prr=o("pretrained_model_name_or_path"),_rr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L4e=a("code"),urr=o("pretrained_model_name_or_path"),brr=o(":"),vrr=l(),V=a("ul"),LF=a("li"),y4e=a("strong"),Frr=o("albert"),Trr=o(" \u2014 "),GQ=a("a"),Mrr=o("AlbertForQuestionAnswering"),Err=o(" (ALBERT model)"),Crr=l(),yF=a("li"),x4e=a("strong"),wrr=o("bart"),Arr=o(" \u2014 "),OQ=a("a"),Lrr=o("BartForQuestionAnswering"),yrr=o(" (BART model)"),xrr=l(),xF=a("li"),$4e=a("strong"),$rr=o("bert"),krr=o(" \u2014 "),VQ=a("a"),Srr=o("BertForQuestionAnswering"),Rrr=o(" (BERT model)"),Prr=l(),$F=a("li"),k4e=a("strong"),Brr=o("big_bird"),Irr=o(" \u2014 "),XQ=a("a"),Nrr=o("BigBirdForQuestionAnswering"),qrr=o(" (BigBird model)"),jrr=l(),kF=a("li"),S4e=a("strong"),Drr=o("bigbird_pegasus"),Grr=o(" \u2014 "),zQ=a("a"),Orr=o("BigBirdPegasusForQuestionAnswering"),Vrr=o(" (BigBird-Pegasus model)"),Xrr=l(),SF=a("li"),R4e=a("strong"),zrr=o("camembert"),Qrr=o(" \u2014 "),QQ=a("a"),Wrr=o("CamembertForQuestionAnswering"),Hrr=o(" (CamemBERT model)"),Urr=l(),RF=a("li"),P4e=a("strong"),Jrr=o("canine"),Yrr=o(" \u2014 "),WQ=a("a"),Krr=o("CanineForQuestionAnswering"),Zrr=o(" (CANINE model)"),etr=l(),PF=a("li"),B4e=a("strong"),otr=o("convbert"),rtr=o(" \u2014 "),HQ=a("a"),ttr=o("ConvBertForQuestionAnswering"),atr=o(" (ConvBERT model)"),ntr=l(),BF=a("li"),I4e=a("strong"),str=o("data2vec-text"),ltr=o(" \u2014 "),UQ=a("a"),itr=o("Data2VecTextForQuestionAnswering"),dtr=o(" (Data2VecText model)"),ctr=l(),IF=a("li"),N4e=a("strong"),ftr=o("deberta"),mtr=o(" \u2014 "),JQ=a("a"),gtr=o("DebertaForQuestionAnswering"),htr=o(" (DeBERTa model)"),ptr=l(),NF=a("li"),q4e=a("strong"),_tr=o("deberta-v2"),utr=o(" \u2014 "),YQ=a("a"),btr=o("DebertaV2ForQuestionAnswering"),vtr=o(" (DeBERTa-v2 model)"),Ftr=l(),qF=a("li"),j4e=a("strong"),Ttr=o("distilbert"),Mtr=o(" \u2014 "),KQ=a("a"),Etr=o("DistilBertForQuestionAnswering"),Ctr=o(" (DistilBERT model)"),wtr=l(),jF=a("li"),D4e=a("strong"),Atr=o("electra"),Ltr=o(" \u2014 "),ZQ=a("a"),ytr=o("ElectraForQuestionAnswering"),xtr=o(" (ELECTRA model)"),$tr=l(),DF=a("li"),G4e=a("strong"),ktr=o("flaubert"),Str=o(" \u2014 "),eW=a("a"),Rtr=o("FlaubertForQuestionAnsweringSimple"),Ptr=o(" (FlauBERT model)"),Btr=l(),GF=a("li"),O4e=a("strong"),Itr=o("fnet"),Ntr=o(" \u2014 "),oW=a("a"),qtr=o("FNetForQuestionAnswering"),jtr=o(" (FNet model)"),Dtr=l(),OF=a("li"),V4e=a("strong"),Gtr=o("funnel"),Otr=o(" \u2014 "),rW=a("a"),Vtr=o("FunnelForQuestionAnswering"),Xtr=o(" (Funnel Transformer model)"),ztr=l(),VF=a("li"),X4e=a("strong"),Qtr=o("gptj"),Wtr=o(" \u2014 "),tW=a("a"),Htr=o("GPTJForQuestionAnswering"),Utr=o(" (GPT-J model)"),Jtr=l(),XF=a("li"),z4e=a("strong"),Ytr=o("ibert"),Ktr=o(" \u2014 "),aW=a("a"),Ztr=o("IBertForQuestionAnswering"),ear=o(" (I-BERT model)"),oar=l(),zF=a("li"),Q4e=a("strong"),rar=o("layoutlmv2"),tar=o(" \u2014 "),nW=a("a"),aar=o("LayoutLMv2ForQuestionAnswering"),nar=o(" (LayoutLMv2 model)"),sar=l(),QF=a("li"),W4e=a("strong"),lar=o("layoutlmv3"),iar=o(" \u2014 "),sW=a("a"),dar=o("LayoutLMv3ForQuestionAnswering"),car=o(" (LayoutLMv3 model)"),far=l(),WF=a("li"),H4e=a("strong"),mar=o("led"),gar=o(" \u2014 "),lW=a("a"),har=o("LEDForQuestionAnswering"),par=o(" (LED model)"),_ar=l(),HF=a("li"),U4e=a("strong"),uar=o("longformer"),bar=o(" \u2014 "),iW=a("a"),Far=o("LongformerForQuestionAnswering"),Tar=o(" (Longformer model)"),Mar=l(),UF=a("li"),J4e=a("strong"),Ear=o("lxmert"),Car=o(" \u2014 "),dW=a("a"),war=o("LxmertForQuestionAnswering"),Aar=o(" (LXMERT model)"),Lar=l(),JF=a("li"),Y4e=a("strong"),yar=o("mbart"),xar=o(" \u2014 "),cW=a("a"),$ar=o("MBartForQuestionAnswering"),kar=o(" (mBART model)"),Sar=l(),YF=a("li"),K4e=a("strong"),Rar=o("megatron-bert"),Par=o(" \u2014 "),fW=a("a"),Bar=o("MegatronBertForQuestionAnswering"),Iar=o(" (Megatron-BERT model)"),Nar=l(),KF=a("li"),Z4e=a("strong"),qar=o("mobilebert"),jar=o(" \u2014 "),mW=a("a"),Dar=o("MobileBertForQuestionAnswering"),Gar=o(" (MobileBERT model)"),Oar=l(),ZF=a("li"),e2e=a("strong"),Var=o("mpnet"),Xar=o(" \u2014 "),gW=a("a"),zar=o("MPNetForQuestionAnswering"),Qar=o(" (MPNet model)"),War=l(),e6=a("li"),o2e=a("strong"),Har=o("mvp"),Uar=o(" \u2014 "),hW=a("a"),Jar=o("MvpForQuestionAnswering"),Yar=o(" (MVP model)"),Kar=l(),o6=a("li"),r2e=a("strong"),Zar=o("nezha"),enr=o(" \u2014 "),pW=a("a"),onr=o("NezhaForQuestionAnswering"),rnr=o(" (Nezha model)"),tnr=l(),r6=a("li"),t2e=a("strong"),anr=o("nystromformer"),nnr=o(" \u2014 "),_W=a("a"),snr=o("NystromformerForQuestionAnswering"),lnr=o(" (Nystr\xF6mformer model)"),inr=l(),t6=a("li"),a2e=a("strong"),dnr=o("qdqbert"),cnr=o(" \u2014 "),uW=a("a"),fnr=o("QDQBertForQuestionAnswering"),mnr=o(" (QDQBert model)"),gnr=l(),a6=a("li"),n2e=a("strong"),hnr=o("reformer"),pnr=o(" \u2014 "),bW=a("a"),_nr=o("ReformerForQuestionAnswering"),unr=o(" (Reformer model)"),bnr=l(),n6=a("li"),s2e=a("strong"),vnr=o("rembert"),Fnr=o(" \u2014 "),vW=a("a"),Tnr=o("RemBertForQuestionAnswering"),Mnr=o(" (RemBERT model)"),Enr=l(),s6=a("li"),l2e=a("strong"),Cnr=o("roberta"),wnr=o(" \u2014 "),FW=a("a"),Anr=o("RobertaForQuestionAnswering"),Lnr=o(" (RoBERTa model)"),ynr=l(),l6=a("li"),i2e=a("strong"),xnr=o("roformer"),$nr=o(" \u2014 "),TW=a("a"),knr=o("RoFormerForQuestionAnswering"),Snr=o(" (RoFormer model)"),Rnr=l(),i6=a("li"),d2e=a("strong"),Pnr=o("splinter"),Bnr=o(" \u2014 "),MW=a("a"),Inr=o("SplinterForQuestionAnswering"),Nnr=o(" (Splinter model)"),qnr=l(),d6=a("li"),c2e=a("strong"),jnr=o("squeezebert"),Dnr=o(" \u2014 "),EW=a("a"),Gnr=o("SqueezeBertForQuestionAnswering"),Onr=o(" (SqueezeBERT model)"),Vnr=l(),c6=a("li"),f2e=a("strong"),Xnr=o("xlm"),znr=o(" \u2014 "),CW=a("a"),Qnr=o("XLMForQuestionAnsweringSimple"),Wnr=o(" (XLM model)"),Hnr=l(),f6=a("li"),m2e=a("strong"),Unr=o("xlm-roberta"),Jnr=o(" \u2014 "),wW=a("a"),Ynr=o("XLMRobertaForQuestionAnswering"),Knr=o(" (XLM-RoBERTa model)"),Znr=l(),m6=a("li"),g2e=a("strong"),esr=o("xlm-roberta-xl"),osr=o(" \u2014 "),AW=a("a"),rsr=o("XLMRobertaXLForQuestionAnswering"),tsr=o(" (XLM-RoBERTa-XL model)"),asr=l(),g6=a("li"),h2e=a("strong"),nsr=o("xlnet"),ssr=o(" \u2014 "),LW=a("a"),lsr=o("XLNetForQuestionAnsweringSimple"),isr=o(" (XLNet model)"),dsr=l(),h6=a("li"),p2e=a("strong"),csr=o("yoso"),fsr=o(" \u2014 "),yW=a("a"),msr=o("YosoForQuestionAnswering"),gsr=o(" (YOSO model)"),hsr=l(),p6=a("p"),psr=o("The model is set in evaluation mode by default using "),_2e=a("code"),_sr=o("model.eval()"),usr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=a("code"),bsr=o("model.train()"),vsr=l(),F(_6.$$.fragment),Tze=l(),vd=a("h2"),u6=a("a"),b2e=a("span"),F(qy.$$.fragment),Fsr=l(),v2e=a("span"),Tsr=o("AutoModelForTableQuestionAnswering"),Mze=l(),Oo=a("div"),F(jy.$$.fragment),Msr=l(),Fd=a("p"),Esr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),xW=a("a"),Csr=o("from_pretrained()"),wsr=o(" class method or the "),$W=a("a"),Asr=o("from_config()"),Lsr=o(` class
method.`),ysr=l(),Dy=a("p"),xsr=o("This class cannot be instantiated directly using "),F2e=a("code"),$sr=o("__init__()"),ksr=o(" (throws an error)."),Ssr=l(),bt=a("div"),F(Gy.$$.fragment),Rsr=l(),T2e=a("p"),Psr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Bsr=l(),Td=a("p"),Isr=o(`Note:
Loading a model from its configuration file does `),M2e=a("strong"),Nsr=o("not"),qsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kW=a("a"),jsr=o("from_pretrained()"),Dsr=o(" to load the model weights."),Gsr=l(),F(b6.$$.fragment),Osr=l(),lo=a("div"),F(Oy.$$.fragment),Vsr=l(),E2e=a("p"),Xsr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),zsr=l(),Qa=a("p"),Qsr=o("The model class to instantiate is selected based on the "),C2e=a("code"),Wsr=o("model_type"),Hsr=o(` property of the config object (either
passed as an argument or loaded from `),w2e=a("code"),Usr=o("pretrained_model_name_or_path"),Jsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A2e=a("code"),Ysr=o("pretrained_model_name_or_path"),Ksr=o(":"),Zsr=l(),L2e=a("ul"),v6=a("li"),y2e=a("strong"),elr=o("tapas"),olr=o(" \u2014 "),SW=a("a"),rlr=o("TapasForQuestionAnswering"),tlr=o(" (TAPAS model)"),alr=l(),F6=a("p"),nlr=o("The model is set in evaluation mode by default using "),x2e=a("code"),slr=o("model.eval()"),llr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$2e=a("code"),ilr=o("model.train()"),dlr=l(),F(T6.$$.fragment),Eze=l(),Md=a("h2"),M6=a("a"),k2e=a("span"),F(Vy.$$.fragment),clr=l(),S2e=a("span"),flr=o("AutoModelForImageClassification"),Cze=l(),Vo=a("div"),F(Xy.$$.fragment),mlr=l(),Ed=a("p"),glr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),RW=a("a"),hlr=o("from_pretrained()"),plr=o(" class method or the "),PW=a("a"),_lr=o("from_config()"),ulr=o(` class
method.`),blr=l(),zy=a("p"),vlr=o("This class cannot be instantiated directly using "),R2e=a("code"),Flr=o("__init__()"),Tlr=o(" (throws an error)."),Mlr=l(),vt=a("div"),F(Qy.$$.fragment),Elr=l(),P2e=a("p"),Clr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),wlr=l(),Cd=a("p"),Alr=o(`Note:
Loading a model from its configuration file does `),B2e=a("strong"),Llr=o("not"),ylr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BW=a("a"),xlr=o("from_pretrained()"),$lr=o(" to load the model weights."),klr=l(),F(E6.$$.fragment),Slr=l(),io=a("div"),F(Wy.$$.fragment),Rlr=l(),I2e=a("p"),Plr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Blr=l(),Wa=a("p"),Ilr=o("The model class to instantiate is selected based on the "),N2e=a("code"),Nlr=o("model_type"),qlr=o(` property of the config object (either
passed as an argument or loaded from `),q2e=a("code"),jlr=o("pretrained_model_name_or_path"),Dlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j2e=a("code"),Glr=o("pretrained_model_name_or_path"),Olr=o(":"),Vlr=l(),ue=a("ul"),C6=a("li"),D2e=a("strong"),Xlr=o("beit"),zlr=o(" \u2014 "),IW=a("a"),Qlr=o("BeitForImageClassification"),Wlr=o(" (BEiT model)"),Hlr=l(),w6=a("li"),G2e=a("strong"),Ulr=o("convnext"),Jlr=o(" \u2014 "),NW=a("a"),Ylr=o("ConvNextForImageClassification"),Klr=o(" (ConvNeXT model)"),Zlr=l(),A6=a("li"),O2e=a("strong"),eir=o("cvt"),oir=o(" \u2014 "),qW=a("a"),rir=o("CvtForImageClassification"),tir=o(" (CvT model)"),air=l(),L6=a("li"),V2e=a("strong"),nir=o("data2vec-vision"),sir=o(" \u2014 "),jW=a("a"),lir=o("Data2VecVisionForImageClassification"),iir=o(" (Data2VecVision model)"),dir=l(),Js=a("li"),X2e=a("strong"),cir=o("deit"),fir=o(" \u2014 "),DW=a("a"),mir=o("DeiTForImageClassification"),gir=o(" or "),GW=a("a"),hir=o("DeiTForImageClassificationWithTeacher"),pir=o(" (DeiT model)"),_ir=l(),y6=a("li"),z2e=a("strong"),uir=o("imagegpt"),bir=o(" \u2014 "),OW=a("a"),vir=o("ImageGPTForImageClassification"),Fir=o(" (ImageGPT model)"),Tir=l(),Ys=a("li"),Q2e=a("strong"),Mir=o("levit"),Eir=o(" \u2014 "),VW=a("a"),Cir=o("LevitForImageClassification"),wir=o(" or "),XW=a("a"),Air=o("LevitForImageClassificationWithTeacher"),Lir=o(" (LeViT model)"),yir=l(),x6=a("li"),W2e=a("strong"),xir=o("mobilevit"),$ir=o(" \u2014 "),zW=a("a"),kir=o("MobileViTForImageClassification"),Sir=o(" (MobileViT model)"),Rir=l(),Ft=a("li"),H2e=a("strong"),Pir=o("perceiver"),Bir=o(" \u2014 "),QW=a("a"),Iir=o("PerceiverForImageClassificationLearned"),Nir=o(" or "),WW=a("a"),qir=o("PerceiverForImageClassificationFourier"),jir=o(" or "),HW=a("a"),Dir=o("PerceiverForImageClassificationConvProcessing"),Gir=o(" (Perceiver model)"),Oir=l(),$6=a("li"),U2e=a("strong"),Vir=o("poolformer"),Xir=o(" \u2014 "),UW=a("a"),zir=o("PoolFormerForImageClassification"),Qir=o(" (PoolFormer model)"),Wir=l(),k6=a("li"),J2e=a("strong"),Hir=o("regnet"),Uir=o(" \u2014 "),JW=a("a"),Jir=o("RegNetForImageClassification"),Yir=o(" (RegNet model)"),Kir=l(),S6=a("li"),Y2e=a("strong"),Zir=o("resnet"),edr=o(" \u2014 "),YW=a("a"),odr=o("ResNetForImageClassification"),rdr=o(" (ResNet model)"),tdr=l(),R6=a("li"),K2e=a("strong"),adr=o("segformer"),ndr=o(" \u2014 "),KW=a("a"),sdr=o("SegformerForImageClassification"),ldr=o(" (SegFormer model)"),idr=l(),P6=a("li"),Z2e=a("strong"),ddr=o("swin"),cdr=o(" \u2014 "),ZW=a("a"),fdr=o("SwinForImageClassification"),mdr=o(" (Swin Transformer model)"),gdr=l(),B6=a("li"),ebe=a("strong"),hdr=o("swinv2"),pdr=o(" \u2014 "),eH=a("a"),_dr=o("Swinv2ForImageClassification"),udr=o(" (Swin Transformer V2 model)"),bdr=l(),I6=a("li"),obe=a("strong"),vdr=o("van"),Fdr=o(" \u2014 "),oH=a("a"),Tdr=o("VanForImageClassification"),Mdr=o(" (VAN model)"),Edr=l(),N6=a("li"),rbe=a("strong"),Cdr=o("vit"),wdr=o(" \u2014 "),rH=a("a"),Adr=o("ViTForImageClassification"),Ldr=o(" (ViT model)"),ydr=l(),q6=a("p"),xdr=o("The model is set in evaluation mode by default using "),tbe=a("code"),$dr=o("model.eval()"),kdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),abe=a("code"),Sdr=o("model.train()"),Rdr=l(),F(j6.$$.fragment),wze=l(),wd=a("h2"),D6=a("a"),nbe=a("span"),F(Hy.$$.fragment),Pdr=l(),sbe=a("span"),Bdr=o("AutoModelForVision2Seq"),Aze=l(),Xo=a("div"),F(Uy.$$.fragment),Idr=l(),Ad=a("p"),Ndr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),tH=a("a"),qdr=o("from_pretrained()"),jdr=o(" class method or the "),aH=a("a"),Ddr=o("from_config()"),Gdr=o(` class
method.`),Odr=l(),Jy=a("p"),Vdr=o("This class cannot be instantiated directly using "),lbe=a("code"),Xdr=o("__init__()"),zdr=o(" (throws an error)."),Qdr=l(),Tt=a("div"),F(Yy.$$.fragment),Wdr=l(),ibe=a("p"),Hdr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Udr=l(),Ld=a("p"),Jdr=o(`Note:
Loading a model from its configuration file does `),dbe=a("strong"),Ydr=o("not"),Kdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nH=a("a"),Zdr=o("from_pretrained()"),ecr=o(" to load the model weights."),ocr=l(),F(G6.$$.fragment),rcr=l(),co=a("div"),F(Ky.$$.fragment),tcr=l(),cbe=a("p"),acr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ncr=l(),Ha=a("p"),scr=o("The model class to instantiate is selected based on the "),fbe=a("code"),lcr=o("model_type"),icr=o(` property of the config object (either
passed as an argument or loaded from `),mbe=a("code"),dcr=o("pretrained_model_name_or_path"),ccr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gbe=a("code"),fcr=o("pretrained_model_name_or_path"),mcr=o(":"),gcr=l(),hbe=a("ul"),O6=a("li"),pbe=a("strong"),hcr=o("vision-encoder-decoder"),pcr=o(" \u2014 "),sH=a("a"),_cr=o("VisionEncoderDecoderModel"),ucr=o(" (Vision Encoder decoder model)"),bcr=l(),V6=a("p"),vcr=o("The model is set in evaluation mode by default using "),_be=a("code"),Fcr=o("model.eval()"),Tcr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ube=a("code"),Mcr=o("model.train()"),Ecr=l(),F(X6.$$.fragment),Lze=l(),yd=a("h2"),z6=a("a"),bbe=a("span"),F(Zy.$$.fragment),Ccr=l(),vbe=a("span"),wcr=o("AutoModelForVisualQuestionAnswering"),yze=l(),zo=a("div"),F(e8.$$.fragment),Acr=l(),xd=a("p"),Lcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),lH=a("a"),ycr=o("from_pretrained()"),xcr=o(" class method or the "),iH=a("a"),$cr=o("from_config()"),kcr=o(` class
method.`),Scr=l(),o8=a("p"),Rcr=o("This class cannot be instantiated directly using "),Fbe=a("code"),Pcr=o("__init__()"),Bcr=o(" (throws an error)."),Icr=l(),Mt=a("div"),F(r8.$$.fragment),Ncr=l(),Tbe=a("p"),qcr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),jcr=l(),$d=a("p"),Dcr=o(`Note:
Loading a model from its configuration file does `),Mbe=a("strong"),Gcr=o("not"),Ocr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dH=a("a"),Vcr=o("from_pretrained()"),Xcr=o(" to load the model weights."),zcr=l(),F(Q6.$$.fragment),Qcr=l(),fo=a("div"),F(t8.$$.fragment),Wcr=l(),Ebe=a("p"),Hcr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Ucr=l(),Ua=a("p"),Jcr=o("The model class to instantiate is selected based on the "),Cbe=a("code"),Ycr=o("model_type"),Kcr=o(` property of the config object (either
passed as an argument or loaded from `),wbe=a("code"),Zcr=o("pretrained_model_name_or_path"),efr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Abe=a("code"),ofr=o("pretrained_model_name_or_path"),rfr=o(":"),tfr=l(),Lbe=a("ul"),W6=a("li"),ybe=a("strong"),afr=o("vilt"),nfr=o(" \u2014 "),cH=a("a"),sfr=o("ViltForQuestionAnswering"),lfr=o(" (ViLT model)"),ifr=l(),H6=a("p"),dfr=o("The model is set in evaluation mode by default using "),xbe=a("code"),cfr=o("model.eval()"),ffr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$be=a("code"),mfr=o("model.train()"),gfr=l(),F(U6.$$.fragment),xze=l(),kd=a("h2"),J6=a("a"),kbe=a("span"),F(a8.$$.fragment),hfr=l(),Sbe=a("span"),pfr=o("AutoModelForAudioClassification"),$ze=l(),Qo=a("div"),F(n8.$$.fragment),_fr=l(),Sd=a("p"),ufr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),fH=a("a"),bfr=o("from_pretrained()"),vfr=o(" class method or the "),mH=a("a"),Ffr=o("from_config()"),Tfr=o(` class
method.`),Mfr=l(),s8=a("p"),Efr=o("This class cannot be instantiated directly using "),Rbe=a("code"),Cfr=o("__init__()"),wfr=o(" (throws an error)."),Afr=l(),Et=a("div"),F(l8.$$.fragment),Lfr=l(),Pbe=a("p"),yfr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),xfr=l(),Rd=a("p"),$fr=o(`Note:
Loading a model from its configuration file does `),Bbe=a("strong"),kfr=o("not"),Sfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=a("a"),Rfr=o("from_pretrained()"),Pfr=o(" to load the model weights."),Bfr=l(),F(Y6.$$.fragment),Ifr=l(),mo=a("div"),F(i8.$$.fragment),Nfr=l(),Ibe=a("p"),qfr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),jfr=l(),Ja=a("p"),Dfr=o("The model class to instantiate is selected based on the "),Nbe=a("code"),Gfr=o("model_type"),Ofr=o(` property of the config object (either
passed as an argument or loaded from `),qbe=a("code"),Vfr=o("pretrained_model_name_or_path"),Xfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jbe=a("code"),zfr=o("pretrained_model_name_or_path"),Qfr=o(":"),Wfr=l(),Pe=a("ul"),K6=a("li"),Dbe=a("strong"),Hfr=o("data2vec-audio"),Ufr=o(" \u2014 "),hH=a("a"),Jfr=o("Data2VecAudioForSequenceClassification"),Yfr=o(" (Data2VecAudio model)"),Kfr=l(),Z6=a("li"),Gbe=a("strong"),Zfr=o("hubert"),emr=o(" \u2014 "),pH=a("a"),omr=o("HubertForSequenceClassification"),rmr=o(" (Hubert model)"),tmr=l(),eT=a("li"),Obe=a("strong"),amr=o("sew"),nmr=o(" \u2014 "),_H=a("a"),smr=o("SEWForSequenceClassification"),lmr=o(" (SEW model)"),imr=l(),oT=a("li"),Vbe=a("strong"),dmr=o("sew-d"),cmr=o(" \u2014 "),uH=a("a"),fmr=o("SEWDForSequenceClassification"),mmr=o(" (SEW-D model)"),gmr=l(),rT=a("li"),Xbe=a("strong"),hmr=o("unispeech"),pmr=o(" \u2014 "),bH=a("a"),_mr=o("UniSpeechForSequenceClassification"),umr=o(" (UniSpeech model)"),bmr=l(),tT=a("li"),zbe=a("strong"),vmr=o("unispeech-sat"),Fmr=o(" \u2014 "),vH=a("a"),Tmr=o("UniSpeechSatForSequenceClassification"),Mmr=o(" (UniSpeechSat model)"),Emr=l(),aT=a("li"),Qbe=a("strong"),Cmr=o("wav2vec2"),wmr=o(" \u2014 "),FH=a("a"),Amr=o("Wav2Vec2ForSequenceClassification"),Lmr=o(" (Wav2Vec2 model)"),ymr=l(),nT=a("li"),Wbe=a("strong"),xmr=o("wav2vec2-conformer"),$mr=o(" \u2014 "),TH=a("a"),kmr=o("Wav2Vec2ConformerForSequenceClassification"),Smr=o(" (Wav2Vec2-Conformer model)"),Rmr=l(),sT=a("li"),Hbe=a("strong"),Pmr=o("wavlm"),Bmr=o(" \u2014 "),MH=a("a"),Imr=o("WavLMForSequenceClassification"),Nmr=o(" (WavLM model)"),qmr=l(),lT=a("p"),jmr=o("The model is set in evaluation mode by default using "),Ube=a("code"),Dmr=o("model.eval()"),Gmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=a("code"),Omr=o("model.train()"),Vmr=l(),F(iT.$$.fragment),kze=l(),Pd=a("h2"),dT=a("a"),Ybe=a("span"),F(d8.$$.fragment),Xmr=l(),Kbe=a("span"),zmr=o("AutoModelForAudioFrameClassification"),Sze=l(),Wo=a("div"),F(c8.$$.fragment),Qmr=l(),Bd=a("p"),Wmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),EH=a("a"),Hmr=o("from_pretrained()"),Umr=o(" class method or the "),CH=a("a"),Jmr=o("from_config()"),Ymr=o(` class
method.`),Kmr=l(),f8=a("p"),Zmr=o("This class cannot be instantiated directly using "),Zbe=a("code"),egr=o("__init__()"),ogr=o(" (throws an error)."),rgr=l(),Ct=a("div"),F(m8.$$.fragment),tgr=l(),eve=a("p"),agr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),ngr=l(),Id=a("p"),sgr=o(`Note:
Loading a model from its configuration file does `),ove=a("strong"),lgr=o("not"),igr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wH=a("a"),dgr=o("from_pretrained()"),cgr=o(" to load the model weights."),fgr=l(),F(cT.$$.fragment),mgr=l(),go=a("div"),F(g8.$$.fragment),ggr=l(),rve=a("p"),hgr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),pgr=l(),Ya=a("p"),_gr=o("The model class to instantiate is selected based on the "),tve=a("code"),ugr=o("model_type"),bgr=o(` property of the config object (either
passed as an argument or loaded from `),ave=a("code"),vgr=o("pretrained_model_name_or_path"),Fgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=a("code"),Tgr=o("pretrained_model_name_or_path"),Mgr=o(":"),Egr=l(),rt=a("ul"),fT=a("li"),sve=a("strong"),Cgr=o("data2vec-audio"),wgr=o(" \u2014 "),AH=a("a"),Agr=o("Data2VecAudioForAudioFrameClassification"),Lgr=o(" (Data2VecAudio model)"),ygr=l(),mT=a("li"),lve=a("strong"),xgr=o("unispeech-sat"),$gr=o(" \u2014 "),LH=a("a"),kgr=o("UniSpeechSatForAudioFrameClassification"),Sgr=o(" (UniSpeechSat model)"),Rgr=l(),gT=a("li"),ive=a("strong"),Pgr=o("wav2vec2"),Bgr=o(" \u2014 "),yH=a("a"),Igr=o("Wav2Vec2ForAudioFrameClassification"),Ngr=o(" (Wav2Vec2 model)"),qgr=l(),hT=a("li"),dve=a("strong"),jgr=o("wav2vec2-conformer"),Dgr=o(" \u2014 "),xH=a("a"),Ggr=o("Wav2Vec2ConformerForAudioFrameClassification"),Ogr=o(" (Wav2Vec2-Conformer model)"),Vgr=l(),pT=a("li"),cve=a("strong"),Xgr=o("wavlm"),zgr=o(" \u2014 "),$H=a("a"),Qgr=o("WavLMForAudioFrameClassification"),Wgr=o(" (WavLM model)"),Hgr=l(),_T=a("p"),Ugr=o("The model is set in evaluation mode by default using "),fve=a("code"),Jgr=o("model.eval()"),Ygr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mve=a("code"),Kgr=o("model.train()"),Zgr=l(),F(uT.$$.fragment),Rze=l(),Nd=a("h2"),bT=a("a"),gve=a("span"),F(h8.$$.fragment),ehr=l(),hve=a("span"),ohr=o("AutoModelForCTC"),Pze=l(),Ho=a("div"),F(p8.$$.fragment),rhr=l(),qd=a("p"),thr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),kH=a("a"),ahr=o("from_pretrained()"),nhr=o(" class method or the "),SH=a("a"),shr=o("from_config()"),lhr=o(` class
method.`),ihr=l(),_8=a("p"),dhr=o("This class cannot be instantiated directly using "),pve=a("code"),chr=o("__init__()"),fhr=o(" (throws an error)."),mhr=l(),wt=a("div"),F(u8.$$.fragment),ghr=l(),_ve=a("p"),hhr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),phr=l(),jd=a("p"),_hr=o(`Note:
Loading a model from its configuration file does `),uve=a("strong"),uhr=o("not"),bhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=a("a"),vhr=o("from_pretrained()"),Fhr=o(" to load the model weights."),Thr=l(),F(vT.$$.fragment),Mhr=l(),ho=a("div"),F(b8.$$.fragment),Ehr=l(),bve=a("p"),Chr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),whr=l(),Ka=a("p"),Ahr=o("The model class to instantiate is selected based on the "),vve=a("code"),Lhr=o("model_type"),yhr=o(` property of the config object (either
passed as an argument or loaded from `),Fve=a("code"),xhr=o("pretrained_model_name_or_path"),$hr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tve=a("code"),khr=o("pretrained_model_name_or_path"),Shr=o(":"),Rhr=l(),Le=a("ul"),FT=a("li"),Mve=a("strong"),Phr=o("data2vec-audio"),Bhr=o(" \u2014 "),PH=a("a"),Ihr=o("Data2VecAudioForCTC"),Nhr=o(" (Data2VecAudio model)"),qhr=l(),TT=a("li"),Eve=a("strong"),jhr=o("hubert"),Dhr=o(" \u2014 "),BH=a("a"),Ghr=o("HubertForCTC"),Ohr=o(" (Hubert model)"),Vhr=l(),MT=a("li"),Cve=a("strong"),Xhr=o("mctct"),zhr=o(" \u2014 "),IH=a("a"),Qhr=o("MCTCTForCTC"),Whr=o(" (M-CTC-T model)"),Hhr=l(),ET=a("li"),wve=a("strong"),Uhr=o("sew"),Jhr=o(" \u2014 "),NH=a("a"),Yhr=o("SEWForCTC"),Khr=o(" (SEW model)"),Zhr=l(),CT=a("li"),Ave=a("strong"),epr=o("sew-d"),opr=o(" \u2014 "),qH=a("a"),rpr=o("SEWDForCTC"),tpr=o(" (SEW-D model)"),apr=l(),wT=a("li"),Lve=a("strong"),npr=o("unispeech"),spr=o(" \u2014 "),jH=a("a"),lpr=o("UniSpeechForCTC"),ipr=o(" (UniSpeech model)"),dpr=l(),AT=a("li"),yve=a("strong"),cpr=o("unispeech-sat"),fpr=o(" \u2014 "),DH=a("a"),mpr=o("UniSpeechSatForCTC"),gpr=o(" (UniSpeechSat model)"),hpr=l(),LT=a("li"),xve=a("strong"),ppr=o("wav2vec2"),_pr=o(" \u2014 "),GH=a("a"),upr=o("Wav2Vec2ForCTC"),bpr=o(" (Wav2Vec2 model)"),vpr=l(),yT=a("li"),$ve=a("strong"),Fpr=o("wav2vec2-conformer"),Tpr=o(" \u2014 "),OH=a("a"),Mpr=o("Wav2Vec2ConformerForCTC"),Epr=o(" (Wav2Vec2-Conformer model)"),Cpr=l(),xT=a("li"),kve=a("strong"),wpr=o("wavlm"),Apr=o(" \u2014 "),VH=a("a"),Lpr=o("WavLMForCTC"),ypr=o(" (WavLM model)"),xpr=l(),$T=a("p"),$pr=o("The model is set in evaluation mode by default using "),Sve=a("code"),kpr=o("model.eval()"),Spr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rve=a("code"),Rpr=o("model.train()"),Ppr=l(),F(kT.$$.fragment),Bze=l(),Dd=a("h2"),ST=a("a"),Pve=a("span"),F(v8.$$.fragment),Bpr=l(),Bve=a("span"),Ipr=o("AutoModelForSpeechSeq2Seq"),Ize=l(),Uo=a("div"),F(F8.$$.fragment),Npr=l(),Gd=a("p"),qpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),XH=a("a"),jpr=o("from_pretrained()"),Dpr=o(" class method or the "),zH=a("a"),Gpr=o("from_config()"),Opr=o(` class
method.`),Vpr=l(),T8=a("p"),Xpr=o("This class cannot be instantiated directly using "),Ive=a("code"),zpr=o("__init__()"),Qpr=o(" (throws an error)."),Wpr=l(),At=a("div"),F(M8.$$.fragment),Hpr=l(),Nve=a("p"),Upr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Jpr=l(),Od=a("p"),Ypr=o(`Note:
Loading a model from its configuration file does `),qve=a("strong"),Kpr=o("not"),Zpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QH=a("a"),e_r=o("from_pretrained()"),o_r=o(" to load the model weights."),r_r=l(),F(RT.$$.fragment),t_r=l(),po=a("div"),F(E8.$$.fragment),a_r=l(),jve=a("p"),n_r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),s_r=l(),Za=a("p"),l_r=o("The model class to instantiate is selected based on the "),Dve=a("code"),i_r=o("model_type"),d_r=o(` property of the config object (either
passed as an argument or loaded from `),Gve=a("code"),c_r=o("pretrained_model_name_or_path"),f_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ove=a("code"),m_r=o("pretrained_model_name_or_path"),g_r=o(":"),h_r=l(),C8=a("ul"),PT=a("li"),Vve=a("strong"),p_r=o("speech-encoder-decoder"),__r=o(" \u2014 "),WH=a("a"),u_r=o("SpeechEncoderDecoderModel"),b_r=o(" (Speech Encoder decoder model)"),v_r=l(),BT=a("li"),Xve=a("strong"),F_r=o("speech_to_text"),T_r=o(" \u2014 "),HH=a("a"),M_r=o("Speech2TextForConditionalGeneration"),E_r=o(" (Speech2Text model)"),C_r=l(),IT=a("p"),w_r=o("The model is set in evaluation mode by default using "),zve=a("code"),A_r=o("model.eval()"),L_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qve=a("code"),y_r=o("model.train()"),x_r=l(),F(NT.$$.fragment),Nze=l(),Vd=a("h2"),qT=a("a"),Wve=a("span"),F(w8.$$.fragment),$_r=l(),Hve=a("span"),k_r=o("AutoModelForAudioXVector"),qze=l(),Jo=a("div"),F(A8.$$.fragment),S_r=l(),Xd=a("p"),R_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),UH=a("a"),P_r=o("from_pretrained()"),B_r=o(" class method or the "),JH=a("a"),I_r=o("from_config()"),N_r=o(` class
method.`),q_r=l(),L8=a("p"),j_r=o("This class cannot be instantiated directly using "),Uve=a("code"),D_r=o("__init__()"),G_r=o(" (throws an error)."),O_r=l(),Lt=a("div"),F(y8.$$.fragment),V_r=l(),Jve=a("p"),X_r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),z_r=l(),zd=a("p"),Q_r=o(`Note:
Loading a model from its configuration file does `),Yve=a("strong"),W_r=o("not"),H_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YH=a("a"),U_r=o("from_pretrained()"),J_r=o(" to load the model weights."),Y_r=l(),F(jT.$$.fragment),K_r=l(),_o=a("div"),F(x8.$$.fragment),Z_r=l(),Kve=a("p"),eur=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),our=l(),en=a("p"),rur=o("The model class to instantiate is selected based on the "),Zve=a("code"),tur=o("model_type"),aur=o(` property of the config object (either
passed as an argument or loaded from `),eFe=a("code"),nur=o("pretrained_model_name_or_path"),sur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=a("code"),lur=o("pretrained_model_name_or_path"),iur=o(":"),dur=l(),tt=a("ul"),DT=a("li"),rFe=a("strong"),cur=o("data2vec-audio"),fur=o(" \u2014 "),KH=a("a"),mur=o("Data2VecAudioForXVector"),gur=o(" (Data2VecAudio model)"),hur=l(),GT=a("li"),tFe=a("strong"),pur=o("unispeech-sat"),_ur=o(" \u2014 "),ZH=a("a"),uur=o("UniSpeechSatForXVector"),bur=o(" (UniSpeechSat model)"),vur=l(),OT=a("li"),aFe=a("strong"),Fur=o("wav2vec2"),Tur=o(" \u2014 "),eU=a("a"),Mur=o("Wav2Vec2ForXVector"),Eur=o(" (Wav2Vec2 model)"),Cur=l(),VT=a("li"),nFe=a("strong"),wur=o("wav2vec2-conformer"),Aur=o(" \u2014 "),oU=a("a"),Lur=o("Wav2Vec2ConformerForXVector"),yur=o(" (Wav2Vec2-Conformer model)"),xur=l(),XT=a("li"),sFe=a("strong"),$ur=o("wavlm"),kur=o(" \u2014 "),rU=a("a"),Sur=o("WavLMForXVector"),Rur=o(" (WavLM model)"),Pur=l(),zT=a("p"),Bur=o("The model is set in evaluation mode by default using "),lFe=a("code"),Iur=o("model.eval()"),Nur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iFe=a("code"),qur=o("model.train()"),jur=l(),F(QT.$$.fragment),jze=l(),Qd=a("h2"),WT=a("a"),dFe=a("span"),F($8.$$.fragment),Dur=l(),cFe=a("span"),Gur=o("AutoModelForMaskedImageModeling"),Dze=l(),Yo=a("div"),F(k8.$$.fragment),Our=l(),Wd=a("p"),Vur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),tU=a("a"),Xur=o("from_pretrained()"),zur=o(" class method or the "),aU=a("a"),Qur=o("from_config()"),Wur=o(` class
method.`),Hur=l(),S8=a("p"),Uur=o("This class cannot be instantiated directly using "),fFe=a("code"),Jur=o("__init__()"),Yur=o(" (throws an error)."),Kur=l(),yt=a("div"),F(R8.$$.fragment),Zur=l(),mFe=a("p"),e1r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),o1r=l(),Hd=a("p"),r1r=o(`Note:
Loading a model from its configuration file does `),gFe=a("strong"),t1r=o("not"),a1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=a("a"),n1r=o("from_pretrained()"),s1r=o(" to load the model weights."),l1r=l(),F(HT.$$.fragment),i1r=l(),uo=a("div"),F(P8.$$.fragment),d1r=l(),hFe=a("p"),c1r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),f1r=l(),on=a("p"),m1r=o("The model class to instantiate is selected based on the "),pFe=a("code"),g1r=o("model_type"),h1r=o(` property of the config object (either
passed as an argument or loaded from `),_Fe=a("code"),p1r=o("pretrained_model_name_or_path"),_1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uFe=a("code"),u1r=o("pretrained_model_name_or_path"),b1r=o(":"),v1r=l(),rn=a("ul"),UT=a("li"),bFe=a("strong"),F1r=o("deit"),T1r=o(" \u2014 "),sU=a("a"),M1r=o("DeiTForMaskedImageModeling"),E1r=o(" (DeiT model)"),C1r=l(),JT=a("li"),vFe=a("strong"),w1r=o("swin"),A1r=o(" \u2014 "),lU=a("a"),L1r=o("SwinForMaskedImageModeling"),y1r=o(" (Swin Transformer model)"),x1r=l(),YT=a("li"),FFe=a("strong"),$1r=o("swinv2"),k1r=o(" \u2014 "),iU=a("a"),S1r=o("Swinv2ForMaskedImageModeling"),R1r=o(" (Swin Transformer V2 model)"),P1r=l(),KT=a("li"),TFe=a("strong"),B1r=o("vit"),I1r=o(" \u2014 "),dU=a("a"),N1r=o("ViTForMaskedImageModeling"),q1r=o(" (ViT model)"),j1r=l(),ZT=a("p"),D1r=o("The model is set in evaluation mode by default using "),MFe=a("code"),G1r=o("model.eval()"),O1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EFe=a("code"),V1r=o("model.train()"),X1r=l(),F(e7.$$.fragment),Gze=l(),Ud=a("h2"),o7=a("a"),CFe=a("span"),F(B8.$$.fragment),z1r=l(),wFe=a("span"),Q1r=o("AutoModelForObjectDetection"),Oze=l(),Ko=a("div"),F(I8.$$.fragment),W1r=l(),Jd=a("p"),H1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),cU=a("a"),U1r=o("from_pretrained()"),J1r=o(" class method or the "),fU=a("a"),Y1r=o("from_config()"),K1r=o(` class
method.`),Z1r=l(),N8=a("p"),e4r=o("This class cannot be instantiated directly using "),AFe=a("code"),o4r=o("__init__()"),r4r=o(" (throws an error)."),t4r=l(),xt=a("div"),F(q8.$$.fragment),a4r=l(),LFe=a("p"),n4r=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),s4r=l(),Yd=a("p"),l4r=o(`Note:
Loading a model from its configuration file does `),yFe=a("strong"),i4r=o("not"),d4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mU=a("a"),c4r=o("from_pretrained()"),f4r=o(" to load the model weights."),m4r=l(),F(r7.$$.fragment),g4r=l(),bo=a("div"),F(j8.$$.fragment),h4r=l(),xFe=a("p"),p4r=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),_4r=l(),tn=a("p"),u4r=o("The model class to instantiate is selected based on the "),$Fe=a("code"),b4r=o("model_type"),v4r=o(` property of the config object (either
passed as an argument or loaded from `),kFe=a("code"),F4r=o("pretrained_model_name_or_path"),T4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=a("code"),M4r=o("pretrained_model_name_or_path"),E4r=o(":"),C4r=l(),D8=a("ul"),t7=a("li"),RFe=a("strong"),w4r=o("detr"),A4r=o(" \u2014 "),gU=a("a"),L4r=o("DetrForObjectDetection"),y4r=o(" (DETR model)"),x4r=l(),a7=a("li"),PFe=a("strong"),$4r=o("yolos"),k4r=o(" \u2014 "),hU=a("a"),S4r=o("YolosForObjectDetection"),R4r=o(" (YOLOS model)"),P4r=l(),n7=a("p"),B4r=o("The model is set in evaluation mode by default using "),BFe=a("code"),I4r=o("model.eval()"),N4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),IFe=a("code"),q4r=o("model.train()"),j4r=l(),F(s7.$$.fragment),Vze=l(),Kd=a("h2"),l7=a("a"),NFe=a("span"),F(G8.$$.fragment),D4r=l(),qFe=a("span"),G4r=o("AutoModelForImageSegmentation"),Xze=l(),Zo=a("div"),F(O8.$$.fragment),O4r=l(),Zd=a("p"),V4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),pU=a("a"),X4r=o("from_pretrained()"),z4r=o(" class method or the "),_U=a("a"),Q4r=o("from_config()"),W4r=o(` class
method.`),H4r=l(),V8=a("p"),U4r=o("This class cannot be instantiated directly using "),jFe=a("code"),J4r=o("__init__()"),Y4r=o(" (throws an error)."),K4r=l(),$t=a("div"),F(X8.$$.fragment),Z4r=l(),DFe=a("p"),e2r=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),o2r=l(),ec=a("p"),r2r=o(`Note:
Loading a model from its configuration file does `),GFe=a("strong"),t2r=o("not"),a2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uU=a("a"),n2r=o("from_pretrained()"),s2r=o(" to load the model weights."),l2r=l(),F(i7.$$.fragment),i2r=l(),vo=a("div"),F(z8.$$.fragment),d2r=l(),OFe=a("p"),c2r=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),f2r=l(),an=a("p"),m2r=o("The model class to instantiate is selected based on the "),VFe=a("code"),g2r=o("model_type"),h2r=o(` property of the config object (either
passed as an argument or loaded from `),XFe=a("code"),p2r=o("pretrained_model_name_or_path"),_2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zFe=a("code"),u2r=o("pretrained_model_name_or_path"),b2r=o(":"),v2r=l(),QFe=a("ul"),d7=a("li"),WFe=a("strong"),F2r=o("detr"),T2r=o(" \u2014 "),bU=a("a"),M2r=o("DetrForSegmentation"),E2r=o(" (DETR model)"),C2r=l(),c7=a("p"),w2r=o("The model is set in evaluation mode by default using "),HFe=a("code"),A2r=o("model.eval()"),L2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UFe=a("code"),y2r=o("model.train()"),x2r=l(),F(f7.$$.fragment),zze=l(),oc=a("h2"),m7=a("a"),JFe=a("span"),F(Q8.$$.fragment),$2r=l(),YFe=a("span"),k2r=o("AutoModelForSemanticSegmentation"),Qze=l(),er=a("div"),F(W8.$$.fragment),S2r=l(),rc=a("p"),R2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),vU=a("a"),P2r=o("from_pretrained()"),B2r=o(" class method or the "),FU=a("a"),I2r=o("from_config()"),N2r=o(` class
method.`),q2r=l(),H8=a("p"),j2r=o("This class cannot be instantiated directly using "),KFe=a("code"),D2r=o("__init__()"),G2r=o(" (throws an error)."),O2r=l(),kt=a("div"),F(U8.$$.fragment),V2r=l(),ZFe=a("p"),X2r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),z2r=l(),tc=a("p"),Q2r=o(`Note:
Loading a model from its configuration file does `),e6e=a("strong"),W2r=o("not"),H2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TU=a("a"),U2r=o("from_pretrained()"),J2r=o(" to load the model weights."),Y2r=l(),F(g7.$$.fragment),K2r=l(),Fo=a("div"),F(J8.$$.fragment),Z2r=l(),o6e=a("p"),ebr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),obr=l(),nn=a("p"),rbr=o("The model class to instantiate is selected based on the "),r6e=a("code"),tbr=o("model_type"),abr=o(` property of the config object (either
passed as an argument or loaded from `),t6e=a("code"),nbr=o("pretrained_model_name_or_path"),sbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=a("code"),lbr=o("pretrained_model_name_or_path"),ibr=o(":"),dbr=l(),at=a("ul"),h7=a("li"),n6e=a("strong"),cbr=o("beit"),fbr=o(" \u2014 "),MU=a("a"),mbr=o("BeitForSemanticSegmentation"),gbr=o(" (BEiT model)"),hbr=l(),p7=a("li"),s6e=a("strong"),pbr=o("data2vec-vision"),_br=o(" \u2014 "),EU=a("a"),ubr=o("Data2VecVisionForSemanticSegmentation"),bbr=o(" (Data2VecVision model)"),vbr=l(),_7=a("li"),l6e=a("strong"),Fbr=o("dpt"),Tbr=o(" \u2014 "),CU=a("a"),Mbr=o("DPTForSemanticSegmentation"),Ebr=o(" (DPT model)"),Cbr=l(),u7=a("li"),i6e=a("strong"),wbr=o("mobilevit"),Abr=o(" \u2014 "),wU=a("a"),Lbr=o("MobileViTForSemanticSegmentation"),ybr=o(" (MobileViT model)"),xbr=l(),b7=a("li"),d6e=a("strong"),$br=o("segformer"),kbr=o(" \u2014 "),AU=a("a"),Sbr=o("SegformerForSemanticSegmentation"),Rbr=o(" (SegFormer model)"),Pbr=l(),v7=a("p"),Bbr=o("The model is set in evaluation mode by default using "),c6e=a("code"),Ibr=o("model.eval()"),Nbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f6e=a("code"),qbr=o("model.train()"),jbr=l(),F(F7.$$.fragment),Wze=l(),ac=a("h2"),T7=a("a"),m6e=a("span"),F(Y8.$$.fragment),Dbr=l(),g6e=a("span"),Gbr=o("AutoModelForInstanceSegmentation"),Hze=l(),or=a("div"),F(K8.$$.fragment),Obr=l(),nc=a("p"),Vbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),LU=a("a"),Xbr=o("from_pretrained()"),zbr=o(" class method or the "),yU=a("a"),Qbr=o("from_config()"),Wbr=o(` class
method.`),Hbr=l(),Z8=a("p"),Ubr=o("This class cannot be instantiated directly using "),h6e=a("code"),Jbr=o("__init__()"),Ybr=o(" (throws an error)."),Kbr=l(),St=a("div"),F(ex.$$.fragment),Zbr=l(),p6e=a("p"),evr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),ovr=l(),sc=a("p"),rvr=o(`Note:
Loading a model from its configuration file does `),_6e=a("strong"),tvr=o("not"),avr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=a("a"),nvr=o("from_pretrained()"),svr=o(" to load the model weights."),lvr=l(),F(M7.$$.fragment),ivr=l(),To=a("div"),F(ox.$$.fragment),dvr=l(),u6e=a("p"),cvr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),fvr=l(),sn=a("p"),mvr=o("The model class to instantiate is selected based on the "),b6e=a("code"),gvr=o("model_type"),hvr=o(` property of the config object (either
passed as an argument or loaded from `),v6e=a("code"),pvr=o("pretrained_model_name_or_path"),_vr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F6e=a("code"),uvr=o("pretrained_model_name_or_path"),bvr=o(":"),vvr=l(),T6e=a("ul"),E7=a("li"),M6e=a("strong"),Fvr=o("maskformer"),Tvr=o(" \u2014 "),$U=a("a"),Mvr=o("MaskFormerForInstanceSegmentation"),Evr=o(" (MaskFormer model)"),Cvr=l(),C7=a("p"),wvr=o("The model is set in evaluation mode by default using "),E6e=a("code"),Avr=o("model.eval()"),Lvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C6e=a("code"),yvr=o("model.train()"),xvr=l(),F(w7.$$.fragment),Uze=l(),lc=a("h2"),A7=a("a"),w6e=a("span"),F(rx.$$.fragment),$vr=l(),A6e=a("span"),kvr=o("TFAutoModel"),Jze=l(),rr=a("div"),F(tx.$$.fragment),Svr=l(),ic=a("p"),Rvr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),kU=a("a"),Pvr=o("from_pretrained()"),Bvr=o(" class method or the "),SU=a("a"),Ivr=o("from_config()"),Nvr=o(` class
method.`),qvr=l(),ax=a("p"),jvr=o("This class cannot be instantiated directly using "),L6e=a("code"),Dvr=o("__init__()"),Gvr=o(" (throws an error)."),Ovr=l(),Rt=a("div"),F(nx.$$.fragment),Vvr=l(),y6e=a("p"),Xvr=o("Instantiates one of the base model classes of the library from a configuration."),zvr=l(),dc=a("p"),Qvr=o(`Note:
Loading a model from its configuration file does `),x6e=a("strong"),Wvr=o("not"),Hvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=a("a"),Uvr=o("from_pretrained()"),Jvr=o(" to load the model weights."),Yvr=l(),F(L7.$$.fragment),Kvr=l(),$r=a("div"),F(sx.$$.fragment),Zvr=l(),$6e=a("p"),eFr=o("Instantiate one of the base model classes of the library from a pretrained model."),oFr=l(),ln=a("p"),rFr=o("The model class to instantiate is selected based on the "),k6e=a("code"),tFr=o("model_type"),aFr=o(` property of the config object (either
passed as an argument or loaded from `),S6e=a("code"),nFr=o("pretrained_model_name_or_path"),sFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R6e=a("code"),lFr=o("pretrained_model_name_or_path"),iFr=o(":"),dFr=l(),I=a("ul"),y7=a("li"),P6e=a("strong"),cFr=o("albert"),fFr=o(" \u2014 "),PU=a("a"),mFr=o("TFAlbertModel"),gFr=o(" (ALBERT model)"),hFr=l(),x7=a("li"),B6e=a("strong"),pFr=o("bart"),_Fr=o(" \u2014 "),BU=a("a"),uFr=o("TFBartModel"),bFr=o(" (BART model)"),vFr=l(),$7=a("li"),I6e=a("strong"),FFr=o("bert"),TFr=o(" \u2014 "),IU=a("a"),MFr=o("TFBertModel"),EFr=o(" (BERT model)"),CFr=l(),k7=a("li"),N6e=a("strong"),wFr=o("blenderbot"),AFr=o(" \u2014 "),NU=a("a"),LFr=o("TFBlenderbotModel"),yFr=o(" (Blenderbot model)"),xFr=l(),S7=a("li"),q6e=a("strong"),$Fr=o("blenderbot-small"),kFr=o(" \u2014 "),qU=a("a"),SFr=o("TFBlenderbotSmallModel"),RFr=o(" (BlenderbotSmall model)"),PFr=l(),R7=a("li"),j6e=a("strong"),BFr=o("camembert"),IFr=o(" \u2014 "),jU=a("a"),NFr=o("TFCamembertModel"),qFr=o(" (CamemBERT model)"),jFr=l(),P7=a("li"),D6e=a("strong"),DFr=o("clip"),GFr=o(" \u2014 "),DU=a("a"),OFr=o("TFCLIPModel"),VFr=o(" (CLIP model)"),XFr=l(),B7=a("li"),G6e=a("strong"),zFr=o("convbert"),QFr=o(" \u2014 "),GU=a("a"),WFr=o("TFConvBertModel"),HFr=o(" (ConvBERT model)"),UFr=l(),I7=a("li"),O6e=a("strong"),JFr=o("convnext"),YFr=o(" \u2014 "),OU=a("a"),KFr=o("TFConvNextModel"),ZFr=o(" (ConvNeXT model)"),e6r=l(),N7=a("li"),V6e=a("strong"),o6r=o("ctrl"),r6r=o(" \u2014 "),VU=a("a"),t6r=o("TFCTRLModel"),a6r=o(" (CTRL model)"),n6r=l(),q7=a("li"),X6e=a("strong"),s6r=o("data2vec-vision"),l6r=o(" \u2014 "),XU=a("a"),i6r=o("TFData2VecVisionModel"),d6r=o(" (Data2VecVision model)"),c6r=l(),j7=a("li"),z6e=a("strong"),f6r=o("deberta"),m6r=o(" \u2014 "),zU=a("a"),g6r=o("TFDebertaModel"),h6r=o(" (DeBERTa model)"),p6r=l(),D7=a("li"),Q6e=a("strong"),_6r=o("deberta-v2"),u6r=o(" \u2014 "),QU=a("a"),b6r=o("TFDebertaV2Model"),v6r=o(" (DeBERTa-v2 model)"),F6r=l(),G7=a("li"),W6e=a("strong"),T6r=o("deit"),M6r=o(" \u2014 "),WU=a("a"),E6r=o("TFDeiTModel"),C6r=o(" (DeiT model)"),w6r=l(),O7=a("li"),H6e=a("strong"),A6r=o("distilbert"),L6r=o(" \u2014 "),HU=a("a"),y6r=o("TFDistilBertModel"),x6r=o(" (DistilBERT model)"),$6r=l(),V7=a("li"),U6e=a("strong"),k6r=o("dpr"),S6r=o(" \u2014 "),UU=a("a"),R6r=o("TFDPRQuestionEncoder"),P6r=o(" (DPR model)"),B6r=l(),X7=a("li"),J6e=a("strong"),I6r=o("electra"),N6r=o(" \u2014 "),JU=a("a"),q6r=o("TFElectraModel"),j6r=o(" (ELECTRA model)"),D6r=l(),z7=a("li"),Y6e=a("strong"),G6r=o("flaubert"),O6r=o(" \u2014 "),YU=a("a"),V6r=o("TFFlaubertModel"),X6r=o(" (FlauBERT model)"),z6r=l(),Ks=a("li"),K6e=a("strong"),Q6r=o("funnel"),W6r=o(" \u2014 "),KU=a("a"),H6r=o("TFFunnelModel"),U6r=o(" or "),ZU=a("a"),J6r=o("TFFunnelBaseModel"),Y6r=o(" (Funnel Transformer model)"),K6r=l(),Q7=a("li"),Z6e=a("strong"),Z6r=o("gpt2"),eTr=o(" \u2014 "),eJ=a("a"),oTr=o("TFGPT2Model"),rTr=o(" (OpenAI GPT-2 model)"),tTr=l(),W7=a("li"),eTe=a("strong"),aTr=o("gptj"),nTr=o(" \u2014 "),oJ=a("a"),sTr=o("TFGPTJModel"),lTr=o(" (GPT-J model)"),iTr=l(),H7=a("li"),oTe=a("strong"),dTr=o("hubert"),cTr=o(" \u2014 "),rJ=a("a"),fTr=o("TFHubertModel"),mTr=o(" (Hubert model)"),gTr=l(),U7=a("li"),rTe=a("strong"),hTr=o("layoutlm"),pTr=o(" \u2014 "),tJ=a("a"),_Tr=o("TFLayoutLMModel"),uTr=o(" (LayoutLM model)"),bTr=l(),J7=a("li"),tTe=a("strong"),vTr=o("led"),FTr=o(" \u2014 "),aJ=a("a"),TTr=o("TFLEDModel"),MTr=o(" (LED model)"),ETr=l(),Y7=a("li"),aTe=a("strong"),CTr=o("longformer"),wTr=o(" \u2014 "),nJ=a("a"),ATr=o("TFLongformerModel"),LTr=o(" (Longformer model)"),yTr=l(),K7=a("li"),nTe=a("strong"),xTr=o("lxmert"),$Tr=o(" \u2014 "),sJ=a("a"),kTr=o("TFLxmertModel"),STr=o(" (LXMERT model)"),RTr=l(),Z7=a("li"),sTe=a("strong"),PTr=o("marian"),BTr=o(" \u2014 "),lJ=a("a"),ITr=o("TFMarianModel"),NTr=o(" (Marian model)"),qTr=l(),e9=a("li"),lTe=a("strong"),jTr=o("mbart"),DTr=o(" \u2014 "),iJ=a("a"),GTr=o("TFMBartModel"),OTr=o(" (mBART model)"),VTr=l(),o9=a("li"),iTe=a("strong"),XTr=o("mobilebert"),zTr=o(" \u2014 "),dJ=a("a"),QTr=o("TFMobileBertModel"),WTr=o(" (MobileBERT model)"),HTr=l(),r9=a("li"),dTe=a("strong"),UTr=o("mpnet"),JTr=o(" \u2014 "),cJ=a("a"),YTr=o("TFMPNetModel"),KTr=o(" (MPNet model)"),ZTr=l(),t9=a("li"),cTe=a("strong"),e7r=o("mt5"),o7r=o(" \u2014 "),fJ=a("a"),r7r=o("TFMT5Model"),t7r=o(" (MT5 model)"),a7r=l(),a9=a("li"),fTe=a("strong"),n7r=o("openai-gpt"),s7r=o(" \u2014 "),mJ=a("a"),l7r=o("TFOpenAIGPTModel"),i7r=o(" (OpenAI GPT model)"),d7r=l(),n9=a("li"),mTe=a("strong"),c7r=o("opt"),f7r=o(" \u2014 "),gJ=a("a"),m7r=o("TFOPTModel"),g7r=o(" (OPT model)"),h7r=l(),s9=a("li"),gTe=a("strong"),p7r=o("pegasus"),_7r=o(" \u2014 "),hJ=a("a"),u7r=o("TFPegasusModel"),b7r=o(" (Pegasus model)"),v7r=l(),l9=a("li"),hTe=a("strong"),F7r=o("regnet"),T7r=o(" \u2014 "),pJ=a("a"),M7r=o("TFRegNetModel"),E7r=o(" (RegNet model)"),C7r=l(),i9=a("li"),pTe=a("strong"),w7r=o("rembert"),A7r=o(" \u2014 "),_J=a("a"),L7r=o("TFRemBertModel"),y7r=o(" (RemBERT model)"),x7r=l(),d9=a("li"),_Te=a("strong"),$7r=o("resnet"),k7r=o(" \u2014 "),uJ=a("a"),S7r=o("TFResNetModel"),R7r=o(" (ResNet model)"),P7r=l(),c9=a("li"),uTe=a("strong"),B7r=o("roberta"),I7r=o(" \u2014 "),bJ=a("a"),N7r=o("TFRobertaModel"),q7r=o(" (RoBERTa model)"),j7r=l(),f9=a("li"),bTe=a("strong"),D7r=o("roformer"),G7r=o(" \u2014 "),vJ=a("a"),O7r=o("TFRoFormerModel"),V7r=o(" (RoFormer model)"),X7r=l(),m9=a("li"),vTe=a("strong"),z7r=o("segformer"),Q7r=o(" \u2014 "),FJ=a("a"),W7r=o("TFSegformerModel"),H7r=o(" (SegFormer model)"),U7r=l(),g9=a("li"),FTe=a("strong"),J7r=o("speech_to_text"),Y7r=o(" \u2014 "),TJ=a("a"),K7r=o("TFSpeech2TextModel"),Z7r=o(" (Speech2Text model)"),e9r=l(),h9=a("li"),TTe=a("strong"),o9r=o("swin"),r9r=o(" \u2014 "),MJ=a("a"),t9r=o("TFSwinModel"),a9r=o(" (Swin Transformer model)"),n9r=l(),p9=a("li"),MTe=a("strong"),s9r=o("t5"),l9r=o(" \u2014 "),EJ=a("a"),i9r=o("TFT5Model"),d9r=o(" (T5 model)"),c9r=l(),_9=a("li"),ETe=a("strong"),f9r=o("tapas"),m9r=o(" \u2014 "),CJ=a("a"),g9r=o("TFTapasModel"),h9r=o(" (TAPAS model)"),p9r=l(),u9=a("li"),CTe=a("strong"),_9r=o("transfo-xl"),u9r=o(" \u2014 "),wJ=a("a"),b9r=o("TFTransfoXLModel"),v9r=o(" (Transformer-XL model)"),F9r=l(),b9=a("li"),wTe=a("strong"),T9r=o("vit"),M9r=o(" \u2014 "),AJ=a("a"),E9r=o("TFViTModel"),C9r=o(" (ViT model)"),w9r=l(),v9=a("li"),ATe=a("strong"),A9r=o("vit_mae"),L9r=o(" \u2014 "),LJ=a("a"),y9r=o("TFViTMAEModel"),x9r=o(" (ViTMAE model)"),$9r=l(),F9=a("li"),LTe=a("strong"),k9r=o("wav2vec2"),S9r=o(" \u2014 "),yJ=a("a"),R9r=o("TFWav2Vec2Model"),P9r=o(" (Wav2Vec2 model)"),B9r=l(),T9=a("li"),yTe=a("strong"),I9r=o("xlm"),N9r=o(" \u2014 "),xJ=a("a"),q9r=o("TFXLMModel"),j9r=o(" (XLM model)"),D9r=l(),M9=a("li"),xTe=a("strong"),G9r=o("xlm-roberta"),O9r=o(" \u2014 "),$J=a("a"),V9r=o("TFXLMRobertaModel"),X9r=o(" (XLM-RoBERTa model)"),z9r=l(),E9=a("li"),$Te=a("strong"),Q9r=o("xlnet"),W9r=o(" \u2014 "),kJ=a("a"),H9r=o("TFXLNetModel"),U9r=o(" (XLNet model)"),J9r=l(),F(C9.$$.fragment),Yze=l(),cc=a("h2"),w9=a("a"),kTe=a("span"),F(lx.$$.fragment),Y9r=l(),STe=a("span"),K9r=o("TFAutoModelForPreTraining"),Kze=l(),tr=a("div"),F(ix.$$.fragment),Z9r=l(),fc=a("p"),eMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),SJ=a("a"),oMr=o("from_pretrained()"),rMr=o(" class method or the "),RJ=a("a"),tMr=o("from_config()"),aMr=o(` class
method.`),nMr=l(),dx=a("p"),sMr=o("This class cannot be instantiated directly using "),RTe=a("code"),lMr=o("__init__()"),iMr=o(" (throws an error)."),dMr=l(),Pt=a("div"),F(cx.$$.fragment),cMr=l(),PTe=a("p"),fMr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),mMr=l(),mc=a("p"),gMr=o(`Note:
Loading a model from its configuration file does `),BTe=a("strong"),hMr=o("not"),pMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PJ=a("a"),_Mr=o("from_pretrained()"),uMr=o(" to load the model weights."),bMr=l(),F(A9.$$.fragment),vMr=l(),kr=a("div"),F(fx.$$.fragment),FMr=l(),ITe=a("p"),TMr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),MMr=l(),dn=a("p"),EMr=o("The model class to instantiate is selected based on the "),NTe=a("code"),CMr=o("model_type"),wMr=o(` property of the config object (either
passed as an argument or loaded from `),qTe=a("code"),AMr=o("pretrained_model_name_or_path"),LMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jTe=a("code"),yMr=o("pretrained_model_name_or_path"),xMr=o(":"),$Mr=l(),se=a("ul"),L9=a("li"),DTe=a("strong"),kMr=o("albert"),SMr=o(" \u2014 "),BJ=a("a"),RMr=o("TFAlbertForPreTraining"),PMr=o(" (ALBERT model)"),BMr=l(),y9=a("li"),GTe=a("strong"),IMr=o("bart"),NMr=o(" \u2014 "),IJ=a("a"),qMr=o("TFBartForConditionalGeneration"),jMr=o(" (BART model)"),DMr=l(),x9=a("li"),OTe=a("strong"),GMr=o("bert"),OMr=o(" \u2014 "),NJ=a("a"),VMr=o("TFBertForPreTraining"),XMr=o(" (BERT model)"),zMr=l(),$9=a("li"),VTe=a("strong"),QMr=o("camembert"),WMr=o(" \u2014 "),qJ=a("a"),HMr=o("TFCamembertForMaskedLM"),UMr=o(" (CamemBERT model)"),JMr=l(),k9=a("li"),XTe=a("strong"),YMr=o("ctrl"),KMr=o(" \u2014 "),jJ=a("a"),ZMr=o("TFCTRLLMHeadModel"),eEr=o(" (CTRL model)"),oEr=l(),S9=a("li"),zTe=a("strong"),rEr=o("distilbert"),tEr=o(" \u2014 "),DJ=a("a"),aEr=o("TFDistilBertForMaskedLM"),nEr=o(" (DistilBERT model)"),sEr=l(),R9=a("li"),QTe=a("strong"),lEr=o("electra"),iEr=o(" \u2014 "),GJ=a("a"),dEr=o("TFElectraForPreTraining"),cEr=o(" (ELECTRA model)"),fEr=l(),P9=a("li"),WTe=a("strong"),mEr=o("flaubert"),gEr=o(" \u2014 "),OJ=a("a"),hEr=o("TFFlaubertWithLMHeadModel"),pEr=o(" (FlauBERT model)"),_Er=l(),B9=a("li"),HTe=a("strong"),uEr=o("funnel"),bEr=o(" \u2014 "),VJ=a("a"),vEr=o("TFFunnelForPreTraining"),FEr=o(" (Funnel Transformer model)"),TEr=l(),I9=a("li"),UTe=a("strong"),MEr=o("gpt2"),EEr=o(" \u2014 "),XJ=a("a"),CEr=o("TFGPT2LMHeadModel"),wEr=o(" (OpenAI GPT-2 model)"),AEr=l(),N9=a("li"),JTe=a("strong"),LEr=o("layoutlm"),yEr=o(" \u2014 "),zJ=a("a"),xEr=o("TFLayoutLMForMaskedLM"),$Er=o(" (LayoutLM model)"),kEr=l(),q9=a("li"),YTe=a("strong"),SEr=o("lxmert"),REr=o(" \u2014 "),QJ=a("a"),PEr=o("TFLxmertForPreTraining"),BEr=o(" (LXMERT model)"),IEr=l(),j9=a("li"),KTe=a("strong"),NEr=o("mobilebert"),qEr=o(" \u2014 "),WJ=a("a"),jEr=o("TFMobileBertForPreTraining"),DEr=o(" (MobileBERT model)"),GEr=l(),D9=a("li"),ZTe=a("strong"),OEr=o("mpnet"),VEr=o(" \u2014 "),HJ=a("a"),XEr=o("TFMPNetForMaskedLM"),zEr=o(" (MPNet model)"),QEr=l(),G9=a("li"),e7e=a("strong"),WEr=o("openai-gpt"),HEr=o(" \u2014 "),UJ=a("a"),UEr=o("TFOpenAIGPTLMHeadModel"),JEr=o(" (OpenAI GPT model)"),YEr=l(),O9=a("li"),o7e=a("strong"),KEr=o("roberta"),ZEr=o(" \u2014 "),JJ=a("a"),eCr=o("TFRobertaForMaskedLM"),oCr=o(" (RoBERTa model)"),rCr=l(),V9=a("li"),r7e=a("strong"),tCr=o("t5"),aCr=o(" \u2014 "),YJ=a("a"),nCr=o("TFT5ForConditionalGeneration"),sCr=o(" (T5 model)"),lCr=l(),X9=a("li"),t7e=a("strong"),iCr=o("tapas"),dCr=o(" \u2014 "),KJ=a("a"),cCr=o("TFTapasForMaskedLM"),fCr=o(" (TAPAS model)"),mCr=l(),z9=a("li"),a7e=a("strong"),gCr=o("transfo-xl"),hCr=o(" \u2014 "),ZJ=a("a"),pCr=o("TFTransfoXLLMHeadModel"),_Cr=o(" (Transformer-XL model)"),uCr=l(),Q9=a("li"),n7e=a("strong"),bCr=o("vit_mae"),vCr=o(" \u2014 "),eY=a("a"),FCr=o("TFViTMAEForPreTraining"),TCr=o(" (ViTMAE model)"),MCr=l(),W9=a("li"),s7e=a("strong"),ECr=o("xlm"),CCr=o(" \u2014 "),oY=a("a"),wCr=o("TFXLMWithLMHeadModel"),ACr=o(" (XLM model)"),LCr=l(),H9=a("li"),l7e=a("strong"),yCr=o("xlm-roberta"),xCr=o(" \u2014 "),rY=a("a"),$Cr=o("TFXLMRobertaForMaskedLM"),kCr=o(" (XLM-RoBERTa model)"),SCr=l(),U9=a("li"),i7e=a("strong"),RCr=o("xlnet"),PCr=o(" \u2014 "),tY=a("a"),BCr=o("TFXLNetLMHeadModel"),ICr=o(" (XLNet model)"),NCr=l(),F(J9.$$.fragment),Zze=l(),gc=a("h2"),Y9=a("a"),d7e=a("span"),F(mx.$$.fragment),qCr=l(),c7e=a("span"),jCr=o("TFAutoModelForCausalLM"),eQe=l(),ar=a("div"),F(gx.$$.fragment),DCr=l(),hc=a("p"),GCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),aY=a("a"),OCr=o("from_pretrained()"),VCr=o(" class method or the "),nY=a("a"),XCr=o("from_config()"),zCr=o(` class
method.`),QCr=l(),hx=a("p"),WCr=o("This class cannot be instantiated directly using "),f7e=a("code"),HCr=o("__init__()"),UCr=o(" (throws an error)."),JCr=l(),Bt=a("div"),F(px.$$.fragment),YCr=l(),m7e=a("p"),KCr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ZCr=l(),pc=a("p"),e5r=o(`Note:
Loading a model from its configuration file does `),g7e=a("strong"),o5r=o("not"),r5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sY=a("a"),t5r=o("from_pretrained()"),a5r=o(" to load the model weights."),n5r=l(),F(K9.$$.fragment),s5r=l(),Sr=a("div"),F(_x.$$.fragment),l5r=l(),h7e=a("p"),i5r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),d5r=l(),cn=a("p"),c5r=o("The model class to instantiate is selected based on the "),p7e=a("code"),f5r=o("model_type"),m5r=o(` property of the config object (either
passed as an argument or loaded from `),_7e=a("code"),g5r=o("pretrained_model_name_or_path"),h5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u7e=a("code"),p5r=o("pretrained_model_name_or_path"),_5r=o(":"),u5r=l(),Me=a("ul"),Z9=a("li"),b7e=a("strong"),b5r=o("bert"),v5r=o(" \u2014 "),lY=a("a"),F5r=o("TFBertLMHeadModel"),T5r=o(" (BERT model)"),M5r=l(),eM=a("li"),v7e=a("strong"),E5r=o("camembert"),C5r=o(" \u2014 "),iY=a("a"),w5r=o("TFCamembertForCausalLM"),A5r=o(" (CamemBERT model)"),L5r=l(),oM=a("li"),F7e=a("strong"),y5r=o("ctrl"),x5r=o(" \u2014 "),dY=a("a"),$5r=o("TFCTRLLMHeadModel"),k5r=o(" (CTRL model)"),S5r=l(),rM=a("li"),T7e=a("strong"),R5r=o("gpt2"),P5r=o(" \u2014 "),cY=a("a"),B5r=o("TFGPT2LMHeadModel"),I5r=o(" (OpenAI GPT-2 model)"),N5r=l(),tM=a("li"),M7e=a("strong"),q5r=o("gptj"),j5r=o(" \u2014 "),fY=a("a"),D5r=o("TFGPTJForCausalLM"),G5r=o(" (GPT-J model)"),O5r=l(),aM=a("li"),E7e=a("strong"),V5r=o("openai-gpt"),X5r=o(" \u2014 "),mY=a("a"),z5r=o("TFOpenAIGPTLMHeadModel"),Q5r=o(" (OpenAI GPT model)"),W5r=l(),nM=a("li"),C7e=a("strong"),H5r=o("opt"),U5r=o(" \u2014 "),gY=a("a"),J5r=o("TFOPTForCausalLM"),Y5r=o(" (OPT model)"),K5r=l(),sM=a("li"),w7e=a("strong"),Z5r=o("rembert"),e3r=o(" \u2014 "),hY=a("a"),o3r=o("TFRemBertForCausalLM"),r3r=o(" (RemBERT model)"),t3r=l(),lM=a("li"),A7e=a("strong"),a3r=o("roberta"),n3r=o(" \u2014 "),pY=a("a"),s3r=o("TFRobertaForCausalLM"),l3r=o(" (RoBERTa model)"),i3r=l(),iM=a("li"),L7e=a("strong"),d3r=o("roformer"),c3r=o(" \u2014 "),_Y=a("a"),f3r=o("TFRoFormerForCausalLM"),m3r=o(" (RoFormer model)"),g3r=l(),dM=a("li"),y7e=a("strong"),h3r=o("transfo-xl"),p3r=o(" \u2014 "),uY=a("a"),_3r=o("TFTransfoXLLMHeadModel"),u3r=o(" (Transformer-XL model)"),b3r=l(),cM=a("li"),x7e=a("strong"),v3r=o("xlm"),F3r=o(" \u2014 "),bY=a("a"),T3r=o("TFXLMWithLMHeadModel"),M3r=o(" (XLM model)"),E3r=l(),fM=a("li"),$7e=a("strong"),C3r=o("xlnet"),w3r=o(" \u2014 "),vY=a("a"),A3r=o("TFXLNetLMHeadModel"),L3r=o(" (XLNet model)"),y3r=l(),F(mM.$$.fragment),oQe=l(),_c=a("h2"),gM=a("a"),k7e=a("span"),F(ux.$$.fragment),x3r=l(),S7e=a("span"),$3r=o("TFAutoModelForImageClassification"),rQe=l(),nr=a("div"),F(bx.$$.fragment),k3r=l(),uc=a("p"),S3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),FY=a("a"),R3r=o("from_pretrained()"),P3r=o(" class method or the "),TY=a("a"),B3r=o("from_config()"),I3r=o(` class
method.`),N3r=l(),vx=a("p"),q3r=o("This class cannot be instantiated directly using "),R7e=a("code"),j3r=o("__init__()"),D3r=o(" (throws an error)."),G3r=l(),It=a("div"),F(Fx.$$.fragment),O3r=l(),P7e=a("p"),V3r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),X3r=l(),bc=a("p"),z3r=o(`Note:
Loading a model from its configuration file does `),B7e=a("strong"),Q3r=o("not"),W3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=a("a"),H3r=o("from_pretrained()"),U3r=o(" to load the model weights."),J3r=l(),F(hM.$$.fragment),Y3r=l(),Rr=a("div"),F(Tx.$$.fragment),K3r=l(),I7e=a("p"),Z3r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),e0r=l(),fn=a("p"),o0r=o("The model class to instantiate is selected based on the "),N7e=a("code"),r0r=o("model_type"),t0r=o(` property of the config object (either
passed as an argument or loaded from `),q7e=a("code"),a0r=o("pretrained_model_name_or_path"),n0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j7e=a("code"),s0r=o("pretrained_model_name_or_path"),l0r=o(":"),i0r=l(),Ve=a("ul"),pM=a("li"),D7e=a("strong"),d0r=o("convnext"),c0r=o(" \u2014 "),EY=a("a"),f0r=o("TFConvNextForImageClassification"),m0r=o(" (ConvNeXT model)"),g0r=l(),_M=a("li"),G7e=a("strong"),h0r=o("data2vec-vision"),p0r=o(" \u2014 "),CY=a("a"),_0r=o("TFData2VecVisionForImageClassification"),u0r=o(" (Data2VecVision model)"),b0r=l(),Zs=a("li"),O7e=a("strong"),v0r=o("deit"),F0r=o(" \u2014 "),wY=a("a"),T0r=o("TFDeiTForImageClassification"),M0r=o(" or "),AY=a("a"),E0r=o("TFDeiTForImageClassificationWithTeacher"),C0r=o(" (DeiT model)"),w0r=l(),uM=a("li"),V7e=a("strong"),A0r=o("regnet"),L0r=o(" \u2014 "),LY=a("a"),y0r=o("TFRegNetForImageClassification"),x0r=o(" (RegNet model)"),$0r=l(),bM=a("li"),X7e=a("strong"),k0r=o("resnet"),S0r=o(" \u2014 "),yY=a("a"),R0r=o("TFResNetForImageClassification"),P0r=o(" (ResNet model)"),B0r=l(),vM=a("li"),z7e=a("strong"),I0r=o("segformer"),N0r=o(" \u2014 "),xY=a("a"),q0r=o("TFSegformerForImageClassification"),j0r=o(" (SegFormer model)"),D0r=l(),FM=a("li"),Q7e=a("strong"),G0r=o("swin"),O0r=o(" \u2014 "),$Y=a("a"),V0r=o("TFSwinForImageClassification"),X0r=o(" (Swin Transformer model)"),z0r=l(),TM=a("li"),W7e=a("strong"),Q0r=o("vit"),W0r=o(" \u2014 "),kY=a("a"),H0r=o("TFViTForImageClassification"),U0r=o(" (ViT model)"),J0r=l(),F(MM.$$.fragment),tQe=l(),vc=a("h2"),EM=a("a"),H7e=a("span"),F(Mx.$$.fragment),Y0r=l(),U7e=a("span"),K0r=o("TFAutoModelForMaskedLM"),aQe=l(),sr=a("div"),F(Ex.$$.fragment),Z0r=l(),Fc=a("p"),ewr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),SY=a("a"),owr=o("from_pretrained()"),rwr=o(" class method or the "),RY=a("a"),twr=o("from_config()"),awr=o(` class
method.`),nwr=l(),Cx=a("p"),swr=o("This class cannot be instantiated directly using "),J7e=a("code"),lwr=o("__init__()"),iwr=o(" (throws an error)."),dwr=l(),Nt=a("div"),F(wx.$$.fragment),cwr=l(),Y7e=a("p"),fwr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),mwr=l(),Tc=a("p"),gwr=o(`Note:
Loading a model from its configuration file does `),K7e=a("strong"),hwr=o("not"),pwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=a("a"),_wr=o("from_pretrained()"),uwr=o(" to load the model weights."),bwr=l(),F(CM.$$.fragment),vwr=l(),Pr=a("div"),F(Ax.$$.fragment),Fwr=l(),Z7e=a("p"),Twr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Mwr=l(),mn=a("p"),Ewr=o("The model class to instantiate is selected based on the "),e9e=a("code"),Cwr=o("model_type"),wwr=o(` property of the config object (either
passed as an argument or loaded from `),o9e=a("code"),Awr=o("pretrained_model_name_or_path"),Lwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r9e=a("code"),ywr=o("pretrained_model_name_or_path"),xwr=o(":"),$wr=l(),ie=a("ul"),wM=a("li"),t9e=a("strong"),kwr=o("albert"),Swr=o(" \u2014 "),BY=a("a"),Rwr=o("TFAlbertForMaskedLM"),Pwr=o(" (ALBERT model)"),Bwr=l(),AM=a("li"),a9e=a("strong"),Iwr=o("bert"),Nwr=o(" \u2014 "),IY=a("a"),qwr=o("TFBertForMaskedLM"),jwr=o(" (BERT model)"),Dwr=l(),LM=a("li"),n9e=a("strong"),Gwr=o("camembert"),Owr=o(" \u2014 "),NY=a("a"),Vwr=o("TFCamembertForMaskedLM"),Xwr=o(" (CamemBERT model)"),zwr=l(),yM=a("li"),s9e=a("strong"),Qwr=o("convbert"),Wwr=o(" \u2014 "),qY=a("a"),Hwr=o("TFConvBertForMaskedLM"),Uwr=o(" (ConvBERT model)"),Jwr=l(),xM=a("li"),l9e=a("strong"),Ywr=o("deberta"),Kwr=o(" \u2014 "),jY=a("a"),Zwr=o("TFDebertaForMaskedLM"),eAr=o(" (DeBERTa model)"),oAr=l(),$M=a("li"),i9e=a("strong"),rAr=o("deberta-v2"),tAr=o(" \u2014 "),DY=a("a"),aAr=o("TFDebertaV2ForMaskedLM"),nAr=o(" (DeBERTa-v2 model)"),sAr=l(),kM=a("li"),d9e=a("strong"),lAr=o("distilbert"),iAr=o(" \u2014 "),GY=a("a"),dAr=o("TFDistilBertForMaskedLM"),cAr=o(" (DistilBERT model)"),fAr=l(),SM=a("li"),c9e=a("strong"),mAr=o("electra"),gAr=o(" \u2014 "),OY=a("a"),hAr=o("TFElectraForMaskedLM"),pAr=o(" (ELECTRA model)"),_Ar=l(),RM=a("li"),f9e=a("strong"),uAr=o("flaubert"),bAr=o(" \u2014 "),VY=a("a"),vAr=o("TFFlaubertWithLMHeadModel"),FAr=o(" (FlauBERT model)"),TAr=l(),PM=a("li"),m9e=a("strong"),MAr=o("funnel"),EAr=o(" \u2014 "),XY=a("a"),CAr=o("TFFunnelForMaskedLM"),wAr=o(" (Funnel Transformer model)"),AAr=l(),BM=a("li"),g9e=a("strong"),LAr=o("layoutlm"),yAr=o(" \u2014 "),zY=a("a"),xAr=o("TFLayoutLMForMaskedLM"),$Ar=o(" (LayoutLM model)"),kAr=l(),IM=a("li"),h9e=a("strong"),SAr=o("longformer"),RAr=o(" \u2014 "),QY=a("a"),PAr=o("TFLongformerForMaskedLM"),BAr=o(" (Longformer model)"),IAr=l(),NM=a("li"),p9e=a("strong"),NAr=o("mobilebert"),qAr=o(" \u2014 "),WY=a("a"),jAr=o("TFMobileBertForMaskedLM"),DAr=o(" (MobileBERT model)"),GAr=l(),qM=a("li"),_9e=a("strong"),OAr=o("mpnet"),VAr=o(" \u2014 "),HY=a("a"),XAr=o("TFMPNetForMaskedLM"),zAr=o(" (MPNet model)"),QAr=l(),jM=a("li"),u9e=a("strong"),WAr=o("rembert"),HAr=o(" \u2014 "),UY=a("a"),UAr=o("TFRemBertForMaskedLM"),JAr=o(" (RemBERT model)"),YAr=l(),DM=a("li"),b9e=a("strong"),KAr=o("roberta"),ZAr=o(" \u2014 "),JY=a("a"),eLr=o("TFRobertaForMaskedLM"),oLr=o(" (RoBERTa model)"),rLr=l(),GM=a("li"),v9e=a("strong"),tLr=o("roformer"),aLr=o(" \u2014 "),YY=a("a"),nLr=o("TFRoFormerForMaskedLM"),sLr=o(" (RoFormer model)"),lLr=l(),OM=a("li"),F9e=a("strong"),iLr=o("tapas"),dLr=o(" \u2014 "),KY=a("a"),cLr=o("TFTapasForMaskedLM"),fLr=o(" (TAPAS model)"),mLr=l(),VM=a("li"),T9e=a("strong"),gLr=o("xlm"),hLr=o(" \u2014 "),ZY=a("a"),pLr=o("TFXLMWithLMHeadModel"),_Lr=o(" (XLM model)"),uLr=l(),XM=a("li"),M9e=a("strong"),bLr=o("xlm-roberta"),vLr=o(" \u2014 "),eK=a("a"),FLr=o("TFXLMRobertaForMaskedLM"),TLr=o(" (XLM-RoBERTa model)"),MLr=l(),F(zM.$$.fragment),nQe=l(),Mc=a("h2"),QM=a("a"),E9e=a("span"),F(Lx.$$.fragment),ELr=l(),C9e=a("span"),CLr=o("TFAutoModelForSeq2SeqLM"),sQe=l(),lr=a("div"),F(yx.$$.fragment),wLr=l(),Ec=a("p"),ALr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),oK=a("a"),LLr=o("from_pretrained()"),yLr=o(" class method or the "),rK=a("a"),xLr=o("from_config()"),$Lr=o(` class
method.`),kLr=l(),xx=a("p"),SLr=o("This class cannot be instantiated directly using "),w9e=a("code"),RLr=o("__init__()"),PLr=o(" (throws an error)."),BLr=l(),qt=a("div"),F($x.$$.fragment),ILr=l(),A9e=a("p"),NLr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),qLr=l(),Cc=a("p"),jLr=o(`Note:
Loading a model from its configuration file does `),L9e=a("strong"),DLr=o("not"),GLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=a("a"),OLr=o("from_pretrained()"),VLr=o(" to load the model weights."),XLr=l(),F(WM.$$.fragment),zLr=l(),Br=a("div"),F(kx.$$.fragment),QLr=l(),y9e=a("p"),WLr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),HLr=l(),gn=a("p"),ULr=o("The model class to instantiate is selected based on the "),x9e=a("code"),JLr=o("model_type"),YLr=o(` property of the config object (either
passed as an argument or loaded from `),$9e=a("code"),KLr=o("pretrained_model_name_or_path"),ZLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k9e=a("code"),eyr=o("pretrained_model_name_or_path"),oyr=o(":"),ryr=l(),ye=a("ul"),HM=a("li"),S9e=a("strong"),tyr=o("bart"),ayr=o(" \u2014 "),aK=a("a"),nyr=o("TFBartForConditionalGeneration"),syr=o(" (BART model)"),lyr=l(),UM=a("li"),R9e=a("strong"),iyr=o("blenderbot"),dyr=o(" \u2014 "),nK=a("a"),cyr=o("TFBlenderbotForConditionalGeneration"),fyr=o(" (Blenderbot model)"),myr=l(),JM=a("li"),P9e=a("strong"),gyr=o("blenderbot-small"),hyr=o(" \u2014 "),sK=a("a"),pyr=o("TFBlenderbotSmallForConditionalGeneration"),_yr=o(" (BlenderbotSmall model)"),uyr=l(),YM=a("li"),B9e=a("strong"),byr=o("encoder-decoder"),vyr=o(" \u2014 "),lK=a("a"),Fyr=o("TFEncoderDecoderModel"),Tyr=o(" (Encoder decoder model)"),Myr=l(),KM=a("li"),I9e=a("strong"),Eyr=o("led"),Cyr=o(" \u2014 "),iK=a("a"),wyr=o("TFLEDForConditionalGeneration"),Ayr=o(" (LED model)"),Lyr=l(),ZM=a("li"),N9e=a("strong"),yyr=o("marian"),xyr=o(" \u2014 "),dK=a("a"),$yr=o("TFMarianMTModel"),kyr=o(" (Marian model)"),Syr=l(),eE=a("li"),q9e=a("strong"),Ryr=o("mbart"),Pyr=o(" \u2014 "),cK=a("a"),Byr=o("TFMBartForConditionalGeneration"),Iyr=o(" (mBART model)"),Nyr=l(),oE=a("li"),j9e=a("strong"),qyr=o("mt5"),jyr=o(" \u2014 "),fK=a("a"),Dyr=o("TFMT5ForConditionalGeneration"),Gyr=o(" (MT5 model)"),Oyr=l(),rE=a("li"),D9e=a("strong"),Vyr=o("pegasus"),Xyr=o(" \u2014 "),mK=a("a"),zyr=o("TFPegasusForConditionalGeneration"),Qyr=o(" (Pegasus model)"),Wyr=l(),tE=a("li"),G9e=a("strong"),Hyr=o("t5"),Uyr=o(" \u2014 "),gK=a("a"),Jyr=o("TFT5ForConditionalGeneration"),Yyr=o(" (T5 model)"),Kyr=l(),F(aE.$$.fragment),lQe=l(),wc=a("h2"),nE=a("a"),O9e=a("span"),F(Sx.$$.fragment),Zyr=l(),V9e=a("span"),e8r=o("TFAutoModelForSequenceClassification"),iQe=l(),ir=a("div"),F(Rx.$$.fragment),o8r=l(),Ac=a("p"),r8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hK=a("a"),t8r=o("from_pretrained()"),a8r=o(" class method or the "),pK=a("a"),n8r=o("from_config()"),s8r=o(` class
method.`),l8r=l(),Px=a("p"),i8r=o("This class cannot be instantiated directly using "),X9e=a("code"),d8r=o("__init__()"),c8r=o(" (throws an error)."),f8r=l(),jt=a("div"),F(Bx.$$.fragment),m8r=l(),z9e=a("p"),g8r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),h8r=l(),Lc=a("p"),p8r=o(`Note:
Loading a model from its configuration file does `),Q9e=a("strong"),_8r=o("not"),u8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=a("a"),b8r=o("from_pretrained()"),v8r=o(" to load the model weights."),F8r=l(),F(sE.$$.fragment),T8r=l(),Ir=a("div"),F(Ix.$$.fragment),M8r=l(),W9e=a("p"),E8r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),C8r=l(),hn=a("p"),w8r=o("The model class to instantiate is selected based on the "),H9e=a("code"),A8r=o("model_type"),L8r=o(` property of the config object (either
passed as an argument or loaded from `),U9e=a("code"),y8r=o("pretrained_model_name_or_path"),x8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J9e=a("code"),$8r=o("pretrained_model_name_or_path"),k8r=o(":"),S8r=l(),te=a("ul"),lE=a("li"),Y9e=a("strong"),R8r=o("albert"),P8r=o(" \u2014 "),uK=a("a"),B8r=o("TFAlbertForSequenceClassification"),I8r=o(" (ALBERT model)"),N8r=l(),iE=a("li"),K9e=a("strong"),q8r=o("bert"),j8r=o(" \u2014 "),bK=a("a"),D8r=o("TFBertForSequenceClassification"),G8r=o(" (BERT model)"),O8r=l(),dE=a("li"),Z9e=a("strong"),V8r=o("camembert"),X8r=o(" \u2014 "),vK=a("a"),z8r=o("TFCamembertForSequenceClassification"),Q8r=o(" (CamemBERT model)"),W8r=l(),cE=a("li"),eMe=a("strong"),H8r=o("convbert"),U8r=o(" \u2014 "),FK=a("a"),J8r=o("TFConvBertForSequenceClassification"),Y8r=o(" (ConvBERT model)"),K8r=l(),fE=a("li"),oMe=a("strong"),Z8r=o("ctrl"),exr=o(" \u2014 "),TK=a("a"),oxr=o("TFCTRLForSequenceClassification"),rxr=o(" (CTRL model)"),txr=l(),mE=a("li"),rMe=a("strong"),axr=o("deberta"),nxr=o(" \u2014 "),MK=a("a"),sxr=o("TFDebertaForSequenceClassification"),lxr=o(" (DeBERTa model)"),ixr=l(),gE=a("li"),tMe=a("strong"),dxr=o("deberta-v2"),cxr=o(" \u2014 "),EK=a("a"),fxr=o("TFDebertaV2ForSequenceClassification"),mxr=o(" (DeBERTa-v2 model)"),gxr=l(),hE=a("li"),aMe=a("strong"),hxr=o("distilbert"),pxr=o(" \u2014 "),CK=a("a"),_xr=o("TFDistilBertForSequenceClassification"),uxr=o(" (DistilBERT model)"),bxr=l(),pE=a("li"),nMe=a("strong"),vxr=o("electra"),Fxr=o(" \u2014 "),wK=a("a"),Txr=o("TFElectraForSequenceClassification"),Mxr=o(" (ELECTRA model)"),Exr=l(),_E=a("li"),sMe=a("strong"),Cxr=o("flaubert"),wxr=o(" \u2014 "),AK=a("a"),Axr=o("TFFlaubertForSequenceClassification"),Lxr=o(" (FlauBERT model)"),yxr=l(),uE=a("li"),lMe=a("strong"),xxr=o("funnel"),$xr=o(" \u2014 "),LK=a("a"),kxr=o("TFFunnelForSequenceClassification"),Sxr=o(" (Funnel Transformer model)"),Rxr=l(),bE=a("li"),iMe=a("strong"),Pxr=o("gpt2"),Bxr=o(" \u2014 "),yK=a("a"),Ixr=o("TFGPT2ForSequenceClassification"),Nxr=o(" (OpenAI GPT-2 model)"),qxr=l(),vE=a("li"),dMe=a("strong"),jxr=o("gptj"),Dxr=o(" \u2014 "),xK=a("a"),Gxr=o("TFGPTJForSequenceClassification"),Oxr=o(" (GPT-J model)"),Vxr=l(),FE=a("li"),cMe=a("strong"),Xxr=o("layoutlm"),zxr=o(" \u2014 "),$K=a("a"),Qxr=o("TFLayoutLMForSequenceClassification"),Wxr=o(" (LayoutLM model)"),Hxr=l(),TE=a("li"),fMe=a("strong"),Uxr=o("longformer"),Jxr=o(" \u2014 "),kK=a("a"),Yxr=o("TFLongformerForSequenceClassification"),Kxr=o(" (Longformer model)"),Zxr=l(),ME=a("li"),mMe=a("strong"),e$r=o("mobilebert"),o$r=o(" \u2014 "),SK=a("a"),r$r=o("TFMobileBertForSequenceClassification"),t$r=o(" (MobileBERT model)"),a$r=l(),EE=a("li"),gMe=a("strong"),n$r=o("mpnet"),s$r=o(" \u2014 "),RK=a("a"),l$r=o("TFMPNetForSequenceClassification"),i$r=o(" (MPNet model)"),d$r=l(),CE=a("li"),hMe=a("strong"),c$r=o("openai-gpt"),f$r=o(" \u2014 "),PK=a("a"),m$r=o("TFOpenAIGPTForSequenceClassification"),g$r=o(" (OpenAI GPT model)"),h$r=l(),wE=a("li"),pMe=a("strong"),p$r=o("rembert"),_$r=o(" \u2014 "),BK=a("a"),u$r=o("TFRemBertForSequenceClassification"),b$r=o(" (RemBERT model)"),v$r=l(),AE=a("li"),_Me=a("strong"),F$r=o("roberta"),T$r=o(" \u2014 "),IK=a("a"),M$r=o("TFRobertaForSequenceClassification"),E$r=o(" (RoBERTa model)"),C$r=l(),LE=a("li"),uMe=a("strong"),w$r=o("roformer"),A$r=o(" \u2014 "),NK=a("a"),L$r=o("TFRoFormerForSequenceClassification"),y$r=o(" (RoFormer model)"),x$r=l(),yE=a("li"),bMe=a("strong"),$$r=o("tapas"),k$r=o(" \u2014 "),qK=a("a"),S$r=o("TFTapasForSequenceClassification"),R$r=o(" (TAPAS model)"),P$r=l(),xE=a("li"),vMe=a("strong"),B$r=o("transfo-xl"),I$r=o(" \u2014 "),jK=a("a"),N$r=o("TFTransfoXLForSequenceClassification"),q$r=o(" (Transformer-XL model)"),j$r=l(),$E=a("li"),FMe=a("strong"),D$r=o("xlm"),G$r=o(" \u2014 "),DK=a("a"),O$r=o("TFXLMForSequenceClassification"),V$r=o(" (XLM model)"),X$r=l(),kE=a("li"),TMe=a("strong"),z$r=o("xlm-roberta"),Q$r=o(" \u2014 "),GK=a("a"),W$r=o("TFXLMRobertaForSequenceClassification"),H$r=o(" (XLM-RoBERTa model)"),U$r=l(),SE=a("li"),MMe=a("strong"),J$r=o("xlnet"),Y$r=o(" \u2014 "),OK=a("a"),K$r=o("TFXLNetForSequenceClassification"),Z$r=o(" (XLNet model)"),ekr=l(),F(RE.$$.fragment),dQe=l(),yc=a("h2"),PE=a("a"),EMe=a("span"),F(Nx.$$.fragment),okr=l(),CMe=a("span"),rkr=o("TFAutoModelForMultipleChoice"),cQe=l(),dr=a("div"),F(qx.$$.fragment),tkr=l(),xc=a("p"),akr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),VK=a("a"),nkr=o("from_pretrained()"),skr=o(" class method or the "),XK=a("a"),lkr=o("from_config()"),ikr=o(` class
method.`),dkr=l(),jx=a("p"),ckr=o("This class cannot be instantiated directly using "),wMe=a("code"),fkr=o("__init__()"),mkr=o(" (throws an error)."),gkr=l(),Dt=a("div"),F(Dx.$$.fragment),hkr=l(),AMe=a("p"),pkr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),_kr=l(),$c=a("p"),ukr=o(`Note:
Loading a model from its configuration file does `),LMe=a("strong"),bkr=o("not"),vkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=a("a"),Fkr=o("from_pretrained()"),Tkr=o(" to load the model weights."),Mkr=l(),F(BE.$$.fragment),Ekr=l(),Nr=a("div"),F(Gx.$$.fragment),Ckr=l(),yMe=a("p"),wkr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Akr=l(),pn=a("p"),Lkr=o("The model class to instantiate is selected based on the "),xMe=a("code"),ykr=o("model_type"),xkr=o(` property of the config object (either
passed as an argument or loaded from `),$Me=a("code"),$kr=o("pretrained_model_name_or_path"),kkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kMe=a("code"),Skr=o("pretrained_model_name_or_path"),Rkr=o(":"),Pkr=l(),be=a("ul"),IE=a("li"),SMe=a("strong"),Bkr=o("albert"),Ikr=o(" \u2014 "),QK=a("a"),Nkr=o("TFAlbertForMultipleChoice"),qkr=o(" (ALBERT model)"),jkr=l(),NE=a("li"),RMe=a("strong"),Dkr=o("bert"),Gkr=o(" \u2014 "),WK=a("a"),Okr=o("TFBertForMultipleChoice"),Vkr=o(" (BERT model)"),Xkr=l(),qE=a("li"),PMe=a("strong"),zkr=o("camembert"),Qkr=o(" \u2014 "),HK=a("a"),Wkr=o("TFCamembertForMultipleChoice"),Hkr=o(" (CamemBERT model)"),Ukr=l(),jE=a("li"),BMe=a("strong"),Jkr=o("convbert"),Ykr=o(" \u2014 "),UK=a("a"),Kkr=o("TFConvBertForMultipleChoice"),Zkr=o(" (ConvBERT model)"),eSr=l(),DE=a("li"),IMe=a("strong"),oSr=o("distilbert"),rSr=o(" \u2014 "),JK=a("a"),tSr=o("TFDistilBertForMultipleChoice"),aSr=o(" (DistilBERT model)"),nSr=l(),GE=a("li"),NMe=a("strong"),sSr=o("electra"),lSr=o(" \u2014 "),YK=a("a"),iSr=o("TFElectraForMultipleChoice"),dSr=o(" (ELECTRA model)"),cSr=l(),OE=a("li"),qMe=a("strong"),fSr=o("flaubert"),mSr=o(" \u2014 "),KK=a("a"),gSr=o("TFFlaubertForMultipleChoice"),hSr=o(" (FlauBERT model)"),pSr=l(),VE=a("li"),jMe=a("strong"),_Sr=o("funnel"),uSr=o(" \u2014 "),ZK=a("a"),bSr=o("TFFunnelForMultipleChoice"),vSr=o(" (Funnel Transformer model)"),FSr=l(),XE=a("li"),DMe=a("strong"),TSr=o("longformer"),MSr=o(" \u2014 "),eZ=a("a"),ESr=o("TFLongformerForMultipleChoice"),CSr=o(" (Longformer model)"),wSr=l(),zE=a("li"),GMe=a("strong"),ASr=o("mobilebert"),LSr=o(" \u2014 "),oZ=a("a"),ySr=o("TFMobileBertForMultipleChoice"),xSr=o(" (MobileBERT model)"),$Sr=l(),QE=a("li"),OMe=a("strong"),kSr=o("mpnet"),SSr=o(" \u2014 "),rZ=a("a"),RSr=o("TFMPNetForMultipleChoice"),PSr=o(" (MPNet model)"),BSr=l(),WE=a("li"),VMe=a("strong"),ISr=o("rembert"),NSr=o(" \u2014 "),tZ=a("a"),qSr=o("TFRemBertForMultipleChoice"),jSr=o(" (RemBERT model)"),DSr=l(),HE=a("li"),XMe=a("strong"),GSr=o("roberta"),OSr=o(" \u2014 "),aZ=a("a"),VSr=o("TFRobertaForMultipleChoice"),XSr=o(" (RoBERTa model)"),zSr=l(),UE=a("li"),zMe=a("strong"),QSr=o("roformer"),WSr=o(" \u2014 "),nZ=a("a"),HSr=o("TFRoFormerForMultipleChoice"),USr=o(" (RoFormer model)"),JSr=l(),JE=a("li"),QMe=a("strong"),YSr=o("xlm"),KSr=o(" \u2014 "),sZ=a("a"),ZSr=o("TFXLMForMultipleChoice"),eRr=o(" (XLM model)"),oRr=l(),YE=a("li"),WMe=a("strong"),rRr=o("xlm-roberta"),tRr=o(" \u2014 "),lZ=a("a"),aRr=o("TFXLMRobertaForMultipleChoice"),nRr=o(" (XLM-RoBERTa model)"),sRr=l(),KE=a("li"),HMe=a("strong"),lRr=o("xlnet"),iRr=o(" \u2014 "),iZ=a("a"),dRr=o("TFXLNetForMultipleChoice"),cRr=o(" (XLNet model)"),fRr=l(),F(ZE.$$.fragment),fQe=l(),kc=a("h2"),eC=a("a"),UMe=a("span"),F(Ox.$$.fragment),mRr=l(),JMe=a("span"),gRr=o("TFAutoModelForNextSentencePrediction"),mQe=l(),cr=a("div"),F(Vx.$$.fragment),hRr=l(),Sc=a("p"),pRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),dZ=a("a"),_Rr=o("from_pretrained()"),uRr=o(" class method or the "),cZ=a("a"),bRr=o("from_config()"),vRr=o(` class
method.`),FRr=l(),Xx=a("p"),TRr=o("This class cannot be instantiated directly using "),YMe=a("code"),MRr=o("__init__()"),ERr=o(" (throws an error)."),CRr=l(),Gt=a("div"),F(zx.$$.fragment),wRr=l(),KMe=a("p"),ARr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),LRr=l(),Rc=a("p"),yRr=o(`Note:
Loading a model from its configuration file does `),ZMe=a("strong"),xRr=o("not"),$Rr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=a("a"),kRr=o("from_pretrained()"),SRr=o(" to load the model weights."),RRr=l(),F(oC.$$.fragment),PRr=l(),qr=a("div"),F(Qx.$$.fragment),BRr=l(),eEe=a("p"),IRr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),NRr=l(),_n=a("p"),qRr=o("The model class to instantiate is selected based on the "),oEe=a("code"),jRr=o("model_type"),DRr=o(` property of the config object (either
passed as an argument or loaded from `),rEe=a("code"),GRr=o("pretrained_model_name_or_path"),ORr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=a("code"),VRr=o("pretrained_model_name_or_path"),XRr=o(":"),zRr=l(),Wx=a("ul"),rC=a("li"),aEe=a("strong"),QRr=o("bert"),WRr=o(" \u2014 "),mZ=a("a"),HRr=o("TFBertForNextSentencePrediction"),URr=o(" (BERT model)"),JRr=l(),tC=a("li"),nEe=a("strong"),YRr=o("mobilebert"),KRr=o(" \u2014 "),gZ=a("a"),ZRr=o("TFMobileBertForNextSentencePrediction"),ePr=o(" (MobileBERT model)"),oPr=l(),F(aC.$$.fragment),gQe=l(),Pc=a("h2"),nC=a("a"),sEe=a("span"),F(Hx.$$.fragment),rPr=l(),lEe=a("span"),tPr=o("TFAutoModelForTableQuestionAnswering"),hQe=l(),fr=a("div"),F(Ux.$$.fragment),aPr=l(),Bc=a("p"),nPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),hZ=a("a"),sPr=o("from_pretrained()"),lPr=o(" class method or the "),pZ=a("a"),iPr=o("from_config()"),dPr=o(` class
method.`),cPr=l(),Jx=a("p"),fPr=o("This class cannot be instantiated directly using "),iEe=a("code"),mPr=o("__init__()"),gPr=o(" (throws an error)."),hPr=l(),Ot=a("div"),F(Yx.$$.fragment),pPr=l(),dEe=a("p"),_Pr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),uPr=l(),Ic=a("p"),bPr=o(`Note:
Loading a model from its configuration file does `),cEe=a("strong"),vPr=o("not"),FPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=a("a"),TPr=o("from_pretrained()"),MPr=o(" to load the model weights."),EPr=l(),F(sC.$$.fragment),CPr=l(),jr=a("div"),F(Kx.$$.fragment),wPr=l(),fEe=a("p"),APr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),LPr=l(),un=a("p"),yPr=o("The model class to instantiate is selected based on the "),mEe=a("code"),xPr=o("model_type"),$Pr=o(` property of the config object (either
passed as an argument or loaded from `),gEe=a("code"),kPr=o("pretrained_model_name_or_path"),SPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hEe=a("code"),RPr=o("pretrained_model_name_or_path"),PPr=o(":"),BPr=l(),pEe=a("ul"),lC=a("li"),_Ee=a("strong"),IPr=o("tapas"),NPr=o(" \u2014 "),uZ=a("a"),qPr=o("TFTapasForQuestionAnswering"),jPr=o(" (TAPAS model)"),DPr=l(),F(iC.$$.fragment),pQe=l(),Nc=a("h2"),dC=a("a"),uEe=a("span"),F(Zx.$$.fragment),GPr=l(),bEe=a("span"),OPr=o("TFAutoModelForTokenClassification"),_Qe=l(),mr=a("div"),F(e$.$$.fragment),VPr=l(),qc=a("p"),XPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bZ=a("a"),zPr=o("from_pretrained()"),QPr=o(" class method or the "),vZ=a("a"),WPr=o("from_config()"),HPr=o(` class
method.`),UPr=l(),o$=a("p"),JPr=o("This class cannot be instantiated directly using "),vEe=a("code"),YPr=o("__init__()"),KPr=o(" (throws an error)."),ZPr=l(),Vt=a("div"),F(r$.$$.fragment),eBr=l(),FEe=a("p"),oBr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),rBr=l(),jc=a("p"),tBr=o(`Note:
Loading a model from its configuration file does `),TEe=a("strong"),aBr=o("not"),nBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FZ=a("a"),sBr=o("from_pretrained()"),lBr=o(" to load the model weights."),iBr=l(),F(cC.$$.fragment),dBr=l(),Dr=a("div"),F(t$.$$.fragment),cBr=l(),MEe=a("p"),fBr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),mBr=l(),bn=a("p"),gBr=o("The model class to instantiate is selected based on the "),EEe=a("code"),hBr=o("model_type"),pBr=o(` property of the config object (either
passed as an argument or loaded from `),CEe=a("code"),_Br=o("pretrained_model_name_or_path"),uBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wEe=a("code"),bBr=o("pretrained_model_name_or_path"),vBr=o(":"),FBr=l(),de=a("ul"),fC=a("li"),AEe=a("strong"),TBr=o("albert"),MBr=o(" \u2014 "),TZ=a("a"),EBr=o("TFAlbertForTokenClassification"),CBr=o(" (ALBERT model)"),wBr=l(),mC=a("li"),LEe=a("strong"),ABr=o("bert"),LBr=o(" \u2014 "),MZ=a("a"),yBr=o("TFBertForTokenClassification"),xBr=o(" (BERT model)"),$Br=l(),gC=a("li"),yEe=a("strong"),kBr=o("camembert"),SBr=o(" \u2014 "),EZ=a("a"),RBr=o("TFCamembertForTokenClassification"),PBr=o(" (CamemBERT model)"),BBr=l(),hC=a("li"),xEe=a("strong"),IBr=o("convbert"),NBr=o(" \u2014 "),CZ=a("a"),qBr=o("TFConvBertForTokenClassification"),jBr=o(" (ConvBERT model)"),DBr=l(),pC=a("li"),$Ee=a("strong"),GBr=o("deberta"),OBr=o(" \u2014 "),wZ=a("a"),VBr=o("TFDebertaForTokenClassification"),XBr=o(" (DeBERTa model)"),zBr=l(),_C=a("li"),kEe=a("strong"),QBr=o("deberta-v2"),WBr=o(" \u2014 "),AZ=a("a"),HBr=o("TFDebertaV2ForTokenClassification"),UBr=o(" (DeBERTa-v2 model)"),JBr=l(),uC=a("li"),SEe=a("strong"),YBr=o("distilbert"),KBr=o(" \u2014 "),LZ=a("a"),ZBr=o("TFDistilBertForTokenClassification"),eIr=o(" (DistilBERT model)"),oIr=l(),bC=a("li"),REe=a("strong"),rIr=o("electra"),tIr=o(" \u2014 "),yZ=a("a"),aIr=o("TFElectraForTokenClassification"),nIr=o(" (ELECTRA model)"),sIr=l(),vC=a("li"),PEe=a("strong"),lIr=o("flaubert"),iIr=o(" \u2014 "),xZ=a("a"),dIr=o("TFFlaubertForTokenClassification"),cIr=o(" (FlauBERT model)"),fIr=l(),FC=a("li"),BEe=a("strong"),mIr=o("funnel"),gIr=o(" \u2014 "),$Z=a("a"),hIr=o("TFFunnelForTokenClassification"),pIr=o(" (Funnel Transformer model)"),_Ir=l(),TC=a("li"),IEe=a("strong"),uIr=o("layoutlm"),bIr=o(" \u2014 "),kZ=a("a"),vIr=o("TFLayoutLMForTokenClassification"),FIr=o(" (LayoutLM model)"),TIr=l(),MC=a("li"),NEe=a("strong"),MIr=o("longformer"),EIr=o(" \u2014 "),SZ=a("a"),CIr=o("TFLongformerForTokenClassification"),wIr=o(" (Longformer model)"),AIr=l(),EC=a("li"),qEe=a("strong"),LIr=o("mobilebert"),yIr=o(" \u2014 "),RZ=a("a"),xIr=o("TFMobileBertForTokenClassification"),$Ir=o(" (MobileBERT model)"),kIr=l(),CC=a("li"),jEe=a("strong"),SIr=o("mpnet"),RIr=o(" \u2014 "),PZ=a("a"),PIr=o("TFMPNetForTokenClassification"),BIr=o(" (MPNet model)"),IIr=l(),wC=a("li"),DEe=a("strong"),NIr=o("rembert"),qIr=o(" \u2014 "),BZ=a("a"),jIr=o("TFRemBertForTokenClassification"),DIr=o(" (RemBERT model)"),GIr=l(),AC=a("li"),GEe=a("strong"),OIr=o("roberta"),VIr=o(" \u2014 "),IZ=a("a"),XIr=o("TFRobertaForTokenClassification"),zIr=o(" (RoBERTa model)"),QIr=l(),LC=a("li"),OEe=a("strong"),WIr=o("roformer"),HIr=o(" \u2014 "),NZ=a("a"),UIr=o("TFRoFormerForTokenClassification"),JIr=o(" (RoFormer model)"),YIr=l(),yC=a("li"),VEe=a("strong"),KIr=o("xlm"),ZIr=o(" \u2014 "),qZ=a("a"),eNr=o("TFXLMForTokenClassification"),oNr=o(" (XLM model)"),rNr=l(),xC=a("li"),XEe=a("strong"),tNr=o("xlm-roberta"),aNr=o(" \u2014 "),jZ=a("a"),nNr=o("TFXLMRobertaForTokenClassification"),sNr=o(" (XLM-RoBERTa model)"),lNr=l(),$C=a("li"),zEe=a("strong"),iNr=o("xlnet"),dNr=o(" \u2014 "),DZ=a("a"),cNr=o("TFXLNetForTokenClassification"),fNr=o(" (XLNet model)"),mNr=l(),F(kC.$$.fragment),uQe=l(),Dc=a("h2"),SC=a("a"),QEe=a("span"),F(a$.$$.fragment),gNr=l(),WEe=a("span"),hNr=o("TFAutoModelForQuestionAnswering"),bQe=l(),gr=a("div"),F(n$.$$.fragment),pNr=l(),Gc=a("p"),_Nr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GZ=a("a"),uNr=o("from_pretrained()"),bNr=o(" class method or the "),OZ=a("a"),vNr=o("from_config()"),FNr=o(` class
method.`),TNr=l(),s$=a("p"),MNr=o("This class cannot be instantiated directly using "),HEe=a("code"),ENr=o("__init__()"),CNr=o(" (throws an error)."),wNr=l(),Xt=a("div"),F(l$.$$.fragment),ANr=l(),UEe=a("p"),LNr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),yNr=l(),Oc=a("p"),xNr=o(`Note:
Loading a model from its configuration file does `),JEe=a("strong"),$Nr=o("not"),kNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VZ=a("a"),SNr=o("from_pretrained()"),RNr=o(" to load the model weights."),PNr=l(),F(RC.$$.fragment),BNr=l(),Gr=a("div"),F(i$.$$.fragment),INr=l(),YEe=a("p"),NNr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),qNr=l(),vn=a("p"),jNr=o("The model class to instantiate is selected based on the "),KEe=a("code"),DNr=o("model_type"),GNr=o(` property of the config object (either
passed as an argument or loaded from `),ZEe=a("code"),ONr=o("pretrained_model_name_or_path"),VNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eCe=a("code"),XNr=o("pretrained_model_name_or_path"),zNr=o(":"),QNr=l(),ce=a("ul"),PC=a("li"),oCe=a("strong"),WNr=o("albert"),HNr=o(" \u2014 "),XZ=a("a"),UNr=o("TFAlbertForQuestionAnswering"),JNr=o(" (ALBERT model)"),YNr=l(),BC=a("li"),rCe=a("strong"),KNr=o("bert"),ZNr=o(" \u2014 "),zZ=a("a"),eqr=o("TFBertForQuestionAnswering"),oqr=o(" (BERT model)"),rqr=l(),IC=a("li"),tCe=a("strong"),tqr=o("camembert"),aqr=o(" \u2014 "),QZ=a("a"),nqr=o("TFCamembertForQuestionAnswering"),sqr=o(" (CamemBERT model)"),lqr=l(),NC=a("li"),aCe=a("strong"),iqr=o("convbert"),dqr=o(" \u2014 "),WZ=a("a"),cqr=o("TFConvBertForQuestionAnswering"),fqr=o(" (ConvBERT model)"),mqr=l(),qC=a("li"),nCe=a("strong"),gqr=o("deberta"),hqr=o(" \u2014 "),HZ=a("a"),pqr=o("TFDebertaForQuestionAnswering"),_qr=o(" (DeBERTa model)"),uqr=l(),jC=a("li"),sCe=a("strong"),bqr=o("deberta-v2"),vqr=o(" \u2014 "),UZ=a("a"),Fqr=o("TFDebertaV2ForQuestionAnswering"),Tqr=o(" (DeBERTa-v2 model)"),Mqr=l(),DC=a("li"),lCe=a("strong"),Eqr=o("distilbert"),Cqr=o(" \u2014 "),JZ=a("a"),wqr=o("TFDistilBertForQuestionAnswering"),Aqr=o(" (DistilBERT model)"),Lqr=l(),GC=a("li"),iCe=a("strong"),yqr=o("electra"),xqr=o(" \u2014 "),YZ=a("a"),$qr=o("TFElectraForQuestionAnswering"),kqr=o(" (ELECTRA model)"),Sqr=l(),OC=a("li"),dCe=a("strong"),Rqr=o("flaubert"),Pqr=o(" \u2014 "),KZ=a("a"),Bqr=o("TFFlaubertForQuestionAnsweringSimple"),Iqr=o(" (FlauBERT model)"),Nqr=l(),VC=a("li"),cCe=a("strong"),qqr=o("funnel"),jqr=o(" \u2014 "),ZZ=a("a"),Dqr=o("TFFunnelForQuestionAnswering"),Gqr=o(" (Funnel Transformer model)"),Oqr=l(),XC=a("li"),fCe=a("strong"),Vqr=o("gptj"),Xqr=o(" \u2014 "),eee=a("a"),zqr=o("TFGPTJForQuestionAnswering"),Qqr=o(" (GPT-J model)"),Wqr=l(),zC=a("li"),mCe=a("strong"),Hqr=o("longformer"),Uqr=o(" \u2014 "),oee=a("a"),Jqr=o("TFLongformerForQuestionAnswering"),Yqr=o(" (Longformer model)"),Kqr=l(),QC=a("li"),gCe=a("strong"),Zqr=o("mobilebert"),ejr=o(" \u2014 "),ree=a("a"),ojr=o("TFMobileBertForQuestionAnswering"),rjr=o(" (MobileBERT model)"),tjr=l(),WC=a("li"),hCe=a("strong"),ajr=o("mpnet"),njr=o(" \u2014 "),tee=a("a"),sjr=o("TFMPNetForQuestionAnswering"),ljr=o(" (MPNet model)"),ijr=l(),HC=a("li"),pCe=a("strong"),djr=o("rembert"),cjr=o(" \u2014 "),aee=a("a"),fjr=o("TFRemBertForQuestionAnswering"),mjr=o(" (RemBERT model)"),gjr=l(),UC=a("li"),_Ce=a("strong"),hjr=o("roberta"),pjr=o(" \u2014 "),nee=a("a"),_jr=o("TFRobertaForQuestionAnswering"),ujr=o(" (RoBERTa model)"),bjr=l(),JC=a("li"),uCe=a("strong"),vjr=o("roformer"),Fjr=o(" \u2014 "),see=a("a"),Tjr=o("TFRoFormerForQuestionAnswering"),Mjr=o(" (RoFormer model)"),Ejr=l(),YC=a("li"),bCe=a("strong"),Cjr=o("xlm"),wjr=o(" \u2014 "),lee=a("a"),Ajr=o("TFXLMForQuestionAnsweringSimple"),Ljr=o(" (XLM model)"),yjr=l(),KC=a("li"),vCe=a("strong"),xjr=o("xlm-roberta"),$jr=o(" \u2014 "),iee=a("a"),kjr=o("TFXLMRobertaForQuestionAnswering"),Sjr=o(" (XLM-RoBERTa model)"),Rjr=l(),ZC=a("li"),FCe=a("strong"),Pjr=o("xlnet"),Bjr=o(" \u2014 "),dee=a("a"),Ijr=o("TFXLNetForQuestionAnsweringSimple"),Njr=o(" (XLNet model)"),qjr=l(),F(e5.$$.fragment),vQe=l(),Vc=a("h2"),o5=a("a"),TCe=a("span"),F(d$.$$.fragment),jjr=l(),MCe=a("span"),Djr=o("TFAutoModelForVision2Seq"),FQe=l(),hr=a("div"),F(c$.$$.fragment),Gjr=l(),Xc=a("p"),Ojr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cee=a("a"),Vjr=o("from_pretrained()"),Xjr=o(" class method or the "),fee=a("a"),zjr=o("from_config()"),Qjr=o(` class
method.`),Wjr=l(),f$=a("p"),Hjr=o("This class cannot be instantiated directly using "),ECe=a("code"),Ujr=o("__init__()"),Jjr=o(" (throws an error)."),Yjr=l(),zt=a("div"),F(m$.$$.fragment),Kjr=l(),CCe=a("p"),Zjr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),eDr=l(),zc=a("p"),oDr=o(`Note:
Loading a model from its configuration file does `),wCe=a("strong"),rDr=o("not"),tDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mee=a("a"),aDr=o("from_pretrained()"),nDr=o(" to load the model weights."),sDr=l(),F(r5.$$.fragment),lDr=l(),Or=a("div"),F(g$.$$.fragment),iDr=l(),ACe=a("p"),dDr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),cDr=l(),Fn=a("p"),fDr=o("The model class to instantiate is selected based on the "),LCe=a("code"),mDr=o("model_type"),gDr=o(` property of the config object (either
passed as an argument or loaded from `),yCe=a("code"),hDr=o("pretrained_model_name_or_path"),pDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xCe=a("code"),_Dr=o("pretrained_model_name_or_path"),uDr=o(":"),bDr=l(),$Ce=a("ul"),t5=a("li"),kCe=a("strong"),vDr=o("vision-encoder-decoder"),FDr=o(" \u2014 "),gee=a("a"),TDr=o("TFVisionEncoderDecoderModel"),MDr=o(" (Vision Encoder decoder model)"),EDr=l(),F(a5.$$.fragment),TQe=l(),Qc=a("h2"),n5=a("a"),SCe=a("span"),F(h$.$$.fragment),CDr=l(),RCe=a("span"),wDr=o("TFAutoModelForSpeechSeq2Seq"),MQe=l(),pr=a("div"),F(p$.$$.fragment),ADr=l(),Wc=a("p"),LDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hee=a("a"),yDr=o("from_pretrained()"),xDr=o(" class method or the "),pee=a("a"),$Dr=o("from_config()"),kDr=o(` class
method.`),SDr=l(),_$=a("p"),RDr=o("This class cannot be instantiated directly using "),PCe=a("code"),PDr=o("__init__()"),BDr=o(" (throws an error)."),IDr=l(),Qt=a("div"),F(u$.$$.fragment),NDr=l(),BCe=a("p"),qDr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),jDr=l(),Hc=a("p"),DDr=o(`Note:
Loading a model from its configuration file does `),ICe=a("strong"),GDr=o("not"),ODr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=a("a"),VDr=o("from_pretrained()"),XDr=o(" to load the model weights."),zDr=l(),F(s5.$$.fragment),QDr=l(),Vr=a("div"),F(b$.$$.fragment),WDr=l(),NCe=a("p"),HDr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),UDr=l(),Tn=a("p"),JDr=o("The model class to instantiate is selected based on the "),qCe=a("code"),YDr=o("model_type"),KDr=o(` property of the config object (either
passed as an argument or loaded from `),jCe=a("code"),ZDr=o("pretrained_model_name_or_path"),eGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DCe=a("code"),oGr=o("pretrained_model_name_or_path"),rGr=o(":"),tGr=l(),GCe=a("ul"),l5=a("li"),OCe=a("strong"),aGr=o("speech_to_text"),nGr=o(" \u2014 "),uee=a("a"),sGr=o("TFSpeech2TextForConditionalGeneration"),lGr=o(" (Speech2Text model)"),iGr=l(),F(i5.$$.fragment),EQe=l(),Uc=a("h2"),d5=a("a"),VCe=a("span"),F(v$.$$.fragment),dGr=l(),XCe=a("span"),cGr=o("FlaxAutoModel"),CQe=l(),_r=a("div"),F(F$.$$.fragment),fGr=l(),Jc=a("p"),mGr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),bee=a("a"),gGr=o("from_pretrained()"),hGr=o(" class method or the "),vee=a("a"),pGr=o("from_config()"),_Gr=o(` class
method.`),uGr=l(),T$=a("p"),bGr=o("This class cannot be instantiated directly using "),zCe=a("code"),vGr=o("__init__()"),FGr=o(" (throws an error)."),TGr=l(),Wt=a("div"),F(M$.$$.fragment),MGr=l(),QCe=a("p"),EGr=o("Instantiates one of the base model classes of the library from a configuration."),CGr=l(),Yc=a("p"),wGr=o(`Note:
Loading a model from its configuration file does `),WCe=a("strong"),AGr=o("not"),LGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fee=a("a"),yGr=o("from_pretrained()"),xGr=o(" to load the model weights."),$Gr=l(),F(c5.$$.fragment),kGr=l(),Xr=a("div"),F(E$.$$.fragment),SGr=l(),HCe=a("p"),RGr=o("Instantiate one of the base model classes of the library from a pretrained model."),PGr=l(),Mn=a("p"),BGr=o("The model class to instantiate is selected based on the "),UCe=a("code"),IGr=o("model_type"),NGr=o(` property of the config object (either
passed as an argument or loaded from `),JCe=a("code"),qGr=o("pretrained_model_name_or_path"),jGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YCe=a("code"),DGr=o("pretrained_model_name_or_path"),GGr=o(":"),OGr=l(),oe=a("ul"),f5=a("li"),KCe=a("strong"),VGr=o("albert"),XGr=o(" \u2014 "),Tee=a("a"),zGr=o("FlaxAlbertModel"),QGr=o(" (ALBERT model)"),WGr=l(),m5=a("li"),ZCe=a("strong"),HGr=o("bart"),UGr=o(" \u2014 "),Mee=a("a"),JGr=o("FlaxBartModel"),YGr=o(" (BART model)"),KGr=l(),g5=a("li"),e5e=a("strong"),ZGr=o("beit"),eOr=o(" \u2014 "),Eee=a("a"),oOr=o("FlaxBeitModel"),rOr=o(" (BEiT model)"),tOr=l(),h5=a("li"),o5e=a("strong"),aOr=o("bert"),nOr=o(" \u2014 "),Cee=a("a"),sOr=o("FlaxBertModel"),lOr=o(" (BERT model)"),iOr=l(),p5=a("li"),r5e=a("strong"),dOr=o("big_bird"),cOr=o(" \u2014 "),wee=a("a"),fOr=o("FlaxBigBirdModel"),mOr=o(" (BigBird model)"),gOr=l(),_5=a("li"),t5e=a("strong"),hOr=o("blenderbot"),pOr=o(" \u2014 "),Aee=a("a"),_Or=o("FlaxBlenderbotModel"),uOr=o(" (Blenderbot model)"),bOr=l(),u5=a("li"),a5e=a("strong"),vOr=o("blenderbot-small"),FOr=o(" \u2014 "),Lee=a("a"),TOr=o("FlaxBlenderbotSmallModel"),MOr=o(" (BlenderbotSmall model)"),EOr=l(),b5=a("li"),n5e=a("strong"),COr=o("clip"),wOr=o(" \u2014 "),yee=a("a"),AOr=o("FlaxCLIPModel"),LOr=o(" (CLIP model)"),yOr=l(),v5=a("li"),s5e=a("strong"),xOr=o("distilbert"),$Or=o(" \u2014 "),xee=a("a"),kOr=o("FlaxDistilBertModel"),SOr=o(" (DistilBERT model)"),ROr=l(),F5=a("li"),l5e=a("strong"),POr=o("electra"),BOr=o(" \u2014 "),$ee=a("a"),IOr=o("FlaxElectraModel"),NOr=o(" (ELECTRA model)"),qOr=l(),T5=a("li"),i5e=a("strong"),jOr=o("gpt2"),DOr=o(" \u2014 "),kee=a("a"),GOr=o("FlaxGPT2Model"),OOr=o(" (OpenAI GPT-2 model)"),VOr=l(),M5=a("li"),d5e=a("strong"),XOr=o("gpt_neo"),zOr=o(" \u2014 "),See=a("a"),QOr=o("FlaxGPTNeoModel"),WOr=o(" (GPT Neo model)"),HOr=l(),E5=a("li"),c5e=a("strong"),UOr=o("gptj"),JOr=o(" \u2014 "),Ree=a("a"),YOr=o("FlaxGPTJModel"),KOr=o(" (GPT-J model)"),ZOr=l(),C5=a("li"),f5e=a("strong"),eVr=o("longt5"),oVr=o(" \u2014 "),Pee=a("a"),rVr=o("FlaxLongT5Model"),tVr=o(" (LongT5 model)"),aVr=l(),w5=a("li"),m5e=a("strong"),nVr=o("marian"),sVr=o(" \u2014 "),Bee=a("a"),lVr=o("FlaxMarianModel"),iVr=o(" (Marian model)"),dVr=l(),A5=a("li"),g5e=a("strong"),cVr=o("mbart"),fVr=o(" \u2014 "),Iee=a("a"),mVr=o("FlaxMBartModel"),gVr=o(" (mBART model)"),hVr=l(),L5=a("li"),h5e=a("strong"),pVr=o("mt5"),_Vr=o(" \u2014 "),Nee=a("a"),uVr=o("FlaxMT5Model"),bVr=o(" (MT5 model)"),vVr=l(),y5=a("li"),p5e=a("strong"),FVr=o("opt"),TVr=o(" \u2014 "),qee=a("a"),MVr=o("FlaxOPTModel"),EVr=o(" (OPT model)"),CVr=l(),x5=a("li"),_5e=a("strong"),wVr=o("pegasus"),AVr=o(" \u2014 "),jee=a("a"),LVr=o("FlaxPegasusModel"),yVr=o(" (Pegasus model)"),xVr=l(),$5=a("li"),u5e=a("strong"),$Vr=o("roberta"),kVr=o(" \u2014 "),Dee=a("a"),SVr=o("FlaxRobertaModel"),RVr=o(" (RoBERTa model)"),PVr=l(),k5=a("li"),b5e=a("strong"),BVr=o("roformer"),IVr=o(" \u2014 "),Gee=a("a"),NVr=o("FlaxRoFormerModel"),qVr=o(" (RoFormer model)"),jVr=l(),S5=a("li"),v5e=a("strong"),DVr=o("t5"),GVr=o(" \u2014 "),Oee=a("a"),OVr=o("FlaxT5Model"),VVr=o(" (T5 model)"),XVr=l(),R5=a("li"),F5e=a("strong"),zVr=o("vision-text-dual-encoder"),QVr=o(" \u2014 "),Vee=a("a"),WVr=o("FlaxVisionTextDualEncoderModel"),HVr=o(" (VisionTextDualEncoder model)"),UVr=l(),P5=a("li"),T5e=a("strong"),JVr=o("vit"),YVr=o(" \u2014 "),Xee=a("a"),KVr=o("FlaxViTModel"),ZVr=o(" (ViT model)"),eXr=l(),B5=a("li"),M5e=a("strong"),oXr=o("wav2vec2"),rXr=o(" \u2014 "),zee=a("a"),tXr=o("FlaxWav2Vec2Model"),aXr=o(" (Wav2Vec2 model)"),nXr=l(),I5=a("li"),E5e=a("strong"),sXr=o("xglm"),lXr=o(" \u2014 "),Qee=a("a"),iXr=o("FlaxXGLMModel"),dXr=o(" (XGLM model)"),cXr=l(),N5=a("li"),C5e=a("strong"),fXr=o("xlm-roberta"),mXr=o(" \u2014 "),Wee=a("a"),gXr=o("FlaxXLMRobertaModel"),hXr=o(" (XLM-RoBERTa model)"),pXr=l(),F(q5.$$.fragment),wQe=l(),Kc=a("h2"),j5=a("a"),w5e=a("span"),F(C$.$$.fragment),_Xr=l(),A5e=a("span"),uXr=o("FlaxAutoModelForCausalLM"),AQe=l(),ur=a("div"),F(w$.$$.fragment),bXr=l(),Zc=a("p"),vXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hee=a("a"),FXr=o("from_pretrained()"),TXr=o(" class method or the "),Uee=a("a"),MXr=o("from_config()"),EXr=o(` class
method.`),CXr=l(),A$=a("p"),wXr=o("This class cannot be instantiated directly using "),L5e=a("code"),AXr=o("__init__()"),LXr=o(" (throws an error)."),yXr=l(),Ht=a("div"),F(L$.$$.fragment),xXr=l(),y5e=a("p"),$Xr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),kXr=l(),ef=a("p"),SXr=o(`Note:
Loading a model from its configuration file does `),x5e=a("strong"),RXr=o("not"),PXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),BXr=o("from_pretrained()"),IXr=o(" to load the model weights."),NXr=l(),F(D5.$$.fragment),qXr=l(),zr=a("div"),F(y$.$$.fragment),jXr=l(),$5e=a("p"),DXr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GXr=l(),En=a("p"),OXr=o("The model class to instantiate is selected based on the "),k5e=a("code"),VXr=o("model_type"),XXr=o(` property of the config object (either
passed as an argument or loaded from `),S5e=a("code"),zXr=o("pretrained_model_name_or_path"),QXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R5e=a("code"),WXr=o("pretrained_model_name_or_path"),HXr=o(":"),UXr=l(),xe=a("ul"),G5=a("li"),P5e=a("strong"),JXr=o("bart"),YXr=o(" \u2014 "),Yee=a("a"),KXr=o("FlaxBartForCausalLM"),ZXr=o(" (BART model)"),ezr=l(),O5=a("li"),B5e=a("strong"),ozr=o("bert"),rzr=o(" \u2014 "),Kee=a("a"),tzr=o("FlaxBertForCausalLM"),azr=o(" (BERT model)"),nzr=l(),V5=a("li"),I5e=a("strong"),szr=o("big_bird"),lzr=o(" \u2014 "),Zee=a("a"),izr=o("FlaxBigBirdForCausalLM"),dzr=o(" (BigBird model)"),czr=l(),X5=a("li"),N5e=a("strong"),fzr=o("electra"),mzr=o(" \u2014 "),eoe=a("a"),gzr=o("FlaxElectraForCausalLM"),hzr=o(" (ELECTRA model)"),pzr=l(),z5=a("li"),q5e=a("strong"),_zr=o("gpt2"),uzr=o(" \u2014 "),ooe=a("a"),bzr=o("FlaxGPT2LMHeadModel"),vzr=o(" (OpenAI GPT-2 model)"),Fzr=l(),Q5=a("li"),j5e=a("strong"),Tzr=o("gpt_neo"),Mzr=o(" \u2014 "),roe=a("a"),Ezr=o("FlaxGPTNeoForCausalLM"),Czr=o(" (GPT Neo model)"),wzr=l(),W5=a("li"),D5e=a("strong"),Azr=o("gptj"),Lzr=o(" \u2014 "),toe=a("a"),yzr=o("FlaxGPTJForCausalLM"),xzr=o(" (GPT-J model)"),$zr=l(),H5=a("li"),G5e=a("strong"),kzr=o("opt"),Szr=o(" \u2014 "),aoe=a("a"),Rzr=o("FlaxOPTForCausalLM"),Pzr=o(" (OPT model)"),Bzr=l(),U5=a("li"),O5e=a("strong"),Izr=o("roberta"),Nzr=o(" \u2014 "),noe=a("a"),qzr=o("FlaxRobertaForCausalLM"),jzr=o(" (RoBERTa model)"),Dzr=l(),J5=a("li"),V5e=a("strong"),Gzr=o("xglm"),Ozr=o(" \u2014 "),soe=a("a"),Vzr=o("FlaxXGLMForCausalLM"),Xzr=o(" (XGLM model)"),zzr=l(),F(Y5.$$.fragment),LQe=l(),of=a("h2"),K5=a("a"),X5e=a("span"),F(x$.$$.fragment),Qzr=l(),z5e=a("span"),Wzr=o("FlaxAutoModelForPreTraining"),yQe=l(),br=a("div"),F($$.$$.fragment),Hzr=l(),rf=a("p"),Uzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),loe=a("a"),Jzr=o("from_pretrained()"),Yzr=o(" class method or the "),ioe=a("a"),Kzr=o("from_config()"),Zzr=o(` class
method.`),eQr=l(),k$=a("p"),oQr=o("This class cannot be instantiated directly using "),Q5e=a("code"),rQr=o("__init__()"),tQr=o(" (throws an error)."),aQr=l(),Ut=a("div"),F(S$.$$.fragment),nQr=l(),W5e=a("p"),sQr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),lQr=l(),tf=a("p"),iQr=o(`Note:
Loading a model from its configuration file does `),H5e=a("strong"),dQr=o("not"),cQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=a("a"),fQr=o("from_pretrained()"),mQr=o(" to load the model weights."),gQr=l(),F(Z5.$$.fragment),hQr=l(),Qr=a("div"),F(R$.$$.fragment),pQr=l(),U5e=a("p"),_Qr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),uQr=l(),Cn=a("p"),bQr=o("The model class to instantiate is selected based on the "),J5e=a("code"),vQr=o("model_type"),FQr=o(` property of the config object (either
passed as an argument or loaded from `),Y5e=a("code"),TQr=o("pretrained_model_name_or_path"),MQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=a("code"),EQr=o("pretrained_model_name_or_path"),CQr=o(":"),wQr=l(),Ee=a("ul"),e3=a("li"),Z5e=a("strong"),AQr=o("albert"),LQr=o(" \u2014 "),coe=a("a"),yQr=o("FlaxAlbertForPreTraining"),xQr=o(" (ALBERT model)"),$Qr=l(),o3=a("li"),e3e=a("strong"),kQr=o("bart"),SQr=o(" \u2014 "),foe=a("a"),RQr=o("FlaxBartForConditionalGeneration"),PQr=o(" (BART model)"),BQr=l(),r3=a("li"),o3e=a("strong"),IQr=o("bert"),NQr=o(" \u2014 "),moe=a("a"),qQr=o("FlaxBertForPreTraining"),jQr=o(" (BERT model)"),DQr=l(),t3=a("li"),r3e=a("strong"),GQr=o("big_bird"),OQr=o(" \u2014 "),goe=a("a"),VQr=o("FlaxBigBirdForPreTraining"),XQr=o(" (BigBird model)"),zQr=l(),a3=a("li"),t3e=a("strong"),QQr=o("electra"),WQr=o(" \u2014 "),hoe=a("a"),HQr=o("FlaxElectraForPreTraining"),UQr=o(" (ELECTRA model)"),JQr=l(),n3=a("li"),a3e=a("strong"),YQr=o("longt5"),KQr=o(" \u2014 "),poe=a("a"),ZQr=o("FlaxLongT5ForConditionalGeneration"),eWr=o(" (LongT5 model)"),oWr=l(),s3=a("li"),n3e=a("strong"),rWr=o("mbart"),tWr=o(" \u2014 "),_oe=a("a"),aWr=o("FlaxMBartForConditionalGeneration"),nWr=o(" (mBART model)"),sWr=l(),l3=a("li"),s3e=a("strong"),lWr=o("mt5"),iWr=o(" \u2014 "),uoe=a("a"),dWr=o("FlaxMT5ForConditionalGeneration"),cWr=o(" (MT5 model)"),fWr=l(),i3=a("li"),l3e=a("strong"),mWr=o("roberta"),gWr=o(" \u2014 "),boe=a("a"),hWr=o("FlaxRobertaForMaskedLM"),pWr=o(" (RoBERTa model)"),_Wr=l(),d3=a("li"),i3e=a("strong"),uWr=o("roformer"),bWr=o(" \u2014 "),voe=a("a"),vWr=o("FlaxRoFormerForMaskedLM"),FWr=o(" (RoFormer model)"),TWr=l(),c3=a("li"),d3e=a("strong"),MWr=o("t5"),EWr=o(" \u2014 "),Foe=a("a"),CWr=o("FlaxT5ForConditionalGeneration"),wWr=o(" (T5 model)"),AWr=l(),f3=a("li"),c3e=a("strong"),LWr=o("wav2vec2"),yWr=o(" \u2014 "),Toe=a("a"),xWr=o("FlaxWav2Vec2ForPreTraining"),$Wr=o(" (Wav2Vec2 model)"),kWr=l(),m3=a("li"),f3e=a("strong"),SWr=o("xlm-roberta"),RWr=o(" \u2014 "),Moe=a("a"),PWr=o("FlaxXLMRobertaForMaskedLM"),BWr=o(" (XLM-RoBERTa model)"),IWr=l(),F(g3.$$.fragment),xQe=l(),af=a("h2"),h3=a("a"),m3e=a("span"),F(P$.$$.fragment),NWr=l(),g3e=a("span"),qWr=o("FlaxAutoModelForMaskedLM"),$Qe=l(),vr=a("div"),F(B$.$$.fragment),jWr=l(),nf=a("p"),DWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Eoe=a("a"),GWr=o("from_pretrained()"),OWr=o(" class method or the "),Coe=a("a"),VWr=o("from_config()"),XWr=o(` class
method.`),zWr=l(),I$=a("p"),QWr=o("This class cannot be instantiated directly using "),h3e=a("code"),WWr=o("__init__()"),HWr=o(" (throws an error)."),UWr=l(),Jt=a("div"),F(N$.$$.fragment),JWr=l(),p3e=a("p"),YWr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),KWr=l(),sf=a("p"),ZWr=o(`Note:
Loading a model from its configuration file does `),_3e=a("strong"),eHr=o("not"),oHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),woe=a("a"),rHr=o("from_pretrained()"),tHr=o(" to load the model weights."),aHr=l(),F(p3.$$.fragment),nHr=l(),Wr=a("div"),F(q$.$$.fragment),sHr=l(),u3e=a("p"),lHr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),iHr=l(),wn=a("p"),dHr=o("The model class to instantiate is selected based on the "),b3e=a("code"),cHr=o("model_type"),fHr=o(` property of the config object (either
passed as an argument or loaded from `),v3e=a("code"),mHr=o("pretrained_model_name_or_path"),gHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F3e=a("code"),hHr=o("pretrained_model_name_or_path"),pHr=o(":"),_Hr=l(),$e=a("ul"),_3=a("li"),T3e=a("strong"),uHr=o("albert"),bHr=o(" \u2014 "),Aoe=a("a"),vHr=o("FlaxAlbertForMaskedLM"),FHr=o(" (ALBERT model)"),THr=l(),u3=a("li"),M3e=a("strong"),MHr=o("bart"),EHr=o(" \u2014 "),Loe=a("a"),CHr=o("FlaxBartForConditionalGeneration"),wHr=o(" (BART model)"),AHr=l(),b3=a("li"),E3e=a("strong"),LHr=o("bert"),yHr=o(" \u2014 "),yoe=a("a"),xHr=o("FlaxBertForMaskedLM"),$Hr=o(" (BERT model)"),kHr=l(),v3=a("li"),C3e=a("strong"),SHr=o("big_bird"),RHr=o(" \u2014 "),xoe=a("a"),PHr=o("FlaxBigBirdForMaskedLM"),BHr=o(" (BigBird model)"),IHr=l(),F3=a("li"),w3e=a("strong"),NHr=o("distilbert"),qHr=o(" \u2014 "),$oe=a("a"),jHr=o("FlaxDistilBertForMaskedLM"),DHr=o(" (DistilBERT model)"),GHr=l(),T3=a("li"),A3e=a("strong"),OHr=o("electra"),VHr=o(" \u2014 "),koe=a("a"),XHr=o("FlaxElectraForMaskedLM"),zHr=o(" (ELECTRA model)"),QHr=l(),M3=a("li"),L3e=a("strong"),WHr=o("mbart"),HHr=o(" \u2014 "),Soe=a("a"),UHr=o("FlaxMBartForConditionalGeneration"),JHr=o(" (mBART model)"),YHr=l(),E3=a("li"),y3e=a("strong"),KHr=o("roberta"),ZHr=o(" \u2014 "),Roe=a("a"),eUr=o("FlaxRobertaForMaskedLM"),oUr=o(" (RoBERTa model)"),rUr=l(),C3=a("li"),x3e=a("strong"),tUr=o("roformer"),aUr=o(" \u2014 "),Poe=a("a"),nUr=o("FlaxRoFormerForMaskedLM"),sUr=o(" (RoFormer model)"),lUr=l(),w3=a("li"),$3e=a("strong"),iUr=o("xlm-roberta"),dUr=o(" \u2014 "),Boe=a("a"),cUr=o("FlaxXLMRobertaForMaskedLM"),fUr=o(" (XLM-RoBERTa model)"),mUr=l(),F(A3.$$.fragment),kQe=l(),lf=a("h2"),L3=a("a"),k3e=a("span"),F(j$.$$.fragment),gUr=l(),S3e=a("span"),hUr=o("FlaxAutoModelForSeq2SeqLM"),SQe=l(),Fr=a("div"),F(D$.$$.fragment),pUr=l(),df=a("p"),_Ur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ioe=a("a"),uUr=o("from_pretrained()"),bUr=o(" class method or the "),Noe=a("a"),vUr=o("from_config()"),FUr=o(` class
method.`),TUr=l(),G$=a("p"),MUr=o("This class cannot be instantiated directly using "),R3e=a("code"),EUr=o("__init__()"),CUr=o(" (throws an error)."),wUr=l(),Yt=a("div"),F(O$.$$.fragment),AUr=l(),P3e=a("p"),LUr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yUr=l(),cf=a("p"),xUr=o(`Note:
Loading a model from its configuration file does `),B3e=a("strong"),$Ur=o("not"),kUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qoe=a("a"),SUr=o("from_pretrained()"),RUr=o(" to load the model weights."),PUr=l(),F(y3.$$.fragment),BUr=l(),Hr=a("div"),F(V$.$$.fragment),IUr=l(),I3e=a("p"),NUr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qUr=l(),An=a("p"),jUr=o("The model class to instantiate is selected based on the "),N3e=a("code"),DUr=o("model_type"),GUr=o(` property of the config object (either
passed as an argument or loaded from `),q3e=a("code"),OUr=o("pretrained_model_name_or_path"),VUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=a("code"),XUr=o("pretrained_model_name_or_path"),zUr=o(":"),QUr=l(),ke=a("ul"),x3=a("li"),D3e=a("strong"),WUr=o("bart"),HUr=o(" \u2014 "),joe=a("a"),UUr=o("FlaxBartForConditionalGeneration"),JUr=o(" (BART model)"),YUr=l(),$3=a("li"),G3e=a("strong"),KUr=o("blenderbot"),ZUr=o(" \u2014 "),Doe=a("a"),eJr=o("FlaxBlenderbotForConditionalGeneration"),oJr=o(" (Blenderbot model)"),rJr=l(),k3=a("li"),O3e=a("strong"),tJr=o("blenderbot-small"),aJr=o(" \u2014 "),Goe=a("a"),nJr=o("FlaxBlenderbotSmallForConditionalGeneration"),sJr=o(" (BlenderbotSmall model)"),lJr=l(),S3=a("li"),V3e=a("strong"),iJr=o("encoder-decoder"),dJr=o(" \u2014 "),Ooe=a("a"),cJr=o("FlaxEncoderDecoderModel"),fJr=o(" (Encoder decoder model)"),mJr=l(),R3=a("li"),X3e=a("strong"),gJr=o("longt5"),hJr=o(" \u2014 "),Voe=a("a"),pJr=o("FlaxLongT5ForConditionalGeneration"),_Jr=o(" (LongT5 model)"),uJr=l(),P3=a("li"),z3e=a("strong"),bJr=o("marian"),vJr=o(" \u2014 "),Xoe=a("a"),FJr=o("FlaxMarianMTModel"),TJr=o(" (Marian model)"),MJr=l(),B3=a("li"),Q3e=a("strong"),EJr=o("mbart"),CJr=o(" \u2014 "),zoe=a("a"),wJr=o("FlaxMBartForConditionalGeneration"),AJr=o(" (mBART model)"),LJr=l(),I3=a("li"),W3e=a("strong"),yJr=o("mt5"),xJr=o(" \u2014 "),Qoe=a("a"),$Jr=o("FlaxMT5ForConditionalGeneration"),kJr=o(" (MT5 model)"),SJr=l(),N3=a("li"),H3e=a("strong"),RJr=o("pegasus"),PJr=o(" \u2014 "),Woe=a("a"),BJr=o("FlaxPegasusForConditionalGeneration"),IJr=o(" (Pegasus model)"),NJr=l(),q3=a("li"),U3e=a("strong"),qJr=o("t5"),jJr=o(" \u2014 "),Hoe=a("a"),DJr=o("FlaxT5ForConditionalGeneration"),GJr=o(" (T5 model)"),OJr=l(),F(j3.$$.fragment),RQe=l(),ff=a("h2"),D3=a("a"),J3e=a("span"),F(X$.$$.fragment),VJr=l(),Y3e=a("span"),XJr=o("FlaxAutoModelForSequenceClassification"),PQe=l(),Tr=a("div"),F(z$.$$.fragment),zJr=l(),mf=a("p"),QJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Uoe=a("a"),WJr=o("from_pretrained()"),HJr=o(" class method or the "),Joe=a("a"),UJr=o("from_config()"),JJr=o(` class
method.`),YJr=l(),Q$=a("p"),KJr=o("This class cannot be instantiated directly using "),K3e=a("code"),ZJr=o("__init__()"),eYr=o(" (throws an error)."),oYr=l(),Kt=a("div"),F(W$.$$.fragment),rYr=l(),Z3e=a("p"),tYr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),aYr=l(),gf=a("p"),nYr=o(`Note:
Loading a model from its configuration file does `),e0e=a("strong"),sYr=o("not"),lYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yoe=a("a"),iYr=o("from_pretrained()"),dYr=o(" to load the model weights."),cYr=l(),F(G3.$$.fragment),fYr=l(),Ur=a("div"),F(H$.$$.fragment),mYr=l(),o0e=a("p"),gYr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),hYr=l(),Ln=a("p"),pYr=o("The model class to instantiate is selected based on the "),r0e=a("code"),_Yr=o("model_type"),uYr=o(` property of the config object (either
passed as an argument or loaded from `),t0e=a("code"),bYr=o("pretrained_model_name_or_path"),vYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=a("code"),FYr=o("pretrained_model_name_or_path"),TYr=o(":"),MYr=l(),Se=a("ul"),O3=a("li"),n0e=a("strong"),EYr=o("albert"),CYr=o(" \u2014 "),Koe=a("a"),wYr=o("FlaxAlbertForSequenceClassification"),AYr=o(" (ALBERT model)"),LYr=l(),V3=a("li"),s0e=a("strong"),yYr=o("bart"),xYr=o(" \u2014 "),Zoe=a("a"),$Yr=o("FlaxBartForSequenceClassification"),kYr=o(" (BART model)"),SYr=l(),X3=a("li"),l0e=a("strong"),RYr=o("bert"),PYr=o(" \u2014 "),ere=a("a"),BYr=o("FlaxBertForSequenceClassification"),IYr=o(" (BERT model)"),NYr=l(),z3=a("li"),i0e=a("strong"),qYr=o("big_bird"),jYr=o(" \u2014 "),ore=a("a"),DYr=o("FlaxBigBirdForSequenceClassification"),GYr=o(" (BigBird model)"),OYr=l(),Q3=a("li"),d0e=a("strong"),VYr=o("distilbert"),XYr=o(" \u2014 "),rre=a("a"),zYr=o("FlaxDistilBertForSequenceClassification"),QYr=o(" (DistilBERT model)"),WYr=l(),W3=a("li"),c0e=a("strong"),HYr=o("electra"),UYr=o(" \u2014 "),tre=a("a"),JYr=o("FlaxElectraForSequenceClassification"),YYr=o(" (ELECTRA model)"),KYr=l(),H3=a("li"),f0e=a("strong"),ZYr=o("mbart"),eKr=o(" \u2014 "),are=a("a"),oKr=o("FlaxMBartForSequenceClassification"),rKr=o(" (mBART model)"),tKr=l(),U3=a("li"),m0e=a("strong"),aKr=o("roberta"),nKr=o(" \u2014 "),nre=a("a"),sKr=o("FlaxRobertaForSequenceClassification"),lKr=o(" (RoBERTa model)"),iKr=l(),J3=a("li"),g0e=a("strong"),dKr=o("roformer"),cKr=o(" \u2014 "),sre=a("a"),fKr=o("FlaxRoFormerForSequenceClassification"),mKr=o(" (RoFormer model)"),gKr=l(),Y3=a("li"),h0e=a("strong"),hKr=o("xlm-roberta"),pKr=o(" \u2014 "),lre=a("a"),_Kr=o("FlaxXLMRobertaForSequenceClassification"),uKr=o(" (XLM-RoBERTa model)"),bKr=l(),F(K3.$$.fragment),BQe=l(),hf=a("h2"),Z3=a("a"),p0e=a("span"),F(U$.$$.fragment),vKr=l(),_0e=a("span"),FKr=o("FlaxAutoModelForQuestionAnswering"),IQe=l(),Mr=a("div"),F(J$.$$.fragment),TKr=l(),pf=a("p"),MKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ire=a("a"),EKr=o("from_pretrained()"),CKr=o(" class method or the "),dre=a("a"),wKr=o("from_config()"),AKr=o(` class
method.`),LKr=l(),Y$=a("p"),yKr=o("This class cannot be instantiated directly using "),u0e=a("code"),xKr=o("__init__()"),$Kr=o(" (throws an error)."),kKr=l(),Zt=a("div"),F(K$.$$.fragment),SKr=l(),b0e=a("p"),RKr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),PKr=l(),_f=a("p"),BKr=o(`Note:
Loading a model from its configuration file does `),v0e=a("strong"),IKr=o("not"),NKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cre=a("a"),qKr=o("from_pretrained()"),jKr=o(" to load the model weights."),DKr=l(),F(e0.$$.fragment),GKr=l(),Jr=a("div"),F(Z$.$$.fragment),OKr=l(),F0e=a("p"),VKr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),XKr=l(),yn=a("p"),zKr=o("The model class to instantiate is selected based on the "),T0e=a("code"),QKr=o("model_type"),WKr=o(` property of the config object (either
passed as an argument or loaded from `),M0e=a("code"),HKr=o("pretrained_model_name_or_path"),UKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E0e=a("code"),JKr=o("pretrained_model_name_or_path"),YKr=o(":"),KKr=l(),Re=a("ul"),o0=a("li"),C0e=a("strong"),ZKr=o("albert"),eZr=o(" \u2014 "),fre=a("a"),oZr=o("FlaxAlbertForQuestionAnswering"),rZr=o(" (ALBERT model)"),tZr=l(),r0=a("li"),w0e=a("strong"),aZr=o("bart"),nZr=o(" \u2014 "),mre=a("a"),sZr=o("FlaxBartForQuestionAnswering"),lZr=o(" (BART model)"),iZr=l(),t0=a("li"),A0e=a("strong"),dZr=o("bert"),cZr=o(" \u2014 "),gre=a("a"),fZr=o("FlaxBertForQuestionAnswering"),mZr=o(" (BERT model)"),gZr=l(),a0=a("li"),L0e=a("strong"),hZr=o("big_bird"),pZr=o(" \u2014 "),hre=a("a"),_Zr=o("FlaxBigBirdForQuestionAnswering"),uZr=o(" (BigBird model)"),bZr=l(),n0=a("li"),y0e=a("strong"),vZr=o("distilbert"),FZr=o(" \u2014 "),pre=a("a"),TZr=o("FlaxDistilBertForQuestionAnswering"),MZr=o(" (DistilBERT model)"),EZr=l(),s0=a("li"),x0e=a("strong"),CZr=o("electra"),wZr=o(" \u2014 "),_re=a("a"),AZr=o("FlaxElectraForQuestionAnswering"),LZr=o(" (ELECTRA model)"),yZr=l(),l0=a("li"),$0e=a("strong"),xZr=o("mbart"),$Zr=o(" \u2014 "),ure=a("a"),kZr=o("FlaxMBartForQuestionAnswering"),SZr=o(" (mBART model)"),RZr=l(),i0=a("li"),k0e=a("strong"),PZr=o("roberta"),BZr=o(" \u2014 "),bre=a("a"),IZr=o("FlaxRobertaForQuestionAnswering"),NZr=o(" (RoBERTa model)"),qZr=l(),d0=a("li"),S0e=a("strong"),jZr=o("roformer"),DZr=o(" \u2014 "),vre=a("a"),GZr=o("FlaxRoFormerForQuestionAnswering"),OZr=o(" (RoFormer model)"),VZr=l(),c0=a("li"),R0e=a("strong"),XZr=o("xlm-roberta"),zZr=o(" \u2014 "),Fre=a("a"),QZr=o("FlaxXLMRobertaForQuestionAnswering"),WZr=o(" (XLM-RoBERTa model)"),HZr=l(),F(f0.$$.fragment),NQe=l(),uf=a("h2"),m0=a("a"),P0e=a("span"),F(ek.$$.fragment),UZr=l(),B0e=a("span"),JZr=o("FlaxAutoModelForTokenClassification"),qQe=l(),Er=a("div"),F(ok.$$.fragment),YZr=l(),bf=a("p"),KZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Tre=a("a"),ZZr=o("from_pretrained()"),eet=o(" class method or the "),Mre=a("a"),oet=o("from_config()"),ret=o(` class
method.`),tet=l(),rk=a("p"),aet=o("This class cannot be instantiated directly using "),I0e=a("code"),net=o("__init__()"),set=o(" (throws an error)."),iet=l(),ea=a("div"),F(tk.$$.fragment),det=l(),N0e=a("p"),cet=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),fet=l(),vf=a("p"),met=o(`Note:
Loading a model from its configuration file does `),q0e=a("strong"),get=o("not"),het=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ere=a("a"),pet=o("from_pretrained()"),_et=o(" to load the model weights."),uet=l(),F(g0.$$.fragment),bet=l(),Yr=a("div"),F(ak.$$.fragment),vet=l(),j0e=a("p"),Fet=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Tet=l(),xn=a("p"),Met=o("The model class to instantiate is selected based on the "),D0e=a("code"),Eet=o("model_type"),Cet=o(` property of the config object (either
passed as an argument or loaded from `),G0e=a("code"),wet=o("pretrained_model_name_or_path"),Aet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O0e=a("code"),Let=o("pretrained_model_name_or_path"),yet=o(":"),xet=l(),Xe=a("ul"),h0=a("li"),V0e=a("strong"),$et=o("albert"),ket=o(" \u2014 "),Cre=a("a"),Set=o("FlaxAlbertForTokenClassification"),Ret=o(" (ALBERT model)"),Pet=l(),p0=a("li"),X0e=a("strong"),Bet=o("bert"),Iet=o(" \u2014 "),wre=a("a"),Net=o("FlaxBertForTokenClassification"),qet=o(" (BERT model)"),jet=l(),_0=a("li"),z0e=a("strong"),Det=o("big_bird"),Get=o(" \u2014 "),Are=a("a"),Oet=o("FlaxBigBirdForTokenClassification"),Vet=o(" (BigBird model)"),Xet=l(),u0=a("li"),Q0e=a("strong"),zet=o("distilbert"),Qet=o(" \u2014 "),Lre=a("a"),Wet=o("FlaxDistilBertForTokenClassification"),Het=o(" (DistilBERT model)"),Uet=l(),b0=a("li"),W0e=a("strong"),Jet=o("electra"),Yet=o(" \u2014 "),yre=a("a"),Ket=o("FlaxElectraForTokenClassification"),Zet=o(" (ELECTRA model)"),eot=l(),v0=a("li"),H0e=a("strong"),oot=o("roberta"),rot=o(" \u2014 "),xre=a("a"),tot=o("FlaxRobertaForTokenClassification"),aot=o(" (RoBERTa model)"),not=l(),F0=a("li"),U0e=a("strong"),sot=o("roformer"),lot=o(" \u2014 "),$re=a("a"),iot=o("FlaxRoFormerForTokenClassification"),dot=o(" (RoFormer model)"),cot=l(),T0=a("li"),J0e=a("strong"),fot=o("xlm-roberta"),mot=o(" \u2014 "),kre=a("a"),got=o("FlaxXLMRobertaForTokenClassification"),hot=o(" (XLM-RoBERTa model)"),pot=l(),F(M0.$$.fragment),jQe=l(),Ff=a("h2"),E0=a("a"),Y0e=a("span"),F(nk.$$.fragment),_ot=l(),K0e=a("span"),uot=o("FlaxAutoModelForMultipleChoice"),DQe=l(),Cr=a("div"),F(sk.$$.fragment),bot=l(),Tf=a("p"),vot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Sre=a("a"),Fot=o("from_pretrained()"),Tot=o(" class method or the "),Rre=a("a"),Mot=o("from_config()"),Eot=o(` class
method.`),Cot=l(),lk=a("p"),wot=o("This class cannot be instantiated directly using "),Z0e=a("code"),Aot=o("__init__()"),Lot=o(" (throws an error)."),yot=l(),oa=a("div"),F(ik.$$.fragment),xot=l(),ewe=a("p"),$ot=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),kot=l(),Mf=a("p"),Sot=o(`Note:
Loading a model from its configuration file does `),owe=a("strong"),Rot=o("not"),Pot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pre=a("a"),Bot=o("from_pretrained()"),Iot=o(" to load the model weights."),Not=l(),F(C0.$$.fragment),qot=l(),Kr=a("div"),F(dk.$$.fragment),jot=l(),rwe=a("p"),Dot=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Got=l(),$n=a("p"),Oot=o("The model class to instantiate is selected based on the "),twe=a("code"),Vot=o("model_type"),Xot=o(` property of the config object (either
passed as an argument or loaded from `),awe=a("code"),zot=o("pretrained_model_name_or_path"),Qot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nwe=a("code"),Wot=o("pretrained_model_name_or_path"),Hot=o(":"),Uot=l(),ze=a("ul"),w0=a("li"),swe=a("strong"),Jot=o("albert"),Yot=o(" \u2014 "),Bre=a("a"),Kot=o("FlaxAlbertForMultipleChoice"),Zot=o(" (ALBERT model)"),ert=l(),A0=a("li"),lwe=a("strong"),ort=o("bert"),rrt=o(" \u2014 "),Ire=a("a"),trt=o("FlaxBertForMultipleChoice"),art=o(" (BERT model)"),nrt=l(),L0=a("li"),iwe=a("strong"),srt=o("big_bird"),lrt=o(" \u2014 "),Nre=a("a"),irt=o("FlaxBigBirdForMultipleChoice"),drt=o(" (BigBird model)"),crt=l(),y0=a("li"),dwe=a("strong"),frt=o("distilbert"),mrt=o(" \u2014 "),qre=a("a"),grt=o("FlaxDistilBertForMultipleChoice"),hrt=o(" (DistilBERT model)"),prt=l(),x0=a("li"),cwe=a("strong"),_rt=o("electra"),urt=o(" \u2014 "),jre=a("a"),brt=o("FlaxElectraForMultipleChoice"),vrt=o(" (ELECTRA model)"),Frt=l(),$0=a("li"),fwe=a("strong"),Trt=o("roberta"),Mrt=o(" \u2014 "),Dre=a("a"),Ert=o("FlaxRobertaForMultipleChoice"),Crt=o(" (RoBERTa model)"),wrt=l(),k0=a("li"),mwe=a("strong"),Art=o("roformer"),Lrt=o(" \u2014 "),Gre=a("a"),yrt=o("FlaxRoFormerForMultipleChoice"),xrt=o(" (RoFormer model)"),$rt=l(),S0=a("li"),gwe=a("strong"),krt=o("xlm-roberta"),Srt=o(" \u2014 "),Ore=a("a"),Rrt=o("FlaxXLMRobertaForMultipleChoice"),Prt=o(" (XLM-RoBERTa model)"),Brt=l(),F(R0.$$.fragment),GQe=l(),Ef=a("h2"),P0=a("a"),hwe=a("span"),F(ck.$$.fragment),Irt=l(),pwe=a("span"),Nrt=o("FlaxAutoModelForNextSentencePrediction"),OQe=l(),wr=a("div"),F(fk.$$.fragment),qrt=l(),Cf=a("p"),jrt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Vre=a("a"),Drt=o("from_pretrained()"),Grt=o(" class method or the "),Xre=a("a"),Ort=o("from_config()"),Vrt=o(` class
method.`),Xrt=l(),mk=a("p"),zrt=o("This class cannot be instantiated directly using "),_we=a("code"),Qrt=o("__init__()"),Wrt=o(" (throws an error)."),Hrt=l(),ra=a("div"),F(gk.$$.fragment),Urt=l(),uwe=a("p"),Jrt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Yrt=l(),wf=a("p"),Krt=o(`Note:
Loading a model from its configuration file does `),bwe=a("strong"),Zrt=o("not"),ett=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=a("a"),ott=o("from_pretrained()"),rtt=o(" to load the model weights."),ttt=l(),F(B0.$$.fragment),att=l(),Zr=a("div"),F(hk.$$.fragment),ntt=l(),vwe=a("p"),stt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),ltt=l(),kn=a("p"),itt=o("The model class to instantiate is selected based on the "),Fwe=a("code"),dtt=o("model_type"),ctt=o(` property of the config object (either
passed as an argument or loaded from `),Twe=a("code"),ftt=o("pretrained_model_name_or_path"),mtt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mwe=a("code"),gtt=o("pretrained_model_name_or_path"),htt=o(":"),ptt=l(),Ewe=a("ul"),I0=a("li"),Cwe=a("strong"),_tt=o("bert"),utt=o(" \u2014 "),Qre=a("a"),btt=o("FlaxBertForNextSentencePrediction"),vtt=o(" (BERT model)"),Ftt=l(),F(N0.$$.fragment),VQe=l(),Af=a("h2"),q0=a("a"),wwe=a("span"),F(pk.$$.fragment),Ttt=l(),Awe=a("span"),Mtt=o("FlaxAutoModelForImageClassification"),XQe=l(),Ar=a("div"),F(_k.$$.fragment),Ett=l(),Lf=a("p"),Ctt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Wre=a("a"),wtt=o("from_pretrained()"),Att=o(" class method or the "),Hre=a("a"),Ltt=o("from_config()"),ytt=o(` class
method.`),xtt=l(),uk=a("p"),$tt=o("This class cannot be instantiated directly using "),Lwe=a("code"),ktt=o("__init__()"),Stt=o(" (throws an error)."),Rtt=l(),ta=a("div"),F(bk.$$.fragment),Ptt=l(),ywe=a("p"),Btt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Itt=l(),yf=a("p"),Ntt=o(`Note:
Loading a model from its configuration file does `),xwe=a("strong"),qtt=o("not"),jtt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ure=a("a"),Dtt=o("from_pretrained()"),Gtt=o(" to load the model weights."),Ott=l(),F(j0.$$.fragment),Vtt=l(),et=a("div"),F(vk.$$.fragment),Xtt=l(),$we=a("p"),ztt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Qtt=l(),Sn=a("p"),Wtt=o("The model class to instantiate is selected based on the "),kwe=a("code"),Htt=o("model_type"),Utt=o(` property of the config object (either
passed as an argument or loaded from `),Swe=a("code"),Jtt=o("pretrained_model_name_or_path"),Ytt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=a("code"),Ktt=o("pretrained_model_name_or_path"),Ztt=o(":"),eat=l(),Fk=a("ul"),D0=a("li"),Pwe=a("strong"),oat=o("beit"),rat=o(" \u2014 "),Jre=a("a"),tat=o("FlaxBeitForImageClassification"),aat=o(" (BEiT model)"),nat=l(),G0=a("li"),Bwe=a("strong"),sat=o("vit"),lat=o(" \u2014 "),Yre=a("a"),iat=o("FlaxViTForImageClassification"),dat=o(" (ViT model)"),cat=l(),F(O0.$$.fragment),zQe=l(),xf=a("h2"),V0=a("a"),Iwe=a("span"),F(Tk.$$.fragment),fat=l(),Nwe=a("span"),mat=o("FlaxAutoModelForVision2Seq"),QQe=l(),Lr=a("div"),F(Mk.$$.fragment),gat=l(),$f=a("p"),hat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kre=a("a"),pat=o("from_pretrained()"),_at=o(" class method or the "),Zre=a("a"),uat=o("from_config()"),bat=o(` class
method.`),vat=l(),Ek=a("p"),Fat=o("This class cannot be instantiated directly using "),qwe=a("code"),Tat=o("__init__()"),Mat=o(" (throws an error)."),Eat=l(),aa=a("div"),F(Ck.$$.fragment),Cat=l(),jwe=a("p"),wat=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Aat=l(),kf=a("p"),Lat=o(`Note:
Loading a model from its configuration file does `),Dwe=a("strong"),yat=o("not"),xat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=a("a"),$at=o("from_pretrained()"),kat=o(" to load the model weights."),Sat=l(),F(X0.$$.fragment),Rat=l(),ot=a("div"),F(wk.$$.fragment),Pat=l(),Gwe=a("p"),Bat=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Iat=l(),Rn=a("p"),Nat=o("The model class to instantiate is selected based on the "),Owe=a("code"),qat=o("model_type"),jat=o(` property of the config object (either
passed as an argument or loaded from `),Vwe=a("code"),Dat=o("pretrained_model_name_or_path"),Gat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xwe=a("code"),Oat=o("pretrained_model_name_or_path"),Vat=o(":"),Xat=l(),zwe=a("ul"),z0=a("li"),Qwe=a("strong"),zat=o("vision-encoder-decoder"),Qat=o(" \u2014 "),ote=a("a"),Wat=o("FlaxVisionEncoderDecoderModel"),Hat=o(" (Vision Encoder decoder model)"),Uat=l(),F(Q0.$$.fragment),this.h()},l(f){const u=JHt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var Ak=s(p);m=n(Ak,"A",{id:!0,class:!0,href:!0});var Wwe=s(m);_=n(Wwe,"SPAN",{});var Hwe=s(_);T(c.$$.fragment,Hwe),Hwe.forEach(t),Wwe.forEach(t),h=i(Ak),wo=n(Ak,"SPAN",{});var Uwe=s(wo);xi=r(Uwe,"Auto Classes"),Uwe.forEach(t),Ak.forEach(t),Bf=i(f),lt=n(f,"P",{});var Lk=s(lt);$i=r(Lk,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ki=n(Lk,"CODE",{});var Jwe=s(ki);mL=r(Jwe,"from_pretrained()"),Jwe.forEach(t),If=r(Lk,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Lk.forEach(t),Oe=i(f),We=n(f,"P",{});var Pn=s(We);Si=r(Pn,"Instantiating one of "),Bn=n(Pn,"A",{href:!0});var Ywe=s(Bn);gL=r(Ywe,"AutoConfig"),Ywe.forEach(t),In=r(Pn,", "),Nn=n(Pn,"A",{href:!0});var Kwe=s(Nn);hL=r(Kwe,"AutoModel"),Kwe.forEach(t),Ri=r(Pn,`, and
`),qn=n(Pn,"A",{href:!0});var Zwe=s(qn);pL=r(Zwe,"AutoTokenizer"),Zwe.forEach(t),Pi=r(Pn," will directly create a class of the relevant architecture. For instance"),Pn.forEach(t),Nf=i(f),T(Sa.$$.fragment,f),He=i(f),Ae=n(f,"P",{});var yk=s(Ae);HS=r(yk,"will create a model that is an instance of "),Bi=n(yk,"A",{href:!0});var eAe=s(Bi);US=r(eAe,"BertModel"),eAe.forEach(t),JS=r(yk,"."),yk.forEach(t),Ao=i(f),Ra=n(f,"P",{});var xk=s(Ra);YS=r(xk,"There is one class of "),qf=n(xk,"CODE",{});var oAe=s(qf);KS=r(oAe,"AutoModel"),oAe.forEach(t),tUe=r(xk," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),xk.forEach(t),OXe=i(f),Ii=n(f,"H2",{class:!0});var $k=s(Ii);jf=n($k,"A",{id:!0,class:!0,href:!0});var rAe=s(jf);Uae=n(rAe,"SPAN",{});var tAe=s(Uae);T(_L.$$.fragment,tAe),tAe.forEach(t),rAe.forEach(t),aUe=i($k),Jae=n($k,"SPAN",{});var aAe=s(Jae);nUe=r(aAe,"Extending the Auto Classes"),aAe.forEach(t),$k.forEach(t),VXe=i(f),jn=n(f,"P",{});var Sf=s(jn);sUe=r(Sf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yae=n(Sf,"CODE",{});var nAe=s(Yae);lUe=r(nAe,"NewModel"),nAe.forEach(t),iUe=r(Sf,", make sure you have a "),Kae=n(Sf,"CODE",{});var sAe=s(Kae);dUe=r(sAe,"NewModelConfig"),sAe.forEach(t),cUe=r(Sf,` then you can add those to the auto
classes like this:`),Sf.forEach(t),XXe=i(f),T(uL.$$.fragment,f),zXe=i(f),ZS=n(f,"P",{});var lAe=s(ZS);fUe=r(lAe,"You will then be able to use the auto classes like you would usually do!"),lAe.forEach(t),QXe=i(f),T(Df.$$.fragment,f),WXe=i(f),Ni=n(f,"H2",{class:!0});var kk=s(Ni);Gf=n(kk,"A",{id:!0,class:!0,href:!0});var iAe=s(Gf);Zae=n(iAe,"SPAN",{});var dAe=s(Zae);T(bL.$$.fragment,dAe),dAe.forEach(t),iAe.forEach(t),mUe=i(kk),ene=n(kk,"SPAN",{});var cAe=s(ene);gUe=r(cAe,"AutoConfig"),cAe.forEach(t),kk.forEach(t),HXe=i(f),Lo=n(f,"DIV",{class:!0});var nt=s(Lo);T(vL.$$.fragment,nt),hUe=i(nt),FL=n(nt,"P",{});var Sk=s(FL);pUe=r(Sk,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),eR=n(Sk,"A",{href:!0});var fAe=s(eR);_Ue=r(fAe,"from_pretrained()"),fAe.forEach(t),uUe=r(Sk," class method."),Sk.forEach(t),bUe=i(nt),TL=n(nt,"P",{});var Rk=s(TL);vUe=r(Rk,"This class cannot be instantiated directly using "),one=n(Rk,"CODE",{});var mAe=s(one);FUe=r(mAe,"__init__()"),mAe.forEach(t),TUe=r(Rk," (throws an error)."),Rk.forEach(t),MUe=i(nt),yr=n(nt,"DIV",{class:!0});var st=s(yr);T(ML.$$.fragment,st),EUe=i(st),rne=n(st,"P",{});var gAe=s(rne);CUe=r(gAe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),gAe.forEach(t),wUe=i(st),qi=n(st,"P",{});var Rf=s(qi);AUe=r(Rf,"The configuration class to instantiate is selected based on the "),tne=n(Rf,"CODE",{});var hAe=s(tne);LUe=r(hAe,"model_type"),hAe.forEach(t),yUe=r(Rf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ane=n(Rf,"CODE",{});var pAe=s(ane);xUe=r(pAe,"pretrained_model_name_or_path"),pAe.forEach(t),$Ue=r(Rf,":"),Rf.forEach(t),kUe=i(st),A=n(st,"UL",{});var L=s(A);Of=n(L,"LI",{});var W0=s(Of);nne=n(W0,"STRONG",{});var _Ae=s(nne);SUe=r(_Ae,"albert"),_Ae.forEach(t),RUe=r(W0," \u2014 "),oR=n(W0,"A",{href:!0});var uAe=s(oR);PUe=r(uAe,"AlbertConfig"),uAe.forEach(t),BUe=r(W0," (ALBERT model)"),W0.forEach(t),IUe=i(L),Vf=n(L,"LI",{});var H0=s(Vf);sne=n(H0,"STRONG",{});var bAe=s(sne);NUe=r(bAe,"bart"),bAe.forEach(t),qUe=r(H0," \u2014 "),rR=n(H0,"A",{href:!0});var vAe=s(rR);jUe=r(vAe,"BartConfig"),vAe.forEach(t),DUe=r(H0," (BART model)"),H0.forEach(t),GUe=i(L),Xf=n(L,"LI",{});var U0=s(Xf);lne=n(U0,"STRONG",{});var FAe=s(lne);OUe=r(FAe,"beit"),FAe.forEach(t),VUe=r(U0," \u2014 "),tR=n(U0,"A",{href:!0});var TAe=s(tR);XUe=r(TAe,"BeitConfig"),TAe.forEach(t),zUe=r(U0," (BEiT model)"),U0.forEach(t),QUe=i(L),zf=n(L,"LI",{});var J0=s(zf);ine=n(J0,"STRONG",{});var MAe=s(ine);WUe=r(MAe,"bert"),MAe.forEach(t),HUe=r(J0," \u2014 "),aR=n(J0,"A",{href:!0});var EAe=s(aR);UUe=r(EAe,"BertConfig"),EAe.forEach(t),JUe=r(J0," (BERT model)"),J0.forEach(t),YUe=i(L),Qf=n(L,"LI",{});var Y0=s(Qf);dne=n(Y0,"STRONG",{});var CAe=s(dne);KUe=r(CAe,"bert-generation"),CAe.forEach(t),ZUe=r(Y0," \u2014 "),nR=n(Y0,"A",{href:!0});var wAe=s(nR);eJe=r(wAe,"BertGenerationConfig"),wAe.forEach(t),oJe=r(Y0," (Bert Generation model)"),Y0.forEach(t),rJe=i(L),Wf=n(L,"LI",{});var K0=s(Wf);cne=n(K0,"STRONG",{});var AAe=s(cne);tJe=r(AAe,"big_bird"),AAe.forEach(t),aJe=r(K0," \u2014 "),sR=n(K0,"A",{href:!0});var LAe=s(sR);nJe=r(LAe,"BigBirdConfig"),LAe.forEach(t),sJe=r(K0," (BigBird model)"),K0.forEach(t),lJe=i(L),Hf=n(L,"LI",{});var Z0=s(Hf);fne=n(Z0,"STRONG",{});var yAe=s(fne);iJe=r(yAe,"bigbird_pegasus"),yAe.forEach(t),dJe=r(Z0," \u2014 "),lR=n(Z0,"A",{href:!0});var xAe=s(lR);cJe=r(xAe,"BigBirdPegasusConfig"),xAe.forEach(t),fJe=r(Z0," (BigBird-Pegasus model)"),Z0.forEach(t),mJe=i(L),Uf=n(L,"LI",{});var ew=s(Uf);mne=n(ew,"STRONG",{});var $Ae=s(mne);gJe=r($Ae,"blenderbot"),$Ae.forEach(t),hJe=r(ew," \u2014 "),iR=n(ew,"A",{href:!0});var kAe=s(iR);pJe=r(kAe,"BlenderbotConfig"),kAe.forEach(t),_Je=r(ew," (Blenderbot model)"),ew.forEach(t),uJe=i(L),Jf=n(L,"LI",{});var ow=s(Jf);gne=n(ow,"STRONG",{});var SAe=s(gne);bJe=r(SAe,"blenderbot-small"),SAe.forEach(t),vJe=r(ow," \u2014 "),dR=n(ow,"A",{href:!0});var RAe=s(dR);FJe=r(RAe,"BlenderbotSmallConfig"),RAe.forEach(t),TJe=r(ow," (BlenderbotSmall model)"),ow.forEach(t),MJe=i(L),Yf=n(L,"LI",{});var rw=s(Yf);hne=n(rw,"STRONG",{});var PAe=s(hne);EJe=r(PAe,"bloom"),PAe.forEach(t),CJe=r(rw," \u2014 "),cR=n(rw,"A",{href:!0});var BAe=s(cR);wJe=r(BAe,"BloomConfig"),BAe.forEach(t),AJe=r(rw," (BLOOM model)"),rw.forEach(t),LJe=i(L),Kf=n(L,"LI",{});var tw=s(Kf);pne=n(tw,"STRONG",{});var IAe=s(pne);yJe=r(IAe,"camembert"),IAe.forEach(t),xJe=r(tw," \u2014 "),fR=n(tw,"A",{href:!0});var NAe=s(fR);$Je=r(NAe,"CamembertConfig"),NAe.forEach(t),kJe=r(tw," (CamemBERT model)"),tw.forEach(t),SJe=i(L),Zf=n(L,"LI",{});var aw=s(Zf);_ne=n(aw,"STRONG",{});var qAe=s(_ne);RJe=r(qAe,"canine"),qAe.forEach(t),PJe=r(aw," \u2014 "),mR=n(aw,"A",{href:!0});var jAe=s(mR);BJe=r(jAe,"CanineConfig"),jAe.forEach(t),IJe=r(aw," (CANINE model)"),aw.forEach(t),NJe=i(L),em=n(L,"LI",{});var nw=s(em);une=n(nw,"STRONG",{});var DAe=s(une);qJe=r(DAe,"clip"),DAe.forEach(t),jJe=r(nw," \u2014 "),gR=n(nw,"A",{href:!0});var GAe=s(gR);DJe=r(GAe,"CLIPConfig"),GAe.forEach(t),GJe=r(nw," (CLIP model)"),nw.forEach(t),OJe=i(L),om=n(L,"LI",{});var sw=s(om);bne=n(sw,"STRONG",{});var OAe=s(bne);VJe=r(OAe,"codegen"),OAe.forEach(t),XJe=r(sw," \u2014 "),hR=n(sw,"A",{href:!0});var VAe=s(hR);zJe=r(VAe,"CodeGenConfig"),VAe.forEach(t),QJe=r(sw," (CodeGen model)"),sw.forEach(t),WJe=i(L),rm=n(L,"LI",{});var lw=s(rm);vne=n(lw,"STRONG",{});var XAe=s(vne);HJe=r(XAe,"convbert"),XAe.forEach(t),UJe=r(lw," \u2014 "),pR=n(lw,"A",{href:!0});var zAe=s(pR);JJe=r(zAe,"ConvBertConfig"),zAe.forEach(t),YJe=r(lw," (ConvBERT model)"),lw.forEach(t),KJe=i(L),tm=n(L,"LI",{});var iw=s(tm);Fne=n(iw,"STRONG",{});var QAe=s(Fne);ZJe=r(QAe,"convnext"),QAe.forEach(t),eYe=r(iw," \u2014 "),_R=n(iw,"A",{href:!0});var WAe=s(_R);oYe=r(WAe,"ConvNextConfig"),WAe.forEach(t),rYe=r(iw," (ConvNeXT model)"),iw.forEach(t),tYe=i(L),am=n(L,"LI",{});var dw=s(am);Tne=n(dw,"STRONG",{});var HAe=s(Tne);aYe=r(HAe,"ctrl"),HAe.forEach(t),nYe=r(dw," \u2014 "),uR=n(dw,"A",{href:!0});var UAe=s(uR);sYe=r(UAe,"CTRLConfig"),UAe.forEach(t),lYe=r(dw," (CTRL model)"),dw.forEach(t),iYe=i(L),nm=n(L,"LI",{});var cw=s(nm);Mne=n(cw,"STRONG",{});var JAe=s(Mne);dYe=r(JAe,"cvt"),JAe.forEach(t),cYe=r(cw," \u2014 "),bR=n(cw,"A",{href:!0});var YAe=s(bR);fYe=r(YAe,"CvtConfig"),YAe.forEach(t),mYe=r(cw," (CvT model)"),cw.forEach(t),gYe=i(L),sm=n(L,"LI",{});var fw=s(sm);Ene=n(fw,"STRONG",{});var KAe=s(Ene);hYe=r(KAe,"data2vec-audio"),KAe.forEach(t),pYe=r(fw," \u2014 "),vR=n(fw,"A",{href:!0});var ZAe=s(vR);_Ye=r(ZAe,"Data2VecAudioConfig"),ZAe.forEach(t),uYe=r(fw," (Data2VecAudio model)"),fw.forEach(t),bYe=i(L),lm=n(L,"LI",{});var mw=s(lm);Cne=n(mw,"STRONG",{});var eLe=s(Cne);vYe=r(eLe,"data2vec-text"),eLe.forEach(t),FYe=r(mw," \u2014 "),FR=n(mw,"A",{href:!0});var oLe=s(FR);TYe=r(oLe,"Data2VecTextConfig"),oLe.forEach(t),MYe=r(mw," (Data2VecText model)"),mw.forEach(t),EYe=i(L),im=n(L,"LI",{});var gw=s(im);wne=n(gw,"STRONG",{});var rLe=s(wne);CYe=r(rLe,"data2vec-vision"),rLe.forEach(t),wYe=r(gw," \u2014 "),TR=n(gw,"A",{href:!0});var tLe=s(TR);AYe=r(tLe,"Data2VecVisionConfig"),tLe.forEach(t),LYe=r(gw," (Data2VecVision model)"),gw.forEach(t),yYe=i(L),dm=n(L,"LI",{});var hw=s(dm);Ane=n(hw,"STRONG",{});var aLe=s(Ane);xYe=r(aLe,"deberta"),aLe.forEach(t),$Ye=r(hw," \u2014 "),MR=n(hw,"A",{href:!0});var nLe=s(MR);kYe=r(nLe,"DebertaConfig"),nLe.forEach(t),SYe=r(hw," (DeBERTa model)"),hw.forEach(t),RYe=i(L),cm=n(L,"LI",{});var pw=s(cm);Lne=n(pw,"STRONG",{});var sLe=s(Lne);PYe=r(sLe,"deberta-v2"),sLe.forEach(t),BYe=r(pw," \u2014 "),ER=n(pw,"A",{href:!0});var lLe=s(ER);IYe=r(lLe,"DebertaV2Config"),lLe.forEach(t),NYe=r(pw," (DeBERTa-v2 model)"),pw.forEach(t),qYe=i(L),fm=n(L,"LI",{});var _w=s(fm);yne=n(_w,"STRONG",{});var Yat=s(yne);jYe=r(Yat,"decision_transformer"),Yat.forEach(t),DYe=r(_w," \u2014 "),CR=n(_w,"A",{href:!0});var Kat=s(CR);GYe=r(Kat,"DecisionTransformerConfig"),Kat.forEach(t),OYe=r(_w," (Decision Transformer model)"),_w.forEach(t),VYe=i(L),mm=n(L,"LI",{});var iLe=s(mm);xne=n(iLe,"STRONG",{});var Zat=s(xne);XYe=r(Zat,"deit"),Zat.forEach(t),zYe=r(iLe," \u2014 "),wR=n(iLe,"A",{href:!0});var ent=s(wR);QYe=r(ent,"DeiTConfig"),ent.forEach(t),WYe=r(iLe," (DeiT model)"),iLe.forEach(t),HYe=i(L),gm=n(L,"LI",{});var dLe=s(gm);$ne=n(dLe,"STRONG",{});var ont=s($ne);UYe=r(ont,"detr"),ont.forEach(t),JYe=r(dLe," \u2014 "),AR=n(dLe,"A",{href:!0});var rnt=s(AR);YYe=r(rnt,"DetrConfig"),rnt.forEach(t),KYe=r(dLe," (DETR model)"),dLe.forEach(t),ZYe=i(L),hm=n(L,"LI",{});var cLe=s(hm);kne=n(cLe,"STRONG",{});var tnt=s(kne);eKe=r(tnt,"distilbert"),tnt.forEach(t),oKe=r(cLe," \u2014 "),LR=n(cLe,"A",{href:!0});var ant=s(LR);rKe=r(ant,"DistilBertConfig"),ant.forEach(t),tKe=r(cLe," (DistilBERT model)"),cLe.forEach(t),aKe=i(L),pm=n(L,"LI",{});var fLe=s(pm);Sne=n(fLe,"STRONG",{});var nnt=s(Sne);nKe=r(nnt,"dpr"),nnt.forEach(t),sKe=r(fLe," \u2014 "),yR=n(fLe,"A",{href:!0});var snt=s(yR);lKe=r(snt,"DPRConfig"),snt.forEach(t),iKe=r(fLe," (DPR model)"),fLe.forEach(t),dKe=i(L),_m=n(L,"LI",{});var mLe=s(_m);Rne=n(mLe,"STRONG",{});var lnt=s(Rne);cKe=r(lnt,"dpt"),lnt.forEach(t),fKe=r(mLe," \u2014 "),xR=n(mLe,"A",{href:!0});var int=s(xR);mKe=r(int,"DPTConfig"),int.forEach(t),gKe=r(mLe," (DPT model)"),mLe.forEach(t),hKe=i(L),um=n(L,"LI",{});var gLe=s(um);Pne=n(gLe,"STRONG",{});var dnt=s(Pne);pKe=r(dnt,"electra"),dnt.forEach(t),_Ke=r(gLe," \u2014 "),$R=n(gLe,"A",{href:!0});var cnt=s($R);uKe=r(cnt,"ElectraConfig"),cnt.forEach(t),bKe=r(gLe," (ELECTRA model)"),gLe.forEach(t),vKe=i(L),bm=n(L,"LI",{});var hLe=s(bm);Bne=n(hLe,"STRONG",{});var fnt=s(Bne);FKe=r(fnt,"encoder-decoder"),fnt.forEach(t),TKe=r(hLe," \u2014 "),kR=n(hLe,"A",{href:!0});var mnt=s(kR);MKe=r(mnt,"EncoderDecoderConfig"),mnt.forEach(t),EKe=r(hLe," (Encoder decoder model)"),hLe.forEach(t),CKe=i(L),vm=n(L,"LI",{});var pLe=s(vm);Ine=n(pLe,"STRONG",{});var gnt=s(Ine);wKe=r(gnt,"flaubert"),gnt.forEach(t),AKe=r(pLe," \u2014 "),SR=n(pLe,"A",{href:!0});var hnt=s(SR);LKe=r(hnt,"FlaubertConfig"),hnt.forEach(t),yKe=r(pLe," (FlauBERT model)"),pLe.forEach(t),xKe=i(L),Fm=n(L,"LI",{});var _Le=s(Fm);Nne=n(_Le,"STRONG",{});var pnt=s(Nne);$Ke=r(pnt,"flava"),pnt.forEach(t),kKe=r(_Le," \u2014 "),RR=n(_Le,"A",{href:!0});var _nt=s(RR);SKe=r(_nt,"FlavaConfig"),_nt.forEach(t),RKe=r(_Le," (FLAVA model)"),_Le.forEach(t),PKe=i(L),Tm=n(L,"LI",{});var uLe=s(Tm);qne=n(uLe,"STRONG",{});var unt=s(qne);BKe=r(unt,"fnet"),unt.forEach(t),IKe=r(uLe," \u2014 "),PR=n(uLe,"A",{href:!0});var bnt=s(PR);NKe=r(bnt,"FNetConfig"),bnt.forEach(t),qKe=r(uLe," (FNet model)"),uLe.forEach(t),jKe=i(L),Mm=n(L,"LI",{});var bLe=s(Mm);jne=n(bLe,"STRONG",{});var vnt=s(jne);DKe=r(vnt,"fsmt"),vnt.forEach(t),GKe=r(bLe," \u2014 "),BR=n(bLe,"A",{href:!0});var Fnt=s(BR);OKe=r(Fnt,"FSMTConfig"),Fnt.forEach(t),VKe=r(bLe," (FairSeq Machine-Translation model)"),bLe.forEach(t),XKe=i(L),Em=n(L,"LI",{});var vLe=s(Em);Dne=n(vLe,"STRONG",{});var Tnt=s(Dne);zKe=r(Tnt,"funnel"),Tnt.forEach(t),QKe=r(vLe," \u2014 "),IR=n(vLe,"A",{href:!0});var Mnt=s(IR);WKe=r(Mnt,"FunnelConfig"),Mnt.forEach(t),HKe=r(vLe," (Funnel Transformer model)"),vLe.forEach(t),UKe=i(L),Cm=n(L,"LI",{});var FLe=s(Cm);Gne=n(FLe,"STRONG",{});var Ent=s(Gne);JKe=r(Ent,"glpn"),Ent.forEach(t),YKe=r(FLe," \u2014 "),NR=n(FLe,"A",{href:!0});var Cnt=s(NR);KKe=r(Cnt,"GLPNConfig"),Cnt.forEach(t),ZKe=r(FLe," (GLPN model)"),FLe.forEach(t),eZe=i(L),wm=n(L,"LI",{});var TLe=s(wm);One=n(TLe,"STRONG",{});var wnt=s(One);oZe=r(wnt,"gpt2"),wnt.forEach(t),rZe=r(TLe," \u2014 "),qR=n(TLe,"A",{href:!0});var Ant=s(qR);tZe=r(Ant,"GPT2Config"),Ant.forEach(t),aZe=r(TLe," (OpenAI GPT-2 model)"),TLe.forEach(t),nZe=i(L),Am=n(L,"LI",{});var MLe=s(Am);Vne=n(MLe,"STRONG",{});var Lnt=s(Vne);sZe=r(Lnt,"gpt_neo"),Lnt.forEach(t),lZe=r(MLe," \u2014 "),jR=n(MLe,"A",{href:!0});var ynt=s(jR);iZe=r(ynt,"GPTNeoConfig"),ynt.forEach(t),dZe=r(MLe," (GPT Neo model)"),MLe.forEach(t),cZe=i(L),Lm=n(L,"LI",{});var ELe=s(Lm);Xne=n(ELe,"STRONG",{});var xnt=s(Xne);fZe=r(xnt,"gpt_neox"),xnt.forEach(t),mZe=r(ELe," \u2014 "),DR=n(ELe,"A",{href:!0});var $nt=s(DR);gZe=r($nt,"GPTNeoXConfig"),$nt.forEach(t),hZe=r(ELe," (GPT NeoX model)"),ELe.forEach(t),pZe=i(L),ym=n(L,"LI",{});var CLe=s(ym);zne=n(CLe,"STRONG",{});var knt=s(zne);_Ze=r(knt,"gptj"),knt.forEach(t),uZe=r(CLe," \u2014 "),GR=n(CLe,"A",{href:!0});var Snt=s(GR);bZe=r(Snt,"GPTJConfig"),Snt.forEach(t),vZe=r(CLe," (GPT-J model)"),CLe.forEach(t),FZe=i(L),xm=n(L,"LI",{});var wLe=s(xm);Qne=n(wLe,"STRONG",{});var Rnt=s(Qne);TZe=r(Rnt,"groupvit"),Rnt.forEach(t),MZe=r(wLe," \u2014 "),OR=n(wLe,"A",{href:!0});var Pnt=s(OR);EZe=r(Pnt,"GroupViTConfig"),Pnt.forEach(t),CZe=r(wLe," (GroupViT model)"),wLe.forEach(t),wZe=i(L),$m=n(L,"LI",{});var ALe=s($m);Wne=n(ALe,"STRONG",{});var Bnt=s(Wne);AZe=r(Bnt,"hubert"),Bnt.forEach(t),LZe=r(ALe," \u2014 "),VR=n(ALe,"A",{href:!0});var Int=s(VR);yZe=r(Int,"HubertConfig"),Int.forEach(t),xZe=r(ALe," (Hubert model)"),ALe.forEach(t),$Ze=i(L),km=n(L,"LI",{});var LLe=s(km);Hne=n(LLe,"STRONG",{});var Nnt=s(Hne);kZe=r(Nnt,"ibert"),Nnt.forEach(t),SZe=r(LLe," \u2014 "),XR=n(LLe,"A",{href:!0});var qnt=s(XR);RZe=r(qnt,"IBertConfig"),qnt.forEach(t),PZe=r(LLe," (I-BERT model)"),LLe.forEach(t),BZe=i(L),Sm=n(L,"LI",{});var yLe=s(Sm);Une=n(yLe,"STRONG",{});var jnt=s(Une);IZe=r(jnt,"imagegpt"),jnt.forEach(t),NZe=r(yLe," \u2014 "),zR=n(yLe,"A",{href:!0});var Dnt=s(zR);qZe=r(Dnt,"ImageGPTConfig"),Dnt.forEach(t),jZe=r(yLe," (ImageGPT model)"),yLe.forEach(t),DZe=i(L),Rm=n(L,"LI",{});var xLe=s(Rm);Jne=n(xLe,"STRONG",{});var Gnt=s(Jne);GZe=r(Gnt,"layoutlm"),Gnt.forEach(t),OZe=r(xLe," \u2014 "),QR=n(xLe,"A",{href:!0});var Ont=s(QR);VZe=r(Ont,"LayoutLMConfig"),Ont.forEach(t),XZe=r(xLe," (LayoutLM model)"),xLe.forEach(t),zZe=i(L),Pm=n(L,"LI",{});var $Le=s(Pm);Yne=n($Le,"STRONG",{});var Vnt=s(Yne);QZe=r(Vnt,"layoutlmv2"),Vnt.forEach(t),WZe=r($Le," \u2014 "),WR=n($Le,"A",{href:!0});var Xnt=s(WR);HZe=r(Xnt,"LayoutLMv2Config"),Xnt.forEach(t),UZe=r($Le," (LayoutLMv2 model)"),$Le.forEach(t),JZe=i(L),Bm=n(L,"LI",{});var kLe=s(Bm);Kne=n(kLe,"STRONG",{});var znt=s(Kne);YZe=r(znt,"layoutlmv3"),znt.forEach(t),KZe=r(kLe," \u2014 "),HR=n(kLe,"A",{href:!0});var Qnt=s(HR);ZZe=r(Qnt,"LayoutLMv3Config"),Qnt.forEach(t),eeo=r(kLe," (LayoutLMv3 model)"),kLe.forEach(t),oeo=i(L),Im=n(L,"LI",{});var SLe=s(Im);Zne=n(SLe,"STRONG",{});var Wnt=s(Zne);reo=r(Wnt,"led"),Wnt.forEach(t),teo=r(SLe," \u2014 "),UR=n(SLe,"A",{href:!0});var Hnt=s(UR);aeo=r(Hnt,"LEDConfig"),Hnt.forEach(t),neo=r(SLe," (LED model)"),SLe.forEach(t),seo=i(L),Nm=n(L,"LI",{});var RLe=s(Nm);ese=n(RLe,"STRONG",{});var Unt=s(ese);leo=r(Unt,"levit"),Unt.forEach(t),ieo=r(RLe," \u2014 "),JR=n(RLe,"A",{href:!0});var Jnt=s(JR);deo=r(Jnt,"LevitConfig"),Jnt.forEach(t),ceo=r(RLe," (LeViT model)"),RLe.forEach(t),feo=i(L),qm=n(L,"LI",{});var PLe=s(qm);ose=n(PLe,"STRONG",{});var Ynt=s(ose);meo=r(Ynt,"longformer"),Ynt.forEach(t),geo=r(PLe," \u2014 "),YR=n(PLe,"A",{href:!0});var Knt=s(YR);heo=r(Knt,"LongformerConfig"),Knt.forEach(t),peo=r(PLe," (Longformer model)"),PLe.forEach(t),_eo=i(L),jm=n(L,"LI",{});var BLe=s(jm);rse=n(BLe,"STRONG",{});var Znt=s(rse);ueo=r(Znt,"longt5"),Znt.forEach(t),beo=r(BLe," \u2014 "),KR=n(BLe,"A",{href:!0});var est=s(KR);veo=r(est,"LongT5Config"),est.forEach(t),Feo=r(BLe," (LongT5 model)"),BLe.forEach(t),Teo=i(L),Dm=n(L,"LI",{});var ILe=s(Dm);tse=n(ILe,"STRONG",{});var ost=s(tse);Meo=r(ost,"luke"),ost.forEach(t),Eeo=r(ILe," \u2014 "),ZR=n(ILe,"A",{href:!0});var rst=s(ZR);Ceo=r(rst,"LukeConfig"),rst.forEach(t),weo=r(ILe," (LUKE model)"),ILe.forEach(t),Aeo=i(L),Gm=n(L,"LI",{});var NLe=s(Gm);ase=n(NLe,"STRONG",{});var tst=s(ase);Leo=r(tst,"lxmert"),tst.forEach(t),yeo=r(NLe," \u2014 "),eP=n(NLe,"A",{href:!0});var ast=s(eP);xeo=r(ast,"LxmertConfig"),ast.forEach(t),$eo=r(NLe," (LXMERT model)"),NLe.forEach(t),keo=i(L),Om=n(L,"LI",{});var qLe=s(Om);nse=n(qLe,"STRONG",{});var nst=s(nse);Seo=r(nst,"m2m_100"),nst.forEach(t),Reo=r(qLe," \u2014 "),oP=n(qLe,"A",{href:!0});var sst=s(oP);Peo=r(sst,"M2M100Config"),sst.forEach(t),Beo=r(qLe," (M2M100 model)"),qLe.forEach(t),Ieo=i(L),Vm=n(L,"LI",{});var jLe=s(Vm);sse=n(jLe,"STRONG",{});var lst=s(sse);Neo=r(lst,"marian"),lst.forEach(t),qeo=r(jLe," \u2014 "),rP=n(jLe,"A",{href:!0});var ist=s(rP);jeo=r(ist,"MarianConfig"),ist.forEach(t),Deo=r(jLe," (Marian model)"),jLe.forEach(t),Geo=i(L),Xm=n(L,"LI",{});var DLe=s(Xm);lse=n(DLe,"STRONG",{});var dst=s(lse);Oeo=r(dst,"maskformer"),dst.forEach(t),Veo=r(DLe," \u2014 "),tP=n(DLe,"A",{href:!0});var cst=s(tP);Xeo=r(cst,"MaskFormerConfig"),cst.forEach(t),zeo=r(DLe," (MaskFormer model)"),DLe.forEach(t),Qeo=i(L),zm=n(L,"LI",{});var GLe=s(zm);ise=n(GLe,"STRONG",{});var fst=s(ise);Weo=r(fst,"mbart"),fst.forEach(t),Heo=r(GLe," \u2014 "),aP=n(GLe,"A",{href:!0});var mst=s(aP);Ueo=r(mst,"MBartConfig"),mst.forEach(t),Jeo=r(GLe," (mBART model)"),GLe.forEach(t),Yeo=i(L),Qm=n(L,"LI",{});var OLe=s(Qm);dse=n(OLe,"STRONG",{});var gst=s(dse);Keo=r(gst,"mctct"),gst.forEach(t),Zeo=r(OLe," \u2014 "),nP=n(OLe,"A",{href:!0});var hst=s(nP);eoo=r(hst,"MCTCTConfig"),hst.forEach(t),ooo=r(OLe," (M-CTC-T model)"),OLe.forEach(t),roo=i(L),Wm=n(L,"LI",{});var VLe=s(Wm);cse=n(VLe,"STRONG",{});var pst=s(cse);too=r(pst,"megatron-bert"),pst.forEach(t),aoo=r(VLe," \u2014 "),sP=n(VLe,"A",{href:!0});var _st=s(sP);noo=r(_st,"MegatronBertConfig"),_st.forEach(t),soo=r(VLe," (Megatron-BERT model)"),VLe.forEach(t),loo=i(L),Hm=n(L,"LI",{});var XLe=s(Hm);fse=n(XLe,"STRONG",{});var ust=s(fse);ioo=r(ust,"mobilebert"),ust.forEach(t),doo=r(XLe," \u2014 "),lP=n(XLe,"A",{href:!0});var bst=s(lP);coo=r(bst,"MobileBertConfig"),bst.forEach(t),foo=r(XLe," (MobileBERT model)"),XLe.forEach(t),moo=i(L),Um=n(L,"LI",{});var zLe=s(Um);mse=n(zLe,"STRONG",{});var vst=s(mse);goo=r(vst,"mobilevit"),vst.forEach(t),hoo=r(zLe," \u2014 "),iP=n(zLe,"A",{href:!0});var Fst=s(iP);poo=r(Fst,"MobileViTConfig"),Fst.forEach(t),_oo=r(zLe," (MobileViT model)"),zLe.forEach(t),uoo=i(L),Jm=n(L,"LI",{});var QLe=s(Jm);gse=n(QLe,"STRONG",{});var Tst=s(gse);boo=r(Tst,"mpnet"),Tst.forEach(t),voo=r(QLe," \u2014 "),dP=n(QLe,"A",{href:!0});var Mst=s(dP);Foo=r(Mst,"MPNetConfig"),Mst.forEach(t),Too=r(QLe," (MPNet model)"),QLe.forEach(t),Moo=i(L),Ym=n(L,"LI",{});var WLe=s(Ym);hse=n(WLe,"STRONG",{});var Est=s(hse);Eoo=r(Est,"mt5"),Est.forEach(t),Coo=r(WLe," \u2014 "),cP=n(WLe,"A",{href:!0});var Cst=s(cP);woo=r(Cst,"MT5Config"),Cst.forEach(t),Aoo=r(WLe," (MT5 model)"),WLe.forEach(t),Loo=i(L),Km=n(L,"LI",{});var HLe=s(Km);pse=n(HLe,"STRONG",{});var wst=s(pse);yoo=r(wst,"mvp"),wst.forEach(t),xoo=r(HLe," \u2014 "),fP=n(HLe,"A",{href:!0});var Ast=s(fP);$oo=r(Ast,"MvpConfig"),Ast.forEach(t),koo=r(HLe," (MVP model)"),HLe.forEach(t),Soo=i(L),Zm=n(L,"LI",{});var ULe=s(Zm);_se=n(ULe,"STRONG",{});var Lst=s(_se);Roo=r(Lst,"nezha"),Lst.forEach(t),Poo=r(ULe," \u2014 "),mP=n(ULe,"A",{href:!0});var yst=s(mP);Boo=r(yst,"NezhaConfig"),yst.forEach(t),Ioo=r(ULe," (Nezha model)"),ULe.forEach(t),Noo=i(L),eg=n(L,"LI",{});var JLe=s(eg);use=n(JLe,"STRONG",{});var xst=s(use);qoo=r(xst,"nystromformer"),xst.forEach(t),joo=r(JLe," \u2014 "),gP=n(JLe,"A",{href:!0});var $st=s(gP);Doo=r($st,"NystromformerConfig"),$st.forEach(t),Goo=r(JLe," (Nystr\xF6mformer model)"),JLe.forEach(t),Ooo=i(L),og=n(L,"LI",{});var YLe=s(og);bse=n(YLe,"STRONG",{});var kst=s(bse);Voo=r(kst,"openai-gpt"),kst.forEach(t),Xoo=r(YLe," \u2014 "),hP=n(YLe,"A",{href:!0});var Sst=s(hP);zoo=r(Sst,"OpenAIGPTConfig"),Sst.forEach(t),Qoo=r(YLe," (OpenAI GPT model)"),YLe.forEach(t),Woo=i(L),rg=n(L,"LI",{});var KLe=s(rg);vse=n(KLe,"STRONG",{});var Rst=s(vse);Hoo=r(Rst,"opt"),Rst.forEach(t),Uoo=r(KLe," \u2014 "),pP=n(KLe,"A",{href:!0});var Pst=s(pP);Joo=r(Pst,"OPTConfig"),Pst.forEach(t),Yoo=r(KLe," (OPT model)"),KLe.forEach(t),Koo=i(L),tg=n(L,"LI",{});var ZLe=s(tg);Fse=n(ZLe,"STRONG",{});var Bst=s(Fse);Zoo=r(Bst,"pegasus"),Bst.forEach(t),ero=r(ZLe," \u2014 "),_P=n(ZLe,"A",{href:!0});var Ist=s(_P);oro=r(Ist,"PegasusConfig"),Ist.forEach(t),rro=r(ZLe," (Pegasus model)"),ZLe.forEach(t),tro=i(L),ag=n(L,"LI",{});var eye=s(ag);Tse=n(eye,"STRONG",{});var Nst=s(Tse);aro=r(Nst,"perceiver"),Nst.forEach(t),nro=r(eye," \u2014 "),uP=n(eye,"A",{href:!0});var qst=s(uP);sro=r(qst,"PerceiverConfig"),qst.forEach(t),lro=r(eye," (Perceiver model)"),eye.forEach(t),iro=i(L),ng=n(L,"LI",{});var oye=s(ng);Mse=n(oye,"STRONG",{});var jst=s(Mse);dro=r(jst,"plbart"),jst.forEach(t),cro=r(oye," \u2014 "),bP=n(oye,"A",{href:!0});var Dst=s(bP);fro=r(Dst,"PLBartConfig"),Dst.forEach(t),mro=r(oye," (PLBart model)"),oye.forEach(t),gro=i(L),sg=n(L,"LI",{});var rye=s(sg);Ese=n(rye,"STRONG",{});var Gst=s(Ese);hro=r(Gst,"poolformer"),Gst.forEach(t),pro=r(rye," \u2014 "),vP=n(rye,"A",{href:!0});var Ost=s(vP);_ro=r(Ost,"PoolFormerConfig"),Ost.forEach(t),uro=r(rye," (PoolFormer model)"),rye.forEach(t),bro=i(L),lg=n(L,"LI",{});var tye=s(lg);Cse=n(tye,"STRONG",{});var Vst=s(Cse);vro=r(Vst,"prophetnet"),Vst.forEach(t),Fro=r(tye," \u2014 "),FP=n(tye,"A",{href:!0});var Xst=s(FP);Tro=r(Xst,"ProphetNetConfig"),Xst.forEach(t),Mro=r(tye," (ProphetNet model)"),tye.forEach(t),Ero=i(L),ig=n(L,"LI",{});var aye=s(ig);wse=n(aye,"STRONG",{});var zst=s(wse);Cro=r(zst,"qdqbert"),zst.forEach(t),wro=r(aye," \u2014 "),TP=n(aye,"A",{href:!0});var Qst=s(TP);Aro=r(Qst,"QDQBertConfig"),Qst.forEach(t),Lro=r(aye," (QDQBert model)"),aye.forEach(t),yro=i(L),dg=n(L,"LI",{});var nye=s(dg);Ase=n(nye,"STRONG",{});var Wst=s(Ase);xro=r(Wst,"rag"),Wst.forEach(t),$ro=r(nye," \u2014 "),MP=n(nye,"A",{href:!0});var Hst=s(MP);kro=r(Hst,"RagConfig"),Hst.forEach(t),Sro=r(nye," (RAG model)"),nye.forEach(t),Rro=i(L),cg=n(L,"LI",{});var sye=s(cg);Lse=n(sye,"STRONG",{});var Ust=s(Lse);Pro=r(Ust,"realm"),Ust.forEach(t),Bro=r(sye," \u2014 "),EP=n(sye,"A",{href:!0});var Jst=s(EP);Iro=r(Jst,"RealmConfig"),Jst.forEach(t),Nro=r(sye," (REALM model)"),sye.forEach(t),qro=i(L),fg=n(L,"LI",{});var lye=s(fg);yse=n(lye,"STRONG",{});var Yst=s(yse);jro=r(Yst,"reformer"),Yst.forEach(t),Dro=r(lye," \u2014 "),CP=n(lye,"A",{href:!0});var Kst=s(CP);Gro=r(Kst,"ReformerConfig"),Kst.forEach(t),Oro=r(lye," (Reformer model)"),lye.forEach(t),Vro=i(L),mg=n(L,"LI",{});var iye=s(mg);xse=n(iye,"STRONG",{});var Zst=s(xse);Xro=r(Zst,"regnet"),Zst.forEach(t),zro=r(iye," \u2014 "),wP=n(iye,"A",{href:!0});var elt=s(wP);Qro=r(elt,"RegNetConfig"),elt.forEach(t),Wro=r(iye," (RegNet model)"),iye.forEach(t),Hro=i(L),gg=n(L,"LI",{});var dye=s(gg);$se=n(dye,"STRONG",{});var olt=s($se);Uro=r(olt,"rembert"),olt.forEach(t),Jro=r(dye," \u2014 "),AP=n(dye,"A",{href:!0});var rlt=s(AP);Yro=r(rlt,"RemBertConfig"),rlt.forEach(t),Kro=r(dye," (RemBERT model)"),dye.forEach(t),Zro=i(L),hg=n(L,"LI",{});var cye=s(hg);kse=n(cye,"STRONG",{});var tlt=s(kse);eto=r(tlt,"resnet"),tlt.forEach(t),oto=r(cye," \u2014 "),LP=n(cye,"A",{href:!0});var alt=s(LP);rto=r(alt,"ResNetConfig"),alt.forEach(t),tto=r(cye," (ResNet model)"),cye.forEach(t),ato=i(L),pg=n(L,"LI",{});var fye=s(pg);Sse=n(fye,"STRONG",{});var nlt=s(Sse);nto=r(nlt,"retribert"),nlt.forEach(t),sto=r(fye," \u2014 "),yP=n(fye,"A",{href:!0});var slt=s(yP);lto=r(slt,"RetriBertConfig"),slt.forEach(t),ito=r(fye," (RetriBERT model)"),fye.forEach(t),dto=i(L),_g=n(L,"LI",{});var mye=s(_g);Rse=n(mye,"STRONG",{});var llt=s(Rse);cto=r(llt,"roberta"),llt.forEach(t),fto=r(mye," \u2014 "),xP=n(mye,"A",{href:!0});var ilt=s(xP);mto=r(ilt,"RobertaConfig"),ilt.forEach(t),gto=r(mye," (RoBERTa model)"),mye.forEach(t),hto=i(L),ug=n(L,"LI",{});var gye=s(ug);Pse=n(gye,"STRONG",{});var dlt=s(Pse);pto=r(dlt,"roformer"),dlt.forEach(t),_to=r(gye," \u2014 "),$P=n(gye,"A",{href:!0});var clt=s($P);uto=r(clt,"RoFormerConfig"),clt.forEach(t),bto=r(gye," (RoFormer model)"),gye.forEach(t),vto=i(L),bg=n(L,"LI",{});var hye=s(bg);Bse=n(hye,"STRONG",{});var flt=s(Bse);Fto=r(flt,"segformer"),flt.forEach(t),Tto=r(hye," \u2014 "),kP=n(hye,"A",{href:!0});var mlt=s(kP);Mto=r(mlt,"SegformerConfig"),mlt.forEach(t),Eto=r(hye," (SegFormer model)"),hye.forEach(t),Cto=i(L),vg=n(L,"LI",{});var pye=s(vg);Ise=n(pye,"STRONG",{});var glt=s(Ise);wto=r(glt,"sew"),glt.forEach(t),Ato=r(pye," \u2014 "),SP=n(pye,"A",{href:!0});var hlt=s(SP);Lto=r(hlt,"SEWConfig"),hlt.forEach(t),yto=r(pye," (SEW model)"),pye.forEach(t),xto=i(L),Fg=n(L,"LI",{});var _ye=s(Fg);Nse=n(_ye,"STRONG",{});var plt=s(Nse);$to=r(plt,"sew-d"),plt.forEach(t),kto=r(_ye," \u2014 "),RP=n(_ye,"A",{href:!0});var _lt=s(RP);Sto=r(_lt,"SEWDConfig"),_lt.forEach(t),Rto=r(_ye," (SEW-D model)"),_ye.forEach(t),Pto=i(L),Tg=n(L,"LI",{});var uye=s(Tg);qse=n(uye,"STRONG",{});var ult=s(qse);Bto=r(ult,"speech-encoder-decoder"),ult.forEach(t),Ito=r(uye," \u2014 "),PP=n(uye,"A",{href:!0});var blt=s(PP);Nto=r(blt,"SpeechEncoderDecoderConfig"),blt.forEach(t),qto=r(uye," (Speech Encoder decoder model)"),uye.forEach(t),jto=i(L),Mg=n(L,"LI",{});var bye=s(Mg);jse=n(bye,"STRONG",{});var vlt=s(jse);Dto=r(vlt,"speech_to_text"),vlt.forEach(t),Gto=r(bye," \u2014 "),BP=n(bye,"A",{href:!0});var Flt=s(BP);Oto=r(Flt,"Speech2TextConfig"),Flt.forEach(t),Vto=r(bye," (Speech2Text model)"),bye.forEach(t),Xto=i(L),Eg=n(L,"LI",{});var vye=s(Eg);Dse=n(vye,"STRONG",{});var Tlt=s(Dse);zto=r(Tlt,"speech_to_text_2"),Tlt.forEach(t),Qto=r(vye," \u2014 "),IP=n(vye,"A",{href:!0});var Mlt=s(IP);Wto=r(Mlt,"Speech2Text2Config"),Mlt.forEach(t),Hto=r(vye," (Speech2Text2 model)"),vye.forEach(t),Uto=i(L),Cg=n(L,"LI",{});var Fye=s(Cg);Gse=n(Fye,"STRONG",{});var Elt=s(Gse);Jto=r(Elt,"splinter"),Elt.forEach(t),Yto=r(Fye," \u2014 "),NP=n(Fye,"A",{href:!0});var Clt=s(NP);Kto=r(Clt,"SplinterConfig"),Clt.forEach(t),Zto=r(Fye," (Splinter model)"),Fye.forEach(t),eao=i(L),wg=n(L,"LI",{});var Tye=s(wg);Ose=n(Tye,"STRONG",{});var wlt=s(Ose);oao=r(wlt,"squeezebert"),wlt.forEach(t),rao=r(Tye," \u2014 "),qP=n(Tye,"A",{href:!0});var Alt=s(qP);tao=r(Alt,"SqueezeBertConfig"),Alt.forEach(t),aao=r(Tye," (SqueezeBERT model)"),Tye.forEach(t),nao=i(L),Ag=n(L,"LI",{});var Mye=s(Ag);Vse=n(Mye,"STRONG",{});var Llt=s(Vse);sao=r(Llt,"swin"),Llt.forEach(t),lao=r(Mye," \u2014 "),jP=n(Mye,"A",{href:!0});var ylt=s(jP);iao=r(ylt,"SwinConfig"),ylt.forEach(t),dao=r(Mye," (Swin Transformer model)"),Mye.forEach(t),cao=i(L),Lg=n(L,"LI",{});var Eye=s(Lg);Xse=n(Eye,"STRONG",{});var xlt=s(Xse);fao=r(xlt,"swinv2"),xlt.forEach(t),mao=r(Eye," \u2014 "),DP=n(Eye,"A",{href:!0});var $lt=s(DP);gao=r($lt,"Swinv2Config"),$lt.forEach(t),hao=r(Eye," (Swin Transformer V2 model)"),Eye.forEach(t),pao=i(L),yg=n(L,"LI",{});var Cye=s(yg);zse=n(Cye,"STRONG",{});var klt=s(zse);_ao=r(klt,"t5"),klt.forEach(t),uao=r(Cye," \u2014 "),GP=n(Cye,"A",{href:!0});var Slt=s(GP);bao=r(Slt,"T5Config"),Slt.forEach(t),vao=r(Cye," (T5 model)"),Cye.forEach(t),Fao=i(L),xg=n(L,"LI",{});var wye=s(xg);Qse=n(wye,"STRONG",{});var Rlt=s(Qse);Tao=r(Rlt,"tapas"),Rlt.forEach(t),Mao=r(wye," \u2014 "),OP=n(wye,"A",{href:!0});var Plt=s(OP);Eao=r(Plt,"TapasConfig"),Plt.forEach(t),Cao=r(wye," (TAPAS model)"),wye.forEach(t),wao=i(L),$g=n(L,"LI",{});var Aye=s($g);Wse=n(Aye,"STRONG",{});var Blt=s(Wse);Aao=r(Blt,"trajectory_transformer"),Blt.forEach(t),Lao=r(Aye," \u2014 "),VP=n(Aye,"A",{href:!0});var Ilt=s(VP);yao=r(Ilt,"TrajectoryTransformerConfig"),Ilt.forEach(t),xao=r(Aye," (Trajectory Transformer model)"),Aye.forEach(t),$ao=i(L),kg=n(L,"LI",{});var Lye=s(kg);Hse=n(Lye,"STRONG",{});var Nlt=s(Hse);kao=r(Nlt,"transfo-xl"),Nlt.forEach(t),Sao=r(Lye," \u2014 "),XP=n(Lye,"A",{href:!0});var qlt=s(XP);Rao=r(qlt,"TransfoXLConfig"),qlt.forEach(t),Pao=r(Lye," (Transformer-XL model)"),Lye.forEach(t),Bao=i(L),Sg=n(L,"LI",{});var yye=s(Sg);Use=n(yye,"STRONG",{});var jlt=s(Use);Iao=r(jlt,"trocr"),jlt.forEach(t),Nao=r(yye," \u2014 "),zP=n(yye,"A",{href:!0});var Dlt=s(zP);qao=r(Dlt,"TrOCRConfig"),Dlt.forEach(t),jao=r(yye," (TrOCR model)"),yye.forEach(t),Dao=i(L),Rg=n(L,"LI",{});var xye=s(Rg);Jse=n(xye,"STRONG",{});var Glt=s(Jse);Gao=r(Glt,"unispeech"),Glt.forEach(t),Oao=r(xye," \u2014 "),QP=n(xye,"A",{href:!0});var Olt=s(QP);Vao=r(Olt,"UniSpeechConfig"),Olt.forEach(t),Xao=r(xye," (UniSpeech model)"),xye.forEach(t),zao=i(L),Pg=n(L,"LI",{});var $ye=s(Pg);Yse=n($ye,"STRONG",{});var Vlt=s(Yse);Qao=r(Vlt,"unispeech-sat"),Vlt.forEach(t),Wao=r($ye," \u2014 "),WP=n($ye,"A",{href:!0});var Xlt=s(WP);Hao=r(Xlt,"UniSpeechSatConfig"),Xlt.forEach(t),Uao=r($ye," (UniSpeechSat model)"),$ye.forEach(t),Jao=i(L),Bg=n(L,"LI",{});var kye=s(Bg);Kse=n(kye,"STRONG",{});var zlt=s(Kse);Yao=r(zlt,"van"),zlt.forEach(t),Kao=r(kye," \u2014 "),HP=n(kye,"A",{href:!0});var Qlt=s(HP);Zao=r(Qlt,"VanConfig"),Qlt.forEach(t),eno=r(kye," (VAN model)"),kye.forEach(t),ono=i(L),Ig=n(L,"LI",{});var Sye=s(Ig);Zse=n(Sye,"STRONG",{});var Wlt=s(Zse);rno=r(Wlt,"vilt"),Wlt.forEach(t),tno=r(Sye," \u2014 "),UP=n(Sye,"A",{href:!0});var Hlt=s(UP);ano=r(Hlt,"ViltConfig"),Hlt.forEach(t),nno=r(Sye," (ViLT model)"),Sye.forEach(t),sno=i(L),Ng=n(L,"LI",{});var Rye=s(Ng);ele=n(Rye,"STRONG",{});var Ult=s(ele);lno=r(Ult,"vision-encoder-decoder"),Ult.forEach(t),ino=r(Rye," \u2014 "),JP=n(Rye,"A",{href:!0});var Jlt=s(JP);dno=r(Jlt,"VisionEncoderDecoderConfig"),Jlt.forEach(t),cno=r(Rye," (Vision Encoder decoder model)"),Rye.forEach(t),fno=i(L),qg=n(L,"LI",{});var Pye=s(qg);ole=n(Pye,"STRONG",{});var Ylt=s(ole);mno=r(Ylt,"vision-text-dual-encoder"),Ylt.forEach(t),gno=r(Pye," \u2014 "),YP=n(Pye,"A",{href:!0});var Klt=s(YP);hno=r(Klt,"VisionTextDualEncoderConfig"),Klt.forEach(t),pno=r(Pye," (VisionTextDualEncoder model)"),Pye.forEach(t),_no=i(L),jg=n(L,"LI",{});var Bye=s(jg);rle=n(Bye,"STRONG",{});var Zlt=s(rle);uno=r(Zlt,"visual_bert"),Zlt.forEach(t),bno=r(Bye," \u2014 "),KP=n(Bye,"A",{href:!0});var eit=s(KP);vno=r(eit,"VisualBertConfig"),eit.forEach(t),Fno=r(Bye," (VisualBERT model)"),Bye.forEach(t),Tno=i(L),Dg=n(L,"LI",{});var Iye=s(Dg);tle=n(Iye,"STRONG",{});var oit=s(tle);Mno=r(oit,"vit"),oit.forEach(t),Eno=r(Iye," \u2014 "),ZP=n(Iye,"A",{href:!0});var rit=s(ZP);Cno=r(rit,"ViTConfig"),rit.forEach(t),wno=r(Iye," (ViT model)"),Iye.forEach(t),Ano=i(L),Gg=n(L,"LI",{});var Nye=s(Gg);ale=n(Nye,"STRONG",{});var tit=s(ale);Lno=r(tit,"vit_mae"),tit.forEach(t),yno=r(Nye," \u2014 "),eB=n(Nye,"A",{href:!0});var ait=s(eB);xno=r(ait,"ViTMAEConfig"),ait.forEach(t),$no=r(Nye," (ViTMAE model)"),Nye.forEach(t),kno=i(L),Og=n(L,"LI",{});var qye=s(Og);nle=n(qye,"STRONG",{});var nit=s(nle);Sno=r(nit,"wav2vec2"),nit.forEach(t),Rno=r(qye," \u2014 "),oB=n(qye,"A",{href:!0});var sit=s(oB);Pno=r(sit,"Wav2Vec2Config"),sit.forEach(t),Bno=r(qye," (Wav2Vec2 model)"),qye.forEach(t),Ino=i(L),Vg=n(L,"LI",{});var jye=s(Vg);sle=n(jye,"STRONG",{});var lit=s(sle);Nno=r(lit,"wav2vec2-conformer"),lit.forEach(t),qno=r(jye," \u2014 "),rB=n(jye,"A",{href:!0});var iit=s(rB);jno=r(iit,"Wav2Vec2ConformerConfig"),iit.forEach(t),Dno=r(jye," (Wav2Vec2-Conformer model)"),jye.forEach(t),Gno=i(L),Xg=n(L,"LI",{});var Dye=s(Xg);lle=n(Dye,"STRONG",{});var dit=s(lle);Ono=r(dit,"wavlm"),dit.forEach(t),Vno=r(Dye," \u2014 "),tB=n(Dye,"A",{href:!0});var cit=s(tB);Xno=r(cit,"WavLMConfig"),cit.forEach(t),zno=r(Dye," (WavLM model)"),Dye.forEach(t),Qno=i(L),zg=n(L,"LI",{});var Gye=s(zg);ile=n(Gye,"STRONG",{});var fit=s(ile);Wno=r(fit,"xglm"),fit.forEach(t),Hno=r(Gye," \u2014 "),aB=n(Gye,"A",{href:!0});var mit=s(aB);Uno=r(mit,"XGLMConfig"),mit.forEach(t),Jno=r(Gye," (XGLM model)"),Gye.forEach(t),Yno=i(L),Qg=n(L,"LI",{});var Oye=s(Qg);dle=n(Oye,"STRONG",{});var git=s(dle);Kno=r(git,"xlm"),git.forEach(t),Zno=r(Oye," \u2014 "),nB=n(Oye,"A",{href:!0});var hit=s(nB);eso=r(hit,"XLMConfig"),hit.forEach(t),oso=r(Oye," (XLM model)"),Oye.forEach(t),rso=i(L),Wg=n(L,"LI",{});var Vye=s(Wg);cle=n(Vye,"STRONG",{});var pit=s(cle);tso=r(pit,"xlm-prophetnet"),pit.forEach(t),aso=r(Vye," \u2014 "),sB=n(Vye,"A",{href:!0});var _it=s(sB);nso=r(_it,"XLMProphetNetConfig"),_it.forEach(t),sso=r(Vye," (XLM-ProphetNet model)"),Vye.forEach(t),lso=i(L),Hg=n(L,"LI",{});var Xye=s(Hg);fle=n(Xye,"STRONG",{});var uit=s(fle);iso=r(uit,"xlm-roberta"),uit.forEach(t),dso=r(Xye," \u2014 "),lB=n(Xye,"A",{href:!0});var bit=s(lB);cso=r(bit,"XLMRobertaConfig"),bit.forEach(t),fso=r(Xye," (XLM-RoBERTa model)"),Xye.forEach(t),mso=i(L),Ug=n(L,"LI",{});var zye=s(Ug);mle=n(zye,"STRONG",{});var vit=s(mle);gso=r(vit,"xlm-roberta-xl"),vit.forEach(t),hso=r(zye," \u2014 "),iB=n(zye,"A",{href:!0});var Fit=s(iB);pso=r(Fit,"XLMRobertaXLConfig"),Fit.forEach(t),_so=r(zye," (XLM-RoBERTa-XL model)"),zye.forEach(t),uso=i(L),Jg=n(L,"LI",{});var Qye=s(Jg);gle=n(Qye,"STRONG",{});var Tit=s(gle);bso=r(Tit,"xlnet"),Tit.forEach(t),vso=r(Qye," \u2014 "),dB=n(Qye,"A",{href:!0});var Mit=s(dB);Fso=r(Mit,"XLNetConfig"),Mit.forEach(t),Tso=r(Qye," (XLNet model)"),Qye.forEach(t),Mso=i(L),Yg=n(L,"LI",{});var Wye=s(Yg);hle=n(Wye,"STRONG",{});var Eit=s(hle);Eso=r(Eit,"yolos"),Eit.forEach(t),Cso=r(Wye," \u2014 "),cB=n(Wye,"A",{href:!0});var Cit=s(cB);wso=r(Cit,"YolosConfig"),Cit.forEach(t),Aso=r(Wye," (YOLOS model)"),Wye.forEach(t),Lso=i(L),Kg=n(L,"LI",{});var Hye=s(Kg);ple=n(Hye,"STRONG",{});var wit=s(ple);yso=r(wit,"yoso"),wit.forEach(t),xso=r(Hye," \u2014 "),fB=n(Hye,"A",{href:!0});var Ait=s(fB);$so=r(Ait,"YosoConfig"),Ait.forEach(t),kso=r(Hye," (YOSO model)"),Hye.forEach(t),L.forEach(t),Sso=i(st),T(Zg.$$.fragment,st),st.forEach(t),Rso=i(nt),eh=n(nt,"DIV",{class:!0});var HQe=s(eh);T(EL.$$.fragment,HQe),Pso=i(HQe),_le=n(HQe,"P",{});var Lit=s(_le);Bso=r(Lit,"Register a new configuration for this class."),Lit.forEach(t),HQe.forEach(t),nt.forEach(t),UXe=i(f),ji=n(f,"H2",{class:!0});var UQe=s(ji);oh=n(UQe,"A",{id:!0,class:!0,href:!0});var yit=s(oh);ule=n(yit,"SPAN",{});var xit=s(ule);T(CL.$$.fragment,xit),xit.forEach(t),yit.forEach(t),Iso=i(UQe),ble=n(UQe,"SPAN",{});var $it=s(ble);Nso=r($it,"AutoTokenizer"),$it.forEach(t),UQe.forEach(t),JXe=i(f),yo=n(f,"DIV",{class:!0});var el=s(yo);T(wL.$$.fragment,el),qso=i(el),AL=n(el,"P",{});var JQe=s(AL);jso=r(JQe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),mB=n(JQe,"A",{href:!0});var kit=s(mB);Dso=r(kit,"AutoTokenizer.from_pretrained()"),kit.forEach(t),Gso=r(JQe," class method."),JQe.forEach(t),Oso=i(el),LL=n(el,"P",{});var YQe=s(LL);Vso=r(YQe,"This class cannot be instantiated directly using "),vle=n(YQe,"CODE",{});var Sit=s(vle);Xso=r(Sit,"__init__()"),Sit.forEach(t),zso=r(YQe," (throws an error)."),YQe.forEach(t),Qso=i(el),xr=n(el,"DIV",{class:!0});var ol=s(xr);T(yL.$$.fragment,ol),Wso=i(ol),Fle=n(ol,"P",{});var Rit=s(Fle);Hso=r(Rit,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Rit.forEach(t),Uso=i(ol),Pa=n(ol,"P",{});var uw=s(Pa);Jso=r(uw,"The tokenizer class to instantiate is selected based on the "),Tle=n(uw,"CODE",{});var Pit=s(Tle);Yso=r(Pit,"model_type"),Pit.forEach(t),Kso=r(uw,` property of the config object (either
passed as an argument or loaded from `),Mle=n(uw,"CODE",{});var Bit=s(Mle);Zso=r(Bit,"pretrained_model_name_or_path"),Bit.forEach(t),elo=r(uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ele=n(uw,"CODE",{});var Iit=s(Ele);olo=r(Iit,"pretrained_model_name_or_path"),Iit.forEach(t),rlo=r(uw,":"),uw.forEach(t),tlo=i(ol),k=n(ol,"UL",{});var S=s(k);Dn=n(S,"LI",{});var Pk=s(Dn);Cle=n(Pk,"STRONG",{});var Nit=s(Cle);alo=r(Nit,"albert"),Nit.forEach(t),nlo=r(Pk," \u2014 "),gB=n(Pk,"A",{href:!0});var qit=s(gB);slo=r(qit,"AlbertTokenizer"),qit.forEach(t),llo=r(Pk," or "),hB=n(Pk,"A",{href:!0});var jit=s(hB);ilo=r(jit,"AlbertTokenizerFast"),jit.forEach(t),dlo=r(Pk," (ALBERT model)"),Pk.forEach(t),clo=i(S),Gn=n(S,"LI",{});var Bk=s(Gn);wle=n(Bk,"STRONG",{});var Dit=s(wle);flo=r(Dit,"bart"),Dit.forEach(t),mlo=r(Bk," \u2014 "),pB=n(Bk,"A",{href:!0});var Git=s(pB);glo=r(Git,"BartTokenizer"),Git.forEach(t),hlo=r(Bk," or "),_B=n(Bk,"A",{href:!0});var Oit=s(_B);plo=r(Oit,"BartTokenizerFast"),Oit.forEach(t),_lo=r(Bk," (BART model)"),Bk.forEach(t),ulo=i(S),On=n(S,"LI",{});var Ik=s(On);Ale=n(Ik,"STRONG",{});var Vit=s(Ale);blo=r(Vit,"barthez"),Vit.forEach(t),vlo=r(Ik," \u2014 "),uB=n(Ik,"A",{href:!0});var Xit=s(uB);Flo=r(Xit,"BarthezTokenizer"),Xit.forEach(t),Tlo=r(Ik," or "),bB=n(Ik,"A",{href:!0});var zit=s(bB);Mlo=r(zit,"BarthezTokenizerFast"),zit.forEach(t),Elo=r(Ik," (BARThez model)"),Ik.forEach(t),Clo=i(S),rh=n(S,"LI",{});var Uye=s(rh);Lle=n(Uye,"STRONG",{});var Qit=s(Lle);wlo=r(Qit,"bartpho"),Qit.forEach(t),Alo=r(Uye," \u2014 "),vB=n(Uye,"A",{href:!0});var Wit=s(vB);Llo=r(Wit,"BartphoTokenizer"),Wit.forEach(t),ylo=r(Uye," (BARTpho model)"),Uye.forEach(t),xlo=i(S),Vn=n(S,"LI",{});var Nk=s(Vn);yle=n(Nk,"STRONG",{});var Hit=s(yle);$lo=r(Hit,"bert"),Hit.forEach(t),klo=r(Nk," \u2014 "),FB=n(Nk,"A",{href:!0});var Uit=s(FB);Slo=r(Uit,"BertTokenizer"),Uit.forEach(t),Rlo=r(Nk," or "),TB=n(Nk,"A",{href:!0});var Jit=s(TB);Plo=r(Jit,"BertTokenizerFast"),Jit.forEach(t),Blo=r(Nk," (BERT model)"),Nk.forEach(t),Ilo=i(S),th=n(S,"LI",{});var Jye=s(th);xle=n(Jye,"STRONG",{});var Yit=s(xle);Nlo=r(Yit,"bert-generation"),Yit.forEach(t),qlo=r(Jye," \u2014 "),MB=n(Jye,"A",{href:!0});var Kit=s(MB);jlo=r(Kit,"BertGenerationTokenizer"),Kit.forEach(t),Dlo=r(Jye," (Bert Generation model)"),Jye.forEach(t),Glo=i(S),ah=n(S,"LI",{});var Yye=s(ah);$le=n(Yye,"STRONG",{});var Zit=s($le);Olo=r(Zit,"bert-japanese"),Zit.forEach(t),Vlo=r(Yye," \u2014 "),EB=n(Yye,"A",{href:!0});var edt=s(EB);Xlo=r(edt,"BertJapaneseTokenizer"),edt.forEach(t),zlo=r(Yye," (BertJapanese model)"),Yye.forEach(t),Qlo=i(S),nh=n(S,"LI",{});var Kye=s(nh);kle=n(Kye,"STRONG",{});var odt=s(kle);Wlo=r(odt,"bertweet"),odt.forEach(t),Hlo=r(Kye," \u2014 "),CB=n(Kye,"A",{href:!0});var rdt=s(CB);Ulo=r(rdt,"BertweetTokenizer"),rdt.forEach(t),Jlo=r(Kye," (BERTweet model)"),Kye.forEach(t),Ylo=i(S),Xn=n(S,"LI",{});var qk=s(Xn);Sle=n(qk,"STRONG",{});var tdt=s(Sle);Klo=r(tdt,"big_bird"),tdt.forEach(t),Zlo=r(qk," \u2014 "),wB=n(qk,"A",{href:!0});var adt=s(wB);eio=r(adt,"BigBirdTokenizer"),adt.forEach(t),oio=r(qk," or "),AB=n(qk,"A",{href:!0});var ndt=s(AB);rio=r(ndt,"BigBirdTokenizerFast"),ndt.forEach(t),tio=r(qk," (BigBird model)"),qk.forEach(t),aio=i(S),zn=n(S,"LI",{});var jk=s(zn);Rle=n(jk,"STRONG",{});var sdt=s(Rle);nio=r(sdt,"bigbird_pegasus"),sdt.forEach(t),sio=r(jk," \u2014 "),LB=n(jk,"A",{href:!0});var ldt=s(LB);lio=r(ldt,"PegasusTokenizer"),ldt.forEach(t),iio=r(jk," or "),yB=n(jk,"A",{href:!0});var idt=s(yB);dio=r(idt,"PegasusTokenizerFast"),idt.forEach(t),cio=r(jk," (BigBird-Pegasus model)"),jk.forEach(t),fio=i(S),Qn=n(S,"LI",{});var Dk=s(Qn);Ple=n(Dk,"STRONG",{});var ddt=s(Ple);mio=r(ddt,"blenderbot"),ddt.forEach(t),gio=r(Dk," \u2014 "),xB=n(Dk,"A",{href:!0});var cdt=s(xB);hio=r(cdt,"BlenderbotTokenizer"),cdt.forEach(t),pio=r(Dk," or "),$B=n(Dk,"A",{href:!0});var fdt=s($B);_io=r(fdt,"BlenderbotTokenizerFast"),fdt.forEach(t),uio=r(Dk," (Blenderbot model)"),Dk.forEach(t),bio=i(S),sh=n(S,"LI",{});var Zye=s(sh);Ble=n(Zye,"STRONG",{});var mdt=s(Ble);vio=r(mdt,"blenderbot-small"),mdt.forEach(t),Fio=r(Zye," \u2014 "),kB=n(Zye,"A",{href:!0});var gdt=s(kB);Tio=r(gdt,"BlenderbotSmallTokenizer"),gdt.forEach(t),Mio=r(Zye," (BlenderbotSmall model)"),Zye.forEach(t),Eio=i(S),lh=n(S,"LI",{});var e8e=s(lh);Ile=n(e8e,"STRONG",{});var hdt=s(Ile);Cio=r(hdt,"bloom"),hdt.forEach(t),wio=r(e8e," \u2014 "),SB=n(e8e,"A",{href:!0});var pdt=s(SB);Aio=r(pdt,"BloomTokenizerFast"),pdt.forEach(t),Lio=r(e8e," (BLOOM model)"),e8e.forEach(t),yio=i(S),ih=n(S,"LI",{});var o8e=s(ih);Nle=n(o8e,"STRONG",{});var _dt=s(Nle);xio=r(_dt,"byt5"),_dt.forEach(t),$io=r(o8e," \u2014 "),RB=n(o8e,"A",{href:!0});var udt=s(RB);kio=r(udt,"ByT5Tokenizer"),udt.forEach(t),Sio=r(o8e," (ByT5 model)"),o8e.forEach(t),Rio=i(S),Wn=n(S,"LI",{});var Gk=s(Wn);qle=n(Gk,"STRONG",{});var bdt=s(qle);Pio=r(bdt,"camembert"),bdt.forEach(t),Bio=r(Gk," \u2014 "),PB=n(Gk,"A",{href:!0});var vdt=s(PB);Iio=r(vdt,"CamembertTokenizer"),vdt.forEach(t),Nio=r(Gk," or "),BB=n(Gk,"A",{href:!0});var Fdt=s(BB);qio=r(Fdt,"CamembertTokenizerFast"),Fdt.forEach(t),jio=r(Gk," (CamemBERT model)"),Gk.forEach(t),Dio=i(S),dh=n(S,"LI",{});var r8e=s(dh);jle=n(r8e,"STRONG",{});var Tdt=s(jle);Gio=r(Tdt,"canine"),Tdt.forEach(t),Oio=r(r8e," \u2014 "),IB=n(r8e,"A",{href:!0});var Mdt=s(IB);Vio=r(Mdt,"CanineTokenizer"),Mdt.forEach(t),Xio=r(r8e," (CANINE model)"),r8e.forEach(t),zio=i(S),Hn=n(S,"LI",{});var Ok=s(Hn);Dle=n(Ok,"STRONG",{});var Edt=s(Dle);Qio=r(Edt,"clip"),Edt.forEach(t),Wio=r(Ok," \u2014 "),NB=n(Ok,"A",{href:!0});var Cdt=s(NB);Hio=r(Cdt,"CLIPTokenizer"),Cdt.forEach(t),Uio=r(Ok," or "),qB=n(Ok,"A",{href:!0});var wdt=s(qB);Jio=r(wdt,"CLIPTokenizerFast"),wdt.forEach(t),Yio=r(Ok," (CLIP model)"),Ok.forEach(t),Kio=i(S),Un=n(S,"LI",{});var Vk=s(Un);Gle=n(Vk,"STRONG",{});var Adt=s(Gle);Zio=r(Adt,"codegen"),Adt.forEach(t),edo=r(Vk," \u2014 "),jB=n(Vk,"A",{href:!0});var Ldt=s(jB);odo=r(Ldt,"CodeGenTokenizer"),Ldt.forEach(t),rdo=r(Vk," or "),DB=n(Vk,"A",{href:!0});var ydt=s(DB);tdo=r(ydt,"CodeGenTokenizerFast"),ydt.forEach(t),ado=r(Vk," (CodeGen model)"),Vk.forEach(t),ndo=i(S),Jn=n(S,"LI",{});var Xk=s(Jn);Ole=n(Xk,"STRONG",{});var xdt=s(Ole);sdo=r(xdt,"convbert"),xdt.forEach(t),ldo=r(Xk," \u2014 "),GB=n(Xk,"A",{href:!0});var $dt=s(GB);ido=r($dt,"ConvBertTokenizer"),$dt.forEach(t),ddo=r(Xk," or "),OB=n(Xk,"A",{href:!0});var kdt=s(OB);cdo=r(kdt,"ConvBertTokenizerFast"),kdt.forEach(t),fdo=r(Xk," (ConvBERT model)"),Xk.forEach(t),mdo=i(S),Yn=n(S,"LI",{});var zk=s(Yn);Vle=n(zk,"STRONG",{});var Sdt=s(Vle);gdo=r(Sdt,"cpm"),Sdt.forEach(t),hdo=r(zk," \u2014 "),VB=n(zk,"A",{href:!0});var Rdt=s(VB);pdo=r(Rdt,"CpmTokenizer"),Rdt.forEach(t),_do=r(zk," or "),XB=n(zk,"A",{href:!0});var Pdt=s(XB);udo=r(Pdt,"CpmTokenizerFast"),Pdt.forEach(t),bdo=r(zk," (CPM model)"),zk.forEach(t),vdo=i(S),ch=n(S,"LI",{});var t8e=s(ch);Xle=n(t8e,"STRONG",{});var Bdt=s(Xle);Fdo=r(Bdt,"ctrl"),Bdt.forEach(t),Tdo=r(t8e," \u2014 "),zB=n(t8e,"A",{href:!0});var Idt=s(zB);Mdo=r(Idt,"CTRLTokenizer"),Idt.forEach(t),Edo=r(t8e," (CTRL model)"),t8e.forEach(t),Cdo=i(S),Kn=n(S,"LI",{});var Qk=s(Kn);zle=n(Qk,"STRONG",{});var Ndt=s(zle);wdo=r(Ndt,"data2vec-text"),Ndt.forEach(t),Ado=r(Qk," \u2014 "),QB=n(Qk,"A",{href:!0});var qdt=s(QB);Ldo=r(qdt,"RobertaTokenizer"),qdt.forEach(t),ydo=r(Qk," or "),WB=n(Qk,"A",{href:!0});var jdt=s(WB);xdo=r(jdt,"RobertaTokenizerFast"),jdt.forEach(t),$do=r(Qk," (Data2VecText model)"),Qk.forEach(t),kdo=i(S),Zn=n(S,"LI",{});var Wk=s(Zn);Qle=n(Wk,"STRONG",{});var Ddt=s(Qle);Sdo=r(Ddt,"deberta"),Ddt.forEach(t),Rdo=r(Wk," \u2014 "),HB=n(Wk,"A",{href:!0});var Gdt=s(HB);Pdo=r(Gdt,"DebertaTokenizer"),Gdt.forEach(t),Bdo=r(Wk," or "),UB=n(Wk,"A",{href:!0});var Odt=s(UB);Ido=r(Odt,"DebertaTokenizerFast"),Odt.forEach(t),Ndo=r(Wk," (DeBERTa model)"),Wk.forEach(t),qdo=i(S),es=n(S,"LI",{});var Hk=s(es);Wle=n(Hk,"STRONG",{});var Vdt=s(Wle);jdo=r(Vdt,"deberta-v2"),Vdt.forEach(t),Ddo=r(Hk," \u2014 "),JB=n(Hk,"A",{href:!0});var Xdt=s(JB);Gdo=r(Xdt,"DebertaV2Tokenizer"),Xdt.forEach(t),Odo=r(Hk," or "),YB=n(Hk,"A",{href:!0});var zdt=s(YB);Vdo=r(zdt,"DebertaV2TokenizerFast"),zdt.forEach(t),Xdo=r(Hk," (DeBERTa-v2 model)"),Hk.forEach(t),zdo=i(S),os=n(S,"LI",{});var Uk=s(os);Hle=n(Uk,"STRONG",{});var Qdt=s(Hle);Qdo=r(Qdt,"distilbert"),Qdt.forEach(t),Wdo=r(Uk," \u2014 "),KB=n(Uk,"A",{href:!0});var Wdt=s(KB);Hdo=r(Wdt,"DistilBertTokenizer"),Wdt.forEach(t),Udo=r(Uk," or "),ZB=n(Uk,"A",{href:!0});var Hdt=s(ZB);Jdo=r(Hdt,"DistilBertTokenizerFast"),Hdt.forEach(t),Ydo=r(Uk," (DistilBERT model)"),Uk.forEach(t),Kdo=i(S),rs=n(S,"LI",{});var Jk=s(rs);Ule=n(Jk,"STRONG",{});var Udt=s(Ule);Zdo=r(Udt,"dpr"),Udt.forEach(t),eco=r(Jk," \u2014 "),eI=n(Jk,"A",{href:!0});var Jdt=s(eI);oco=r(Jdt,"DPRQuestionEncoderTokenizer"),Jdt.forEach(t),rco=r(Jk," or "),oI=n(Jk,"A",{href:!0});var Ydt=s(oI);tco=r(Ydt,"DPRQuestionEncoderTokenizerFast"),Ydt.forEach(t),aco=r(Jk," (DPR model)"),Jk.forEach(t),nco=i(S),ts=n(S,"LI",{});var Yk=s(ts);Jle=n(Yk,"STRONG",{});var Kdt=s(Jle);sco=r(Kdt,"electra"),Kdt.forEach(t),lco=r(Yk," \u2014 "),rI=n(Yk,"A",{href:!0});var Zdt=s(rI);ico=r(Zdt,"ElectraTokenizer"),Zdt.forEach(t),dco=r(Yk," or "),tI=n(Yk,"A",{href:!0});var ect=s(tI);cco=r(ect,"ElectraTokenizerFast"),ect.forEach(t),fco=r(Yk," (ELECTRA model)"),Yk.forEach(t),mco=i(S),fh=n(S,"LI",{});var a8e=s(fh);Yle=n(a8e,"STRONG",{});var oct=s(Yle);gco=r(oct,"flaubert"),oct.forEach(t),hco=r(a8e," \u2014 "),aI=n(a8e,"A",{href:!0});var rct=s(aI);pco=r(rct,"FlaubertTokenizer"),rct.forEach(t),_co=r(a8e," (FlauBERT model)"),a8e.forEach(t),uco=i(S),as=n(S,"LI",{});var Kk=s(as);Kle=n(Kk,"STRONG",{});var tct=s(Kle);bco=r(tct,"fnet"),tct.forEach(t),vco=r(Kk," \u2014 "),nI=n(Kk,"A",{href:!0});var act=s(nI);Fco=r(act,"FNetTokenizer"),act.forEach(t),Tco=r(Kk," or "),sI=n(Kk,"A",{href:!0});var nct=s(sI);Mco=r(nct,"FNetTokenizerFast"),nct.forEach(t),Eco=r(Kk," (FNet model)"),Kk.forEach(t),Cco=i(S),mh=n(S,"LI",{});var n8e=s(mh);Zle=n(n8e,"STRONG",{});var sct=s(Zle);wco=r(sct,"fsmt"),sct.forEach(t),Aco=r(n8e," \u2014 "),lI=n(n8e,"A",{href:!0});var lct=s(lI);Lco=r(lct,"FSMTTokenizer"),lct.forEach(t),yco=r(n8e," (FairSeq Machine-Translation model)"),n8e.forEach(t),xco=i(S),ns=n(S,"LI",{});var Zk=s(ns);eie=n(Zk,"STRONG",{});var ict=s(eie);$co=r(ict,"funnel"),ict.forEach(t),kco=r(Zk," \u2014 "),iI=n(Zk,"A",{href:!0});var dct=s(iI);Sco=r(dct,"FunnelTokenizer"),dct.forEach(t),Rco=r(Zk," or "),dI=n(Zk,"A",{href:!0});var cct=s(dI);Pco=r(cct,"FunnelTokenizerFast"),cct.forEach(t),Bco=r(Zk," (Funnel Transformer model)"),Zk.forEach(t),Ico=i(S),ss=n(S,"LI",{});var eS=s(ss);oie=n(eS,"STRONG",{});var fct=s(oie);Nco=r(fct,"gpt2"),fct.forEach(t),qco=r(eS," \u2014 "),cI=n(eS,"A",{href:!0});var mct=s(cI);jco=r(mct,"GPT2Tokenizer"),mct.forEach(t),Dco=r(eS," or "),fI=n(eS,"A",{href:!0});var gct=s(fI);Gco=r(gct,"GPT2TokenizerFast"),gct.forEach(t),Oco=r(eS," (OpenAI GPT-2 model)"),eS.forEach(t),Vco=i(S),ls=n(S,"LI",{});var oS=s(ls);rie=n(oS,"STRONG",{});var hct=s(rie);Xco=r(hct,"gpt_neo"),hct.forEach(t),zco=r(oS," \u2014 "),mI=n(oS,"A",{href:!0});var pct=s(mI);Qco=r(pct,"GPT2Tokenizer"),pct.forEach(t),Wco=r(oS," or "),gI=n(oS,"A",{href:!0});var _ct=s(gI);Hco=r(_ct,"GPT2TokenizerFast"),_ct.forEach(t),Uco=r(oS," (GPT Neo model)"),oS.forEach(t),Jco=i(S),gh=n(S,"LI",{});var s8e=s(gh);tie=n(s8e,"STRONG",{});var uct=s(tie);Yco=r(uct,"gpt_neox"),uct.forEach(t),Kco=r(s8e," \u2014 "),hI=n(s8e,"A",{href:!0});var bct=s(hI);Zco=r(bct,"GPTNeoXTokenizerFast"),bct.forEach(t),efo=r(s8e," (GPT NeoX model)"),s8e.forEach(t),ofo=i(S),is=n(S,"LI",{});var rS=s(is);aie=n(rS,"STRONG",{});var vct=s(aie);rfo=r(vct,"gptj"),vct.forEach(t),tfo=r(rS," \u2014 "),pI=n(rS,"A",{href:!0});var Fct=s(pI);afo=r(Fct,"GPT2Tokenizer"),Fct.forEach(t),nfo=r(rS," or "),_I=n(rS,"A",{href:!0});var Tct=s(_I);sfo=r(Tct,"GPT2TokenizerFast"),Tct.forEach(t),lfo=r(rS," (GPT-J model)"),rS.forEach(t),ifo=i(S),ds=n(S,"LI",{});var tS=s(ds);nie=n(tS,"STRONG",{});var Mct=s(nie);dfo=r(Mct,"groupvit"),Mct.forEach(t),cfo=r(tS," \u2014 "),uI=n(tS,"A",{href:!0});var Ect=s(uI);ffo=r(Ect,"CLIPTokenizer"),Ect.forEach(t),mfo=r(tS," or "),bI=n(tS,"A",{href:!0});var Cct=s(bI);gfo=r(Cct,"CLIPTokenizerFast"),Cct.forEach(t),hfo=r(tS," (GroupViT model)"),tS.forEach(t),pfo=i(S),cs=n(S,"LI",{});var aS=s(cs);sie=n(aS,"STRONG",{});var wct=s(sie);_fo=r(wct,"herbert"),wct.forEach(t),ufo=r(aS," \u2014 "),vI=n(aS,"A",{href:!0});var Act=s(vI);bfo=r(Act,"HerbertTokenizer"),Act.forEach(t),vfo=r(aS," or "),FI=n(aS,"A",{href:!0});var Lct=s(FI);Ffo=r(Lct,"HerbertTokenizerFast"),Lct.forEach(t),Tfo=r(aS," (HerBERT model)"),aS.forEach(t),Mfo=i(S),hh=n(S,"LI",{});var l8e=s(hh);lie=n(l8e,"STRONG",{});var yct=s(lie);Efo=r(yct,"hubert"),yct.forEach(t),Cfo=r(l8e," \u2014 "),TI=n(l8e,"A",{href:!0});var xct=s(TI);wfo=r(xct,"Wav2Vec2CTCTokenizer"),xct.forEach(t),Afo=r(l8e," (Hubert model)"),l8e.forEach(t),Lfo=i(S),fs=n(S,"LI",{});var nS=s(fs);iie=n(nS,"STRONG",{});var $ct=s(iie);yfo=r($ct,"ibert"),$ct.forEach(t),xfo=r(nS," \u2014 "),MI=n(nS,"A",{href:!0});var kct=s(MI);$fo=r(kct,"RobertaTokenizer"),kct.forEach(t),kfo=r(nS," or "),EI=n(nS,"A",{href:!0});var Sct=s(EI);Sfo=r(Sct,"RobertaTokenizerFast"),Sct.forEach(t),Rfo=r(nS," (I-BERT model)"),nS.forEach(t),Pfo=i(S),ms=n(S,"LI",{});var sS=s(ms);die=n(sS,"STRONG",{});var Rct=s(die);Bfo=r(Rct,"layoutlm"),Rct.forEach(t),Ifo=r(sS," \u2014 "),CI=n(sS,"A",{href:!0});var Pct=s(CI);Nfo=r(Pct,"LayoutLMTokenizer"),Pct.forEach(t),qfo=r(sS," or "),wI=n(sS,"A",{href:!0});var Bct=s(wI);jfo=r(Bct,"LayoutLMTokenizerFast"),Bct.forEach(t),Dfo=r(sS," (LayoutLM model)"),sS.forEach(t),Gfo=i(S),gs=n(S,"LI",{});var lS=s(gs);cie=n(lS,"STRONG",{});var Ict=s(cie);Ofo=r(Ict,"layoutlmv2"),Ict.forEach(t),Vfo=r(lS," \u2014 "),AI=n(lS,"A",{href:!0});var Nct=s(AI);Xfo=r(Nct,"LayoutLMv2Tokenizer"),Nct.forEach(t),zfo=r(lS," or "),LI=n(lS,"A",{href:!0});var qct=s(LI);Qfo=r(qct,"LayoutLMv2TokenizerFast"),qct.forEach(t),Wfo=r(lS," (LayoutLMv2 model)"),lS.forEach(t),Hfo=i(S),hs=n(S,"LI",{});var iS=s(hs);fie=n(iS,"STRONG",{});var jct=s(fie);Ufo=r(jct,"layoutlmv3"),jct.forEach(t),Jfo=r(iS," \u2014 "),yI=n(iS,"A",{href:!0});var Dct=s(yI);Yfo=r(Dct,"LayoutLMv3Tokenizer"),Dct.forEach(t),Kfo=r(iS," or "),xI=n(iS,"A",{href:!0});var Gct=s(xI);Zfo=r(Gct,"LayoutLMv3TokenizerFast"),Gct.forEach(t),emo=r(iS," (LayoutLMv3 model)"),iS.forEach(t),omo=i(S),ps=n(S,"LI",{});var dS=s(ps);mie=n(dS,"STRONG",{});var Oct=s(mie);rmo=r(Oct,"layoutxlm"),Oct.forEach(t),tmo=r(dS," \u2014 "),$I=n(dS,"A",{href:!0});var Vct=s($I);amo=r(Vct,"LayoutXLMTokenizer"),Vct.forEach(t),nmo=r(dS," or "),kI=n(dS,"A",{href:!0});var Xct=s(kI);smo=r(Xct,"LayoutXLMTokenizerFast"),Xct.forEach(t),lmo=r(dS," (LayoutXLM model)"),dS.forEach(t),imo=i(S),_s=n(S,"LI",{});var cS=s(_s);gie=n(cS,"STRONG",{});var zct=s(gie);dmo=r(zct,"led"),zct.forEach(t),cmo=r(cS," \u2014 "),SI=n(cS,"A",{href:!0});var Qct=s(SI);fmo=r(Qct,"LEDTokenizer"),Qct.forEach(t),mmo=r(cS," or "),RI=n(cS,"A",{href:!0});var Wct=s(RI);gmo=r(Wct,"LEDTokenizerFast"),Wct.forEach(t),hmo=r(cS," (LED model)"),cS.forEach(t),pmo=i(S),us=n(S,"LI",{});var fS=s(us);hie=n(fS,"STRONG",{});var Hct=s(hie);_mo=r(Hct,"longformer"),Hct.forEach(t),umo=r(fS," \u2014 "),PI=n(fS,"A",{href:!0});var Uct=s(PI);bmo=r(Uct,"LongformerTokenizer"),Uct.forEach(t),vmo=r(fS," or "),BI=n(fS,"A",{href:!0});var Jct=s(BI);Fmo=r(Jct,"LongformerTokenizerFast"),Jct.forEach(t),Tmo=r(fS," (Longformer model)"),fS.forEach(t),Mmo=i(S),bs=n(S,"LI",{});var mS=s(bs);pie=n(mS,"STRONG",{});var Yct=s(pie);Emo=r(Yct,"longt5"),Yct.forEach(t),Cmo=r(mS," \u2014 "),II=n(mS,"A",{href:!0});var Kct=s(II);wmo=r(Kct,"T5Tokenizer"),Kct.forEach(t),Amo=r(mS," or "),NI=n(mS,"A",{href:!0});var Zct=s(NI);Lmo=r(Zct,"T5TokenizerFast"),Zct.forEach(t),ymo=r(mS," (LongT5 model)"),mS.forEach(t),xmo=i(S),ph=n(S,"LI",{});var i8e=s(ph);_ie=n(i8e,"STRONG",{});var eft=s(_ie);$mo=r(eft,"luke"),eft.forEach(t),kmo=r(i8e," \u2014 "),qI=n(i8e,"A",{href:!0});var oft=s(qI);Smo=r(oft,"LukeTokenizer"),oft.forEach(t),Rmo=r(i8e," (LUKE model)"),i8e.forEach(t),Pmo=i(S),vs=n(S,"LI",{});var gS=s(vs);uie=n(gS,"STRONG",{});var rft=s(uie);Bmo=r(rft,"lxmert"),rft.forEach(t),Imo=r(gS," \u2014 "),jI=n(gS,"A",{href:!0});var tft=s(jI);Nmo=r(tft,"LxmertTokenizer"),tft.forEach(t),qmo=r(gS," or "),DI=n(gS,"A",{href:!0});var aft=s(DI);jmo=r(aft,"LxmertTokenizerFast"),aft.forEach(t),Dmo=r(gS," (LXMERT model)"),gS.forEach(t),Gmo=i(S),_h=n(S,"LI",{});var d8e=s(_h);bie=n(d8e,"STRONG",{});var nft=s(bie);Omo=r(nft,"m2m_100"),nft.forEach(t),Vmo=r(d8e," \u2014 "),GI=n(d8e,"A",{href:!0});var sft=s(GI);Xmo=r(sft,"M2M100Tokenizer"),sft.forEach(t),zmo=r(d8e," (M2M100 model)"),d8e.forEach(t),Qmo=i(S),uh=n(S,"LI",{});var c8e=s(uh);vie=n(c8e,"STRONG",{});var lft=s(vie);Wmo=r(lft,"marian"),lft.forEach(t),Hmo=r(c8e," \u2014 "),OI=n(c8e,"A",{href:!0});var ift=s(OI);Umo=r(ift,"MarianTokenizer"),ift.forEach(t),Jmo=r(c8e," (Marian model)"),c8e.forEach(t),Ymo=i(S),Fs=n(S,"LI",{});var hS=s(Fs);Fie=n(hS,"STRONG",{});var dft=s(Fie);Kmo=r(dft,"mbart"),dft.forEach(t),Zmo=r(hS," \u2014 "),VI=n(hS,"A",{href:!0});var cft=s(VI);ego=r(cft,"MBartTokenizer"),cft.forEach(t),ogo=r(hS," or "),XI=n(hS,"A",{href:!0});var fft=s(XI);rgo=r(fft,"MBartTokenizerFast"),fft.forEach(t),tgo=r(hS," (mBART model)"),hS.forEach(t),ago=i(S),Ts=n(S,"LI",{});var pS=s(Ts);Tie=n(pS,"STRONG",{});var mft=s(Tie);ngo=r(mft,"mbart50"),mft.forEach(t),sgo=r(pS," \u2014 "),zI=n(pS,"A",{href:!0});var gft=s(zI);lgo=r(gft,"MBart50Tokenizer"),gft.forEach(t),igo=r(pS," or "),QI=n(pS,"A",{href:!0});var hft=s(QI);dgo=r(hft,"MBart50TokenizerFast"),hft.forEach(t),cgo=r(pS," (mBART-50 model)"),pS.forEach(t),fgo=i(S),Ms=n(S,"LI",{});var _S=s(Ms);Mie=n(_S,"STRONG",{});var pft=s(Mie);mgo=r(pft,"megatron-bert"),pft.forEach(t),ggo=r(_S," \u2014 "),WI=n(_S,"A",{href:!0});var _ft=s(WI);hgo=r(_ft,"BertTokenizer"),_ft.forEach(t),pgo=r(_S," or "),HI=n(_S,"A",{href:!0});var uft=s(HI);_go=r(uft,"BertTokenizerFast"),uft.forEach(t),ugo=r(_S," (Megatron-BERT model)"),_S.forEach(t),bgo=i(S),bh=n(S,"LI",{});var f8e=s(bh);Eie=n(f8e,"STRONG",{});var bft=s(Eie);vgo=r(bft,"mluke"),bft.forEach(t),Fgo=r(f8e," \u2014 "),UI=n(f8e,"A",{href:!0});var vft=s(UI);Tgo=r(vft,"MLukeTokenizer"),vft.forEach(t),Mgo=r(f8e," (mLUKE model)"),f8e.forEach(t),Ego=i(S),Es=n(S,"LI",{});var uS=s(Es);Cie=n(uS,"STRONG",{});var Fft=s(Cie);Cgo=r(Fft,"mobilebert"),Fft.forEach(t),wgo=r(uS," \u2014 "),JI=n(uS,"A",{href:!0});var Tft=s(JI);Ago=r(Tft,"MobileBertTokenizer"),Tft.forEach(t),Lgo=r(uS," or "),YI=n(uS,"A",{href:!0});var Mft=s(YI);ygo=r(Mft,"MobileBertTokenizerFast"),Mft.forEach(t),xgo=r(uS," (MobileBERT model)"),uS.forEach(t),$go=i(S),Cs=n(S,"LI",{});var bS=s(Cs);wie=n(bS,"STRONG",{});var Eft=s(wie);kgo=r(Eft,"mpnet"),Eft.forEach(t),Sgo=r(bS," \u2014 "),KI=n(bS,"A",{href:!0});var Cft=s(KI);Rgo=r(Cft,"MPNetTokenizer"),Cft.forEach(t),Pgo=r(bS," or "),ZI=n(bS,"A",{href:!0});var wft=s(ZI);Bgo=r(wft,"MPNetTokenizerFast"),wft.forEach(t),Igo=r(bS," (MPNet model)"),bS.forEach(t),Ngo=i(S),ws=n(S,"LI",{});var vS=s(ws);Aie=n(vS,"STRONG",{});var Aft=s(Aie);qgo=r(Aft,"mt5"),Aft.forEach(t),jgo=r(vS," \u2014 "),eN=n(vS,"A",{href:!0});var Lft=s(eN);Dgo=r(Lft,"MT5Tokenizer"),Lft.forEach(t),Ggo=r(vS," or "),oN=n(vS,"A",{href:!0});var yft=s(oN);Ogo=r(yft,"MT5TokenizerFast"),yft.forEach(t),Vgo=r(vS," (MT5 model)"),vS.forEach(t),Xgo=i(S),As=n(S,"LI",{});var FS=s(As);Lie=n(FS,"STRONG",{});var xft=s(Lie);zgo=r(xft,"mvp"),xft.forEach(t),Qgo=r(FS," \u2014 "),rN=n(FS,"A",{href:!0});var $ft=s(rN);Wgo=r($ft,"MvpTokenizer"),$ft.forEach(t),Hgo=r(FS," or "),tN=n(FS,"A",{href:!0});var kft=s(tN);Ugo=r(kft,"MvpTokenizerFast"),kft.forEach(t),Jgo=r(FS," (MVP model)"),FS.forEach(t),Ygo=i(S),Ls=n(S,"LI",{});var TS=s(Ls);yie=n(TS,"STRONG",{});var Sft=s(yie);Kgo=r(Sft,"nezha"),Sft.forEach(t),Zgo=r(TS," \u2014 "),aN=n(TS,"A",{href:!0});var Rft=s(aN);eho=r(Rft,"BertTokenizer"),Rft.forEach(t),oho=r(TS," or "),nN=n(TS,"A",{href:!0});var Pft=s(nN);rho=r(Pft,"BertTokenizerFast"),Pft.forEach(t),tho=r(TS," (Nezha model)"),TS.forEach(t),aho=i(S),ys=n(S,"LI",{});var MS=s(ys);xie=n(MS,"STRONG",{});var Bft=s(xie);nho=r(Bft,"nllb"),Bft.forEach(t),sho=r(MS," \u2014 "),sN=n(MS,"A",{href:!0});var Ift=s(sN);lho=r(Ift,"NllbTokenizer"),Ift.forEach(t),iho=r(MS," or "),lN=n(MS,"A",{href:!0});var Nft=s(lN);dho=r(Nft,"NllbTokenizerFast"),Nft.forEach(t),cho=r(MS," (NLLB model)"),MS.forEach(t),fho=i(S),xs=n(S,"LI",{});var ES=s(xs);$ie=n(ES,"STRONG",{});var qft=s($ie);mho=r(qft,"nystromformer"),qft.forEach(t),gho=r(ES," \u2014 "),iN=n(ES,"A",{href:!0});var jft=s(iN);hho=r(jft,"AlbertTokenizer"),jft.forEach(t),pho=r(ES," or "),dN=n(ES,"A",{href:!0});var Dft=s(dN);_ho=r(Dft,"AlbertTokenizerFast"),Dft.forEach(t),uho=r(ES," (Nystr\xF6mformer model)"),ES.forEach(t),bho=i(S),$s=n(S,"LI",{});var CS=s($s);kie=n(CS,"STRONG",{});var Gft=s(kie);vho=r(Gft,"openai-gpt"),Gft.forEach(t),Fho=r(CS," \u2014 "),cN=n(CS,"A",{href:!0});var Oft=s(cN);Tho=r(Oft,"OpenAIGPTTokenizer"),Oft.forEach(t),Mho=r(CS," or "),fN=n(CS,"A",{href:!0});var Vft=s(fN);Eho=r(Vft,"OpenAIGPTTokenizerFast"),Vft.forEach(t),Cho=r(CS," (OpenAI GPT model)"),CS.forEach(t),who=i(S),vh=n(S,"LI",{});var m8e=s(vh);Sie=n(m8e,"STRONG",{});var Xft=s(Sie);Aho=r(Xft,"opt"),Xft.forEach(t),Lho=r(m8e," \u2014 "),mN=n(m8e,"A",{href:!0});var zft=s(mN);yho=r(zft,"GPT2Tokenizer"),zft.forEach(t),xho=r(m8e," (OPT model)"),m8e.forEach(t),$ho=i(S),ks=n(S,"LI",{});var wS=s(ks);Rie=n(wS,"STRONG",{});var Qft=s(Rie);kho=r(Qft,"pegasus"),Qft.forEach(t),Sho=r(wS," \u2014 "),gN=n(wS,"A",{href:!0});var Wft=s(gN);Rho=r(Wft,"PegasusTokenizer"),Wft.forEach(t),Pho=r(wS," or "),hN=n(wS,"A",{href:!0});var Hft=s(hN);Bho=r(Hft,"PegasusTokenizerFast"),Hft.forEach(t),Iho=r(wS," (Pegasus model)"),wS.forEach(t),Nho=i(S),Fh=n(S,"LI",{});var g8e=s(Fh);Pie=n(g8e,"STRONG",{});var Uft=s(Pie);qho=r(Uft,"perceiver"),Uft.forEach(t),jho=r(g8e," \u2014 "),pN=n(g8e,"A",{href:!0});var Jft=s(pN);Dho=r(Jft,"PerceiverTokenizer"),Jft.forEach(t),Gho=r(g8e," (Perceiver model)"),g8e.forEach(t),Oho=i(S),Th=n(S,"LI",{});var h8e=s(Th);Bie=n(h8e,"STRONG",{});var Yft=s(Bie);Vho=r(Yft,"phobert"),Yft.forEach(t),Xho=r(h8e," \u2014 "),_N=n(h8e,"A",{href:!0});var Kft=s(_N);zho=r(Kft,"PhobertTokenizer"),Kft.forEach(t),Qho=r(h8e," (PhoBERT model)"),h8e.forEach(t),Who=i(S),Mh=n(S,"LI",{});var p8e=s(Mh);Iie=n(p8e,"STRONG",{});var Zft=s(Iie);Hho=r(Zft,"plbart"),Zft.forEach(t),Uho=r(p8e," \u2014 "),uN=n(p8e,"A",{href:!0});var emt=s(uN);Jho=r(emt,"PLBartTokenizer"),emt.forEach(t),Yho=r(p8e," (PLBart model)"),p8e.forEach(t),Kho=i(S),Eh=n(S,"LI",{});var _8e=s(Eh);Nie=n(_8e,"STRONG",{});var omt=s(Nie);Zho=r(omt,"prophetnet"),omt.forEach(t),epo=r(_8e," \u2014 "),bN=n(_8e,"A",{href:!0});var rmt=s(bN);opo=r(rmt,"ProphetNetTokenizer"),rmt.forEach(t),rpo=r(_8e," (ProphetNet model)"),_8e.forEach(t),tpo=i(S),Ss=n(S,"LI",{});var AS=s(Ss);qie=n(AS,"STRONG",{});var tmt=s(qie);apo=r(tmt,"qdqbert"),tmt.forEach(t),npo=r(AS," \u2014 "),vN=n(AS,"A",{href:!0});var amt=s(vN);spo=r(amt,"BertTokenizer"),amt.forEach(t),lpo=r(AS," or "),FN=n(AS,"A",{href:!0});var nmt=s(FN);ipo=r(nmt,"BertTokenizerFast"),nmt.forEach(t),dpo=r(AS," (QDQBert model)"),AS.forEach(t),cpo=i(S),Ch=n(S,"LI",{});var u8e=s(Ch);jie=n(u8e,"STRONG",{});var smt=s(jie);fpo=r(smt,"rag"),smt.forEach(t),mpo=r(u8e," \u2014 "),TN=n(u8e,"A",{href:!0});var lmt=s(TN);gpo=r(lmt,"RagTokenizer"),lmt.forEach(t),hpo=r(u8e," (RAG model)"),u8e.forEach(t),ppo=i(S),Rs=n(S,"LI",{});var LS=s(Rs);Die=n(LS,"STRONG",{});var imt=s(Die);_po=r(imt,"realm"),imt.forEach(t),upo=r(LS," \u2014 "),MN=n(LS,"A",{href:!0});var dmt=s(MN);bpo=r(dmt,"RealmTokenizer"),dmt.forEach(t),vpo=r(LS," or "),EN=n(LS,"A",{href:!0});var cmt=s(EN);Fpo=r(cmt,"RealmTokenizerFast"),cmt.forEach(t),Tpo=r(LS," (REALM model)"),LS.forEach(t),Mpo=i(S),Ps=n(S,"LI",{});var yS=s(Ps);Gie=n(yS,"STRONG",{});var fmt=s(Gie);Epo=r(fmt,"reformer"),fmt.forEach(t),Cpo=r(yS," \u2014 "),CN=n(yS,"A",{href:!0});var mmt=s(CN);wpo=r(mmt,"ReformerTokenizer"),mmt.forEach(t),Apo=r(yS," or "),wN=n(yS,"A",{href:!0});var gmt=s(wN);Lpo=r(gmt,"ReformerTokenizerFast"),gmt.forEach(t),ypo=r(yS," (Reformer model)"),yS.forEach(t),xpo=i(S),Bs=n(S,"LI",{});var xS=s(Bs);Oie=n(xS,"STRONG",{});var hmt=s(Oie);$po=r(hmt,"rembert"),hmt.forEach(t),kpo=r(xS," \u2014 "),AN=n(xS,"A",{href:!0});var pmt=s(AN);Spo=r(pmt,"RemBertTokenizer"),pmt.forEach(t),Rpo=r(xS," or "),LN=n(xS,"A",{href:!0});var _mt=s(LN);Ppo=r(_mt,"RemBertTokenizerFast"),_mt.forEach(t),Bpo=r(xS," (RemBERT model)"),xS.forEach(t),Ipo=i(S),Is=n(S,"LI",{});var $S=s(Is);Vie=n($S,"STRONG",{});var umt=s(Vie);Npo=r(umt,"retribert"),umt.forEach(t),qpo=r($S," \u2014 "),yN=n($S,"A",{href:!0});var bmt=s(yN);jpo=r(bmt,"RetriBertTokenizer"),bmt.forEach(t),Dpo=r($S," or "),xN=n($S,"A",{href:!0});var vmt=s(xN);Gpo=r(vmt,"RetriBertTokenizerFast"),vmt.forEach(t),Opo=r($S," (RetriBERT model)"),$S.forEach(t),Vpo=i(S),Ns=n(S,"LI",{});var kS=s(Ns);Xie=n(kS,"STRONG",{});var Fmt=s(Xie);Xpo=r(Fmt,"roberta"),Fmt.forEach(t),zpo=r(kS," \u2014 "),$N=n(kS,"A",{href:!0});var Tmt=s($N);Qpo=r(Tmt,"RobertaTokenizer"),Tmt.forEach(t),Wpo=r(kS," or "),kN=n(kS,"A",{href:!0});var Mmt=s(kN);Hpo=r(Mmt,"RobertaTokenizerFast"),Mmt.forEach(t),Upo=r(kS," (RoBERTa model)"),kS.forEach(t),Jpo=i(S),qs=n(S,"LI",{});var SS=s(qs);zie=n(SS,"STRONG",{});var Emt=s(zie);Ypo=r(Emt,"roformer"),Emt.forEach(t),Kpo=r(SS," \u2014 "),SN=n(SS,"A",{href:!0});var Cmt=s(SN);Zpo=r(Cmt,"RoFormerTokenizer"),Cmt.forEach(t),e_o=r(SS," or "),RN=n(SS,"A",{href:!0});var wmt=s(RN);o_o=r(wmt,"RoFormerTokenizerFast"),wmt.forEach(t),r_o=r(SS," (RoFormer model)"),SS.forEach(t),t_o=i(S),wh=n(S,"LI",{});var b8e=s(wh);Qie=n(b8e,"STRONG",{});var Amt=s(Qie);a_o=r(Amt,"speech_to_text"),Amt.forEach(t),n_o=r(b8e," \u2014 "),PN=n(b8e,"A",{href:!0});var Lmt=s(PN);s_o=r(Lmt,"Speech2TextTokenizer"),Lmt.forEach(t),l_o=r(b8e," (Speech2Text model)"),b8e.forEach(t),i_o=i(S),Ah=n(S,"LI",{});var v8e=s(Ah);Wie=n(v8e,"STRONG",{});var ymt=s(Wie);d_o=r(ymt,"speech_to_text_2"),ymt.forEach(t),c_o=r(v8e," \u2014 "),BN=n(v8e,"A",{href:!0});var xmt=s(BN);f_o=r(xmt,"Speech2Text2Tokenizer"),xmt.forEach(t),m_o=r(v8e," (Speech2Text2 model)"),v8e.forEach(t),g_o=i(S),js=n(S,"LI",{});var RS=s(js);Hie=n(RS,"STRONG",{});var $mt=s(Hie);h_o=r($mt,"splinter"),$mt.forEach(t),p_o=r(RS," \u2014 "),IN=n(RS,"A",{href:!0});var kmt=s(IN);__o=r(kmt,"SplinterTokenizer"),kmt.forEach(t),u_o=r(RS," or "),NN=n(RS,"A",{href:!0});var Smt=s(NN);b_o=r(Smt,"SplinterTokenizerFast"),Smt.forEach(t),v_o=r(RS," (Splinter model)"),RS.forEach(t),F_o=i(S),Ds=n(S,"LI",{});var PS=s(Ds);Uie=n(PS,"STRONG",{});var Rmt=s(Uie);T_o=r(Rmt,"squeezebert"),Rmt.forEach(t),M_o=r(PS," \u2014 "),qN=n(PS,"A",{href:!0});var Pmt=s(qN);E_o=r(Pmt,"SqueezeBertTokenizer"),Pmt.forEach(t),C_o=r(PS," or "),jN=n(PS,"A",{href:!0});var Bmt=s(jN);w_o=r(Bmt,"SqueezeBertTokenizerFast"),Bmt.forEach(t),A_o=r(PS," (SqueezeBERT model)"),PS.forEach(t),L_o=i(S),Gs=n(S,"LI",{});var BS=s(Gs);Jie=n(BS,"STRONG",{});var Imt=s(Jie);y_o=r(Imt,"t5"),Imt.forEach(t),x_o=r(BS," \u2014 "),DN=n(BS,"A",{href:!0});var Nmt=s(DN);$_o=r(Nmt,"T5Tokenizer"),Nmt.forEach(t),k_o=r(BS," or "),GN=n(BS,"A",{href:!0});var qmt=s(GN);S_o=r(qmt,"T5TokenizerFast"),qmt.forEach(t),R_o=r(BS," (T5 model)"),BS.forEach(t),P_o=i(S),Lh=n(S,"LI",{});var F8e=s(Lh);Yie=n(F8e,"STRONG",{});var jmt=s(Yie);B_o=r(jmt,"tapas"),jmt.forEach(t),I_o=r(F8e," \u2014 "),ON=n(F8e,"A",{href:!0});var Dmt=s(ON);N_o=r(Dmt,"TapasTokenizer"),Dmt.forEach(t),q_o=r(F8e," (TAPAS model)"),F8e.forEach(t),j_o=i(S),yh=n(S,"LI",{});var T8e=s(yh);Kie=n(T8e,"STRONG",{});var Gmt=s(Kie);D_o=r(Gmt,"tapex"),Gmt.forEach(t),G_o=r(T8e," \u2014 "),VN=n(T8e,"A",{href:!0});var Omt=s(VN);O_o=r(Omt,"TapexTokenizer"),Omt.forEach(t),V_o=r(T8e," (TAPEX model)"),T8e.forEach(t),X_o=i(S),xh=n(S,"LI",{});var M8e=s(xh);Zie=n(M8e,"STRONG",{});var Vmt=s(Zie);z_o=r(Vmt,"transfo-xl"),Vmt.forEach(t),Q_o=r(M8e," \u2014 "),XN=n(M8e,"A",{href:!0});var Xmt=s(XN);W_o=r(Xmt,"TransfoXLTokenizer"),Xmt.forEach(t),H_o=r(M8e," (Transformer-XL model)"),M8e.forEach(t),U_o=i(S),Os=n(S,"LI",{});var IS=s(Os);ede=n(IS,"STRONG",{});var zmt=s(ede);J_o=r(zmt,"vilt"),zmt.forEach(t),Y_o=r(IS," \u2014 "),zN=n(IS,"A",{href:!0});var Qmt=s(zN);K_o=r(Qmt,"BertTokenizer"),Qmt.forEach(t),Z_o=r(IS," or "),QN=n(IS,"A",{href:!0});var Wmt=s(QN);euo=r(Wmt,"BertTokenizerFast"),Wmt.forEach(t),ouo=r(IS," (ViLT model)"),IS.forEach(t),ruo=i(S),Vs=n(S,"LI",{});var NS=s(Vs);ode=n(NS,"STRONG",{});var Hmt=s(ode);tuo=r(Hmt,"visual_bert"),Hmt.forEach(t),auo=r(NS," \u2014 "),WN=n(NS,"A",{href:!0});var Umt=s(WN);nuo=r(Umt,"BertTokenizer"),Umt.forEach(t),suo=r(NS," or "),HN=n(NS,"A",{href:!0});var Jmt=s(HN);luo=r(Jmt,"BertTokenizerFast"),Jmt.forEach(t),iuo=r(NS," (VisualBERT model)"),NS.forEach(t),duo=i(S),$h=n(S,"LI",{});var E8e=s($h);rde=n(E8e,"STRONG",{});var Ymt=s(rde);cuo=r(Ymt,"wav2vec2"),Ymt.forEach(t),fuo=r(E8e," \u2014 "),UN=n(E8e,"A",{href:!0});var Kmt=s(UN);muo=r(Kmt,"Wav2Vec2CTCTokenizer"),Kmt.forEach(t),guo=r(E8e," (Wav2Vec2 model)"),E8e.forEach(t),huo=i(S),kh=n(S,"LI",{});var C8e=s(kh);tde=n(C8e,"STRONG",{});var Zmt=s(tde);puo=r(Zmt,"wav2vec2-conformer"),Zmt.forEach(t),_uo=r(C8e," \u2014 "),JN=n(C8e,"A",{href:!0});var egt=s(JN);uuo=r(egt,"Wav2Vec2CTCTokenizer"),egt.forEach(t),buo=r(C8e," (Wav2Vec2-Conformer model)"),C8e.forEach(t),vuo=i(S),Sh=n(S,"LI",{});var w8e=s(Sh);ade=n(w8e,"STRONG",{});var ogt=s(ade);Fuo=r(ogt,"wav2vec2_phoneme"),ogt.forEach(t),Tuo=r(w8e," \u2014 "),YN=n(w8e,"A",{href:!0});var rgt=s(YN);Muo=r(rgt,"Wav2Vec2PhonemeCTCTokenizer"),rgt.forEach(t),Euo=r(w8e," (Wav2Vec2Phoneme model)"),w8e.forEach(t),Cuo=i(S),Xs=n(S,"LI",{});var qS=s(Xs);nde=n(qS,"STRONG",{});var tgt=s(nde);wuo=r(tgt,"xglm"),tgt.forEach(t),Auo=r(qS," \u2014 "),KN=n(qS,"A",{href:!0});var agt=s(KN);Luo=r(agt,"XGLMTokenizer"),agt.forEach(t),yuo=r(qS," or "),ZN=n(qS,"A",{href:!0});var ngt=s(ZN);xuo=r(ngt,"XGLMTokenizerFast"),ngt.forEach(t),$uo=r(qS," (XGLM model)"),qS.forEach(t),kuo=i(S),Rh=n(S,"LI",{});var A8e=s(Rh);sde=n(A8e,"STRONG",{});var sgt=s(sde);Suo=r(sgt,"xlm"),sgt.forEach(t),Ruo=r(A8e," \u2014 "),eq=n(A8e,"A",{href:!0});var lgt=s(eq);Puo=r(lgt,"XLMTokenizer"),lgt.forEach(t),Buo=r(A8e," (XLM model)"),A8e.forEach(t),Iuo=i(S),Ph=n(S,"LI",{});var L8e=s(Ph);lde=n(L8e,"STRONG",{});var igt=s(lde);Nuo=r(igt,"xlm-prophetnet"),igt.forEach(t),quo=r(L8e," \u2014 "),oq=n(L8e,"A",{href:!0});var dgt=s(oq);juo=r(dgt,"XLMProphetNetTokenizer"),dgt.forEach(t),Duo=r(L8e," (XLM-ProphetNet model)"),L8e.forEach(t),Guo=i(S),zs=n(S,"LI",{});var jS=s(zs);ide=n(jS,"STRONG",{});var cgt=s(ide);Ouo=r(cgt,"xlm-roberta"),cgt.forEach(t),Vuo=r(jS," \u2014 "),rq=n(jS,"A",{href:!0});var fgt=s(rq);Xuo=r(fgt,"XLMRobertaTokenizer"),fgt.forEach(t),zuo=r(jS," or "),tq=n(jS,"A",{href:!0});var mgt=s(tq);Quo=r(mgt,"XLMRobertaTokenizerFast"),mgt.forEach(t),Wuo=r(jS," (XLM-RoBERTa model)"),jS.forEach(t),Huo=i(S),Qs=n(S,"LI",{});var DS=s(Qs);dde=n(DS,"STRONG",{});var ggt=s(dde);Uuo=r(ggt,"xlm-roberta-xl"),ggt.forEach(t),Juo=r(DS," \u2014 "),aq=n(DS,"A",{href:!0});var hgt=s(aq);Yuo=r(hgt,"RobertaTokenizer"),hgt.forEach(t),Kuo=r(DS," or "),nq=n(DS,"A",{href:!0});var pgt=s(nq);Zuo=r(pgt,"RobertaTokenizerFast"),pgt.forEach(t),e1o=r(DS," (XLM-RoBERTa-XL model)"),DS.forEach(t),o1o=i(S),Ws=n(S,"LI",{});var GS=s(Ws);cde=n(GS,"STRONG",{});var _gt=s(cde);r1o=r(_gt,"xlnet"),_gt.forEach(t),t1o=r(GS," \u2014 "),sq=n(GS,"A",{href:!0});var ugt=s(sq);a1o=r(ugt,"XLNetTokenizer"),ugt.forEach(t),n1o=r(GS," or "),lq=n(GS,"A",{href:!0});var bgt=s(lq);s1o=r(bgt,"XLNetTokenizerFast"),bgt.forEach(t),l1o=r(GS," (XLNet model)"),GS.forEach(t),i1o=i(S),Hs=n(S,"LI",{});var OS=s(Hs);fde=n(OS,"STRONG",{});var vgt=s(fde);d1o=r(vgt,"yoso"),vgt.forEach(t),c1o=r(OS," \u2014 "),iq=n(OS,"A",{href:!0});var Fgt=s(iq);f1o=r(Fgt,"AlbertTokenizer"),Fgt.forEach(t),m1o=r(OS," or "),dq=n(OS,"A",{href:!0});var Tgt=s(dq);g1o=r(Tgt,"AlbertTokenizerFast"),Tgt.forEach(t),h1o=r(OS," (YOSO model)"),OS.forEach(t),S.forEach(t),p1o=i(ol),T(Bh.$$.fragment,ol),ol.forEach(t),_1o=i(el),Ih=n(el,"DIV",{class:!0});var KQe=s(Ih);T(xL.$$.fragment,KQe),u1o=i(KQe),mde=n(KQe,"P",{});var Mgt=s(mde);b1o=r(Mgt,"Register a new tokenizer in this mapping."),Mgt.forEach(t),KQe.forEach(t),el.forEach(t),YXe=i(f),Di=n(f,"H2",{class:!0});var ZQe=s(Di);Nh=n(ZQe,"A",{id:!0,class:!0,href:!0});var Egt=s(Nh);gde=n(Egt,"SPAN",{});var Cgt=s(gde);T($L.$$.fragment,Cgt),Cgt.forEach(t),Egt.forEach(t),v1o=i(ZQe),hde=n(ZQe,"SPAN",{});var wgt=s(hde);F1o=r(wgt,"AutoFeatureExtractor"),wgt.forEach(t),ZQe.forEach(t),KXe=i(f),xo=n(f,"DIV",{class:!0});var rl=s(xo);T(kL.$$.fragment,rl),T1o=i(rl),SL=n(rl,"P",{});var eWe=s(SL);M1o=r(eWe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),cq=n(eWe,"A",{href:!0});var Agt=s(cq);E1o=r(Agt,"AutoFeatureExtractor.from_pretrained()"),Agt.forEach(t),C1o=r(eWe," class method."),eWe.forEach(t),w1o=i(rl),RL=n(rl,"P",{});var oWe=s(RL);A1o=r(oWe,"This class cannot be instantiated directly using "),pde=n(oWe,"CODE",{});var Lgt=s(pde);L1o=r(Lgt,"__init__()"),Lgt.forEach(t),y1o=r(oWe," (throws an error)."),oWe.forEach(t),x1o=i(rl),Ue=n(rl,"DIV",{class:!0});var na=s(Ue);T(PL.$$.fragment,na),$1o=i(na),_de=n(na,"P",{});var ygt=s(_de);k1o=r(ygt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),ygt.forEach(t),S1o=i(na),Ba=n(na,"P",{});var bw=s(Ba);R1o=r(bw,"The feature extractor class to instantiate is selected based on the "),ude=n(bw,"CODE",{});var xgt=s(ude);P1o=r(xgt,"model_type"),xgt.forEach(t),B1o=r(bw,` property of the config object
(either passed as an argument or loaded from `),bde=n(bw,"CODE",{});var $gt=s(bde);I1o=r($gt,"pretrained_model_name_or_path"),$gt.forEach(t),N1o=r(bw,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),vde=n(bw,"CODE",{});var kgt=s(vde);q1o=r(kgt,"pretrained_model_name_or_path"),kgt.forEach(t),j1o=r(bw,":"),bw.forEach(t),D1o=i(na),J=n(na,"UL",{});var K=s(J);qh=n(K,"LI",{});var y8e=s(qh);Fde=n(y8e,"STRONG",{});var Sgt=s(Fde);G1o=r(Sgt,"beit"),Sgt.forEach(t),O1o=r(y8e," \u2014 "),fq=n(y8e,"A",{href:!0});var Rgt=s(fq);V1o=r(Rgt,"BeitFeatureExtractor"),Rgt.forEach(t),X1o=r(y8e," (BEiT model)"),y8e.forEach(t),z1o=i(K),jh=n(K,"LI",{});var x8e=s(jh);Tde=n(x8e,"STRONG",{});var Pgt=s(Tde);Q1o=r(Pgt,"clip"),Pgt.forEach(t),W1o=r(x8e," \u2014 "),mq=n(x8e,"A",{href:!0});var Bgt=s(mq);H1o=r(Bgt,"CLIPFeatureExtractor"),Bgt.forEach(t),U1o=r(x8e," (CLIP model)"),x8e.forEach(t),J1o=i(K),Dh=n(K,"LI",{});var $8e=s(Dh);Mde=n($8e,"STRONG",{});var Igt=s(Mde);Y1o=r(Igt,"convnext"),Igt.forEach(t),K1o=r($8e," \u2014 "),gq=n($8e,"A",{href:!0});var Ngt=s(gq);Z1o=r(Ngt,"ConvNextFeatureExtractor"),Ngt.forEach(t),e4o=r($8e," (ConvNeXT model)"),$8e.forEach(t),o4o=i(K),Gh=n(K,"LI",{});var k8e=s(Gh);Ede=n(k8e,"STRONG",{});var qgt=s(Ede);r4o=r(qgt,"cvt"),qgt.forEach(t),t4o=r(k8e," \u2014 "),hq=n(k8e,"A",{href:!0});var jgt=s(hq);a4o=r(jgt,"ConvNextFeatureExtractor"),jgt.forEach(t),n4o=r(k8e," (CvT model)"),k8e.forEach(t),s4o=i(K),Oh=n(K,"LI",{});var S8e=s(Oh);Cde=n(S8e,"STRONG",{});var Dgt=s(Cde);l4o=r(Dgt,"data2vec-audio"),Dgt.forEach(t),i4o=r(S8e," \u2014 "),pq=n(S8e,"A",{href:!0});var Ggt=s(pq);d4o=r(Ggt,"Wav2Vec2FeatureExtractor"),Ggt.forEach(t),c4o=r(S8e," (Data2VecAudio model)"),S8e.forEach(t),f4o=i(K),Vh=n(K,"LI",{});var R8e=s(Vh);wde=n(R8e,"STRONG",{});var Ogt=s(wde);m4o=r(Ogt,"data2vec-vision"),Ogt.forEach(t),g4o=r(R8e," \u2014 "),_q=n(R8e,"A",{href:!0});var Vgt=s(_q);h4o=r(Vgt,"BeitFeatureExtractor"),Vgt.forEach(t),p4o=r(R8e," (Data2VecVision model)"),R8e.forEach(t),_4o=i(K),Xh=n(K,"LI",{});var P8e=s(Xh);Ade=n(P8e,"STRONG",{});var Xgt=s(Ade);u4o=r(Xgt,"deit"),Xgt.forEach(t),b4o=r(P8e," \u2014 "),uq=n(P8e,"A",{href:!0});var zgt=s(uq);v4o=r(zgt,"DeiTFeatureExtractor"),zgt.forEach(t),F4o=r(P8e," (DeiT model)"),P8e.forEach(t),T4o=i(K),zh=n(K,"LI",{});var B8e=s(zh);Lde=n(B8e,"STRONG",{});var Qgt=s(Lde);M4o=r(Qgt,"detr"),Qgt.forEach(t),E4o=r(B8e," \u2014 "),bq=n(B8e,"A",{href:!0});var Wgt=s(bq);C4o=r(Wgt,"DetrFeatureExtractor"),Wgt.forEach(t),w4o=r(B8e," (DETR model)"),B8e.forEach(t),A4o=i(K),Qh=n(K,"LI",{});var I8e=s(Qh);yde=n(I8e,"STRONG",{});var Hgt=s(yde);L4o=r(Hgt,"dpt"),Hgt.forEach(t),y4o=r(I8e," \u2014 "),vq=n(I8e,"A",{href:!0});var Ugt=s(vq);x4o=r(Ugt,"DPTFeatureExtractor"),Ugt.forEach(t),$4o=r(I8e," (DPT model)"),I8e.forEach(t),k4o=i(K),Wh=n(K,"LI",{});var N8e=s(Wh);xde=n(N8e,"STRONG",{});var Jgt=s(xde);S4o=r(Jgt,"flava"),Jgt.forEach(t),R4o=r(N8e," \u2014 "),Fq=n(N8e,"A",{href:!0});var Ygt=s(Fq);P4o=r(Ygt,"FlavaFeatureExtractor"),Ygt.forEach(t),B4o=r(N8e," (FLAVA model)"),N8e.forEach(t),I4o=i(K),Hh=n(K,"LI",{});var q8e=s(Hh);$de=n(q8e,"STRONG",{});var Kgt=s($de);N4o=r(Kgt,"glpn"),Kgt.forEach(t),q4o=r(q8e," \u2014 "),Tq=n(q8e,"A",{href:!0});var Zgt=s(Tq);j4o=r(Zgt,"GLPNFeatureExtractor"),Zgt.forEach(t),D4o=r(q8e," (GLPN model)"),q8e.forEach(t),G4o=i(K),Uh=n(K,"LI",{});var j8e=s(Uh);kde=n(j8e,"STRONG",{});var eht=s(kde);O4o=r(eht,"groupvit"),eht.forEach(t),V4o=r(j8e," \u2014 "),Mq=n(j8e,"A",{href:!0});var oht=s(Mq);X4o=r(oht,"CLIPFeatureExtractor"),oht.forEach(t),z4o=r(j8e," (GroupViT model)"),j8e.forEach(t),Q4o=i(K),Jh=n(K,"LI",{});var D8e=s(Jh);Sde=n(D8e,"STRONG",{});var rht=s(Sde);W4o=r(rht,"hubert"),rht.forEach(t),H4o=r(D8e," \u2014 "),Eq=n(D8e,"A",{href:!0});var tht=s(Eq);U4o=r(tht,"Wav2Vec2FeatureExtractor"),tht.forEach(t),J4o=r(D8e," (Hubert model)"),D8e.forEach(t),Y4o=i(K),Yh=n(K,"LI",{});var G8e=s(Yh);Rde=n(G8e,"STRONG",{});var aht=s(Rde);K4o=r(aht,"imagegpt"),aht.forEach(t),Z4o=r(G8e," \u2014 "),Cq=n(G8e,"A",{href:!0});var nht=s(Cq);e2o=r(nht,"ImageGPTFeatureExtractor"),nht.forEach(t),o2o=r(G8e," (ImageGPT model)"),G8e.forEach(t),r2o=i(K),Kh=n(K,"LI",{});var O8e=s(Kh);Pde=n(O8e,"STRONG",{});var sht=s(Pde);t2o=r(sht,"layoutlmv2"),sht.forEach(t),a2o=r(O8e," \u2014 "),wq=n(O8e,"A",{href:!0});var lht=s(wq);n2o=r(lht,"LayoutLMv2FeatureExtractor"),lht.forEach(t),s2o=r(O8e," (LayoutLMv2 model)"),O8e.forEach(t),l2o=i(K),Zh=n(K,"LI",{});var V8e=s(Zh);Bde=n(V8e,"STRONG",{});var iht=s(Bde);i2o=r(iht,"layoutlmv3"),iht.forEach(t),d2o=r(V8e," \u2014 "),Aq=n(V8e,"A",{href:!0});var dht=s(Aq);c2o=r(dht,"LayoutLMv3FeatureExtractor"),dht.forEach(t),f2o=r(V8e," (LayoutLMv3 model)"),V8e.forEach(t),m2o=i(K),ep=n(K,"LI",{});var X8e=s(ep);Ide=n(X8e,"STRONG",{});var cht=s(Ide);g2o=r(cht,"levit"),cht.forEach(t),h2o=r(X8e," \u2014 "),Lq=n(X8e,"A",{href:!0});var fht=s(Lq);p2o=r(fht,"LevitFeatureExtractor"),fht.forEach(t),_2o=r(X8e," (LeViT model)"),X8e.forEach(t),u2o=i(K),op=n(K,"LI",{});var z8e=s(op);Nde=n(z8e,"STRONG",{});var mht=s(Nde);b2o=r(mht,"maskformer"),mht.forEach(t),v2o=r(z8e," \u2014 "),yq=n(z8e,"A",{href:!0});var ght=s(yq);F2o=r(ght,"MaskFormerFeatureExtractor"),ght.forEach(t),T2o=r(z8e," (MaskFormer model)"),z8e.forEach(t),M2o=i(K),rp=n(K,"LI",{});var Q8e=s(rp);qde=n(Q8e,"STRONG",{});var hht=s(qde);E2o=r(hht,"mctct"),hht.forEach(t),C2o=r(Q8e," \u2014 "),xq=n(Q8e,"A",{href:!0});var pht=s(xq);w2o=r(pht,"MCTCTFeatureExtractor"),pht.forEach(t),A2o=r(Q8e," (M-CTC-T model)"),Q8e.forEach(t),L2o=i(K),tp=n(K,"LI",{});var W8e=s(tp);jde=n(W8e,"STRONG",{});var _ht=s(jde);y2o=r(_ht,"mobilevit"),_ht.forEach(t),x2o=r(W8e," \u2014 "),$q=n(W8e,"A",{href:!0});var uht=s($q);$2o=r(uht,"MobileViTFeatureExtractor"),uht.forEach(t),k2o=r(W8e," (MobileViT model)"),W8e.forEach(t),S2o=i(K),ap=n(K,"LI",{});var H8e=s(ap);Dde=n(H8e,"STRONG",{});var bht=s(Dde);R2o=r(bht,"perceiver"),bht.forEach(t),P2o=r(H8e," \u2014 "),kq=n(H8e,"A",{href:!0});var vht=s(kq);B2o=r(vht,"PerceiverFeatureExtractor"),vht.forEach(t),I2o=r(H8e," (Perceiver model)"),H8e.forEach(t),N2o=i(K),np=n(K,"LI",{});var U8e=s(np);Gde=n(U8e,"STRONG",{});var Fht=s(Gde);q2o=r(Fht,"poolformer"),Fht.forEach(t),j2o=r(U8e," \u2014 "),Sq=n(U8e,"A",{href:!0});var Tht=s(Sq);D2o=r(Tht,"PoolFormerFeatureExtractor"),Tht.forEach(t),G2o=r(U8e," (PoolFormer model)"),U8e.forEach(t),O2o=i(K),sp=n(K,"LI",{});var J8e=s(sp);Ode=n(J8e,"STRONG",{});var Mht=s(Ode);V2o=r(Mht,"regnet"),Mht.forEach(t),X2o=r(J8e," \u2014 "),Rq=n(J8e,"A",{href:!0});var Eht=s(Rq);z2o=r(Eht,"ConvNextFeatureExtractor"),Eht.forEach(t),Q2o=r(J8e," (RegNet model)"),J8e.forEach(t),W2o=i(K),lp=n(K,"LI",{});var Y8e=s(lp);Vde=n(Y8e,"STRONG",{});var Cht=s(Vde);H2o=r(Cht,"resnet"),Cht.forEach(t),U2o=r(Y8e," \u2014 "),Pq=n(Y8e,"A",{href:!0});var wht=s(Pq);J2o=r(wht,"ConvNextFeatureExtractor"),wht.forEach(t),Y2o=r(Y8e," (ResNet model)"),Y8e.forEach(t),K2o=i(K),ip=n(K,"LI",{});var K8e=s(ip);Xde=n(K8e,"STRONG",{});var Aht=s(Xde);Z2o=r(Aht,"segformer"),Aht.forEach(t),ebo=r(K8e," \u2014 "),Bq=n(K8e,"A",{href:!0});var Lht=s(Bq);obo=r(Lht,"SegformerFeatureExtractor"),Lht.forEach(t),rbo=r(K8e," (SegFormer model)"),K8e.forEach(t),tbo=i(K),dp=n(K,"LI",{});var Z8e=s(dp);zde=n(Z8e,"STRONG",{});var yht=s(zde);abo=r(yht,"speech_to_text"),yht.forEach(t),nbo=r(Z8e," \u2014 "),Iq=n(Z8e,"A",{href:!0});var xht=s(Iq);sbo=r(xht,"Speech2TextFeatureExtractor"),xht.forEach(t),lbo=r(Z8e," (Speech2Text model)"),Z8e.forEach(t),ibo=i(K),cp=n(K,"LI",{});var exe=s(cp);Qde=n(exe,"STRONG",{});var $ht=s(Qde);dbo=r($ht,"swin"),$ht.forEach(t),cbo=r(exe," \u2014 "),Nq=n(exe,"A",{href:!0});var kht=s(Nq);fbo=r(kht,"ViTFeatureExtractor"),kht.forEach(t),mbo=r(exe," (Swin Transformer model)"),exe.forEach(t),gbo=i(K),fp=n(K,"LI",{});var oxe=s(fp);Wde=n(oxe,"STRONG",{});var Sht=s(Wde);hbo=r(Sht,"swinv2"),Sht.forEach(t),pbo=r(oxe," \u2014 "),qq=n(oxe,"A",{href:!0});var Rht=s(qq);_bo=r(Rht,"ViTFeatureExtractor"),Rht.forEach(t),ubo=r(oxe," (Swin Transformer V2 model)"),oxe.forEach(t),bbo=i(K),mp=n(K,"LI",{});var rxe=s(mp);Hde=n(rxe,"STRONG",{});var Pht=s(Hde);vbo=r(Pht,"van"),Pht.forEach(t),Fbo=r(rxe," \u2014 "),jq=n(rxe,"A",{href:!0});var Bht=s(jq);Tbo=r(Bht,"ConvNextFeatureExtractor"),Bht.forEach(t),Mbo=r(rxe," (VAN model)"),rxe.forEach(t),Ebo=i(K),gp=n(K,"LI",{});var txe=s(gp);Ude=n(txe,"STRONG",{});var Iht=s(Ude);Cbo=r(Iht,"vilt"),Iht.forEach(t),wbo=r(txe," \u2014 "),Dq=n(txe,"A",{href:!0});var Nht=s(Dq);Abo=r(Nht,"ViltFeatureExtractor"),Nht.forEach(t),Lbo=r(txe," (ViLT model)"),txe.forEach(t),ybo=i(K),hp=n(K,"LI",{});var axe=s(hp);Jde=n(axe,"STRONG",{});var qht=s(Jde);xbo=r(qht,"vit"),qht.forEach(t),$bo=r(axe," \u2014 "),Gq=n(axe,"A",{href:!0});var jht=s(Gq);kbo=r(jht,"ViTFeatureExtractor"),jht.forEach(t),Sbo=r(axe," (ViT model)"),axe.forEach(t),Rbo=i(K),pp=n(K,"LI",{});var nxe=s(pp);Yde=n(nxe,"STRONG",{});var Dht=s(Yde);Pbo=r(Dht,"vit_mae"),Dht.forEach(t),Bbo=r(nxe," \u2014 "),Oq=n(nxe,"A",{href:!0});var Ght=s(Oq);Ibo=r(Ght,"ViTFeatureExtractor"),Ght.forEach(t),Nbo=r(nxe," (ViTMAE model)"),nxe.forEach(t),qbo=i(K),_p=n(K,"LI",{});var sxe=s(_p);Kde=n(sxe,"STRONG",{});var Oht=s(Kde);jbo=r(Oht,"wav2vec2"),Oht.forEach(t),Dbo=r(sxe," \u2014 "),Vq=n(sxe,"A",{href:!0});var Vht=s(Vq);Gbo=r(Vht,"Wav2Vec2FeatureExtractor"),Vht.forEach(t),Obo=r(sxe," (Wav2Vec2 model)"),sxe.forEach(t),Vbo=i(K),up=n(K,"LI",{});var lxe=s(up);Zde=n(lxe,"STRONG",{});var Xht=s(Zde);Xbo=r(Xht,"wav2vec2-conformer"),Xht.forEach(t),zbo=r(lxe," \u2014 "),Xq=n(lxe,"A",{href:!0});var zht=s(Xq);Qbo=r(zht,"Wav2Vec2FeatureExtractor"),zht.forEach(t),Wbo=r(lxe," (Wav2Vec2-Conformer model)"),lxe.forEach(t),Hbo=i(K),bp=n(K,"LI",{});var ixe=s(bp);ece=n(ixe,"STRONG",{});var Qht=s(ece);Ubo=r(Qht,"yolos"),Qht.forEach(t),Jbo=r(ixe," \u2014 "),zq=n(ixe,"A",{href:!0});var Wht=s(zq);Ybo=r(Wht,"YolosFeatureExtractor"),Wht.forEach(t),Kbo=r(ixe," (YOLOS model)"),ixe.forEach(t),K.forEach(t),Zbo=i(na),T(vp.$$.fragment,na),evo=i(na),T(Fp.$$.fragment,na),na.forEach(t),ovo=i(rl),Tp=n(rl,"DIV",{class:!0});var rWe=s(Tp);T(BL.$$.fragment,rWe),rvo=i(rWe),oce=n(rWe,"P",{});var Hht=s(oce);tvo=r(Hht,"Register a new feature extractor for this class."),Hht.forEach(t),rWe.forEach(t),rl.forEach(t),ZXe=i(f),Gi=n(f,"H2",{class:!0});var tWe=s(Gi);Mp=n(tWe,"A",{id:!0,class:!0,href:!0});var Uht=s(Mp);rce=n(Uht,"SPAN",{});var Jht=s(rce);T(IL.$$.fragment,Jht),Jht.forEach(t),Uht.forEach(t),avo=i(tWe),tce=n(tWe,"SPAN",{});var Yht=s(tce);nvo=r(Yht,"AutoProcessor"),Yht.forEach(t),tWe.forEach(t),eze=i(f),$o=n(f,"DIV",{class:!0});var tl=s($o);T(NL.$$.fragment,tl),svo=i(tl),qL=n(tl,"P",{});var aWe=s(qL);lvo=r(aWe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Qq=n(aWe,"A",{href:!0});var Kht=s(Qq);ivo=r(Kht,"AutoProcessor.from_pretrained()"),Kht.forEach(t),dvo=r(aWe," class method."),aWe.forEach(t),cvo=i(tl),jL=n(tl,"P",{});var nWe=s(jL);fvo=r(nWe,"This class cannot be instantiated directly using "),ace=n(nWe,"CODE",{});var Zht=s(ace);mvo=r(Zht,"__init__()"),Zht.forEach(t),gvo=r(nWe," (throws an error)."),nWe.forEach(t),hvo=i(tl),Je=n(tl,"DIV",{class:!0});var sa=s(Je);T(DL.$$.fragment,sa),pvo=i(sa),nce=n(sa,"P",{});var ept=s(nce);_vo=r(ept,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),ept.forEach(t),uvo=i(sa),Oi=n(sa,"P",{});var rte=s(Oi);bvo=r(rte,"The processor class to instantiate is selected based on the "),sce=n(rte,"CODE",{});var opt=s(sce);vvo=r(opt,"model_type"),opt.forEach(t),Fvo=r(rte,` property of the config object (either
passed as an argument or loaded from `),lce=n(rte,"CODE",{});var rpt=s(lce);Tvo=r(rpt,"pretrained_model_name_or_path"),rpt.forEach(t),Mvo=r(rte," if possible):"),rte.forEach(t),Evo=i(sa),pe=n(sa,"UL",{});var ve=s(pe);Ep=n(ve,"LI",{});var dxe=s(Ep);ice=n(dxe,"STRONG",{});var tpt=s(ice);Cvo=r(tpt,"clip"),tpt.forEach(t),wvo=r(dxe," \u2014 "),Wq=n(dxe,"A",{href:!0});var apt=s(Wq);Avo=r(apt,"CLIPProcessor"),apt.forEach(t),Lvo=r(dxe," (CLIP model)"),dxe.forEach(t),yvo=i(ve),Cp=n(ve,"LI",{});var cxe=s(Cp);dce=n(cxe,"STRONG",{});var npt=s(dce);xvo=r(npt,"flava"),npt.forEach(t),$vo=r(cxe," \u2014 "),Hq=n(cxe,"A",{href:!0});var spt=s(Hq);kvo=r(spt,"FlavaProcessor"),spt.forEach(t),Svo=r(cxe," (FLAVA model)"),cxe.forEach(t),Rvo=i(ve),wp=n(ve,"LI",{});var fxe=s(wp);cce=n(fxe,"STRONG",{});var lpt=s(cce);Pvo=r(lpt,"groupvit"),lpt.forEach(t),Bvo=r(fxe," \u2014 "),Uq=n(fxe,"A",{href:!0});var ipt=s(Uq);Ivo=r(ipt,"CLIPProcessor"),ipt.forEach(t),Nvo=r(fxe," (GroupViT model)"),fxe.forEach(t),qvo=i(ve),Ap=n(ve,"LI",{});var mxe=s(Ap);fce=n(mxe,"STRONG",{});var dpt=s(fce);jvo=r(dpt,"layoutlmv2"),dpt.forEach(t),Dvo=r(mxe," \u2014 "),Jq=n(mxe,"A",{href:!0});var cpt=s(Jq);Gvo=r(cpt,"LayoutLMv2Processor"),cpt.forEach(t),Ovo=r(mxe," (LayoutLMv2 model)"),mxe.forEach(t),Vvo=i(ve),Lp=n(ve,"LI",{});var gxe=s(Lp);mce=n(gxe,"STRONG",{});var fpt=s(mce);Xvo=r(fpt,"layoutlmv3"),fpt.forEach(t),zvo=r(gxe," \u2014 "),Yq=n(gxe,"A",{href:!0});var mpt=s(Yq);Qvo=r(mpt,"LayoutLMv3Processor"),mpt.forEach(t),Wvo=r(gxe," (LayoutLMv3 model)"),gxe.forEach(t),Hvo=i(ve),yp=n(ve,"LI",{});var hxe=s(yp);gce=n(hxe,"STRONG",{});var gpt=s(gce);Uvo=r(gpt,"layoutxlm"),gpt.forEach(t),Jvo=r(hxe," \u2014 "),Kq=n(hxe,"A",{href:!0});var hpt=s(Kq);Yvo=r(hpt,"LayoutXLMProcessor"),hpt.forEach(t),Kvo=r(hxe," (LayoutXLM model)"),hxe.forEach(t),Zvo=i(ve),xp=n(ve,"LI",{});var pxe=s(xp);hce=n(pxe,"STRONG",{});var ppt=s(hce);eFo=r(ppt,"sew"),ppt.forEach(t),oFo=r(pxe," \u2014 "),Zq=n(pxe,"A",{href:!0});var _pt=s(Zq);rFo=r(_pt,"Wav2Vec2Processor"),_pt.forEach(t),tFo=r(pxe," (SEW model)"),pxe.forEach(t),aFo=i(ve),$p=n(ve,"LI",{});var _xe=s($p);pce=n(_xe,"STRONG",{});var upt=s(pce);nFo=r(upt,"sew-d"),upt.forEach(t),sFo=r(_xe," \u2014 "),ej=n(_xe,"A",{href:!0});var bpt=s(ej);lFo=r(bpt,"Wav2Vec2Processor"),bpt.forEach(t),iFo=r(_xe," (SEW-D model)"),_xe.forEach(t),dFo=i(ve),kp=n(ve,"LI",{});var uxe=s(kp);_ce=n(uxe,"STRONG",{});var vpt=s(_ce);cFo=r(vpt,"speech_to_text"),vpt.forEach(t),fFo=r(uxe," \u2014 "),oj=n(uxe,"A",{href:!0});var Fpt=s(oj);mFo=r(Fpt,"Speech2TextProcessor"),Fpt.forEach(t),gFo=r(uxe," (Speech2Text model)"),uxe.forEach(t),hFo=i(ve),Sp=n(ve,"LI",{});var bxe=s(Sp);uce=n(bxe,"STRONG",{});var Tpt=s(uce);pFo=r(Tpt,"speech_to_text_2"),Tpt.forEach(t),_Fo=r(bxe," \u2014 "),rj=n(bxe,"A",{href:!0});var Mpt=s(rj);uFo=r(Mpt,"Speech2Text2Processor"),Mpt.forEach(t),bFo=r(bxe," (Speech2Text2 model)"),bxe.forEach(t),vFo=i(ve),Rp=n(ve,"LI",{});var vxe=s(Rp);bce=n(vxe,"STRONG",{});var Ept=s(bce);FFo=r(Ept,"trocr"),Ept.forEach(t),TFo=r(vxe," \u2014 "),tj=n(vxe,"A",{href:!0});var Cpt=s(tj);MFo=r(Cpt,"TrOCRProcessor"),Cpt.forEach(t),EFo=r(vxe," (TrOCR model)"),vxe.forEach(t),CFo=i(ve),Pp=n(ve,"LI",{});var Fxe=s(Pp);vce=n(Fxe,"STRONG",{});var wpt=s(vce);wFo=r(wpt,"unispeech"),wpt.forEach(t),AFo=r(Fxe," \u2014 "),aj=n(Fxe,"A",{href:!0});var Apt=s(aj);LFo=r(Apt,"Wav2Vec2Processor"),Apt.forEach(t),yFo=r(Fxe," (UniSpeech model)"),Fxe.forEach(t),xFo=i(ve),Bp=n(ve,"LI",{});var Txe=s(Bp);Fce=n(Txe,"STRONG",{});var Lpt=s(Fce);$Fo=r(Lpt,"unispeech-sat"),Lpt.forEach(t),kFo=r(Txe," \u2014 "),nj=n(Txe,"A",{href:!0});var ypt=s(nj);SFo=r(ypt,"Wav2Vec2Processor"),ypt.forEach(t),RFo=r(Txe," (UniSpeechSat model)"),Txe.forEach(t),PFo=i(ve),Ip=n(ve,"LI",{});var Mxe=s(Ip);Tce=n(Mxe,"STRONG",{});var xpt=s(Tce);BFo=r(xpt,"vilt"),xpt.forEach(t),IFo=r(Mxe," \u2014 "),sj=n(Mxe,"A",{href:!0});var $pt=s(sj);NFo=r($pt,"ViltProcessor"),$pt.forEach(t),qFo=r(Mxe," (ViLT model)"),Mxe.forEach(t),jFo=i(ve),Np=n(ve,"LI",{});var Exe=s(Np);Mce=n(Exe,"STRONG",{});var kpt=s(Mce);DFo=r(kpt,"vision-text-dual-encoder"),kpt.forEach(t),GFo=r(Exe," \u2014 "),lj=n(Exe,"A",{href:!0});var Spt=s(lj);OFo=r(Spt,"VisionTextDualEncoderProcessor"),Spt.forEach(t),VFo=r(Exe," (VisionTextDualEncoder model)"),Exe.forEach(t),XFo=i(ve),qp=n(ve,"LI",{});var Cxe=s(qp);Ece=n(Cxe,"STRONG",{});var Rpt=s(Ece);zFo=r(Rpt,"wav2vec2"),Rpt.forEach(t),QFo=r(Cxe," \u2014 "),ij=n(Cxe,"A",{href:!0});var Ppt=s(ij);WFo=r(Ppt,"Wav2Vec2Processor"),Ppt.forEach(t),HFo=r(Cxe," (Wav2Vec2 model)"),Cxe.forEach(t),UFo=i(ve),jp=n(ve,"LI",{});var wxe=s(jp);Cce=n(wxe,"STRONG",{});var Bpt=s(Cce);JFo=r(Bpt,"wav2vec2-conformer"),Bpt.forEach(t),YFo=r(wxe," \u2014 "),dj=n(wxe,"A",{href:!0});var Ipt=s(dj);KFo=r(Ipt,"Wav2Vec2Processor"),Ipt.forEach(t),ZFo=r(wxe," (Wav2Vec2-Conformer model)"),wxe.forEach(t),e6o=i(ve),Dp=n(ve,"LI",{});var Axe=s(Dp);wce=n(Axe,"STRONG",{});var Npt=s(wce);o6o=r(Npt,"wavlm"),Npt.forEach(t),r6o=r(Axe," \u2014 "),cj=n(Axe,"A",{href:!0});var qpt=s(cj);t6o=r(qpt,"Wav2Vec2Processor"),qpt.forEach(t),a6o=r(Axe," (WavLM model)"),Axe.forEach(t),ve.forEach(t),n6o=i(sa),T(Gp.$$.fragment,sa),s6o=i(sa),T(Op.$$.fragment,sa),sa.forEach(t),l6o=i(tl),Vp=n(tl,"DIV",{class:!0});var sWe=s(Vp);T(GL.$$.fragment,sWe),i6o=i(sWe),Ace=n(sWe,"P",{});var jpt=s(Ace);d6o=r(jpt,"Register a new processor for this class."),jpt.forEach(t),sWe.forEach(t),tl.forEach(t),oze=i(f),Vi=n(f,"H2",{class:!0});var lWe=s(Vi);Xp=n(lWe,"A",{id:!0,class:!0,href:!0});var Dpt=s(Xp);Lce=n(Dpt,"SPAN",{});var Gpt=s(Lce);T(OL.$$.fragment,Gpt),Gpt.forEach(t),Dpt.forEach(t),c6o=i(lWe),yce=n(lWe,"SPAN",{});var Opt=s(yce);f6o=r(Opt,"AutoModel"),Opt.forEach(t),lWe.forEach(t),rze=i(f),ko=n(f,"DIV",{class:!0});var al=s(ko);T(VL.$$.fragment,al),m6o=i(al),Xi=n(al,"P",{});var tte=s(Xi);g6o=r(tte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),fj=n(tte,"A",{href:!0});var Vpt=s(fj);h6o=r(Vpt,"from_pretrained()"),Vpt.forEach(t),p6o=r(tte," class method or the "),mj=n(tte,"A",{href:!0});var Xpt=s(mj);_6o=r(Xpt,"from_config()"),Xpt.forEach(t),u6o=r(tte,` class
method.`),tte.forEach(t),b6o=i(al),XL=n(al,"P",{});var iWe=s(XL);v6o=r(iWe,"This class cannot be instantiated directly using "),xce=n(iWe,"CODE",{});var zpt=s(xce);F6o=r(zpt,"__init__()"),zpt.forEach(t),T6o=r(iWe," (throws an error)."),iWe.forEach(t),M6o=i(al),it=n(al,"DIV",{class:!0});var vw=s(it);T(zL.$$.fragment,vw),E6o=i(vw),$ce=n(vw,"P",{});var Qpt=s($ce);C6o=r(Qpt,"Instantiates one of the base model classes of the library from a configuration."),Qpt.forEach(t),w6o=i(vw),zi=n(vw,"P",{});var ate=s(zi);A6o=r(ate,`Note:
Loading a model from its configuration file does `),kce=n(ate,"STRONG",{});var Wpt=s(kce);L6o=r(Wpt,"not"),Wpt.forEach(t),y6o=r(ate,` load the model weights. It only affects the
model\u2019s configuration. Use `),gj=n(ate,"A",{href:!0});var Hpt=s(gj);x6o=r(Hpt,"from_pretrained()"),Hpt.forEach(t),$6o=r(ate," to load the model weights."),ate.forEach(t),k6o=i(vw),T(zp.$$.fragment,vw),vw.forEach(t),S6o=i(al),Ye=n(al,"DIV",{class:!0});var la=s(Ye);T(QL.$$.fragment,la),R6o=i(la),Sce=n(la,"P",{});var Upt=s(Sce);P6o=r(Upt,"Instantiate one of the base model classes of the library from a pretrained model."),Upt.forEach(t),B6o=i(la),Ia=n(la,"P",{});var Fw=s(Ia);I6o=r(Fw,"The model class to instantiate is selected based on the "),Rce=n(Fw,"CODE",{});var Jpt=s(Rce);N6o=r(Jpt,"model_type"),Jpt.forEach(t),q6o=r(Fw,` property of the config object (either
passed as an argument or loaded from `),Pce=n(Fw,"CODE",{});var Ypt=s(Pce);j6o=r(Ypt,"pretrained_model_name_or_path"),Ypt.forEach(t),D6o=r(Fw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bce=n(Fw,"CODE",{});var Kpt=s(Bce);G6o=r(Kpt,"pretrained_model_name_or_path"),Kpt.forEach(t),O6o=r(Fw,":"),Fw.forEach(t),V6o=i(la),y=n(la,"UL",{});var x=s(y);Qp=n(x,"LI",{});var Lxe=s(Qp);Ice=n(Lxe,"STRONG",{});var Zpt=s(Ice);X6o=r(Zpt,"albert"),Zpt.forEach(t),z6o=r(Lxe," \u2014 "),hj=n(Lxe,"A",{href:!0});var e_t=s(hj);Q6o=r(e_t,"AlbertModel"),e_t.forEach(t),W6o=r(Lxe," (ALBERT model)"),Lxe.forEach(t),H6o=i(x),Wp=n(x,"LI",{});var yxe=s(Wp);Nce=n(yxe,"STRONG",{});var o_t=s(Nce);U6o=r(o_t,"bart"),o_t.forEach(t),J6o=r(yxe," \u2014 "),pj=n(yxe,"A",{href:!0});var r_t=s(pj);Y6o=r(r_t,"BartModel"),r_t.forEach(t),K6o=r(yxe," (BART model)"),yxe.forEach(t),Z6o=i(x),Hp=n(x,"LI",{});var xxe=s(Hp);qce=n(xxe,"STRONG",{});var t_t=s(qce);eTo=r(t_t,"beit"),t_t.forEach(t),oTo=r(xxe," \u2014 "),_j=n(xxe,"A",{href:!0});var a_t=s(_j);rTo=r(a_t,"BeitModel"),a_t.forEach(t),tTo=r(xxe," (BEiT model)"),xxe.forEach(t),aTo=i(x),Up=n(x,"LI",{});var $xe=s(Up);jce=n($xe,"STRONG",{});var n_t=s(jce);nTo=r(n_t,"bert"),n_t.forEach(t),sTo=r($xe," \u2014 "),uj=n($xe,"A",{href:!0});var s_t=s(uj);lTo=r(s_t,"BertModel"),s_t.forEach(t),iTo=r($xe," (BERT model)"),$xe.forEach(t),dTo=i(x),Jp=n(x,"LI",{});var kxe=s(Jp);Dce=n(kxe,"STRONG",{});var l_t=s(Dce);cTo=r(l_t,"bert-generation"),l_t.forEach(t),fTo=r(kxe," \u2014 "),bj=n(kxe,"A",{href:!0});var i_t=s(bj);mTo=r(i_t,"BertGenerationEncoder"),i_t.forEach(t),gTo=r(kxe," (Bert Generation model)"),kxe.forEach(t),hTo=i(x),Yp=n(x,"LI",{});var Sxe=s(Yp);Gce=n(Sxe,"STRONG",{});var d_t=s(Gce);pTo=r(d_t,"big_bird"),d_t.forEach(t),_To=r(Sxe," \u2014 "),vj=n(Sxe,"A",{href:!0});var c_t=s(vj);uTo=r(c_t,"BigBirdModel"),c_t.forEach(t),bTo=r(Sxe," (BigBird model)"),Sxe.forEach(t),vTo=i(x),Kp=n(x,"LI",{});var Rxe=s(Kp);Oce=n(Rxe,"STRONG",{});var f_t=s(Oce);FTo=r(f_t,"bigbird_pegasus"),f_t.forEach(t),TTo=r(Rxe," \u2014 "),Fj=n(Rxe,"A",{href:!0});var m_t=s(Fj);MTo=r(m_t,"BigBirdPegasusModel"),m_t.forEach(t),ETo=r(Rxe," (BigBird-Pegasus model)"),Rxe.forEach(t),CTo=i(x),Zp=n(x,"LI",{});var Pxe=s(Zp);Vce=n(Pxe,"STRONG",{});var g_t=s(Vce);wTo=r(g_t,"blenderbot"),g_t.forEach(t),ATo=r(Pxe," \u2014 "),Tj=n(Pxe,"A",{href:!0});var h_t=s(Tj);LTo=r(h_t,"BlenderbotModel"),h_t.forEach(t),yTo=r(Pxe," (Blenderbot model)"),Pxe.forEach(t),xTo=i(x),e_=n(x,"LI",{});var Bxe=s(e_);Xce=n(Bxe,"STRONG",{});var p_t=s(Xce);$To=r(p_t,"blenderbot-small"),p_t.forEach(t),kTo=r(Bxe," \u2014 "),Mj=n(Bxe,"A",{href:!0});var __t=s(Mj);STo=r(__t,"BlenderbotSmallModel"),__t.forEach(t),RTo=r(Bxe," (BlenderbotSmall model)"),Bxe.forEach(t),PTo=i(x),o_=n(x,"LI",{});var Ixe=s(o_);zce=n(Ixe,"STRONG",{});var u_t=s(zce);BTo=r(u_t,"bloom"),u_t.forEach(t),ITo=r(Ixe," \u2014 "),Ej=n(Ixe,"A",{href:!0});var b_t=s(Ej);NTo=r(b_t,"BloomModel"),b_t.forEach(t),qTo=r(Ixe," (BLOOM model)"),Ixe.forEach(t),jTo=i(x),r_=n(x,"LI",{});var Nxe=s(r_);Qce=n(Nxe,"STRONG",{});var v_t=s(Qce);DTo=r(v_t,"camembert"),v_t.forEach(t),GTo=r(Nxe," \u2014 "),Cj=n(Nxe,"A",{href:!0});var F_t=s(Cj);OTo=r(F_t,"CamembertModel"),F_t.forEach(t),VTo=r(Nxe," (CamemBERT model)"),Nxe.forEach(t),XTo=i(x),t_=n(x,"LI",{});var qxe=s(t_);Wce=n(qxe,"STRONG",{});var T_t=s(Wce);zTo=r(T_t,"canine"),T_t.forEach(t),QTo=r(qxe," \u2014 "),wj=n(qxe,"A",{href:!0});var M_t=s(wj);WTo=r(M_t,"CanineModel"),M_t.forEach(t),HTo=r(qxe," (CANINE model)"),qxe.forEach(t),UTo=i(x),a_=n(x,"LI",{});var jxe=s(a_);Hce=n(jxe,"STRONG",{});var E_t=s(Hce);JTo=r(E_t,"clip"),E_t.forEach(t),YTo=r(jxe," \u2014 "),Aj=n(jxe,"A",{href:!0});var C_t=s(Aj);KTo=r(C_t,"CLIPModel"),C_t.forEach(t),ZTo=r(jxe," (CLIP model)"),jxe.forEach(t),e7o=i(x),n_=n(x,"LI",{});var Dxe=s(n_);Uce=n(Dxe,"STRONG",{});var w_t=s(Uce);o7o=r(w_t,"codegen"),w_t.forEach(t),r7o=r(Dxe," \u2014 "),Lj=n(Dxe,"A",{href:!0});var A_t=s(Lj);t7o=r(A_t,"CodeGenModel"),A_t.forEach(t),a7o=r(Dxe," (CodeGen model)"),Dxe.forEach(t),n7o=i(x),s_=n(x,"LI",{});var Gxe=s(s_);Jce=n(Gxe,"STRONG",{});var L_t=s(Jce);s7o=r(L_t,"convbert"),L_t.forEach(t),l7o=r(Gxe," \u2014 "),yj=n(Gxe,"A",{href:!0});var y_t=s(yj);i7o=r(y_t,"ConvBertModel"),y_t.forEach(t),d7o=r(Gxe," (ConvBERT model)"),Gxe.forEach(t),c7o=i(x),l_=n(x,"LI",{});var Oxe=s(l_);Yce=n(Oxe,"STRONG",{});var x_t=s(Yce);f7o=r(x_t,"convnext"),x_t.forEach(t),m7o=r(Oxe," \u2014 "),xj=n(Oxe,"A",{href:!0});var $_t=s(xj);g7o=r($_t,"ConvNextModel"),$_t.forEach(t),h7o=r(Oxe," (ConvNeXT model)"),Oxe.forEach(t),p7o=i(x),i_=n(x,"LI",{});var Vxe=s(i_);Kce=n(Vxe,"STRONG",{});var k_t=s(Kce);_7o=r(k_t,"ctrl"),k_t.forEach(t),u7o=r(Vxe," \u2014 "),$j=n(Vxe,"A",{href:!0});var S_t=s($j);b7o=r(S_t,"CTRLModel"),S_t.forEach(t),v7o=r(Vxe," (CTRL model)"),Vxe.forEach(t),F7o=i(x),d_=n(x,"LI",{});var Xxe=s(d_);Zce=n(Xxe,"STRONG",{});var R_t=s(Zce);T7o=r(R_t,"cvt"),R_t.forEach(t),M7o=r(Xxe," \u2014 "),kj=n(Xxe,"A",{href:!0});var P_t=s(kj);E7o=r(P_t,"CvtModel"),P_t.forEach(t),C7o=r(Xxe," (CvT model)"),Xxe.forEach(t),w7o=i(x),c_=n(x,"LI",{});var zxe=s(c_);efe=n(zxe,"STRONG",{});var B_t=s(efe);A7o=r(B_t,"data2vec-audio"),B_t.forEach(t),L7o=r(zxe," \u2014 "),Sj=n(zxe,"A",{href:!0});var I_t=s(Sj);y7o=r(I_t,"Data2VecAudioModel"),I_t.forEach(t),x7o=r(zxe," (Data2VecAudio model)"),zxe.forEach(t),$7o=i(x),f_=n(x,"LI",{});var Qxe=s(f_);ofe=n(Qxe,"STRONG",{});var N_t=s(ofe);k7o=r(N_t,"data2vec-text"),N_t.forEach(t),S7o=r(Qxe," \u2014 "),Rj=n(Qxe,"A",{href:!0});var q_t=s(Rj);R7o=r(q_t,"Data2VecTextModel"),q_t.forEach(t),P7o=r(Qxe," (Data2VecText model)"),Qxe.forEach(t),B7o=i(x),m_=n(x,"LI",{});var Wxe=s(m_);rfe=n(Wxe,"STRONG",{});var j_t=s(rfe);I7o=r(j_t,"data2vec-vision"),j_t.forEach(t),N7o=r(Wxe," \u2014 "),Pj=n(Wxe,"A",{href:!0});var D_t=s(Pj);q7o=r(D_t,"Data2VecVisionModel"),D_t.forEach(t),j7o=r(Wxe," (Data2VecVision model)"),Wxe.forEach(t),D7o=i(x),g_=n(x,"LI",{});var Hxe=s(g_);tfe=n(Hxe,"STRONG",{});var G_t=s(tfe);G7o=r(G_t,"deberta"),G_t.forEach(t),O7o=r(Hxe," \u2014 "),Bj=n(Hxe,"A",{href:!0});var O_t=s(Bj);V7o=r(O_t,"DebertaModel"),O_t.forEach(t),X7o=r(Hxe," (DeBERTa model)"),Hxe.forEach(t),z7o=i(x),h_=n(x,"LI",{});var Uxe=s(h_);afe=n(Uxe,"STRONG",{});var V_t=s(afe);Q7o=r(V_t,"deberta-v2"),V_t.forEach(t),W7o=r(Uxe," \u2014 "),Ij=n(Uxe,"A",{href:!0});var X_t=s(Ij);H7o=r(X_t,"DebertaV2Model"),X_t.forEach(t),U7o=r(Uxe," (DeBERTa-v2 model)"),Uxe.forEach(t),J7o=i(x),p_=n(x,"LI",{});var Jxe=s(p_);nfe=n(Jxe,"STRONG",{});var z_t=s(nfe);Y7o=r(z_t,"decision_transformer"),z_t.forEach(t),K7o=r(Jxe," \u2014 "),Nj=n(Jxe,"A",{href:!0});var Q_t=s(Nj);Z7o=r(Q_t,"DecisionTransformerModel"),Q_t.forEach(t),e9o=r(Jxe," (Decision Transformer model)"),Jxe.forEach(t),o9o=i(x),__=n(x,"LI",{});var Yxe=s(__);sfe=n(Yxe,"STRONG",{});var W_t=s(sfe);r9o=r(W_t,"deit"),W_t.forEach(t),t9o=r(Yxe," \u2014 "),qj=n(Yxe,"A",{href:!0});var H_t=s(qj);a9o=r(H_t,"DeiTModel"),H_t.forEach(t),n9o=r(Yxe," (DeiT model)"),Yxe.forEach(t),s9o=i(x),u_=n(x,"LI",{});var Kxe=s(u_);lfe=n(Kxe,"STRONG",{});var U_t=s(lfe);l9o=r(U_t,"detr"),U_t.forEach(t),i9o=r(Kxe," \u2014 "),jj=n(Kxe,"A",{href:!0});var J_t=s(jj);d9o=r(J_t,"DetrModel"),J_t.forEach(t),c9o=r(Kxe," (DETR model)"),Kxe.forEach(t),f9o=i(x),b_=n(x,"LI",{});var Zxe=s(b_);ife=n(Zxe,"STRONG",{});var Y_t=s(ife);m9o=r(Y_t,"distilbert"),Y_t.forEach(t),g9o=r(Zxe," \u2014 "),Dj=n(Zxe,"A",{href:!0});var K_t=s(Dj);h9o=r(K_t,"DistilBertModel"),K_t.forEach(t),p9o=r(Zxe," (DistilBERT model)"),Zxe.forEach(t),_9o=i(x),v_=n(x,"LI",{});var e$e=s(v_);dfe=n(e$e,"STRONG",{});var Z_t=s(dfe);u9o=r(Z_t,"dpr"),Z_t.forEach(t),b9o=r(e$e," \u2014 "),Gj=n(e$e,"A",{href:!0});var eut=s(Gj);v9o=r(eut,"DPRQuestionEncoder"),eut.forEach(t),F9o=r(e$e," (DPR model)"),e$e.forEach(t),T9o=i(x),F_=n(x,"LI",{});var o$e=s(F_);cfe=n(o$e,"STRONG",{});var out=s(cfe);M9o=r(out,"dpt"),out.forEach(t),E9o=r(o$e," \u2014 "),Oj=n(o$e,"A",{href:!0});var rut=s(Oj);C9o=r(rut,"DPTModel"),rut.forEach(t),w9o=r(o$e," (DPT model)"),o$e.forEach(t),A9o=i(x),T_=n(x,"LI",{});var r$e=s(T_);ffe=n(r$e,"STRONG",{});var tut=s(ffe);L9o=r(tut,"electra"),tut.forEach(t),y9o=r(r$e," \u2014 "),Vj=n(r$e,"A",{href:!0});var aut=s(Vj);x9o=r(aut,"ElectraModel"),aut.forEach(t),$9o=r(r$e," (ELECTRA model)"),r$e.forEach(t),k9o=i(x),M_=n(x,"LI",{});var t$e=s(M_);mfe=n(t$e,"STRONG",{});var nut=s(mfe);S9o=r(nut,"flaubert"),nut.forEach(t),R9o=r(t$e," \u2014 "),Xj=n(t$e,"A",{href:!0});var sut=s(Xj);P9o=r(sut,"FlaubertModel"),sut.forEach(t),B9o=r(t$e," (FlauBERT model)"),t$e.forEach(t),I9o=i(x),E_=n(x,"LI",{});var a$e=s(E_);gfe=n(a$e,"STRONG",{});var lut=s(gfe);N9o=r(lut,"flava"),lut.forEach(t),q9o=r(a$e," \u2014 "),zj=n(a$e,"A",{href:!0});var iut=s(zj);j9o=r(iut,"FlavaModel"),iut.forEach(t),D9o=r(a$e," (FLAVA model)"),a$e.forEach(t),G9o=i(x),C_=n(x,"LI",{});var n$e=s(C_);hfe=n(n$e,"STRONG",{});var dut=s(hfe);O9o=r(dut,"fnet"),dut.forEach(t),V9o=r(n$e," \u2014 "),Qj=n(n$e,"A",{href:!0});var cut=s(Qj);X9o=r(cut,"FNetModel"),cut.forEach(t),z9o=r(n$e," (FNet model)"),n$e.forEach(t),Q9o=i(x),w_=n(x,"LI",{});var s$e=s(w_);pfe=n(s$e,"STRONG",{});var fut=s(pfe);W9o=r(fut,"fsmt"),fut.forEach(t),H9o=r(s$e," \u2014 "),Wj=n(s$e,"A",{href:!0});var mut=s(Wj);U9o=r(mut,"FSMTModel"),mut.forEach(t),J9o=r(s$e," (FairSeq Machine-Translation model)"),s$e.forEach(t),Y9o=i(x),Us=n(x,"LI",{});var VS=s(Us);_fe=n(VS,"STRONG",{});var gut=s(_fe);K9o=r(gut,"funnel"),gut.forEach(t),Z9o=r(VS," \u2014 "),Hj=n(VS,"A",{href:!0});var hut=s(Hj);eMo=r(hut,"FunnelModel"),hut.forEach(t),oMo=r(VS," or "),Uj=n(VS,"A",{href:!0});var put=s(Uj);rMo=r(put,"FunnelBaseModel"),put.forEach(t),tMo=r(VS," (Funnel Transformer model)"),VS.forEach(t),aMo=i(x),A_=n(x,"LI",{});var l$e=s(A_);ufe=n(l$e,"STRONG",{});var _ut=s(ufe);nMo=r(_ut,"glpn"),_ut.forEach(t),sMo=r(l$e," \u2014 "),Jj=n(l$e,"A",{href:!0});var uut=s(Jj);lMo=r(uut,"GLPNModel"),uut.forEach(t),iMo=r(l$e," (GLPN model)"),l$e.forEach(t),dMo=i(x),L_=n(x,"LI",{});var i$e=s(L_);bfe=n(i$e,"STRONG",{});var but=s(bfe);cMo=r(but,"gpt2"),but.forEach(t),fMo=r(i$e," \u2014 "),Yj=n(i$e,"A",{href:!0});var vut=s(Yj);mMo=r(vut,"GPT2Model"),vut.forEach(t),gMo=r(i$e," (OpenAI GPT-2 model)"),i$e.forEach(t),hMo=i(x),y_=n(x,"LI",{});var d$e=s(y_);vfe=n(d$e,"STRONG",{});var Fut=s(vfe);pMo=r(Fut,"gpt_neo"),Fut.forEach(t),_Mo=r(d$e," \u2014 "),Kj=n(d$e,"A",{href:!0});var Tut=s(Kj);uMo=r(Tut,"GPTNeoModel"),Tut.forEach(t),bMo=r(d$e," (GPT Neo model)"),d$e.forEach(t),vMo=i(x),x_=n(x,"LI",{});var c$e=s(x_);Ffe=n(c$e,"STRONG",{});var Mut=s(Ffe);FMo=r(Mut,"gpt_neox"),Mut.forEach(t),TMo=r(c$e," \u2014 "),Zj=n(c$e,"A",{href:!0});var Eut=s(Zj);MMo=r(Eut,"GPTNeoXModel"),Eut.forEach(t),EMo=r(c$e," (GPT NeoX model)"),c$e.forEach(t),CMo=i(x),$_=n(x,"LI",{});var f$e=s($_);Tfe=n(f$e,"STRONG",{});var Cut=s(Tfe);wMo=r(Cut,"gptj"),Cut.forEach(t),AMo=r(f$e," \u2014 "),eD=n(f$e,"A",{href:!0});var wut=s(eD);LMo=r(wut,"GPTJModel"),wut.forEach(t),yMo=r(f$e," (GPT-J model)"),f$e.forEach(t),xMo=i(x),k_=n(x,"LI",{});var m$e=s(k_);Mfe=n(m$e,"STRONG",{});var Aut=s(Mfe);$Mo=r(Aut,"groupvit"),Aut.forEach(t),kMo=r(m$e," \u2014 "),oD=n(m$e,"A",{href:!0});var Lut=s(oD);SMo=r(Lut,"GroupViTModel"),Lut.forEach(t),RMo=r(m$e," (GroupViT model)"),m$e.forEach(t),PMo=i(x),S_=n(x,"LI",{});var g$e=s(S_);Efe=n(g$e,"STRONG",{});var yut=s(Efe);BMo=r(yut,"hubert"),yut.forEach(t),IMo=r(g$e," \u2014 "),rD=n(g$e,"A",{href:!0});var xut=s(rD);NMo=r(xut,"HubertModel"),xut.forEach(t),qMo=r(g$e," (Hubert model)"),g$e.forEach(t),jMo=i(x),R_=n(x,"LI",{});var h$e=s(R_);Cfe=n(h$e,"STRONG",{});var $ut=s(Cfe);DMo=r($ut,"ibert"),$ut.forEach(t),GMo=r(h$e," \u2014 "),tD=n(h$e,"A",{href:!0});var kut=s(tD);OMo=r(kut,"IBertModel"),kut.forEach(t),VMo=r(h$e," (I-BERT model)"),h$e.forEach(t),XMo=i(x),P_=n(x,"LI",{});var p$e=s(P_);wfe=n(p$e,"STRONG",{});var Sut=s(wfe);zMo=r(Sut,"imagegpt"),Sut.forEach(t),QMo=r(p$e," \u2014 "),aD=n(p$e,"A",{href:!0});var Rut=s(aD);WMo=r(Rut,"ImageGPTModel"),Rut.forEach(t),HMo=r(p$e," (ImageGPT model)"),p$e.forEach(t),UMo=i(x),B_=n(x,"LI",{});var _$e=s(B_);Afe=n(_$e,"STRONG",{});var Put=s(Afe);JMo=r(Put,"layoutlm"),Put.forEach(t),YMo=r(_$e," \u2014 "),nD=n(_$e,"A",{href:!0});var But=s(nD);KMo=r(But,"LayoutLMModel"),But.forEach(t),ZMo=r(_$e," (LayoutLM model)"),_$e.forEach(t),eEo=i(x),I_=n(x,"LI",{});var u$e=s(I_);Lfe=n(u$e,"STRONG",{});var Iut=s(Lfe);oEo=r(Iut,"layoutlmv2"),Iut.forEach(t),rEo=r(u$e," \u2014 "),sD=n(u$e,"A",{href:!0});var Nut=s(sD);tEo=r(Nut,"LayoutLMv2Model"),Nut.forEach(t),aEo=r(u$e," (LayoutLMv2 model)"),u$e.forEach(t),nEo=i(x),N_=n(x,"LI",{});var b$e=s(N_);yfe=n(b$e,"STRONG",{});var qut=s(yfe);sEo=r(qut,"layoutlmv3"),qut.forEach(t),lEo=r(b$e," \u2014 "),lD=n(b$e,"A",{href:!0});var jut=s(lD);iEo=r(jut,"LayoutLMv3Model"),jut.forEach(t),dEo=r(b$e," (LayoutLMv3 model)"),b$e.forEach(t),cEo=i(x),q_=n(x,"LI",{});var v$e=s(q_);xfe=n(v$e,"STRONG",{});var Dut=s(xfe);fEo=r(Dut,"led"),Dut.forEach(t),mEo=r(v$e," \u2014 "),iD=n(v$e,"A",{href:!0});var Gut=s(iD);gEo=r(Gut,"LEDModel"),Gut.forEach(t),hEo=r(v$e," (LED model)"),v$e.forEach(t),pEo=i(x),j_=n(x,"LI",{});var F$e=s(j_);$fe=n(F$e,"STRONG",{});var Out=s($fe);_Eo=r(Out,"levit"),Out.forEach(t),uEo=r(F$e," \u2014 "),dD=n(F$e,"A",{href:!0});var Vut=s(dD);bEo=r(Vut,"LevitModel"),Vut.forEach(t),vEo=r(F$e," (LeViT model)"),F$e.forEach(t),FEo=i(x),D_=n(x,"LI",{});var T$e=s(D_);kfe=n(T$e,"STRONG",{});var Xut=s(kfe);TEo=r(Xut,"longformer"),Xut.forEach(t),MEo=r(T$e," \u2014 "),cD=n(T$e,"A",{href:!0});var zut=s(cD);EEo=r(zut,"LongformerModel"),zut.forEach(t),CEo=r(T$e," (Longformer model)"),T$e.forEach(t),wEo=i(x),G_=n(x,"LI",{});var M$e=s(G_);Sfe=n(M$e,"STRONG",{});var Qut=s(Sfe);AEo=r(Qut,"longt5"),Qut.forEach(t),LEo=r(M$e," \u2014 "),fD=n(M$e,"A",{href:!0});var Wut=s(fD);yEo=r(Wut,"LongT5Model"),Wut.forEach(t),xEo=r(M$e," (LongT5 model)"),M$e.forEach(t),$Eo=i(x),O_=n(x,"LI",{});var E$e=s(O_);Rfe=n(E$e,"STRONG",{});var Hut=s(Rfe);kEo=r(Hut,"luke"),Hut.forEach(t),SEo=r(E$e," \u2014 "),mD=n(E$e,"A",{href:!0});var Uut=s(mD);REo=r(Uut,"LukeModel"),Uut.forEach(t),PEo=r(E$e," (LUKE model)"),E$e.forEach(t),BEo=i(x),V_=n(x,"LI",{});var C$e=s(V_);Pfe=n(C$e,"STRONG",{});var Jut=s(Pfe);IEo=r(Jut,"lxmert"),Jut.forEach(t),NEo=r(C$e," \u2014 "),gD=n(C$e,"A",{href:!0});var Yut=s(gD);qEo=r(Yut,"LxmertModel"),Yut.forEach(t),jEo=r(C$e," (LXMERT model)"),C$e.forEach(t),DEo=i(x),X_=n(x,"LI",{});var w$e=s(X_);Bfe=n(w$e,"STRONG",{});var Kut=s(Bfe);GEo=r(Kut,"m2m_100"),Kut.forEach(t),OEo=r(w$e," \u2014 "),hD=n(w$e,"A",{href:!0});var Zut=s(hD);VEo=r(Zut,"M2M100Model"),Zut.forEach(t),XEo=r(w$e," (M2M100 model)"),w$e.forEach(t),zEo=i(x),z_=n(x,"LI",{});var A$e=s(z_);Ife=n(A$e,"STRONG",{});var e1t=s(Ife);QEo=r(e1t,"marian"),e1t.forEach(t),WEo=r(A$e," \u2014 "),pD=n(A$e,"A",{href:!0});var o1t=s(pD);HEo=r(o1t,"MarianModel"),o1t.forEach(t),UEo=r(A$e," (Marian model)"),A$e.forEach(t),JEo=i(x),Q_=n(x,"LI",{});var L$e=s(Q_);Nfe=n(L$e,"STRONG",{});var r1t=s(Nfe);YEo=r(r1t,"maskformer"),r1t.forEach(t),KEo=r(L$e," \u2014 "),_D=n(L$e,"A",{href:!0});var t1t=s(_D);ZEo=r(t1t,"MaskFormerModel"),t1t.forEach(t),eCo=r(L$e," (MaskFormer model)"),L$e.forEach(t),oCo=i(x),W_=n(x,"LI",{});var y$e=s(W_);qfe=n(y$e,"STRONG",{});var a1t=s(qfe);rCo=r(a1t,"mbart"),a1t.forEach(t),tCo=r(y$e," \u2014 "),uD=n(y$e,"A",{href:!0});var n1t=s(uD);aCo=r(n1t,"MBartModel"),n1t.forEach(t),nCo=r(y$e," (mBART model)"),y$e.forEach(t),sCo=i(x),H_=n(x,"LI",{});var x$e=s(H_);jfe=n(x$e,"STRONG",{});var s1t=s(jfe);lCo=r(s1t,"mctct"),s1t.forEach(t),iCo=r(x$e," \u2014 "),bD=n(x$e,"A",{href:!0});var l1t=s(bD);dCo=r(l1t,"MCTCTModel"),l1t.forEach(t),cCo=r(x$e," (M-CTC-T model)"),x$e.forEach(t),fCo=i(x),U_=n(x,"LI",{});var $$e=s(U_);Dfe=n($$e,"STRONG",{});var i1t=s(Dfe);mCo=r(i1t,"megatron-bert"),i1t.forEach(t),gCo=r($$e," \u2014 "),vD=n($$e,"A",{href:!0});var d1t=s(vD);hCo=r(d1t,"MegatronBertModel"),d1t.forEach(t),pCo=r($$e," (Megatron-BERT model)"),$$e.forEach(t),_Co=i(x),J_=n(x,"LI",{});var k$e=s(J_);Gfe=n(k$e,"STRONG",{});var c1t=s(Gfe);uCo=r(c1t,"mobilebert"),c1t.forEach(t),bCo=r(k$e," \u2014 "),FD=n(k$e,"A",{href:!0});var f1t=s(FD);vCo=r(f1t,"MobileBertModel"),f1t.forEach(t),FCo=r(k$e," (MobileBERT model)"),k$e.forEach(t),TCo=i(x),Y_=n(x,"LI",{});var S$e=s(Y_);Ofe=n(S$e,"STRONG",{});var m1t=s(Ofe);MCo=r(m1t,"mobilevit"),m1t.forEach(t),ECo=r(S$e," \u2014 "),TD=n(S$e,"A",{href:!0});var g1t=s(TD);CCo=r(g1t,"MobileViTModel"),g1t.forEach(t),wCo=r(S$e," (MobileViT model)"),S$e.forEach(t),ACo=i(x),K_=n(x,"LI",{});var R$e=s(K_);Vfe=n(R$e,"STRONG",{});var h1t=s(Vfe);LCo=r(h1t,"mpnet"),h1t.forEach(t),yCo=r(R$e," \u2014 "),MD=n(R$e,"A",{href:!0});var p1t=s(MD);xCo=r(p1t,"MPNetModel"),p1t.forEach(t),$Co=r(R$e," (MPNet model)"),R$e.forEach(t),kCo=i(x),Z_=n(x,"LI",{});var P$e=s(Z_);Xfe=n(P$e,"STRONG",{});var _1t=s(Xfe);SCo=r(_1t,"mt5"),_1t.forEach(t),RCo=r(P$e," \u2014 "),ED=n(P$e,"A",{href:!0});var u1t=s(ED);PCo=r(u1t,"MT5Model"),u1t.forEach(t),BCo=r(P$e," (MT5 model)"),P$e.forEach(t),ICo=i(x),eu=n(x,"LI",{});var B$e=s(eu);zfe=n(B$e,"STRONG",{});var b1t=s(zfe);NCo=r(b1t,"mvp"),b1t.forEach(t),qCo=r(B$e," \u2014 "),CD=n(B$e,"A",{href:!0});var v1t=s(CD);jCo=r(v1t,"MvpModel"),v1t.forEach(t),DCo=r(B$e," (MVP model)"),B$e.forEach(t),GCo=i(x),ou=n(x,"LI",{});var I$e=s(ou);Qfe=n(I$e,"STRONG",{});var F1t=s(Qfe);OCo=r(F1t,"nezha"),F1t.forEach(t),VCo=r(I$e," \u2014 "),wD=n(I$e,"A",{href:!0});var T1t=s(wD);XCo=r(T1t,"NezhaModel"),T1t.forEach(t),zCo=r(I$e," (Nezha model)"),I$e.forEach(t),QCo=i(x),ru=n(x,"LI",{});var N$e=s(ru);Wfe=n(N$e,"STRONG",{});var M1t=s(Wfe);WCo=r(M1t,"nllb"),M1t.forEach(t),HCo=r(N$e," \u2014 "),AD=n(N$e,"A",{href:!0});var E1t=s(AD);UCo=r(E1t,"M2M100Model"),E1t.forEach(t),JCo=r(N$e," (NLLB model)"),N$e.forEach(t),YCo=i(x),tu=n(x,"LI",{});var q$e=s(tu);Hfe=n(q$e,"STRONG",{});var C1t=s(Hfe);KCo=r(C1t,"nystromformer"),C1t.forEach(t),ZCo=r(q$e," \u2014 "),LD=n(q$e,"A",{href:!0});var w1t=s(LD);e5o=r(w1t,"NystromformerModel"),w1t.forEach(t),o5o=r(q$e," (Nystr\xF6mformer model)"),q$e.forEach(t),r5o=i(x),au=n(x,"LI",{});var j$e=s(au);Ufe=n(j$e,"STRONG",{});var A1t=s(Ufe);t5o=r(A1t,"openai-gpt"),A1t.forEach(t),a5o=r(j$e," \u2014 "),yD=n(j$e,"A",{href:!0});var L1t=s(yD);n5o=r(L1t,"OpenAIGPTModel"),L1t.forEach(t),s5o=r(j$e," (OpenAI GPT model)"),j$e.forEach(t),l5o=i(x),nu=n(x,"LI",{});var D$e=s(nu);Jfe=n(D$e,"STRONG",{});var y1t=s(Jfe);i5o=r(y1t,"opt"),y1t.forEach(t),d5o=r(D$e," \u2014 "),xD=n(D$e,"A",{href:!0});var x1t=s(xD);c5o=r(x1t,"OPTModel"),x1t.forEach(t),f5o=r(D$e," (OPT model)"),D$e.forEach(t),m5o=i(x),su=n(x,"LI",{});var G$e=s(su);Yfe=n(G$e,"STRONG",{});var $1t=s(Yfe);g5o=r($1t,"pegasus"),$1t.forEach(t),h5o=r(G$e," \u2014 "),$D=n(G$e,"A",{href:!0});var k1t=s($D);p5o=r(k1t,"PegasusModel"),k1t.forEach(t),_5o=r(G$e," (Pegasus model)"),G$e.forEach(t),u5o=i(x),lu=n(x,"LI",{});var O$e=s(lu);Kfe=n(O$e,"STRONG",{});var S1t=s(Kfe);b5o=r(S1t,"perceiver"),S1t.forEach(t),v5o=r(O$e," \u2014 "),kD=n(O$e,"A",{href:!0});var R1t=s(kD);F5o=r(R1t,"PerceiverModel"),R1t.forEach(t),T5o=r(O$e," (Perceiver model)"),O$e.forEach(t),M5o=i(x),iu=n(x,"LI",{});var V$e=s(iu);Zfe=n(V$e,"STRONG",{});var P1t=s(Zfe);E5o=r(P1t,"plbart"),P1t.forEach(t),C5o=r(V$e," \u2014 "),SD=n(V$e,"A",{href:!0});var B1t=s(SD);w5o=r(B1t,"PLBartModel"),B1t.forEach(t),A5o=r(V$e," (PLBart model)"),V$e.forEach(t),L5o=i(x),du=n(x,"LI",{});var X$e=s(du);eme=n(X$e,"STRONG",{});var I1t=s(eme);y5o=r(I1t,"poolformer"),I1t.forEach(t),x5o=r(X$e," \u2014 "),RD=n(X$e,"A",{href:!0});var N1t=s(RD);$5o=r(N1t,"PoolFormerModel"),N1t.forEach(t),k5o=r(X$e," (PoolFormer model)"),X$e.forEach(t),S5o=i(x),cu=n(x,"LI",{});var z$e=s(cu);ome=n(z$e,"STRONG",{});var q1t=s(ome);R5o=r(q1t,"prophetnet"),q1t.forEach(t),P5o=r(z$e," \u2014 "),PD=n(z$e,"A",{href:!0});var j1t=s(PD);B5o=r(j1t,"ProphetNetModel"),j1t.forEach(t),I5o=r(z$e," (ProphetNet model)"),z$e.forEach(t),N5o=i(x),fu=n(x,"LI",{});var Q$e=s(fu);rme=n(Q$e,"STRONG",{});var D1t=s(rme);q5o=r(D1t,"qdqbert"),D1t.forEach(t),j5o=r(Q$e," \u2014 "),BD=n(Q$e,"A",{href:!0});var G1t=s(BD);D5o=r(G1t,"QDQBertModel"),G1t.forEach(t),G5o=r(Q$e," (QDQBert model)"),Q$e.forEach(t),O5o=i(x),mu=n(x,"LI",{});var W$e=s(mu);tme=n(W$e,"STRONG",{});var O1t=s(tme);V5o=r(O1t,"reformer"),O1t.forEach(t),X5o=r(W$e," \u2014 "),ID=n(W$e,"A",{href:!0});var V1t=s(ID);z5o=r(V1t,"ReformerModel"),V1t.forEach(t),Q5o=r(W$e," (Reformer model)"),W$e.forEach(t),W5o=i(x),gu=n(x,"LI",{});var H$e=s(gu);ame=n(H$e,"STRONG",{});var X1t=s(ame);H5o=r(X1t,"regnet"),X1t.forEach(t),U5o=r(H$e," \u2014 "),ND=n(H$e,"A",{href:!0});var z1t=s(ND);J5o=r(z1t,"RegNetModel"),z1t.forEach(t),Y5o=r(H$e," (RegNet model)"),H$e.forEach(t),K5o=i(x),hu=n(x,"LI",{});var U$e=s(hu);nme=n(U$e,"STRONG",{});var Q1t=s(nme);Z5o=r(Q1t,"rembert"),Q1t.forEach(t),e3o=r(U$e," \u2014 "),qD=n(U$e,"A",{href:!0});var W1t=s(qD);o3o=r(W1t,"RemBertModel"),W1t.forEach(t),r3o=r(U$e," (RemBERT model)"),U$e.forEach(t),t3o=i(x),pu=n(x,"LI",{});var J$e=s(pu);sme=n(J$e,"STRONG",{});var H1t=s(sme);a3o=r(H1t,"resnet"),H1t.forEach(t),n3o=r(J$e," \u2014 "),jD=n(J$e,"A",{href:!0});var U1t=s(jD);s3o=r(U1t,"ResNetModel"),U1t.forEach(t),l3o=r(J$e," (ResNet model)"),J$e.forEach(t),i3o=i(x),_u=n(x,"LI",{});var Y$e=s(_u);lme=n(Y$e,"STRONG",{});var J1t=s(lme);d3o=r(J1t,"retribert"),J1t.forEach(t),c3o=r(Y$e," \u2014 "),DD=n(Y$e,"A",{href:!0});var Y1t=s(DD);f3o=r(Y1t,"RetriBertModel"),Y1t.forEach(t),m3o=r(Y$e," (RetriBERT model)"),Y$e.forEach(t),g3o=i(x),uu=n(x,"LI",{});var K$e=s(uu);ime=n(K$e,"STRONG",{});var K1t=s(ime);h3o=r(K1t,"roberta"),K1t.forEach(t),p3o=r(K$e," \u2014 "),GD=n(K$e,"A",{href:!0});var Z1t=s(GD);_3o=r(Z1t,"RobertaModel"),Z1t.forEach(t),u3o=r(K$e," (RoBERTa model)"),K$e.forEach(t),b3o=i(x),bu=n(x,"LI",{});var Z$e=s(bu);dme=n(Z$e,"STRONG",{});var e4t=s(dme);v3o=r(e4t,"roformer"),e4t.forEach(t),F3o=r(Z$e," \u2014 "),OD=n(Z$e,"A",{href:!0});var o4t=s(OD);T3o=r(o4t,"RoFormerModel"),o4t.forEach(t),M3o=r(Z$e," (RoFormer model)"),Z$e.forEach(t),E3o=i(x),vu=n(x,"LI",{});var eke=s(vu);cme=n(eke,"STRONG",{});var r4t=s(cme);C3o=r(r4t,"segformer"),r4t.forEach(t),w3o=r(eke," \u2014 "),VD=n(eke,"A",{href:!0});var t4t=s(VD);A3o=r(t4t,"SegformerModel"),t4t.forEach(t),L3o=r(eke," (SegFormer model)"),eke.forEach(t),y3o=i(x),Fu=n(x,"LI",{});var oke=s(Fu);fme=n(oke,"STRONG",{});var a4t=s(fme);x3o=r(a4t,"sew"),a4t.forEach(t),$3o=r(oke," \u2014 "),XD=n(oke,"A",{href:!0});var n4t=s(XD);k3o=r(n4t,"SEWModel"),n4t.forEach(t),S3o=r(oke," (SEW model)"),oke.forEach(t),R3o=i(x),Tu=n(x,"LI",{});var rke=s(Tu);mme=n(rke,"STRONG",{});var s4t=s(mme);P3o=r(s4t,"sew-d"),s4t.forEach(t),B3o=r(rke," \u2014 "),zD=n(rke,"A",{href:!0});var l4t=s(zD);I3o=r(l4t,"SEWDModel"),l4t.forEach(t),N3o=r(rke," (SEW-D model)"),rke.forEach(t),q3o=i(x),Mu=n(x,"LI",{});var tke=s(Mu);gme=n(tke,"STRONG",{});var i4t=s(gme);j3o=r(i4t,"speech_to_text"),i4t.forEach(t),D3o=r(tke," \u2014 "),QD=n(tke,"A",{href:!0});var d4t=s(QD);G3o=r(d4t,"Speech2TextModel"),d4t.forEach(t),O3o=r(tke," (Speech2Text model)"),tke.forEach(t),V3o=i(x),Eu=n(x,"LI",{});var ake=s(Eu);hme=n(ake,"STRONG",{});var c4t=s(hme);X3o=r(c4t,"splinter"),c4t.forEach(t),z3o=r(ake," \u2014 "),WD=n(ake,"A",{href:!0});var f4t=s(WD);Q3o=r(f4t,"SplinterModel"),f4t.forEach(t),W3o=r(ake," (Splinter model)"),ake.forEach(t),H3o=i(x),Cu=n(x,"LI",{});var nke=s(Cu);pme=n(nke,"STRONG",{});var m4t=s(pme);U3o=r(m4t,"squeezebert"),m4t.forEach(t),J3o=r(nke," \u2014 "),HD=n(nke,"A",{href:!0});var g4t=s(HD);Y3o=r(g4t,"SqueezeBertModel"),g4t.forEach(t),K3o=r(nke," (SqueezeBERT model)"),nke.forEach(t),Z3o=i(x),wu=n(x,"LI",{});var ske=s(wu);_me=n(ske,"STRONG",{});var h4t=s(_me);e0o=r(h4t,"swin"),h4t.forEach(t),o0o=r(ske," \u2014 "),UD=n(ske,"A",{href:!0});var p4t=s(UD);r0o=r(p4t,"SwinModel"),p4t.forEach(t),t0o=r(ske," (Swin Transformer model)"),ske.forEach(t),a0o=i(x),Au=n(x,"LI",{});var lke=s(Au);ume=n(lke,"STRONG",{});var _4t=s(ume);n0o=r(_4t,"swinv2"),_4t.forEach(t),s0o=r(lke," \u2014 "),JD=n(lke,"A",{href:!0});var u4t=s(JD);l0o=r(u4t,"Swinv2Model"),u4t.forEach(t),i0o=r(lke," (Swin Transformer V2 model)"),lke.forEach(t),d0o=i(x),Lu=n(x,"LI",{});var ike=s(Lu);bme=n(ike,"STRONG",{});var b4t=s(bme);c0o=r(b4t,"t5"),b4t.forEach(t),f0o=r(ike," \u2014 "),YD=n(ike,"A",{href:!0});var v4t=s(YD);m0o=r(v4t,"T5Model"),v4t.forEach(t),g0o=r(ike," (T5 model)"),ike.forEach(t),h0o=i(x),yu=n(x,"LI",{});var dke=s(yu);vme=n(dke,"STRONG",{});var F4t=s(vme);p0o=r(F4t,"tapas"),F4t.forEach(t),_0o=r(dke," \u2014 "),KD=n(dke,"A",{href:!0});var T4t=s(KD);u0o=r(T4t,"TapasModel"),T4t.forEach(t),b0o=r(dke," (TAPAS model)"),dke.forEach(t),v0o=i(x),xu=n(x,"LI",{});var cke=s(xu);Fme=n(cke,"STRONG",{});var M4t=s(Fme);F0o=r(M4t,"trajectory_transformer"),M4t.forEach(t),T0o=r(cke," \u2014 "),ZD=n(cke,"A",{href:!0});var E4t=s(ZD);M0o=r(E4t,"TrajectoryTransformerModel"),E4t.forEach(t),E0o=r(cke," (Trajectory Transformer model)"),cke.forEach(t),C0o=i(x),$u=n(x,"LI",{});var fke=s($u);Tme=n(fke,"STRONG",{});var C4t=s(Tme);w0o=r(C4t,"transfo-xl"),C4t.forEach(t),A0o=r(fke," \u2014 "),eG=n(fke,"A",{href:!0});var w4t=s(eG);L0o=r(w4t,"TransfoXLModel"),w4t.forEach(t),y0o=r(fke," (Transformer-XL model)"),fke.forEach(t),x0o=i(x),ku=n(x,"LI",{});var mke=s(ku);Mme=n(mke,"STRONG",{});var A4t=s(Mme);$0o=r(A4t,"unispeech"),A4t.forEach(t),k0o=r(mke," \u2014 "),oG=n(mke,"A",{href:!0});var L4t=s(oG);S0o=r(L4t,"UniSpeechModel"),L4t.forEach(t),R0o=r(mke," (UniSpeech model)"),mke.forEach(t),P0o=i(x),Su=n(x,"LI",{});var gke=s(Su);Eme=n(gke,"STRONG",{});var y4t=s(Eme);B0o=r(y4t,"unispeech-sat"),y4t.forEach(t),I0o=r(gke," \u2014 "),rG=n(gke,"A",{href:!0});var x4t=s(rG);N0o=r(x4t,"UniSpeechSatModel"),x4t.forEach(t),q0o=r(gke," (UniSpeechSat model)"),gke.forEach(t),j0o=i(x),Ru=n(x,"LI",{});var hke=s(Ru);Cme=n(hke,"STRONG",{});var $4t=s(Cme);D0o=r($4t,"van"),$4t.forEach(t),G0o=r(hke," \u2014 "),tG=n(hke,"A",{href:!0});var k4t=s(tG);O0o=r(k4t,"VanModel"),k4t.forEach(t),V0o=r(hke," (VAN model)"),hke.forEach(t),X0o=i(x),Pu=n(x,"LI",{});var pke=s(Pu);wme=n(pke,"STRONG",{});var S4t=s(wme);z0o=r(S4t,"vilt"),S4t.forEach(t),Q0o=r(pke," \u2014 "),aG=n(pke,"A",{href:!0});var R4t=s(aG);W0o=r(R4t,"ViltModel"),R4t.forEach(t),H0o=r(pke," (ViLT model)"),pke.forEach(t),U0o=i(x),Bu=n(x,"LI",{});var _ke=s(Bu);Ame=n(_ke,"STRONG",{});var P4t=s(Ame);J0o=r(P4t,"vision-text-dual-encoder"),P4t.forEach(t),Y0o=r(_ke," \u2014 "),nG=n(_ke,"A",{href:!0});var B4t=s(nG);K0o=r(B4t,"VisionTextDualEncoderModel"),B4t.forEach(t),Z0o=r(_ke," (VisionTextDualEncoder model)"),_ke.forEach(t),ewo=i(x),Iu=n(x,"LI",{});var uke=s(Iu);Lme=n(uke,"STRONG",{});var I4t=s(Lme);owo=r(I4t,"visual_bert"),I4t.forEach(t),rwo=r(uke," \u2014 "),sG=n(uke,"A",{href:!0});var N4t=s(sG);two=r(N4t,"VisualBertModel"),N4t.forEach(t),awo=r(uke," (VisualBERT model)"),uke.forEach(t),nwo=i(x),Nu=n(x,"LI",{});var bke=s(Nu);yme=n(bke,"STRONG",{});var q4t=s(yme);swo=r(q4t,"vit"),q4t.forEach(t),lwo=r(bke," \u2014 "),lG=n(bke,"A",{href:!0});var j4t=s(lG);iwo=r(j4t,"ViTModel"),j4t.forEach(t),dwo=r(bke," (ViT model)"),bke.forEach(t),cwo=i(x),qu=n(x,"LI",{});var vke=s(qu);xme=n(vke,"STRONG",{});var D4t=s(xme);fwo=r(D4t,"vit_mae"),D4t.forEach(t),mwo=r(vke," \u2014 "),iG=n(vke,"A",{href:!0});var G4t=s(iG);gwo=r(G4t,"ViTMAEModel"),G4t.forEach(t),hwo=r(vke," (ViTMAE model)"),vke.forEach(t),pwo=i(x),ju=n(x,"LI",{});var Fke=s(ju);$me=n(Fke,"STRONG",{});var O4t=s($me);_wo=r(O4t,"wav2vec2"),O4t.forEach(t),uwo=r(Fke," \u2014 "),dG=n(Fke,"A",{href:!0});var V4t=s(dG);bwo=r(V4t,"Wav2Vec2Model"),V4t.forEach(t),vwo=r(Fke," (Wav2Vec2 model)"),Fke.forEach(t),Fwo=i(x),Du=n(x,"LI",{});var Tke=s(Du);kme=n(Tke,"STRONG",{});var X4t=s(kme);Two=r(X4t,"wav2vec2-conformer"),X4t.forEach(t),Mwo=r(Tke," \u2014 "),cG=n(Tke,"A",{href:!0});var z4t=s(cG);Ewo=r(z4t,"Wav2Vec2ConformerModel"),z4t.forEach(t),Cwo=r(Tke," (Wav2Vec2-Conformer model)"),Tke.forEach(t),wwo=i(x),Gu=n(x,"LI",{});var Mke=s(Gu);Sme=n(Mke,"STRONG",{});var Q4t=s(Sme);Awo=r(Q4t,"wavlm"),Q4t.forEach(t),Lwo=r(Mke," \u2014 "),fG=n(Mke,"A",{href:!0});var W4t=s(fG);ywo=r(W4t,"WavLMModel"),W4t.forEach(t),xwo=r(Mke," (WavLM model)"),Mke.forEach(t),$wo=i(x),Ou=n(x,"LI",{});var Eke=s(Ou);Rme=n(Eke,"STRONG",{});var H4t=s(Rme);kwo=r(H4t,"xglm"),H4t.forEach(t),Swo=r(Eke," \u2014 "),mG=n(Eke,"A",{href:!0});var U4t=s(mG);Rwo=r(U4t,"XGLMModel"),U4t.forEach(t),Pwo=r(Eke," (XGLM model)"),Eke.forEach(t),Bwo=i(x),Vu=n(x,"LI",{});var Cke=s(Vu);Pme=n(Cke,"STRONG",{});var J4t=s(Pme);Iwo=r(J4t,"xlm"),J4t.forEach(t),Nwo=r(Cke," \u2014 "),gG=n(Cke,"A",{href:!0});var Y4t=s(gG);qwo=r(Y4t,"XLMModel"),Y4t.forEach(t),jwo=r(Cke," (XLM model)"),Cke.forEach(t),Dwo=i(x),Xu=n(x,"LI",{});var wke=s(Xu);Bme=n(wke,"STRONG",{});var K4t=s(Bme);Gwo=r(K4t,"xlm-prophetnet"),K4t.forEach(t),Owo=r(wke," \u2014 "),hG=n(wke,"A",{href:!0});var Z4t=s(hG);Vwo=r(Z4t,"XLMProphetNetModel"),Z4t.forEach(t),Xwo=r(wke," (XLM-ProphetNet model)"),wke.forEach(t),zwo=i(x),zu=n(x,"LI",{});var Ake=s(zu);Ime=n(Ake,"STRONG",{});var e2t=s(Ime);Qwo=r(e2t,"xlm-roberta"),e2t.forEach(t),Wwo=r(Ake," \u2014 "),pG=n(Ake,"A",{href:!0});var o2t=s(pG);Hwo=r(o2t,"XLMRobertaModel"),o2t.forEach(t),Uwo=r(Ake," (XLM-RoBERTa model)"),Ake.forEach(t),Jwo=i(x),Qu=n(x,"LI",{});var Lke=s(Qu);Nme=n(Lke,"STRONG",{});var r2t=s(Nme);Ywo=r(r2t,"xlm-roberta-xl"),r2t.forEach(t),Kwo=r(Lke," \u2014 "),_G=n(Lke,"A",{href:!0});var t2t=s(_G);Zwo=r(t2t,"XLMRobertaXLModel"),t2t.forEach(t),eAo=r(Lke," (XLM-RoBERTa-XL model)"),Lke.forEach(t),oAo=i(x),Wu=n(x,"LI",{});var yke=s(Wu);qme=n(yke,"STRONG",{});var a2t=s(qme);rAo=r(a2t,"xlnet"),a2t.forEach(t),tAo=r(yke," \u2014 "),uG=n(yke,"A",{href:!0});var n2t=s(uG);aAo=r(n2t,"XLNetModel"),n2t.forEach(t),nAo=r(yke," (XLNet model)"),yke.forEach(t),sAo=i(x),Hu=n(x,"LI",{});var xke=s(Hu);jme=n(xke,"STRONG",{});var s2t=s(jme);lAo=r(s2t,"yolos"),s2t.forEach(t),iAo=r(xke," \u2014 "),bG=n(xke,"A",{href:!0});var l2t=s(bG);dAo=r(l2t,"YolosModel"),l2t.forEach(t),cAo=r(xke," (YOLOS model)"),xke.forEach(t),fAo=i(x),Uu=n(x,"LI",{});var $ke=s(Uu);Dme=n($ke,"STRONG",{});var i2t=s(Dme);mAo=r(i2t,"yoso"),i2t.forEach(t),gAo=r($ke," \u2014 "),vG=n($ke,"A",{href:!0});var d2t=s(vG);hAo=r(d2t,"YosoModel"),d2t.forEach(t),pAo=r($ke," (YOSO model)"),$ke.forEach(t),x.forEach(t),_Ao=i(la),Ju=n(la,"P",{});var kke=s(Ju);uAo=r(kke,"The model is set in evaluation mode by default using "),Gme=n(kke,"CODE",{});var c2t=s(Gme);bAo=r(c2t,"model.eval()"),c2t.forEach(t),vAo=r(kke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ome=n(kke,"CODE",{});var f2t=s(Ome);FAo=r(f2t,"model.train()"),f2t.forEach(t),kke.forEach(t),TAo=i(la),T(Yu.$$.fragment,la),la.forEach(t),al.forEach(t),tze=i(f),Qi=n(f,"H2",{class:!0});var dWe=s(Qi);Ku=n(dWe,"A",{id:!0,class:!0,href:!0});var m2t=s(Ku);Vme=n(m2t,"SPAN",{});var g2t=s(Vme);T(WL.$$.fragment,g2t),g2t.forEach(t),m2t.forEach(t),MAo=i(dWe),Xme=n(dWe,"SPAN",{});var h2t=s(Xme);EAo=r(h2t,"AutoModelForPreTraining"),h2t.forEach(t),dWe.forEach(t),aze=i(f),So=n(f,"DIV",{class:!0});var nl=s(So);T(HL.$$.fragment,nl),CAo=i(nl),Wi=n(nl,"P",{});var nte=s(Wi);wAo=r(nte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),FG=n(nte,"A",{href:!0});var p2t=s(FG);AAo=r(p2t,"from_pretrained()"),p2t.forEach(t),LAo=r(nte," class method or the "),TG=n(nte,"A",{href:!0});var _2t=s(TG);yAo=r(_2t,"from_config()"),_2t.forEach(t),xAo=r(nte,` class
method.`),nte.forEach(t),$Ao=i(nl),UL=n(nl,"P",{});var cWe=s(UL);kAo=r(cWe,"This class cannot be instantiated directly using "),zme=n(cWe,"CODE",{});var u2t=s(zme);SAo=r(u2t,"__init__()"),u2t.forEach(t),RAo=r(cWe," (throws an error)."),cWe.forEach(t),PAo=i(nl),dt=n(nl,"DIV",{class:!0});var Tw=s(dt);T(JL.$$.fragment,Tw),BAo=i(Tw),Qme=n(Tw,"P",{});var b2t=s(Qme);IAo=r(b2t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),b2t.forEach(t),NAo=i(Tw),Hi=n(Tw,"P",{});var ste=s(Hi);qAo=r(ste,`Note:
Loading a model from its configuration file does `),Wme=n(ste,"STRONG",{});var v2t=s(Wme);jAo=r(v2t,"not"),v2t.forEach(t),DAo=r(ste,` load the model weights. It only affects the
model\u2019s configuration. Use `),MG=n(ste,"A",{href:!0});var F2t=s(MG);GAo=r(F2t,"from_pretrained()"),F2t.forEach(t),OAo=r(ste," to load the model weights."),ste.forEach(t),VAo=i(Tw),T(Zu.$$.fragment,Tw),Tw.forEach(t),XAo=i(nl),Ke=n(nl,"DIV",{class:!0});var ia=s(Ke);T(YL.$$.fragment,ia),zAo=i(ia),Hme=n(ia,"P",{});var T2t=s(Hme);QAo=r(T2t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),T2t.forEach(t),WAo=i(ia),Na=n(ia,"P",{});var Mw=s(Na);HAo=r(Mw,"The model class to instantiate is selected based on the "),Ume=n(Mw,"CODE",{});var M2t=s(Ume);UAo=r(M2t,"model_type"),M2t.forEach(t),JAo=r(Mw,` property of the config object (either
passed as an argument or loaded from `),Jme=n(Mw,"CODE",{});var E2t=s(Jme);YAo=r(E2t,"pretrained_model_name_or_path"),E2t.forEach(t),KAo=r(Mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yme=n(Mw,"CODE",{});var C2t=s(Yme);ZAo=r(C2t,"pretrained_model_name_or_path"),C2t.forEach(t),eLo=r(Mw,":"),Mw.forEach(t),oLo=i(ia),G=n(ia,"UL",{});var O=s(G);e1=n(O,"LI",{});var Ske=s(e1);Kme=n(Ske,"STRONG",{});var w2t=s(Kme);rLo=r(w2t,"albert"),w2t.forEach(t),tLo=r(Ske," \u2014 "),EG=n(Ske,"A",{href:!0});var A2t=s(EG);aLo=r(A2t,"AlbertForPreTraining"),A2t.forEach(t),nLo=r(Ske," (ALBERT model)"),Ske.forEach(t),sLo=i(O),o1=n(O,"LI",{});var Rke=s(o1);Zme=n(Rke,"STRONG",{});var L2t=s(Zme);lLo=r(L2t,"bart"),L2t.forEach(t),iLo=r(Rke," \u2014 "),CG=n(Rke,"A",{href:!0});var y2t=s(CG);dLo=r(y2t,"BartForConditionalGeneration"),y2t.forEach(t),cLo=r(Rke," (BART model)"),Rke.forEach(t),fLo=i(O),r1=n(O,"LI",{});var Pke=s(r1);ege=n(Pke,"STRONG",{});var x2t=s(ege);mLo=r(x2t,"bert"),x2t.forEach(t),gLo=r(Pke," \u2014 "),wG=n(Pke,"A",{href:!0});var $2t=s(wG);hLo=r($2t,"BertForPreTraining"),$2t.forEach(t),pLo=r(Pke," (BERT model)"),Pke.forEach(t),_Lo=i(O),t1=n(O,"LI",{});var Bke=s(t1);oge=n(Bke,"STRONG",{});var k2t=s(oge);uLo=r(k2t,"big_bird"),k2t.forEach(t),bLo=r(Bke," \u2014 "),AG=n(Bke,"A",{href:!0});var S2t=s(AG);vLo=r(S2t,"BigBirdForPreTraining"),S2t.forEach(t),FLo=r(Bke," (BigBird model)"),Bke.forEach(t),TLo=i(O),a1=n(O,"LI",{});var Ike=s(a1);rge=n(Ike,"STRONG",{});var R2t=s(rge);MLo=r(R2t,"bloom"),R2t.forEach(t),ELo=r(Ike," \u2014 "),LG=n(Ike,"A",{href:!0});var P2t=s(LG);CLo=r(P2t,"BloomForCausalLM"),P2t.forEach(t),wLo=r(Ike," (BLOOM model)"),Ike.forEach(t),ALo=i(O),n1=n(O,"LI",{});var Nke=s(n1);tge=n(Nke,"STRONG",{});var B2t=s(tge);LLo=r(B2t,"camembert"),B2t.forEach(t),yLo=r(Nke," \u2014 "),yG=n(Nke,"A",{href:!0});var I2t=s(yG);xLo=r(I2t,"CamembertForMaskedLM"),I2t.forEach(t),$Lo=r(Nke," (CamemBERT model)"),Nke.forEach(t),kLo=i(O),s1=n(O,"LI",{});var qke=s(s1);age=n(qke,"STRONG",{});var N2t=s(age);SLo=r(N2t,"ctrl"),N2t.forEach(t),RLo=r(qke," \u2014 "),xG=n(qke,"A",{href:!0});var q2t=s(xG);PLo=r(q2t,"CTRLLMHeadModel"),q2t.forEach(t),BLo=r(qke," (CTRL model)"),qke.forEach(t),ILo=i(O),l1=n(O,"LI",{});var jke=s(l1);nge=n(jke,"STRONG",{});var j2t=s(nge);NLo=r(j2t,"data2vec-text"),j2t.forEach(t),qLo=r(jke," \u2014 "),$G=n(jke,"A",{href:!0});var D2t=s($G);jLo=r(D2t,"Data2VecTextForMaskedLM"),D2t.forEach(t),DLo=r(jke," (Data2VecText model)"),jke.forEach(t),GLo=i(O),i1=n(O,"LI",{});var Dke=s(i1);sge=n(Dke,"STRONG",{});var G2t=s(sge);OLo=r(G2t,"deberta"),G2t.forEach(t),VLo=r(Dke," \u2014 "),kG=n(Dke,"A",{href:!0});var O2t=s(kG);XLo=r(O2t,"DebertaForMaskedLM"),O2t.forEach(t),zLo=r(Dke," (DeBERTa model)"),Dke.forEach(t),QLo=i(O),d1=n(O,"LI",{});var Gke=s(d1);lge=n(Gke,"STRONG",{});var V2t=s(lge);WLo=r(V2t,"deberta-v2"),V2t.forEach(t),HLo=r(Gke," \u2014 "),SG=n(Gke,"A",{href:!0});var X2t=s(SG);ULo=r(X2t,"DebertaV2ForMaskedLM"),X2t.forEach(t),JLo=r(Gke," (DeBERTa-v2 model)"),Gke.forEach(t),YLo=i(O),c1=n(O,"LI",{});var Oke=s(c1);ige=n(Oke,"STRONG",{});var z2t=s(ige);KLo=r(z2t,"distilbert"),z2t.forEach(t),ZLo=r(Oke," \u2014 "),RG=n(Oke,"A",{href:!0});var Q2t=s(RG);eyo=r(Q2t,"DistilBertForMaskedLM"),Q2t.forEach(t),oyo=r(Oke," (DistilBERT model)"),Oke.forEach(t),ryo=i(O),f1=n(O,"LI",{});var Vke=s(f1);dge=n(Vke,"STRONG",{});var W2t=s(dge);tyo=r(W2t,"electra"),W2t.forEach(t),ayo=r(Vke," \u2014 "),PG=n(Vke,"A",{href:!0});var H2t=s(PG);nyo=r(H2t,"ElectraForPreTraining"),H2t.forEach(t),syo=r(Vke," (ELECTRA model)"),Vke.forEach(t),lyo=i(O),m1=n(O,"LI",{});var Xke=s(m1);cge=n(Xke,"STRONG",{});var U2t=s(cge);iyo=r(U2t,"flaubert"),U2t.forEach(t),dyo=r(Xke," \u2014 "),BG=n(Xke,"A",{href:!0});var J2t=s(BG);cyo=r(J2t,"FlaubertWithLMHeadModel"),J2t.forEach(t),fyo=r(Xke," (FlauBERT model)"),Xke.forEach(t),myo=i(O),g1=n(O,"LI",{});var zke=s(g1);fge=n(zke,"STRONG",{});var Y2t=s(fge);gyo=r(Y2t,"flava"),Y2t.forEach(t),hyo=r(zke," \u2014 "),IG=n(zke,"A",{href:!0});var K2t=s(IG);pyo=r(K2t,"FlavaForPreTraining"),K2t.forEach(t),_yo=r(zke," (FLAVA model)"),zke.forEach(t),uyo=i(O),h1=n(O,"LI",{});var Qke=s(h1);mge=n(Qke,"STRONG",{});var Z2t=s(mge);byo=r(Z2t,"fnet"),Z2t.forEach(t),vyo=r(Qke," \u2014 "),NG=n(Qke,"A",{href:!0});var ebt=s(NG);Fyo=r(ebt,"FNetForPreTraining"),ebt.forEach(t),Tyo=r(Qke," (FNet model)"),Qke.forEach(t),Myo=i(O),p1=n(O,"LI",{});var Wke=s(p1);gge=n(Wke,"STRONG",{});var obt=s(gge);Eyo=r(obt,"fsmt"),obt.forEach(t),Cyo=r(Wke," \u2014 "),qG=n(Wke,"A",{href:!0});var rbt=s(qG);wyo=r(rbt,"FSMTForConditionalGeneration"),rbt.forEach(t),Ayo=r(Wke," (FairSeq Machine-Translation model)"),Wke.forEach(t),Lyo=i(O),_1=n(O,"LI",{});var Hke=s(_1);hge=n(Hke,"STRONG",{});var tbt=s(hge);yyo=r(tbt,"funnel"),tbt.forEach(t),xyo=r(Hke," \u2014 "),jG=n(Hke,"A",{href:!0});var abt=s(jG);$yo=r(abt,"FunnelForPreTraining"),abt.forEach(t),kyo=r(Hke," (Funnel Transformer model)"),Hke.forEach(t),Syo=i(O),u1=n(O,"LI",{});var Uke=s(u1);pge=n(Uke,"STRONG",{});var nbt=s(pge);Ryo=r(nbt,"gpt2"),nbt.forEach(t),Pyo=r(Uke," \u2014 "),DG=n(Uke,"A",{href:!0});var sbt=s(DG);Byo=r(sbt,"GPT2LMHeadModel"),sbt.forEach(t),Iyo=r(Uke," (OpenAI GPT-2 model)"),Uke.forEach(t),Nyo=i(O),b1=n(O,"LI",{});var Jke=s(b1);_ge=n(Jke,"STRONG",{});var lbt=s(_ge);qyo=r(lbt,"ibert"),lbt.forEach(t),jyo=r(Jke," \u2014 "),GG=n(Jke,"A",{href:!0});var ibt=s(GG);Dyo=r(ibt,"IBertForMaskedLM"),ibt.forEach(t),Gyo=r(Jke," (I-BERT model)"),Jke.forEach(t),Oyo=i(O),v1=n(O,"LI",{});var Yke=s(v1);uge=n(Yke,"STRONG",{});var dbt=s(uge);Vyo=r(dbt,"layoutlm"),dbt.forEach(t),Xyo=r(Yke," \u2014 "),OG=n(Yke,"A",{href:!0});var cbt=s(OG);zyo=r(cbt,"LayoutLMForMaskedLM"),cbt.forEach(t),Qyo=r(Yke," (LayoutLM model)"),Yke.forEach(t),Wyo=i(O),F1=n(O,"LI",{});var Kke=s(F1);bge=n(Kke,"STRONG",{});var fbt=s(bge);Hyo=r(fbt,"longformer"),fbt.forEach(t),Uyo=r(Kke," \u2014 "),VG=n(Kke,"A",{href:!0});var mbt=s(VG);Jyo=r(mbt,"LongformerForMaskedLM"),mbt.forEach(t),Yyo=r(Kke," (Longformer model)"),Kke.forEach(t),Kyo=i(O),T1=n(O,"LI",{});var Zke=s(T1);vge=n(Zke,"STRONG",{});var gbt=s(vge);Zyo=r(gbt,"lxmert"),gbt.forEach(t),e8o=r(Zke," \u2014 "),XG=n(Zke,"A",{href:!0});var hbt=s(XG);o8o=r(hbt,"LxmertForPreTraining"),hbt.forEach(t),r8o=r(Zke," (LXMERT model)"),Zke.forEach(t),t8o=i(O),M1=n(O,"LI",{});var eSe=s(M1);Fge=n(eSe,"STRONG",{});var pbt=s(Fge);a8o=r(pbt,"megatron-bert"),pbt.forEach(t),n8o=r(eSe," \u2014 "),zG=n(eSe,"A",{href:!0});var _bt=s(zG);s8o=r(_bt,"MegatronBertForPreTraining"),_bt.forEach(t),l8o=r(eSe," (Megatron-BERT model)"),eSe.forEach(t),i8o=i(O),E1=n(O,"LI",{});var oSe=s(E1);Tge=n(oSe,"STRONG",{});var ubt=s(Tge);d8o=r(ubt,"mobilebert"),ubt.forEach(t),c8o=r(oSe," \u2014 "),QG=n(oSe,"A",{href:!0});var bbt=s(QG);f8o=r(bbt,"MobileBertForPreTraining"),bbt.forEach(t),m8o=r(oSe," (MobileBERT model)"),oSe.forEach(t),g8o=i(O),C1=n(O,"LI",{});var rSe=s(C1);Mge=n(rSe,"STRONG",{});var vbt=s(Mge);h8o=r(vbt,"mpnet"),vbt.forEach(t),p8o=r(rSe," \u2014 "),WG=n(rSe,"A",{href:!0});var Fbt=s(WG);_8o=r(Fbt,"MPNetForMaskedLM"),Fbt.forEach(t),u8o=r(rSe," (MPNet model)"),rSe.forEach(t),b8o=i(O),w1=n(O,"LI",{});var tSe=s(w1);Ege=n(tSe,"STRONG",{});var Tbt=s(Ege);v8o=r(Tbt,"mvp"),Tbt.forEach(t),F8o=r(tSe," \u2014 "),HG=n(tSe,"A",{href:!0});var Mbt=s(HG);T8o=r(Mbt,"MvpForConditionalGeneration"),Mbt.forEach(t),M8o=r(tSe," (MVP model)"),tSe.forEach(t),E8o=i(O),A1=n(O,"LI",{});var aSe=s(A1);Cge=n(aSe,"STRONG",{});var Ebt=s(Cge);C8o=r(Ebt,"nezha"),Ebt.forEach(t),w8o=r(aSe," \u2014 "),UG=n(aSe,"A",{href:!0});var Cbt=s(UG);A8o=r(Cbt,"NezhaForPreTraining"),Cbt.forEach(t),L8o=r(aSe," (Nezha model)"),aSe.forEach(t),y8o=i(O),L1=n(O,"LI",{});var nSe=s(L1);wge=n(nSe,"STRONG",{});var wbt=s(wge);x8o=r(wbt,"openai-gpt"),wbt.forEach(t),$8o=r(nSe," \u2014 "),JG=n(nSe,"A",{href:!0});var Abt=s(JG);k8o=r(Abt,"OpenAIGPTLMHeadModel"),Abt.forEach(t),S8o=r(nSe," (OpenAI GPT model)"),nSe.forEach(t),R8o=i(O),y1=n(O,"LI",{});var sSe=s(y1);Age=n(sSe,"STRONG",{});var Lbt=s(Age);P8o=r(Lbt,"retribert"),Lbt.forEach(t),B8o=r(sSe," \u2014 "),YG=n(sSe,"A",{href:!0});var ybt=s(YG);I8o=r(ybt,"RetriBertModel"),ybt.forEach(t),N8o=r(sSe," (RetriBERT model)"),sSe.forEach(t),q8o=i(O),x1=n(O,"LI",{});var lSe=s(x1);Lge=n(lSe,"STRONG",{});var xbt=s(Lge);j8o=r(xbt,"roberta"),xbt.forEach(t),D8o=r(lSe," \u2014 "),KG=n(lSe,"A",{href:!0});var $bt=s(KG);G8o=r($bt,"RobertaForMaskedLM"),$bt.forEach(t),O8o=r(lSe," (RoBERTa model)"),lSe.forEach(t),V8o=i(O),$1=n(O,"LI",{});var iSe=s($1);yge=n(iSe,"STRONG",{});var kbt=s(yge);X8o=r(kbt,"splinter"),kbt.forEach(t),z8o=r(iSe," \u2014 "),ZG=n(iSe,"A",{href:!0});var Sbt=s(ZG);Q8o=r(Sbt,"SplinterForPreTraining"),Sbt.forEach(t),W8o=r(iSe," (Splinter model)"),iSe.forEach(t),H8o=i(O),k1=n(O,"LI",{});var dSe=s(k1);xge=n(dSe,"STRONG",{});var Rbt=s(xge);U8o=r(Rbt,"squeezebert"),Rbt.forEach(t),J8o=r(dSe," \u2014 "),eO=n(dSe,"A",{href:!0});var Pbt=s(eO);Y8o=r(Pbt,"SqueezeBertForMaskedLM"),Pbt.forEach(t),K8o=r(dSe," (SqueezeBERT model)"),dSe.forEach(t),Z8o=i(O),S1=n(O,"LI",{});var cSe=s(S1);$ge=n(cSe,"STRONG",{});var Bbt=s($ge);exo=r(Bbt,"t5"),Bbt.forEach(t),oxo=r(cSe," \u2014 "),oO=n(cSe,"A",{href:!0});var Ibt=s(oO);rxo=r(Ibt,"T5ForConditionalGeneration"),Ibt.forEach(t),txo=r(cSe," (T5 model)"),cSe.forEach(t),axo=i(O),R1=n(O,"LI",{});var fSe=s(R1);kge=n(fSe,"STRONG",{});var Nbt=s(kge);nxo=r(Nbt,"tapas"),Nbt.forEach(t),sxo=r(fSe," \u2014 "),rO=n(fSe,"A",{href:!0});var qbt=s(rO);lxo=r(qbt,"TapasForMaskedLM"),qbt.forEach(t),ixo=r(fSe," (TAPAS model)"),fSe.forEach(t),dxo=i(O),P1=n(O,"LI",{});var mSe=s(P1);Sge=n(mSe,"STRONG",{});var jbt=s(Sge);cxo=r(jbt,"transfo-xl"),jbt.forEach(t),fxo=r(mSe," \u2014 "),tO=n(mSe,"A",{href:!0});var Dbt=s(tO);mxo=r(Dbt,"TransfoXLLMHeadModel"),Dbt.forEach(t),gxo=r(mSe," (Transformer-XL model)"),mSe.forEach(t),hxo=i(O),B1=n(O,"LI",{});var gSe=s(B1);Rge=n(gSe,"STRONG",{});var Gbt=s(Rge);pxo=r(Gbt,"unispeech"),Gbt.forEach(t),_xo=r(gSe," \u2014 "),aO=n(gSe,"A",{href:!0});var Obt=s(aO);uxo=r(Obt,"UniSpeechForPreTraining"),Obt.forEach(t),bxo=r(gSe," (UniSpeech model)"),gSe.forEach(t),vxo=i(O),I1=n(O,"LI",{});var hSe=s(I1);Pge=n(hSe,"STRONG",{});var Vbt=s(Pge);Fxo=r(Vbt,"unispeech-sat"),Vbt.forEach(t),Txo=r(hSe," \u2014 "),nO=n(hSe,"A",{href:!0});var Xbt=s(nO);Mxo=r(Xbt,"UniSpeechSatForPreTraining"),Xbt.forEach(t),Exo=r(hSe," (UniSpeechSat model)"),hSe.forEach(t),Cxo=i(O),N1=n(O,"LI",{});var pSe=s(N1);Bge=n(pSe,"STRONG",{});var zbt=s(Bge);wxo=r(zbt,"visual_bert"),zbt.forEach(t),Axo=r(pSe," \u2014 "),sO=n(pSe,"A",{href:!0});var Qbt=s(sO);Lxo=r(Qbt,"VisualBertForPreTraining"),Qbt.forEach(t),yxo=r(pSe," (VisualBERT model)"),pSe.forEach(t),xxo=i(O),q1=n(O,"LI",{});var _Se=s(q1);Ige=n(_Se,"STRONG",{});var Wbt=s(Ige);$xo=r(Wbt,"vit_mae"),Wbt.forEach(t),kxo=r(_Se," \u2014 "),lO=n(_Se,"A",{href:!0});var Hbt=s(lO);Sxo=r(Hbt,"ViTMAEForPreTraining"),Hbt.forEach(t),Rxo=r(_Se," (ViTMAE model)"),_Se.forEach(t),Pxo=i(O),j1=n(O,"LI",{});var uSe=s(j1);Nge=n(uSe,"STRONG",{});var Ubt=s(Nge);Bxo=r(Ubt,"wav2vec2"),Ubt.forEach(t),Ixo=r(uSe," \u2014 "),iO=n(uSe,"A",{href:!0});var Jbt=s(iO);Nxo=r(Jbt,"Wav2Vec2ForPreTraining"),Jbt.forEach(t),qxo=r(uSe," (Wav2Vec2 model)"),uSe.forEach(t),jxo=i(O),D1=n(O,"LI",{});var bSe=s(D1);qge=n(bSe,"STRONG",{});var Ybt=s(qge);Dxo=r(Ybt,"wav2vec2-conformer"),Ybt.forEach(t),Gxo=r(bSe," \u2014 "),dO=n(bSe,"A",{href:!0});var Kbt=s(dO);Oxo=r(Kbt,"Wav2Vec2ConformerForPreTraining"),Kbt.forEach(t),Vxo=r(bSe," (Wav2Vec2-Conformer model)"),bSe.forEach(t),Xxo=i(O),G1=n(O,"LI",{});var vSe=s(G1);jge=n(vSe,"STRONG",{});var Zbt=s(jge);zxo=r(Zbt,"xlm"),Zbt.forEach(t),Qxo=r(vSe," \u2014 "),cO=n(vSe,"A",{href:!0});var evt=s(cO);Wxo=r(evt,"XLMWithLMHeadModel"),evt.forEach(t),Hxo=r(vSe," (XLM model)"),vSe.forEach(t),Uxo=i(O),O1=n(O,"LI",{});var FSe=s(O1);Dge=n(FSe,"STRONG",{});var ovt=s(Dge);Jxo=r(ovt,"xlm-roberta"),ovt.forEach(t),Yxo=r(FSe," \u2014 "),fO=n(FSe,"A",{href:!0});var rvt=s(fO);Kxo=r(rvt,"XLMRobertaForMaskedLM"),rvt.forEach(t),Zxo=r(FSe," (XLM-RoBERTa model)"),FSe.forEach(t),e$o=i(O),V1=n(O,"LI",{});var TSe=s(V1);Gge=n(TSe,"STRONG",{});var tvt=s(Gge);o$o=r(tvt,"xlm-roberta-xl"),tvt.forEach(t),r$o=r(TSe," \u2014 "),mO=n(TSe,"A",{href:!0});var avt=s(mO);t$o=r(avt,"XLMRobertaXLForMaskedLM"),avt.forEach(t),a$o=r(TSe," (XLM-RoBERTa-XL model)"),TSe.forEach(t),n$o=i(O),X1=n(O,"LI",{});var MSe=s(X1);Oge=n(MSe,"STRONG",{});var nvt=s(Oge);s$o=r(nvt,"xlnet"),nvt.forEach(t),l$o=r(MSe," \u2014 "),gO=n(MSe,"A",{href:!0});var svt=s(gO);i$o=r(svt,"XLNetLMHeadModel"),svt.forEach(t),d$o=r(MSe," (XLNet model)"),MSe.forEach(t),O.forEach(t),c$o=i(ia),z1=n(ia,"P",{});var ESe=s(z1);f$o=r(ESe,"The model is set in evaluation mode by default using "),Vge=n(ESe,"CODE",{});var lvt=s(Vge);m$o=r(lvt,"model.eval()"),lvt.forEach(t),g$o=r(ESe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xge=n(ESe,"CODE",{});var ivt=s(Xge);h$o=r(ivt,"model.train()"),ivt.forEach(t),ESe.forEach(t),p$o=i(ia),T(Q1.$$.fragment,ia),ia.forEach(t),nl.forEach(t),nze=i(f),Ui=n(f,"H2",{class:!0});var fWe=s(Ui);W1=n(fWe,"A",{id:!0,class:!0,href:!0});var dvt=s(W1);zge=n(dvt,"SPAN",{});var cvt=s(zge);T(KL.$$.fragment,cvt),cvt.forEach(t),dvt.forEach(t),_$o=i(fWe),Qge=n(fWe,"SPAN",{});var fvt=s(Qge);u$o=r(fvt,"AutoModelForCausalLM"),fvt.forEach(t),fWe.forEach(t),sze=i(f),Ro=n(f,"DIV",{class:!0});var sl=s(Ro);T(ZL.$$.fragment,sl),b$o=i(sl),Ji=n(sl,"P",{});var lte=s(Ji);v$o=r(lte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hO=n(lte,"A",{href:!0});var mvt=s(hO);F$o=r(mvt,"from_pretrained()"),mvt.forEach(t),T$o=r(lte," class method or the "),pO=n(lte,"A",{href:!0});var gvt=s(pO);M$o=r(gvt,"from_config()"),gvt.forEach(t),E$o=r(lte,` class
method.`),lte.forEach(t),C$o=i(sl),ey=n(sl,"P",{});var mWe=s(ey);w$o=r(mWe,"This class cannot be instantiated directly using "),Wge=n(mWe,"CODE",{});var hvt=s(Wge);A$o=r(hvt,"__init__()"),hvt.forEach(t),L$o=r(mWe," (throws an error)."),mWe.forEach(t),y$o=i(sl),ct=n(sl,"DIV",{class:!0});var Ew=s(ct);T(oy.$$.fragment,Ew),x$o=i(Ew),Hge=n(Ew,"P",{});var pvt=s(Hge);$$o=r(pvt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),pvt.forEach(t),k$o=i(Ew),Yi=n(Ew,"P",{});var ite=s(Yi);S$o=r(ite,`Note:
Loading a model from its configuration file does `),Uge=n(ite,"STRONG",{});var _vt=s(Uge);R$o=r(_vt,"not"),_vt.forEach(t),P$o=r(ite,` load the model weights. It only affects the
model\u2019s configuration. Use `),_O=n(ite,"A",{href:!0});var uvt=s(_O);B$o=r(uvt,"from_pretrained()"),uvt.forEach(t),I$o=r(ite," to load the model weights."),ite.forEach(t),N$o=i(Ew),T(H1.$$.fragment,Ew),Ew.forEach(t),q$o=i(sl),Ze=n(sl,"DIV",{class:!0});var da=s(Ze);T(ry.$$.fragment,da),j$o=i(da),Jge=n(da,"P",{});var bvt=s(Jge);D$o=r(bvt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),bvt.forEach(t),G$o=i(da),qa=n(da,"P",{});var Cw=s(qa);O$o=r(Cw,"The model class to instantiate is selected based on the "),Yge=n(Cw,"CODE",{});var vvt=s(Yge);V$o=r(vvt,"model_type"),vvt.forEach(t),X$o=r(Cw,` property of the config object (either
passed as an argument or loaded from `),Kge=n(Cw,"CODE",{});var Fvt=s(Kge);z$o=r(Fvt,"pretrained_model_name_or_path"),Fvt.forEach(t),Q$o=r(Cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zge=n(Cw,"CODE",{});var Tvt=s(Zge);W$o=r(Tvt,"pretrained_model_name_or_path"),Tvt.forEach(t),H$o=r(Cw,":"),Cw.forEach(t),U$o=i(da),z=n(da,"UL",{});var Q=s(z);U1=n(Q,"LI",{});var CSe=s(U1);ehe=n(CSe,"STRONG",{});var Mvt=s(ehe);J$o=r(Mvt,"bart"),Mvt.forEach(t),Y$o=r(CSe," \u2014 "),uO=n(CSe,"A",{href:!0});var Evt=s(uO);K$o=r(Evt,"BartForCausalLM"),Evt.forEach(t),Z$o=r(CSe," (BART model)"),CSe.forEach(t),eko=i(Q),J1=n(Q,"LI",{});var wSe=s(J1);ohe=n(wSe,"STRONG",{});var Cvt=s(ohe);oko=r(Cvt,"bert"),Cvt.forEach(t),rko=r(wSe," \u2014 "),bO=n(wSe,"A",{href:!0});var wvt=s(bO);tko=r(wvt,"BertLMHeadModel"),wvt.forEach(t),ako=r(wSe," (BERT model)"),wSe.forEach(t),nko=i(Q),Y1=n(Q,"LI",{});var ASe=s(Y1);rhe=n(ASe,"STRONG",{});var Avt=s(rhe);sko=r(Avt,"bert-generation"),Avt.forEach(t),lko=r(ASe," \u2014 "),vO=n(ASe,"A",{href:!0});var Lvt=s(vO);iko=r(Lvt,"BertGenerationDecoder"),Lvt.forEach(t),dko=r(ASe," (Bert Generation model)"),ASe.forEach(t),cko=i(Q),K1=n(Q,"LI",{});var LSe=s(K1);the=n(LSe,"STRONG",{});var yvt=s(the);fko=r(yvt,"big_bird"),yvt.forEach(t),mko=r(LSe," \u2014 "),FO=n(LSe,"A",{href:!0});var xvt=s(FO);gko=r(xvt,"BigBirdForCausalLM"),xvt.forEach(t),hko=r(LSe," (BigBird model)"),LSe.forEach(t),pko=i(Q),Z1=n(Q,"LI",{});var ySe=s(Z1);ahe=n(ySe,"STRONG",{});var $vt=s(ahe);_ko=r($vt,"bigbird_pegasus"),$vt.forEach(t),uko=r(ySe," \u2014 "),TO=n(ySe,"A",{href:!0});var kvt=s(TO);bko=r(kvt,"BigBirdPegasusForCausalLM"),kvt.forEach(t),vko=r(ySe," (BigBird-Pegasus model)"),ySe.forEach(t),Fko=i(Q),e4=n(Q,"LI",{});var xSe=s(e4);nhe=n(xSe,"STRONG",{});var Svt=s(nhe);Tko=r(Svt,"blenderbot"),Svt.forEach(t),Mko=r(xSe," \u2014 "),MO=n(xSe,"A",{href:!0});var Rvt=s(MO);Eko=r(Rvt,"BlenderbotForCausalLM"),Rvt.forEach(t),Cko=r(xSe," (Blenderbot model)"),xSe.forEach(t),wko=i(Q),o4=n(Q,"LI",{});var $Se=s(o4);she=n($Se,"STRONG",{});var Pvt=s(she);Ako=r(Pvt,"blenderbot-small"),Pvt.forEach(t),Lko=r($Se," \u2014 "),EO=n($Se,"A",{href:!0});var Bvt=s(EO);yko=r(Bvt,"BlenderbotSmallForCausalLM"),Bvt.forEach(t),xko=r($Se," (BlenderbotSmall model)"),$Se.forEach(t),$ko=i(Q),r4=n(Q,"LI",{});var kSe=s(r4);lhe=n(kSe,"STRONG",{});var Ivt=s(lhe);kko=r(Ivt,"bloom"),Ivt.forEach(t),Sko=r(kSe," \u2014 "),CO=n(kSe,"A",{href:!0});var Nvt=s(CO);Rko=r(Nvt,"BloomForCausalLM"),Nvt.forEach(t),Pko=r(kSe," (BLOOM model)"),kSe.forEach(t),Bko=i(Q),t4=n(Q,"LI",{});var SSe=s(t4);ihe=n(SSe,"STRONG",{});var qvt=s(ihe);Iko=r(qvt,"camembert"),qvt.forEach(t),Nko=r(SSe," \u2014 "),wO=n(SSe,"A",{href:!0});var jvt=s(wO);qko=r(jvt,"CamembertForCausalLM"),jvt.forEach(t),jko=r(SSe," (CamemBERT model)"),SSe.forEach(t),Dko=i(Q),a4=n(Q,"LI",{});var RSe=s(a4);dhe=n(RSe,"STRONG",{});var Dvt=s(dhe);Gko=r(Dvt,"codegen"),Dvt.forEach(t),Oko=r(RSe," \u2014 "),AO=n(RSe,"A",{href:!0});var Gvt=s(AO);Vko=r(Gvt,"CodeGenForCausalLM"),Gvt.forEach(t),Xko=r(RSe," (CodeGen model)"),RSe.forEach(t),zko=i(Q),n4=n(Q,"LI",{});var PSe=s(n4);che=n(PSe,"STRONG",{});var Ovt=s(che);Qko=r(Ovt,"ctrl"),Ovt.forEach(t),Wko=r(PSe," \u2014 "),LO=n(PSe,"A",{href:!0});var Vvt=s(LO);Hko=r(Vvt,"CTRLLMHeadModel"),Vvt.forEach(t),Uko=r(PSe," (CTRL model)"),PSe.forEach(t),Jko=i(Q),s4=n(Q,"LI",{});var BSe=s(s4);fhe=n(BSe,"STRONG",{});var Xvt=s(fhe);Yko=r(Xvt,"data2vec-text"),Xvt.forEach(t),Kko=r(BSe," \u2014 "),yO=n(BSe,"A",{href:!0});var zvt=s(yO);Zko=r(zvt,"Data2VecTextForCausalLM"),zvt.forEach(t),eSo=r(BSe," (Data2VecText model)"),BSe.forEach(t),oSo=i(Q),l4=n(Q,"LI",{});var ISe=s(l4);mhe=n(ISe,"STRONG",{});var Qvt=s(mhe);rSo=r(Qvt,"electra"),Qvt.forEach(t),tSo=r(ISe," \u2014 "),xO=n(ISe,"A",{href:!0});var Wvt=s(xO);aSo=r(Wvt,"ElectraForCausalLM"),Wvt.forEach(t),nSo=r(ISe," (ELECTRA model)"),ISe.forEach(t),sSo=i(Q),i4=n(Q,"LI",{});var NSe=s(i4);ghe=n(NSe,"STRONG",{});var Hvt=s(ghe);lSo=r(Hvt,"gpt2"),Hvt.forEach(t),iSo=r(NSe," \u2014 "),$O=n(NSe,"A",{href:!0});var Uvt=s($O);dSo=r(Uvt,"GPT2LMHeadModel"),Uvt.forEach(t),cSo=r(NSe," (OpenAI GPT-2 model)"),NSe.forEach(t),fSo=i(Q),d4=n(Q,"LI",{});var qSe=s(d4);hhe=n(qSe,"STRONG",{});var Jvt=s(hhe);mSo=r(Jvt,"gpt_neo"),Jvt.forEach(t),gSo=r(qSe," \u2014 "),kO=n(qSe,"A",{href:!0});var Yvt=s(kO);hSo=r(Yvt,"GPTNeoForCausalLM"),Yvt.forEach(t),pSo=r(qSe," (GPT Neo model)"),qSe.forEach(t),_So=i(Q),c4=n(Q,"LI",{});var jSe=s(c4);phe=n(jSe,"STRONG",{});var Kvt=s(phe);uSo=r(Kvt,"gpt_neox"),Kvt.forEach(t),bSo=r(jSe," \u2014 "),SO=n(jSe,"A",{href:!0});var Zvt=s(SO);vSo=r(Zvt,"GPTNeoXForCausalLM"),Zvt.forEach(t),FSo=r(jSe," (GPT NeoX model)"),jSe.forEach(t),TSo=i(Q),f4=n(Q,"LI",{});var DSe=s(f4);_he=n(DSe,"STRONG",{});var eFt=s(_he);MSo=r(eFt,"gptj"),eFt.forEach(t),ESo=r(DSe," \u2014 "),RO=n(DSe,"A",{href:!0});var oFt=s(RO);CSo=r(oFt,"GPTJForCausalLM"),oFt.forEach(t),wSo=r(DSe," (GPT-J model)"),DSe.forEach(t),ASo=i(Q),m4=n(Q,"LI",{});var GSe=s(m4);uhe=n(GSe,"STRONG",{});var rFt=s(uhe);LSo=r(rFt,"marian"),rFt.forEach(t),ySo=r(GSe," \u2014 "),PO=n(GSe,"A",{href:!0});var tFt=s(PO);xSo=r(tFt,"MarianForCausalLM"),tFt.forEach(t),$So=r(GSe," (Marian model)"),GSe.forEach(t),kSo=i(Q),g4=n(Q,"LI",{});var OSe=s(g4);bhe=n(OSe,"STRONG",{});var aFt=s(bhe);SSo=r(aFt,"mbart"),aFt.forEach(t),RSo=r(OSe," \u2014 "),BO=n(OSe,"A",{href:!0});var nFt=s(BO);PSo=r(nFt,"MBartForCausalLM"),nFt.forEach(t),BSo=r(OSe," (mBART model)"),OSe.forEach(t),ISo=i(Q),h4=n(Q,"LI",{});var VSe=s(h4);vhe=n(VSe,"STRONG",{});var sFt=s(vhe);NSo=r(sFt,"megatron-bert"),sFt.forEach(t),qSo=r(VSe," \u2014 "),IO=n(VSe,"A",{href:!0});var lFt=s(IO);jSo=r(lFt,"MegatronBertForCausalLM"),lFt.forEach(t),DSo=r(VSe," (Megatron-BERT model)"),VSe.forEach(t),GSo=i(Q),p4=n(Q,"LI",{});var XSe=s(p4);Fhe=n(XSe,"STRONG",{});var iFt=s(Fhe);OSo=r(iFt,"mvp"),iFt.forEach(t),VSo=r(XSe," \u2014 "),NO=n(XSe,"A",{href:!0});var dFt=s(NO);XSo=r(dFt,"MvpForCausalLM"),dFt.forEach(t),zSo=r(XSe," (MVP model)"),XSe.forEach(t),QSo=i(Q),_4=n(Q,"LI",{});var zSe=s(_4);The=n(zSe,"STRONG",{});var cFt=s(The);WSo=r(cFt,"openai-gpt"),cFt.forEach(t),HSo=r(zSe," \u2014 "),qO=n(zSe,"A",{href:!0});var fFt=s(qO);USo=r(fFt,"OpenAIGPTLMHeadModel"),fFt.forEach(t),JSo=r(zSe," (OpenAI GPT model)"),zSe.forEach(t),YSo=i(Q),u4=n(Q,"LI",{});var QSe=s(u4);Mhe=n(QSe,"STRONG",{});var mFt=s(Mhe);KSo=r(mFt,"opt"),mFt.forEach(t),ZSo=r(QSe," \u2014 "),jO=n(QSe,"A",{href:!0});var gFt=s(jO);eRo=r(gFt,"OPTForCausalLM"),gFt.forEach(t),oRo=r(QSe," (OPT model)"),QSe.forEach(t),rRo=i(Q),b4=n(Q,"LI",{});var WSe=s(b4);Ehe=n(WSe,"STRONG",{});var hFt=s(Ehe);tRo=r(hFt,"pegasus"),hFt.forEach(t),aRo=r(WSe," \u2014 "),DO=n(WSe,"A",{href:!0});var pFt=s(DO);nRo=r(pFt,"PegasusForCausalLM"),pFt.forEach(t),sRo=r(WSe," (Pegasus model)"),WSe.forEach(t),lRo=i(Q),v4=n(Q,"LI",{});var HSe=s(v4);Che=n(HSe,"STRONG",{});var _Ft=s(Che);iRo=r(_Ft,"plbart"),_Ft.forEach(t),dRo=r(HSe," \u2014 "),GO=n(HSe,"A",{href:!0});var uFt=s(GO);cRo=r(uFt,"PLBartForCausalLM"),uFt.forEach(t),fRo=r(HSe," (PLBart model)"),HSe.forEach(t),mRo=i(Q),F4=n(Q,"LI",{});var USe=s(F4);whe=n(USe,"STRONG",{});var bFt=s(whe);gRo=r(bFt,"prophetnet"),bFt.forEach(t),hRo=r(USe," \u2014 "),OO=n(USe,"A",{href:!0});var vFt=s(OO);pRo=r(vFt,"ProphetNetForCausalLM"),vFt.forEach(t),_Ro=r(USe," (ProphetNet model)"),USe.forEach(t),uRo=i(Q),T4=n(Q,"LI",{});var JSe=s(T4);Ahe=n(JSe,"STRONG",{});var FFt=s(Ahe);bRo=r(FFt,"qdqbert"),FFt.forEach(t),vRo=r(JSe," \u2014 "),VO=n(JSe,"A",{href:!0});var TFt=s(VO);FRo=r(TFt,"QDQBertLMHeadModel"),TFt.forEach(t),TRo=r(JSe," (QDQBert model)"),JSe.forEach(t),MRo=i(Q),M4=n(Q,"LI",{});var YSe=s(M4);Lhe=n(YSe,"STRONG",{});var MFt=s(Lhe);ERo=r(MFt,"reformer"),MFt.forEach(t),CRo=r(YSe," \u2014 "),XO=n(YSe,"A",{href:!0});var EFt=s(XO);wRo=r(EFt,"ReformerModelWithLMHead"),EFt.forEach(t),ARo=r(YSe," (Reformer model)"),YSe.forEach(t),LRo=i(Q),E4=n(Q,"LI",{});var KSe=s(E4);yhe=n(KSe,"STRONG",{});var CFt=s(yhe);yRo=r(CFt,"rembert"),CFt.forEach(t),xRo=r(KSe," \u2014 "),zO=n(KSe,"A",{href:!0});var wFt=s(zO);$Ro=r(wFt,"RemBertForCausalLM"),wFt.forEach(t),kRo=r(KSe," (RemBERT model)"),KSe.forEach(t),SRo=i(Q),C4=n(Q,"LI",{});var ZSe=s(C4);xhe=n(ZSe,"STRONG",{});var AFt=s(xhe);RRo=r(AFt,"roberta"),AFt.forEach(t),PRo=r(ZSe," \u2014 "),QO=n(ZSe,"A",{href:!0});var LFt=s(QO);BRo=r(LFt,"RobertaForCausalLM"),LFt.forEach(t),IRo=r(ZSe," (RoBERTa model)"),ZSe.forEach(t),NRo=i(Q),w4=n(Q,"LI",{});var eRe=s(w4);$he=n(eRe,"STRONG",{});var yFt=s($he);qRo=r(yFt,"roformer"),yFt.forEach(t),jRo=r(eRe," \u2014 "),WO=n(eRe,"A",{href:!0});var xFt=s(WO);DRo=r(xFt,"RoFormerForCausalLM"),xFt.forEach(t),GRo=r(eRe," (RoFormer model)"),eRe.forEach(t),ORo=i(Q),A4=n(Q,"LI",{});var oRe=s(A4);khe=n(oRe,"STRONG",{});var $Ft=s(khe);VRo=r($Ft,"speech_to_text_2"),$Ft.forEach(t),XRo=r(oRe," \u2014 "),HO=n(oRe,"A",{href:!0});var kFt=s(HO);zRo=r(kFt,"Speech2Text2ForCausalLM"),kFt.forEach(t),QRo=r(oRe," (Speech2Text2 model)"),oRe.forEach(t),WRo=i(Q),L4=n(Q,"LI",{});var rRe=s(L4);She=n(rRe,"STRONG",{});var SFt=s(She);HRo=r(SFt,"transfo-xl"),SFt.forEach(t),URo=r(rRe," \u2014 "),UO=n(rRe,"A",{href:!0});var RFt=s(UO);JRo=r(RFt,"TransfoXLLMHeadModel"),RFt.forEach(t),YRo=r(rRe," (Transformer-XL model)"),rRe.forEach(t),KRo=i(Q),y4=n(Q,"LI",{});var tRe=s(y4);Rhe=n(tRe,"STRONG",{});var PFt=s(Rhe);ZRo=r(PFt,"trocr"),PFt.forEach(t),ePo=r(tRe," \u2014 "),JO=n(tRe,"A",{href:!0});var BFt=s(JO);oPo=r(BFt,"TrOCRForCausalLM"),BFt.forEach(t),rPo=r(tRe," (TrOCR model)"),tRe.forEach(t),tPo=i(Q),x4=n(Q,"LI",{});var aRe=s(x4);Phe=n(aRe,"STRONG",{});var IFt=s(Phe);aPo=r(IFt,"xglm"),IFt.forEach(t),nPo=r(aRe," \u2014 "),YO=n(aRe,"A",{href:!0});var NFt=s(YO);sPo=r(NFt,"XGLMForCausalLM"),NFt.forEach(t),lPo=r(aRe," (XGLM model)"),aRe.forEach(t),iPo=i(Q),$4=n(Q,"LI",{});var nRe=s($4);Bhe=n(nRe,"STRONG",{});var qFt=s(Bhe);dPo=r(qFt,"xlm"),qFt.forEach(t),cPo=r(nRe," \u2014 "),KO=n(nRe,"A",{href:!0});var jFt=s(KO);fPo=r(jFt,"XLMWithLMHeadModel"),jFt.forEach(t),mPo=r(nRe," (XLM model)"),nRe.forEach(t),gPo=i(Q),k4=n(Q,"LI",{});var sRe=s(k4);Ihe=n(sRe,"STRONG",{});var DFt=s(Ihe);hPo=r(DFt,"xlm-prophetnet"),DFt.forEach(t),pPo=r(sRe," \u2014 "),ZO=n(sRe,"A",{href:!0});var GFt=s(ZO);_Po=r(GFt,"XLMProphetNetForCausalLM"),GFt.forEach(t),uPo=r(sRe," (XLM-ProphetNet model)"),sRe.forEach(t),bPo=i(Q),S4=n(Q,"LI",{});var lRe=s(S4);Nhe=n(lRe,"STRONG",{});var OFt=s(Nhe);vPo=r(OFt,"xlm-roberta"),OFt.forEach(t),FPo=r(lRe," \u2014 "),eV=n(lRe,"A",{href:!0});var VFt=s(eV);TPo=r(VFt,"XLMRobertaForCausalLM"),VFt.forEach(t),MPo=r(lRe," (XLM-RoBERTa model)"),lRe.forEach(t),EPo=i(Q),R4=n(Q,"LI",{});var iRe=s(R4);qhe=n(iRe,"STRONG",{});var XFt=s(qhe);CPo=r(XFt,"xlm-roberta-xl"),XFt.forEach(t),wPo=r(iRe," \u2014 "),oV=n(iRe,"A",{href:!0});var zFt=s(oV);APo=r(zFt,"XLMRobertaXLForCausalLM"),zFt.forEach(t),LPo=r(iRe," (XLM-RoBERTa-XL model)"),iRe.forEach(t),yPo=i(Q),P4=n(Q,"LI",{});var dRe=s(P4);jhe=n(dRe,"STRONG",{});var QFt=s(jhe);xPo=r(QFt,"xlnet"),QFt.forEach(t),$Po=r(dRe," \u2014 "),rV=n(dRe,"A",{href:!0});var WFt=s(rV);kPo=r(WFt,"XLNetLMHeadModel"),WFt.forEach(t),SPo=r(dRe," (XLNet model)"),dRe.forEach(t),Q.forEach(t),RPo=i(da),B4=n(da,"P",{});var cRe=s(B4);PPo=r(cRe,"The model is set in evaluation mode by default using "),Dhe=n(cRe,"CODE",{});var HFt=s(Dhe);BPo=r(HFt,"model.eval()"),HFt.forEach(t),IPo=r(cRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ghe=n(cRe,"CODE",{});var UFt=s(Ghe);NPo=r(UFt,"model.train()"),UFt.forEach(t),cRe.forEach(t),qPo=i(da),T(I4.$$.fragment,da),da.forEach(t),sl.forEach(t),lze=i(f),Ki=n(f,"H2",{class:!0});var gWe=s(Ki);N4=n(gWe,"A",{id:!0,class:!0,href:!0});var JFt=s(N4);Ohe=n(JFt,"SPAN",{});var YFt=s(Ohe);T(ty.$$.fragment,YFt),YFt.forEach(t),JFt.forEach(t),jPo=i(gWe),Vhe=n(gWe,"SPAN",{});var KFt=s(Vhe);DPo=r(KFt,"AutoModelForMaskedLM"),KFt.forEach(t),gWe.forEach(t),ize=i(f),Po=n(f,"DIV",{class:!0});var ll=s(Po);T(ay.$$.fragment,ll),GPo=i(ll),Zi=n(ll,"P",{});var dte=s(Zi);OPo=r(dte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),tV=n(dte,"A",{href:!0});var ZFt=s(tV);VPo=r(ZFt,"from_pretrained()"),ZFt.forEach(t),XPo=r(dte," class method or the "),aV=n(dte,"A",{href:!0});var e6t=s(aV);zPo=r(e6t,"from_config()"),e6t.forEach(t),QPo=r(dte,` class
method.`),dte.forEach(t),WPo=i(ll),ny=n(ll,"P",{});var hWe=s(ny);HPo=r(hWe,"This class cannot be instantiated directly using "),Xhe=n(hWe,"CODE",{});var o6t=s(Xhe);UPo=r(o6t,"__init__()"),o6t.forEach(t),JPo=r(hWe," (throws an error)."),hWe.forEach(t),YPo=i(ll),ft=n(ll,"DIV",{class:!0});var ww=s(ft);T(sy.$$.fragment,ww),KPo=i(ww),zhe=n(ww,"P",{});var r6t=s(zhe);ZPo=r(r6t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),r6t.forEach(t),eBo=i(ww),ed=n(ww,"P",{});var cte=s(ed);oBo=r(cte,`Note:
Loading a model from its configuration file does `),Qhe=n(cte,"STRONG",{});var t6t=s(Qhe);rBo=r(t6t,"not"),t6t.forEach(t),tBo=r(cte,` load the model weights. It only affects the
model\u2019s configuration. Use `),nV=n(cte,"A",{href:!0});var a6t=s(nV);aBo=r(a6t,"from_pretrained()"),a6t.forEach(t),nBo=r(cte," to load the model weights."),cte.forEach(t),sBo=i(ww),T(q4.$$.fragment,ww),ww.forEach(t),lBo=i(ll),eo=n(ll,"DIV",{class:!0});var ca=s(eo);T(ly.$$.fragment,ca),iBo=i(ca),Whe=n(ca,"P",{});var n6t=s(Whe);dBo=r(n6t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),n6t.forEach(t),cBo=i(ca),ja=n(ca,"P",{});var Aw=s(ja);fBo=r(Aw,"The model class to instantiate is selected based on the "),Hhe=n(Aw,"CODE",{});var s6t=s(Hhe);mBo=r(s6t,"model_type"),s6t.forEach(t),gBo=r(Aw,` property of the config object (either
passed as an argument or loaded from `),Uhe=n(Aw,"CODE",{});var l6t=s(Uhe);hBo=r(l6t,"pretrained_model_name_or_path"),l6t.forEach(t),pBo=r(Aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jhe=n(Aw,"CODE",{});var i6t=s(Jhe);_Bo=r(i6t,"pretrained_model_name_or_path"),i6t.forEach(t),uBo=r(Aw,":"),Aw.forEach(t),bBo=i(ca),W=n(ca,"UL",{});var H=s(W);j4=n(H,"LI",{});var fRe=s(j4);Yhe=n(fRe,"STRONG",{});var d6t=s(Yhe);vBo=r(d6t,"albert"),d6t.forEach(t),FBo=r(fRe," \u2014 "),sV=n(fRe,"A",{href:!0});var c6t=s(sV);TBo=r(c6t,"AlbertForMaskedLM"),c6t.forEach(t),MBo=r(fRe," (ALBERT model)"),fRe.forEach(t),EBo=i(H),D4=n(H,"LI",{});var mRe=s(D4);Khe=n(mRe,"STRONG",{});var f6t=s(Khe);CBo=r(f6t,"bart"),f6t.forEach(t),wBo=r(mRe," \u2014 "),lV=n(mRe,"A",{href:!0});var m6t=s(lV);ABo=r(m6t,"BartForConditionalGeneration"),m6t.forEach(t),LBo=r(mRe," (BART model)"),mRe.forEach(t),yBo=i(H),G4=n(H,"LI",{});var gRe=s(G4);Zhe=n(gRe,"STRONG",{});var g6t=s(Zhe);xBo=r(g6t,"bert"),g6t.forEach(t),$Bo=r(gRe," \u2014 "),iV=n(gRe,"A",{href:!0});var h6t=s(iV);kBo=r(h6t,"BertForMaskedLM"),h6t.forEach(t),SBo=r(gRe," (BERT model)"),gRe.forEach(t),RBo=i(H),O4=n(H,"LI",{});var hRe=s(O4);epe=n(hRe,"STRONG",{});var p6t=s(epe);PBo=r(p6t,"big_bird"),p6t.forEach(t),BBo=r(hRe," \u2014 "),dV=n(hRe,"A",{href:!0});var _6t=s(dV);IBo=r(_6t,"BigBirdForMaskedLM"),_6t.forEach(t),NBo=r(hRe," (BigBird model)"),hRe.forEach(t),qBo=i(H),V4=n(H,"LI",{});var pRe=s(V4);ope=n(pRe,"STRONG",{});var u6t=s(ope);jBo=r(u6t,"camembert"),u6t.forEach(t),DBo=r(pRe," \u2014 "),cV=n(pRe,"A",{href:!0});var b6t=s(cV);GBo=r(b6t,"CamembertForMaskedLM"),b6t.forEach(t),OBo=r(pRe," (CamemBERT model)"),pRe.forEach(t),VBo=i(H),X4=n(H,"LI",{});var _Re=s(X4);rpe=n(_Re,"STRONG",{});var v6t=s(rpe);XBo=r(v6t,"convbert"),v6t.forEach(t),zBo=r(_Re," \u2014 "),fV=n(_Re,"A",{href:!0});var F6t=s(fV);QBo=r(F6t,"ConvBertForMaskedLM"),F6t.forEach(t),WBo=r(_Re," (ConvBERT model)"),_Re.forEach(t),HBo=i(H),z4=n(H,"LI",{});var uRe=s(z4);tpe=n(uRe,"STRONG",{});var T6t=s(tpe);UBo=r(T6t,"data2vec-text"),T6t.forEach(t),JBo=r(uRe," \u2014 "),mV=n(uRe,"A",{href:!0});var M6t=s(mV);YBo=r(M6t,"Data2VecTextForMaskedLM"),M6t.forEach(t),KBo=r(uRe," (Data2VecText model)"),uRe.forEach(t),ZBo=i(H),Q4=n(H,"LI",{});var bRe=s(Q4);ape=n(bRe,"STRONG",{});var E6t=s(ape);eIo=r(E6t,"deberta"),E6t.forEach(t),oIo=r(bRe," \u2014 "),gV=n(bRe,"A",{href:!0});var C6t=s(gV);rIo=r(C6t,"DebertaForMaskedLM"),C6t.forEach(t),tIo=r(bRe," (DeBERTa model)"),bRe.forEach(t),aIo=i(H),W4=n(H,"LI",{});var vRe=s(W4);npe=n(vRe,"STRONG",{});var w6t=s(npe);nIo=r(w6t,"deberta-v2"),w6t.forEach(t),sIo=r(vRe," \u2014 "),hV=n(vRe,"A",{href:!0});var A6t=s(hV);lIo=r(A6t,"DebertaV2ForMaskedLM"),A6t.forEach(t),iIo=r(vRe," (DeBERTa-v2 model)"),vRe.forEach(t),dIo=i(H),H4=n(H,"LI",{});var FRe=s(H4);spe=n(FRe,"STRONG",{});var L6t=s(spe);cIo=r(L6t,"distilbert"),L6t.forEach(t),fIo=r(FRe," \u2014 "),pV=n(FRe,"A",{href:!0});var y6t=s(pV);mIo=r(y6t,"DistilBertForMaskedLM"),y6t.forEach(t),gIo=r(FRe," (DistilBERT model)"),FRe.forEach(t),hIo=i(H),U4=n(H,"LI",{});var TRe=s(U4);lpe=n(TRe,"STRONG",{});var x6t=s(lpe);pIo=r(x6t,"electra"),x6t.forEach(t),_Io=r(TRe," \u2014 "),_V=n(TRe,"A",{href:!0});var $6t=s(_V);uIo=r($6t,"ElectraForMaskedLM"),$6t.forEach(t),bIo=r(TRe," (ELECTRA model)"),TRe.forEach(t),vIo=i(H),J4=n(H,"LI",{});var MRe=s(J4);ipe=n(MRe,"STRONG",{});var k6t=s(ipe);FIo=r(k6t,"flaubert"),k6t.forEach(t),TIo=r(MRe," \u2014 "),uV=n(MRe,"A",{href:!0});var S6t=s(uV);MIo=r(S6t,"FlaubertWithLMHeadModel"),S6t.forEach(t),EIo=r(MRe," (FlauBERT model)"),MRe.forEach(t),CIo=i(H),Y4=n(H,"LI",{});var ERe=s(Y4);dpe=n(ERe,"STRONG",{});var R6t=s(dpe);wIo=r(R6t,"fnet"),R6t.forEach(t),AIo=r(ERe," \u2014 "),bV=n(ERe,"A",{href:!0});var P6t=s(bV);LIo=r(P6t,"FNetForMaskedLM"),P6t.forEach(t),yIo=r(ERe," (FNet model)"),ERe.forEach(t),xIo=i(H),K4=n(H,"LI",{});var CRe=s(K4);cpe=n(CRe,"STRONG",{});var B6t=s(cpe);$Io=r(B6t,"funnel"),B6t.forEach(t),kIo=r(CRe," \u2014 "),vV=n(CRe,"A",{href:!0});var I6t=s(vV);SIo=r(I6t,"FunnelForMaskedLM"),I6t.forEach(t),RIo=r(CRe," (Funnel Transformer model)"),CRe.forEach(t),PIo=i(H),Z4=n(H,"LI",{});var wRe=s(Z4);fpe=n(wRe,"STRONG",{});var N6t=s(fpe);BIo=r(N6t,"ibert"),N6t.forEach(t),IIo=r(wRe," \u2014 "),FV=n(wRe,"A",{href:!0});var q6t=s(FV);NIo=r(q6t,"IBertForMaskedLM"),q6t.forEach(t),qIo=r(wRe," (I-BERT model)"),wRe.forEach(t),jIo=i(H),e2=n(H,"LI",{});var ARe=s(e2);mpe=n(ARe,"STRONG",{});var j6t=s(mpe);DIo=r(j6t,"layoutlm"),j6t.forEach(t),GIo=r(ARe," \u2014 "),TV=n(ARe,"A",{href:!0});var D6t=s(TV);OIo=r(D6t,"LayoutLMForMaskedLM"),D6t.forEach(t),VIo=r(ARe," (LayoutLM model)"),ARe.forEach(t),XIo=i(H),o2=n(H,"LI",{});var LRe=s(o2);gpe=n(LRe,"STRONG",{});var G6t=s(gpe);zIo=r(G6t,"longformer"),G6t.forEach(t),QIo=r(LRe," \u2014 "),MV=n(LRe,"A",{href:!0});var O6t=s(MV);WIo=r(O6t,"LongformerForMaskedLM"),O6t.forEach(t),HIo=r(LRe," (Longformer model)"),LRe.forEach(t),UIo=i(H),r2=n(H,"LI",{});var yRe=s(r2);hpe=n(yRe,"STRONG",{});var V6t=s(hpe);JIo=r(V6t,"luke"),V6t.forEach(t),YIo=r(yRe," \u2014 "),EV=n(yRe,"A",{href:!0});var X6t=s(EV);KIo=r(X6t,"LukeForMaskedLM"),X6t.forEach(t),ZIo=r(yRe," (LUKE model)"),yRe.forEach(t),eNo=i(H),t2=n(H,"LI",{});var xRe=s(t2);ppe=n(xRe,"STRONG",{});var z6t=s(ppe);oNo=r(z6t,"mbart"),z6t.forEach(t),rNo=r(xRe," \u2014 "),CV=n(xRe,"A",{href:!0});var Q6t=s(CV);tNo=r(Q6t,"MBartForConditionalGeneration"),Q6t.forEach(t),aNo=r(xRe," (mBART model)"),xRe.forEach(t),nNo=i(H),a2=n(H,"LI",{});var $Re=s(a2);_pe=n($Re,"STRONG",{});var W6t=s(_pe);sNo=r(W6t,"megatron-bert"),W6t.forEach(t),lNo=r($Re," \u2014 "),wV=n($Re,"A",{href:!0});var H6t=s(wV);iNo=r(H6t,"MegatronBertForMaskedLM"),H6t.forEach(t),dNo=r($Re," (Megatron-BERT model)"),$Re.forEach(t),cNo=i(H),n2=n(H,"LI",{});var kRe=s(n2);upe=n(kRe,"STRONG",{});var U6t=s(upe);fNo=r(U6t,"mobilebert"),U6t.forEach(t),mNo=r(kRe," \u2014 "),AV=n(kRe,"A",{href:!0});var J6t=s(AV);gNo=r(J6t,"MobileBertForMaskedLM"),J6t.forEach(t),hNo=r(kRe," (MobileBERT model)"),kRe.forEach(t),pNo=i(H),s2=n(H,"LI",{});var SRe=s(s2);bpe=n(SRe,"STRONG",{});var Y6t=s(bpe);_No=r(Y6t,"mpnet"),Y6t.forEach(t),uNo=r(SRe," \u2014 "),LV=n(SRe,"A",{href:!0});var K6t=s(LV);bNo=r(K6t,"MPNetForMaskedLM"),K6t.forEach(t),vNo=r(SRe," (MPNet model)"),SRe.forEach(t),FNo=i(H),l2=n(H,"LI",{});var RRe=s(l2);vpe=n(RRe,"STRONG",{});var Z6t=s(vpe);TNo=r(Z6t,"mvp"),Z6t.forEach(t),MNo=r(RRe," \u2014 "),yV=n(RRe,"A",{href:!0});var eTt=s(yV);ENo=r(eTt,"MvpForConditionalGeneration"),eTt.forEach(t),CNo=r(RRe," (MVP model)"),RRe.forEach(t),wNo=i(H),i2=n(H,"LI",{});var PRe=s(i2);Fpe=n(PRe,"STRONG",{});var oTt=s(Fpe);ANo=r(oTt,"nezha"),oTt.forEach(t),LNo=r(PRe," \u2014 "),xV=n(PRe,"A",{href:!0});var rTt=s(xV);yNo=r(rTt,"NezhaForMaskedLM"),rTt.forEach(t),xNo=r(PRe," (Nezha model)"),PRe.forEach(t),$No=i(H),d2=n(H,"LI",{});var BRe=s(d2);Tpe=n(BRe,"STRONG",{});var tTt=s(Tpe);kNo=r(tTt,"nystromformer"),tTt.forEach(t),SNo=r(BRe," \u2014 "),$V=n(BRe,"A",{href:!0});var aTt=s($V);RNo=r(aTt,"NystromformerForMaskedLM"),aTt.forEach(t),PNo=r(BRe," (Nystr\xF6mformer model)"),BRe.forEach(t),BNo=i(H),c2=n(H,"LI",{});var IRe=s(c2);Mpe=n(IRe,"STRONG",{});var nTt=s(Mpe);INo=r(nTt,"perceiver"),nTt.forEach(t),NNo=r(IRe," \u2014 "),kV=n(IRe,"A",{href:!0});var sTt=s(kV);qNo=r(sTt,"PerceiverForMaskedLM"),sTt.forEach(t),jNo=r(IRe," (Perceiver model)"),IRe.forEach(t),DNo=i(H),f2=n(H,"LI",{});var NRe=s(f2);Epe=n(NRe,"STRONG",{});var lTt=s(Epe);GNo=r(lTt,"qdqbert"),lTt.forEach(t),ONo=r(NRe," \u2014 "),SV=n(NRe,"A",{href:!0});var iTt=s(SV);VNo=r(iTt,"QDQBertForMaskedLM"),iTt.forEach(t),XNo=r(NRe," (QDQBert model)"),NRe.forEach(t),zNo=i(H),m2=n(H,"LI",{});var qRe=s(m2);Cpe=n(qRe,"STRONG",{});var dTt=s(Cpe);QNo=r(dTt,"reformer"),dTt.forEach(t),WNo=r(qRe," \u2014 "),RV=n(qRe,"A",{href:!0});var cTt=s(RV);HNo=r(cTt,"ReformerForMaskedLM"),cTt.forEach(t),UNo=r(qRe," (Reformer model)"),qRe.forEach(t),JNo=i(H),g2=n(H,"LI",{});var jRe=s(g2);wpe=n(jRe,"STRONG",{});var fTt=s(wpe);YNo=r(fTt,"rembert"),fTt.forEach(t),KNo=r(jRe," \u2014 "),PV=n(jRe,"A",{href:!0});var mTt=s(PV);ZNo=r(mTt,"RemBertForMaskedLM"),mTt.forEach(t),eqo=r(jRe," (RemBERT model)"),jRe.forEach(t),oqo=i(H),h2=n(H,"LI",{});var DRe=s(h2);Ape=n(DRe,"STRONG",{});var gTt=s(Ape);rqo=r(gTt,"roberta"),gTt.forEach(t),tqo=r(DRe," \u2014 "),BV=n(DRe,"A",{href:!0});var hTt=s(BV);aqo=r(hTt,"RobertaForMaskedLM"),hTt.forEach(t),nqo=r(DRe," (RoBERTa model)"),DRe.forEach(t),sqo=i(H),p2=n(H,"LI",{});var GRe=s(p2);Lpe=n(GRe,"STRONG",{});var pTt=s(Lpe);lqo=r(pTt,"roformer"),pTt.forEach(t),iqo=r(GRe," \u2014 "),IV=n(GRe,"A",{href:!0});var _Tt=s(IV);dqo=r(_Tt,"RoFormerForMaskedLM"),_Tt.forEach(t),cqo=r(GRe," (RoFormer model)"),GRe.forEach(t),fqo=i(H),_2=n(H,"LI",{});var ORe=s(_2);ype=n(ORe,"STRONG",{});var uTt=s(ype);mqo=r(uTt,"squeezebert"),uTt.forEach(t),gqo=r(ORe," \u2014 "),NV=n(ORe,"A",{href:!0});var bTt=s(NV);hqo=r(bTt,"SqueezeBertForMaskedLM"),bTt.forEach(t),pqo=r(ORe," (SqueezeBERT model)"),ORe.forEach(t),_qo=i(H),u2=n(H,"LI",{});var VRe=s(u2);xpe=n(VRe,"STRONG",{});var vTt=s(xpe);uqo=r(vTt,"tapas"),vTt.forEach(t),bqo=r(VRe," \u2014 "),qV=n(VRe,"A",{href:!0});var FTt=s(qV);vqo=r(FTt,"TapasForMaskedLM"),FTt.forEach(t),Fqo=r(VRe," (TAPAS model)"),VRe.forEach(t),Tqo=i(H),b2=n(H,"LI",{});var XRe=s(b2);$pe=n(XRe,"STRONG",{});var TTt=s($pe);Mqo=r(TTt,"wav2vec2"),TTt.forEach(t),Eqo=r(XRe," \u2014 "),kpe=n(XRe,"CODE",{});var MTt=s(kpe);Cqo=r(MTt,"Wav2Vec2ForMaskedLM"),MTt.forEach(t),wqo=r(XRe," (Wav2Vec2 model)"),XRe.forEach(t),Aqo=i(H),v2=n(H,"LI",{});var zRe=s(v2);Spe=n(zRe,"STRONG",{});var ETt=s(Spe);Lqo=r(ETt,"xlm"),ETt.forEach(t),yqo=r(zRe," \u2014 "),jV=n(zRe,"A",{href:!0});var CTt=s(jV);xqo=r(CTt,"XLMWithLMHeadModel"),CTt.forEach(t),$qo=r(zRe," (XLM model)"),zRe.forEach(t),kqo=i(H),F2=n(H,"LI",{});var QRe=s(F2);Rpe=n(QRe,"STRONG",{});var wTt=s(Rpe);Sqo=r(wTt,"xlm-roberta"),wTt.forEach(t),Rqo=r(QRe," \u2014 "),DV=n(QRe,"A",{href:!0});var ATt=s(DV);Pqo=r(ATt,"XLMRobertaForMaskedLM"),ATt.forEach(t),Bqo=r(QRe," (XLM-RoBERTa model)"),QRe.forEach(t),Iqo=i(H),T2=n(H,"LI",{});var WRe=s(T2);Ppe=n(WRe,"STRONG",{});var LTt=s(Ppe);Nqo=r(LTt,"xlm-roberta-xl"),LTt.forEach(t),qqo=r(WRe," \u2014 "),GV=n(WRe,"A",{href:!0});var yTt=s(GV);jqo=r(yTt,"XLMRobertaXLForMaskedLM"),yTt.forEach(t),Dqo=r(WRe," (XLM-RoBERTa-XL model)"),WRe.forEach(t),Gqo=i(H),M2=n(H,"LI",{});var HRe=s(M2);Bpe=n(HRe,"STRONG",{});var xTt=s(Bpe);Oqo=r(xTt,"yoso"),xTt.forEach(t),Vqo=r(HRe," \u2014 "),OV=n(HRe,"A",{href:!0});var $Tt=s(OV);Xqo=r($Tt,"YosoForMaskedLM"),$Tt.forEach(t),zqo=r(HRe," (YOSO model)"),HRe.forEach(t),H.forEach(t),Qqo=i(ca),E2=n(ca,"P",{});var URe=s(E2);Wqo=r(URe,"The model is set in evaluation mode by default using "),Ipe=n(URe,"CODE",{});var kTt=s(Ipe);Hqo=r(kTt,"model.eval()"),kTt.forEach(t),Uqo=r(URe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Npe=n(URe,"CODE",{});var STt=s(Npe);Jqo=r(STt,"model.train()"),STt.forEach(t),URe.forEach(t),Yqo=i(ca),T(C2.$$.fragment,ca),ca.forEach(t),ll.forEach(t),dze=i(f),od=n(f,"H2",{class:!0});var pWe=s(od);w2=n(pWe,"A",{id:!0,class:!0,href:!0});var RTt=s(w2);qpe=n(RTt,"SPAN",{});var PTt=s(qpe);T(iy.$$.fragment,PTt),PTt.forEach(t),RTt.forEach(t),Kqo=i(pWe),jpe=n(pWe,"SPAN",{});var BTt=s(jpe);Zqo=r(BTt,"AutoModelForSeq2SeqLM"),BTt.forEach(t),pWe.forEach(t),cze=i(f),Bo=n(f,"DIV",{class:!0});var il=s(Bo);T(dy.$$.fragment,il),ejo=i(il),rd=n(il,"P",{});var fte=s(rd);ojo=r(fte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),VV=n(fte,"A",{href:!0});var ITt=s(VV);rjo=r(ITt,"from_pretrained()"),ITt.forEach(t),tjo=r(fte," class method or the "),XV=n(fte,"A",{href:!0});var NTt=s(XV);ajo=r(NTt,"from_config()"),NTt.forEach(t),njo=r(fte,` class
method.`),fte.forEach(t),sjo=i(il),cy=n(il,"P",{});var _We=s(cy);ljo=r(_We,"This class cannot be instantiated directly using "),Dpe=n(_We,"CODE",{});var qTt=s(Dpe);ijo=r(qTt,"__init__()"),qTt.forEach(t),djo=r(_We," (throws an error)."),_We.forEach(t),cjo=i(il),mt=n(il,"DIV",{class:!0});var Lw=s(mt);T(fy.$$.fragment,Lw),fjo=i(Lw),Gpe=n(Lw,"P",{});var jTt=s(Gpe);mjo=r(jTt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),jTt.forEach(t),gjo=i(Lw),td=n(Lw,"P",{});var mte=s(td);hjo=r(mte,`Note:
Loading a model from its configuration file does `),Ope=n(mte,"STRONG",{});var DTt=s(Ope);pjo=r(DTt,"not"),DTt.forEach(t),_jo=r(mte,` load the model weights. It only affects the
model\u2019s configuration. Use `),zV=n(mte,"A",{href:!0});var GTt=s(zV);ujo=r(GTt,"from_pretrained()"),GTt.forEach(t),bjo=r(mte," to load the model weights."),mte.forEach(t),vjo=i(Lw),T(A2.$$.fragment,Lw),Lw.forEach(t),Fjo=i(il),oo=n(il,"DIV",{class:!0});var fa=s(oo);T(my.$$.fragment,fa),Tjo=i(fa),Vpe=n(fa,"P",{});var OTt=s(Vpe);Mjo=r(OTt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),OTt.forEach(t),Ejo=i(fa),Da=n(fa,"P",{});var yw=s(Da);Cjo=r(yw,"The model class to instantiate is selected based on the "),Xpe=n(yw,"CODE",{});var VTt=s(Xpe);wjo=r(VTt,"model_type"),VTt.forEach(t),Ajo=r(yw,` property of the config object (either
passed as an argument or loaded from `),zpe=n(yw,"CODE",{});var XTt=s(zpe);Ljo=r(XTt,"pretrained_model_name_or_path"),XTt.forEach(t),yjo=r(yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qpe=n(yw,"CODE",{});var zTt=s(Qpe);xjo=r(zTt,"pretrained_model_name_or_path"),zTt.forEach(t),$jo=r(yw,":"),yw.forEach(t),kjo=i(fa),fe=n(fa,"UL",{});var _e=s(fe);L2=n(_e,"LI",{});var JRe=s(L2);Wpe=n(JRe,"STRONG",{});var QTt=s(Wpe);Sjo=r(QTt,"bart"),QTt.forEach(t),Rjo=r(JRe," \u2014 "),QV=n(JRe,"A",{href:!0});var WTt=s(QV);Pjo=r(WTt,"BartForConditionalGeneration"),WTt.forEach(t),Bjo=r(JRe," (BART model)"),JRe.forEach(t),Ijo=i(_e),y2=n(_e,"LI",{});var YRe=s(y2);Hpe=n(YRe,"STRONG",{});var HTt=s(Hpe);Njo=r(HTt,"bigbird_pegasus"),HTt.forEach(t),qjo=r(YRe," \u2014 "),WV=n(YRe,"A",{href:!0});var UTt=s(WV);jjo=r(UTt,"BigBirdPegasusForConditionalGeneration"),UTt.forEach(t),Djo=r(YRe," (BigBird-Pegasus model)"),YRe.forEach(t),Gjo=i(_e),x2=n(_e,"LI",{});var KRe=s(x2);Upe=n(KRe,"STRONG",{});var JTt=s(Upe);Ojo=r(JTt,"blenderbot"),JTt.forEach(t),Vjo=r(KRe," \u2014 "),HV=n(KRe,"A",{href:!0});var YTt=s(HV);Xjo=r(YTt,"BlenderbotForConditionalGeneration"),YTt.forEach(t),zjo=r(KRe," (Blenderbot model)"),KRe.forEach(t),Qjo=i(_e),$2=n(_e,"LI",{});var ZRe=s($2);Jpe=n(ZRe,"STRONG",{});var KTt=s(Jpe);Wjo=r(KTt,"blenderbot-small"),KTt.forEach(t),Hjo=r(ZRe," \u2014 "),UV=n(ZRe,"A",{href:!0});var ZTt=s(UV);Ujo=r(ZTt,"BlenderbotSmallForConditionalGeneration"),ZTt.forEach(t),Jjo=r(ZRe," (BlenderbotSmall model)"),ZRe.forEach(t),Yjo=i(_e),k2=n(_e,"LI",{});var ePe=s(k2);Ype=n(ePe,"STRONG",{});var e7t=s(Ype);Kjo=r(e7t,"encoder-decoder"),e7t.forEach(t),Zjo=r(ePe," \u2014 "),JV=n(ePe,"A",{href:!0});var o7t=s(JV);eDo=r(o7t,"EncoderDecoderModel"),o7t.forEach(t),oDo=r(ePe," (Encoder decoder model)"),ePe.forEach(t),rDo=i(_e),S2=n(_e,"LI",{});var oPe=s(S2);Kpe=n(oPe,"STRONG",{});var r7t=s(Kpe);tDo=r(r7t,"fsmt"),r7t.forEach(t),aDo=r(oPe," \u2014 "),YV=n(oPe,"A",{href:!0});var t7t=s(YV);nDo=r(t7t,"FSMTForConditionalGeneration"),t7t.forEach(t),sDo=r(oPe," (FairSeq Machine-Translation model)"),oPe.forEach(t),lDo=i(_e),R2=n(_e,"LI",{});var rPe=s(R2);Zpe=n(rPe,"STRONG",{});var a7t=s(Zpe);iDo=r(a7t,"led"),a7t.forEach(t),dDo=r(rPe," \u2014 "),KV=n(rPe,"A",{href:!0});var n7t=s(KV);cDo=r(n7t,"LEDForConditionalGeneration"),n7t.forEach(t),fDo=r(rPe," (LED model)"),rPe.forEach(t),mDo=i(_e),P2=n(_e,"LI",{});var tPe=s(P2);e_e=n(tPe,"STRONG",{});var s7t=s(e_e);gDo=r(s7t,"longt5"),s7t.forEach(t),hDo=r(tPe," \u2014 "),ZV=n(tPe,"A",{href:!0});var l7t=s(ZV);pDo=r(l7t,"LongT5ForConditionalGeneration"),l7t.forEach(t),_Do=r(tPe," (LongT5 model)"),tPe.forEach(t),uDo=i(_e),B2=n(_e,"LI",{});var aPe=s(B2);o_e=n(aPe,"STRONG",{});var i7t=s(o_e);bDo=r(i7t,"m2m_100"),i7t.forEach(t),vDo=r(aPe," \u2014 "),eX=n(aPe,"A",{href:!0});var d7t=s(eX);FDo=r(d7t,"M2M100ForConditionalGeneration"),d7t.forEach(t),TDo=r(aPe," (M2M100 model)"),aPe.forEach(t),MDo=i(_e),I2=n(_e,"LI",{});var nPe=s(I2);r_e=n(nPe,"STRONG",{});var c7t=s(r_e);EDo=r(c7t,"marian"),c7t.forEach(t),CDo=r(nPe," \u2014 "),oX=n(nPe,"A",{href:!0});var f7t=s(oX);wDo=r(f7t,"MarianMTModel"),f7t.forEach(t),ADo=r(nPe," (Marian model)"),nPe.forEach(t),LDo=i(_e),N2=n(_e,"LI",{});var sPe=s(N2);t_e=n(sPe,"STRONG",{});var m7t=s(t_e);yDo=r(m7t,"mbart"),m7t.forEach(t),xDo=r(sPe," \u2014 "),rX=n(sPe,"A",{href:!0});var g7t=s(rX);$Do=r(g7t,"MBartForConditionalGeneration"),g7t.forEach(t),kDo=r(sPe," (mBART model)"),sPe.forEach(t),SDo=i(_e),q2=n(_e,"LI",{});var lPe=s(q2);a_e=n(lPe,"STRONG",{});var h7t=s(a_e);RDo=r(h7t,"mt5"),h7t.forEach(t),PDo=r(lPe," \u2014 "),tX=n(lPe,"A",{href:!0});var p7t=s(tX);BDo=r(p7t,"MT5ForConditionalGeneration"),p7t.forEach(t),IDo=r(lPe," (MT5 model)"),lPe.forEach(t),NDo=i(_e),j2=n(_e,"LI",{});var iPe=s(j2);n_e=n(iPe,"STRONG",{});var _7t=s(n_e);qDo=r(_7t,"mvp"),_7t.forEach(t),jDo=r(iPe," \u2014 "),aX=n(iPe,"A",{href:!0});var u7t=s(aX);DDo=r(u7t,"MvpForConditionalGeneration"),u7t.forEach(t),GDo=r(iPe," (MVP model)"),iPe.forEach(t),ODo=i(_e),D2=n(_e,"LI",{});var dPe=s(D2);s_e=n(dPe,"STRONG",{});var b7t=s(s_e);VDo=r(b7t,"nllb"),b7t.forEach(t),XDo=r(dPe," \u2014 "),nX=n(dPe,"A",{href:!0});var v7t=s(nX);zDo=r(v7t,"M2M100ForConditionalGeneration"),v7t.forEach(t),QDo=r(dPe," (NLLB model)"),dPe.forEach(t),WDo=i(_e),G2=n(_e,"LI",{});var cPe=s(G2);l_e=n(cPe,"STRONG",{});var F7t=s(l_e);HDo=r(F7t,"pegasus"),F7t.forEach(t),UDo=r(cPe," \u2014 "),sX=n(cPe,"A",{href:!0});var T7t=s(sX);JDo=r(T7t,"PegasusForConditionalGeneration"),T7t.forEach(t),YDo=r(cPe," (Pegasus model)"),cPe.forEach(t),KDo=i(_e),O2=n(_e,"LI",{});var fPe=s(O2);i_e=n(fPe,"STRONG",{});var M7t=s(i_e);ZDo=r(M7t,"plbart"),M7t.forEach(t),eGo=r(fPe," \u2014 "),lX=n(fPe,"A",{href:!0});var E7t=s(lX);oGo=r(E7t,"PLBartForConditionalGeneration"),E7t.forEach(t),rGo=r(fPe," (PLBart model)"),fPe.forEach(t),tGo=i(_e),V2=n(_e,"LI",{});var mPe=s(V2);d_e=n(mPe,"STRONG",{});var C7t=s(d_e);aGo=r(C7t,"prophetnet"),C7t.forEach(t),nGo=r(mPe," \u2014 "),iX=n(mPe,"A",{href:!0});var w7t=s(iX);sGo=r(w7t,"ProphetNetForConditionalGeneration"),w7t.forEach(t),lGo=r(mPe," (ProphetNet model)"),mPe.forEach(t),iGo=i(_e),X2=n(_e,"LI",{});var gPe=s(X2);c_e=n(gPe,"STRONG",{});var A7t=s(c_e);dGo=r(A7t,"t5"),A7t.forEach(t),cGo=r(gPe," \u2014 "),dX=n(gPe,"A",{href:!0});var L7t=s(dX);fGo=r(L7t,"T5ForConditionalGeneration"),L7t.forEach(t),mGo=r(gPe," (T5 model)"),gPe.forEach(t),gGo=i(_e),z2=n(_e,"LI",{});var hPe=s(z2);f_e=n(hPe,"STRONG",{});var y7t=s(f_e);hGo=r(y7t,"xlm-prophetnet"),y7t.forEach(t),pGo=r(hPe," \u2014 "),cX=n(hPe,"A",{href:!0});var x7t=s(cX);_Go=r(x7t,"XLMProphetNetForConditionalGeneration"),x7t.forEach(t),uGo=r(hPe," (XLM-ProphetNet model)"),hPe.forEach(t),_e.forEach(t),bGo=i(fa),Q2=n(fa,"P",{});var pPe=s(Q2);vGo=r(pPe,"The model is set in evaluation mode by default using "),m_e=n(pPe,"CODE",{});var $7t=s(m_e);FGo=r($7t,"model.eval()"),$7t.forEach(t),TGo=r(pPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g_e=n(pPe,"CODE",{});var k7t=s(g_e);MGo=r(k7t,"model.train()"),k7t.forEach(t),pPe.forEach(t),EGo=i(fa),T(W2.$$.fragment,fa),fa.forEach(t),il.forEach(t),fze=i(f),ad=n(f,"H2",{class:!0});var uWe=s(ad);H2=n(uWe,"A",{id:!0,class:!0,href:!0});var S7t=s(H2);h_e=n(S7t,"SPAN",{});var R7t=s(h_e);T(gy.$$.fragment,R7t),R7t.forEach(t),S7t.forEach(t),CGo=i(uWe),p_e=n(uWe,"SPAN",{});var P7t=s(p_e);wGo=r(P7t,"AutoModelForSequenceClassification"),P7t.forEach(t),uWe.forEach(t),mze=i(f),Io=n(f,"DIV",{class:!0});var dl=s(Io);T(hy.$$.fragment,dl),AGo=i(dl),nd=n(dl,"P",{});var gte=s(nd);LGo=r(gte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fX=n(gte,"A",{href:!0});var B7t=s(fX);yGo=r(B7t,"from_pretrained()"),B7t.forEach(t),xGo=r(gte," class method or the "),mX=n(gte,"A",{href:!0});var I7t=s(mX);$Go=r(I7t,"from_config()"),I7t.forEach(t),kGo=r(gte,` class
method.`),gte.forEach(t),SGo=i(dl),py=n(dl,"P",{});var bWe=s(py);RGo=r(bWe,"This class cannot be instantiated directly using "),__e=n(bWe,"CODE",{});var N7t=s(__e);PGo=r(N7t,"__init__()"),N7t.forEach(t),BGo=r(bWe," (throws an error)."),bWe.forEach(t),IGo=i(dl),gt=n(dl,"DIV",{class:!0});var xw=s(gt);T(_y.$$.fragment,xw),NGo=i(xw),u_e=n(xw,"P",{});var q7t=s(u_e);qGo=r(q7t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),q7t.forEach(t),jGo=i(xw),sd=n(xw,"P",{});var hte=s(sd);DGo=r(hte,`Note:
Loading a model from its configuration file does `),b_e=n(hte,"STRONG",{});var j7t=s(b_e);GGo=r(j7t,"not"),j7t.forEach(t),OGo=r(hte,` load the model weights. It only affects the
model\u2019s configuration. Use `),gX=n(hte,"A",{href:!0});var D7t=s(gX);VGo=r(D7t,"from_pretrained()"),D7t.forEach(t),XGo=r(hte," to load the model weights."),hte.forEach(t),zGo=i(xw),T(U2.$$.fragment,xw),xw.forEach(t),QGo=i(dl),ro=n(dl,"DIV",{class:!0});var ma=s(ro);T(uy.$$.fragment,ma),WGo=i(ma),v_e=n(ma,"P",{});var G7t=s(v_e);HGo=r(G7t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),G7t.forEach(t),UGo=i(ma),Ga=n(ma,"P",{});var $w=s(Ga);JGo=r($w,"The model class to instantiate is selected based on the "),F_e=n($w,"CODE",{});var O7t=s(F_e);YGo=r(O7t,"model_type"),O7t.forEach(t),KGo=r($w,` property of the config object (either
passed as an argument or loaded from `),T_e=n($w,"CODE",{});var V7t=s(T_e);ZGo=r(V7t,"pretrained_model_name_or_path"),V7t.forEach(t),eOo=r($w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M_e=n($w,"CODE",{});var X7t=s(M_e);oOo=r(X7t,"pretrained_model_name_or_path"),X7t.forEach(t),rOo=r($w,":"),$w.forEach(t),tOo=i(ma),B=n(ma,"UL",{});var j=s(B);J2=n(j,"LI",{});var _Pe=s(J2);E_e=n(_Pe,"STRONG",{});var z7t=s(E_e);aOo=r(z7t,"albert"),z7t.forEach(t),nOo=r(_Pe," \u2014 "),hX=n(_Pe,"A",{href:!0});var Q7t=s(hX);sOo=r(Q7t,"AlbertForSequenceClassification"),Q7t.forEach(t),lOo=r(_Pe," (ALBERT model)"),_Pe.forEach(t),iOo=i(j),Y2=n(j,"LI",{});var uPe=s(Y2);C_e=n(uPe,"STRONG",{});var W7t=s(C_e);dOo=r(W7t,"bart"),W7t.forEach(t),cOo=r(uPe," \u2014 "),pX=n(uPe,"A",{href:!0});var H7t=s(pX);fOo=r(H7t,"BartForSequenceClassification"),H7t.forEach(t),mOo=r(uPe," (BART model)"),uPe.forEach(t),gOo=i(j),K2=n(j,"LI",{});var bPe=s(K2);w_e=n(bPe,"STRONG",{});var U7t=s(w_e);hOo=r(U7t,"bert"),U7t.forEach(t),pOo=r(bPe," \u2014 "),_X=n(bPe,"A",{href:!0});var J7t=s(_X);_Oo=r(J7t,"BertForSequenceClassification"),J7t.forEach(t),uOo=r(bPe," (BERT model)"),bPe.forEach(t),bOo=i(j),Z2=n(j,"LI",{});var vPe=s(Z2);A_e=n(vPe,"STRONG",{});var Y7t=s(A_e);vOo=r(Y7t,"big_bird"),Y7t.forEach(t),FOo=r(vPe," \u2014 "),uX=n(vPe,"A",{href:!0});var K7t=s(uX);TOo=r(K7t,"BigBirdForSequenceClassification"),K7t.forEach(t),MOo=r(vPe," (BigBird model)"),vPe.forEach(t),EOo=i(j),eb=n(j,"LI",{});var FPe=s(eb);L_e=n(FPe,"STRONG",{});var Z7t=s(L_e);COo=r(Z7t,"bigbird_pegasus"),Z7t.forEach(t),wOo=r(FPe," \u2014 "),bX=n(FPe,"A",{href:!0});var e9t=s(bX);AOo=r(e9t,"BigBirdPegasusForSequenceClassification"),e9t.forEach(t),LOo=r(FPe," (BigBird-Pegasus model)"),FPe.forEach(t),yOo=i(j),ob=n(j,"LI",{});var TPe=s(ob);y_e=n(TPe,"STRONG",{});var o9t=s(y_e);xOo=r(o9t,"bloom"),o9t.forEach(t),$Oo=r(TPe," \u2014 "),vX=n(TPe,"A",{href:!0});var r9t=s(vX);kOo=r(r9t,"BloomForSequenceClassification"),r9t.forEach(t),SOo=r(TPe," (BLOOM model)"),TPe.forEach(t),ROo=i(j),rb=n(j,"LI",{});var MPe=s(rb);x_e=n(MPe,"STRONG",{});var t9t=s(x_e);POo=r(t9t,"camembert"),t9t.forEach(t),BOo=r(MPe," \u2014 "),FX=n(MPe,"A",{href:!0});var a9t=s(FX);IOo=r(a9t,"CamembertForSequenceClassification"),a9t.forEach(t),NOo=r(MPe," (CamemBERT model)"),MPe.forEach(t),qOo=i(j),tb=n(j,"LI",{});var EPe=s(tb);$_e=n(EPe,"STRONG",{});var n9t=s($_e);jOo=r(n9t,"canine"),n9t.forEach(t),DOo=r(EPe," \u2014 "),TX=n(EPe,"A",{href:!0});var s9t=s(TX);GOo=r(s9t,"CanineForSequenceClassification"),s9t.forEach(t),OOo=r(EPe," (CANINE model)"),EPe.forEach(t),VOo=i(j),ab=n(j,"LI",{});var CPe=s(ab);k_e=n(CPe,"STRONG",{});var l9t=s(k_e);XOo=r(l9t,"convbert"),l9t.forEach(t),zOo=r(CPe," \u2014 "),MX=n(CPe,"A",{href:!0});var i9t=s(MX);QOo=r(i9t,"ConvBertForSequenceClassification"),i9t.forEach(t),WOo=r(CPe," (ConvBERT model)"),CPe.forEach(t),HOo=i(j),nb=n(j,"LI",{});var wPe=s(nb);S_e=n(wPe,"STRONG",{});var d9t=s(S_e);UOo=r(d9t,"ctrl"),d9t.forEach(t),JOo=r(wPe," \u2014 "),EX=n(wPe,"A",{href:!0});var c9t=s(EX);YOo=r(c9t,"CTRLForSequenceClassification"),c9t.forEach(t),KOo=r(wPe," (CTRL model)"),wPe.forEach(t),ZOo=i(j),sb=n(j,"LI",{});var APe=s(sb);R_e=n(APe,"STRONG",{});var f9t=s(R_e);eVo=r(f9t,"data2vec-text"),f9t.forEach(t),oVo=r(APe," \u2014 "),CX=n(APe,"A",{href:!0});var m9t=s(CX);rVo=r(m9t,"Data2VecTextForSequenceClassification"),m9t.forEach(t),tVo=r(APe," (Data2VecText model)"),APe.forEach(t),aVo=i(j),lb=n(j,"LI",{});var LPe=s(lb);P_e=n(LPe,"STRONG",{});var g9t=s(P_e);nVo=r(g9t,"deberta"),g9t.forEach(t),sVo=r(LPe," \u2014 "),wX=n(LPe,"A",{href:!0});var h9t=s(wX);lVo=r(h9t,"DebertaForSequenceClassification"),h9t.forEach(t),iVo=r(LPe," (DeBERTa model)"),LPe.forEach(t),dVo=i(j),ib=n(j,"LI",{});var yPe=s(ib);B_e=n(yPe,"STRONG",{});var p9t=s(B_e);cVo=r(p9t,"deberta-v2"),p9t.forEach(t),fVo=r(yPe," \u2014 "),AX=n(yPe,"A",{href:!0});var _9t=s(AX);mVo=r(_9t,"DebertaV2ForSequenceClassification"),_9t.forEach(t),gVo=r(yPe," (DeBERTa-v2 model)"),yPe.forEach(t),hVo=i(j),db=n(j,"LI",{});var xPe=s(db);I_e=n(xPe,"STRONG",{});var u9t=s(I_e);pVo=r(u9t,"distilbert"),u9t.forEach(t),_Vo=r(xPe," \u2014 "),LX=n(xPe,"A",{href:!0});var b9t=s(LX);uVo=r(b9t,"DistilBertForSequenceClassification"),b9t.forEach(t),bVo=r(xPe," (DistilBERT model)"),xPe.forEach(t),vVo=i(j),cb=n(j,"LI",{});var $Pe=s(cb);N_e=n($Pe,"STRONG",{});var v9t=s(N_e);FVo=r(v9t,"electra"),v9t.forEach(t),TVo=r($Pe," \u2014 "),yX=n($Pe,"A",{href:!0});var F9t=s(yX);MVo=r(F9t,"ElectraForSequenceClassification"),F9t.forEach(t),EVo=r($Pe," (ELECTRA model)"),$Pe.forEach(t),CVo=i(j),fb=n(j,"LI",{});var kPe=s(fb);q_e=n(kPe,"STRONG",{});var T9t=s(q_e);wVo=r(T9t,"flaubert"),T9t.forEach(t),AVo=r(kPe," \u2014 "),xX=n(kPe,"A",{href:!0});var M9t=s(xX);LVo=r(M9t,"FlaubertForSequenceClassification"),M9t.forEach(t),yVo=r(kPe," (FlauBERT model)"),kPe.forEach(t),xVo=i(j),mb=n(j,"LI",{});var SPe=s(mb);j_e=n(SPe,"STRONG",{});var E9t=s(j_e);$Vo=r(E9t,"fnet"),E9t.forEach(t),kVo=r(SPe," \u2014 "),$X=n(SPe,"A",{href:!0});var C9t=s($X);SVo=r(C9t,"FNetForSequenceClassification"),C9t.forEach(t),RVo=r(SPe," (FNet model)"),SPe.forEach(t),PVo=i(j),gb=n(j,"LI",{});var RPe=s(gb);D_e=n(RPe,"STRONG",{});var w9t=s(D_e);BVo=r(w9t,"funnel"),w9t.forEach(t),IVo=r(RPe," \u2014 "),kX=n(RPe,"A",{href:!0});var A9t=s(kX);NVo=r(A9t,"FunnelForSequenceClassification"),A9t.forEach(t),qVo=r(RPe," (Funnel Transformer model)"),RPe.forEach(t),jVo=i(j),hb=n(j,"LI",{});var PPe=s(hb);G_e=n(PPe,"STRONG",{});var L9t=s(G_e);DVo=r(L9t,"gpt2"),L9t.forEach(t),GVo=r(PPe," \u2014 "),SX=n(PPe,"A",{href:!0});var y9t=s(SX);OVo=r(y9t,"GPT2ForSequenceClassification"),y9t.forEach(t),VVo=r(PPe," (OpenAI GPT-2 model)"),PPe.forEach(t),XVo=i(j),pb=n(j,"LI",{});var BPe=s(pb);O_e=n(BPe,"STRONG",{});var x9t=s(O_e);zVo=r(x9t,"gpt_neo"),x9t.forEach(t),QVo=r(BPe," \u2014 "),RX=n(BPe,"A",{href:!0});var $9t=s(RX);WVo=r($9t,"GPTNeoForSequenceClassification"),$9t.forEach(t),HVo=r(BPe," (GPT Neo model)"),BPe.forEach(t),UVo=i(j),_b=n(j,"LI",{});var IPe=s(_b);V_e=n(IPe,"STRONG",{});var k9t=s(V_e);JVo=r(k9t,"gptj"),k9t.forEach(t),YVo=r(IPe," \u2014 "),PX=n(IPe,"A",{href:!0});var S9t=s(PX);KVo=r(S9t,"GPTJForSequenceClassification"),S9t.forEach(t),ZVo=r(IPe," (GPT-J model)"),IPe.forEach(t),eXo=i(j),ub=n(j,"LI",{});var NPe=s(ub);X_e=n(NPe,"STRONG",{});var R9t=s(X_e);oXo=r(R9t,"ibert"),R9t.forEach(t),rXo=r(NPe," \u2014 "),BX=n(NPe,"A",{href:!0});var P9t=s(BX);tXo=r(P9t,"IBertForSequenceClassification"),P9t.forEach(t),aXo=r(NPe," (I-BERT model)"),NPe.forEach(t),nXo=i(j),bb=n(j,"LI",{});var qPe=s(bb);z_e=n(qPe,"STRONG",{});var B9t=s(z_e);sXo=r(B9t,"layoutlm"),B9t.forEach(t),lXo=r(qPe," \u2014 "),IX=n(qPe,"A",{href:!0});var I9t=s(IX);iXo=r(I9t,"LayoutLMForSequenceClassification"),I9t.forEach(t),dXo=r(qPe," (LayoutLM model)"),qPe.forEach(t),cXo=i(j),vb=n(j,"LI",{});var jPe=s(vb);Q_e=n(jPe,"STRONG",{});var N9t=s(Q_e);fXo=r(N9t,"layoutlmv2"),N9t.forEach(t),mXo=r(jPe," \u2014 "),NX=n(jPe,"A",{href:!0});var q9t=s(NX);gXo=r(q9t,"LayoutLMv2ForSequenceClassification"),q9t.forEach(t),hXo=r(jPe," (LayoutLMv2 model)"),jPe.forEach(t),pXo=i(j),Fb=n(j,"LI",{});var DPe=s(Fb);W_e=n(DPe,"STRONG",{});var j9t=s(W_e);_Xo=r(j9t,"layoutlmv3"),j9t.forEach(t),uXo=r(DPe," \u2014 "),qX=n(DPe,"A",{href:!0});var D9t=s(qX);bXo=r(D9t,"LayoutLMv3ForSequenceClassification"),D9t.forEach(t),vXo=r(DPe," (LayoutLMv3 model)"),DPe.forEach(t),FXo=i(j),Tb=n(j,"LI",{});var GPe=s(Tb);H_e=n(GPe,"STRONG",{});var G9t=s(H_e);TXo=r(G9t,"led"),G9t.forEach(t),MXo=r(GPe," \u2014 "),jX=n(GPe,"A",{href:!0});var O9t=s(jX);EXo=r(O9t,"LEDForSequenceClassification"),O9t.forEach(t),CXo=r(GPe," (LED model)"),GPe.forEach(t),wXo=i(j),Mb=n(j,"LI",{});var OPe=s(Mb);U_e=n(OPe,"STRONG",{});var V9t=s(U_e);AXo=r(V9t,"longformer"),V9t.forEach(t),LXo=r(OPe," \u2014 "),DX=n(OPe,"A",{href:!0});var X9t=s(DX);yXo=r(X9t,"LongformerForSequenceClassification"),X9t.forEach(t),xXo=r(OPe," (Longformer model)"),OPe.forEach(t),$Xo=i(j),Eb=n(j,"LI",{});var VPe=s(Eb);J_e=n(VPe,"STRONG",{});var z9t=s(J_e);kXo=r(z9t,"mbart"),z9t.forEach(t),SXo=r(VPe," \u2014 "),GX=n(VPe,"A",{href:!0});var Q9t=s(GX);RXo=r(Q9t,"MBartForSequenceClassification"),Q9t.forEach(t),PXo=r(VPe," (mBART model)"),VPe.forEach(t),BXo=i(j),Cb=n(j,"LI",{});var XPe=s(Cb);Y_e=n(XPe,"STRONG",{});var W9t=s(Y_e);IXo=r(W9t,"megatron-bert"),W9t.forEach(t),NXo=r(XPe," \u2014 "),OX=n(XPe,"A",{href:!0});var H9t=s(OX);qXo=r(H9t,"MegatronBertForSequenceClassification"),H9t.forEach(t),jXo=r(XPe," (Megatron-BERT model)"),XPe.forEach(t),DXo=i(j),wb=n(j,"LI",{});var zPe=s(wb);K_e=n(zPe,"STRONG",{});var U9t=s(K_e);GXo=r(U9t,"mobilebert"),U9t.forEach(t),OXo=r(zPe," \u2014 "),VX=n(zPe,"A",{href:!0});var J9t=s(VX);VXo=r(J9t,"MobileBertForSequenceClassification"),J9t.forEach(t),XXo=r(zPe," (MobileBERT model)"),zPe.forEach(t),zXo=i(j),Ab=n(j,"LI",{});var QPe=s(Ab);Z_e=n(QPe,"STRONG",{});var Y9t=s(Z_e);QXo=r(Y9t,"mpnet"),Y9t.forEach(t),WXo=r(QPe," \u2014 "),XX=n(QPe,"A",{href:!0});var K9t=s(XX);HXo=r(K9t,"MPNetForSequenceClassification"),K9t.forEach(t),UXo=r(QPe," (MPNet model)"),QPe.forEach(t),JXo=i(j),Lb=n(j,"LI",{});var WPe=s(Lb);eue=n(WPe,"STRONG",{});var Z9t=s(eue);YXo=r(Z9t,"mvp"),Z9t.forEach(t),KXo=r(WPe," \u2014 "),zX=n(WPe,"A",{href:!0});var eMt=s(zX);ZXo=r(eMt,"MvpForSequenceClassification"),eMt.forEach(t),ezo=r(WPe," (MVP model)"),WPe.forEach(t),ozo=i(j),yb=n(j,"LI",{});var HPe=s(yb);oue=n(HPe,"STRONG",{});var oMt=s(oue);rzo=r(oMt,"nezha"),oMt.forEach(t),tzo=r(HPe," \u2014 "),QX=n(HPe,"A",{href:!0});var rMt=s(QX);azo=r(rMt,"NezhaForSequenceClassification"),rMt.forEach(t),nzo=r(HPe," (Nezha model)"),HPe.forEach(t),szo=i(j),xb=n(j,"LI",{});var UPe=s(xb);rue=n(UPe,"STRONG",{});var tMt=s(rue);lzo=r(tMt,"nystromformer"),tMt.forEach(t),izo=r(UPe," \u2014 "),WX=n(UPe,"A",{href:!0});var aMt=s(WX);dzo=r(aMt,"NystromformerForSequenceClassification"),aMt.forEach(t),czo=r(UPe," (Nystr\xF6mformer model)"),UPe.forEach(t),fzo=i(j),$b=n(j,"LI",{});var JPe=s($b);tue=n(JPe,"STRONG",{});var nMt=s(tue);mzo=r(nMt,"openai-gpt"),nMt.forEach(t),gzo=r(JPe," \u2014 "),HX=n(JPe,"A",{href:!0});var sMt=s(HX);hzo=r(sMt,"OpenAIGPTForSequenceClassification"),sMt.forEach(t),pzo=r(JPe," (OpenAI GPT model)"),JPe.forEach(t),_zo=i(j),kb=n(j,"LI",{});var YPe=s(kb);aue=n(YPe,"STRONG",{});var lMt=s(aue);uzo=r(lMt,"opt"),lMt.forEach(t),bzo=r(YPe," \u2014 "),UX=n(YPe,"A",{href:!0});var iMt=s(UX);vzo=r(iMt,"OPTForSequenceClassification"),iMt.forEach(t),Fzo=r(YPe," (OPT model)"),YPe.forEach(t),Tzo=i(j),Sb=n(j,"LI",{});var KPe=s(Sb);nue=n(KPe,"STRONG",{});var dMt=s(nue);Mzo=r(dMt,"perceiver"),dMt.forEach(t),Ezo=r(KPe," \u2014 "),JX=n(KPe,"A",{href:!0});var cMt=s(JX);Czo=r(cMt,"PerceiverForSequenceClassification"),cMt.forEach(t),wzo=r(KPe," (Perceiver model)"),KPe.forEach(t),Azo=i(j),Rb=n(j,"LI",{});var ZPe=s(Rb);sue=n(ZPe,"STRONG",{});var fMt=s(sue);Lzo=r(fMt,"plbart"),fMt.forEach(t),yzo=r(ZPe," \u2014 "),YX=n(ZPe,"A",{href:!0});var mMt=s(YX);xzo=r(mMt,"PLBartForSequenceClassification"),mMt.forEach(t),$zo=r(ZPe," (PLBart model)"),ZPe.forEach(t),kzo=i(j),Pb=n(j,"LI",{});var eBe=s(Pb);lue=n(eBe,"STRONG",{});var gMt=s(lue);Szo=r(gMt,"qdqbert"),gMt.forEach(t),Rzo=r(eBe," \u2014 "),KX=n(eBe,"A",{href:!0});var hMt=s(KX);Pzo=r(hMt,"QDQBertForSequenceClassification"),hMt.forEach(t),Bzo=r(eBe," (QDQBert model)"),eBe.forEach(t),Izo=i(j),Bb=n(j,"LI",{});var oBe=s(Bb);iue=n(oBe,"STRONG",{});var pMt=s(iue);Nzo=r(pMt,"reformer"),pMt.forEach(t),qzo=r(oBe," \u2014 "),ZX=n(oBe,"A",{href:!0});var _Mt=s(ZX);jzo=r(_Mt,"ReformerForSequenceClassification"),_Mt.forEach(t),Dzo=r(oBe," (Reformer model)"),oBe.forEach(t),Gzo=i(j),Ib=n(j,"LI",{});var rBe=s(Ib);due=n(rBe,"STRONG",{});var uMt=s(due);Ozo=r(uMt,"rembert"),uMt.forEach(t),Vzo=r(rBe," \u2014 "),ez=n(rBe,"A",{href:!0});var bMt=s(ez);Xzo=r(bMt,"RemBertForSequenceClassification"),bMt.forEach(t),zzo=r(rBe," (RemBERT model)"),rBe.forEach(t),Qzo=i(j),Nb=n(j,"LI",{});var tBe=s(Nb);cue=n(tBe,"STRONG",{});var vMt=s(cue);Wzo=r(vMt,"roberta"),vMt.forEach(t),Hzo=r(tBe," \u2014 "),oz=n(tBe,"A",{href:!0});var FMt=s(oz);Uzo=r(FMt,"RobertaForSequenceClassification"),FMt.forEach(t),Jzo=r(tBe," (RoBERTa model)"),tBe.forEach(t),Yzo=i(j),qb=n(j,"LI",{});var aBe=s(qb);fue=n(aBe,"STRONG",{});var TMt=s(fue);Kzo=r(TMt,"roformer"),TMt.forEach(t),Zzo=r(aBe," \u2014 "),rz=n(aBe,"A",{href:!0});var MMt=s(rz);eQo=r(MMt,"RoFormerForSequenceClassification"),MMt.forEach(t),oQo=r(aBe," (RoFormer model)"),aBe.forEach(t),rQo=i(j),jb=n(j,"LI",{});var nBe=s(jb);mue=n(nBe,"STRONG",{});var EMt=s(mue);tQo=r(EMt,"squeezebert"),EMt.forEach(t),aQo=r(nBe," \u2014 "),tz=n(nBe,"A",{href:!0});var CMt=s(tz);nQo=r(CMt,"SqueezeBertForSequenceClassification"),CMt.forEach(t),sQo=r(nBe," (SqueezeBERT model)"),nBe.forEach(t),lQo=i(j),Db=n(j,"LI",{});var sBe=s(Db);gue=n(sBe,"STRONG",{});var wMt=s(gue);iQo=r(wMt,"tapas"),wMt.forEach(t),dQo=r(sBe," \u2014 "),az=n(sBe,"A",{href:!0});var AMt=s(az);cQo=r(AMt,"TapasForSequenceClassification"),AMt.forEach(t),fQo=r(sBe," (TAPAS model)"),sBe.forEach(t),mQo=i(j),Gb=n(j,"LI",{});var lBe=s(Gb);hue=n(lBe,"STRONG",{});var LMt=s(hue);gQo=r(LMt,"transfo-xl"),LMt.forEach(t),hQo=r(lBe," \u2014 "),nz=n(lBe,"A",{href:!0});var yMt=s(nz);pQo=r(yMt,"TransfoXLForSequenceClassification"),yMt.forEach(t),_Qo=r(lBe," (Transformer-XL model)"),lBe.forEach(t),uQo=i(j),Ob=n(j,"LI",{});var iBe=s(Ob);pue=n(iBe,"STRONG",{});var xMt=s(pue);bQo=r(xMt,"xlm"),xMt.forEach(t),vQo=r(iBe," \u2014 "),sz=n(iBe,"A",{href:!0});var $Mt=s(sz);FQo=r($Mt,"XLMForSequenceClassification"),$Mt.forEach(t),TQo=r(iBe," (XLM model)"),iBe.forEach(t),MQo=i(j),Vb=n(j,"LI",{});var dBe=s(Vb);_ue=n(dBe,"STRONG",{});var kMt=s(_ue);EQo=r(kMt,"xlm-roberta"),kMt.forEach(t),CQo=r(dBe," \u2014 "),lz=n(dBe,"A",{href:!0});var SMt=s(lz);wQo=r(SMt,"XLMRobertaForSequenceClassification"),SMt.forEach(t),AQo=r(dBe," (XLM-RoBERTa model)"),dBe.forEach(t),LQo=i(j),Xb=n(j,"LI",{});var cBe=s(Xb);uue=n(cBe,"STRONG",{});var RMt=s(uue);yQo=r(RMt,"xlm-roberta-xl"),RMt.forEach(t),xQo=r(cBe," \u2014 "),iz=n(cBe,"A",{href:!0});var PMt=s(iz);$Qo=r(PMt,"XLMRobertaXLForSequenceClassification"),PMt.forEach(t),kQo=r(cBe," (XLM-RoBERTa-XL model)"),cBe.forEach(t),SQo=i(j),zb=n(j,"LI",{});var fBe=s(zb);bue=n(fBe,"STRONG",{});var BMt=s(bue);RQo=r(BMt,"xlnet"),BMt.forEach(t),PQo=r(fBe," \u2014 "),dz=n(fBe,"A",{href:!0});var IMt=s(dz);BQo=r(IMt,"XLNetForSequenceClassification"),IMt.forEach(t),IQo=r(fBe," (XLNet model)"),fBe.forEach(t),NQo=i(j),Qb=n(j,"LI",{});var mBe=s(Qb);vue=n(mBe,"STRONG",{});var NMt=s(vue);qQo=r(NMt,"yoso"),NMt.forEach(t),jQo=r(mBe," \u2014 "),cz=n(mBe,"A",{href:!0});var qMt=s(cz);DQo=r(qMt,"YosoForSequenceClassification"),qMt.forEach(t),GQo=r(mBe," (YOSO model)"),mBe.forEach(t),j.forEach(t),OQo=i(ma),Wb=n(ma,"P",{});var gBe=s(Wb);VQo=r(gBe,"The model is set in evaluation mode by default using "),Fue=n(gBe,"CODE",{});var jMt=s(Fue);XQo=r(jMt,"model.eval()"),jMt.forEach(t),zQo=r(gBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tue=n(gBe,"CODE",{});var DMt=s(Tue);QQo=r(DMt,"model.train()"),DMt.forEach(t),gBe.forEach(t),WQo=i(ma),T(Hb.$$.fragment,ma),ma.forEach(t),dl.forEach(t),gze=i(f),ld=n(f,"H2",{class:!0});var vWe=s(ld);Ub=n(vWe,"A",{id:!0,class:!0,href:!0});var GMt=s(Ub);Mue=n(GMt,"SPAN",{});var OMt=s(Mue);T(by.$$.fragment,OMt),OMt.forEach(t),GMt.forEach(t),HQo=i(vWe),Eue=n(vWe,"SPAN",{});var VMt=s(Eue);UQo=r(VMt,"AutoModelForMultipleChoice"),VMt.forEach(t),vWe.forEach(t),hze=i(f),No=n(f,"DIV",{class:!0});var cl=s(No);T(vy.$$.fragment,cl),JQo=i(cl),id=n(cl,"P",{});var pte=s(id);YQo=r(pte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),fz=n(pte,"A",{href:!0});var XMt=s(fz);KQo=r(XMt,"from_pretrained()"),XMt.forEach(t),ZQo=r(pte," class method or the "),mz=n(pte,"A",{href:!0});var zMt=s(mz);eWo=r(zMt,"from_config()"),zMt.forEach(t),oWo=r(pte,` class
method.`),pte.forEach(t),rWo=i(cl),Fy=n(cl,"P",{});var FWe=s(Fy);tWo=r(FWe,"This class cannot be instantiated directly using "),Cue=n(FWe,"CODE",{});var QMt=s(Cue);aWo=r(QMt,"__init__()"),QMt.forEach(t),nWo=r(FWe," (throws an error)."),FWe.forEach(t),sWo=i(cl),ht=n(cl,"DIV",{class:!0});var kw=s(ht);T(Ty.$$.fragment,kw),lWo=i(kw),wue=n(kw,"P",{});var WMt=s(wue);iWo=r(WMt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),WMt.forEach(t),dWo=i(kw),dd=n(kw,"P",{});var _te=s(dd);cWo=r(_te,`Note:
Loading a model from its configuration file does `),Aue=n(_te,"STRONG",{});var HMt=s(Aue);fWo=r(HMt,"not"),HMt.forEach(t),mWo=r(_te,` load the model weights. It only affects the
model\u2019s configuration. Use `),gz=n(_te,"A",{href:!0});var UMt=s(gz);gWo=r(UMt,"from_pretrained()"),UMt.forEach(t),hWo=r(_te," to load the model weights."),_te.forEach(t),pWo=i(kw),T(Jb.$$.fragment,kw),kw.forEach(t),_Wo=i(cl),to=n(cl,"DIV",{class:!0});var ga=s(to);T(My.$$.fragment,ga),uWo=i(ga),Lue=n(ga,"P",{});var JMt=s(Lue);bWo=r(JMt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),JMt.forEach(t),vWo=i(ga),Oa=n(ga,"P",{});var Sw=s(Oa);FWo=r(Sw,"The model class to instantiate is selected based on the "),yue=n(Sw,"CODE",{});var YMt=s(yue);TWo=r(YMt,"model_type"),YMt.forEach(t),MWo=r(Sw,` property of the config object (either
passed as an argument or loaded from `),xue=n(Sw,"CODE",{});var KMt=s(xue);EWo=r(KMt,"pretrained_model_name_or_path"),KMt.forEach(t),CWo=r(Sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ue=n(Sw,"CODE",{});var ZMt=s($ue);wWo=r(ZMt,"pretrained_model_name_or_path"),ZMt.forEach(t),AWo=r(Sw,":"),Sw.forEach(t),LWo=i(ga),Z=n(ga,"UL",{});var ee=s(Z);Yb=n(ee,"LI",{});var hBe=s(Yb);kue=n(hBe,"STRONG",{});var eEt=s(kue);yWo=r(eEt,"albert"),eEt.forEach(t),xWo=r(hBe," \u2014 "),hz=n(hBe,"A",{href:!0});var oEt=s(hz);$Wo=r(oEt,"AlbertForMultipleChoice"),oEt.forEach(t),kWo=r(hBe," (ALBERT model)"),hBe.forEach(t),SWo=i(ee),Kb=n(ee,"LI",{});var pBe=s(Kb);Sue=n(pBe,"STRONG",{});var rEt=s(Sue);RWo=r(rEt,"bert"),rEt.forEach(t),PWo=r(pBe," \u2014 "),pz=n(pBe,"A",{href:!0});var tEt=s(pz);BWo=r(tEt,"BertForMultipleChoice"),tEt.forEach(t),IWo=r(pBe," (BERT model)"),pBe.forEach(t),NWo=i(ee),Zb=n(ee,"LI",{});var _Be=s(Zb);Rue=n(_Be,"STRONG",{});var aEt=s(Rue);qWo=r(aEt,"big_bird"),aEt.forEach(t),jWo=r(_Be," \u2014 "),_z=n(_Be,"A",{href:!0});var nEt=s(_z);DWo=r(nEt,"BigBirdForMultipleChoice"),nEt.forEach(t),GWo=r(_Be," (BigBird model)"),_Be.forEach(t),OWo=i(ee),ev=n(ee,"LI",{});var uBe=s(ev);Pue=n(uBe,"STRONG",{});var sEt=s(Pue);VWo=r(sEt,"camembert"),sEt.forEach(t),XWo=r(uBe," \u2014 "),uz=n(uBe,"A",{href:!0});var lEt=s(uz);zWo=r(lEt,"CamembertForMultipleChoice"),lEt.forEach(t),QWo=r(uBe," (CamemBERT model)"),uBe.forEach(t),WWo=i(ee),ov=n(ee,"LI",{});var bBe=s(ov);Bue=n(bBe,"STRONG",{});var iEt=s(Bue);HWo=r(iEt,"canine"),iEt.forEach(t),UWo=r(bBe," \u2014 "),bz=n(bBe,"A",{href:!0});var dEt=s(bz);JWo=r(dEt,"CanineForMultipleChoice"),dEt.forEach(t),YWo=r(bBe," (CANINE model)"),bBe.forEach(t),KWo=i(ee),rv=n(ee,"LI",{});var vBe=s(rv);Iue=n(vBe,"STRONG",{});var cEt=s(Iue);ZWo=r(cEt,"convbert"),cEt.forEach(t),eHo=r(vBe," \u2014 "),vz=n(vBe,"A",{href:!0});var fEt=s(vz);oHo=r(fEt,"ConvBertForMultipleChoice"),fEt.forEach(t),rHo=r(vBe," (ConvBERT model)"),vBe.forEach(t),tHo=i(ee),tv=n(ee,"LI",{});var FBe=s(tv);Nue=n(FBe,"STRONG",{});var mEt=s(Nue);aHo=r(mEt,"data2vec-text"),mEt.forEach(t),nHo=r(FBe," \u2014 "),Fz=n(FBe,"A",{href:!0});var gEt=s(Fz);sHo=r(gEt,"Data2VecTextForMultipleChoice"),gEt.forEach(t),lHo=r(FBe," (Data2VecText model)"),FBe.forEach(t),iHo=i(ee),av=n(ee,"LI",{});var TBe=s(av);que=n(TBe,"STRONG",{});var hEt=s(que);dHo=r(hEt,"deberta-v2"),hEt.forEach(t),cHo=r(TBe," \u2014 "),Tz=n(TBe,"A",{href:!0});var pEt=s(Tz);fHo=r(pEt,"DebertaV2ForMultipleChoice"),pEt.forEach(t),mHo=r(TBe," (DeBERTa-v2 model)"),TBe.forEach(t),gHo=i(ee),nv=n(ee,"LI",{});var MBe=s(nv);jue=n(MBe,"STRONG",{});var _Et=s(jue);hHo=r(_Et,"distilbert"),_Et.forEach(t),pHo=r(MBe," \u2014 "),Mz=n(MBe,"A",{href:!0});var uEt=s(Mz);_Ho=r(uEt,"DistilBertForMultipleChoice"),uEt.forEach(t),uHo=r(MBe," (DistilBERT model)"),MBe.forEach(t),bHo=i(ee),sv=n(ee,"LI",{});var EBe=s(sv);Due=n(EBe,"STRONG",{});var bEt=s(Due);vHo=r(bEt,"electra"),bEt.forEach(t),FHo=r(EBe," \u2014 "),Ez=n(EBe,"A",{href:!0});var vEt=s(Ez);THo=r(vEt,"ElectraForMultipleChoice"),vEt.forEach(t),MHo=r(EBe," (ELECTRA model)"),EBe.forEach(t),EHo=i(ee),lv=n(ee,"LI",{});var CBe=s(lv);Gue=n(CBe,"STRONG",{});var FEt=s(Gue);CHo=r(FEt,"flaubert"),FEt.forEach(t),wHo=r(CBe," \u2014 "),Cz=n(CBe,"A",{href:!0});var TEt=s(Cz);AHo=r(TEt,"FlaubertForMultipleChoice"),TEt.forEach(t),LHo=r(CBe," (FlauBERT model)"),CBe.forEach(t),yHo=i(ee),iv=n(ee,"LI",{});var wBe=s(iv);Oue=n(wBe,"STRONG",{});var MEt=s(Oue);xHo=r(MEt,"fnet"),MEt.forEach(t),$Ho=r(wBe," \u2014 "),wz=n(wBe,"A",{href:!0});var EEt=s(wz);kHo=r(EEt,"FNetForMultipleChoice"),EEt.forEach(t),SHo=r(wBe," (FNet model)"),wBe.forEach(t),RHo=i(ee),dv=n(ee,"LI",{});var ABe=s(dv);Vue=n(ABe,"STRONG",{});var CEt=s(Vue);PHo=r(CEt,"funnel"),CEt.forEach(t),BHo=r(ABe," \u2014 "),Az=n(ABe,"A",{href:!0});var wEt=s(Az);IHo=r(wEt,"FunnelForMultipleChoice"),wEt.forEach(t),NHo=r(ABe," (Funnel Transformer model)"),ABe.forEach(t),qHo=i(ee),cv=n(ee,"LI",{});var LBe=s(cv);Xue=n(LBe,"STRONG",{});var AEt=s(Xue);jHo=r(AEt,"ibert"),AEt.forEach(t),DHo=r(LBe," \u2014 "),Lz=n(LBe,"A",{href:!0});var LEt=s(Lz);GHo=r(LEt,"IBertForMultipleChoice"),LEt.forEach(t),OHo=r(LBe," (I-BERT model)"),LBe.forEach(t),VHo=i(ee),fv=n(ee,"LI",{});var yBe=s(fv);zue=n(yBe,"STRONG",{});var yEt=s(zue);XHo=r(yEt,"longformer"),yEt.forEach(t),zHo=r(yBe," \u2014 "),yz=n(yBe,"A",{href:!0});var xEt=s(yz);QHo=r(xEt,"LongformerForMultipleChoice"),xEt.forEach(t),WHo=r(yBe," (Longformer model)"),yBe.forEach(t),HHo=i(ee),mv=n(ee,"LI",{});var xBe=s(mv);Que=n(xBe,"STRONG",{});var $Et=s(Que);UHo=r($Et,"megatron-bert"),$Et.forEach(t),JHo=r(xBe," \u2014 "),xz=n(xBe,"A",{href:!0});var kEt=s(xz);YHo=r(kEt,"MegatronBertForMultipleChoice"),kEt.forEach(t),KHo=r(xBe," (Megatron-BERT model)"),xBe.forEach(t),ZHo=i(ee),gv=n(ee,"LI",{});var $Be=s(gv);Wue=n($Be,"STRONG",{});var SEt=s(Wue);eUo=r(SEt,"mobilebert"),SEt.forEach(t),oUo=r($Be," \u2014 "),$z=n($Be,"A",{href:!0});var REt=s($z);rUo=r(REt,"MobileBertForMultipleChoice"),REt.forEach(t),tUo=r($Be," (MobileBERT model)"),$Be.forEach(t),aUo=i(ee),hv=n(ee,"LI",{});var kBe=s(hv);Hue=n(kBe,"STRONG",{});var PEt=s(Hue);nUo=r(PEt,"mpnet"),PEt.forEach(t),sUo=r(kBe," \u2014 "),kz=n(kBe,"A",{href:!0});var BEt=s(kz);lUo=r(BEt,"MPNetForMultipleChoice"),BEt.forEach(t),iUo=r(kBe," (MPNet model)"),kBe.forEach(t),dUo=i(ee),pv=n(ee,"LI",{});var SBe=s(pv);Uue=n(SBe,"STRONG",{});var IEt=s(Uue);cUo=r(IEt,"nezha"),IEt.forEach(t),fUo=r(SBe," \u2014 "),Sz=n(SBe,"A",{href:!0});var NEt=s(Sz);mUo=r(NEt,"NezhaForMultipleChoice"),NEt.forEach(t),gUo=r(SBe," (Nezha model)"),SBe.forEach(t),hUo=i(ee),_v=n(ee,"LI",{});var RBe=s(_v);Jue=n(RBe,"STRONG",{});var qEt=s(Jue);pUo=r(qEt,"nystromformer"),qEt.forEach(t),_Uo=r(RBe," \u2014 "),Rz=n(RBe,"A",{href:!0});var jEt=s(Rz);uUo=r(jEt,"NystromformerForMultipleChoice"),jEt.forEach(t),bUo=r(RBe," (Nystr\xF6mformer model)"),RBe.forEach(t),vUo=i(ee),uv=n(ee,"LI",{});var PBe=s(uv);Yue=n(PBe,"STRONG",{});var DEt=s(Yue);FUo=r(DEt,"qdqbert"),DEt.forEach(t),TUo=r(PBe," \u2014 "),Pz=n(PBe,"A",{href:!0});var GEt=s(Pz);MUo=r(GEt,"QDQBertForMultipleChoice"),GEt.forEach(t),EUo=r(PBe," (QDQBert model)"),PBe.forEach(t),CUo=i(ee),bv=n(ee,"LI",{});var BBe=s(bv);Kue=n(BBe,"STRONG",{});var OEt=s(Kue);wUo=r(OEt,"rembert"),OEt.forEach(t),AUo=r(BBe," \u2014 "),Bz=n(BBe,"A",{href:!0});var VEt=s(Bz);LUo=r(VEt,"RemBertForMultipleChoice"),VEt.forEach(t),yUo=r(BBe," (RemBERT model)"),BBe.forEach(t),xUo=i(ee),vv=n(ee,"LI",{});var IBe=s(vv);Zue=n(IBe,"STRONG",{});var XEt=s(Zue);$Uo=r(XEt,"roberta"),XEt.forEach(t),kUo=r(IBe," \u2014 "),Iz=n(IBe,"A",{href:!0});var zEt=s(Iz);SUo=r(zEt,"RobertaForMultipleChoice"),zEt.forEach(t),RUo=r(IBe," (RoBERTa model)"),IBe.forEach(t),PUo=i(ee),Fv=n(ee,"LI",{});var NBe=s(Fv);e1e=n(NBe,"STRONG",{});var QEt=s(e1e);BUo=r(QEt,"roformer"),QEt.forEach(t),IUo=r(NBe," \u2014 "),Nz=n(NBe,"A",{href:!0});var WEt=s(Nz);NUo=r(WEt,"RoFormerForMultipleChoice"),WEt.forEach(t),qUo=r(NBe," (RoFormer model)"),NBe.forEach(t),jUo=i(ee),Tv=n(ee,"LI",{});var qBe=s(Tv);o1e=n(qBe,"STRONG",{});var HEt=s(o1e);DUo=r(HEt,"squeezebert"),HEt.forEach(t),GUo=r(qBe," \u2014 "),qz=n(qBe,"A",{href:!0});var UEt=s(qz);OUo=r(UEt,"SqueezeBertForMultipleChoice"),UEt.forEach(t),VUo=r(qBe," (SqueezeBERT model)"),qBe.forEach(t),XUo=i(ee),Mv=n(ee,"LI",{});var jBe=s(Mv);r1e=n(jBe,"STRONG",{});var JEt=s(r1e);zUo=r(JEt,"xlm"),JEt.forEach(t),QUo=r(jBe," \u2014 "),jz=n(jBe,"A",{href:!0});var YEt=s(jz);WUo=r(YEt,"XLMForMultipleChoice"),YEt.forEach(t),HUo=r(jBe," (XLM model)"),jBe.forEach(t),UUo=i(ee),Ev=n(ee,"LI",{});var DBe=s(Ev);t1e=n(DBe,"STRONG",{});var KEt=s(t1e);JUo=r(KEt,"xlm-roberta"),KEt.forEach(t),YUo=r(DBe," \u2014 "),Dz=n(DBe,"A",{href:!0});var ZEt=s(Dz);KUo=r(ZEt,"XLMRobertaForMultipleChoice"),ZEt.forEach(t),ZUo=r(DBe," (XLM-RoBERTa model)"),DBe.forEach(t),eJo=i(ee),Cv=n(ee,"LI",{});var GBe=s(Cv);a1e=n(GBe,"STRONG",{});var eCt=s(a1e);oJo=r(eCt,"xlm-roberta-xl"),eCt.forEach(t),rJo=r(GBe," \u2014 "),Gz=n(GBe,"A",{href:!0});var oCt=s(Gz);tJo=r(oCt,"XLMRobertaXLForMultipleChoice"),oCt.forEach(t),aJo=r(GBe," (XLM-RoBERTa-XL model)"),GBe.forEach(t),nJo=i(ee),wv=n(ee,"LI",{});var OBe=s(wv);n1e=n(OBe,"STRONG",{});var rCt=s(n1e);sJo=r(rCt,"xlnet"),rCt.forEach(t),lJo=r(OBe," \u2014 "),Oz=n(OBe,"A",{href:!0});var tCt=s(Oz);iJo=r(tCt,"XLNetForMultipleChoice"),tCt.forEach(t),dJo=r(OBe," (XLNet model)"),OBe.forEach(t),cJo=i(ee),Av=n(ee,"LI",{});var VBe=s(Av);s1e=n(VBe,"STRONG",{});var aCt=s(s1e);fJo=r(aCt,"yoso"),aCt.forEach(t),mJo=r(VBe," \u2014 "),Vz=n(VBe,"A",{href:!0});var nCt=s(Vz);gJo=r(nCt,"YosoForMultipleChoice"),nCt.forEach(t),hJo=r(VBe," (YOSO model)"),VBe.forEach(t),ee.forEach(t),pJo=i(ga),Lv=n(ga,"P",{});var XBe=s(Lv);_Jo=r(XBe,"The model is set in evaluation mode by default using "),l1e=n(XBe,"CODE",{});var sCt=s(l1e);uJo=r(sCt,"model.eval()"),sCt.forEach(t),bJo=r(XBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),i1e=n(XBe,"CODE",{});var lCt=s(i1e);vJo=r(lCt,"model.train()"),lCt.forEach(t),XBe.forEach(t),FJo=i(ga),T(yv.$$.fragment,ga),ga.forEach(t),cl.forEach(t),pze=i(f),cd=n(f,"H2",{class:!0});var TWe=s(cd);xv=n(TWe,"A",{id:!0,class:!0,href:!0});var iCt=s(xv);d1e=n(iCt,"SPAN",{});var dCt=s(d1e);T(Ey.$$.fragment,dCt),dCt.forEach(t),iCt.forEach(t),TJo=i(TWe),c1e=n(TWe,"SPAN",{});var cCt=s(c1e);MJo=r(cCt,"AutoModelForNextSentencePrediction"),cCt.forEach(t),TWe.forEach(t),_ze=i(f),qo=n(f,"DIV",{class:!0});var fl=s(qo);T(Cy.$$.fragment,fl),EJo=i(fl),fd=n(fl,"P",{});var ute=s(fd);CJo=r(ute,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xz=n(ute,"A",{href:!0});var fCt=s(Xz);wJo=r(fCt,"from_pretrained()"),fCt.forEach(t),AJo=r(ute," class method or the "),zz=n(ute,"A",{href:!0});var mCt=s(zz);LJo=r(mCt,"from_config()"),mCt.forEach(t),yJo=r(ute,` class
method.`),ute.forEach(t),xJo=i(fl),wy=n(fl,"P",{});var MWe=s(wy);$Jo=r(MWe,"This class cannot be instantiated directly using "),f1e=n(MWe,"CODE",{});var gCt=s(f1e);kJo=r(gCt,"__init__()"),gCt.forEach(t),SJo=r(MWe," (throws an error)."),MWe.forEach(t),RJo=i(fl),pt=n(fl,"DIV",{class:!0});var Rw=s(pt);T(Ay.$$.fragment,Rw),PJo=i(Rw),m1e=n(Rw,"P",{});var hCt=s(m1e);BJo=r(hCt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),hCt.forEach(t),IJo=i(Rw),md=n(Rw,"P",{});var bte=s(md);NJo=r(bte,`Note:
Loading a model from its configuration file does `),g1e=n(bte,"STRONG",{});var pCt=s(g1e);qJo=r(pCt,"not"),pCt.forEach(t),jJo=r(bte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qz=n(bte,"A",{href:!0});var _Ct=s(Qz);DJo=r(_Ct,"from_pretrained()"),_Ct.forEach(t),GJo=r(bte," to load the model weights."),bte.forEach(t),OJo=i(Rw),T($v.$$.fragment,Rw),Rw.forEach(t),VJo=i(fl),ao=n(fl,"DIV",{class:!0});var ha=s(ao);T(Ly.$$.fragment,ha),XJo=i(ha),h1e=n(ha,"P",{});var uCt=s(h1e);zJo=r(uCt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),uCt.forEach(t),QJo=i(ha),Va=n(ha,"P",{});var Pw=s(Va);WJo=r(Pw,"The model class to instantiate is selected based on the "),p1e=n(Pw,"CODE",{});var bCt=s(p1e);HJo=r(bCt,"model_type"),bCt.forEach(t),UJo=r(Pw,` property of the config object (either
passed as an argument or loaded from `),_1e=n(Pw,"CODE",{});var vCt=s(_1e);JJo=r(vCt,"pretrained_model_name_or_path"),vCt.forEach(t),YJo=r(Pw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u1e=n(Pw,"CODE",{});var FCt=s(u1e);KJo=r(FCt,"pretrained_model_name_or_path"),FCt.forEach(t),ZJo=r(Pw,":"),Pw.forEach(t),eYo=i(ha),jo=n(ha,"UL",{});var pa=s(jo);kv=n(pa,"LI",{});var zBe=s(kv);b1e=n(zBe,"STRONG",{});var TCt=s(b1e);oYo=r(TCt,"bert"),TCt.forEach(t),rYo=r(zBe," \u2014 "),Wz=n(zBe,"A",{href:!0});var MCt=s(Wz);tYo=r(MCt,"BertForNextSentencePrediction"),MCt.forEach(t),aYo=r(zBe," (BERT model)"),zBe.forEach(t),nYo=i(pa),Sv=n(pa,"LI",{});var QBe=s(Sv);v1e=n(QBe,"STRONG",{});var ECt=s(v1e);sYo=r(ECt,"fnet"),ECt.forEach(t),lYo=r(QBe," \u2014 "),Hz=n(QBe,"A",{href:!0});var CCt=s(Hz);iYo=r(CCt,"FNetForNextSentencePrediction"),CCt.forEach(t),dYo=r(QBe," (FNet model)"),QBe.forEach(t),cYo=i(pa),Rv=n(pa,"LI",{});var WBe=s(Rv);F1e=n(WBe,"STRONG",{});var wCt=s(F1e);fYo=r(wCt,"megatron-bert"),wCt.forEach(t),mYo=r(WBe," \u2014 "),Uz=n(WBe,"A",{href:!0});var ACt=s(Uz);gYo=r(ACt,"MegatronBertForNextSentencePrediction"),ACt.forEach(t),hYo=r(WBe," (Megatron-BERT model)"),WBe.forEach(t),pYo=i(pa),Pv=n(pa,"LI",{});var HBe=s(Pv);T1e=n(HBe,"STRONG",{});var LCt=s(T1e);_Yo=r(LCt,"mobilebert"),LCt.forEach(t),uYo=r(HBe," \u2014 "),Jz=n(HBe,"A",{href:!0});var yCt=s(Jz);bYo=r(yCt,"MobileBertForNextSentencePrediction"),yCt.forEach(t),vYo=r(HBe," (MobileBERT model)"),HBe.forEach(t),FYo=i(pa),Bv=n(pa,"LI",{});var UBe=s(Bv);M1e=n(UBe,"STRONG",{});var xCt=s(M1e);TYo=r(xCt,"nezha"),xCt.forEach(t),MYo=r(UBe," \u2014 "),Yz=n(UBe,"A",{href:!0});var $Ct=s(Yz);EYo=r($Ct,"NezhaForNextSentencePrediction"),$Ct.forEach(t),CYo=r(UBe," (Nezha model)"),UBe.forEach(t),wYo=i(pa),Iv=n(pa,"LI",{});var JBe=s(Iv);E1e=n(JBe,"STRONG",{});var kCt=s(E1e);AYo=r(kCt,"qdqbert"),kCt.forEach(t),LYo=r(JBe," \u2014 "),Kz=n(JBe,"A",{href:!0});var SCt=s(Kz);yYo=r(SCt,"QDQBertForNextSentencePrediction"),SCt.forEach(t),xYo=r(JBe," (QDQBert model)"),JBe.forEach(t),pa.forEach(t),$Yo=i(ha),Nv=n(ha,"P",{});var YBe=s(Nv);kYo=r(YBe,"The model is set in evaluation mode by default using "),C1e=n(YBe,"CODE",{});var RCt=s(C1e);SYo=r(RCt,"model.eval()"),RCt.forEach(t),RYo=r(YBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w1e=n(YBe,"CODE",{});var PCt=s(w1e);PYo=r(PCt,"model.train()"),PCt.forEach(t),YBe.forEach(t),BYo=i(ha),T(qv.$$.fragment,ha),ha.forEach(t),fl.forEach(t),uze=i(f),gd=n(f,"H2",{class:!0});var EWe=s(gd);jv=n(EWe,"A",{id:!0,class:!0,href:!0});var BCt=s(jv);A1e=n(BCt,"SPAN",{});var ICt=s(A1e);T(yy.$$.fragment,ICt),ICt.forEach(t),BCt.forEach(t),IYo=i(EWe),L1e=n(EWe,"SPAN",{});var NCt=s(L1e);NYo=r(NCt,"AutoModelForTokenClassification"),NCt.forEach(t),EWe.forEach(t),bze=i(f),Do=n(f,"DIV",{class:!0});var ml=s(Do);T(xy.$$.fragment,ml),qYo=i(ml),hd=n(ml,"P",{});var vte=s(hd);jYo=r(vte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Zz=n(vte,"A",{href:!0});var qCt=s(Zz);DYo=r(qCt,"from_pretrained()"),qCt.forEach(t),GYo=r(vte," class method or the "),eQ=n(vte,"A",{href:!0});var jCt=s(eQ);OYo=r(jCt,"from_config()"),jCt.forEach(t),VYo=r(vte,` class
method.`),vte.forEach(t),XYo=i(ml),$y=n(ml,"P",{});var CWe=s($y);zYo=r(CWe,"This class cannot be instantiated directly using "),y1e=n(CWe,"CODE",{});var DCt=s(y1e);QYo=r(DCt,"__init__()"),DCt.forEach(t),WYo=r(CWe," (throws an error)."),CWe.forEach(t),HYo=i(ml),_t=n(ml,"DIV",{class:!0});var Bw=s(_t);T(ky.$$.fragment,Bw),UYo=i(Bw),x1e=n(Bw,"P",{});var GCt=s(x1e);JYo=r(GCt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),GCt.forEach(t),YYo=i(Bw),pd=n(Bw,"P",{});var Fte=s(pd);KYo=r(Fte,`Note:
Loading a model from its configuration file does `),$1e=n(Fte,"STRONG",{});var OCt=s($1e);ZYo=r(OCt,"not"),OCt.forEach(t),eKo=r(Fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),oQ=n(Fte,"A",{href:!0});var VCt=s(oQ);oKo=r(VCt,"from_pretrained()"),VCt.forEach(t),rKo=r(Fte," to load the model weights."),Fte.forEach(t),tKo=i(Bw),T(Dv.$$.fragment,Bw),Bw.forEach(t),aKo=i(ml),no=n(ml,"DIV",{class:!0});var _a=s(no);T(Sy.$$.fragment,_a),nKo=i(_a),k1e=n(_a,"P",{});var XCt=s(k1e);sKo=r(XCt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),XCt.forEach(t),lKo=i(_a),Xa=n(_a,"P",{});var Iw=s(Xa);iKo=r(Iw,"The model class to instantiate is selected based on the "),S1e=n(Iw,"CODE",{});var zCt=s(S1e);dKo=r(zCt,"model_type"),zCt.forEach(t),cKo=r(Iw,` property of the config object (either
passed as an argument or loaded from `),R1e=n(Iw,"CODE",{});var QCt=s(R1e);fKo=r(QCt,"pretrained_model_name_or_path"),QCt.forEach(t),mKo=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P1e=n(Iw,"CODE",{});var WCt=s(P1e);gKo=r(WCt,"pretrained_model_name_or_path"),WCt.forEach(t),hKo=r(Iw,":"),Iw.forEach(t),pKo=i(_a),U=n(_a,"UL",{});var Y=s(U);Gv=n(Y,"LI",{});var KBe=s(Gv);B1e=n(KBe,"STRONG",{});var HCt=s(B1e);_Ko=r(HCt,"albert"),HCt.forEach(t),uKo=r(KBe," \u2014 "),rQ=n(KBe,"A",{href:!0});var UCt=s(rQ);bKo=r(UCt,"AlbertForTokenClassification"),UCt.forEach(t),vKo=r(KBe," (ALBERT model)"),KBe.forEach(t),FKo=i(Y),Ov=n(Y,"LI",{});var ZBe=s(Ov);I1e=n(ZBe,"STRONG",{});var JCt=s(I1e);TKo=r(JCt,"bert"),JCt.forEach(t),MKo=r(ZBe," \u2014 "),tQ=n(ZBe,"A",{href:!0});var YCt=s(tQ);EKo=r(YCt,"BertForTokenClassification"),YCt.forEach(t),CKo=r(ZBe," (BERT model)"),ZBe.forEach(t),wKo=i(Y),Vv=n(Y,"LI",{});var eIe=s(Vv);N1e=n(eIe,"STRONG",{});var KCt=s(N1e);AKo=r(KCt,"big_bird"),KCt.forEach(t),LKo=r(eIe," \u2014 "),aQ=n(eIe,"A",{href:!0});var ZCt=s(aQ);yKo=r(ZCt,"BigBirdForTokenClassification"),ZCt.forEach(t),xKo=r(eIe," (BigBird model)"),eIe.forEach(t),$Ko=i(Y),Xv=n(Y,"LI",{});var oIe=s(Xv);q1e=n(oIe,"STRONG",{});var e5t=s(q1e);kKo=r(e5t,"bloom"),e5t.forEach(t),SKo=r(oIe," \u2014 "),nQ=n(oIe,"A",{href:!0});var o5t=s(nQ);RKo=r(o5t,"BloomForTokenClassification"),o5t.forEach(t),PKo=r(oIe," (BLOOM model)"),oIe.forEach(t),BKo=i(Y),zv=n(Y,"LI",{});var rIe=s(zv);j1e=n(rIe,"STRONG",{});var r5t=s(j1e);IKo=r(r5t,"camembert"),r5t.forEach(t),NKo=r(rIe," \u2014 "),sQ=n(rIe,"A",{href:!0});var t5t=s(sQ);qKo=r(t5t,"CamembertForTokenClassification"),t5t.forEach(t),jKo=r(rIe," (CamemBERT model)"),rIe.forEach(t),DKo=i(Y),Qv=n(Y,"LI",{});var tIe=s(Qv);D1e=n(tIe,"STRONG",{});var a5t=s(D1e);GKo=r(a5t,"canine"),a5t.forEach(t),OKo=r(tIe," \u2014 "),lQ=n(tIe,"A",{href:!0});var n5t=s(lQ);VKo=r(n5t,"CanineForTokenClassification"),n5t.forEach(t),XKo=r(tIe," (CANINE model)"),tIe.forEach(t),zKo=i(Y),Wv=n(Y,"LI",{});var aIe=s(Wv);G1e=n(aIe,"STRONG",{});var s5t=s(G1e);QKo=r(s5t,"convbert"),s5t.forEach(t),WKo=r(aIe," \u2014 "),iQ=n(aIe,"A",{href:!0});var l5t=s(iQ);HKo=r(l5t,"ConvBertForTokenClassification"),l5t.forEach(t),UKo=r(aIe," (ConvBERT model)"),aIe.forEach(t),JKo=i(Y),Hv=n(Y,"LI",{});var nIe=s(Hv);O1e=n(nIe,"STRONG",{});var i5t=s(O1e);YKo=r(i5t,"data2vec-text"),i5t.forEach(t),KKo=r(nIe," \u2014 "),dQ=n(nIe,"A",{href:!0});var d5t=s(dQ);ZKo=r(d5t,"Data2VecTextForTokenClassification"),d5t.forEach(t),eZo=r(nIe," (Data2VecText model)"),nIe.forEach(t),oZo=i(Y),Uv=n(Y,"LI",{});var sIe=s(Uv);V1e=n(sIe,"STRONG",{});var c5t=s(V1e);rZo=r(c5t,"deberta"),c5t.forEach(t),tZo=r(sIe," \u2014 "),cQ=n(sIe,"A",{href:!0});var f5t=s(cQ);aZo=r(f5t,"DebertaForTokenClassification"),f5t.forEach(t),nZo=r(sIe," (DeBERTa model)"),sIe.forEach(t),sZo=i(Y),Jv=n(Y,"LI",{});var lIe=s(Jv);X1e=n(lIe,"STRONG",{});var m5t=s(X1e);lZo=r(m5t,"deberta-v2"),m5t.forEach(t),iZo=r(lIe," \u2014 "),fQ=n(lIe,"A",{href:!0});var g5t=s(fQ);dZo=r(g5t,"DebertaV2ForTokenClassification"),g5t.forEach(t),cZo=r(lIe," (DeBERTa-v2 model)"),lIe.forEach(t),fZo=i(Y),Yv=n(Y,"LI",{});var iIe=s(Yv);z1e=n(iIe,"STRONG",{});var h5t=s(z1e);mZo=r(h5t,"distilbert"),h5t.forEach(t),gZo=r(iIe," \u2014 "),mQ=n(iIe,"A",{href:!0});var p5t=s(mQ);hZo=r(p5t,"DistilBertForTokenClassification"),p5t.forEach(t),pZo=r(iIe," (DistilBERT model)"),iIe.forEach(t),_Zo=i(Y),Kv=n(Y,"LI",{});var dIe=s(Kv);Q1e=n(dIe,"STRONG",{});var _5t=s(Q1e);uZo=r(_5t,"electra"),_5t.forEach(t),bZo=r(dIe," \u2014 "),gQ=n(dIe,"A",{href:!0});var u5t=s(gQ);vZo=r(u5t,"ElectraForTokenClassification"),u5t.forEach(t),FZo=r(dIe," (ELECTRA model)"),dIe.forEach(t),TZo=i(Y),Zv=n(Y,"LI",{});var cIe=s(Zv);W1e=n(cIe,"STRONG",{});var b5t=s(W1e);MZo=r(b5t,"flaubert"),b5t.forEach(t),EZo=r(cIe," \u2014 "),hQ=n(cIe,"A",{href:!0});var v5t=s(hQ);CZo=r(v5t,"FlaubertForTokenClassification"),v5t.forEach(t),wZo=r(cIe," (FlauBERT model)"),cIe.forEach(t),AZo=i(Y),eF=n(Y,"LI",{});var fIe=s(eF);H1e=n(fIe,"STRONG",{});var F5t=s(H1e);LZo=r(F5t,"fnet"),F5t.forEach(t),yZo=r(fIe," \u2014 "),pQ=n(fIe,"A",{href:!0});var T5t=s(pQ);xZo=r(T5t,"FNetForTokenClassification"),T5t.forEach(t),$Zo=r(fIe," (FNet model)"),fIe.forEach(t),kZo=i(Y),oF=n(Y,"LI",{});var mIe=s(oF);U1e=n(mIe,"STRONG",{});var M5t=s(U1e);SZo=r(M5t,"funnel"),M5t.forEach(t),RZo=r(mIe," \u2014 "),_Q=n(mIe,"A",{href:!0});var E5t=s(_Q);PZo=r(E5t,"FunnelForTokenClassification"),E5t.forEach(t),BZo=r(mIe," (Funnel Transformer model)"),mIe.forEach(t),IZo=i(Y),rF=n(Y,"LI",{});var gIe=s(rF);J1e=n(gIe,"STRONG",{});var C5t=s(J1e);NZo=r(C5t,"gpt2"),C5t.forEach(t),qZo=r(gIe," \u2014 "),uQ=n(gIe,"A",{href:!0});var w5t=s(uQ);jZo=r(w5t,"GPT2ForTokenClassification"),w5t.forEach(t),DZo=r(gIe," (OpenAI GPT-2 model)"),gIe.forEach(t),GZo=i(Y),tF=n(Y,"LI",{});var hIe=s(tF);Y1e=n(hIe,"STRONG",{});var A5t=s(Y1e);OZo=r(A5t,"ibert"),A5t.forEach(t),VZo=r(hIe," \u2014 "),bQ=n(hIe,"A",{href:!0});var L5t=s(bQ);XZo=r(L5t,"IBertForTokenClassification"),L5t.forEach(t),zZo=r(hIe," (I-BERT model)"),hIe.forEach(t),QZo=i(Y),aF=n(Y,"LI",{});var pIe=s(aF);K1e=n(pIe,"STRONG",{});var y5t=s(K1e);WZo=r(y5t,"layoutlm"),y5t.forEach(t),HZo=r(pIe," \u2014 "),vQ=n(pIe,"A",{href:!0});var x5t=s(vQ);UZo=r(x5t,"LayoutLMForTokenClassification"),x5t.forEach(t),JZo=r(pIe," (LayoutLM model)"),pIe.forEach(t),YZo=i(Y),nF=n(Y,"LI",{});var _Ie=s(nF);Z1e=n(_Ie,"STRONG",{});var $5t=s(Z1e);KZo=r($5t,"layoutlmv2"),$5t.forEach(t),ZZo=r(_Ie," \u2014 "),FQ=n(_Ie,"A",{href:!0});var k5t=s(FQ);eer=r(k5t,"LayoutLMv2ForTokenClassification"),k5t.forEach(t),oer=r(_Ie," (LayoutLMv2 model)"),_Ie.forEach(t),rer=i(Y),sF=n(Y,"LI",{});var uIe=s(sF);e4e=n(uIe,"STRONG",{});var S5t=s(e4e);ter=r(S5t,"layoutlmv3"),S5t.forEach(t),aer=r(uIe," \u2014 "),TQ=n(uIe,"A",{href:!0});var R5t=s(TQ);ner=r(R5t,"LayoutLMv3ForTokenClassification"),R5t.forEach(t),ser=r(uIe," (LayoutLMv3 model)"),uIe.forEach(t),ler=i(Y),lF=n(Y,"LI",{});var bIe=s(lF);o4e=n(bIe,"STRONG",{});var P5t=s(o4e);ier=r(P5t,"longformer"),P5t.forEach(t),der=r(bIe," \u2014 "),MQ=n(bIe,"A",{href:!0});var B5t=s(MQ);cer=r(B5t,"LongformerForTokenClassification"),B5t.forEach(t),fer=r(bIe," (Longformer model)"),bIe.forEach(t),mer=i(Y),iF=n(Y,"LI",{});var vIe=s(iF);r4e=n(vIe,"STRONG",{});var I5t=s(r4e);ger=r(I5t,"megatron-bert"),I5t.forEach(t),her=r(vIe," \u2014 "),EQ=n(vIe,"A",{href:!0});var N5t=s(EQ);per=r(N5t,"MegatronBertForTokenClassification"),N5t.forEach(t),_er=r(vIe," (Megatron-BERT model)"),vIe.forEach(t),uer=i(Y),dF=n(Y,"LI",{});var FIe=s(dF);t4e=n(FIe,"STRONG",{});var q5t=s(t4e);ber=r(q5t,"mobilebert"),q5t.forEach(t),ver=r(FIe," \u2014 "),CQ=n(FIe,"A",{href:!0});var j5t=s(CQ);Fer=r(j5t,"MobileBertForTokenClassification"),j5t.forEach(t),Ter=r(FIe," (MobileBERT model)"),FIe.forEach(t),Mer=i(Y),cF=n(Y,"LI",{});var TIe=s(cF);a4e=n(TIe,"STRONG",{});var D5t=s(a4e);Eer=r(D5t,"mpnet"),D5t.forEach(t),Cer=r(TIe," \u2014 "),wQ=n(TIe,"A",{href:!0});var G5t=s(wQ);wer=r(G5t,"MPNetForTokenClassification"),G5t.forEach(t),Aer=r(TIe," (MPNet model)"),TIe.forEach(t),Ler=i(Y),fF=n(Y,"LI",{});var MIe=s(fF);n4e=n(MIe,"STRONG",{});var O5t=s(n4e);yer=r(O5t,"nezha"),O5t.forEach(t),xer=r(MIe," \u2014 "),AQ=n(MIe,"A",{href:!0});var V5t=s(AQ);$er=r(V5t,"NezhaForTokenClassification"),V5t.forEach(t),ker=r(MIe," (Nezha model)"),MIe.forEach(t),Ser=i(Y),mF=n(Y,"LI",{});var EIe=s(mF);s4e=n(EIe,"STRONG",{});var X5t=s(s4e);Rer=r(X5t,"nystromformer"),X5t.forEach(t),Per=r(EIe," \u2014 "),LQ=n(EIe,"A",{href:!0});var z5t=s(LQ);Ber=r(z5t,"NystromformerForTokenClassification"),z5t.forEach(t),Ier=r(EIe," (Nystr\xF6mformer model)"),EIe.forEach(t),Ner=i(Y),gF=n(Y,"LI",{});var CIe=s(gF);l4e=n(CIe,"STRONG",{});var Q5t=s(l4e);qer=r(Q5t,"qdqbert"),Q5t.forEach(t),jer=r(CIe," \u2014 "),yQ=n(CIe,"A",{href:!0});var W5t=s(yQ);Der=r(W5t,"QDQBertForTokenClassification"),W5t.forEach(t),Ger=r(CIe," (QDQBert model)"),CIe.forEach(t),Oer=i(Y),hF=n(Y,"LI",{});var wIe=s(hF);i4e=n(wIe,"STRONG",{});var H5t=s(i4e);Ver=r(H5t,"rembert"),H5t.forEach(t),Xer=r(wIe," \u2014 "),xQ=n(wIe,"A",{href:!0});var U5t=s(xQ);zer=r(U5t,"RemBertForTokenClassification"),U5t.forEach(t),Qer=r(wIe," (RemBERT model)"),wIe.forEach(t),Wer=i(Y),pF=n(Y,"LI",{});var AIe=s(pF);d4e=n(AIe,"STRONG",{});var J5t=s(d4e);Her=r(J5t,"roberta"),J5t.forEach(t),Uer=r(AIe," \u2014 "),$Q=n(AIe,"A",{href:!0});var Y5t=s($Q);Jer=r(Y5t,"RobertaForTokenClassification"),Y5t.forEach(t),Yer=r(AIe," (RoBERTa model)"),AIe.forEach(t),Ker=i(Y),_F=n(Y,"LI",{});var LIe=s(_F);c4e=n(LIe,"STRONG",{});var K5t=s(c4e);Zer=r(K5t,"roformer"),K5t.forEach(t),eor=r(LIe," \u2014 "),kQ=n(LIe,"A",{href:!0});var Z5t=s(kQ);oor=r(Z5t,"RoFormerForTokenClassification"),Z5t.forEach(t),ror=r(LIe," (RoFormer model)"),LIe.forEach(t),tor=i(Y),uF=n(Y,"LI",{});var yIe=s(uF);f4e=n(yIe,"STRONG",{});var e3t=s(f4e);aor=r(e3t,"squeezebert"),e3t.forEach(t),nor=r(yIe," \u2014 "),SQ=n(yIe,"A",{href:!0});var o3t=s(SQ);sor=r(o3t,"SqueezeBertForTokenClassification"),o3t.forEach(t),lor=r(yIe," (SqueezeBERT model)"),yIe.forEach(t),ior=i(Y),bF=n(Y,"LI",{});var xIe=s(bF);m4e=n(xIe,"STRONG",{});var r3t=s(m4e);dor=r(r3t,"xlm"),r3t.forEach(t),cor=r(xIe," \u2014 "),RQ=n(xIe,"A",{href:!0});var t3t=s(RQ);mor=r(t3t,"XLMForTokenClassification"),t3t.forEach(t),gor=r(xIe," (XLM model)"),xIe.forEach(t),hor=i(Y),vF=n(Y,"LI",{});var $Ie=s(vF);g4e=n($Ie,"STRONG",{});var a3t=s(g4e);por=r(a3t,"xlm-roberta"),a3t.forEach(t),_or=r($Ie," \u2014 "),PQ=n($Ie,"A",{href:!0});var n3t=s(PQ);uor=r(n3t,"XLMRobertaForTokenClassification"),n3t.forEach(t),bor=r($Ie," (XLM-RoBERTa model)"),$Ie.forEach(t),vor=i(Y),FF=n(Y,"LI",{});var kIe=s(FF);h4e=n(kIe,"STRONG",{});var s3t=s(h4e);For=r(s3t,"xlm-roberta-xl"),s3t.forEach(t),Tor=r(kIe," \u2014 "),BQ=n(kIe,"A",{href:!0});var l3t=s(BQ);Mor=r(l3t,"XLMRobertaXLForTokenClassification"),l3t.forEach(t),Eor=r(kIe," (XLM-RoBERTa-XL model)"),kIe.forEach(t),Cor=i(Y),TF=n(Y,"LI",{});var SIe=s(TF);p4e=n(SIe,"STRONG",{});var i3t=s(p4e);wor=r(i3t,"xlnet"),i3t.forEach(t),Aor=r(SIe," \u2014 "),IQ=n(SIe,"A",{href:!0});var d3t=s(IQ);Lor=r(d3t,"XLNetForTokenClassification"),d3t.forEach(t),yor=r(SIe," (XLNet model)"),SIe.forEach(t),xor=i(Y),MF=n(Y,"LI",{});var RIe=s(MF);_4e=n(RIe,"STRONG",{});var c3t=s(_4e);$or=r(c3t,"yoso"),c3t.forEach(t),kor=r(RIe," \u2014 "),NQ=n(RIe,"A",{href:!0});var f3t=s(NQ);Sor=r(f3t,"YosoForTokenClassification"),f3t.forEach(t),Ror=r(RIe," (YOSO model)"),RIe.forEach(t),Y.forEach(t),Por=i(_a),EF=n(_a,"P",{});var PIe=s(EF);Bor=r(PIe,"The model is set in evaluation mode by default using "),u4e=n(PIe,"CODE",{});var m3t=s(u4e);Ior=r(m3t,"model.eval()"),m3t.forEach(t),Nor=r(PIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b4e=n(PIe,"CODE",{});var g3t=s(b4e);qor=r(g3t,"model.train()"),g3t.forEach(t),PIe.forEach(t),jor=i(_a),T(CF.$$.fragment,_a),_a.forEach(t),ml.forEach(t),vze=i(f),_d=n(f,"H2",{class:!0});var wWe=s(_d);wF=n(wWe,"A",{id:!0,class:!0,href:!0});var h3t=s(wF);v4e=n(h3t,"SPAN",{});var p3t=s(v4e);T(Ry.$$.fragment,p3t),p3t.forEach(t),h3t.forEach(t),Dor=i(wWe),F4e=n(wWe,"SPAN",{});var _3t=s(F4e);Gor=r(_3t,"AutoModelForQuestionAnswering"),_3t.forEach(t),wWe.forEach(t),Fze=i(f),Go=n(f,"DIV",{class:!0});var gl=s(Go);T(Py.$$.fragment,gl),Oor=i(gl),ud=n(gl,"P",{});var Tte=s(ud);Vor=r(Tte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qQ=n(Tte,"A",{href:!0});var u3t=s(qQ);Xor=r(u3t,"from_pretrained()"),u3t.forEach(t),zor=r(Tte," class method or the "),jQ=n(Tte,"A",{href:!0});var b3t=s(jQ);Qor=r(b3t,"from_config()"),b3t.forEach(t),Wor=r(Tte,` class
method.`),Tte.forEach(t),Hor=i(gl),By=n(gl,"P",{});var AWe=s(By);Uor=r(AWe,"This class cannot be instantiated directly using "),T4e=n(AWe,"CODE",{});var v3t=s(T4e);Jor=r(v3t,"__init__()"),v3t.forEach(t),Yor=r(AWe," (throws an error)."),AWe.forEach(t),Kor=i(gl),ut=n(gl,"DIV",{class:!0});var Nw=s(ut);T(Iy.$$.fragment,Nw),Zor=i(Nw),M4e=n(Nw,"P",{});var F3t=s(M4e);err=r(F3t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),F3t.forEach(t),orr=i(Nw),bd=n(Nw,"P",{});var Mte=s(bd);rrr=r(Mte,`Note:
Loading a model from its configuration file does `),E4e=n(Mte,"STRONG",{});var T3t=s(E4e);trr=r(T3t,"not"),T3t.forEach(t),arr=r(Mte,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Mte,"A",{href:!0});var M3t=s(DQ);nrr=r(M3t,"from_pretrained()"),M3t.forEach(t),srr=r(Mte," to load the model weights."),Mte.forEach(t),lrr=i(Nw),T(AF.$$.fragment,Nw),Nw.forEach(t),irr=i(gl),so=n(gl,"DIV",{class:!0});var ua=s(so);T(Ny.$$.fragment,ua),drr=i(ua),C4e=n(ua,"P",{});var E3t=s(C4e);crr=r(E3t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),E3t.forEach(t),frr=i(ua),za=n(ua,"P",{});var qw=s(za);mrr=r(qw,"The model class to instantiate is selected based on the "),w4e=n(qw,"CODE",{});var C3t=s(w4e);grr=r(C3t,"model_type"),C3t.forEach(t),hrr=r(qw,` property of the config object (either
passed as an argument or loaded from `),A4e=n(qw,"CODE",{});var w3t=s(A4e);prr=r(w3t,"pretrained_model_name_or_path"),w3t.forEach(t),_rr=r(qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L4e=n(qw,"CODE",{});var A3t=s(L4e);urr=r(A3t,"pretrained_model_name_or_path"),A3t.forEach(t),brr=r(qw,":"),qw.forEach(t),vrr=i(ua),V=n(ua,"UL",{});var X=s(V);LF=n(X,"LI",{});var BIe=s(LF);y4e=n(BIe,"STRONG",{});var L3t=s(y4e);Frr=r(L3t,"albert"),L3t.forEach(t),Trr=r(BIe," \u2014 "),GQ=n(BIe,"A",{href:!0});var y3t=s(GQ);Mrr=r(y3t,"AlbertForQuestionAnswering"),y3t.forEach(t),Err=r(BIe," (ALBERT model)"),BIe.forEach(t),Crr=i(X),yF=n(X,"LI",{});var IIe=s(yF);x4e=n(IIe,"STRONG",{});var x3t=s(x4e);wrr=r(x3t,"bart"),x3t.forEach(t),Arr=r(IIe," \u2014 "),OQ=n(IIe,"A",{href:!0});var $3t=s(OQ);Lrr=r($3t,"BartForQuestionAnswering"),$3t.forEach(t),yrr=r(IIe," (BART model)"),IIe.forEach(t),xrr=i(X),xF=n(X,"LI",{});var NIe=s(xF);$4e=n(NIe,"STRONG",{});var k3t=s($4e);$rr=r(k3t,"bert"),k3t.forEach(t),krr=r(NIe," \u2014 "),VQ=n(NIe,"A",{href:!0});var S3t=s(VQ);Srr=r(S3t,"BertForQuestionAnswering"),S3t.forEach(t),Rrr=r(NIe," (BERT model)"),NIe.forEach(t),Prr=i(X),$F=n(X,"LI",{});var qIe=s($F);k4e=n(qIe,"STRONG",{});var R3t=s(k4e);Brr=r(R3t,"big_bird"),R3t.forEach(t),Irr=r(qIe," \u2014 "),XQ=n(qIe,"A",{href:!0});var P3t=s(XQ);Nrr=r(P3t,"BigBirdForQuestionAnswering"),P3t.forEach(t),qrr=r(qIe," (BigBird model)"),qIe.forEach(t),jrr=i(X),kF=n(X,"LI",{});var jIe=s(kF);S4e=n(jIe,"STRONG",{});var B3t=s(S4e);Drr=r(B3t,"bigbird_pegasus"),B3t.forEach(t),Grr=r(jIe," \u2014 "),zQ=n(jIe,"A",{href:!0});var I3t=s(zQ);Orr=r(I3t,"BigBirdPegasusForQuestionAnswering"),I3t.forEach(t),Vrr=r(jIe," (BigBird-Pegasus model)"),jIe.forEach(t),Xrr=i(X),SF=n(X,"LI",{});var DIe=s(SF);R4e=n(DIe,"STRONG",{});var N3t=s(R4e);zrr=r(N3t,"camembert"),N3t.forEach(t),Qrr=r(DIe," \u2014 "),QQ=n(DIe,"A",{href:!0});var q3t=s(QQ);Wrr=r(q3t,"CamembertForQuestionAnswering"),q3t.forEach(t),Hrr=r(DIe," (CamemBERT model)"),DIe.forEach(t),Urr=i(X),RF=n(X,"LI",{});var GIe=s(RF);P4e=n(GIe,"STRONG",{});var j3t=s(P4e);Jrr=r(j3t,"canine"),j3t.forEach(t),Yrr=r(GIe," \u2014 "),WQ=n(GIe,"A",{href:!0});var D3t=s(WQ);Krr=r(D3t,"CanineForQuestionAnswering"),D3t.forEach(t),Zrr=r(GIe," (CANINE model)"),GIe.forEach(t),etr=i(X),PF=n(X,"LI",{});var OIe=s(PF);B4e=n(OIe,"STRONG",{});var G3t=s(B4e);otr=r(G3t,"convbert"),G3t.forEach(t),rtr=r(OIe," \u2014 "),HQ=n(OIe,"A",{href:!0});var O3t=s(HQ);ttr=r(O3t,"ConvBertForQuestionAnswering"),O3t.forEach(t),atr=r(OIe," (ConvBERT model)"),OIe.forEach(t),ntr=i(X),BF=n(X,"LI",{});var VIe=s(BF);I4e=n(VIe,"STRONG",{});var V3t=s(I4e);str=r(V3t,"data2vec-text"),V3t.forEach(t),ltr=r(VIe," \u2014 "),UQ=n(VIe,"A",{href:!0});var X3t=s(UQ);itr=r(X3t,"Data2VecTextForQuestionAnswering"),X3t.forEach(t),dtr=r(VIe," (Data2VecText model)"),VIe.forEach(t),ctr=i(X),IF=n(X,"LI",{});var XIe=s(IF);N4e=n(XIe,"STRONG",{});var z3t=s(N4e);ftr=r(z3t,"deberta"),z3t.forEach(t),mtr=r(XIe," \u2014 "),JQ=n(XIe,"A",{href:!0});var Q3t=s(JQ);gtr=r(Q3t,"DebertaForQuestionAnswering"),Q3t.forEach(t),htr=r(XIe," (DeBERTa model)"),XIe.forEach(t),ptr=i(X),NF=n(X,"LI",{});var zIe=s(NF);q4e=n(zIe,"STRONG",{});var W3t=s(q4e);_tr=r(W3t,"deberta-v2"),W3t.forEach(t),utr=r(zIe," \u2014 "),YQ=n(zIe,"A",{href:!0});var H3t=s(YQ);btr=r(H3t,"DebertaV2ForQuestionAnswering"),H3t.forEach(t),vtr=r(zIe," (DeBERTa-v2 model)"),zIe.forEach(t),Ftr=i(X),qF=n(X,"LI",{});var QIe=s(qF);j4e=n(QIe,"STRONG",{});var U3t=s(j4e);Ttr=r(U3t,"distilbert"),U3t.forEach(t),Mtr=r(QIe," \u2014 "),KQ=n(QIe,"A",{href:!0});var J3t=s(KQ);Etr=r(J3t,"DistilBertForQuestionAnswering"),J3t.forEach(t),Ctr=r(QIe," (DistilBERT model)"),QIe.forEach(t),wtr=i(X),jF=n(X,"LI",{});var WIe=s(jF);D4e=n(WIe,"STRONG",{});var Y3t=s(D4e);Atr=r(Y3t,"electra"),Y3t.forEach(t),Ltr=r(WIe," \u2014 "),ZQ=n(WIe,"A",{href:!0});var K3t=s(ZQ);ytr=r(K3t,"ElectraForQuestionAnswering"),K3t.forEach(t),xtr=r(WIe," (ELECTRA model)"),WIe.forEach(t),$tr=i(X),DF=n(X,"LI",{});var HIe=s(DF);G4e=n(HIe,"STRONG",{});var Z3t=s(G4e);ktr=r(Z3t,"flaubert"),Z3t.forEach(t),Str=r(HIe," \u2014 "),eW=n(HIe,"A",{href:!0});var e0t=s(eW);Rtr=r(e0t,"FlaubertForQuestionAnsweringSimple"),e0t.forEach(t),Ptr=r(HIe," (FlauBERT model)"),HIe.forEach(t),Btr=i(X),GF=n(X,"LI",{});var UIe=s(GF);O4e=n(UIe,"STRONG",{});var o0t=s(O4e);Itr=r(o0t,"fnet"),o0t.forEach(t),Ntr=r(UIe," \u2014 "),oW=n(UIe,"A",{href:!0});var r0t=s(oW);qtr=r(r0t,"FNetForQuestionAnswering"),r0t.forEach(t),jtr=r(UIe," (FNet model)"),UIe.forEach(t),Dtr=i(X),OF=n(X,"LI",{});var JIe=s(OF);V4e=n(JIe,"STRONG",{});var t0t=s(V4e);Gtr=r(t0t,"funnel"),t0t.forEach(t),Otr=r(JIe," \u2014 "),rW=n(JIe,"A",{href:!0});var a0t=s(rW);Vtr=r(a0t,"FunnelForQuestionAnswering"),a0t.forEach(t),Xtr=r(JIe," (Funnel Transformer model)"),JIe.forEach(t),ztr=i(X),VF=n(X,"LI",{});var YIe=s(VF);X4e=n(YIe,"STRONG",{});var n0t=s(X4e);Qtr=r(n0t,"gptj"),n0t.forEach(t),Wtr=r(YIe," \u2014 "),tW=n(YIe,"A",{href:!0});var s0t=s(tW);Htr=r(s0t,"GPTJForQuestionAnswering"),s0t.forEach(t),Utr=r(YIe," (GPT-J model)"),YIe.forEach(t),Jtr=i(X),XF=n(X,"LI",{});var KIe=s(XF);z4e=n(KIe,"STRONG",{});var l0t=s(z4e);Ytr=r(l0t,"ibert"),l0t.forEach(t),Ktr=r(KIe," \u2014 "),aW=n(KIe,"A",{href:!0});var i0t=s(aW);Ztr=r(i0t,"IBertForQuestionAnswering"),i0t.forEach(t),ear=r(KIe," (I-BERT model)"),KIe.forEach(t),oar=i(X),zF=n(X,"LI",{});var ZIe=s(zF);Q4e=n(ZIe,"STRONG",{});var d0t=s(Q4e);rar=r(d0t,"layoutlmv2"),d0t.forEach(t),tar=r(ZIe," \u2014 "),nW=n(ZIe,"A",{href:!0});var c0t=s(nW);aar=r(c0t,"LayoutLMv2ForQuestionAnswering"),c0t.forEach(t),nar=r(ZIe," (LayoutLMv2 model)"),ZIe.forEach(t),sar=i(X),QF=n(X,"LI",{});var eNe=s(QF);W4e=n(eNe,"STRONG",{});var f0t=s(W4e);lar=r(f0t,"layoutlmv3"),f0t.forEach(t),iar=r(eNe," \u2014 "),sW=n(eNe,"A",{href:!0});var m0t=s(sW);dar=r(m0t,"LayoutLMv3ForQuestionAnswering"),m0t.forEach(t),car=r(eNe," (LayoutLMv3 model)"),eNe.forEach(t),far=i(X),WF=n(X,"LI",{});var oNe=s(WF);H4e=n(oNe,"STRONG",{});var g0t=s(H4e);mar=r(g0t,"led"),g0t.forEach(t),gar=r(oNe," \u2014 "),lW=n(oNe,"A",{href:!0});var h0t=s(lW);har=r(h0t,"LEDForQuestionAnswering"),h0t.forEach(t),par=r(oNe," (LED model)"),oNe.forEach(t),_ar=i(X),HF=n(X,"LI",{});var rNe=s(HF);U4e=n(rNe,"STRONG",{});var p0t=s(U4e);uar=r(p0t,"longformer"),p0t.forEach(t),bar=r(rNe," \u2014 "),iW=n(rNe,"A",{href:!0});var _0t=s(iW);Far=r(_0t,"LongformerForQuestionAnswering"),_0t.forEach(t),Tar=r(rNe," (Longformer model)"),rNe.forEach(t),Mar=i(X),UF=n(X,"LI",{});var tNe=s(UF);J4e=n(tNe,"STRONG",{});var u0t=s(J4e);Ear=r(u0t,"lxmert"),u0t.forEach(t),Car=r(tNe," \u2014 "),dW=n(tNe,"A",{href:!0});var b0t=s(dW);war=r(b0t,"LxmertForQuestionAnswering"),b0t.forEach(t),Aar=r(tNe," (LXMERT model)"),tNe.forEach(t),Lar=i(X),JF=n(X,"LI",{});var aNe=s(JF);Y4e=n(aNe,"STRONG",{});var v0t=s(Y4e);yar=r(v0t,"mbart"),v0t.forEach(t),xar=r(aNe," \u2014 "),cW=n(aNe,"A",{href:!0});var F0t=s(cW);$ar=r(F0t,"MBartForQuestionAnswering"),F0t.forEach(t),kar=r(aNe," (mBART model)"),aNe.forEach(t),Sar=i(X),YF=n(X,"LI",{});var nNe=s(YF);K4e=n(nNe,"STRONG",{});var T0t=s(K4e);Rar=r(T0t,"megatron-bert"),T0t.forEach(t),Par=r(nNe," \u2014 "),fW=n(nNe,"A",{href:!0});var M0t=s(fW);Bar=r(M0t,"MegatronBertForQuestionAnswering"),M0t.forEach(t),Iar=r(nNe," (Megatron-BERT model)"),nNe.forEach(t),Nar=i(X),KF=n(X,"LI",{});var sNe=s(KF);Z4e=n(sNe,"STRONG",{});var E0t=s(Z4e);qar=r(E0t,"mobilebert"),E0t.forEach(t),jar=r(sNe," \u2014 "),mW=n(sNe,"A",{href:!0});var C0t=s(mW);Dar=r(C0t,"MobileBertForQuestionAnswering"),C0t.forEach(t),Gar=r(sNe," (MobileBERT model)"),sNe.forEach(t),Oar=i(X),ZF=n(X,"LI",{});var lNe=s(ZF);e2e=n(lNe,"STRONG",{});var w0t=s(e2e);Var=r(w0t,"mpnet"),w0t.forEach(t),Xar=r(lNe," \u2014 "),gW=n(lNe,"A",{href:!0});var A0t=s(gW);zar=r(A0t,"MPNetForQuestionAnswering"),A0t.forEach(t),Qar=r(lNe," (MPNet model)"),lNe.forEach(t),War=i(X),e6=n(X,"LI",{});var iNe=s(e6);o2e=n(iNe,"STRONG",{});var L0t=s(o2e);Har=r(L0t,"mvp"),L0t.forEach(t),Uar=r(iNe," \u2014 "),hW=n(iNe,"A",{href:!0});var y0t=s(hW);Jar=r(y0t,"MvpForQuestionAnswering"),y0t.forEach(t),Yar=r(iNe," (MVP model)"),iNe.forEach(t),Kar=i(X),o6=n(X,"LI",{});var dNe=s(o6);r2e=n(dNe,"STRONG",{});var x0t=s(r2e);Zar=r(x0t,"nezha"),x0t.forEach(t),enr=r(dNe," \u2014 "),pW=n(dNe,"A",{href:!0});var $0t=s(pW);onr=r($0t,"NezhaForQuestionAnswering"),$0t.forEach(t),rnr=r(dNe," (Nezha model)"),dNe.forEach(t),tnr=i(X),r6=n(X,"LI",{});var cNe=s(r6);t2e=n(cNe,"STRONG",{});var k0t=s(t2e);anr=r(k0t,"nystromformer"),k0t.forEach(t),nnr=r(cNe," \u2014 "),_W=n(cNe,"A",{href:!0});var S0t=s(_W);snr=r(S0t,"NystromformerForQuestionAnswering"),S0t.forEach(t),lnr=r(cNe," (Nystr\xF6mformer model)"),cNe.forEach(t),inr=i(X),t6=n(X,"LI",{});var fNe=s(t6);a2e=n(fNe,"STRONG",{});var R0t=s(a2e);dnr=r(R0t,"qdqbert"),R0t.forEach(t),cnr=r(fNe," \u2014 "),uW=n(fNe,"A",{href:!0});var P0t=s(uW);fnr=r(P0t,"QDQBertForQuestionAnswering"),P0t.forEach(t),mnr=r(fNe," (QDQBert model)"),fNe.forEach(t),gnr=i(X),a6=n(X,"LI",{});var mNe=s(a6);n2e=n(mNe,"STRONG",{});var B0t=s(n2e);hnr=r(B0t,"reformer"),B0t.forEach(t),pnr=r(mNe," \u2014 "),bW=n(mNe,"A",{href:!0});var I0t=s(bW);_nr=r(I0t,"ReformerForQuestionAnswering"),I0t.forEach(t),unr=r(mNe," (Reformer model)"),mNe.forEach(t),bnr=i(X),n6=n(X,"LI",{});var gNe=s(n6);s2e=n(gNe,"STRONG",{});var N0t=s(s2e);vnr=r(N0t,"rembert"),N0t.forEach(t),Fnr=r(gNe," \u2014 "),vW=n(gNe,"A",{href:!0});var q0t=s(vW);Tnr=r(q0t,"RemBertForQuestionAnswering"),q0t.forEach(t),Mnr=r(gNe," (RemBERT model)"),gNe.forEach(t),Enr=i(X),s6=n(X,"LI",{});var hNe=s(s6);l2e=n(hNe,"STRONG",{});var j0t=s(l2e);Cnr=r(j0t,"roberta"),j0t.forEach(t),wnr=r(hNe," \u2014 "),FW=n(hNe,"A",{href:!0});var D0t=s(FW);Anr=r(D0t,"RobertaForQuestionAnswering"),D0t.forEach(t),Lnr=r(hNe," (RoBERTa model)"),hNe.forEach(t),ynr=i(X),l6=n(X,"LI",{});var pNe=s(l6);i2e=n(pNe,"STRONG",{});var G0t=s(i2e);xnr=r(G0t,"roformer"),G0t.forEach(t),$nr=r(pNe," \u2014 "),TW=n(pNe,"A",{href:!0});var O0t=s(TW);knr=r(O0t,"RoFormerForQuestionAnswering"),O0t.forEach(t),Snr=r(pNe," (RoFormer model)"),pNe.forEach(t),Rnr=i(X),i6=n(X,"LI",{});var _Ne=s(i6);d2e=n(_Ne,"STRONG",{});var V0t=s(d2e);Pnr=r(V0t,"splinter"),V0t.forEach(t),Bnr=r(_Ne," \u2014 "),MW=n(_Ne,"A",{href:!0});var X0t=s(MW);Inr=r(X0t,"SplinterForQuestionAnswering"),X0t.forEach(t),Nnr=r(_Ne," (Splinter model)"),_Ne.forEach(t),qnr=i(X),d6=n(X,"LI",{});var uNe=s(d6);c2e=n(uNe,"STRONG",{});var z0t=s(c2e);jnr=r(z0t,"squeezebert"),z0t.forEach(t),Dnr=r(uNe," \u2014 "),EW=n(uNe,"A",{href:!0});var Q0t=s(EW);Gnr=r(Q0t,"SqueezeBertForQuestionAnswering"),Q0t.forEach(t),Onr=r(uNe," (SqueezeBERT model)"),uNe.forEach(t),Vnr=i(X),c6=n(X,"LI",{});var bNe=s(c6);f2e=n(bNe,"STRONG",{});var W0t=s(f2e);Xnr=r(W0t,"xlm"),W0t.forEach(t),znr=r(bNe," \u2014 "),CW=n(bNe,"A",{href:!0});var H0t=s(CW);Qnr=r(H0t,"XLMForQuestionAnsweringSimple"),H0t.forEach(t),Wnr=r(bNe," (XLM model)"),bNe.forEach(t),Hnr=i(X),f6=n(X,"LI",{});var vNe=s(f6);m2e=n(vNe,"STRONG",{});var U0t=s(m2e);Unr=r(U0t,"xlm-roberta"),U0t.forEach(t),Jnr=r(vNe," \u2014 "),wW=n(vNe,"A",{href:!0});var J0t=s(wW);Ynr=r(J0t,"XLMRobertaForQuestionAnswering"),J0t.forEach(t),Knr=r(vNe," (XLM-RoBERTa model)"),vNe.forEach(t),Znr=i(X),m6=n(X,"LI",{});var FNe=s(m6);g2e=n(FNe,"STRONG",{});var Y0t=s(g2e);esr=r(Y0t,"xlm-roberta-xl"),Y0t.forEach(t),osr=r(FNe," \u2014 "),AW=n(FNe,"A",{href:!0});var K0t=s(AW);rsr=r(K0t,"XLMRobertaXLForQuestionAnswering"),K0t.forEach(t),tsr=r(FNe," (XLM-RoBERTa-XL model)"),FNe.forEach(t),asr=i(X),g6=n(X,"LI",{});var TNe=s(g6);h2e=n(TNe,"STRONG",{});var Z0t=s(h2e);nsr=r(Z0t,"xlnet"),Z0t.forEach(t),ssr=r(TNe," \u2014 "),LW=n(TNe,"A",{href:!0});var ewt=s(LW);lsr=r(ewt,"XLNetForQuestionAnsweringSimple"),ewt.forEach(t),isr=r(TNe," (XLNet model)"),TNe.forEach(t),dsr=i(X),h6=n(X,"LI",{});var MNe=s(h6);p2e=n(MNe,"STRONG",{});var owt=s(p2e);csr=r(owt,"yoso"),owt.forEach(t),fsr=r(MNe," \u2014 "),yW=n(MNe,"A",{href:!0});var rwt=s(yW);msr=r(rwt,"YosoForQuestionAnswering"),rwt.forEach(t),gsr=r(MNe," (YOSO model)"),MNe.forEach(t),X.forEach(t),hsr=i(ua),p6=n(ua,"P",{});var ENe=s(p6);psr=r(ENe,"The model is set in evaluation mode by default using "),_2e=n(ENe,"CODE",{});var twt=s(_2e);_sr=r(twt,"model.eval()"),twt.forEach(t),usr=r(ENe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=n(ENe,"CODE",{});var awt=s(u2e);bsr=r(awt,"model.train()"),awt.forEach(t),ENe.forEach(t),vsr=i(ua),T(_6.$$.fragment,ua),ua.forEach(t),gl.forEach(t),Tze=i(f),vd=n(f,"H2",{class:!0});var LWe=s(vd);u6=n(LWe,"A",{id:!0,class:!0,href:!0});var nwt=s(u6);b2e=n(nwt,"SPAN",{});var swt=s(b2e);T(qy.$$.fragment,swt),swt.forEach(t),nwt.forEach(t),Fsr=i(LWe),v2e=n(LWe,"SPAN",{});var lwt=s(v2e);Tsr=r(lwt,"AutoModelForTableQuestionAnswering"),lwt.forEach(t),LWe.forEach(t),Mze=i(f),Oo=n(f,"DIV",{class:!0});var hl=s(Oo);T(jy.$$.fragment,hl),Msr=i(hl),Fd=n(hl,"P",{});var Ete=s(Fd);Esr=r(Ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),xW=n(Ete,"A",{href:!0});var iwt=s(xW);Csr=r(iwt,"from_pretrained()"),iwt.forEach(t),wsr=r(Ete," class method or the "),$W=n(Ete,"A",{href:!0});var dwt=s($W);Asr=r(dwt,"from_config()"),dwt.forEach(t),Lsr=r(Ete,` class
method.`),Ete.forEach(t),ysr=i(hl),Dy=n(hl,"P",{});var yWe=s(Dy);xsr=r(yWe,"This class cannot be instantiated directly using "),F2e=n(yWe,"CODE",{});var cwt=s(F2e);$sr=r(cwt,"__init__()"),cwt.forEach(t),ksr=r(yWe," (throws an error)."),yWe.forEach(t),Ssr=i(hl),bt=n(hl,"DIV",{class:!0});var jw=s(bt);T(Gy.$$.fragment,jw),Rsr=i(jw),T2e=n(jw,"P",{});var fwt=s(T2e);Psr=r(fwt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),fwt.forEach(t),Bsr=i(jw),Td=n(jw,"P",{});var Cte=s(Td);Isr=r(Cte,`Note:
Loading a model from its configuration file does `),M2e=n(Cte,"STRONG",{});var mwt=s(M2e);Nsr=r(mwt,"not"),mwt.forEach(t),qsr=r(Cte,` load the model weights. It only affects the
model\u2019s configuration. Use `),kW=n(Cte,"A",{href:!0});var gwt=s(kW);jsr=r(gwt,"from_pretrained()"),gwt.forEach(t),Dsr=r(Cte," to load the model weights."),Cte.forEach(t),Gsr=i(jw),T(b6.$$.fragment,jw),jw.forEach(t),Osr=i(hl),lo=n(hl,"DIV",{class:!0});var ba=s(lo);T(Oy.$$.fragment,ba),Vsr=i(ba),E2e=n(ba,"P",{});var hwt=s(E2e);Xsr=r(hwt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),hwt.forEach(t),zsr=i(ba),Qa=n(ba,"P",{});var Dw=s(Qa);Qsr=r(Dw,"The model class to instantiate is selected based on the "),C2e=n(Dw,"CODE",{});var pwt=s(C2e);Wsr=r(pwt,"model_type"),pwt.forEach(t),Hsr=r(Dw,` property of the config object (either
passed as an argument or loaded from `),w2e=n(Dw,"CODE",{});var _wt=s(w2e);Usr=r(_wt,"pretrained_model_name_or_path"),_wt.forEach(t),Jsr=r(Dw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A2e=n(Dw,"CODE",{});var uwt=s(A2e);Ysr=r(uwt,"pretrained_model_name_or_path"),uwt.forEach(t),Ksr=r(Dw,":"),Dw.forEach(t),Zsr=i(ba),L2e=n(ba,"UL",{});var bwt=s(L2e);v6=n(bwt,"LI",{});var CNe=s(v6);y2e=n(CNe,"STRONG",{});var vwt=s(y2e);elr=r(vwt,"tapas"),vwt.forEach(t),olr=r(CNe," \u2014 "),SW=n(CNe,"A",{href:!0});var Fwt=s(SW);rlr=r(Fwt,"TapasForQuestionAnswering"),Fwt.forEach(t),tlr=r(CNe," (TAPAS model)"),CNe.forEach(t),bwt.forEach(t),alr=i(ba),F6=n(ba,"P",{});var wNe=s(F6);nlr=r(wNe,"The model is set in evaluation mode by default using "),x2e=n(wNe,"CODE",{});var Twt=s(x2e);slr=r(Twt,"model.eval()"),Twt.forEach(t),llr=r(wNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$2e=n(wNe,"CODE",{});var Mwt=s($2e);ilr=r(Mwt,"model.train()"),Mwt.forEach(t),wNe.forEach(t),dlr=i(ba),T(T6.$$.fragment,ba),ba.forEach(t),hl.forEach(t),Eze=i(f),Md=n(f,"H2",{class:!0});var xWe=s(Md);M6=n(xWe,"A",{id:!0,class:!0,href:!0});var Ewt=s(M6);k2e=n(Ewt,"SPAN",{});var Cwt=s(k2e);T(Vy.$$.fragment,Cwt),Cwt.forEach(t),Ewt.forEach(t),clr=i(xWe),S2e=n(xWe,"SPAN",{});var wwt=s(S2e);flr=r(wwt,"AutoModelForImageClassification"),wwt.forEach(t),xWe.forEach(t),Cze=i(f),Vo=n(f,"DIV",{class:!0});var pl=s(Vo);T(Xy.$$.fragment,pl),mlr=i(pl),Ed=n(pl,"P",{});var wte=s(Ed);glr=r(wte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),RW=n(wte,"A",{href:!0});var Awt=s(RW);hlr=r(Awt,"from_pretrained()"),Awt.forEach(t),plr=r(wte," class method or the "),PW=n(wte,"A",{href:!0});var Lwt=s(PW);_lr=r(Lwt,"from_config()"),Lwt.forEach(t),ulr=r(wte,` class
method.`),wte.forEach(t),blr=i(pl),zy=n(pl,"P",{});var $We=s(zy);vlr=r($We,"This class cannot be instantiated directly using "),R2e=n($We,"CODE",{});var ywt=s(R2e);Flr=r(ywt,"__init__()"),ywt.forEach(t),Tlr=r($We," (throws an error)."),$We.forEach(t),Mlr=i(pl),vt=n(pl,"DIV",{class:!0});var Gw=s(vt);T(Qy.$$.fragment,Gw),Elr=i(Gw),P2e=n(Gw,"P",{});var xwt=s(P2e);Clr=r(xwt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),xwt.forEach(t),wlr=i(Gw),Cd=n(Gw,"P",{});var Ate=s(Cd);Alr=r(Ate,`Note:
Loading a model from its configuration file does `),B2e=n(Ate,"STRONG",{});var $wt=s(B2e);Llr=r($wt,"not"),$wt.forEach(t),ylr=r(Ate,` load the model weights. It only affects the
model\u2019s configuration. Use `),BW=n(Ate,"A",{href:!0});var kwt=s(BW);xlr=r(kwt,"from_pretrained()"),kwt.forEach(t),$lr=r(Ate," to load the model weights."),Ate.forEach(t),klr=i(Gw),T(E6.$$.fragment,Gw),Gw.forEach(t),Slr=i(pl),io=n(pl,"DIV",{class:!0});var va=s(io);T(Wy.$$.fragment,va),Rlr=i(va),I2e=n(va,"P",{});var Swt=s(I2e);Plr=r(Swt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Swt.forEach(t),Blr=i(va),Wa=n(va,"P",{});var Ow=s(Wa);Ilr=r(Ow,"The model class to instantiate is selected based on the "),N2e=n(Ow,"CODE",{});var Rwt=s(N2e);Nlr=r(Rwt,"model_type"),Rwt.forEach(t),qlr=r(Ow,` property of the config object (either
passed as an argument or loaded from `),q2e=n(Ow,"CODE",{});var Pwt=s(q2e);jlr=r(Pwt,"pretrained_model_name_or_path"),Pwt.forEach(t),Dlr=r(Ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j2e=n(Ow,"CODE",{});var Bwt=s(j2e);Glr=r(Bwt,"pretrained_model_name_or_path"),Bwt.forEach(t),Olr=r(Ow,":"),Ow.forEach(t),Vlr=i(va),ue=n(va,"UL",{});var Fe=s(ue);C6=n(Fe,"LI",{});var ANe=s(C6);D2e=n(ANe,"STRONG",{});var Iwt=s(D2e);Xlr=r(Iwt,"beit"),Iwt.forEach(t),zlr=r(ANe," \u2014 "),IW=n(ANe,"A",{href:!0});var Nwt=s(IW);Qlr=r(Nwt,"BeitForImageClassification"),Nwt.forEach(t),Wlr=r(ANe," (BEiT model)"),ANe.forEach(t),Hlr=i(Fe),w6=n(Fe,"LI",{});var LNe=s(w6);G2e=n(LNe,"STRONG",{});var qwt=s(G2e);Ulr=r(qwt,"convnext"),qwt.forEach(t),Jlr=r(LNe," \u2014 "),NW=n(LNe,"A",{href:!0});var jwt=s(NW);Ylr=r(jwt,"ConvNextForImageClassification"),jwt.forEach(t),Klr=r(LNe," (ConvNeXT model)"),LNe.forEach(t),Zlr=i(Fe),A6=n(Fe,"LI",{});var yNe=s(A6);O2e=n(yNe,"STRONG",{});var Dwt=s(O2e);eir=r(Dwt,"cvt"),Dwt.forEach(t),oir=r(yNe," \u2014 "),qW=n(yNe,"A",{href:!0});var Gwt=s(qW);rir=r(Gwt,"CvtForImageClassification"),Gwt.forEach(t),tir=r(yNe," (CvT model)"),yNe.forEach(t),air=i(Fe),L6=n(Fe,"LI",{});var xNe=s(L6);V2e=n(xNe,"STRONG",{});var Owt=s(V2e);nir=r(Owt,"data2vec-vision"),Owt.forEach(t),sir=r(xNe," \u2014 "),jW=n(xNe,"A",{href:!0});var Vwt=s(jW);lir=r(Vwt,"Data2VecVisionForImageClassification"),Vwt.forEach(t),iir=r(xNe," (Data2VecVision model)"),xNe.forEach(t),dir=i(Fe),Js=n(Fe,"LI",{});var XS=s(Js);X2e=n(XS,"STRONG",{});var Xwt=s(X2e);cir=r(Xwt,"deit"),Xwt.forEach(t),fir=r(XS," \u2014 "),DW=n(XS,"A",{href:!0});var zwt=s(DW);mir=r(zwt,"DeiTForImageClassification"),zwt.forEach(t),gir=r(XS," or "),GW=n(XS,"A",{href:!0});var Qwt=s(GW);hir=r(Qwt,"DeiTForImageClassificationWithTeacher"),Qwt.forEach(t),pir=r(XS," (DeiT model)"),XS.forEach(t),_ir=i(Fe),y6=n(Fe,"LI",{});var $Ne=s(y6);z2e=n($Ne,"STRONG",{});var Wwt=s(z2e);uir=r(Wwt,"imagegpt"),Wwt.forEach(t),bir=r($Ne," \u2014 "),OW=n($Ne,"A",{href:!0});var Hwt=s(OW);vir=r(Hwt,"ImageGPTForImageClassification"),Hwt.forEach(t),Fir=r($Ne," (ImageGPT model)"),$Ne.forEach(t),Tir=i(Fe),Ys=n(Fe,"LI",{});var zS=s(Ys);Q2e=n(zS,"STRONG",{});var Uwt=s(Q2e);Mir=r(Uwt,"levit"),Uwt.forEach(t),Eir=r(zS," \u2014 "),VW=n(zS,"A",{href:!0});var Jwt=s(VW);Cir=r(Jwt,"LevitForImageClassification"),Jwt.forEach(t),wir=r(zS," or "),XW=n(zS,"A",{href:!0});var Ywt=s(XW);Air=r(Ywt,"LevitForImageClassificationWithTeacher"),Ywt.forEach(t),Lir=r(zS," (LeViT model)"),zS.forEach(t),yir=i(Fe),x6=n(Fe,"LI",{});var kNe=s(x6);W2e=n(kNe,"STRONG",{});var Kwt=s(W2e);xir=r(Kwt,"mobilevit"),Kwt.forEach(t),$ir=r(kNe," \u2014 "),zW=n(kNe,"A",{href:!0});var Zwt=s(zW);kir=r(Zwt,"MobileViTForImageClassification"),Zwt.forEach(t),Sir=r(kNe," (MobileViT model)"),kNe.forEach(t),Rir=i(Fe),Ft=n(Fe,"LI",{});var Pf=s(Ft);H2e=n(Pf,"STRONG",{});var eAt=s(H2e);Pir=r(eAt,"perceiver"),eAt.forEach(t),Bir=r(Pf," \u2014 "),QW=n(Pf,"A",{href:!0});var oAt=s(QW);Iir=r(oAt,"PerceiverForImageClassificationLearned"),oAt.forEach(t),Nir=r(Pf," or "),WW=n(Pf,"A",{href:!0});var rAt=s(WW);qir=r(rAt,"PerceiverForImageClassificationFourier"),rAt.forEach(t),jir=r(Pf," or "),HW=n(Pf,"A",{href:!0});var tAt=s(HW);Dir=r(tAt,"PerceiverForImageClassificationConvProcessing"),tAt.forEach(t),Gir=r(Pf," (Perceiver model)"),Pf.forEach(t),Oir=i(Fe),$6=n(Fe,"LI",{});var SNe=s($6);U2e=n(SNe,"STRONG",{});var aAt=s(U2e);Vir=r(aAt,"poolformer"),aAt.forEach(t),Xir=r(SNe," \u2014 "),UW=n(SNe,"A",{href:!0});var nAt=s(UW);zir=r(nAt,"PoolFormerForImageClassification"),nAt.forEach(t),Qir=r(SNe," (PoolFormer model)"),SNe.forEach(t),Wir=i(Fe),k6=n(Fe,"LI",{});var RNe=s(k6);J2e=n(RNe,"STRONG",{});var sAt=s(J2e);Hir=r(sAt,"regnet"),sAt.forEach(t),Uir=r(RNe," \u2014 "),JW=n(RNe,"A",{href:!0});var lAt=s(JW);Jir=r(lAt,"RegNetForImageClassification"),lAt.forEach(t),Yir=r(RNe," (RegNet model)"),RNe.forEach(t),Kir=i(Fe),S6=n(Fe,"LI",{});var PNe=s(S6);Y2e=n(PNe,"STRONG",{});var iAt=s(Y2e);Zir=r(iAt,"resnet"),iAt.forEach(t),edr=r(PNe," \u2014 "),YW=n(PNe,"A",{href:!0});var dAt=s(YW);odr=r(dAt,"ResNetForImageClassification"),dAt.forEach(t),rdr=r(PNe," (ResNet model)"),PNe.forEach(t),tdr=i(Fe),R6=n(Fe,"LI",{});var BNe=s(R6);K2e=n(BNe,"STRONG",{});var cAt=s(K2e);adr=r(cAt,"segformer"),cAt.forEach(t),ndr=r(BNe," \u2014 "),KW=n(BNe,"A",{href:!0});var fAt=s(KW);sdr=r(fAt,"SegformerForImageClassification"),fAt.forEach(t),ldr=r(BNe," (SegFormer model)"),BNe.forEach(t),idr=i(Fe),P6=n(Fe,"LI",{});var INe=s(P6);Z2e=n(INe,"STRONG",{});var mAt=s(Z2e);ddr=r(mAt,"swin"),mAt.forEach(t),cdr=r(INe," \u2014 "),ZW=n(INe,"A",{href:!0});var gAt=s(ZW);fdr=r(gAt,"SwinForImageClassification"),gAt.forEach(t),mdr=r(INe," (Swin Transformer model)"),INe.forEach(t),gdr=i(Fe),B6=n(Fe,"LI",{});var NNe=s(B6);ebe=n(NNe,"STRONG",{});var hAt=s(ebe);hdr=r(hAt,"swinv2"),hAt.forEach(t),pdr=r(NNe," \u2014 "),eH=n(NNe,"A",{href:!0});var pAt=s(eH);_dr=r(pAt,"Swinv2ForImageClassification"),pAt.forEach(t),udr=r(NNe," (Swin Transformer V2 model)"),NNe.forEach(t),bdr=i(Fe),I6=n(Fe,"LI",{});var qNe=s(I6);obe=n(qNe,"STRONG",{});var _At=s(obe);vdr=r(_At,"van"),_At.forEach(t),Fdr=r(qNe," \u2014 "),oH=n(qNe,"A",{href:!0});var uAt=s(oH);Tdr=r(uAt,"VanForImageClassification"),uAt.forEach(t),Mdr=r(qNe," (VAN model)"),qNe.forEach(t),Edr=i(Fe),N6=n(Fe,"LI",{});var jNe=s(N6);rbe=n(jNe,"STRONG",{});var bAt=s(rbe);Cdr=r(bAt,"vit"),bAt.forEach(t),wdr=r(jNe," \u2014 "),rH=n(jNe,"A",{href:!0});var vAt=s(rH);Adr=r(vAt,"ViTForImageClassification"),vAt.forEach(t),Ldr=r(jNe," (ViT model)"),jNe.forEach(t),Fe.forEach(t),ydr=i(va),q6=n(va,"P",{});var DNe=s(q6);xdr=r(DNe,"The model is set in evaluation mode by default using "),tbe=n(DNe,"CODE",{});var FAt=s(tbe);$dr=r(FAt,"model.eval()"),FAt.forEach(t),kdr=r(DNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),abe=n(DNe,"CODE",{});var TAt=s(abe);Sdr=r(TAt,"model.train()"),TAt.forEach(t),DNe.forEach(t),Rdr=i(va),T(j6.$$.fragment,va),va.forEach(t),pl.forEach(t),wze=i(f),wd=n(f,"H2",{class:!0});var kWe=s(wd);D6=n(kWe,"A",{id:!0,class:!0,href:!0});var MAt=s(D6);nbe=n(MAt,"SPAN",{});var EAt=s(nbe);T(Hy.$$.fragment,EAt),EAt.forEach(t),MAt.forEach(t),Pdr=i(kWe),sbe=n(kWe,"SPAN",{});var CAt=s(sbe);Bdr=r(CAt,"AutoModelForVision2Seq"),CAt.forEach(t),kWe.forEach(t),Aze=i(f),Xo=n(f,"DIV",{class:!0});var _l=s(Xo);T(Uy.$$.fragment,_l),Idr=i(_l),Ad=n(_l,"P",{});var Lte=s(Ad);Ndr=r(Lte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),tH=n(Lte,"A",{href:!0});var wAt=s(tH);qdr=r(wAt,"from_pretrained()"),wAt.forEach(t),jdr=r(Lte," class method or the "),aH=n(Lte,"A",{href:!0});var AAt=s(aH);Ddr=r(AAt,"from_config()"),AAt.forEach(t),Gdr=r(Lte,` class
method.`),Lte.forEach(t),Odr=i(_l),Jy=n(_l,"P",{});var SWe=s(Jy);Vdr=r(SWe,"This class cannot be instantiated directly using "),lbe=n(SWe,"CODE",{});var LAt=s(lbe);Xdr=r(LAt,"__init__()"),LAt.forEach(t),zdr=r(SWe," (throws an error)."),SWe.forEach(t),Qdr=i(_l),Tt=n(_l,"DIV",{class:!0});var Vw=s(Tt);T(Yy.$$.fragment,Vw),Wdr=i(Vw),ibe=n(Vw,"P",{});var yAt=s(ibe);Hdr=r(yAt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yAt.forEach(t),Udr=i(Vw),Ld=n(Vw,"P",{});var yte=s(Ld);Jdr=r(yte,`Note:
Loading a model from its configuration file does `),dbe=n(yte,"STRONG",{});var xAt=s(dbe);Ydr=r(xAt,"not"),xAt.forEach(t),Kdr=r(yte,` load the model weights. It only affects the
model\u2019s configuration. Use `),nH=n(yte,"A",{href:!0});var $At=s(nH);Zdr=r($At,"from_pretrained()"),$At.forEach(t),ecr=r(yte," to load the model weights."),yte.forEach(t),ocr=i(Vw),T(G6.$$.fragment,Vw),Vw.forEach(t),rcr=i(_l),co=n(_l,"DIV",{class:!0});var Fa=s(co);T(Ky.$$.fragment,Fa),tcr=i(Fa),cbe=n(Fa,"P",{});var kAt=s(cbe);acr=r(kAt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),kAt.forEach(t),ncr=i(Fa),Ha=n(Fa,"P",{});var Xw=s(Ha);scr=r(Xw,"The model class to instantiate is selected based on the "),fbe=n(Xw,"CODE",{});var SAt=s(fbe);lcr=r(SAt,"model_type"),SAt.forEach(t),icr=r(Xw,` property of the config object (either
passed as an argument or loaded from `),mbe=n(Xw,"CODE",{});var RAt=s(mbe);dcr=r(RAt,"pretrained_model_name_or_path"),RAt.forEach(t),ccr=r(Xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gbe=n(Xw,"CODE",{});var PAt=s(gbe);fcr=r(PAt,"pretrained_model_name_or_path"),PAt.forEach(t),mcr=r(Xw,":"),Xw.forEach(t),gcr=i(Fa),hbe=n(Fa,"UL",{});var BAt=s(hbe);O6=n(BAt,"LI",{});var GNe=s(O6);pbe=n(GNe,"STRONG",{});var IAt=s(pbe);hcr=r(IAt,"vision-encoder-decoder"),IAt.forEach(t),pcr=r(GNe," \u2014 "),sH=n(GNe,"A",{href:!0});var NAt=s(sH);_cr=r(NAt,"VisionEncoderDecoderModel"),NAt.forEach(t),ucr=r(GNe," (Vision Encoder decoder model)"),GNe.forEach(t),BAt.forEach(t),bcr=i(Fa),V6=n(Fa,"P",{});var ONe=s(V6);vcr=r(ONe,"The model is set in evaluation mode by default using "),_be=n(ONe,"CODE",{});var qAt=s(_be);Fcr=r(qAt,"model.eval()"),qAt.forEach(t),Tcr=r(ONe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ube=n(ONe,"CODE",{});var jAt=s(ube);Mcr=r(jAt,"model.train()"),jAt.forEach(t),ONe.forEach(t),Ecr=i(Fa),T(X6.$$.fragment,Fa),Fa.forEach(t),_l.forEach(t),Lze=i(f),yd=n(f,"H2",{class:!0});var RWe=s(yd);z6=n(RWe,"A",{id:!0,class:!0,href:!0});var DAt=s(z6);bbe=n(DAt,"SPAN",{});var GAt=s(bbe);T(Zy.$$.fragment,GAt),GAt.forEach(t),DAt.forEach(t),Ccr=i(RWe),vbe=n(RWe,"SPAN",{});var OAt=s(vbe);wcr=r(OAt,"AutoModelForVisualQuestionAnswering"),OAt.forEach(t),RWe.forEach(t),yze=i(f),zo=n(f,"DIV",{class:!0});var ul=s(zo);T(e8.$$.fragment,ul),Acr=i(ul),xd=n(ul,"P",{});var xte=s(xd);Lcr=r(xte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),lH=n(xte,"A",{href:!0});var VAt=s(lH);ycr=r(VAt,"from_pretrained()"),VAt.forEach(t),xcr=r(xte," class method or the "),iH=n(xte,"A",{href:!0});var XAt=s(iH);$cr=r(XAt,"from_config()"),XAt.forEach(t),kcr=r(xte,` class
method.`),xte.forEach(t),Scr=i(ul),o8=n(ul,"P",{});var PWe=s(o8);Rcr=r(PWe,"This class cannot be instantiated directly using "),Fbe=n(PWe,"CODE",{});var zAt=s(Fbe);Pcr=r(zAt,"__init__()"),zAt.forEach(t),Bcr=r(PWe," (throws an error)."),PWe.forEach(t),Icr=i(ul),Mt=n(ul,"DIV",{class:!0});var zw=s(Mt);T(r8.$$.fragment,zw),Ncr=i(zw),Tbe=n(zw,"P",{});var QAt=s(Tbe);qcr=r(QAt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),QAt.forEach(t),jcr=i(zw),$d=n(zw,"P",{});var $te=s($d);Dcr=r($te,`Note:
Loading a model from its configuration file does `),Mbe=n($te,"STRONG",{});var WAt=s(Mbe);Gcr=r(WAt,"not"),WAt.forEach(t),Ocr=r($te,` load the model weights. It only affects the
model\u2019s configuration. Use `),dH=n($te,"A",{href:!0});var HAt=s(dH);Vcr=r(HAt,"from_pretrained()"),HAt.forEach(t),Xcr=r($te," to load the model weights."),$te.forEach(t),zcr=i(zw),T(Q6.$$.fragment,zw),zw.forEach(t),Qcr=i(ul),fo=n(ul,"DIV",{class:!0});var Ta=s(fo);T(t8.$$.fragment,Ta),Wcr=i(Ta),Ebe=n(Ta,"P",{});var UAt=s(Ebe);Hcr=r(UAt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),UAt.forEach(t),Ucr=i(Ta),Ua=n(Ta,"P",{});var Qw=s(Ua);Jcr=r(Qw,"The model class to instantiate is selected based on the "),Cbe=n(Qw,"CODE",{});var JAt=s(Cbe);Ycr=r(JAt,"model_type"),JAt.forEach(t),Kcr=r(Qw,` property of the config object (either
passed as an argument or loaded from `),wbe=n(Qw,"CODE",{});var YAt=s(wbe);Zcr=r(YAt,"pretrained_model_name_or_path"),YAt.forEach(t),efr=r(Qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Abe=n(Qw,"CODE",{});var KAt=s(Abe);ofr=r(KAt,"pretrained_model_name_or_path"),KAt.forEach(t),rfr=r(Qw,":"),Qw.forEach(t),tfr=i(Ta),Lbe=n(Ta,"UL",{});var ZAt=s(Lbe);W6=n(ZAt,"LI",{});var VNe=s(W6);ybe=n(VNe,"STRONG",{});var eLt=s(ybe);afr=r(eLt,"vilt"),eLt.forEach(t),nfr=r(VNe," \u2014 "),cH=n(VNe,"A",{href:!0});var oLt=s(cH);sfr=r(oLt,"ViltForQuestionAnswering"),oLt.forEach(t),lfr=r(VNe," (ViLT model)"),VNe.forEach(t),ZAt.forEach(t),ifr=i(Ta),H6=n(Ta,"P",{});var XNe=s(H6);dfr=r(XNe,"The model is set in evaluation mode by default using "),xbe=n(XNe,"CODE",{});var rLt=s(xbe);cfr=r(rLt,"model.eval()"),rLt.forEach(t),ffr=r(XNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$be=n(XNe,"CODE",{});var tLt=s($be);mfr=r(tLt,"model.train()"),tLt.forEach(t),XNe.forEach(t),gfr=i(Ta),T(U6.$$.fragment,Ta),Ta.forEach(t),ul.forEach(t),xze=i(f),kd=n(f,"H2",{class:!0});var BWe=s(kd);J6=n(BWe,"A",{id:!0,class:!0,href:!0});var aLt=s(J6);kbe=n(aLt,"SPAN",{});var nLt=s(kbe);T(a8.$$.fragment,nLt),nLt.forEach(t),aLt.forEach(t),hfr=i(BWe),Sbe=n(BWe,"SPAN",{});var sLt=s(Sbe);pfr=r(sLt,"AutoModelForAudioClassification"),sLt.forEach(t),BWe.forEach(t),$ze=i(f),Qo=n(f,"DIV",{class:!0});var bl=s(Qo);T(n8.$$.fragment,bl),_fr=i(bl),Sd=n(bl,"P",{});var kte=s(Sd);ufr=r(kte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),fH=n(kte,"A",{href:!0});var lLt=s(fH);bfr=r(lLt,"from_pretrained()"),lLt.forEach(t),vfr=r(kte," class method or the "),mH=n(kte,"A",{href:!0});var iLt=s(mH);Ffr=r(iLt,"from_config()"),iLt.forEach(t),Tfr=r(kte,` class
method.`),kte.forEach(t),Mfr=i(bl),s8=n(bl,"P",{});var IWe=s(s8);Efr=r(IWe,"This class cannot be instantiated directly using "),Rbe=n(IWe,"CODE",{});var dLt=s(Rbe);Cfr=r(dLt,"__init__()"),dLt.forEach(t),wfr=r(IWe," (throws an error)."),IWe.forEach(t),Afr=i(bl),Et=n(bl,"DIV",{class:!0});var Ww=s(Et);T(l8.$$.fragment,Ww),Lfr=i(Ww),Pbe=n(Ww,"P",{});var cLt=s(Pbe);yfr=r(cLt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),cLt.forEach(t),xfr=i(Ww),Rd=n(Ww,"P",{});var Ste=s(Rd);$fr=r(Ste,`Note:
Loading a model from its configuration file does `),Bbe=n(Ste,"STRONG",{});var fLt=s(Bbe);kfr=r(fLt,"not"),fLt.forEach(t),Sfr=r(Ste,` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=n(Ste,"A",{href:!0});var mLt=s(gH);Rfr=r(mLt,"from_pretrained()"),mLt.forEach(t),Pfr=r(Ste," to load the model weights."),Ste.forEach(t),Bfr=i(Ww),T(Y6.$$.fragment,Ww),Ww.forEach(t),Ifr=i(bl),mo=n(bl,"DIV",{class:!0});var Ma=s(mo);T(i8.$$.fragment,Ma),Nfr=i(Ma),Ibe=n(Ma,"P",{});var gLt=s(Ibe);qfr=r(gLt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),gLt.forEach(t),jfr=i(Ma),Ja=n(Ma,"P",{});var Hw=s(Ja);Dfr=r(Hw,"The model class to instantiate is selected based on the "),Nbe=n(Hw,"CODE",{});var hLt=s(Nbe);Gfr=r(hLt,"model_type"),hLt.forEach(t),Ofr=r(Hw,` property of the config object (either
passed as an argument or loaded from `),qbe=n(Hw,"CODE",{});var pLt=s(qbe);Vfr=r(pLt,"pretrained_model_name_or_path"),pLt.forEach(t),Xfr=r(Hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jbe=n(Hw,"CODE",{});var _Lt=s(jbe);zfr=r(_Lt,"pretrained_model_name_or_path"),_Lt.forEach(t),Qfr=r(Hw,":"),Hw.forEach(t),Wfr=i(Ma),Pe=n(Ma,"UL",{});var Qe=s(Pe);K6=n(Qe,"LI",{});var zNe=s(K6);Dbe=n(zNe,"STRONG",{});var uLt=s(Dbe);Hfr=r(uLt,"data2vec-audio"),uLt.forEach(t),Ufr=r(zNe," \u2014 "),hH=n(zNe,"A",{href:!0});var bLt=s(hH);Jfr=r(bLt,"Data2VecAudioForSequenceClassification"),bLt.forEach(t),Yfr=r(zNe," (Data2VecAudio model)"),zNe.forEach(t),Kfr=i(Qe),Z6=n(Qe,"LI",{});var QNe=s(Z6);Gbe=n(QNe,"STRONG",{});var vLt=s(Gbe);Zfr=r(vLt,"hubert"),vLt.forEach(t),emr=r(QNe," \u2014 "),pH=n(QNe,"A",{href:!0});var FLt=s(pH);omr=r(FLt,"HubertForSequenceClassification"),FLt.forEach(t),rmr=r(QNe," (Hubert model)"),QNe.forEach(t),tmr=i(Qe),eT=n(Qe,"LI",{});var WNe=s(eT);Obe=n(WNe,"STRONG",{});var TLt=s(Obe);amr=r(TLt,"sew"),TLt.forEach(t),nmr=r(WNe," \u2014 "),_H=n(WNe,"A",{href:!0});var MLt=s(_H);smr=r(MLt,"SEWForSequenceClassification"),MLt.forEach(t),lmr=r(WNe," (SEW model)"),WNe.forEach(t),imr=i(Qe),oT=n(Qe,"LI",{});var HNe=s(oT);Vbe=n(HNe,"STRONG",{});var ELt=s(Vbe);dmr=r(ELt,"sew-d"),ELt.forEach(t),cmr=r(HNe," \u2014 "),uH=n(HNe,"A",{href:!0});var CLt=s(uH);fmr=r(CLt,"SEWDForSequenceClassification"),CLt.forEach(t),mmr=r(HNe," (SEW-D model)"),HNe.forEach(t),gmr=i(Qe),rT=n(Qe,"LI",{});var UNe=s(rT);Xbe=n(UNe,"STRONG",{});var wLt=s(Xbe);hmr=r(wLt,"unispeech"),wLt.forEach(t),pmr=r(UNe," \u2014 "),bH=n(UNe,"A",{href:!0});var ALt=s(bH);_mr=r(ALt,"UniSpeechForSequenceClassification"),ALt.forEach(t),umr=r(UNe," (UniSpeech model)"),UNe.forEach(t),bmr=i(Qe),tT=n(Qe,"LI",{});var JNe=s(tT);zbe=n(JNe,"STRONG",{});var LLt=s(zbe);vmr=r(LLt,"unispeech-sat"),LLt.forEach(t),Fmr=r(JNe," \u2014 "),vH=n(JNe,"A",{href:!0});var yLt=s(vH);Tmr=r(yLt,"UniSpeechSatForSequenceClassification"),yLt.forEach(t),Mmr=r(JNe," (UniSpeechSat model)"),JNe.forEach(t),Emr=i(Qe),aT=n(Qe,"LI",{});var YNe=s(aT);Qbe=n(YNe,"STRONG",{});var xLt=s(Qbe);Cmr=r(xLt,"wav2vec2"),xLt.forEach(t),wmr=r(YNe," \u2014 "),FH=n(YNe,"A",{href:!0});var $Lt=s(FH);Amr=r($Lt,"Wav2Vec2ForSequenceClassification"),$Lt.forEach(t),Lmr=r(YNe," (Wav2Vec2 model)"),YNe.forEach(t),ymr=i(Qe),nT=n(Qe,"LI",{});var KNe=s(nT);Wbe=n(KNe,"STRONG",{});var kLt=s(Wbe);xmr=r(kLt,"wav2vec2-conformer"),kLt.forEach(t),$mr=r(KNe," \u2014 "),TH=n(KNe,"A",{href:!0});var SLt=s(TH);kmr=r(SLt,"Wav2Vec2ConformerForSequenceClassification"),SLt.forEach(t),Smr=r(KNe," (Wav2Vec2-Conformer model)"),KNe.forEach(t),Rmr=i(Qe),sT=n(Qe,"LI",{});var ZNe=s(sT);Hbe=n(ZNe,"STRONG",{});var RLt=s(Hbe);Pmr=r(RLt,"wavlm"),RLt.forEach(t),Bmr=r(ZNe," \u2014 "),MH=n(ZNe,"A",{href:!0});var PLt=s(MH);Imr=r(PLt,"WavLMForSequenceClassification"),PLt.forEach(t),Nmr=r(ZNe," (WavLM model)"),ZNe.forEach(t),Qe.forEach(t),qmr=i(Ma),lT=n(Ma,"P",{});var eqe=s(lT);jmr=r(eqe,"The model is set in evaluation mode by default using "),Ube=n(eqe,"CODE",{});var BLt=s(Ube);Dmr=r(BLt,"model.eval()"),BLt.forEach(t),Gmr=r(eqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=n(eqe,"CODE",{});var ILt=s(Jbe);Omr=r(ILt,"model.train()"),ILt.forEach(t),eqe.forEach(t),Vmr=i(Ma),T(iT.$$.fragment,Ma),Ma.forEach(t),bl.forEach(t),kze=i(f),Pd=n(f,"H2",{class:!0});var NWe=s(Pd);dT=n(NWe,"A",{id:!0,class:!0,href:!0});var NLt=s(dT);Ybe=n(NLt,"SPAN",{});var qLt=s(Ybe);T(d8.$$.fragment,qLt),qLt.forEach(t),NLt.forEach(t),Xmr=i(NWe),Kbe=n(NWe,"SPAN",{});var jLt=s(Kbe);zmr=r(jLt,"AutoModelForAudioFrameClassification"),jLt.forEach(t),NWe.forEach(t),Sze=i(f),Wo=n(f,"DIV",{class:!0});var vl=s(Wo);T(c8.$$.fragment,vl),Qmr=i(vl),Bd=n(vl,"P",{});var Rte=s(Bd);Wmr=r(Rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),EH=n(Rte,"A",{href:!0});var DLt=s(EH);Hmr=r(DLt,"from_pretrained()"),DLt.forEach(t),Umr=r(Rte," class method or the "),CH=n(Rte,"A",{href:!0});var GLt=s(CH);Jmr=r(GLt,"from_config()"),GLt.forEach(t),Ymr=r(Rte,` class
method.`),Rte.forEach(t),Kmr=i(vl),f8=n(vl,"P",{});var qWe=s(f8);Zmr=r(qWe,"This class cannot be instantiated directly using "),Zbe=n(qWe,"CODE",{});var OLt=s(Zbe);egr=r(OLt,"__init__()"),OLt.forEach(t),ogr=r(qWe," (throws an error)."),qWe.forEach(t),rgr=i(vl),Ct=n(vl,"DIV",{class:!0});var Uw=s(Ct);T(m8.$$.fragment,Uw),tgr=i(Uw),eve=n(Uw,"P",{});var VLt=s(eve);agr=r(VLt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),VLt.forEach(t),ngr=i(Uw),Id=n(Uw,"P",{});var Pte=s(Id);sgr=r(Pte,`Note:
Loading a model from its configuration file does `),ove=n(Pte,"STRONG",{});var XLt=s(ove);lgr=r(XLt,"not"),XLt.forEach(t),igr=r(Pte,` load the model weights. It only affects the
model\u2019s configuration. Use `),wH=n(Pte,"A",{href:!0});var zLt=s(wH);dgr=r(zLt,"from_pretrained()"),zLt.forEach(t),cgr=r(Pte," to load the model weights."),Pte.forEach(t),fgr=i(Uw),T(cT.$$.fragment,Uw),Uw.forEach(t),mgr=i(vl),go=n(vl,"DIV",{class:!0});var Ea=s(go);T(g8.$$.fragment,Ea),ggr=i(Ea),rve=n(Ea,"P",{});var QLt=s(rve);hgr=r(QLt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),QLt.forEach(t),pgr=i(Ea),Ya=n(Ea,"P",{});var Jw=s(Ya);_gr=r(Jw,"The model class to instantiate is selected based on the "),tve=n(Jw,"CODE",{});var WLt=s(tve);ugr=r(WLt,"model_type"),WLt.forEach(t),bgr=r(Jw,` property of the config object (either
passed as an argument or loaded from `),ave=n(Jw,"CODE",{});var HLt=s(ave);vgr=r(HLt,"pretrained_model_name_or_path"),HLt.forEach(t),Fgr=r(Jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=n(Jw,"CODE",{});var ULt=s(nve);Tgr=r(ULt,"pretrained_model_name_or_path"),ULt.forEach(t),Mgr=r(Jw,":"),Jw.forEach(t),Egr=i(Ea),rt=n(Ea,"UL",{});var Fl=s(rt);fT=n(Fl,"LI",{});var oqe=s(fT);sve=n(oqe,"STRONG",{});var JLt=s(sve);Cgr=r(JLt,"data2vec-audio"),JLt.forEach(t),wgr=r(oqe," \u2014 "),AH=n(oqe,"A",{href:!0});var YLt=s(AH);Agr=r(YLt,"Data2VecAudioForAudioFrameClassification"),YLt.forEach(t),Lgr=r(oqe," (Data2VecAudio model)"),oqe.forEach(t),ygr=i(Fl),mT=n(Fl,"LI",{});var rqe=s(mT);lve=n(rqe,"STRONG",{});var KLt=s(lve);xgr=r(KLt,"unispeech-sat"),KLt.forEach(t),$gr=r(rqe," \u2014 "),LH=n(rqe,"A",{href:!0});var ZLt=s(LH);kgr=r(ZLt,"UniSpeechSatForAudioFrameClassification"),ZLt.forEach(t),Sgr=r(rqe," (UniSpeechSat model)"),rqe.forEach(t),Rgr=i(Fl),gT=n(Fl,"LI",{});var tqe=s(gT);ive=n(tqe,"STRONG",{});var eyt=s(ive);Pgr=r(eyt,"wav2vec2"),eyt.forEach(t),Bgr=r(tqe," \u2014 "),yH=n(tqe,"A",{href:!0});var oyt=s(yH);Igr=r(oyt,"Wav2Vec2ForAudioFrameClassification"),oyt.forEach(t),Ngr=r(tqe," (Wav2Vec2 model)"),tqe.forEach(t),qgr=i(Fl),hT=n(Fl,"LI",{});var aqe=s(hT);dve=n(aqe,"STRONG",{});var ryt=s(dve);jgr=r(ryt,"wav2vec2-conformer"),ryt.forEach(t),Dgr=r(aqe," \u2014 "),xH=n(aqe,"A",{href:!0});var tyt=s(xH);Ggr=r(tyt,"Wav2Vec2ConformerForAudioFrameClassification"),tyt.forEach(t),Ogr=r(aqe," (Wav2Vec2-Conformer model)"),aqe.forEach(t),Vgr=i(Fl),pT=n(Fl,"LI",{});var nqe=s(pT);cve=n(nqe,"STRONG",{});var ayt=s(cve);Xgr=r(ayt,"wavlm"),ayt.forEach(t),zgr=r(nqe," \u2014 "),$H=n(nqe,"A",{href:!0});var nyt=s($H);Qgr=r(nyt,"WavLMForAudioFrameClassification"),nyt.forEach(t),Wgr=r(nqe," (WavLM model)"),nqe.forEach(t),Fl.forEach(t),Hgr=i(Ea),_T=n(Ea,"P",{});var sqe=s(_T);Ugr=r(sqe,"The model is set in evaluation mode by default using "),fve=n(sqe,"CODE",{});var syt=s(fve);Jgr=r(syt,"model.eval()"),syt.forEach(t),Ygr=r(sqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mve=n(sqe,"CODE",{});var lyt=s(mve);Kgr=r(lyt,"model.train()"),lyt.forEach(t),sqe.forEach(t),Zgr=i(Ea),T(uT.$$.fragment,Ea),Ea.forEach(t),vl.forEach(t),Rze=i(f),Nd=n(f,"H2",{class:!0});var jWe=s(Nd);bT=n(jWe,"A",{id:!0,class:!0,href:!0});var iyt=s(bT);gve=n(iyt,"SPAN",{});var dyt=s(gve);T(h8.$$.fragment,dyt),dyt.forEach(t),iyt.forEach(t),ehr=i(jWe),hve=n(jWe,"SPAN",{});var cyt=s(hve);ohr=r(cyt,"AutoModelForCTC"),cyt.forEach(t),jWe.forEach(t),Pze=i(f),Ho=n(f,"DIV",{class:!0});var Tl=s(Ho);T(p8.$$.fragment,Tl),rhr=i(Tl),qd=n(Tl,"P",{});var Bte=s(qd);thr=r(Bte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),kH=n(Bte,"A",{href:!0});var fyt=s(kH);ahr=r(fyt,"from_pretrained()"),fyt.forEach(t),nhr=r(Bte," class method or the "),SH=n(Bte,"A",{href:!0});var myt=s(SH);shr=r(myt,"from_config()"),myt.forEach(t),lhr=r(Bte,` class
method.`),Bte.forEach(t),ihr=i(Tl),_8=n(Tl,"P",{});var DWe=s(_8);dhr=r(DWe,"This class cannot be instantiated directly using "),pve=n(DWe,"CODE",{});var gyt=s(pve);chr=r(gyt,"__init__()"),gyt.forEach(t),fhr=r(DWe," (throws an error)."),DWe.forEach(t),mhr=i(Tl),wt=n(Tl,"DIV",{class:!0});var Yw=s(wt);T(u8.$$.fragment,Yw),ghr=i(Yw),_ve=n(Yw,"P",{});var hyt=s(_ve);hhr=r(hyt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),hyt.forEach(t),phr=i(Yw),jd=n(Yw,"P",{});var Ite=s(jd);_hr=r(Ite,`Note:
Loading a model from its configuration file does `),uve=n(Ite,"STRONG",{});var pyt=s(uve);uhr=r(pyt,"not"),pyt.forEach(t),bhr=r(Ite,` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=n(Ite,"A",{href:!0});var _yt=s(RH);vhr=r(_yt,"from_pretrained()"),_yt.forEach(t),Fhr=r(Ite," to load the model weights."),Ite.forEach(t),Thr=i(Yw),T(vT.$$.fragment,Yw),Yw.forEach(t),Mhr=i(Tl),ho=n(Tl,"DIV",{class:!0});var Ca=s(ho);T(b8.$$.fragment,Ca),Ehr=i(Ca),bve=n(Ca,"P",{});var uyt=s(bve);Chr=r(uyt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),uyt.forEach(t),whr=i(Ca),Ka=n(Ca,"P",{});var Kw=s(Ka);Ahr=r(Kw,"The model class to instantiate is selected based on the "),vve=n(Kw,"CODE",{});var byt=s(vve);Lhr=r(byt,"model_type"),byt.forEach(t),yhr=r(Kw,` property of the config object (either
passed as an argument or loaded from `),Fve=n(Kw,"CODE",{});var vyt=s(Fve);xhr=r(vyt,"pretrained_model_name_or_path"),vyt.forEach(t),$hr=r(Kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tve=n(Kw,"CODE",{});var Fyt=s(Tve);khr=r(Fyt,"pretrained_model_name_or_path"),Fyt.forEach(t),Shr=r(Kw,":"),Kw.forEach(t),Rhr=i(Ca),Le=n(Ca,"UL",{});var Be=s(Le);FT=n(Be,"LI",{});var lqe=s(FT);Mve=n(lqe,"STRONG",{});var Tyt=s(Mve);Phr=r(Tyt,"data2vec-audio"),Tyt.forEach(t),Bhr=r(lqe," \u2014 "),PH=n(lqe,"A",{href:!0});var Myt=s(PH);Ihr=r(Myt,"Data2VecAudioForCTC"),Myt.forEach(t),Nhr=r(lqe," (Data2VecAudio model)"),lqe.forEach(t),qhr=i(Be),TT=n(Be,"LI",{});var iqe=s(TT);Eve=n(iqe,"STRONG",{});var Eyt=s(Eve);jhr=r(Eyt,"hubert"),Eyt.forEach(t),Dhr=r(iqe," \u2014 "),BH=n(iqe,"A",{href:!0});var Cyt=s(BH);Ghr=r(Cyt,"HubertForCTC"),Cyt.forEach(t),Ohr=r(iqe," (Hubert model)"),iqe.forEach(t),Vhr=i(Be),MT=n(Be,"LI",{});var dqe=s(MT);Cve=n(dqe,"STRONG",{});var wyt=s(Cve);Xhr=r(wyt,"mctct"),wyt.forEach(t),zhr=r(dqe," \u2014 "),IH=n(dqe,"A",{href:!0});var Ayt=s(IH);Qhr=r(Ayt,"MCTCTForCTC"),Ayt.forEach(t),Whr=r(dqe," (M-CTC-T model)"),dqe.forEach(t),Hhr=i(Be),ET=n(Be,"LI",{});var cqe=s(ET);wve=n(cqe,"STRONG",{});var Lyt=s(wve);Uhr=r(Lyt,"sew"),Lyt.forEach(t),Jhr=r(cqe," \u2014 "),NH=n(cqe,"A",{href:!0});var yyt=s(NH);Yhr=r(yyt,"SEWForCTC"),yyt.forEach(t),Khr=r(cqe," (SEW model)"),cqe.forEach(t),Zhr=i(Be),CT=n(Be,"LI",{});var fqe=s(CT);Ave=n(fqe,"STRONG",{});var xyt=s(Ave);epr=r(xyt,"sew-d"),xyt.forEach(t),opr=r(fqe," \u2014 "),qH=n(fqe,"A",{href:!0});var $yt=s(qH);rpr=r($yt,"SEWDForCTC"),$yt.forEach(t),tpr=r(fqe," (SEW-D model)"),fqe.forEach(t),apr=i(Be),wT=n(Be,"LI",{});var mqe=s(wT);Lve=n(mqe,"STRONG",{});var kyt=s(Lve);npr=r(kyt,"unispeech"),kyt.forEach(t),spr=r(mqe," \u2014 "),jH=n(mqe,"A",{href:!0});var Syt=s(jH);lpr=r(Syt,"UniSpeechForCTC"),Syt.forEach(t),ipr=r(mqe," (UniSpeech model)"),mqe.forEach(t),dpr=i(Be),AT=n(Be,"LI",{});var gqe=s(AT);yve=n(gqe,"STRONG",{});var Ryt=s(yve);cpr=r(Ryt,"unispeech-sat"),Ryt.forEach(t),fpr=r(gqe," \u2014 "),DH=n(gqe,"A",{href:!0});var Pyt=s(DH);mpr=r(Pyt,"UniSpeechSatForCTC"),Pyt.forEach(t),gpr=r(gqe," (UniSpeechSat model)"),gqe.forEach(t),hpr=i(Be),LT=n(Be,"LI",{});var hqe=s(LT);xve=n(hqe,"STRONG",{});var Byt=s(xve);ppr=r(Byt,"wav2vec2"),Byt.forEach(t),_pr=r(hqe," \u2014 "),GH=n(hqe,"A",{href:!0});var Iyt=s(GH);upr=r(Iyt,"Wav2Vec2ForCTC"),Iyt.forEach(t),bpr=r(hqe," (Wav2Vec2 model)"),hqe.forEach(t),vpr=i(Be),yT=n(Be,"LI",{});var pqe=s(yT);$ve=n(pqe,"STRONG",{});var Nyt=s($ve);Fpr=r(Nyt,"wav2vec2-conformer"),Nyt.forEach(t),Tpr=r(pqe," \u2014 "),OH=n(pqe,"A",{href:!0});var qyt=s(OH);Mpr=r(qyt,"Wav2Vec2ConformerForCTC"),qyt.forEach(t),Epr=r(pqe," (Wav2Vec2-Conformer model)"),pqe.forEach(t),Cpr=i(Be),xT=n(Be,"LI",{});var _qe=s(xT);kve=n(_qe,"STRONG",{});var jyt=s(kve);wpr=r(jyt,"wavlm"),jyt.forEach(t),Apr=r(_qe," \u2014 "),VH=n(_qe,"A",{href:!0});var Dyt=s(VH);Lpr=r(Dyt,"WavLMForCTC"),Dyt.forEach(t),ypr=r(_qe," (WavLM model)"),_qe.forEach(t),Be.forEach(t),xpr=i(Ca),$T=n(Ca,"P",{});var uqe=s($T);$pr=r(uqe,"The model is set in evaluation mode by default using "),Sve=n(uqe,"CODE",{});var Gyt=s(Sve);kpr=r(Gyt,"model.eval()"),Gyt.forEach(t),Spr=r(uqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rve=n(uqe,"CODE",{});var Oyt=s(Rve);Rpr=r(Oyt,"model.train()"),Oyt.forEach(t),uqe.forEach(t),Ppr=i(Ca),T(kT.$$.fragment,Ca),Ca.forEach(t),Tl.forEach(t),Bze=i(f),Dd=n(f,"H2",{class:!0});var GWe=s(Dd);ST=n(GWe,"A",{id:!0,class:!0,href:!0});var Vyt=s(ST);Pve=n(Vyt,"SPAN",{});var Xyt=s(Pve);T(v8.$$.fragment,Xyt),Xyt.forEach(t),Vyt.forEach(t),Bpr=i(GWe),Bve=n(GWe,"SPAN",{});var zyt=s(Bve);Ipr=r(zyt,"AutoModelForSpeechSeq2Seq"),zyt.forEach(t),GWe.forEach(t),Ize=i(f),Uo=n(f,"DIV",{class:!0});var Ml=s(Uo);T(F8.$$.fragment,Ml),Npr=i(Ml),Gd=n(Ml,"P",{});var Nte=s(Gd);qpr=r(Nte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),XH=n(Nte,"A",{href:!0});var Qyt=s(XH);jpr=r(Qyt,"from_pretrained()"),Qyt.forEach(t),Dpr=r(Nte," class method or the "),zH=n(Nte,"A",{href:!0});var Wyt=s(zH);Gpr=r(Wyt,"from_config()"),Wyt.forEach(t),Opr=r(Nte,` class
method.`),Nte.forEach(t),Vpr=i(Ml),T8=n(Ml,"P",{});var OWe=s(T8);Xpr=r(OWe,"This class cannot be instantiated directly using "),Ive=n(OWe,"CODE",{});var Hyt=s(Ive);zpr=r(Hyt,"__init__()"),Hyt.forEach(t),Qpr=r(OWe," (throws an error)."),OWe.forEach(t),Wpr=i(Ml),At=n(Ml,"DIV",{class:!0});var Zw=s(At);T(M8.$$.fragment,Zw),Hpr=i(Zw),Nve=n(Zw,"P",{});var Uyt=s(Nve);Upr=r(Uyt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Uyt.forEach(t),Jpr=i(Zw),Od=n(Zw,"P",{});var qte=s(Od);Ypr=r(qte,`Note:
Loading a model from its configuration file does `),qve=n(qte,"STRONG",{});var Jyt=s(qve);Kpr=r(Jyt,"not"),Jyt.forEach(t),Zpr=r(qte,` load the model weights. It only affects the
model\u2019s configuration. Use `),QH=n(qte,"A",{href:!0});var Yyt=s(QH);e_r=r(Yyt,"from_pretrained()"),Yyt.forEach(t),o_r=r(qte," to load the model weights."),qte.forEach(t),r_r=i(Zw),T(RT.$$.fragment,Zw),Zw.forEach(t),t_r=i(Ml),po=n(Ml,"DIV",{class:!0});var wa=s(po);T(E8.$$.fragment,wa),a_r=i(wa),jve=n(wa,"P",{});var Kyt=s(jve);n_r=r(Kyt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Kyt.forEach(t),s_r=i(wa),Za=n(wa,"P",{});var eA=s(Za);l_r=r(eA,"The model class to instantiate is selected based on the "),Dve=n(eA,"CODE",{});var Zyt=s(Dve);i_r=r(Zyt,"model_type"),Zyt.forEach(t),d_r=r(eA,` property of the config object (either
passed as an argument or loaded from `),Gve=n(eA,"CODE",{});var e8t=s(Gve);c_r=r(e8t,"pretrained_model_name_or_path"),e8t.forEach(t),f_r=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ove=n(eA,"CODE",{});var o8t=s(Ove);m_r=r(o8t,"pretrained_model_name_or_path"),o8t.forEach(t),g_r=r(eA,":"),eA.forEach(t),h_r=i(wa),C8=n(wa,"UL",{});var VWe=s(C8);PT=n(VWe,"LI",{});var bqe=s(PT);Vve=n(bqe,"STRONG",{});var r8t=s(Vve);p_r=r(r8t,"speech-encoder-decoder"),r8t.forEach(t),__r=r(bqe," \u2014 "),WH=n(bqe,"A",{href:!0});var t8t=s(WH);u_r=r(t8t,"SpeechEncoderDecoderModel"),t8t.forEach(t),b_r=r(bqe," (Speech Encoder decoder model)"),bqe.forEach(t),v_r=i(VWe),BT=n(VWe,"LI",{});var vqe=s(BT);Xve=n(vqe,"STRONG",{});var a8t=s(Xve);F_r=r(a8t,"speech_to_text"),a8t.forEach(t),T_r=r(vqe," \u2014 "),HH=n(vqe,"A",{href:!0});var n8t=s(HH);M_r=r(n8t,"Speech2TextForConditionalGeneration"),n8t.forEach(t),E_r=r(vqe," (Speech2Text model)"),vqe.forEach(t),VWe.forEach(t),C_r=i(wa),IT=n(wa,"P",{});var Fqe=s(IT);w_r=r(Fqe,"The model is set in evaluation mode by default using "),zve=n(Fqe,"CODE",{});var s8t=s(zve);A_r=r(s8t,"model.eval()"),s8t.forEach(t),L_r=r(Fqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qve=n(Fqe,"CODE",{});var l8t=s(Qve);y_r=r(l8t,"model.train()"),l8t.forEach(t),Fqe.forEach(t),x_r=i(wa),T(NT.$$.fragment,wa),wa.forEach(t),Ml.forEach(t),Nze=i(f),Vd=n(f,"H2",{class:!0});var XWe=s(Vd);qT=n(XWe,"A",{id:!0,class:!0,href:!0});var i8t=s(qT);Wve=n(i8t,"SPAN",{});var d8t=s(Wve);T(w8.$$.fragment,d8t),d8t.forEach(t),i8t.forEach(t),$_r=i(XWe),Hve=n(XWe,"SPAN",{});var c8t=s(Hve);k_r=r(c8t,"AutoModelForAudioXVector"),c8t.forEach(t),XWe.forEach(t),qze=i(f),Jo=n(f,"DIV",{class:!0});var El=s(Jo);T(A8.$$.fragment,El),S_r=i(El),Xd=n(El,"P",{});var jte=s(Xd);R_r=r(jte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),UH=n(jte,"A",{href:!0});var f8t=s(UH);P_r=r(f8t,"from_pretrained()"),f8t.forEach(t),B_r=r(jte," class method or the "),JH=n(jte,"A",{href:!0});var m8t=s(JH);I_r=r(m8t,"from_config()"),m8t.forEach(t),N_r=r(jte,` class
method.`),jte.forEach(t),q_r=i(El),L8=n(El,"P",{});var zWe=s(L8);j_r=r(zWe,"This class cannot be instantiated directly using "),Uve=n(zWe,"CODE",{});var g8t=s(Uve);D_r=r(g8t,"__init__()"),g8t.forEach(t),G_r=r(zWe," (throws an error)."),zWe.forEach(t),O_r=i(El),Lt=n(El,"DIV",{class:!0});var oA=s(Lt);T(y8.$$.fragment,oA),V_r=i(oA),Jve=n(oA,"P",{});var h8t=s(Jve);X_r=r(h8t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),h8t.forEach(t),z_r=i(oA),zd=n(oA,"P",{});var Dte=s(zd);Q_r=r(Dte,`Note:
Loading a model from its configuration file does `),Yve=n(Dte,"STRONG",{});var p8t=s(Yve);W_r=r(p8t,"not"),p8t.forEach(t),H_r=r(Dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),YH=n(Dte,"A",{href:!0});var _8t=s(YH);U_r=r(_8t,"from_pretrained()"),_8t.forEach(t),J_r=r(Dte," to load the model weights."),Dte.forEach(t),Y_r=i(oA),T(jT.$$.fragment,oA),oA.forEach(t),K_r=i(El),_o=n(El,"DIV",{class:!0});var Aa=s(_o);T(x8.$$.fragment,Aa),Z_r=i(Aa),Kve=n(Aa,"P",{});var u8t=s(Kve);eur=r(u8t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),u8t.forEach(t),our=i(Aa),en=n(Aa,"P",{});var rA=s(en);rur=r(rA,"The model class to instantiate is selected based on the "),Zve=n(rA,"CODE",{});var b8t=s(Zve);tur=r(b8t,"model_type"),b8t.forEach(t),aur=r(rA,` property of the config object (either
passed as an argument or loaded from `),eFe=n(rA,"CODE",{});var v8t=s(eFe);nur=r(v8t,"pretrained_model_name_or_path"),v8t.forEach(t),sur=r(rA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=n(rA,"CODE",{});var F8t=s(oFe);lur=r(F8t,"pretrained_model_name_or_path"),F8t.forEach(t),iur=r(rA,":"),rA.forEach(t),dur=i(Aa),tt=n(Aa,"UL",{});var Cl=s(tt);DT=n(Cl,"LI",{});var Tqe=s(DT);rFe=n(Tqe,"STRONG",{});var T8t=s(rFe);cur=r(T8t,"data2vec-audio"),T8t.forEach(t),fur=r(Tqe," \u2014 "),KH=n(Tqe,"A",{href:!0});var M8t=s(KH);mur=r(M8t,"Data2VecAudioForXVector"),M8t.forEach(t),gur=r(Tqe," (Data2VecAudio model)"),Tqe.forEach(t),hur=i(Cl),GT=n(Cl,"LI",{});var Mqe=s(GT);tFe=n(Mqe,"STRONG",{});var E8t=s(tFe);pur=r(E8t,"unispeech-sat"),E8t.forEach(t),_ur=r(Mqe," \u2014 "),ZH=n(Mqe,"A",{href:!0});var C8t=s(ZH);uur=r(C8t,"UniSpeechSatForXVector"),C8t.forEach(t),bur=r(Mqe," (UniSpeechSat model)"),Mqe.forEach(t),vur=i(Cl),OT=n(Cl,"LI",{});var Eqe=s(OT);aFe=n(Eqe,"STRONG",{});var w8t=s(aFe);Fur=r(w8t,"wav2vec2"),w8t.forEach(t),Tur=r(Eqe," \u2014 "),eU=n(Eqe,"A",{href:!0});var A8t=s(eU);Mur=r(A8t,"Wav2Vec2ForXVector"),A8t.forEach(t),Eur=r(Eqe," (Wav2Vec2 model)"),Eqe.forEach(t),Cur=i(Cl),VT=n(Cl,"LI",{});var Cqe=s(VT);nFe=n(Cqe,"STRONG",{});var L8t=s(nFe);wur=r(L8t,"wav2vec2-conformer"),L8t.forEach(t),Aur=r(Cqe," \u2014 "),oU=n(Cqe,"A",{href:!0});var y8t=s(oU);Lur=r(y8t,"Wav2Vec2ConformerForXVector"),y8t.forEach(t),yur=r(Cqe," (Wav2Vec2-Conformer model)"),Cqe.forEach(t),xur=i(Cl),XT=n(Cl,"LI",{});var wqe=s(XT);sFe=n(wqe,"STRONG",{});var x8t=s(sFe);$ur=r(x8t,"wavlm"),x8t.forEach(t),kur=r(wqe," \u2014 "),rU=n(wqe,"A",{href:!0});var $8t=s(rU);Sur=r($8t,"WavLMForXVector"),$8t.forEach(t),Rur=r(wqe," (WavLM model)"),wqe.forEach(t),Cl.forEach(t),Pur=i(Aa),zT=n(Aa,"P",{});var Aqe=s(zT);Bur=r(Aqe,"The model is set in evaluation mode by default using "),lFe=n(Aqe,"CODE",{});var k8t=s(lFe);Iur=r(k8t,"model.eval()"),k8t.forEach(t),Nur=r(Aqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iFe=n(Aqe,"CODE",{});var S8t=s(iFe);qur=r(S8t,"model.train()"),S8t.forEach(t),Aqe.forEach(t),jur=i(Aa),T(QT.$$.fragment,Aa),Aa.forEach(t),El.forEach(t),jze=i(f),Qd=n(f,"H2",{class:!0});var QWe=s(Qd);WT=n(QWe,"A",{id:!0,class:!0,href:!0});var R8t=s(WT);dFe=n(R8t,"SPAN",{});var P8t=s(dFe);T($8.$$.fragment,P8t),P8t.forEach(t),R8t.forEach(t),Dur=i(QWe),cFe=n(QWe,"SPAN",{});var B8t=s(cFe);Gur=r(B8t,"AutoModelForMaskedImageModeling"),B8t.forEach(t),QWe.forEach(t),Dze=i(f),Yo=n(f,"DIV",{class:!0});var wl=s(Yo);T(k8.$$.fragment,wl),Our=i(wl),Wd=n(wl,"P",{});var Gte=s(Wd);Vur=r(Gte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),tU=n(Gte,"A",{href:!0});var I8t=s(tU);Xur=r(I8t,"from_pretrained()"),I8t.forEach(t),zur=r(Gte," class method or the "),aU=n(Gte,"A",{href:!0});var N8t=s(aU);Qur=r(N8t,"from_config()"),N8t.forEach(t),Wur=r(Gte,` class
method.`),Gte.forEach(t),Hur=i(wl),S8=n(wl,"P",{});var WWe=s(S8);Uur=r(WWe,"This class cannot be instantiated directly using "),fFe=n(WWe,"CODE",{});var q8t=s(fFe);Jur=r(q8t,"__init__()"),q8t.forEach(t),Yur=r(WWe," (throws an error)."),WWe.forEach(t),Kur=i(wl),yt=n(wl,"DIV",{class:!0});var tA=s(yt);T(R8.$$.fragment,tA),Zur=i(tA),mFe=n(tA,"P",{});var j8t=s(mFe);e1r=r(j8t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),j8t.forEach(t),o1r=i(tA),Hd=n(tA,"P",{});var Ote=s(Hd);r1r=r(Ote,`Note:
Loading a model from its configuration file does `),gFe=n(Ote,"STRONG",{});var D8t=s(gFe);t1r=r(D8t,"not"),D8t.forEach(t),a1r=r(Ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=n(Ote,"A",{href:!0});var G8t=s(nU);n1r=r(G8t,"from_pretrained()"),G8t.forEach(t),s1r=r(Ote," to load the model weights."),Ote.forEach(t),l1r=i(tA),T(HT.$$.fragment,tA),tA.forEach(t),i1r=i(wl),uo=n(wl,"DIV",{class:!0});var La=s(uo);T(P8.$$.fragment,La),d1r=i(La),hFe=n(La,"P",{});var O8t=s(hFe);c1r=r(O8t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),O8t.forEach(t),f1r=i(La),on=n(La,"P",{});var aA=s(on);m1r=r(aA,"The model class to instantiate is selected based on the "),pFe=n(aA,"CODE",{});var V8t=s(pFe);g1r=r(V8t,"model_type"),V8t.forEach(t),h1r=r(aA,` property of the config object (either
passed as an argument or loaded from `),_Fe=n(aA,"CODE",{});var X8t=s(_Fe);p1r=r(X8t,"pretrained_model_name_or_path"),X8t.forEach(t),_1r=r(aA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uFe=n(aA,"CODE",{});var z8t=s(uFe);u1r=r(z8t,"pretrained_model_name_or_path"),z8t.forEach(t),b1r=r(aA,":"),aA.forEach(t),v1r=i(La),rn=n(La,"UL",{});var nA=s(rn);UT=n(nA,"LI",{});var Lqe=s(UT);bFe=n(Lqe,"STRONG",{});var Q8t=s(bFe);F1r=r(Q8t,"deit"),Q8t.forEach(t),T1r=r(Lqe," \u2014 "),sU=n(Lqe,"A",{href:!0});var W8t=s(sU);M1r=r(W8t,"DeiTForMaskedImageModeling"),W8t.forEach(t),E1r=r(Lqe," (DeiT model)"),Lqe.forEach(t),C1r=i(nA),JT=n(nA,"LI",{});var yqe=s(JT);vFe=n(yqe,"STRONG",{});var H8t=s(vFe);w1r=r(H8t,"swin"),H8t.forEach(t),A1r=r(yqe," \u2014 "),lU=n(yqe,"A",{href:!0});var U8t=s(lU);L1r=r(U8t,"SwinForMaskedImageModeling"),U8t.forEach(t),y1r=r(yqe," (Swin Transformer model)"),yqe.forEach(t),x1r=i(nA),YT=n(nA,"LI",{});var xqe=s(YT);FFe=n(xqe,"STRONG",{});var J8t=s(FFe);$1r=r(J8t,"swinv2"),J8t.forEach(t),k1r=r(xqe," \u2014 "),iU=n(xqe,"A",{href:!0});var Y8t=s(iU);S1r=r(Y8t,"Swinv2ForMaskedImageModeling"),Y8t.forEach(t),R1r=r(xqe," (Swin Transformer V2 model)"),xqe.forEach(t),P1r=i(nA),KT=n(nA,"LI",{});var $qe=s(KT);TFe=n($qe,"STRONG",{});var K8t=s(TFe);B1r=r(K8t,"vit"),K8t.forEach(t),I1r=r($qe," \u2014 "),dU=n($qe,"A",{href:!0});var Z8t=s(dU);N1r=r(Z8t,"ViTForMaskedImageModeling"),Z8t.forEach(t),q1r=r($qe," (ViT model)"),$qe.forEach(t),nA.forEach(t),j1r=i(La),ZT=n(La,"P",{});var kqe=s(ZT);D1r=r(kqe,"The model is set in evaluation mode by default using "),MFe=n(kqe,"CODE",{});var ext=s(MFe);G1r=r(ext,"model.eval()"),ext.forEach(t),O1r=r(kqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EFe=n(kqe,"CODE",{});var oxt=s(EFe);V1r=r(oxt,"model.train()"),oxt.forEach(t),kqe.forEach(t),X1r=i(La),T(e7.$$.fragment,La),La.forEach(t),wl.forEach(t),Gze=i(f),Ud=n(f,"H2",{class:!0});var HWe=s(Ud);o7=n(HWe,"A",{id:!0,class:!0,href:!0});var rxt=s(o7);CFe=n(rxt,"SPAN",{});var txt=s(CFe);T(B8.$$.fragment,txt),txt.forEach(t),rxt.forEach(t),z1r=i(HWe),wFe=n(HWe,"SPAN",{});var axt=s(wFe);Q1r=r(axt,"AutoModelForObjectDetection"),axt.forEach(t),HWe.forEach(t),Oze=i(f),Ko=n(f,"DIV",{class:!0});var Al=s(Ko);T(I8.$$.fragment,Al),W1r=i(Al),Jd=n(Al,"P",{});var Vte=s(Jd);H1r=r(Vte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),cU=n(Vte,"A",{href:!0});var nxt=s(cU);U1r=r(nxt,"from_pretrained()"),nxt.forEach(t),J1r=r(Vte," class method or the "),fU=n(Vte,"A",{href:!0});var sxt=s(fU);Y1r=r(sxt,"from_config()"),sxt.forEach(t),K1r=r(Vte,` class
method.`),Vte.forEach(t),Z1r=i(Al),N8=n(Al,"P",{});var UWe=s(N8);e4r=r(UWe,"This class cannot be instantiated directly using "),AFe=n(UWe,"CODE",{});var lxt=s(AFe);o4r=r(lxt,"__init__()"),lxt.forEach(t),r4r=r(UWe," (throws an error)."),UWe.forEach(t),t4r=i(Al),xt=n(Al,"DIV",{class:!0});var sA=s(xt);T(q8.$$.fragment,sA),a4r=i(sA),LFe=n(sA,"P",{});var ixt=s(LFe);n4r=r(ixt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),ixt.forEach(t),s4r=i(sA),Yd=n(sA,"P",{});var Xte=s(Yd);l4r=r(Xte,`Note:
Loading a model from its configuration file does `),yFe=n(Xte,"STRONG",{});var dxt=s(yFe);i4r=r(dxt,"not"),dxt.forEach(t),d4r=r(Xte,` load the model weights. It only affects the
model\u2019s configuration. Use `),mU=n(Xte,"A",{href:!0});var cxt=s(mU);c4r=r(cxt,"from_pretrained()"),cxt.forEach(t),f4r=r(Xte," to load the model weights."),Xte.forEach(t),m4r=i(sA),T(r7.$$.fragment,sA),sA.forEach(t),g4r=i(Al),bo=n(Al,"DIV",{class:!0});var ya=s(bo);T(j8.$$.fragment,ya),h4r=i(ya),xFe=n(ya,"P",{});var fxt=s(xFe);p4r=r(fxt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),fxt.forEach(t),_4r=i(ya),tn=n(ya,"P",{});var lA=s(tn);u4r=r(lA,"The model class to instantiate is selected based on the "),$Fe=n(lA,"CODE",{});var mxt=s($Fe);b4r=r(mxt,"model_type"),mxt.forEach(t),v4r=r(lA,` property of the config object (either
passed as an argument or loaded from `),kFe=n(lA,"CODE",{});var gxt=s(kFe);F4r=r(gxt,"pretrained_model_name_or_path"),gxt.forEach(t),T4r=r(lA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=n(lA,"CODE",{});var hxt=s(SFe);M4r=r(hxt,"pretrained_model_name_or_path"),hxt.forEach(t),E4r=r(lA,":"),lA.forEach(t),C4r=i(ya),D8=n(ya,"UL",{});var JWe=s(D8);t7=n(JWe,"LI",{});var Sqe=s(t7);RFe=n(Sqe,"STRONG",{});var pxt=s(RFe);w4r=r(pxt,"detr"),pxt.forEach(t),A4r=r(Sqe," \u2014 "),gU=n(Sqe,"A",{href:!0});var _xt=s(gU);L4r=r(_xt,"DetrForObjectDetection"),_xt.forEach(t),y4r=r(Sqe," (DETR model)"),Sqe.forEach(t),x4r=i(JWe),a7=n(JWe,"LI",{});var Rqe=s(a7);PFe=n(Rqe,"STRONG",{});var uxt=s(PFe);$4r=r(uxt,"yolos"),uxt.forEach(t),k4r=r(Rqe," \u2014 "),hU=n(Rqe,"A",{href:!0});var bxt=s(hU);S4r=r(bxt,"YolosForObjectDetection"),bxt.forEach(t),R4r=r(Rqe," (YOLOS model)"),Rqe.forEach(t),JWe.forEach(t),P4r=i(ya),n7=n(ya,"P",{});var Pqe=s(n7);B4r=r(Pqe,"The model is set in evaluation mode by default using "),BFe=n(Pqe,"CODE",{});var vxt=s(BFe);I4r=r(vxt,"model.eval()"),vxt.forEach(t),N4r=r(Pqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),IFe=n(Pqe,"CODE",{});var Fxt=s(IFe);q4r=r(Fxt,"model.train()"),Fxt.forEach(t),Pqe.forEach(t),j4r=i(ya),T(s7.$$.fragment,ya),ya.forEach(t),Al.forEach(t),Vze=i(f),Kd=n(f,"H2",{class:!0});var YWe=s(Kd);l7=n(YWe,"A",{id:!0,class:!0,href:!0});var Txt=s(l7);NFe=n(Txt,"SPAN",{});var Mxt=s(NFe);T(G8.$$.fragment,Mxt),Mxt.forEach(t),Txt.forEach(t),D4r=i(YWe),qFe=n(YWe,"SPAN",{});var Ext=s(qFe);G4r=r(Ext,"AutoModelForImageSegmentation"),Ext.forEach(t),YWe.forEach(t),Xze=i(f),Zo=n(f,"DIV",{class:!0});var Ll=s(Zo);T(O8.$$.fragment,Ll),O4r=i(Ll),Zd=n(Ll,"P",{});var zte=s(Zd);V4r=r(zte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),pU=n(zte,"A",{href:!0});var Cxt=s(pU);X4r=r(Cxt,"from_pretrained()"),Cxt.forEach(t),z4r=r(zte," class method or the "),_U=n(zte,"A",{href:!0});var wxt=s(_U);Q4r=r(wxt,"from_config()"),wxt.forEach(t),W4r=r(zte,` class
method.`),zte.forEach(t),H4r=i(Ll),V8=n(Ll,"P",{});var KWe=s(V8);U4r=r(KWe,"This class cannot be instantiated directly using "),jFe=n(KWe,"CODE",{});var Axt=s(jFe);J4r=r(Axt,"__init__()"),Axt.forEach(t),Y4r=r(KWe," (throws an error)."),KWe.forEach(t),K4r=i(Ll),$t=n(Ll,"DIV",{class:!0});var iA=s($t);T(X8.$$.fragment,iA),Z4r=i(iA),DFe=n(iA,"P",{});var Lxt=s(DFe);e2r=r(Lxt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Lxt.forEach(t),o2r=i(iA),ec=n(iA,"P",{});var Qte=s(ec);r2r=r(Qte,`Note:
Loading a model from its configuration file does `),GFe=n(Qte,"STRONG",{});var yxt=s(GFe);t2r=r(yxt,"not"),yxt.forEach(t),a2r=r(Qte,` load the model weights. It only affects the
model\u2019s configuration. Use `),uU=n(Qte,"A",{href:!0});var xxt=s(uU);n2r=r(xxt,"from_pretrained()"),xxt.forEach(t),s2r=r(Qte," to load the model weights."),Qte.forEach(t),l2r=i(iA),T(i7.$$.fragment,iA),iA.forEach(t),i2r=i(Ll),vo=n(Ll,"DIV",{class:!0});var xa=s(vo);T(z8.$$.fragment,xa),d2r=i(xa),OFe=n(xa,"P",{});var $xt=s(OFe);c2r=r($xt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),$xt.forEach(t),f2r=i(xa),an=n(xa,"P",{});var dA=s(an);m2r=r(dA,"The model class to instantiate is selected based on the "),VFe=n(dA,"CODE",{});var kxt=s(VFe);g2r=r(kxt,"model_type"),kxt.forEach(t),h2r=r(dA,` property of the config object (either
passed as an argument or loaded from `),XFe=n(dA,"CODE",{});var Sxt=s(XFe);p2r=r(Sxt,"pretrained_model_name_or_path"),Sxt.forEach(t),_2r=r(dA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zFe=n(dA,"CODE",{});var Rxt=s(zFe);u2r=r(Rxt,"pretrained_model_name_or_path"),Rxt.forEach(t),b2r=r(dA,":"),dA.forEach(t),v2r=i(xa),QFe=n(xa,"UL",{});var Pxt=s(QFe);d7=n(Pxt,"LI",{});var Bqe=s(d7);WFe=n(Bqe,"STRONG",{});var Bxt=s(WFe);F2r=r(Bxt,"detr"),Bxt.forEach(t),T2r=r(Bqe," \u2014 "),bU=n(Bqe,"A",{href:!0});var Ixt=s(bU);M2r=r(Ixt,"DetrForSegmentation"),Ixt.forEach(t),E2r=r(Bqe," (DETR model)"),Bqe.forEach(t),Pxt.forEach(t),C2r=i(xa),c7=n(xa,"P",{});var Iqe=s(c7);w2r=r(Iqe,"The model is set in evaluation mode by default using "),HFe=n(Iqe,"CODE",{});var Nxt=s(HFe);A2r=r(Nxt,"model.eval()"),Nxt.forEach(t),L2r=r(Iqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UFe=n(Iqe,"CODE",{});var qxt=s(UFe);y2r=r(qxt,"model.train()"),qxt.forEach(t),Iqe.forEach(t),x2r=i(xa),T(f7.$$.fragment,xa),xa.forEach(t),Ll.forEach(t),zze=i(f),oc=n(f,"H2",{class:!0});var ZWe=s(oc);m7=n(ZWe,"A",{id:!0,class:!0,href:!0});var jxt=s(m7);JFe=n(jxt,"SPAN",{});var Dxt=s(JFe);T(Q8.$$.fragment,Dxt),Dxt.forEach(t),jxt.forEach(t),$2r=i(ZWe),YFe=n(ZWe,"SPAN",{});var Gxt=s(YFe);k2r=r(Gxt,"AutoModelForSemanticSegmentation"),Gxt.forEach(t),ZWe.forEach(t),Qze=i(f),er=n(f,"DIV",{class:!0});var yl=s(er);T(W8.$$.fragment,yl),S2r=i(yl),rc=n(yl,"P",{});var Wte=s(rc);R2r=r(Wte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),vU=n(Wte,"A",{href:!0});var Oxt=s(vU);P2r=r(Oxt,"from_pretrained()"),Oxt.forEach(t),B2r=r(Wte," class method or the "),FU=n(Wte,"A",{href:!0});var Vxt=s(FU);I2r=r(Vxt,"from_config()"),Vxt.forEach(t),N2r=r(Wte,` class
method.`),Wte.forEach(t),q2r=i(yl),H8=n(yl,"P",{});var eHe=s(H8);j2r=r(eHe,"This class cannot be instantiated directly using "),KFe=n(eHe,"CODE",{});var Xxt=s(KFe);D2r=r(Xxt,"__init__()"),Xxt.forEach(t),G2r=r(eHe," (throws an error)."),eHe.forEach(t),O2r=i(yl),kt=n(yl,"DIV",{class:!0});var cA=s(kt);T(U8.$$.fragment,cA),V2r=i(cA),ZFe=n(cA,"P",{});var zxt=s(ZFe);X2r=r(zxt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),zxt.forEach(t),z2r=i(cA),tc=n(cA,"P",{});var Hte=s(tc);Q2r=r(Hte,`Note:
Loading a model from its configuration file does `),e6e=n(Hte,"STRONG",{});var Qxt=s(e6e);W2r=r(Qxt,"not"),Qxt.forEach(t),H2r=r(Hte,` load the model weights. It only affects the
model\u2019s configuration. Use `),TU=n(Hte,"A",{href:!0});var Wxt=s(TU);U2r=r(Wxt,"from_pretrained()"),Wxt.forEach(t),J2r=r(Hte," to load the model weights."),Hte.forEach(t),Y2r=i(cA),T(g7.$$.fragment,cA),cA.forEach(t),K2r=i(yl),Fo=n(yl,"DIV",{class:!0});var $a=s(Fo);T(J8.$$.fragment,$a),Z2r=i($a),o6e=n($a,"P",{});var Hxt=s(o6e);ebr=r(Hxt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Hxt.forEach(t),obr=i($a),nn=n($a,"P",{});var fA=s(nn);rbr=r(fA,"The model class to instantiate is selected based on the "),r6e=n(fA,"CODE",{});var Uxt=s(r6e);tbr=r(Uxt,"model_type"),Uxt.forEach(t),abr=r(fA,` property of the config object (either
passed as an argument or loaded from `),t6e=n(fA,"CODE",{});var Jxt=s(t6e);nbr=r(Jxt,"pretrained_model_name_or_path"),Jxt.forEach(t),sbr=r(fA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=n(fA,"CODE",{});var Yxt=s(a6e);lbr=r(Yxt,"pretrained_model_name_or_path"),Yxt.forEach(t),ibr=r(fA,":"),fA.forEach(t),dbr=i($a),at=n($a,"UL",{});var xl=s(at);h7=n(xl,"LI",{});var Nqe=s(h7);n6e=n(Nqe,"STRONG",{});var Kxt=s(n6e);cbr=r(Kxt,"beit"),Kxt.forEach(t),fbr=r(Nqe," \u2014 "),MU=n(Nqe,"A",{href:!0});var Zxt=s(MU);mbr=r(Zxt,"BeitForSemanticSegmentation"),Zxt.forEach(t),gbr=r(Nqe," (BEiT model)"),Nqe.forEach(t),hbr=i(xl),p7=n(xl,"LI",{});var qqe=s(p7);s6e=n(qqe,"STRONG",{});var e$t=s(s6e);pbr=r(e$t,"data2vec-vision"),e$t.forEach(t),_br=r(qqe," \u2014 "),EU=n(qqe,"A",{href:!0});var o$t=s(EU);ubr=r(o$t,"Data2VecVisionForSemanticSegmentation"),o$t.forEach(t),bbr=r(qqe," (Data2VecVision model)"),qqe.forEach(t),vbr=i(xl),_7=n(xl,"LI",{});var jqe=s(_7);l6e=n(jqe,"STRONG",{});var r$t=s(l6e);Fbr=r(r$t,"dpt"),r$t.forEach(t),Tbr=r(jqe," \u2014 "),CU=n(jqe,"A",{href:!0});var t$t=s(CU);Mbr=r(t$t,"DPTForSemanticSegmentation"),t$t.forEach(t),Ebr=r(jqe," (DPT model)"),jqe.forEach(t),Cbr=i(xl),u7=n(xl,"LI",{});var Dqe=s(u7);i6e=n(Dqe,"STRONG",{});var a$t=s(i6e);wbr=r(a$t,"mobilevit"),a$t.forEach(t),Abr=r(Dqe," \u2014 "),wU=n(Dqe,"A",{href:!0});var n$t=s(wU);Lbr=r(n$t,"MobileViTForSemanticSegmentation"),n$t.forEach(t),ybr=r(Dqe," (MobileViT model)"),Dqe.forEach(t),xbr=i(xl),b7=n(xl,"LI",{});var Gqe=s(b7);d6e=n(Gqe,"STRONG",{});var s$t=s(d6e);$br=r(s$t,"segformer"),s$t.forEach(t),kbr=r(Gqe," \u2014 "),AU=n(Gqe,"A",{href:!0});var l$t=s(AU);Sbr=r(l$t,"SegformerForSemanticSegmentation"),l$t.forEach(t),Rbr=r(Gqe," (SegFormer model)"),Gqe.forEach(t),xl.forEach(t),Pbr=i($a),v7=n($a,"P",{});var Oqe=s(v7);Bbr=r(Oqe,"The model is set in evaluation mode by default using "),c6e=n(Oqe,"CODE",{});var i$t=s(c6e);Ibr=r(i$t,"model.eval()"),i$t.forEach(t),Nbr=r(Oqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f6e=n(Oqe,"CODE",{});var d$t=s(f6e);qbr=r(d$t,"model.train()"),d$t.forEach(t),Oqe.forEach(t),jbr=i($a),T(F7.$$.fragment,$a),$a.forEach(t),yl.forEach(t),Wze=i(f),ac=n(f,"H2",{class:!0});var oHe=s(ac);T7=n(oHe,"A",{id:!0,class:!0,href:!0});var c$t=s(T7);m6e=n(c$t,"SPAN",{});var f$t=s(m6e);T(Y8.$$.fragment,f$t),f$t.forEach(t),c$t.forEach(t),Dbr=i(oHe),g6e=n(oHe,"SPAN",{});var m$t=s(g6e);Gbr=r(m$t,"AutoModelForInstanceSegmentation"),m$t.forEach(t),oHe.forEach(t),Hze=i(f),or=n(f,"DIV",{class:!0});var $l=s(or);T(K8.$$.fragment,$l),Obr=i($l),nc=n($l,"P",{});var Ute=s(nc);Vbr=r(Ute,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),LU=n(Ute,"A",{href:!0});var g$t=s(LU);Xbr=r(g$t,"from_pretrained()"),g$t.forEach(t),zbr=r(Ute," class method or the "),yU=n(Ute,"A",{href:!0});var h$t=s(yU);Qbr=r(h$t,"from_config()"),h$t.forEach(t),Wbr=r(Ute,` class
method.`),Ute.forEach(t),Hbr=i($l),Z8=n($l,"P",{});var rHe=s(Z8);Ubr=r(rHe,"This class cannot be instantiated directly using "),h6e=n(rHe,"CODE",{});var p$t=s(h6e);Jbr=r(p$t,"__init__()"),p$t.forEach(t),Ybr=r(rHe," (throws an error)."),rHe.forEach(t),Kbr=i($l),St=n($l,"DIV",{class:!0});var mA=s(St);T(ex.$$.fragment,mA),Zbr=i(mA),p6e=n(mA,"P",{});var _$t=s(p6e);evr=r(_$t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),_$t.forEach(t),ovr=i(mA),sc=n(mA,"P",{});var Jte=s(sc);rvr=r(Jte,`Note:
Loading a model from its configuration file does `),_6e=n(Jte,"STRONG",{});var u$t=s(_6e);tvr=r(u$t,"not"),u$t.forEach(t),avr=r(Jte,` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=n(Jte,"A",{href:!0});var b$t=s(xU);nvr=r(b$t,"from_pretrained()"),b$t.forEach(t),svr=r(Jte," to load the model weights."),Jte.forEach(t),lvr=i(mA),T(M7.$$.fragment,mA),mA.forEach(t),ivr=i($l),To=n($l,"DIV",{class:!0});var ka=s(To);T(ox.$$.fragment,ka),dvr=i(ka),u6e=n(ka,"P",{});var v$t=s(u6e);cvr=r(v$t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),v$t.forEach(t),fvr=i(ka),sn=n(ka,"P",{});var gA=s(sn);mvr=r(gA,"The model class to instantiate is selected based on the "),b6e=n(gA,"CODE",{});var F$t=s(b6e);gvr=r(F$t,"model_type"),F$t.forEach(t),hvr=r(gA,` property of the config object (either
passed as an argument or loaded from `),v6e=n(gA,"CODE",{});var T$t=s(v6e);pvr=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),_vr=r(gA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F6e=n(gA,"CODE",{});var M$t=s(F6e);uvr=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),bvr=r(gA,":"),gA.forEach(t),vvr=i(ka),T6e=n(ka,"UL",{});var E$t=s(T6e);E7=n(E$t,"LI",{});var Vqe=s(E7);M6e=n(Vqe,"STRONG",{});var C$t=s(M6e);Fvr=r(C$t,"maskformer"),C$t.forEach(t),Tvr=r(Vqe," \u2014 "),$U=n(Vqe,"A",{href:!0});var w$t=s($U);Mvr=r(w$t,"MaskFormerForInstanceSegmentation"),w$t.forEach(t),Evr=r(Vqe," (MaskFormer model)"),Vqe.forEach(t),E$t.forEach(t),Cvr=i(ka),C7=n(ka,"P",{});var Xqe=s(C7);wvr=r(Xqe,"The model is set in evaluation mode by default using "),E6e=n(Xqe,"CODE",{});var A$t=s(E6e);Avr=r(A$t,"model.eval()"),A$t.forEach(t),Lvr=r(Xqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C6e=n(Xqe,"CODE",{});var L$t=s(C6e);yvr=r(L$t,"model.train()"),L$t.forEach(t),Xqe.forEach(t),xvr=i(ka),T(w7.$$.fragment,ka),ka.forEach(t),$l.forEach(t),Uze=i(f),lc=n(f,"H2",{class:!0});var tHe=s(lc);A7=n(tHe,"A",{id:!0,class:!0,href:!0});var y$t=s(A7);w6e=n(y$t,"SPAN",{});var x$t=s(w6e);T(rx.$$.fragment,x$t),x$t.forEach(t),y$t.forEach(t),$vr=i(tHe),A6e=n(tHe,"SPAN",{});var $$t=s(A6e);kvr=r($$t,"TFAutoModel"),$$t.forEach(t),tHe.forEach(t),Jze=i(f),rr=n(f,"DIV",{class:!0});var kl=s(rr);T(tx.$$.fragment,kl),Svr=i(kl),ic=n(kl,"P",{});var Yte=s(ic);Rvr=r(Yte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),kU=n(Yte,"A",{href:!0});var k$t=s(kU);Pvr=r(k$t,"from_pretrained()"),k$t.forEach(t),Bvr=r(Yte," class method or the "),SU=n(Yte,"A",{href:!0});var S$t=s(SU);Ivr=r(S$t,"from_config()"),S$t.forEach(t),Nvr=r(Yte,` class
method.`),Yte.forEach(t),qvr=i(kl),ax=n(kl,"P",{});var aHe=s(ax);jvr=r(aHe,"This class cannot be instantiated directly using "),L6e=n(aHe,"CODE",{});var R$t=s(L6e);Dvr=r(R$t,"__init__()"),R$t.forEach(t),Gvr=r(aHe," (throws an error)."),aHe.forEach(t),Ovr=i(kl),Rt=n(kl,"DIV",{class:!0});var hA=s(Rt);T(nx.$$.fragment,hA),Vvr=i(hA),y6e=n(hA,"P",{});var P$t=s(y6e);Xvr=r(P$t,"Instantiates one of the base model classes of the library from a configuration."),P$t.forEach(t),zvr=i(hA),dc=n(hA,"P",{});var Kte=s(dc);Qvr=r(Kte,`Note:
Loading a model from its configuration file does `),x6e=n(Kte,"STRONG",{});var B$t=s(x6e);Wvr=r(B$t,"not"),B$t.forEach(t),Hvr=r(Kte,` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=n(Kte,"A",{href:!0});var I$t=s(RU);Uvr=r(I$t,"from_pretrained()"),I$t.forEach(t),Jvr=r(Kte," to load the model weights."),Kte.forEach(t),Yvr=i(hA),T(L7.$$.fragment,hA),hA.forEach(t),Kvr=i(kl),$r=n(kl,"DIV",{class:!0});var Sl=s($r);T(sx.$$.fragment,Sl),Zvr=i(Sl),$6e=n(Sl,"P",{});var N$t=s($6e);eFr=r(N$t,"Instantiate one of the base model classes of the library from a pretrained model."),N$t.forEach(t),oFr=i(Sl),ln=n(Sl,"P",{});var pA=s(ln);rFr=r(pA,"The model class to instantiate is selected based on the "),k6e=n(pA,"CODE",{});var q$t=s(k6e);tFr=r(q$t,"model_type"),q$t.forEach(t),aFr=r(pA,` property of the config object (either
passed as an argument or loaded from `),S6e=n(pA,"CODE",{});var j$t=s(S6e);nFr=r(j$t,"pretrained_model_name_or_path"),j$t.forEach(t),sFr=r(pA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R6e=n(pA,"CODE",{});var D$t=s(R6e);lFr=r(D$t,"pretrained_model_name_or_path"),D$t.forEach(t),iFr=r(pA,":"),pA.forEach(t),dFr=i(Sl),I=n(Sl,"UL",{});var D=s(I);y7=n(D,"LI",{});var zqe=s(y7);P6e=n(zqe,"STRONG",{});var G$t=s(P6e);cFr=r(G$t,"albert"),G$t.forEach(t),fFr=r(zqe," \u2014 "),PU=n(zqe,"A",{href:!0});var O$t=s(PU);mFr=r(O$t,"TFAlbertModel"),O$t.forEach(t),gFr=r(zqe," (ALBERT model)"),zqe.forEach(t),hFr=i(D),x7=n(D,"LI",{});var Qqe=s(x7);B6e=n(Qqe,"STRONG",{});var V$t=s(B6e);pFr=r(V$t,"bart"),V$t.forEach(t),_Fr=r(Qqe," \u2014 "),BU=n(Qqe,"A",{href:!0});var X$t=s(BU);uFr=r(X$t,"TFBartModel"),X$t.forEach(t),bFr=r(Qqe," (BART model)"),Qqe.forEach(t),vFr=i(D),$7=n(D,"LI",{});var Wqe=s($7);I6e=n(Wqe,"STRONG",{});var z$t=s(I6e);FFr=r(z$t,"bert"),z$t.forEach(t),TFr=r(Wqe," \u2014 "),IU=n(Wqe,"A",{href:!0});var Q$t=s(IU);MFr=r(Q$t,"TFBertModel"),Q$t.forEach(t),EFr=r(Wqe," (BERT model)"),Wqe.forEach(t),CFr=i(D),k7=n(D,"LI",{});var Hqe=s(k7);N6e=n(Hqe,"STRONG",{});var W$t=s(N6e);wFr=r(W$t,"blenderbot"),W$t.forEach(t),AFr=r(Hqe," \u2014 "),NU=n(Hqe,"A",{href:!0});var H$t=s(NU);LFr=r(H$t,"TFBlenderbotModel"),H$t.forEach(t),yFr=r(Hqe," (Blenderbot model)"),Hqe.forEach(t),xFr=i(D),S7=n(D,"LI",{});var Uqe=s(S7);q6e=n(Uqe,"STRONG",{});var U$t=s(q6e);$Fr=r(U$t,"blenderbot-small"),U$t.forEach(t),kFr=r(Uqe," \u2014 "),qU=n(Uqe,"A",{href:!0});var J$t=s(qU);SFr=r(J$t,"TFBlenderbotSmallModel"),J$t.forEach(t),RFr=r(Uqe," (BlenderbotSmall model)"),Uqe.forEach(t),PFr=i(D),R7=n(D,"LI",{});var Jqe=s(R7);j6e=n(Jqe,"STRONG",{});var Y$t=s(j6e);BFr=r(Y$t,"camembert"),Y$t.forEach(t),IFr=r(Jqe," \u2014 "),jU=n(Jqe,"A",{href:!0});var K$t=s(jU);NFr=r(K$t,"TFCamembertModel"),K$t.forEach(t),qFr=r(Jqe," (CamemBERT model)"),Jqe.forEach(t),jFr=i(D),P7=n(D,"LI",{});var Yqe=s(P7);D6e=n(Yqe,"STRONG",{});var Z$t=s(D6e);DFr=r(Z$t,"clip"),Z$t.forEach(t),GFr=r(Yqe," \u2014 "),DU=n(Yqe,"A",{href:!0});var ekt=s(DU);OFr=r(ekt,"TFCLIPModel"),ekt.forEach(t),VFr=r(Yqe," (CLIP model)"),Yqe.forEach(t),XFr=i(D),B7=n(D,"LI",{});var Kqe=s(B7);G6e=n(Kqe,"STRONG",{});var okt=s(G6e);zFr=r(okt,"convbert"),okt.forEach(t),QFr=r(Kqe," \u2014 "),GU=n(Kqe,"A",{href:!0});var rkt=s(GU);WFr=r(rkt,"TFConvBertModel"),rkt.forEach(t),HFr=r(Kqe," (ConvBERT model)"),Kqe.forEach(t),UFr=i(D),I7=n(D,"LI",{});var Zqe=s(I7);O6e=n(Zqe,"STRONG",{});var tkt=s(O6e);JFr=r(tkt,"convnext"),tkt.forEach(t),YFr=r(Zqe," \u2014 "),OU=n(Zqe,"A",{href:!0});var akt=s(OU);KFr=r(akt,"TFConvNextModel"),akt.forEach(t),ZFr=r(Zqe," (ConvNeXT model)"),Zqe.forEach(t),e6r=i(D),N7=n(D,"LI",{});var eje=s(N7);V6e=n(eje,"STRONG",{});var nkt=s(V6e);o6r=r(nkt,"ctrl"),nkt.forEach(t),r6r=r(eje," \u2014 "),VU=n(eje,"A",{href:!0});var skt=s(VU);t6r=r(skt,"TFCTRLModel"),skt.forEach(t),a6r=r(eje," (CTRL model)"),eje.forEach(t),n6r=i(D),q7=n(D,"LI",{});var oje=s(q7);X6e=n(oje,"STRONG",{});var lkt=s(X6e);s6r=r(lkt,"data2vec-vision"),lkt.forEach(t),l6r=r(oje," \u2014 "),XU=n(oje,"A",{href:!0});var ikt=s(XU);i6r=r(ikt,"TFData2VecVisionModel"),ikt.forEach(t),d6r=r(oje," (Data2VecVision model)"),oje.forEach(t),c6r=i(D),j7=n(D,"LI",{});var rje=s(j7);z6e=n(rje,"STRONG",{});var dkt=s(z6e);f6r=r(dkt,"deberta"),dkt.forEach(t),m6r=r(rje," \u2014 "),zU=n(rje,"A",{href:!0});var ckt=s(zU);g6r=r(ckt,"TFDebertaModel"),ckt.forEach(t),h6r=r(rje," (DeBERTa model)"),rje.forEach(t),p6r=i(D),D7=n(D,"LI",{});var tje=s(D7);Q6e=n(tje,"STRONG",{});var fkt=s(Q6e);_6r=r(fkt,"deberta-v2"),fkt.forEach(t),u6r=r(tje," \u2014 "),QU=n(tje,"A",{href:!0});var mkt=s(QU);b6r=r(mkt,"TFDebertaV2Model"),mkt.forEach(t),v6r=r(tje," (DeBERTa-v2 model)"),tje.forEach(t),F6r=i(D),G7=n(D,"LI",{});var aje=s(G7);W6e=n(aje,"STRONG",{});var gkt=s(W6e);T6r=r(gkt,"deit"),gkt.forEach(t),M6r=r(aje," \u2014 "),WU=n(aje,"A",{href:!0});var hkt=s(WU);E6r=r(hkt,"TFDeiTModel"),hkt.forEach(t),C6r=r(aje," (DeiT model)"),aje.forEach(t),w6r=i(D),O7=n(D,"LI",{});var nje=s(O7);H6e=n(nje,"STRONG",{});var pkt=s(H6e);A6r=r(pkt,"distilbert"),pkt.forEach(t),L6r=r(nje," \u2014 "),HU=n(nje,"A",{href:!0});var _kt=s(HU);y6r=r(_kt,"TFDistilBertModel"),_kt.forEach(t),x6r=r(nje," (DistilBERT model)"),nje.forEach(t),$6r=i(D),V7=n(D,"LI",{});var sje=s(V7);U6e=n(sje,"STRONG",{});var ukt=s(U6e);k6r=r(ukt,"dpr"),ukt.forEach(t),S6r=r(sje," \u2014 "),UU=n(sje,"A",{href:!0});var bkt=s(UU);R6r=r(bkt,"TFDPRQuestionEncoder"),bkt.forEach(t),P6r=r(sje," (DPR model)"),sje.forEach(t),B6r=i(D),X7=n(D,"LI",{});var lje=s(X7);J6e=n(lje,"STRONG",{});var vkt=s(J6e);I6r=r(vkt,"electra"),vkt.forEach(t),N6r=r(lje," \u2014 "),JU=n(lje,"A",{href:!0});var Fkt=s(JU);q6r=r(Fkt,"TFElectraModel"),Fkt.forEach(t),j6r=r(lje," (ELECTRA model)"),lje.forEach(t),D6r=i(D),z7=n(D,"LI",{});var ije=s(z7);Y6e=n(ije,"STRONG",{});var Tkt=s(Y6e);G6r=r(Tkt,"flaubert"),Tkt.forEach(t),O6r=r(ije," \u2014 "),YU=n(ije,"A",{href:!0});var Mkt=s(YU);V6r=r(Mkt,"TFFlaubertModel"),Mkt.forEach(t),X6r=r(ije," (FlauBERT model)"),ije.forEach(t),z6r=i(D),Ks=n(D,"LI",{});var QS=s(Ks);K6e=n(QS,"STRONG",{});var Ekt=s(K6e);Q6r=r(Ekt,"funnel"),Ekt.forEach(t),W6r=r(QS," \u2014 "),KU=n(QS,"A",{href:!0});var Ckt=s(KU);H6r=r(Ckt,"TFFunnelModel"),Ckt.forEach(t),U6r=r(QS," or "),ZU=n(QS,"A",{href:!0});var wkt=s(ZU);J6r=r(wkt,"TFFunnelBaseModel"),wkt.forEach(t),Y6r=r(QS," (Funnel Transformer model)"),QS.forEach(t),K6r=i(D),Q7=n(D,"LI",{});var dje=s(Q7);Z6e=n(dje,"STRONG",{});var Akt=s(Z6e);Z6r=r(Akt,"gpt2"),Akt.forEach(t),eTr=r(dje," \u2014 "),eJ=n(dje,"A",{href:!0});var Lkt=s(eJ);oTr=r(Lkt,"TFGPT2Model"),Lkt.forEach(t),rTr=r(dje," (OpenAI GPT-2 model)"),dje.forEach(t),tTr=i(D),W7=n(D,"LI",{});var cje=s(W7);eTe=n(cje,"STRONG",{});var ykt=s(eTe);aTr=r(ykt,"gptj"),ykt.forEach(t),nTr=r(cje," \u2014 "),oJ=n(cje,"A",{href:!0});var xkt=s(oJ);sTr=r(xkt,"TFGPTJModel"),xkt.forEach(t),lTr=r(cje," (GPT-J model)"),cje.forEach(t),iTr=i(D),H7=n(D,"LI",{});var fje=s(H7);oTe=n(fje,"STRONG",{});var $kt=s(oTe);dTr=r($kt,"hubert"),$kt.forEach(t),cTr=r(fje," \u2014 "),rJ=n(fje,"A",{href:!0});var kkt=s(rJ);fTr=r(kkt,"TFHubertModel"),kkt.forEach(t),mTr=r(fje," (Hubert model)"),fje.forEach(t),gTr=i(D),U7=n(D,"LI",{});var mje=s(U7);rTe=n(mje,"STRONG",{});var Skt=s(rTe);hTr=r(Skt,"layoutlm"),Skt.forEach(t),pTr=r(mje," \u2014 "),tJ=n(mje,"A",{href:!0});var Rkt=s(tJ);_Tr=r(Rkt,"TFLayoutLMModel"),Rkt.forEach(t),uTr=r(mje," (LayoutLM model)"),mje.forEach(t),bTr=i(D),J7=n(D,"LI",{});var gje=s(J7);tTe=n(gje,"STRONG",{});var Pkt=s(tTe);vTr=r(Pkt,"led"),Pkt.forEach(t),FTr=r(gje," \u2014 "),aJ=n(gje,"A",{href:!0});var Bkt=s(aJ);TTr=r(Bkt,"TFLEDModel"),Bkt.forEach(t),MTr=r(gje," (LED model)"),gje.forEach(t),ETr=i(D),Y7=n(D,"LI",{});var hje=s(Y7);aTe=n(hje,"STRONG",{});var Ikt=s(aTe);CTr=r(Ikt,"longformer"),Ikt.forEach(t),wTr=r(hje," \u2014 "),nJ=n(hje,"A",{href:!0});var Nkt=s(nJ);ATr=r(Nkt,"TFLongformerModel"),Nkt.forEach(t),LTr=r(hje," (Longformer model)"),hje.forEach(t),yTr=i(D),K7=n(D,"LI",{});var pje=s(K7);nTe=n(pje,"STRONG",{});var qkt=s(nTe);xTr=r(qkt,"lxmert"),qkt.forEach(t),$Tr=r(pje," \u2014 "),sJ=n(pje,"A",{href:!0});var jkt=s(sJ);kTr=r(jkt,"TFLxmertModel"),jkt.forEach(t),STr=r(pje," (LXMERT model)"),pje.forEach(t),RTr=i(D),Z7=n(D,"LI",{});var _je=s(Z7);sTe=n(_je,"STRONG",{});var Dkt=s(sTe);PTr=r(Dkt,"marian"),Dkt.forEach(t),BTr=r(_je," \u2014 "),lJ=n(_je,"A",{href:!0});var Gkt=s(lJ);ITr=r(Gkt,"TFMarianModel"),Gkt.forEach(t),NTr=r(_je," (Marian model)"),_je.forEach(t),qTr=i(D),e9=n(D,"LI",{});var uje=s(e9);lTe=n(uje,"STRONG",{});var Okt=s(lTe);jTr=r(Okt,"mbart"),Okt.forEach(t),DTr=r(uje," \u2014 "),iJ=n(uje,"A",{href:!0});var Vkt=s(iJ);GTr=r(Vkt,"TFMBartModel"),Vkt.forEach(t),OTr=r(uje," (mBART model)"),uje.forEach(t),VTr=i(D),o9=n(D,"LI",{});var bje=s(o9);iTe=n(bje,"STRONG",{});var Xkt=s(iTe);XTr=r(Xkt,"mobilebert"),Xkt.forEach(t),zTr=r(bje," \u2014 "),dJ=n(bje,"A",{href:!0});var zkt=s(dJ);QTr=r(zkt,"TFMobileBertModel"),zkt.forEach(t),WTr=r(bje," (MobileBERT model)"),bje.forEach(t),HTr=i(D),r9=n(D,"LI",{});var vje=s(r9);dTe=n(vje,"STRONG",{});var Qkt=s(dTe);UTr=r(Qkt,"mpnet"),Qkt.forEach(t),JTr=r(vje," \u2014 "),cJ=n(vje,"A",{href:!0});var Wkt=s(cJ);YTr=r(Wkt,"TFMPNetModel"),Wkt.forEach(t),KTr=r(vje," (MPNet model)"),vje.forEach(t),ZTr=i(D),t9=n(D,"LI",{});var Fje=s(t9);cTe=n(Fje,"STRONG",{});var Hkt=s(cTe);e7r=r(Hkt,"mt5"),Hkt.forEach(t),o7r=r(Fje," \u2014 "),fJ=n(Fje,"A",{href:!0});var Ukt=s(fJ);r7r=r(Ukt,"TFMT5Model"),Ukt.forEach(t),t7r=r(Fje," (MT5 model)"),Fje.forEach(t),a7r=i(D),a9=n(D,"LI",{});var Tje=s(a9);fTe=n(Tje,"STRONG",{});var Jkt=s(fTe);n7r=r(Jkt,"openai-gpt"),Jkt.forEach(t),s7r=r(Tje," \u2014 "),mJ=n(Tje,"A",{href:!0});var Ykt=s(mJ);l7r=r(Ykt,"TFOpenAIGPTModel"),Ykt.forEach(t),i7r=r(Tje," (OpenAI GPT model)"),Tje.forEach(t),d7r=i(D),n9=n(D,"LI",{});var Mje=s(n9);mTe=n(Mje,"STRONG",{});var Kkt=s(mTe);c7r=r(Kkt,"opt"),Kkt.forEach(t),f7r=r(Mje," \u2014 "),gJ=n(Mje,"A",{href:!0});var Zkt=s(gJ);m7r=r(Zkt,"TFOPTModel"),Zkt.forEach(t),g7r=r(Mje," (OPT model)"),Mje.forEach(t),h7r=i(D),s9=n(D,"LI",{});var Eje=s(s9);gTe=n(Eje,"STRONG",{});var eSt=s(gTe);p7r=r(eSt,"pegasus"),eSt.forEach(t),_7r=r(Eje," \u2014 "),hJ=n(Eje,"A",{href:!0});var oSt=s(hJ);u7r=r(oSt,"TFPegasusModel"),oSt.forEach(t),b7r=r(Eje," (Pegasus model)"),Eje.forEach(t),v7r=i(D),l9=n(D,"LI",{});var Cje=s(l9);hTe=n(Cje,"STRONG",{});var rSt=s(hTe);F7r=r(rSt,"regnet"),rSt.forEach(t),T7r=r(Cje," \u2014 "),pJ=n(Cje,"A",{href:!0});var tSt=s(pJ);M7r=r(tSt,"TFRegNetModel"),tSt.forEach(t),E7r=r(Cje," (RegNet model)"),Cje.forEach(t),C7r=i(D),i9=n(D,"LI",{});var wje=s(i9);pTe=n(wje,"STRONG",{});var aSt=s(pTe);w7r=r(aSt,"rembert"),aSt.forEach(t),A7r=r(wje," \u2014 "),_J=n(wje,"A",{href:!0});var nSt=s(_J);L7r=r(nSt,"TFRemBertModel"),nSt.forEach(t),y7r=r(wje," (RemBERT model)"),wje.forEach(t),x7r=i(D),d9=n(D,"LI",{});var Aje=s(d9);_Te=n(Aje,"STRONG",{});var sSt=s(_Te);$7r=r(sSt,"resnet"),sSt.forEach(t),k7r=r(Aje," \u2014 "),uJ=n(Aje,"A",{href:!0});var lSt=s(uJ);S7r=r(lSt,"TFResNetModel"),lSt.forEach(t),R7r=r(Aje," (ResNet model)"),Aje.forEach(t),P7r=i(D),c9=n(D,"LI",{});var Lje=s(c9);uTe=n(Lje,"STRONG",{});var iSt=s(uTe);B7r=r(iSt,"roberta"),iSt.forEach(t),I7r=r(Lje," \u2014 "),bJ=n(Lje,"A",{href:!0});var dSt=s(bJ);N7r=r(dSt,"TFRobertaModel"),dSt.forEach(t),q7r=r(Lje," (RoBERTa model)"),Lje.forEach(t),j7r=i(D),f9=n(D,"LI",{});var yje=s(f9);bTe=n(yje,"STRONG",{});var cSt=s(bTe);D7r=r(cSt,"roformer"),cSt.forEach(t),G7r=r(yje," \u2014 "),vJ=n(yje,"A",{href:!0});var fSt=s(vJ);O7r=r(fSt,"TFRoFormerModel"),fSt.forEach(t),V7r=r(yje," (RoFormer model)"),yje.forEach(t),X7r=i(D),m9=n(D,"LI",{});var xje=s(m9);vTe=n(xje,"STRONG",{});var mSt=s(vTe);z7r=r(mSt,"segformer"),mSt.forEach(t),Q7r=r(xje," \u2014 "),FJ=n(xje,"A",{href:!0});var gSt=s(FJ);W7r=r(gSt,"TFSegformerModel"),gSt.forEach(t),H7r=r(xje," (SegFormer model)"),xje.forEach(t),U7r=i(D),g9=n(D,"LI",{});var $je=s(g9);FTe=n($je,"STRONG",{});var hSt=s(FTe);J7r=r(hSt,"speech_to_text"),hSt.forEach(t),Y7r=r($je," \u2014 "),TJ=n($je,"A",{href:!0});var pSt=s(TJ);K7r=r(pSt,"TFSpeech2TextModel"),pSt.forEach(t),Z7r=r($je," (Speech2Text model)"),$je.forEach(t),e9r=i(D),h9=n(D,"LI",{});var kje=s(h9);TTe=n(kje,"STRONG",{});var _St=s(TTe);o9r=r(_St,"swin"),_St.forEach(t),r9r=r(kje," \u2014 "),MJ=n(kje,"A",{href:!0});var uSt=s(MJ);t9r=r(uSt,"TFSwinModel"),uSt.forEach(t),a9r=r(kje," (Swin Transformer model)"),kje.forEach(t),n9r=i(D),p9=n(D,"LI",{});var Sje=s(p9);MTe=n(Sje,"STRONG",{});var bSt=s(MTe);s9r=r(bSt,"t5"),bSt.forEach(t),l9r=r(Sje," \u2014 "),EJ=n(Sje,"A",{href:!0});var vSt=s(EJ);i9r=r(vSt,"TFT5Model"),vSt.forEach(t),d9r=r(Sje," (T5 model)"),Sje.forEach(t),c9r=i(D),_9=n(D,"LI",{});var Rje=s(_9);ETe=n(Rje,"STRONG",{});var FSt=s(ETe);f9r=r(FSt,"tapas"),FSt.forEach(t),m9r=r(Rje," \u2014 "),CJ=n(Rje,"A",{href:!0});var TSt=s(CJ);g9r=r(TSt,"TFTapasModel"),TSt.forEach(t),h9r=r(Rje," (TAPAS model)"),Rje.forEach(t),p9r=i(D),u9=n(D,"LI",{});var Pje=s(u9);CTe=n(Pje,"STRONG",{});var MSt=s(CTe);_9r=r(MSt,"transfo-xl"),MSt.forEach(t),u9r=r(Pje," \u2014 "),wJ=n(Pje,"A",{href:!0});var ESt=s(wJ);b9r=r(ESt,"TFTransfoXLModel"),ESt.forEach(t),v9r=r(Pje," (Transformer-XL model)"),Pje.forEach(t),F9r=i(D),b9=n(D,"LI",{});var Bje=s(b9);wTe=n(Bje,"STRONG",{});var CSt=s(wTe);T9r=r(CSt,"vit"),CSt.forEach(t),M9r=r(Bje," \u2014 "),AJ=n(Bje,"A",{href:!0});var wSt=s(AJ);E9r=r(wSt,"TFViTModel"),wSt.forEach(t),C9r=r(Bje," (ViT model)"),Bje.forEach(t),w9r=i(D),v9=n(D,"LI",{});var Ije=s(v9);ATe=n(Ije,"STRONG",{});var ASt=s(ATe);A9r=r(ASt,"vit_mae"),ASt.forEach(t),L9r=r(Ije," \u2014 "),LJ=n(Ije,"A",{href:!0});var LSt=s(LJ);y9r=r(LSt,"TFViTMAEModel"),LSt.forEach(t),x9r=r(Ije," (ViTMAE model)"),Ije.forEach(t),$9r=i(D),F9=n(D,"LI",{});var Nje=s(F9);LTe=n(Nje,"STRONG",{});var ySt=s(LTe);k9r=r(ySt,"wav2vec2"),ySt.forEach(t),S9r=r(Nje," \u2014 "),yJ=n(Nje,"A",{href:!0});var xSt=s(yJ);R9r=r(xSt,"TFWav2Vec2Model"),xSt.forEach(t),P9r=r(Nje," (Wav2Vec2 model)"),Nje.forEach(t),B9r=i(D),T9=n(D,"LI",{});var qje=s(T9);yTe=n(qje,"STRONG",{});var $St=s(yTe);I9r=r($St,"xlm"),$St.forEach(t),N9r=r(qje," \u2014 "),xJ=n(qje,"A",{href:!0});var kSt=s(xJ);q9r=r(kSt,"TFXLMModel"),kSt.forEach(t),j9r=r(qje," (XLM model)"),qje.forEach(t),D9r=i(D),M9=n(D,"LI",{});var jje=s(M9);xTe=n(jje,"STRONG",{});var SSt=s(xTe);G9r=r(SSt,"xlm-roberta"),SSt.forEach(t),O9r=r(jje," \u2014 "),$J=n(jje,"A",{href:!0});var RSt=s($J);V9r=r(RSt,"TFXLMRobertaModel"),RSt.forEach(t),X9r=r(jje," (XLM-RoBERTa model)"),jje.forEach(t),z9r=i(D),E9=n(D,"LI",{});var Dje=s(E9);$Te=n(Dje,"STRONG",{});var PSt=s($Te);Q9r=r(PSt,"xlnet"),PSt.forEach(t),W9r=r(Dje," \u2014 "),kJ=n(Dje,"A",{href:!0});var BSt=s(kJ);H9r=r(BSt,"TFXLNetModel"),BSt.forEach(t),U9r=r(Dje," (XLNet model)"),Dje.forEach(t),D.forEach(t),J9r=i(Sl),T(C9.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),Yze=i(f),cc=n(f,"H2",{class:!0});var nHe=s(cc);w9=n(nHe,"A",{id:!0,class:!0,href:!0});var ISt=s(w9);kTe=n(ISt,"SPAN",{});var NSt=s(kTe);T(lx.$$.fragment,NSt),NSt.forEach(t),ISt.forEach(t),Y9r=i(nHe),STe=n(nHe,"SPAN",{});var qSt=s(STe);K9r=r(qSt,"TFAutoModelForPreTraining"),qSt.forEach(t),nHe.forEach(t),Kze=i(f),tr=n(f,"DIV",{class:!0});var Rl=s(tr);T(ix.$$.fragment,Rl),Z9r=i(Rl),fc=n(Rl,"P",{});var Zte=s(fc);eMr=r(Zte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),SJ=n(Zte,"A",{href:!0});var jSt=s(SJ);oMr=r(jSt,"from_pretrained()"),jSt.forEach(t),rMr=r(Zte," class method or the "),RJ=n(Zte,"A",{href:!0});var DSt=s(RJ);tMr=r(DSt,"from_config()"),DSt.forEach(t),aMr=r(Zte,` class
method.`),Zte.forEach(t),nMr=i(Rl),dx=n(Rl,"P",{});var sHe=s(dx);sMr=r(sHe,"This class cannot be instantiated directly using "),RTe=n(sHe,"CODE",{});var GSt=s(RTe);lMr=r(GSt,"__init__()"),GSt.forEach(t),iMr=r(sHe," (throws an error)."),sHe.forEach(t),dMr=i(Rl),Pt=n(Rl,"DIV",{class:!0});var _A=s(Pt);T(cx.$$.fragment,_A),cMr=i(_A),PTe=n(_A,"P",{});var OSt=s(PTe);fMr=r(OSt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),OSt.forEach(t),mMr=i(_A),mc=n(_A,"P",{});var eae=s(mc);gMr=r(eae,`Note:
Loading a model from its configuration file does `),BTe=n(eae,"STRONG",{});var VSt=s(BTe);hMr=r(VSt,"not"),VSt.forEach(t),pMr=r(eae,` load the model weights. It only affects the
model\u2019s configuration. Use `),PJ=n(eae,"A",{href:!0});var XSt=s(PJ);_Mr=r(XSt,"from_pretrained()"),XSt.forEach(t),uMr=r(eae," to load the model weights."),eae.forEach(t),bMr=i(_A),T(A9.$$.fragment,_A),_A.forEach(t),vMr=i(Rl),kr=n(Rl,"DIV",{class:!0});var Pl=s(kr);T(fx.$$.fragment,Pl),FMr=i(Pl),ITe=n(Pl,"P",{});var zSt=s(ITe);TMr=r(zSt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),zSt.forEach(t),MMr=i(Pl),dn=n(Pl,"P",{});var uA=s(dn);EMr=r(uA,"The model class to instantiate is selected based on the "),NTe=n(uA,"CODE",{});var QSt=s(NTe);CMr=r(QSt,"model_type"),QSt.forEach(t),wMr=r(uA,` property of the config object (either
passed as an argument or loaded from `),qTe=n(uA,"CODE",{});var WSt=s(qTe);AMr=r(WSt,"pretrained_model_name_or_path"),WSt.forEach(t),LMr=r(uA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jTe=n(uA,"CODE",{});var HSt=s(jTe);yMr=r(HSt,"pretrained_model_name_or_path"),HSt.forEach(t),xMr=r(uA,":"),uA.forEach(t),$Mr=i(Pl),se=n(Pl,"UL",{});var le=s(se);L9=n(le,"LI",{});var Gje=s(L9);DTe=n(Gje,"STRONG",{});var USt=s(DTe);kMr=r(USt,"albert"),USt.forEach(t),SMr=r(Gje," \u2014 "),BJ=n(Gje,"A",{href:!0});var JSt=s(BJ);RMr=r(JSt,"TFAlbertForPreTraining"),JSt.forEach(t),PMr=r(Gje," (ALBERT model)"),Gje.forEach(t),BMr=i(le),y9=n(le,"LI",{});var Oje=s(y9);GTe=n(Oje,"STRONG",{});var YSt=s(GTe);IMr=r(YSt,"bart"),YSt.forEach(t),NMr=r(Oje," \u2014 "),IJ=n(Oje,"A",{href:!0});var KSt=s(IJ);qMr=r(KSt,"TFBartForConditionalGeneration"),KSt.forEach(t),jMr=r(Oje," (BART model)"),Oje.forEach(t),DMr=i(le),x9=n(le,"LI",{});var Vje=s(x9);OTe=n(Vje,"STRONG",{});var ZSt=s(OTe);GMr=r(ZSt,"bert"),ZSt.forEach(t),OMr=r(Vje," \u2014 "),NJ=n(Vje,"A",{href:!0});var eRt=s(NJ);VMr=r(eRt,"TFBertForPreTraining"),eRt.forEach(t),XMr=r(Vje," (BERT model)"),Vje.forEach(t),zMr=i(le),$9=n(le,"LI",{});var Xje=s($9);VTe=n(Xje,"STRONG",{});var oRt=s(VTe);QMr=r(oRt,"camembert"),oRt.forEach(t),WMr=r(Xje," \u2014 "),qJ=n(Xje,"A",{href:!0});var rRt=s(qJ);HMr=r(rRt,"TFCamembertForMaskedLM"),rRt.forEach(t),UMr=r(Xje," (CamemBERT model)"),Xje.forEach(t),JMr=i(le),k9=n(le,"LI",{});var zje=s(k9);XTe=n(zje,"STRONG",{});var tRt=s(XTe);YMr=r(tRt,"ctrl"),tRt.forEach(t),KMr=r(zje," \u2014 "),jJ=n(zje,"A",{href:!0});var aRt=s(jJ);ZMr=r(aRt,"TFCTRLLMHeadModel"),aRt.forEach(t),eEr=r(zje," (CTRL model)"),zje.forEach(t),oEr=i(le),S9=n(le,"LI",{});var Qje=s(S9);zTe=n(Qje,"STRONG",{});var nRt=s(zTe);rEr=r(nRt,"distilbert"),nRt.forEach(t),tEr=r(Qje," \u2014 "),DJ=n(Qje,"A",{href:!0});var sRt=s(DJ);aEr=r(sRt,"TFDistilBertForMaskedLM"),sRt.forEach(t),nEr=r(Qje," (DistilBERT model)"),Qje.forEach(t),sEr=i(le),R9=n(le,"LI",{});var Wje=s(R9);QTe=n(Wje,"STRONG",{});var lRt=s(QTe);lEr=r(lRt,"electra"),lRt.forEach(t),iEr=r(Wje," \u2014 "),GJ=n(Wje,"A",{href:!0});var iRt=s(GJ);dEr=r(iRt,"TFElectraForPreTraining"),iRt.forEach(t),cEr=r(Wje," (ELECTRA model)"),Wje.forEach(t),fEr=i(le),P9=n(le,"LI",{});var Hje=s(P9);WTe=n(Hje,"STRONG",{});var dRt=s(WTe);mEr=r(dRt,"flaubert"),dRt.forEach(t),gEr=r(Hje," \u2014 "),OJ=n(Hje,"A",{href:!0});var cRt=s(OJ);hEr=r(cRt,"TFFlaubertWithLMHeadModel"),cRt.forEach(t),pEr=r(Hje," (FlauBERT model)"),Hje.forEach(t),_Er=i(le),B9=n(le,"LI",{});var Uje=s(B9);HTe=n(Uje,"STRONG",{});var fRt=s(HTe);uEr=r(fRt,"funnel"),fRt.forEach(t),bEr=r(Uje," \u2014 "),VJ=n(Uje,"A",{href:!0});var mRt=s(VJ);vEr=r(mRt,"TFFunnelForPreTraining"),mRt.forEach(t),FEr=r(Uje," (Funnel Transformer model)"),Uje.forEach(t),TEr=i(le),I9=n(le,"LI",{});var Jje=s(I9);UTe=n(Jje,"STRONG",{});var gRt=s(UTe);MEr=r(gRt,"gpt2"),gRt.forEach(t),EEr=r(Jje," \u2014 "),XJ=n(Jje,"A",{href:!0});var hRt=s(XJ);CEr=r(hRt,"TFGPT2LMHeadModel"),hRt.forEach(t),wEr=r(Jje," (OpenAI GPT-2 model)"),Jje.forEach(t),AEr=i(le),N9=n(le,"LI",{});var Yje=s(N9);JTe=n(Yje,"STRONG",{});var pRt=s(JTe);LEr=r(pRt,"layoutlm"),pRt.forEach(t),yEr=r(Yje," \u2014 "),zJ=n(Yje,"A",{href:!0});var _Rt=s(zJ);xEr=r(_Rt,"TFLayoutLMForMaskedLM"),_Rt.forEach(t),$Er=r(Yje," (LayoutLM model)"),Yje.forEach(t),kEr=i(le),q9=n(le,"LI",{});var Kje=s(q9);YTe=n(Kje,"STRONG",{});var uRt=s(YTe);SEr=r(uRt,"lxmert"),uRt.forEach(t),REr=r(Kje," \u2014 "),QJ=n(Kje,"A",{href:!0});var bRt=s(QJ);PEr=r(bRt,"TFLxmertForPreTraining"),bRt.forEach(t),BEr=r(Kje," (LXMERT model)"),Kje.forEach(t),IEr=i(le),j9=n(le,"LI",{});var Zje=s(j9);KTe=n(Zje,"STRONG",{});var vRt=s(KTe);NEr=r(vRt,"mobilebert"),vRt.forEach(t),qEr=r(Zje," \u2014 "),WJ=n(Zje,"A",{href:!0});var FRt=s(WJ);jEr=r(FRt,"TFMobileBertForPreTraining"),FRt.forEach(t),DEr=r(Zje," (MobileBERT model)"),Zje.forEach(t),GEr=i(le),D9=n(le,"LI",{});var eDe=s(D9);ZTe=n(eDe,"STRONG",{});var TRt=s(ZTe);OEr=r(TRt,"mpnet"),TRt.forEach(t),VEr=r(eDe," \u2014 "),HJ=n(eDe,"A",{href:!0});var MRt=s(HJ);XEr=r(MRt,"TFMPNetForMaskedLM"),MRt.forEach(t),zEr=r(eDe," (MPNet model)"),eDe.forEach(t),QEr=i(le),G9=n(le,"LI",{});var oDe=s(G9);e7e=n(oDe,"STRONG",{});var ERt=s(e7e);WEr=r(ERt,"openai-gpt"),ERt.forEach(t),HEr=r(oDe," \u2014 "),UJ=n(oDe,"A",{href:!0});var CRt=s(UJ);UEr=r(CRt,"TFOpenAIGPTLMHeadModel"),CRt.forEach(t),JEr=r(oDe," (OpenAI GPT model)"),oDe.forEach(t),YEr=i(le),O9=n(le,"LI",{});var rDe=s(O9);o7e=n(rDe,"STRONG",{});var wRt=s(o7e);KEr=r(wRt,"roberta"),wRt.forEach(t),ZEr=r(rDe," \u2014 "),JJ=n(rDe,"A",{href:!0});var ARt=s(JJ);eCr=r(ARt,"TFRobertaForMaskedLM"),ARt.forEach(t),oCr=r(rDe," (RoBERTa model)"),rDe.forEach(t),rCr=i(le),V9=n(le,"LI",{});var tDe=s(V9);r7e=n(tDe,"STRONG",{});var LRt=s(r7e);tCr=r(LRt,"t5"),LRt.forEach(t),aCr=r(tDe," \u2014 "),YJ=n(tDe,"A",{href:!0});var yRt=s(YJ);nCr=r(yRt,"TFT5ForConditionalGeneration"),yRt.forEach(t),sCr=r(tDe," (T5 model)"),tDe.forEach(t),lCr=i(le),X9=n(le,"LI",{});var aDe=s(X9);t7e=n(aDe,"STRONG",{});var xRt=s(t7e);iCr=r(xRt,"tapas"),xRt.forEach(t),dCr=r(aDe," \u2014 "),KJ=n(aDe,"A",{href:!0});var $Rt=s(KJ);cCr=r($Rt,"TFTapasForMaskedLM"),$Rt.forEach(t),fCr=r(aDe," (TAPAS model)"),aDe.forEach(t),mCr=i(le),z9=n(le,"LI",{});var nDe=s(z9);a7e=n(nDe,"STRONG",{});var kRt=s(a7e);gCr=r(kRt,"transfo-xl"),kRt.forEach(t),hCr=r(nDe," \u2014 "),ZJ=n(nDe,"A",{href:!0});var SRt=s(ZJ);pCr=r(SRt,"TFTransfoXLLMHeadModel"),SRt.forEach(t),_Cr=r(nDe," (Transformer-XL model)"),nDe.forEach(t),uCr=i(le),Q9=n(le,"LI",{});var sDe=s(Q9);n7e=n(sDe,"STRONG",{});var RRt=s(n7e);bCr=r(RRt,"vit_mae"),RRt.forEach(t),vCr=r(sDe," \u2014 "),eY=n(sDe,"A",{href:!0});var PRt=s(eY);FCr=r(PRt,"TFViTMAEForPreTraining"),PRt.forEach(t),TCr=r(sDe," (ViTMAE model)"),sDe.forEach(t),MCr=i(le),W9=n(le,"LI",{});var lDe=s(W9);s7e=n(lDe,"STRONG",{});var BRt=s(s7e);ECr=r(BRt,"xlm"),BRt.forEach(t),CCr=r(lDe," \u2014 "),oY=n(lDe,"A",{href:!0});var IRt=s(oY);wCr=r(IRt,"TFXLMWithLMHeadModel"),IRt.forEach(t),ACr=r(lDe," (XLM model)"),lDe.forEach(t),LCr=i(le),H9=n(le,"LI",{});var iDe=s(H9);l7e=n(iDe,"STRONG",{});var NRt=s(l7e);yCr=r(NRt,"xlm-roberta"),NRt.forEach(t),xCr=r(iDe," \u2014 "),rY=n(iDe,"A",{href:!0});var qRt=s(rY);$Cr=r(qRt,"TFXLMRobertaForMaskedLM"),qRt.forEach(t),kCr=r(iDe," (XLM-RoBERTa model)"),iDe.forEach(t),SCr=i(le),U9=n(le,"LI",{});var dDe=s(U9);i7e=n(dDe,"STRONG",{});var jRt=s(i7e);RCr=r(jRt,"xlnet"),jRt.forEach(t),PCr=r(dDe," \u2014 "),tY=n(dDe,"A",{href:!0});var DRt=s(tY);BCr=r(DRt,"TFXLNetLMHeadModel"),DRt.forEach(t),ICr=r(dDe," (XLNet model)"),dDe.forEach(t),le.forEach(t),NCr=i(Pl),T(J9.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),Zze=i(f),gc=n(f,"H2",{class:!0});var lHe=s(gc);Y9=n(lHe,"A",{id:!0,class:!0,href:!0});var GRt=s(Y9);d7e=n(GRt,"SPAN",{});var ORt=s(d7e);T(mx.$$.fragment,ORt),ORt.forEach(t),GRt.forEach(t),qCr=i(lHe),c7e=n(lHe,"SPAN",{});var VRt=s(c7e);jCr=r(VRt,"TFAutoModelForCausalLM"),VRt.forEach(t),lHe.forEach(t),eQe=i(f),ar=n(f,"DIV",{class:!0});var Bl=s(ar);T(gx.$$.fragment,Bl),DCr=i(Bl),hc=n(Bl,"P",{});var oae=s(hc);GCr=r(oae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),aY=n(oae,"A",{href:!0});var XRt=s(aY);OCr=r(XRt,"from_pretrained()"),XRt.forEach(t),VCr=r(oae," class method or the "),nY=n(oae,"A",{href:!0});var zRt=s(nY);XCr=r(zRt,"from_config()"),zRt.forEach(t),zCr=r(oae,` class
method.`),oae.forEach(t),QCr=i(Bl),hx=n(Bl,"P",{});var iHe=s(hx);WCr=r(iHe,"This class cannot be instantiated directly using "),f7e=n(iHe,"CODE",{});var QRt=s(f7e);HCr=r(QRt,"__init__()"),QRt.forEach(t),UCr=r(iHe," (throws an error)."),iHe.forEach(t),JCr=i(Bl),Bt=n(Bl,"DIV",{class:!0});var bA=s(Bt);T(px.$$.fragment,bA),YCr=i(bA),m7e=n(bA,"P",{});var WRt=s(m7e);KCr=r(WRt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),WRt.forEach(t),ZCr=i(bA),pc=n(bA,"P",{});var rae=s(pc);e5r=r(rae,`Note:
Loading a model from its configuration file does `),g7e=n(rae,"STRONG",{});var HRt=s(g7e);o5r=r(HRt,"not"),HRt.forEach(t),r5r=r(rae,` load the model weights. It only affects the
model\u2019s configuration. Use `),sY=n(rae,"A",{href:!0});var URt=s(sY);t5r=r(URt,"from_pretrained()"),URt.forEach(t),a5r=r(rae," to load the model weights."),rae.forEach(t),n5r=i(bA),T(K9.$$.fragment,bA),bA.forEach(t),s5r=i(Bl),Sr=n(Bl,"DIV",{class:!0});var Il=s(Sr);T(_x.$$.fragment,Il),l5r=i(Il),h7e=n(Il,"P",{});var JRt=s(h7e);i5r=r(JRt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),JRt.forEach(t),d5r=i(Il),cn=n(Il,"P",{});var vA=s(cn);c5r=r(vA,"The model class to instantiate is selected based on the "),p7e=n(vA,"CODE",{});var YRt=s(p7e);f5r=r(YRt,"model_type"),YRt.forEach(t),m5r=r(vA,` property of the config object (either
passed as an argument or loaded from `),_7e=n(vA,"CODE",{});var KRt=s(_7e);g5r=r(KRt,"pretrained_model_name_or_path"),KRt.forEach(t),h5r=r(vA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u7e=n(vA,"CODE",{});var ZRt=s(u7e);p5r=r(ZRt,"pretrained_model_name_or_path"),ZRt.forEach(t),_5r=r(vA,":"),vA.forEach(t),u5r=i(Il),Me=n(Il,"UL",{});var Ce=s(Me);Z9=n(Ce,"LI",{});var cDe=s(Z9);b7e=n(cDe,"STRONG",{});var ePt=s(b7e);b5r=r(ePt,"bert"),ePt.forEach(t),v5r=r(cDe," \u2014 "),lY=n(cDe,"A",{href:!0});var oPt=s(lY);F5r=r(oPt,"TFBertLMHeadModel"),oPt.forEach(t),T5r=r(cDe," (BERT model)"),cDe.forEach(t),M5r=i(Ce),eM=n(Ce,"LI",{});var fDe=s(eM);v7e=n(fDe,"STRONG",{});var rPt=s(v7e);E5r=r(rPt,"camembert"),rPt.forEach(t),C5r=r(fDe," \u2014 "),iY=n(fDe,"A",{href:!0});var tPt=s(iY);w5r=r(tPt,"TFCamembertForCausalLM"),tPt.forEach(t),A5r=r(fDe," (CamemBERT model)"),fDe.forEach(t),L5r=i(Ce),oM=n(Ce,"LI",{});var mDe=s(oM);F7e=n(mDe,"STRONG",{});var aPt=s(F7e);y5r=r(aPt,"ctrl"),aPt.forEach(t),x5r=r(mDe," \u2014 "),dY=n(mDe,"A",{href:!0});var nPt=s(dY);$5r=r(nPt,"TFCTRLLMHeadModel"),nPt.forEach(t),k5r=r(mDe," (CTRL model)"),mDe.forEach(t),S5r=i(Ce),rM=n(Ce,"LI",{});var gDe=s(rM);T7e=n(gDe,"STRONG",{});var sPt=s(T7e);R5r=r(sPt,"gpt2"),sPt.forEach(t),P5r=r(gDe," \u2014 "),cY=n(gDe,"A",{href:!0});var lPt=s(cY);B5r=r(lPt,"TFGPT2LMHeadModel"),lPt.forEach(t),I5r=r(gDe," (OpenAI GPT-2 model)"),gDe.forEach(t),N5r=i(Ce),tM=n(Ce,"LI",{});var hDe=s(tM);M7e=n(hDe,"STRONG",{});var iPt=s(M7e);q5r=r(iPt,"gptj"),iPt.forEach(t),j5r=r(hDe," \u2014 "),fY=n(hDe,"A",{href:!0});var dPt=s(fY);D5r=r(dPt,"TFGPTJForCausalLM"),dPt.forEach(t),G5r=r(hDe," (GPT-J model)"),hDe.forEach(t),O5r=i(Ce),aM=n(Ce,"LI",{});var pDe=s(aM);E7e=n(pDe,"STRONG",{});var cPt=s(E7e);V5r=r(cPt,"openai-gpt"),cPt.forEach(t),X5r=r(pDe," \u2014 "),mY=n(pDe,"A",{href:!0});var fPt=s(mY);z5r=r(fPt,"TFOpenAIGPTLMHeadModel"),fPt.forEach(t),Q5r=r(pDe," (OpenAI GPT model)"),pDe.forEach(t),W5r=i(Ce),nM=n(Ce,"LI",{});var _De=s(nM);C7e=n(_De,"STRONG",{});var mPt=s(C7e);H5r=r(mPt,"opt"),mPt.forEach(t),U5r=r(_De," \u2014 "),gY=n(_De,"A",{href:!0});var gPt=s(gY);J5r=r(gPt,"TFOPTForCausalLM"),gPt.forEach(t),Y5r=r(_De," (OPT model)"),_De.forEach(t),K5r=i(Ce),sM=n(Ce,"LI",{});var uDe=s(sM);w7e=n(uDe,"STRONG",{});var hPt=s(w7e);Z5r=r(hPt,"rembert"),hPt.forEach(t),e3r=r(uDe," \u2014 "),hY=n(uDe,"A",{href:!0});var pPt=s(hY);o3r=r(pPt,"TFRemBertForCausalLM"),pPt.forEach(t),r3r=r(uDe," (RemBERT model)"),uDe.forEach(t),t3r=i(Ce),lM=n(Ce,"LI",{});var bDe=s(lM);A7e=n(bDe,"STRONG",{});var _Pt=s(A7e);a3r=r(_Pt,"roberta"),_Pt.forEach(t),n3r=r(bDe," \u2014 "),pY=n(bDe,"A",{href:!0});var uPt=s(pY);s3r=r(uPt,"TFRobertaForCausalLM"),uPt.forEach(t),l3r=r(bDe," (RoBERTa model)"),bDe.forEach(t),i3r=i(Ce),iM=n(Ce,"LI",{});var vDe=s(iM);L7e=n(vDe,"STRONG",{});var bPt=s(L7e);d3r=r(bPt,"roformer"),bPt.forEach(t),c3r=r(vDe," \u2014 "),_Y=n(vDe,"A",{href:!0});var vPt=s(_Y);f3r=r(vPt,"TFRoFormerForCausalLM"),vPt.forEach(t),m3r=r(vDe," (RoFormer model)"),vDe.forEach(t),g3r=i(Ce),dM=n(Ce,"LI",{});var FDe=s(dM);y7e=n(FDe,"STRONG",{});var FPt=s(y7e);h3r=r(FPt,"transfo-xl"),FPt.forEach(t),p3r=r(FDe," \u2014 "),uY=n(FDe,"A",{href:!0});var TPt=s(uY);_3r=r(TPt,"TFTransfoXLLMHeadModel"),TPt.forEach(t),u3r=r(FDe," (Transformer-XL model)"),FDe.forEach(t),b3r=i(Ce),cM=n(Ce,"LI",{});var TDe=s(cM);x7e=n(TDe,"STRONG",{});var MPt=s(x7e);v3r=r(MPt,"xlm"),MPt.forEach(t),F3r=r(TDe," \u2014 "),bY=n(TDe,"A",{href:!0});var EPt=s(bY);T3r=r(EPt,"TFXLMWithLMHeadModel"),EPt.forEach(t),M3r=r(TDe," (XLM model)"),TDe.forEach(t),E3r=i(Ce),fM=n(Ce,"LI",{});var MDe=s(fM);$7e=n(MDe,"STRONG",{});var CPt=s($7e);C3r=r(CPt,"xlnet"),CPt.forEach(t),w3r=r(MDe," \u2014 "),vY=n(MDe,"A",{href:!0});var wPt=s(vY);A3r=r(wPt,"TFXLNetLMHeadModel"),wPt.forEach(t),L3r=r(MDe," (XLNet model)"),MDe.forEach(t),Ce.forEach(t),y3r=i(Il),T(mM.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),oQe=i(f),_c=n(f,"H2",{class:!0});var dHe=s(_c);gM=n(dHe,"A",{id:!0,class:!0,href:!0});var APt=s(gM);k7e=n(APt,"SPAN",{});var LPt=s(k7e);T(ux.$$.fragment,LPt),LPt.forEach(t),APt.forEach(t),x3r=i(dHe),S7e=n(dHe,"SPAN",{});var yPt=s(S7e);$3r=r(yPt,"TFAutoModelForImageClassification"),yPt.forEach(t),dHe.forEach(t),rQe=i(f),nr=n(f,"DIV",{class:!0});var Nl=s(nr);T(bx.$$.fragment,Nl),k3r=i(Nl),uc=n(Nl,"P",{});var tae=s(uc);S3r=r(tae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),FY=n(tae,"A",{href:!0});var xPt=s(FY);R3r=r(xPt,"from_pretrained()"),xPt.forEach(t),P3r=r(tae," class method or the "),TY=n(tae,"A",{href:!0});var $Pt=s(TY);B3r=r($Pt,"from_config()"),$Pt.forEach(t),I3r=r(tae,` class
method.`),tae.forEach(t),N3r=i(Nl),vx=n(Nl,"P",{});var cHe=s(vx);q3r=r(cHe,"This class cannot be instantiated directly using "),R7e=n(cHe,"CODE",{});var kPt=s(R7e);j3r=r(kPt,"__init__()"),kPt.forEach(t),D3r=r(cHe," (throws an error)."),cHe.forEach(t),G3r=i(Nl),It=n(Nl,"DIV",{class:!0});var FA=s(It);T(Fx.$$.fragment,FA),O3r=i(FA),P7e=n(FA,"P",{});var SPt=s(P7e);V3r=r(SPt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),SPt.forEach(t),X3r=i(FA),bc=n(FA,"P",{});var aae=s(bc);z3r=r(aae,`Note:
Loading a model from its configuration file does `),B7e=n(aae,"STRONG",{});var RPt=s(B7e);Q3r=r(RPt,"not"),RPt.forEach(t),W3r=r(aae,` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=n(aae,"A",{href:!0});var PPt=s(MY);H3r=r(PPt,"from_pretrained()"),PPt.forEach(t),U3r=r(aae," to load the model weights."),aae.forEach(t),J3r=i(FA),T(hM.$$.fragment,FA),FA.forEach(t),Y3r=i(Nl),Rr=n(Nl,"DIV",{class:!0});var ql=s(Rr);T(Tx.$$.fragment,ql),K3r=i(ql),I7e=n(ql,"P",{});var BPt=s(I7e);Z3r=r(BPt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),BPt.forEach(t),e0r=i(ql),fn=n(ql,"P",{});var TA=s(fn);o0r=r(TA,"The model class to instantiate is selected based on the "),N7e=n(TA,"CODE",{});var IPt=s(N7e);r0r=r(IPt,"model_type"),IPt.forEach(t),t0r=r(TA,` property of the config object (either
passed as an argument or loaded from `),q7e=n(TA,"CODE",{});var NPt=s(q7e);a0r=r(NPt,"pretrained_model_name_or_path"),NPt.forEach(t),n0r=r(TA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j7e=n(TA,"CODE",{});var qPt=s(j7e);s0r=r(qPt,"pretrained_model_name_or_path"),qPt.forEach(t),l0r=r(TA,":"),TA.forEach(t),i0r=i(ql),Ve=n(ql,"UL",{});var Mo=s(Ve);pM=n(Mo,"LI",{});var EDe=s(pM);D7e=n(EDe,"STRONG",{});var jPt=s(D7e);d0r=r(jPt,"convnext"),jPt.forEach(t),c0r=r(EDe," \u2014 "),EY=n(EDe,"A",{href:!0});var DPt=s(EY);f0r=r(DPt,"TFConvNextForImageClassification"),DPt.forEach(t),m0r=r(EDe," (ConvNeXT model)"),EDe.forEach(t),g0r=i(Mo),_M=n(Mo,"LI",{});var CDe=s(_M);G7e=n(CDe,"STRONG",{});var GPt=s(G7e);h0r=r(GPt,"data2vec-vision"),GPt.forEach(t),p0r=r(CDe," \u2014 "),CY=n(CDe,"A",{href:!0});var OPt=s(CY);_0r=r(OPt,"TFData2VecVisionForImageClassification"),OPt.forEach(t),u0r=r(CDe," (Data2VecVision model)"),CDe.forEach(t),b0r=i(Mo),Zs=n(Mo,"LI",{});var WS=s(Zs);O7e=n(WS,"STRONG",{});var VPt=s(O7e);v0r=r(VPt,"deit"),VPt.forEach(t),F0r=r(WS," \u2014 "),wY=n(WS,"A",{href:!0});var XPt=s(wY);T0r=r(XPt,"TFDeiTForImageClassification"),XPt.forEach(t),M0r=r(WS," or "),AY=n(WS,"A",{href:!0});var zPt=s(AY);E0r=r(zPt,"TFDeiTForImageClassificationWithTeacher"),zPt.forEach(t),C0r=r(WS," (DeiT model)"),WS.forEach(t),w0r=i(Mo),uM=n(Mo,"LI",{});var wDe=s(uM);V7e=n(wDe,"STRONG",{});var QPt=s(V7e);A0r=r(QPt,"regnet"),QPt.forEach(t),L0r=r(wDe," \u2014 "),LY=n(wDe,"A",{href:!0});var WPt=s(LY);y0r=r(WPt,"TFRegNetForImageClassification"),WPt.forEach(t),x0r=r(wDe," (RegNet model)"),wDe.forEach(t),$0r=i(Mo),bM=n(Mo,"LI",{});var ADe=s(bM);X7e=n(ADe,"STRONG",{});var HPt=s(X7e);k0r=r(HPt,"resnet"),HPt.forEach(t),S0r=r(ADe," \u2014 "),yY=n(ADe,"A",{href:!0});var UPt=s(yY);R0r=r(UPt,"TFResNetForImageClassification"),UPt.forEach(t),P0r=r(ADe," (ResNet model)"),ADe.forEach(t),B0r=i(Mo),vM=n(Mo,"LI",{});var LDe=s(vM);z7e=n(LDe,"STRONG",{});var JPt=s(z7e);I0r=r(JPt,"segformer"),JPt.forEach(t),N0r=r(LDe," \u2014 "),xY=n(LDe,"A",{href:!0});var YPt=s(xY);q0r=r(YPt,"TFSegformerForImageClassification"),YPt.forEach(t),j0r=r(LDe," (SegFormer model)"),LDe.forEach(t),D0r=i(Mo),FM=n(Mo,"LI",{});var yDe=s(FM);Q7e=n(yDe,"STRONG",{});var KPt=s(Q7e);G0r=r(KPt,"swin"),KPt.forEach(t),O0r=r(yDe," \u2014 "),$Y=n(yDe,"A",{href:!0});var ZPt=s($Y);V0r=r(ZPt,"TFSwinForImageClassification"),ZPt.forEach(t),X0r=r(yDe," (Swin Transformer model)"),yDe.forEach(t),z0r=i(Mo),TM=n(Mo,"LI",{});var xDe=s(TM);W7e=n(xDe,"STRONG",{});var eBt=s(W7e);Q0r=r(eBt,"vit"),eBt.forEach(t),W0r=r(xDe," \u2014 "),kY=n(xDe,"A",{href:!0});var oBt=s(kY);H0r=r(oBt,"TFViTForImageClassification"),oBt.forEach(t),U0r=r(xDe," (ViT model)"),xDe.forEach(t),Mo.forEach(t),J0r=i(ql),T(MM.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),tQe=i(f),vc=n(f,"H2",{class:!0});var fHe=s(vc);EM=n(fHe,"A",{id:!0,class:!0,href:!0});var rBt=s(EM);H7e=n(rBt,"SPAN",{});var tBt=s(H7e);T(Mx.$$.fragment,tBt),tBt.forEach(t),rBt.forEach(t),Y0r=i(fHe),U7e=n(fHe,"SPAN",{});var aBt=s(U7e);K0r=r(aBt,"TFAutoModelForMaskedLM"),aBt.forEach(t),fHe.forEach(t),aQe=i(f),sr=n(f,"DIV",{class:!0});var jl=s(sr);T(Ex.$$.fragment,jl),Z0r=i(jl),Fc=n(jl,"P",{});var nae=s(Fc);ewr=r(nae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),SY=n(nae,"A",{href:!0});var nBt=s(SY);owr=r(nBt,"from_pretrained()"),nBt.forEach(t),rwr=r(nae," class method or the "),RY=n(nae,"A",{href:!0});var sBt=s(RY);twr=r(sBt,"from_config()"),sBt.forEach(t),awr=r(nae,` class
method.`),nae.forEach(t),nwr=i(jl),Cx=n(jl,"P",{});var mHe=s(Cx);swr=r(mHe,"This class cannot be instantiated directly using "),J7e=n(mHe,"CODE",{});var lBt=s(J7e);lwr=r(lBt,"__init__()"),lBt.forEach(t),iwr=r(mHe," (throws an error)."),mHe.forEach(t),dwr=i(jl),Nt=n(jl,"DIV",{class:!0});var MA=s(Nt);T(wx.$$.fragment,MA),cwr=i(MA),Y7e=n(MA,"P",{});var iBt=s(Y7e);fwr=r(iBt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),iBt.forEach(t),mwr=i(MA),Tc=n(MA,"P",{});var sae=s(Tc);gwr=r(sae,`Note:
Loading a model from its configuration file does `),K7e=n(sae,"STRONG",{});var dBt=s(K7e);hwr=r(dBt,"not"),dBt.forEach(t),pwr=r(sae,` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=n(sae,"A",{href:!0});var cBt=s(PY);_wr=r(cBt,"from_pretrained()"),cBt.forEach(t),uwr=r(sae," to load the model weights."),sae.forEach(t),bwr=i(MA),T(CM.$$.fragment,MA),MA.forEach(t),vwr=i(jl),Pr=n(jl,"DIV",{class:!0});var Dl=s(Pr);T(Ax.$$.fragment,Dl),Fwr=i(Dl),Z7e=n(Dl,"P",{});var fBt=s(Z7e);Twr=r(fBt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fBt.forEach(t),Mwr=i(Dl),mn=n(Dl,"P",{});var EA=s(mn);Ewr=r(EA,"The model class to instantiate is selected based on the "),e9e=n(EA,"CODE",{});var mBt=s(e9e);Cwr=r(mBt,"model_type"),mBt.forEach(t),wwr=r(EA,` property of the config object (either
passed as an argument or loaded from `),o9e=n(EA,"CODE",{});var gBt=s(o9e);Awr=r(gBt,"pretrained_model_name_or_path"),gBt.forEach(t),Lwr=r(EA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r9e=n(EA,"CODE",{});var hBt=s(r9e);ywr=r(hBt,"pretrained_model_name_or_path"),hBt.forEach(t),xwr=r(EA,":"),EA.forEach(t),$wr=i(Dl),ie=n(Dl,"UL",{});var me=s(ie);wM=n(me,"LI",{});var $De=s(wM);t9e=n($De,"STRONG",{});var pBt=s(t9e);kwr=r(pBt,"albert"),pBt.forEach(t),Swr=r($De," \u2014 "),BY=n($De,"A",{href:!0});var _Bt=s(BY);Rwr=r(_Bt,"TFAlbertForMaskedLM"),_Bt.forEach(t),Pwr=r($De," (ALBERT model)"),$De.forEach(t),Bwr=i(me),AM=n(me,"LI",{});var kDe=s(AM);a9e=n(kDe,"STRONG",{});var uBt=s(a9e);Iwr=r(uBt,"bert"),uBt.forEach(t),Nwr=r(kDe," \u2014 "),IY=n(kDe,"A",{href:!0});var bBt=s(IY);qwr=r(bBt,"TFBertForMaskedLM"),bBt.forEach(t),jwr=r(kDe," (BERT model)"),kDe.forEach(t),Dwr=i(me),LM=n(me,"LI",{});var SDe=s(LM);n9e=n(SDe,"STRONG",{});var vBt=s(n9e);Gwr=r(vBt,"camembert"),vBt.forEach(t),Owr=r(SDe," \u2014 "),NY=n(SDe,"A",{href:!0});var FBt=s(NY);Vwr=r(FBt,"TFCamembertForMaskedLM"),FBt.forEach(t),Xwr=r(SDe," (CamemBERT model)"),SDe.forEach(t),zwr=i(me),yM=n(me,"LI",{});var RDe=s(yM);s9e=n(RDe,"STRONG",{});var TBt=s(s9e);Qwr=r(TBt,"convbert"),TBt.forEach(t),Wwr=r(RDe," \u2014 "),qY=n(RDe,"A",{href:!0});var MBt=s(qY);Hwr=r(MBt,"TFConvBertForMaskedLM"),MBt.forEach(t),Uwr=r(RDe," (ConvBERT model)"),RDe.forEach(t),Jwr=i(me),xM=n(me,"LI",{});var PDe=s(xM);l9e=n(PDe,"STRONG",{});var EBt=s(l9e);Ywr=r(EBt,"deberta"),EBt.forEach(t),Kwr=r(PDe," \u2014 "),jY=n(PDe,"A",{href:!0});var CBt=s(jY);Zwr=r(CBt,"TFDebertaForMaskedLM"),CBt.forEach(t),eAr=r(PDe," (DeBERTa model)"),PDe.forEach(t),oAr=i(me),$M=n(me,"LI",{});var BDe=s($M);i9e=n(BDe,"STRONG",{});var wBt=s(i9e);rAr=r(wBt,"deberta-v2"),wBt.forEach(t),tAr=r(BDe," \u2014 "),DY=n(BDe,"A",{href:!0});var ABt=s(DY);aAr=r(ABt,"TFDebertaV2ForMaskedLM"),ABt.forEach(t),nAr=r(BDe," (DeBERTa-v2 model)"),BDe.forEach(t),sAr=i(me),kM=n(me,"LI",{});var IDe=s(kM);d9e=n(IDe,"STRONG",{});var LBt=s(d9e);lAr=r(LBt,"distilbert"),LBt.forEach(t),iAr=r(IDe," \u2014 "),GY=n(IDe,"A",{href:!0});var yBt=s(GY);dAr=r(yBt,"TFDistilBertForMaskedLM"),yBt.forEach(t),cAr=r(IDe," (DistilBERT model)"),IDe.forEach(t),fAr=i(me),SM=n(me,"LI",{});var NDe=s(SM);c9e=n(NDe,"STRONG",{});var xBt=s(c9e);mAr=r(xBt,"electra"),xBt.forEach(t),gAr=r(NDe," \u2014 "),OY=n(NDe,"A",{href:!0});var $Bt=s(OY);hAr=r($Bt,"TFElectraForMaskedLM"),$Bt.forEach(t),pAr=r(NDe," (ELECTRA model)"),NDe.forEach(t),_Ar=i(me),RM=n(me,"LI",{});var qDe=s(RM);f9e=n(qDe,"STRONG",{});var kBt=s(f9e);uAr=r(kBt,"flaubert"),kBt.forEach(t),bAr=r(qDe," \u2014 "),VY=n(qDe,"A",{href:!0});var SBt=s(VY);vAr=r(SBt,"TFFlaubertWithLMHeadModel"),SBt.forEach(t),FAr=r(qDe," (FlauBERT model)"),qDe.forEach(t),TAr=i(me),PM=n(me,"LI",{});var jDe=s(PM);m9e=n(jDe,"STRONG",{});var RBt=s(m9e);MAr=r(RBt,"funnel"),RBt.forEach(t),EAr=r(jDe," \u2014 "),XY=n(jDe,"A",{href:!0});var PBt=s(XY);CAr=r(PBt,"TFFunnelForMaskedLM"),PBt.forEach(t),wAr=r(jDe," (Funnel Transformer model)"),jDe.forEach(t),AAr=i(me),BM=n(me,"LI",{});var DDe=s(BM);g9e=n(DDe,"STRONG",{});var BBt=s(g9e);LAr=r(BBt,"layoutlm"),BBt.forEach(t),yAr=r(DDe," \u2014 "),zY=n(DDe,"A",{href:!0});var IBt=s(zY);xAr=r(IBt,"TFLayoutLMForMaskedLM"),IBt.forEach(t),$Ar=r(DDe," (LayoutLM model)"),DDe.forEach(t),kAr=i(me),IM=n(me,"LI",{});var GDe=s(IM);h9e=n(GDe,"STRONG",{});var NBt=s(h9e);SAr=r(NBt,"longformer"),NBt.forEach(t),RAr=r(GDe," \u2014 "),QY=n(GDe,"A",{href:!0});var qBt=s(QY);PAr=r(qBt,"TFLongformerForMaskedLM"),qBt.forEach(t),BAr=r(GDe," (Longformer model)"),GDe.forEach(t),IAr=i(me),NM=n(me,"LI",{});var ODe=s(NM);p9e=n(ODe,"STRONG",{});var jBt=s(p9e);NAr=r(jBt,"mobilebert"),jBt.forEach(t),qAr=r(ODe," \u2014 "),WY=n(ODe,"A",{href:!0});var DBt=s(WY);jAr=r(DBt,"TFMobileBertForMaskedLM"),DBt.forEach(t),DAr=r(ODe," (MobileBERT model)"),ODe.forEach(t),GAr=i(me),qM=n(me,"LI",{});var VDe=s(qM);_9e=n(VDe,"STRONG",{});var GBt=s(_9e);OAr=r(GBt,"mpnet"),GBt.forEach(t),VAr=r(VDe," \u2014 "),HY=n(VDe,"A",{href:!0});var OBt=s(HY);XAr=r(OBt,"TFMPNetForMaskedLM"),OBt.forEach(t),zAr=r(VDe," (MPNet model)"),VDe.forEach(t),QAr=i(me),jM=n(me,"LI",{});var XDe=s(jM);u9e=n(XDe,"STRONG",{});var VBt=s(u9e);WAr=r(VBt,"rembert"),VBt.forEach(t),HAr=r(XDe," \u2014 "),UY=n(XDe,"A",{href:!0});var XBt=s(UY);UAr=r(XBt,"TFRemBertForMaskedLM"),XBt.forEach(t),JAr=r(XDe," (RemBERT model)"),XDe.forEach(t),YAr=i(me),DM=n(me,"LI",{});var zDe=s(DM);b9e=n(zDe,"STRONG",{});var zBt=s(b9e);KAr=r(zBt,"roberta"),zBt.forEach(t),ZAr=r(zDe," \u2014 "),JY=n(zDe,"A",{href:!0});var QBt=s(JY);eLr=r(QBt,"TFRobertaForMaskedLM"),QBt.forEach(t),oLr=r(zDe," (RoBERTa model)"),zDe.forEach(t),rLr=i(me),GM=n(me,"LI",{});var QDe=s(GM);v9e=n(QDe,"STRONG",{});var WBt=s(v9e);tLr=r(WBt,"roformer"),WBt.forEach(t),aLr=r(QDe," \u2014 "),YY=n(QDe,"A",{href:!0});var HBt=s(YY);nLr=r(HBt,"TFRoFormerForMaskedLM"),HBt.forEach(t),sLr=r(QDe," (RoFormer model)"),QDe.forEach(t),lLr=i(me),OM=n(me,"LI",{});var WDe=s(OM);F9e=n(WDe,"STRONG",{});var UBt=s(F9e);iLr=r(UBt,"tapas"),UBt.forEach(t),dLr=r(WDe," \u2014 "),KY=n(WDe,"A",{href:!0});var JBt=s(KY);cLr=r(JBt,"TFTapasForMaskedLM"),JBt.forEach(t),fLr=r(WDe," (TAPAS model)"),WDe.forEach(t),mLr=i(me),VM=n(me,"LI",{});var HDe=s(VM);T9e=n(HDe,"STRONG",{});var YBt=s(T9e);gLr=r(YBt,"xlm"),YBt.forEach(t),hLr=r(HDe," \u2014 "),ZY=n(HDe,"A",{href:!0});var KBt=s(ZY);pLr=r(KBt,"TFXLMWithLMHeadModel"),KBt.forEach(t),_Lr=r(HDe," (XLM model)"),HDe.forEach(t),uLr=i(me),XM=n(me,"LI",{});var UDe=s(XM);M9e=n(UDe,"STRONG",{});var ZBt=s(M9e);bLr=r(ZBt,"xlm-roberta"),ZBt.forEach(t),vLr=r(UDe," \u2014 "),eK=n(UDe,"A",{href:!0});var eIt=s(eK);FLr=r(eIt,"TFXLMRobertaForMaskedLM"),eIt.forEach(t),TLr=r(UDe," (XLM-RoBERTa model)"),UDe.forEach(t),me.forEach(t),MLr=i(Dl),T(zM.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),nQe=i(f),Mc=n(f,"H2",{class:!0});var gHe=s(Mc);QM=n(gHe,"A",{id:!0,class:!0,href:!0});var oIt=s(QM);E9e=n(oIt,"SPAN",{});var rIt=s(E9e);T(Lx.$$.fragment,rIt),rIt.forEach(t),oIt.forEach(t),ELr=i(gHe),C9e=n(gHe,"SPAN",{});var tIt=s(C9e);CLr=r(tIt,"TFAutoModelForSeq2SeqLM"),tIt.forEach(t),gHe.forEach(t),sQe=i(f),lr=n(f,"DIV",{class:!0});var Gl=s(lr);T(yx.$$.fragment,Gl),wLr=i(Gl),Ec=n(Gl,"P",{});var lae=s(Ec);ALr=r(lae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),oK=n(lae,"A",{href:!0});var aIt=s(oK);LLr=r(aIt,"from_pretrained()"),aIt.forEach(t),yLr=r(lae," class method or the "),rK=n(lae,"A",{href:!0});var nIt=s(rK);xLr=r(nIt,"from_config()"),nIt.forEach(t),$Lr=r(lae,` class
method.`),lae.forEach(t),kLr=i(Gl),xx=n(Gl,"P",{});var hHe=s(xx);SLr=r(hHe,"This class cannot be instantiated directly using "),w9e=n(hHe,"CODE",{});var sIt=s(w9e);RLr=r(sIt,"__init__()"),sIt.forEach(t),PLr=r(hHe," (throws an error)."),hHe.forEach(t),BLr=i(Gl),qt=n(Gl,"DIV",{class:!0});var CA=s(qt);T($x.$$.fragment,CA),ILr=i(CA),A9e=n(CA,"P",{});var lIt=s(A9e);NLr=r(lIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),lIt.forEach(t),qLr=i(CA),Cc=n(CA,"P",{});var iae=s(Cc);jLr=r(iae,`Note:
Loading a model from its configuration file does `),L9e=n(iae,"STRONG",{});var iIt=s(L9e);DLr=r(iIt,"not"),iIt.forEach(t),GLr=r(iae,` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=n(iae,"A",{href:!0});var dIt=s(tK);OLr=r(dIt,"from_pretrained()"),dIt.forEach(t),VLr=r(iae," to load the model weights."),iae.forEach(t),XLr=i(CA),T(WM.$$.fragment,CA),CA.forEach(t),zLr=i(Gl),Br=n(Gl,"DIV",{class:!0});var Ol=s(Br);T(kx.$$.fragment,Ol),QLr=i(Ol),y9e=n(Ol,"P",{});var cIt=s(y9e);WLr=r(cIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),cIt.forEach(t),HLr=i(Ol),gn=n(Ol,"P",{});var wA=s(gn);ULr=r(wA,"The model class to instantiate is selected based on the "),x9e=n(wA,"CODE",{});var fIt=s(x9e);JLr=r(fIt,"model_type"),fIt.forEach(t),YLr=r(wA,` property of the config object (either
passed as an argument or loaded from `),$9e=n(wA,"CODE",{});var mIt=s($9e);KLr=r(mIt,"pretrained_model_name_or_path"),mIt.forEach(t),ZLr=r(wA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k9e=n(wA,"CODE",{});var gIt=s(k9e);eyr=r(gIt,"pretrained_model_name_or_path"),gIt.forEach(t),oyr=r(wA,":"),wA.forEach(t),ryr=i(Ol),ye=n(Ol,"UL",{});var Ie=s(ye);HM=n(Ie,"LI",{});var JDe=s(HM);S9e=n(JDe,"STRONG",{});var hIt=s(S9e);tyr=r(hIt,"bart"),hIt.forEach(t),ayr=r(JDe," \u2014 "),aK=n(JDe,"A",{href:!0});var pIt=s(aK);nyr=r(pIt,"TFBartForConditionalGeneration"),pIt.forEach(t),syr=r(JDe," (BART model)"),JDe.forEach(t),lyr=i(Ie),UM=n(Ie,"LI",{});var YDe=s(UM);R9e=n(YDe,"STRONG",{});var _It=s(R9e);iyr=r(_It,"blenderbot"),_It.forEach(t),dyr=r(YDe," \u2014 "),nK=n(YDe,"A",{href:!0});var uIt=s(nK);cyr=r(uIt,"TFBlenderbotForConditionalGeneration"),uIt.forEach(t),fyr=r(YDe," (Blenderbot model)"),YDe.forEach(t),myr=i(Ie),JM=n(Ie,"LI",{});var KDe=s(JM);P9e=n(KDe,"STRONG",{});var bIt=s(P9e);gyr=r(bIt,"blenderbot-small"),bIt.forEach(t),hyr=r(KDe," \u2014 "),sK=n(KDe,"A",{href:!0});var vIt=s(sK);pyr=r(vIt,"TFBlenderbotSmallForConditionalGeneration"),vIt.forEach(t),_yr=r(KDe," (BlenderbotSmall model)"),KDe.forEach(t),uyr=i(Ie),YM=n(Ie,"LI",{});var ZDe=s(YM);B9e=n(ZDe,"STRONG",{});var FIt=s(B9e);byr=r(FIt,"encoder-decoder"),FIt.forEach(t),vyr=r(ZDe," \u2014 "),lK=n(ZDe,"A",{href:!0});var TIt=s(lK);Fyr=r(TIt,"TFEncoderDecoderModel"),TIt.forEach(t),Tyr=r(ZDe," (Encoder decoder model)"),ZDe.forEach(t),Myr=i(Ie),KM=n(Ie,"LI",{});var eGe=s(KM);I9e=n(eGe,"STRONG",{});var MIt=s(I9e);Eyr=r(MIt,"led"),MIt.forEach(t),Cyr=r(eGe," \u2014 "),iK=n(eGe,"A",{href:!0});var EIt=s(iK);wyr=r(EIt,"TFLEDForConditionalGeneration"),EIt.forEach(t),Ayr=r(eGe," (LED model)"),eGe.forEach(t),Lyr=i(Ie),ZM=n(Ie,"LI",{});var oGe=s(ZM);N9e=n(oGe,"STRONG",{});var CIt=s(N9e);yyr=r(CIt,"marian"),CIt.forEach(t),xyr=r(oGe," \u2014 "),dK=n(oGe,"A",{href:!0});var wIt=s(dK);$yr=r(wIt,"TFMarianMTModel"),wIt.forEach(t),kyr=r(oGe," (Marian model)"),oGe.forEach(t),Syr=i(Ie),eE=n(Ie,"LI",{});var rGe=s(eE);q9e=n(rGe,"STRONG",{});var AIt=s(q9e);Ryr=r(AIt,"mbart"),AIt.forEach(t),Pyr=r(rGe," \u2014 "),cK=n(rGe,"A",{href:!0});var LIt=s(cK);Byr=r(LIt,"TFMBartForConditionalGeneration"),LIt.forEach(t),Iyr=r(rGe," (mBART model)"),rGe.forEach(t),Nyr=i(Ie),oE=n(Ie,"LI",{});var tGe=s(oE);j9e=n(tGe,"STRONG",{});var yIt=s(j9e);qyr=r(yIt,"mt5"),yIt.forEach(t),jyr=r(tGe," \u2014 "),fK=n(tGe,"A",{href:!0});var xIt=s(fK);Dyr=r(xIt,"TFMT5ForConditionalGeneration"),xIt.forEach(t),Gyr=r(tGe," (MT5 model)"),tGe.forEach(t),Oyr=i(Ie),rE=n(Ie,"LI",{});var aGe=s(rE);D9e=n(aGe,"STRONG",{});var $It=s(D9e);Vyr=r($It,"pegasus"),$It.forEach(t),Xyr=r(aGe," \u2014 "),mK=n(aGe,"A",{href:!0});var kIt=s(mK);zyr=r(kIt,"TFPegasusForConditionalGeneration"),kIt.forEach(t),Qyr=r(aGe," (Pegasus model)"),aGe.forEach(t),Wyr=i(Ie),tE=n(Ie,"LI",{});var nGe=s(tE);G9e=n(nGe,"STRONG",{});var SIt=s(G9e);Hyr=r(SIt,"t5"),SIt.forEach(t),Uyr=r(nGe," \u2014 "),gK=n(nGe,"A",{href:!0});var RIt=s(gK);Jyr=r(RIt,"TFT5ForConditionalGeneration"),RIt.forEach(t),Yyr=r(nGe," (T5 model)"),nGe.forEach(t),Ie.forEach(t),Kyr=i(Ol),T(aE.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),lQe=i(f),wc=n(f,"H2",{class:!0});var pHe=s(wc);nE=n(pHe,"A",{id:!0,class:!0,href:!0});var PIt=s(nE);O9e=n(PIt,"SPAN",{});var BIt=s(O9e);T(Sx.$$.fragment,BIt),BIt.forEach(t),PIt.forEach(t),Zyr=i(pHe),V9e=n(pHe,"SPAN",{});var IIt=s(V9e);e8r=r(IIt,"TFAutoModelForSequenceClassification"),IIt.forEach(t),pHe.forEach(t),iQe=i(f),ir=n(f,"DIV",{class:!0});var Vl=s(ir);T(Rx.$$.fragment,Vl),o8r=i(Vl),Ac=n(Vl,"P",{});var dae=s(Ac);r8r=r(dae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hK=n(dae,"A",{href:!0});var NIt=s(hK);t8r=r(NIt,"from_pretrained()"),NIt.forEach(t),a8r=r(dae," class method or the "),pK=n(dae,"A",{href:!0});var qIt=s(pK);n8r=r(qIt,"from_config()"),qIt.forEach(t),s8r=r(dae,` class
method.`),dae.forEach(t),l8r=i(Vl),Px=n(Vl,"P",{});var _He=s(Px);i8r=r(_He,"This class cannot be instantiated directly using "),X9e=n(_He,"CODE",{});var jIt=s(X9e);d8r=r(jIt,"__init__()"),jIt.forEach(t),c8r=r(_He," (throws an error)."),_He.forEach(t),f8r=i(Vl),jt=n(Vl,"DIV",{class:!0});var AA=s(jt);T(Bx.$$.fragment,AA),m8r=i(AA),z9e=n(AA,"P",{});var DIt=s(z9e);g8r=r(DIt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),DIt.forEach(t),h8r=i(AA),Lc=n(AA,"P",{});var cae=s(Lc);p8r=r(cae,`Note:
Loading a model from its configuration file does `),Q9e=n(cae,"STRONG",{});var GIt=s(Q9e);_8r=r(GIt,"not"),GIt.forEach(t),u8r=r(cae,` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=n(cae,"A",{href:!0});var OIt=s(_K);b8r=r(OIt,"from_pretrained()"),OIt.forEach(t),v8r=r(cae," to load the model weights."),cae.forEach(t),F8r=i(AA),T(sE.$$.fragment,AA),AA.forEach(t),T8r=i(Vl),Ir=n(Vl,"DIV",{class:!0});var Xl=s(Ir);T(Ix.$$.fragment,Xl),M8r=i(Xl),W9e=n(Xl,"P",{});var VIt=s(W9e);E8r=r(VIt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),VIt.forEach(t),C8r=i(Xl),hn=n(Xl,"P",{});var LA=s(hn);w8r=r(LA,"The model class to instantiate is selected based on the "),H9e=n(LA,"CODE",{});var XIt=s(H9e);A8r=r(XIt,"model_type"),XIt.forEach(t),L8r=r(LA,` property of the config object (either
passed as an argument or loaded from `),U9e=n(LA,"CODE",{});var zIt=s(U9e);y8r=r(zIt,"pretrained_model_name_or_path"),zIt.forEach(t),x8r=r(LA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J9e=n(LA,"CODE",{});var QIt=s(J9e);$8r=r(QIt,"pretrained_model_name_or_path"),QIt.forEach(t),k8r=r(LA,":"),LA.forEach(t),S8r=i(Xl),te=n(Xl,"UL",{});var ne=s(te);lE=n(ne,"LI",{});var sGe=s(lE);Y9e=n(sGe,"STRONG",{});var WIt=s(Y9e);R8r=r(WIt,"albert"),WIt.forEach(t),P8r=r(sGe," \u2014 "),uK=n(sGe,"A",{href:!0});var HIt=s(uK);B8r=r(HIt,"TFAlbertForSequenceClassification"),HIt.forEach(t),I8r=r(sGe," (ALBERT model)"),sGe.forEach(t),N8r=i(ne),iE=n(ne,"LI",{});var lGe=s(iE);K9e=n(lGe,"STRONG",{});var UIt=s(K9e);q8r=r(UIt,"bert"),UIt.forEach(t),j8r=r(lGe," \u2014 "),bK=n(lGe,"A",{href:!0});var JIt=s(bK);D8r=r(JIt,"TFBertForSequenceClassification"),JIt.forEach(t),G8r=r(lGe," (BERT model)"),lGe.forEach(t),O8r=i(ne),dE=n(ne,"LI",{});var iGe=s(dE);Z9e=n(iGe,"STRONG",{});var YIt=s(Z9e);V8r=r(YIt,"camembert"),YIt.forEach(t),X8r=r(iGe," \u2014 "),vK=n(iGe,"A",{href:!0});var KIt=s(vK);z8r=r(KIt,"TFCamembertForSequenceClassification"),KIt.forEach(t),Q8r=r(iGe," (CamemBERT model)"),iGe.forEach(t),W8r=i(ne),cE=n(ne,"LI",{});var dGe=s(cE);eMe=n(dGe,"STRONG",{});var ZIt=s(eMe);H8r=r(ZIt,"convbert"),ZIt.forEach(t),U8r=r(dGe," \u2014 "),FK=n(dGe,"A",{href:!0});var eNt=s(FK);J8r=r(eNt,"TFConvBertForSequenceClassification"),eNt.forEach(t),Y8r=r(dGe," (ConvBERT model)"),dGe.forEach(t),K8r=i(ne),fE=n(ne,"LI",{});var cGe=s(fE);oMe=n(cGe,"STRONG",{});var oNt=s(oMe);Z8r=r(oNt,"ctrl"),oNt.forEach(t),exr=r(cGe," \u2014 "),TK=n(cGe,"A",{href:!0});var rNt=s(TK);oxr=r(rNt,"TFCTRLForSequenceClassification"),rNt.forEach(t),rxr=r(cGe," (CTRL model)"),cGe.forEach(t),txr=i(ne),mE=n(ne,"LI",{});var fGe=s(mE);rMe=n(fGe,"STRONG",{});var tNt=s(rMe);axr=r(tNt,"deberta"),tNt.forEach(t),nxr=r(fGe," \u2014 "),MK=n(fGe,"A",{href:!0});var aNt=s(MK);sxr=r(aNt,"TFDebertaForSequenceClassification"),aNt.forEach(t),lxr=r(fGe," (DeBERTa model)"),fGe.forEach(t),ixr=i(ne),gE=n(ne,"LI",{});var mGe=s(gE);tMe=n(mGe,"STRONG",{});var nNt=s(tMe);dxr=r(nNt,"deberta-v2"),nNt.forEach(t),cxr=r(mGe," \u2014 "),EK=n(mGe,"A",{href:!0});var sNt=s(EK);fxr=r(sNt,"TFDebertaV2ForSequenceClassification"),sNt.forEach(t),mxr=r(mGe," (DeBERTa-v2 model)"),mGe.forEach(t),gxr=i(ne),hE=n(ne,"LI",{});var gGe=s(hE);aMe=n(gGe,"STRONG",{});var lNt=s(aMe);hxr=r(lNt,"distilbert"),lNt.forEach(t),pxr=r(gGe," \u2014 "),CK=n(gGe,"A",{href:!0});var iNt=s(CK);_xr=r(iNt,"TFDistilBertForSequenceClassification"),iNt.forEach(t),uxr=r(gGe," (DistilBERT model)"),gGe.forEach(t),bxr=i(ne),pE=n(ne,"LI",{});var hGe=s(pE);nMe=n(hGe,"STRONG",{});var dNt=s(nMe);vxr=r(dNt,"electra"),dNt.forEach(t),Fxr=r(hGe," \u2014 "),wK=n(hGe,"A",{href:!0});var cNt=s(wK);Txr=r(cNt,"TFElectraForSequenceClassification"),cNt.forEach(t),Mxr=r(hGe," (ELECTRA model)"),hGe.forEach(t),Exr=i(ne),_E=n(ne,"LI",{});var pGe=s(_E);sMe=n(pGe,"STRONG",{});var fNt=s(sMe);Cxr=r(fNt,"flaubert"),fNt.forEach(t),wxr=r(pGe," \u2014 "),AK=n(pGe,"A",{href:!0});var mNt=s(AK);Axr=r(mNt,"TFFlaubertForSequenceClassification"),mNt.forEach(t),Lxr=r(pGe," (FlauBERT model)"),pGe.forEach(t),yxr=i(ne),uE=n(ne,"LI",{});var _Ge=s(uE);lMe=n(_Ge,"STRONG",{});var gNt=s(lMe);xxr=r(gNt,"funnel"),gNt.forEach(t),$xr=r(_Ge," \u2014 "),LK=n(_Ge,"A",{href:!0});var hNt=s(LK);kxr=r(hNt,"TFFunnelForSequenceClassification"),hNt.forEach(t),Sxr=r(_Ge," (Funnel Transformer model)"),_Ge.forEach(t),Rxr=i(ne),bE=n(ne,"LI",{});var uGe=s(bE);iMe=n(uGe,"STRONG",{});var pNt=s(iMe);Pxr=r(pNt,"gpt2"),pNt.forEach(t),Bxr=r(uGe," \u2014 "),yK=n(uGe,"A",{href:!0});var _Nt=s(yK);Ixr=r(_Nt,"TFGPT2ForSequenceClassification"),_Nt.forEach(t),Nxr=r(uGe," (OpenAI GPT-2 model)"),uGe.forEach(t),qxr=i(ne),vE=n(ne,"LI",{});var bGe=s(vE);dMe=n(bGe,"STRONG",{});var uNt=s(dMe);jxr=r(uNt,"gptj"),uNt.forEach(t),Dxr=r(bGe," \u2014 "),xK=n(bGe,"A",{href:!0});var bNt=s(xK);Gxr=r(bNt,"TFGPTJForSequenceClassification"),bNt.forEach(t),Oxr=r(bGe," (GPT-J model)"),bGe.forEach(t),Vxr=i(ne),FE=n(ne,"LI",{});var vGe=s(FE);cMe=n(vGe,"STRONG",{});var vNt=s(cMe);Xxr=r(vNt,"layoutlm"),vNt.forEach(t),zxr=r(vGe," \u2014 "),$K=n(vGe,"A",{href:!0});var FNt=s($K);Qxr=r(FNt,"TFLayoutLMForSequenceClassification"),FNt.forEach(t),Wxr=r(vGe," (LayoutLM model)"),vGe.forEach(t),Hxr=i(ne),TE=n(ne,"LI",{});var FGe=s(TE);fMe=n(FGe,"STRONG",{});var TNt=s(fMe);Uxr=r(TNt,"longformer"),TNt.forEach(t),Jxr=r(FGe," \u2014 "),kK=n(FGe,"A",{href:!0});var MNt=s(kK);Yxr=r(MNt,"TFLongformerForSequenceClassification"),MNt.forEach(t),Kxr=r(FGe," (Longformer model)"),FGe.forEach(t),Zxr=i(ne),ME=n(ne,"LI",{});var TGe=s(ME);mMe=n(TGe,"STRONG",{});var ENt=s(mMe);e$r=r(ENt,"mobilebert"),ENt.forEach(t),o$r=r(TGe," \u2014 "),SK=n(TGe,"A",{href:!0});var CNt=s(SK);r$r=r(CNt,"TFMobileBertForSequenceClassification"),CNt.forEach(t),t$r=r(TGe," (MobileBERT model)"),TGe.forEach(t),a$r=i(ne),EE=n(ne,"LI",{});var MGe=s(EE);gMe=n(MGe,"STRONG",{});var wNt=s(gMe);n$r=r(wNt,"mpnet"),wNt.forEach(t),s$r=r(MGe," \u2014 "),RK=n(MGe,"A",{href:!0});var ANt=s(RK);l$r=r(ANt,"TFMPNetForSequenceClassification"),ANt.forEach(t),i$r=r(MGe," (MPNet model)"),MGe.forEach(t),d$r=i(ne),CE=n(ne,"LI",{});var EGe=s(CE);hMe=n(EGe,"STRONG",{});var LNt=s(hMe);c$r=r(LNt,"openai-gpt"),LNt.forEach(t),f$r=r(EGe," \u2014 "),PK=n(EGe,"A",{href:!0});var yNt=s(PK);m$r=r(yNt,"TFOpenAIGPTForSequenceClassification"),yNt.forEach(t),g$r=r(EGe," (OpenAI GPT model)"),EGe.forEach(t),h$r=i(ne),wE=n(ne,"LI",{});var CGe=s(wE);pMe=n(CGe,"STRONG",{});var xNt=s(pMe);p$r=r(xNt,"rembert"),xNt.forEach(t),_$r=r(CGe," \u2014 "),BK=n(CGe,"A",{href:!0});var $Nt=s(BK);u$r=r($Nt,"TFRemBertForSequenceClassification"),$Nt.forEach(t),b$r=r(CGe," (RemBERT model)"),CGe.forEach(t),v$r=i(ne),AE=n(ne,"LI",{});var wGe=s(AE);_Me=n(wGe,"STRONG",{});var kNt=s(_Me);F$r=r(kNt,"roberta"),kNt.forEach(t),T$r=r(wGe," \u2014 "),IK=n(wGe,"A",{href:!0});var SNt=s(IK);M$r=r(SNt,"TFRobertaForSequenceClassification"),SNt.forEach(t),E$r=r(wGe," (RoBERTa model)"),wGe.forEach(t),C$r=i(ne),LE=n(ne,"LI",{});var AGe=s(LE);uMe=n(AGe,"STRONG",{});var RNt=s(uMe);w$r=r(RNt,"roformer"),RNt.forEach(t),A$r=r(AGe," \u2014 "),NK=n(AGe,"A",{href:!0});var PNt=s(NK);L$r=r(PNt,"TFRoFormerForSequenceClassification"),PNt.forEach(t),y$r=r(AGe," (RoFormer model)"),AGe.forEach(t),x$r=i(ne),yE=n(ne,"LI",{});var LGe=s(yE);bMe=n(LGe,"STRONG",{});var BNt=s(bMe);$$r=r(BNt,"tapas"),BNt.forEach(t),k$r=r(LGe," \u2014 "),qK=n(LGe,"A",{href:!0});var INt=s(qK);S$r=r(INt,"TFTapasForSequenceClassification"),INt.forEach(t),R$r=r(LGe," (TAPAS model)"),LGe.forEach(t),P$r=i(ne),xE=n(ne,"LI",{});var yGe=s(xE);vMe=n(yGe,"STRONG",{});var NNt=s(vMe);B$r=r(NNt,"transfo-xl"),NNt.forEach(t),I$r=r(yGe," \u2014 "),jK=n(yGe,"A",{href:!0});var qNt=s(jK);N$r=r(qNt,"TFTransfoXLForSequenceClassification"),qNt.forEach(t),q$r=r(yGe," (Transformer-XL model)"),yGe.forEach(t),j$r=i(ne),$E=n(ne,"LI",{});var xGe=s($E);FMe=n(xGe,"STRONG",{});var jNt=s(FMe);D$r=r(jNt,"xlm"),jNt.forEach(t),G$r=r(xGe," \u2014 "),DK=n(xGe,"A",{href:!0});var DNt=s(DK);O$r=r(DNt,"TFXLMForSequenceClassification"),DNt.forEach(t),V$r=r(xGe," (XLM model)"),xGe.forEach(t),X$r=i(ne),kE=n(ne,"LI",{});var $Ge=s(kE);TMe=n($Ge,"STRONG",{});var GNt=s(TMe);z$r=r(GNt,"xlm-roberta"),GNt.forEach(t),Q$r=r($Ge," \u2014 "),GK=n($Ge,"A",{href:!0});var ONt=s(GK);W$r=r(ONt,"TFXLMRobertaForSequenceClassification"),ONt.forEach(t),H$r=r($Ge," (XLM-RoBERTa model)"),$Ge.forEach(t),U$r=i(ne),SE=n(ne,"LI",{});var kGe=s(SE);MMe=n(kGe,"STRONG",{});var VNt=s(MMe);J$r=r(VNt,"xlnet"),VNt.forEach(t),Y$r=r(kGe," \u2014 "),OK=n(kGe,"A",{href:!0});var XNt=s(OK);K$r=r(XNt,"TFXLNetForSequenceClassification"),XNt.forEach(t),Z$r=r(kGe," (XLNet model)"),kGe.forEach(t),ne.forEach(t),ekr=i(Xl),T(RE.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),dQe=i(f),yc=n(f,"H2",{class:!0});var uHe=s(yc);PE=n(uHe,"A",{id:!0,class:!0,href:!0});var zNt=s(PE);EMe=n(zNt,"SPAN",{});var QNt=s(EMe);T(Nx.$$.fragment,QNt),QNt.forEach(t),zNt.forEach(t),okr=i(uHe),CMe=n(uHe,"SPAN",{});var WNt=s(CMe);rkr=r(WNt,"TFAutoModelForMultipleChoice"),WNt.forEach(t),uHe.forEach(t),cQe=i(f),dr=n(f,"DIV",{class:!0});var zl=s(dr);T(qx.$$.fragment,zl),tkr=i(zl),xc=n(zl,"P",{});var fae=s(xc);akr=r(fae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),VK=n(fae,"A",{href:!0});var HNt=s(VK);nkr=r(HNt,"from_pretrained()"),HNt.forEach(t),skr=r(fae," class method or the "),XK=n(fae,"A",{href:!0});var UNt=s(XK);lkr=r(UNt,"from_config()"),UNt.forEach(t),ikr=r(fae,` class
method.`),fae.forEach(t),dkr=i(zl),jx=n(zl,"P",{});var bHe=s(jx);ckr=r(bHe,"This class cannot be instantiated directly using "),wMe=n(bHe,"CODE",{});var JNt=s(wMe);fkr=r(JNt,"__init__()"),JNt.forEach(t),mkr=r(bHe," (throws an error)."),bHe.forEach(t),gkr=i(zl),Dt=n(zl,"DIV",{class:!0});var yA=s(Dt);T(Dx.$$.fragment,yA),hkr=i(yA),AMe=n(yA,"P",{});var YNt=s(AMe);pkr=r(YNt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),YNt.forEach(t),_kr=i(yA),$c=n(yA,"P",{});var mae=s($c);ukr=r(mae,`Note:
Loading a model from its configuration file does `),LMe=n(mae,"STRONG",{});var KNt=s(LMe);bkr=r(KNt,"not"),KNt.forEach(t),vkr=r(mae,` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=n(mae,"A",{href:!0});var ZNt=s(zK);Fkr=r(ZNt,"from_pretrained()"),ZNt.forEach(t),Tkr=r(mae," to load the model weights."),mae.forEach(t),Mkr=i(yA),T(BE.$$.fragment,yA),yA.forEach(t),Ekr=i(zl),Nr=n(zl,"DIV",{class:!0});var Ql=s(Nr);T(Gx.$$.fragment,Ql),Ckr=i(Ql),yMe=n(Ql,"P",{});var eqt=s(yMe);wkr=r(eqt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),eqt.forEach(t),Akr=i(Ql),pn=n(Ql,"P",{});var xA=s(pn);Lkr=r(xA,"The model class to instantiate is selected based on the "),xMe=n(xA,"CODE",{});var oqt=s(xMe);ykr=r(oqt,"model_type"),oqt.forEach(t),xkr=r(xA,` property of the config object (either
passed as an argument or loaded from `),$Me=n(xA,"CODE",{});var rqt=s($Me);$kr=r(rqt,"pretrained_model_name_or_path"),rqt.forEach(t),kkr=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kMe=n(xA,"CODE",{});var tqt=s(kMe);Skr=r(tqt,"pretrained_model_name_or_path"),tqt.forEach(t),Rkr=r(xA,":"),xA.forEach(t),Pkr=i(Ql),be=n(Ql,"UL",{});var Te=s(be);IE=n(Te,"LI",{});var SGe=s(IE);SMe=n(SGe,"STRONG",{});var aqt=s(SMe);Bkr=r(aqt,"albert"),aqt.forEach(t),Ikr=r(SGe," \u2014 "),QK=n(SGe,"A",{href:!0});var nqt=s(QK);Nkr=r(nqt,"TFAlbertForMultipleChoice"),nqt.forEach(t),qkr=r(SGe," (ALBERT model)"),SGe.forEach(t),jkr=i(Te),NE=n(Te,"LI",{});var RGe=s(NE);RMe=n(RGe,"STRONG",{});var sqt=s(RMe);Dkr=r(sqt,"bert"),sqt.forEach(t),Gkr=r(RGe," \u2014 "),WK=n(RGe,"A",{href:!0});var lqt=s(WK);Okr=r(lqt,"TFBertForMultipleChoice"),lqt.forEach(t),Vkr=r(RGe," (BERT model)"),RGe.forEach(t),Xkr=i(Te),qE=n(Te,"LI",{});var PGe=s(qE);PMe=n(PGe,"STRONG",{});var iqt=s(PMe);zkr=r(iqt,"camembert"),iqt.forEach(t),Qkr=r(PGe," \u2014 "),HK=n(PGe,"A",{href:!0});var dqt=s(HK);Wkr=r(dqt,"TFCamembertForMultipleChoice"),dqt.forEach(t),Hkr=r(PGe," (CamemBERT model)"),PGe.forEach(t),Ukr=i(Te),jE=n(Te,"LI",{});var BGe=s(jE);BMe=n(BGe,"STRONG",{});var cqt=s(BMe);Jkr=r(cqt,"convbert"),cqt.forEach(t),Ykr=r(BGe," \u2014 "),UK=n(BGe,"A",{href:!0});var fqt=s(UK);Kkr=r(fqt,"TFConvBertForMultipleChoice"),fqt.forEach(t),Zkr=r(BGe," (ConvBERT model)"),BGe.forEach(t),eSr=i(Te),DE=n(Te,"LI",{});var IGe=s(DE);IMe=n(IGe,"STRONG",{});var mqt=s(IMe);oSr=r(mqt,"distilbert"),mqt.forEach(t),rSr=r(IGe," \u2014 "),JK=n(IGe,"A",{href:!0});var gqt=s(JK);tSr=r(gqt,"TFDistilBertForMultipleChoice"),gqt.forEach(t),aSr=r(IGe," (DistilBERT model)"),IGe.forEach(t),nSr=i(Te),GE=n(Te,"LI",{});var NGe=s(GE);NMe=n(NGe,"STRONG",{});var hqt=s(NMe);sSr=r(hqt,"electra"),hqt.forEach(t),lSr=r(NGe," \u2014 "),YK=n(NGe,"A",{href:!0});var pqt=s(YK);iSr=r(pqt,"TFElectraForMultipleChoice"),pqt.forEach(t),dSr=r(NGe," (ELECTRA model)"),NGe.forEach(t),cSr=i(Te),OE=n(Te,"LI",{});var qGe=s(OE);qMe=n(qGe,"STRONG",{});var _qt=s(qMe);fSr=r(_qt,"flaubert"),_qt.forEach(t),mSr=r(qGe," \u2014 "),KK=n(qGe,"A",{href:!0});var uqt=s(KK);gSr=r(uqt,"TFFlaubertForMultipleChoice"),uqt.forEach(t),hSr=r(qGe," (FlauBERT model)"),qGe.forEach(t),pSr=i(Te),VE=n(Te,"LI",{});var jGe=s(VE);jMe=n(jGe,"STRONG",{});var bqt=s(jMe);_Sr=r(bqt,"funnel"),bqt.forEach(t),uSr=r(jGe," \u2014 "),ZK=n(jGe,"A",{href:!0});var vqt=s(ZK);bSr=r(vqt,"TFFunnelForMultipleChoice"),vqt.forEach(t),vSr=r(jGe," (Funnel Transformer model)"),jGe.forEach(t),FSr=i(Te),XE=n(Te,"LI",{});var DGe=s(XE);DMe=n(DGe,"STRONG",{});var Fqt=s(DMe);TSr=r(Fqt,"longformer"),Fqt.forEach(t),MSr=r(DGe," \u2014 "),eZ=n(DGe,"A",{href:!0});var Tqt=s(eZ);ESr=r(Tqt,"TFLongformerForMultipleChoice"),Tqt.forEach(t),CSr=r(DGe," (Longformer model)"),DGe.forEach(t),wSr=i(Te),zE=n(Te,"LI",{});var GGe=s(zE);GMe=n(GGe,"STRONG",{});var Mqt=s(GMe);ASr=r(Mqt,"mobilebert"),Mqt.forEach(t),LSr=r(GGe," \u2014 "),oZ=n(GGe,"A",{href:!0});var Eqt=s(oZ);ySr=r(Eqt,"TFMobileBertForMultipleChoice"),Eqt.forEach(t),xSr=r(GGe," (MobileBERT model)"),GGe.forEach(t),$Sr=i(Te),QE=n(Te,"LI",{});var OGe=s(QE);OMe=n(OGe,"STRONG",{});var Cqt=s(OMe);kSr=r(Cqt,"mpnet"),Cqt.forEach(t),SSr=r(OGe," \u2014 "),rZ=n(OGe,"A",{href:!0});var wqt=s(rZ);RSr=r(wqt,"TFMPNetForMultipleChoice"),wqt.forEach(t),PSr=r(OGe," (MPNet model)"),OGe.forEach(t),BSr=i(Te),WE=n(Te,"LI",{});var VGe=s(WE);VMe=n(VGe,"STRONG",{});var Aqt=s(VMe);ISr=r(Aqt,"rembert"),Aqt.forEach(t),NSr=r(VGe," \u2014 "),tZ=n(VGe,"A",{href:!0});var Lqt=s(tZ);qSr=r(Lqt,"TFRemBertForMultipleChoice"),Lqt.forEach(t),jSr=r(VGe," (RemBERT model)"),VGe.forEach(t),DSr=i(Te),HE=n(Te,"LI",{});var XGe=s(HE);XMe=n(XGe,"STRONG",{});var yqt=s(XMe);GSr=r(yqt,"roberta"),yqt.forEach(t),OSr=r(XGe," \u2014 "),aZ=n(XGe,"A",{href:!0});var xqt=s(aZ);VSr=r(xqt,"TFRobertaForMultipleChoice"),xqt.forEach(t),XSr=r(XGe," (RoBERTa model)"),XGe.forEach(t),zSr=i(Te),UE=n(Te,"LI",{});var zGe=s(UE);zMe=n(zGe,"STRONG",{});var $qt=s(zMe);QSr=r($qt,"roformer"),$qt.forEach(t),WSr=r(zGe," \u2014 "),nZ=n(zGe,"A",{href:!0});var kqt=s(nZ);HSr=r(kqt,"TFRoFormerForMultipleChoice"),kqt.forEach(t),USr=r(zGe," (RoFormer model)"),zGe.forEach(t),JSr=i(Te),JE=n(Te,"LI",{});var QGe=s(JE);QMe=n(QGe,"STRONG",{});var Sqt=s(QMe);YSr=r(Sqt,"xlm"),Sqt.forEach(t),KSr=r(QGe," \u2014 "),sZ=n(QGe,"A",{href:!0});var Rqt=s(sZ);ZSr=r(Rqt,"TFXLMForMultipleChoice"),Rqt.forEach(t),eRr=r(QGe," (XLM model)"),QGe.forEach(t),oRr=i(Te),YE=n(Te,"LI",{});var WGe=s(YE);WMe=n(WGe,"STRONG",{});var Pqt=s(WMe);rRr=r(Pqt,"xlm-roberta"),Pqt.forEach(t),tRr=r(WGe," \u2014 "),lZ=n(WGe,"A",{href:!0});var Bqt=s(lZ);aRr=r(Bqt,"TFXLMRobertaForMultipleChoice"),Bqt.forEach(t),nRr=r(WGe," (XLM-RoBERTa model)"),WGe.forEach(t),sRr=i(Te),KE=n(Te,"LI",{});var HGe=s(KE);HMe=n(HGe,"STRONG",{});var Iqt=s(HMe);lRr=r(Iqt,"xlnet"),Iqt.forEach(t),iRr=r(HGe," \u2014 "),iZ=n(HGe,"A",{href:!0});var Nqt=s(iZ);dRr=r(Nqt,"TFXLNetForMultipleChoice"),Nqt.forEach(t),cRr=r(HGe," (XLNet model)"),HGe.forEach(t),Te.forEach(t),fRr=i(Ql),T(ZE.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),fQe=i(f),kc=n(f,"H2",{class:!0});var vHe=s(kc);eC=n(vHe,"A",{id:!0,class:!0,href:!0});var qqt=s(eC);UMe=n(qqt,"SPAN",{});var jqt=s(UMe);T(Ox.$$.fragment,jqt),jqt.forEach(t),qqt.forEach(t),mRr=i(vHe),JMe=n(vHe,"SPAN",{});var Dqt=s(JMe);gRr=r(Dqt,"TFAutoModelForNextSentencePrediction"),Dqt.forEach(t),vHe.forEach(t),mQe=i(f),cr=n(f,"DIV",{class:!0});var Wl=s(cr);T(Vx.$$.fragment,Wl),hRr=i(Wl),Sc=n(Wl,"P",{});var gae=s(Sc);pRr=r(gae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),dZ=n(gae,"A",{href:!0});var Gqt=s(dZ);_Rr=r(Gqt,"from_pretrained()"),Gqt.forEach(t),uRr=r(gae," class method or the "),cZ=n(gae,"A",{href:!0});var Oqt=s(cZ);bRr=r(Oqt,"from_config()"),Oqt.forEach(t),vRr=r(gae,` class
method.`),gae.forEach(t),FRr=i(Wl),Xx=n(Wl,"P",{});var FHe=s(Xx);TRr=r(FHe,"This class cannot be instantiated directly using "),YMe=n(FHe,"CODE",{});var Vqt=s(YMe);MRr=r(Vqt,"__init__()"),Vqt.forEach(t),ERr=r(FHe," (throws an error)."),FHe.forEach(t),CRr=i(Wl),Gt=n(Wl,"DIV",{class:!0});var $A=s(Gt);T(zx.$$.fragment,$A),wRr=i($A),KMe=n($A,"P",{});var Xqt=s(KMe);ARr=r(Xqt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Xqt.forEach(t),LRr=i($A),Rc=n($A,"P",{});var hae=s(Rc);yRr=r(hae,`Note:
Loading a model from its configuration file does `),ZMe=n(hae,"STRONG",{});var zqt=s(ZMe);xRr=r(zqt,"not"),zqt.forEach(t),$Rr=r(hae,` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=n(hae,"A",{href:!0});var Qqt=s(fZ);kRr=r(Qqt,"from_pretrained()"),Qqt.forEach(t),SRr=r(hae," to load the model weights."),hae.forEach(t),RRr=i($A),T(oC.$$.fragment,$A),$A.forEach(t),PRr=i(Wl),qr=n(Wl,"DIV",{class:!0});var Hl=s(qr);T(Qx.$$.fragment,Hl),BRr=i(Hl),eEe=n(Hl,"P",{});var Wqt=s(eEe);IRr=r(Wqt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Wqt.forEach(t),NRr=i(Hl),_n=n(Hl,"P",{});var kA=s(_n);qRr=r(kA,"The model class to instantiate is selected based on the "),oEe=n(kA,"CODE",{});var Hqt=s(oEe);jRr=r(Hqt,"model_type"),Hqt.forEach(t),DRr=r(kA,` property of the config object (either
passed as an argument or loaded from `),rEe=n(kA,"CODE",{});var Uqt=s(rEe);GRr=r(Uqt,"pretrained_model_name_or_path"),Uqt.forEach(t),ORr=r(kA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=n(kA,"CODE",{});var Jqt=s(tEe);VRr=r(Jqt,"pretrained_model_name_or_path"),Jqt.forEach(t),XRr=r(kA,":"),kA.forEach(t),zRr=i(Hl),Wx=n(Hl,"UL",{});var THe=s(Wx);rC=n(THe,"LI",{});var UGe=s(rC);aEe=n(UGe,"STRONG",{});var Yqt=s(aEe);QRr=r(Yqt,"bert"),Yqt.forEach(t),WRr=r(UGe," \u2014 "),mZ=n(UGe,"A",{href:!0});var Kqt=s(mZ);HRr=r(Kqt,"TFBertForNextSentencePrediction"),Kqt.forEach(t),URr=r(UGe," (BERT model)"),UGe.forEach(t),JRr=i(THe),tC=n(THe,"LI",{});var JGe=s(tC);nEe=n(JGe,"STRONG",{});var Zqt=s(nEe);YRr=r(Zqt,"mobilebert"),Zqt.forEach(t),KRr=r(JGe," \u2014 "),gZ=n(JGe,"A",{href:!0});var ejt=s(gZ);ZRr=r(ejt,"TFMobileBertForNextSentencePrediction"),ejt.forEach(t),ePr=r(JGe," (MobileBERT model)"),JGe.forEach(t),THe.forEach(t),oPr=i(Hl),T(aC.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),gQe=i(f),Pc=n(f,"H2",{class:!0});var MHe=s(Pc);nC=n(MHe,"A",{id:!0,class:!0,href:!0});var ojt=s(nC);sEe=n(ojt,"SPAN",{});var rjt=s(sEe);T(Hx.$$.fragment,rjt),rjt.forEach(t),ojt.forEach(t),rPr=i(MHe),lEe=n(MHe,"SPAN",{});var tjt=s(lEe);tPr=r(tjt,"TFAutoModelForTableQuestionAnswering"),tjt.forEach(t),MHe.forEach(t),hQe=i(f),fr=n(f,"DIV",{class:!0});var Ul=s(fr);T(Ux.$$.fragment,Ul),aPr=i(Ul),Bc=n(Ul,"P",{});var pae=s(Bc);nPr=r(pae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),hZ=n(pae,"A",{href:!0});var ajt=s(hZ);sPr=r(ajt,"from_pretrained()"),ajt.forEach(t),lPr=r(pae," class method or the "),pZ=n(pae,"A",{href:!0});var njt=s(pZ);iPr=r(njt,"from_config()"),njt.forEach(t),dPr=r(pae,` class
method.`),pae.forEach(t),cPr=i(Ul),Jx=n(Ul,"P",{});var EHe=s(Jx);fPr=r(EHe,"This class cannot be instantiated directly using "),iEe=n(EHe,"CODE",{});var sjt=s(iEe);mPr=r(sjt,"__init__()"),sjt.forEach(t),gPr=r(EHe," (throws an error)."),EHe.forEach(t),hPr=i(Ul),Ot=n(Ul,"DIV",{class:!0});var SA=s(Ot);T(Yx.$$.fragment,SA),pPr=i(SA),dEe=n(SA,"P",{});var ljt=s(dEe);_Pr=r(ljt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ljt.forEach(t),uPr=i(SA),Ic=n(SA,"P",{});var _ae=s(Ic);bPr=r(_ae,`Note:
Loading a model from its configuration file does `),cEe=n(_ae,"STRONG",{});var ijt=s(cEe);vPr=r(ijt,"not"),ijt.forEach(t),FPr=r(_ae,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=n(_ae,"A",{href:!0});var djt=s(_Z);TPr=r(djt,"from_pretrained()"),djt.forEach(t),MPr=r(_ae," to load the model weights."),_ae.forEach(t),EPr=i(SA),T(sC.$$.fragment,SA),SA.forEach(t),CPr=i(Ul),jr=n(Ul,"DIV",{class:!0});var Jl=s(jr);T(Kx.$$.fragment,Jl),wPr=i(Jl),fEe=n(Jl,"P",{});var cjt=s(fEe);APr=r(cjt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),cjt.forEach(t),LPr=i(Jl),un=n(Jl,"P",{});var RA=s(un);yPr=r(RA,"The model class to instantiate is selected based on the "),mEe=n(RA,"CODE",{});var fjt=s(mEe);xPr=r(fjt,"model_type"),fjt.forEach(t),$Pr=r(RA,` property of the config object (either
passed as an argument or loaded from `),gEe=n(RA,"CODE",{});var mjt=s(gEe);kPr=r(mjt,"pretrained_model_name_or_path"),mjt.forEach(t),SPr=r(RA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hEe=n(RA,"CODE",{});var gjt=s(hEe);RPr=r(gjt,"pretrained_model_name_or_path"),gjt.forEach(t),PPr=r(RA,":"),RA.forEach(t),BPr=i(Jl),pEe=n(Jl,"UL",{});var hjt=s(pEe);lC=n(hjt,"LI",{});var YGe=s(lC);_Ee=n(YGe,"STRONG",{});var pjt=s(_Ee);IPr=r(pjt,"tapas"),pjt.forEach(t),NPr=r(YGe," \u2014 "),uZ=n(YGe,"A",{href:!0});var _jt=s(uZ);qPr=r(_jt,"TFTapasForQuestionAnswering"),_jt.forEach(t),jPr=r(YGe," (TAPAS model)"),YGe.forEach(t),hjt.forEach(t),DPr=i(Jl),T(iC.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),pQe=i(f),Nc=n(f,"H2",{class:!0});var CHe=s(Nc);dC=n(CHe,"A",{id:!0,class:!0,href:!0});var ujt=s(dC);uEe=n(ujt,"SPAN",{});var bjt=s(uEe);T(Zx.$$.fragment,bjt),bjt.forEach(t),ujt.forEach(t),GPr=i(CHe),bEe=n(CHe,"SPAN",{});var vjt=s(bEe);OPr=r(vjt,"TFAutoModelForTokenClassification"),vjt.forEach(t),CHe.forEach(t),_Qe=i(f),mr=n(f,"DIV",{class:!0});var Yl=s(mr);T(e$.$$.fragment,Yl),VPr=i(Yl),qc=n(Yl,"P",{});var uae=s(qc);XPr=r(uae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bZ=n(uae,"A",{href:!0});var Fjt=s(bZ);zPr=r(Fjt,"from_pretrained()"),Fjt.forEach(t),QPr=r(uae," class method or the "),vZ=n(uae,"A",{href:!0});var Tjt=s(vZ);WPr=r(Tjt,"from_config()"),Tjt.forEach(t),HPr=r(uae,` class
method.`),uae.forEach(t),UPr=i(Yl),o$=n(Yl,"P",{});var wHe=s(o$);JPr=r(wHe,"This class cannot be instantiated directly using "),vEe=n(wHe,"CODE",{});var Mjt=s(vEe);YPr=r(Mjt,"__init__()"),Mjt.forEach(t),KPr=r(wHe," (throws an error)."),wHe.forEach(t),ZPr=i(Yl),Vt=n(Yl,"DIV",{class:!0});var PA=s(Vt);T(r$.$$.fragment,PA),eBr=i(PA),FEe=n(PA,"P",{});var Ejt=s(FEe);oBr=r(Ejt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Ejt.forEach(t),rBr=i(PA),jc=n(PA,"P",{});var bae=s(jc);tBr=r(bae,`Note:
Loading a model from its configuration file does `),TEe=n(bae,"STRONG",{});var Cjt=s(TEe);aBr=r(Cjt,"not"),Cjt.forEach(t),nBr=r(bae,` load the model weights. It only affects the
model\u2019s configuration. Use `),FZ=n(bae,"A",{href:!0});var wjt=s(FZ);sBr=r(wjt,"from_pretrained()"),wjt.forEach(t),lBr=r(bae," to load the model weights."),bae.forEach(t),iBr=i(PA),T(cC.$$.fragment,PA),PA.forEach(t),dBr=i(Yl),Dr=n(Yl,"DIV",{class:!0});var Kl=s(Dr);T(t$.$$.fragment,Kl),cBr=i(Kl),MEe=n(Kl,"P",{});var Ajt=s(MEe);fBr=r(Ajt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ajt.forEach(t),mBr=i(Kl),bn=n(Kl,"P",{});var BA=s(bn);gBr=r(BA,"The model class to instantiate is selected based on the "),EEe=n(BA,"CODE",{});var Ljt=s(EEe);hBr=r(Ljt,"model_type"),Ljt.forEach(t),pBr=r(BA,` property of the config object (either
passed as an argument or loaded from `),CEe=n(BA,"CODE",{});var yjt=s(CEe);_Br=r(yjt,"pretrained_model_name_or_path"),yjt.forEach(t),uBr=r(BA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wEe=n(BA,"CODE",{});var xjt=s(wEe);bBr=r(xjt,"pretrained_model_name_or_path"),xjt.forEach(t),vBr=r(BA,":"),BA.forEach(t),FBr=i(Kl),de=n(Kl,"UL",{});var ge=s(de);fC=n(ge,"LI",{});var KGe=s(fC);AEe=n(KGe,"STRONG",{});var $jt=s(AEe);TBr=r($jt,"albert"),$jt.forEach(t),MBr=r(KGe," \u2014 "),TZ=n(KGe,"A",{href:!0});var kjt=s(TZ);EBr=r(kjt,"TFAlbertForTokenClassification"),kjt.forEach(t),CBr=r(KGe," (ALBERT model)"),KGe.forEach(t),wBr=i(ge),mC=n(ge,"LI",{});var ZGe=s(mC);LEe=n(ZGe,"STRONG",{});var Sjt=s(LEe);ABr=r(Sjt,"bert"),Sjt.forEach(t),LBr=r(ZGe," \u2014 "),MZ=n(ZGe,"A",{href:!0});var Rjt=s(MZ);yBr=r(Rjt,"TFBertForTokenClassification"),Rjt.forEach(t),xBr=r(ZGe," (BERT model)"),ZGe.forEach(t),$Br=i(ge),gC=n(ge,"LI",{});var eOe=s(gC);yEe=n(eOe,"STRONG",{});var Pjt=s(yEe);kBr=r(Pjt,"camembert"),Pjt.forEach(t),SBr=r(eOe," \u2014 "),EZ=n(eOe,"A",{href:!0});var Bjt=s(EZ);RBr=r(Bjt,"TFCamembertForTokenClassification"),Bjt.forEach(t),PBr=r(eOe," (CamemBERT model)"),eOe.forEach(t),BBr=i(ge),hC=n(ge,"LI",{});var oOe=s(hC);xEe=n(oOe,"STRONG",{});var Ijt=s(xEe);IBr=r(Ijt,"convbert"),Ijt.forEach(t),NBr=r(oOe," \u2014 "),CZ=n(oOe,"A",{href:!0});var Njt=s(CZ);qBr=r(Njt,"TFConvBertForTokenClassification"),Njt.forEach(t),jBr=r(oOe," (ConvBERT model)"),oOe.forEach(t),DBr=i(ge),pC=n(ge,"LI",{});var rOe=s(pC);$Ee=n(rOe,"STRONG",{});var qjt=s($Ee);GBr=r(qjt,"deberta"),qjt.forEach(t),OBr=r(rOe," \u2014 "),wZ=n(rOe,"A",{href:!0});var jjt=s(wZ);VBr=r(jjt,"TFDebertaForTokenClassification"),jjt.forEach(t),XBr=r(rOe," (DeBERTa model)"),rOe.forEach(t),zBr=i(ge),_C=n(ge,"LI",{});var tOe=s(_C);kEe=n(tOe,"STRONG",{});var Djt=s(kEe);QBr=r(Djt,"deberta-v2"),Djt.forEach(t),WBr=r(tOe," \u2014 "),AZ=n(tOe,"A",{href:!0});var Gjt=s(AZ);HBr=r(Gjt,"TFDebertaV2ForTokenClassification"),Gjt.forEach(t),UBr=r(tOe," (DeBERTa-v2 model)"),tOe.forEach(t),JBr=i(ge),uC=n(ge,"LI",{});var aOe=s(uC);SEe=n(aOe,"STRONG",{});var Ojt=s(SEe);YBr=r(Ojt,"distilbert"),Ojt.forEach(t),KBr=r(aOe," \u2014 "),LZ=n(aOe,"A",{href:!0});var Vjt=s(LZ);ZBr=r(Vjt,"TFDistilBertForTokenClassification"),Vjt.forEach(t),eIr=r(aOe," (DistilBERT model)"),aOe.forEach(t),oIr=i(ge),bC=n(ge,"LI",{});var nOe=s(bC);REe=n(nOe,"STRONG",{});var Xjt=s(REe);rIr=r(Xjt,"electra"),Xjt.forEach(t),tIr=r(nOe," \u2014 "),yZ=n(nOe,"A",{href:!0});var zjt=s(yZ);aIr=r(zjt,"TFElectraForTokenClassification"),zjt.forEach(t),nIr=r(nOe," (ELECTRA model)"),nOe.forEach(t),sIr=i(ge),vC=n(ge,"LI",{});var sOe=s(vC);PEe=n(sOe,"STRONG",{});var Qjt=s(PEe);lIr=r(Qjt,"flaubert"),Qjt.forEach(t),iIr=r(sOe," \u2014 "),xZ=n(sOe,"A",{href:!0});var Wjt=s(xZ);dIr=r(Wjt,"TFFlaubertForTokenClassification"),Wjt.forEach(t),cIr=r(sOe," (FlauBERT model)"),sOe.forEach(t),fIr=i(ge),FC=n(ge,"LI",{});var lOe=s(FC);BEe=n(lOe,"STRONG",{});var Hjt=s(BEe);mIr=r(Hjt,"funnel"),Hjt.forEach(t),gIr=r(lOe," \u2014 "),$Z=n(lOe,"A",{href:!0});var Ujt=s($Z);hIr=r(Ujt,"TFFunnelForTokenClassification"),Ujt.forEach(t),pIr=r(lOe," (Funnel Transformer model)"),lOe.forEach(t),_Ir=i(ge),TC=n(ge,"LI",{});var iOe=s(TC);IEe=n(iOe,"STRONG",{});var Jjt=s(IEe);uIr=r(Jjt,"layoutlm"),Jjt.forEach(t),bIr=r(iOe," \u2014 "),kZ=n(iOe,"A",{href:!0});var Yjt=s(kZ);vIr=r(Yjt,"TFLayoutLMForTokenClassification"),Yjt.forEach(t),FIr=r(iOe," (LayoutLM model)"),iOe.forEach(t),TIr=i(ge),MC=n(ge,"LI",{});var dOe=s(MC);NEe=n(dOe,"STRONG",{});var Kjt=s(NEe);MIr=r(Kjt,"longformer"),Kjt.forEach(t),EIr=r(dOe," \u2014 "),SZ=n(dOe,"A",{href:!0});var Zjt=s(SZ);CIr=r(Zjt,"TFLongformerForTokenClassification"),Zjt.forEach(t),wIr=r(dOe," (Longformer model)"),dOe.forEach(t),AIr=i(ge),EC=n(ge,"LI",{});var cOe=s(EC);qEe=n(cOe,"STRONG",{});var eDt=s(qEe);LIr=r(eDt,"mobilebert"),eDt.forEach(t),yIr=r(cOe," \u2014 "),RZ=n(cOe,"A",{href:!0});var oDt=s(RZ);xIr=r(oDt,"TFMobileBertForTokenClassification"),oDt.forEach(t),$Ir=r(cOe," (MobileBERT model)"),cOe.forEach(t),kIr=i(ge),CC=n(ge,"LI",{});var fOe=s(CC);jEe=n(fOe,"STRONG",{});var rDt=s(jEe);SIr=r(rDt,"mpnet"),rDt.forEach(t),RIr=r(fOe," \u2014 "),PZ=n(fOe,"A",{href:!0});var tDt=s(PZ);PIr=r(tDt,"TFMPNetForTokenClassification"),tDt.forEach(t),BIr=r(fOe," (MPNet model)"),fOe.forEach(t),IIr=i(ge),wC=n(ge,"LI",{});var mOe=s(wC);DEe=n(mOe,"STRONG",{});var aDt=s(DEe);NIr=r(aDt,"rembert"),aDt.forEach(t),qIr=r(mOe," \u2014 "),BZ=n(mOe,"A",{href:!0});var nDt=s(BZ);jIr=r(nDt,"TFRemBertForTokenClassification"),nDt.forEach(t),DIr=r(mOe," (RemBERT model)"),mOe.forEach(t),GIr=i(ge),AC=n(ge,"LI",{});var gOe=s(AC);GEe=n(gOe,"STRONG",{});var sDt=s(GEe);OIr=r(sDt,"roberta"),sDt.forEach(t),VIr=r(gOe," \u2014 "),IZ=n(gOe,"A",{href:!0});var lDt=s(IZ);XIr=r(lDt,"TFRobertaForTokenClassification"),lDt.forEach(t),zIr=r(gOe," (RoBERTa model)"),gOe.forEach(t),QIr=i(ge),LC=n(ge,"LI",{});var hOe=s(LC);OEe=n(hOe,"STRONG",{});var iDt=s(OEe);WIr=r(iDt,"roformer"),iDt.forEach(t),HIr=r(hOe," \u2014 "),NZ=n(hOe,"A",{href:!0});var dDt=s(NZ);UIr=r(dDt,"TFRoFormerForTokenClassification"),dDt.forEach(t),JIr=r(hOe," (RoFormer model)"),hOe.forEach(t),YIr=i(ge),yC=n(ge,"LI",{});var pOe=s(yC);VEe=n(pOe,"STRONG",{});var cDt=s(VEe);KIr=r(cDt,"xlm"),cDt.forEach(t),ZIr=r(pOe," \u2014 "),qZ=n(pOe,"A",{href:!0});var fDt=s(qZ);eNr=r(fDt,"TFXLMForTokenClassification"),fDt.forEach(t),oNr=r(pOe," (XLM model)"),pOe.forEach(t),rNr=i(ge),xC=n(ge,"LI",{});var _Oe=s(xC);XEe=n(_Oe,"STRONG",{});var mDt=s(XEe);tNr=r(mDt,"xlm-roberta"),mDt.forEach(t),aNr=r(_Oe," \u2014 "),jZ=n(_Oe,"A",{href:!0});var gDt=s(jZ);nNr=r(gDt,"TFXLMRobertaForTokenClassification"),gDt.forEach(t),sNr=r(_Oe," (XLM-RoBERTa model)"),_Oe.forEach(t),lNr=i(ge),$C=n(ge,"LI",{});var uOe=s($C);zEe=n(uOe,"STRONG",{});var hDt=s(zEe);iNr=r(hDt,"xlnet"),hDt.forEach(t),dNr=r(uOe," \u2014 "),DZ=n(uOe,"A",{href:!0});var pDt=s(DZ);cNr=r(pDt,"TFXLNetForTokenClassification"),pDt.forEach(t),fNr=r(uOe," (XLNet model)"),uOe.forEach(t),ge.forEach(t),mNr=i(Kl),T(kC.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),uQe=i(f),Dc=n(f,"H2",{class:!0});var AHe=s(Dc);SC=n(AHe,"A",{id:!0,class:!0,href:!0});var _Dt=s(SC);QEe=n(_Dt,"SPAN",{});var uDt=s(QEe);T(a$.$$.fragment,uDt),uDt.forEach(t),_Dt.forEach(t),gNr=i(AHe),WEe=n(AHe,"SPAN",{});var bDt=s(WEe);hNr=r(bDt,"TFAutoModelForQuestionAnswering"),bDt.forEach(t),AHe.forEach(t),bQe=i(f),gr=n(f,"DIV",{class:!0});var Zl=s(gr);T(n$.$$.fragment,Zl),pNr=i(Zl),Gc=n(Zl,"P",{});var vae=s(Gc);_Nr=r(vae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GZ=n(vae,"A",{href:!0});var vDt=s(GZ);uNr=r(vDt,"from_pretrained()"),vDt.forEach(t),bNr=r(vae," class method or the "),OZ=n(vae,"A",{href:!0});var FDt=s(OZ);vNr=r(FDt,"from_config()"),FDt.forEach(t),FNr=r(vae,` class
method.`),vae.forEach(t),TNr=i(Zl),s$=n(Zl,"P",{});var LHe=s(s$);MNr=r(LHe,"This class cannot be instantiated directly using "),HEe=n(LHe,"CODE",{});var TDt=s(HEe);ENr=r(TDt,"__init__()"),TDt.forEach(t),CNr=r(LHe," (throws an error)."),LHe.forEach(t),wNr=i(Zl),Xt=n(Zl,"DIV",{class:!0});var IA=s(Xt);T(l$.$$.fragment,IA),ANr=i(IA),UEe=n(IA,"P",{});var MDt=s(UEe);LNr=r(MDt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),MDt.forEach(t),yNr=i(IA),Oc=n(IA,"P",{});var Fae=s(Oc);xNr=r(Fae,`Note:
Loading a model from its configuration file does `),JEe=n(Fae,"STRONG",{});var EDt=s(JEe);$Nr=r(EDt,"not"),EDt.forEach(t),kNr=r(Fae,` load the model weights. It only affects the
model\u2019s configuration. Use `),VZ=n(Fae,"A",{href:!0});var CDt=s(VZ);SNr=r(CDt,"from_pretrained()"),CDt.forEach(t),RNr=r(Fae," to load the model weights."),Fae.forEach(t),PNr=i(IA),T(RC.$$.fragment,IA),IA.forEach(t),BNr=i(Zl),Gr=n(Zl,"DIV",{class:!0});var ei=s(Gr);T(i$.$$.fragment,ei),INr=i(ei),YEe=n(ei,"P",{});var wDt=s(YEe);NNr=r(wDt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),wDt.forEach(t),qNr=i(ei),vn=n(ei,"P",{});var NA=s(vn);jNr=r(NA,"The model class to instantiate is selected based on the "),KEe=n(NA,"CODE",{});var ADt=s(KEe);DNr=r(ADt,"model_type"),ADt.forEach(t),GNr=r(NA,` property of the config object (either
passed as an argument or loaded from `),ZEe=n(NA,"CODE",{});var LDt=s(ZEe);ONr=r(LDt,"pretrained_model_name_or_path"),LDt.forEach(t),VNr=r(NA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eCe=n(NA,"CODE",{});var yDt=s(eCe);XNr=r(yDt,"pretrained_model_name_or_path"),yDt.forEach(t),zNr=r(NA,":"),NA.forEach(t),QNr=i(ei),ce=n(ei,"UL",{});var he=s(ce);PC=n(he,"LI",{});var bOe=s(PC);oCe=n(bOe,"STRONG",{});var xDt=s(oCe);WNr=r(xDt,"albert"),xDt.forEach(t),HNr=r(bOe," \u2014 "),XZ=n(bOe,"A",{href:!0});var $Dt=s(XZ);UNr=r($Dt,"TFAlbertForQuestionAnswering"),$Dt.forEach(t),JNr=r(bOe," (ALBERT model)"),bOe.forEach(t),YNr=i(he),BC=n(he,"LI",{});var vOe=s(BC);rCe=n(vOe,"STRONG",{});var kDt=s(rCe);KNr=r(kDt,"bert"),kDt.forEach(t),ZNr=r(vOe," \u2014 "),zZ=n(vOe,"A",{href:!0});var SDt=s(zZ);eqr=r(SDt,"TFBertForQuestionAnswering"),SDt.forEach(t),oqr=r(vOe," (BERT model)"),vOe.forEach(t),rqr=i(he),IC=n(he,"LI",{});var FOe=s(IC);tCe=n(FOe,"STRONG",{});var RDt=s(tCe);tqr=r(RDt,"camembert"),RDt.forEach(t),aqr=r(FOe," \u2014 "),QZ=n(FOe,"A",{href:!0});var PDt=s(QZ);nqr=r(PDt,"TFCamembertForQuestionAnswering"),PDt.forEach(t),sqr=r(FOe," (CamemBERT model)"),FOe.forEach(t),lqr=i(he),NC=n(he,"LI",{});var TOe=s(NC);aCe=n(TOe,"STRONG",{});var BDt=s(aCe);iqr=r(BDt,"convbert"),BDt.forEach(t),dqr=r(TOe," \u2014 "),WZ=n(TOe,"A",{href:!0});var IDt=s(WZ);cqr=r(IDt,"TFConvBertForQuestionAnswering"),IDt.forEach(t),fqr=r(TOe," (ConvBERT model)"),TOe.forEach(t),mqr=i(he),qC=n(he,"LI",{});var MOe=s(qC);nCe=n(MOe,"STRONG",{});var NDt=s(nCe);gqr=r(NDt,"deberta"),NDt.forEach(t),hqr=r(MOe," \u2014 "),HZ=n(MOe,"A",{href:!0});var qDt=s(HZ);pqr=r(qDt,"TFDebertaForQuestionAnswering"),qDt.forEach(t),_qr=r(MOe," (DeBERTa model)"),MOe.forEach(t),uqr=i(he),jC=n(he,"LI",{});var EOe=s(jC);sCe=n(EOe,"STRONG",{});var jDt=s(sCe);bqr=r(jDt,"deberta-v2"),jDt.forEach(t),vqr=r(EOe," \u2014 "),UZ=n(EOe,"A",{href:!0});var DDt=s(UZ);Fqr=r(DDt,"TFDebertaV2ForQuestionAnswering"),DDt.forEach(t),Tqr=r(EOe," (DeBERTa-v2 model)"),EOe.forEach(t),Mqr=i(he),DC=n(he,"LI",{});var COe=s(DC);lCe=n(COe,"STRONG",{});var GDt=s(lCe);Eqr=r(GDt,"distilbert"),GDt.forEach(t),Cqr=r(COe," \u2014 "),JZ=n(COe,"A",{href:!0});var ODt=s(JZ);wqr=r(ODt,"TFDistilBertForQuestionAnswering"),ODt.forEach(t),Aqr=r(COe," (DistilBERT model)"),COe.forEach(t),Lqr=i(he),GC=n(he,"LI",{});var wOe=s(GC);iCe=n(wOe,"STRONG",{});var VDt=s(iCe);yqr=r(VDt,"electra"),VDt.forEach(t),xqr=r(wOe," \u2014 "),YZ=n(wOe,"A",{href:!0});var XDt=s(YZ);$qr=r(XDt,"TFElectraForQuestionAnswering"),XDt.forEach(t),kqr=r(wOe," (ELECTRA model)"),wOe.forEach(t),Sqr=i(he),OC=n(he,"LI",{});var AOe=s(OC);dCe=n(AOe,"STRONG",{});var zDt=s(dCe);Rqr=r(zDt,"flaubert"),zDt.forEach(t),Pqr=r(AOe," \u2014 "),KZ=n(AOe,"A",{href:!0});var QDt=s(KZ);Bqr=r(QDt,"TFFlaubertForQuestionAnsweringSimple"),QDt.forEach(t),Iqr=r(AOe," (FlauBERT model)"),AOe.forEach(t),Nqr=i(he),VC=n(he,"LI",{});var LOe=s(VC);cCe=n(LOe,"STRONG",{});var WDt=s(cCe);qqr=r(WDt,"funnel"),WDt.forEach(t),jqr=r(LOe," \u2014 "),ZZ=n(LOe,"A",{href:!0});var HDt=s(ZZ);Dqr=r(HDt,"TFFunnelForQuestionAnswering"),HDt.forEach(t),Gqr=r(LOe," (Funnel Transformer model)"),LOe.forEach(t),Oqr=i(he),XC=n(he,"LI",{});var yOe=s(XC);fCe=n(yOe,"STRONG",{});var UDt=s(fCe);Vqr=r(UDt,"gptj"),UDt.forEach(t),Xqr=r(yOe," \u2014 "),eee=n(yOe,"A",{href:!0});var JDt=s(eee);zqr=r(JDt,"TFGPTJForQuestionAnswering"),JDt.forEach(t),Qqr=r(yOe," (GPT-J model)"),yOe.forEach(t),Wqr=i(he),zC=n(he,"LI",{});var xOe=s(zC);mCe=n(xOe,"STRONG",{});var YDt=s(mCe);Hqr=r(YDt,"longformer"),YDt.forEach(t),Uqr=r(xOe," \u2014 "),oee=n(xOe,"A",{href:!0});var KDt=s(oee);Jqr=r(KDt,"TFLongformerForQuestionAnswering"),KDt.forEach(t),Yqr=r(xOe," (Longformer model)"),xOe.forEach(t),Kqr=i(he),QC=n(he,"LI",{});var $Oe=s(QC);gCe=n($Oe,"STRONG",{});var ZDt=s(gCe);Zqr=r(ZDt,"mobilebert"),ZDt.forEach(t),ejr=r($Oe," \u2014 "),ree=n($Oe,"A",{href:!0});var eGt=s(ree);ojr=r(eGt,"TFMobileBertForQuestionAnswering"),eGt.forEach(t),rjr=r($Oe," (MobileBERT model)"),$Oe.forEach(t),tjr=i(he),WC=n(he,"LI",{});var kOe=s(WC);hCe=n(kOe,"STRONG",{});var oGt=s(hCe);ajr=r(oGt,"mpnet"),oGt.forEach(t),njr=r(kOe," \u2014 "),tee=n(kOe,"A",{href:!0});var rGt=s(tee);sjr=r(rGt,"TFMPNetForQuestionAnswering"),rGt.forEach(t),ljr=r(kOe," (MPNet model)"),kOe.forEach(t),ijr=i(he),HC=n(he,"LI",{});var SOe=s(HC);pCe=n(SOe,"STRONG",{});var tGt=s(pCe);djr=r(tGt,"rembert"),tGt.forEach(t),cjr=r(SOe," \u2014 "),aee=n(SOe,"A",{href:!0});var aGt=s(aee);fjr=r(aGt,"TFRemBertForQuestionAnswering"),aGt.forEach(t),mjr=r(SOe," (RemBERT model)"),SOe.forEach(t),gjr=i(he),UC=n(he,"LI",{});var ROe=s(UC);_Ce=n(ROe,"STRONG",{});var nGt=s(_Ce);hjr=r(nGt,"roberta"),nGt.forEach(t),pjr=r(ROe," \u2014 "),nee=n(ROe,"A",{href:!0});var sGt=s(nee);_jr=r(sGt,"TFRobertaForQuestionAnswering"),sGt.forEach(t),ujr=r(ROe," (RoBERTa model)"),ROe.forEach(t),bjr=i(he),JC=n(he,"LI",{});var POe=s(JC);uCe=n(POe,"STRONG",{});var lGt=s(uCe);vjr=r(lGt,"roformer"),lGt.forEach(t),Fjr=r(POe," \u2014 "),see=n(POe,"A",{href:!0});var iGt=s(see);Tjr=r(iGt,"TFRoFormerForQuestionAnswering"),iGt.forEach(t),Mjr=r(POe," (RoFormer model)"),POe.forEach(t),Ejr=i(he),YC=n(he,"LI",{});var BOe=s(YC);bCe=n(BOe,"STRONG",{});var dGt=s(bCe);Cjr=r(dGt,"xlm"),dGt.forEach(t),wjr=r(BOe," \u2014 "),lee=n(BOe,"A",{href:!0});var cGt=s(lee);Ajr=r(cGt,"TFXLMForQuestionAnsweringSimple"),cGt.forEach(t),Ljr=r(BOe," (XLM model)"),BOe.forEach(t),yjr=i(he),KC=n(he,"LI",{});var IOe=s(KC);vCe=n(IOe,"STRONG",{});var fGt=s(vCe);xjr=r(fGt,"xlm-roberta"),fGt.forEach(t),$jr=r(IOe," \u2014 "),iee=n(IOe,"A",{href:!0});var mGt=s(iee);kjr=r(mGt,"TFXLMRobertaForQuestionAnswering"),mGt.forEach(t),Sjr=r(IOe," (XLM-RoBERTa model)"),IOe.forEach(t),Rjr=i(he),ZC=n(he,"LI",{});var NOe=s(ZC);FCe=n(NOe,"STRONG",{});var gGt=s(FCe);Pjr=r(gGt,"xlnet"),gGt.forEach(t),Bjr=r(NOe," \u2014 "),dee=n(NOe,"A",{href:!0});var hGt=s(dee);Ijr=r(hGt,"TFXLNetForQuestionAnsweringSimple"),hGt.forEach(t),Njr=r(NOe," (XLNet model)"),NOe.forEach(t),he.forEach(t),qjr=i(ei),T(e5.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),vQe=i(f),Vc=n(f,"H2",{class:!0});var yHe=s(Vc);o5=n(yHe,"A",{id:!0,class:!0,href:!0});var pGt=s(o5);TCe=n(pGt,"SPAN",{});var _Gt=s(TCe);T(d$.$$.fragment,_Gt),_Gt.forEach(t),pGt.forEach(t),jjr=i(yHe),MCe=n(yHe,"SPAN",{});var uGt=s(MCe);Djr=r(uGt,"TFAutoModelForVision2Seq"),uGt.forEach(t),yHe.forEach(t),FQe=i(f),hr=n(f,"DIV",{class:!0});var oi=s(hr);T(c$.$$.fragment,oi),Gjr=i(oi),Xc=n(oi,"P",{});var Tae=s(Xc);Ojr=r(Tae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cee=n(Tae,"A",{href:!0});var bGt=s(cee);Vjr=r(bGt,"from_pretrained()"),bGt.forEach(t),Xjr=r(Tae," class method or the "),fee=n(Tae,"A",{href:!0});var vGt=s(fee);zjr=r(vGt,"from_config()"),vGt.forEach(t),Qjr=r(Tae,` class
method.`),Tae.forEach(t),Wjr=i(oi),f$=n(oi,"P",{});var xHe=s(f$);Hjr=r(xHe,"This class cannot be instantiated directly using "),ECe=n(xHe,"CODE",{});var FGt=s(ECe);Ujr=r(FGt,"__init__()"),FGt.forEach(t),Jjr=r(xHe," (throws an error)."),xHe.forEach(t),Yjr=i(oi),zt=n(oi,"DIV",{class:!0});var qA=s(zt);T(m$.$$.fragment,qA),Kjr=i(qA),CCe=n(qA,"P",{});var TGt=s(CCe);Zjr=r(TGt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),TGt.forEach(t),eDr=i(qA),zc=n(qA,"P",{});var Mae=s(zc);oDr=r(Mae,`Note:
Loading a model from its configuration file does `),wCe=n(Mae,"STRONG",{});var MGt=s(wCe);rDr=r(MGt,"not"),MGt.forEach(t),tDr=r(Mae,` load the model weights. It only affects the
model\u2019s configuration. Use `),mee=n(Mae,"A",{href:!0});var EGt=s(mee);aDr=r(EGt,"from_pretrained()"),EGt.forEach(t),nDr=r(Mae," to load the model weights."),Mae.forEach(t),sDr=i(qA),T(r5.$$.fragment,qA),qA.forEach(t),lDr=i(oi),Or=n(oi,"DIV",{class:!0});var ri=s(Or);T(g$.$$.fragment,ri),iDr=i(ri),ACe=n(ri,"P",{});var CGt=s(ACe);dDr=r(CGt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CGt.forEach(t),cDr=i(ri),Fn=n(ri,"P",{});var jA=s(Fn);fDr=r(jA,"The model class to instantiate is selected based on the "),LCe=n(jA,"CODE",{});var wGt=s(LCe);mDr=r(wGt,"model_type"),wGt.forEach(t),gDr=r(jA,` property of the config object (either
passed as an argument or loaded from `),yCe=n(jA,"CODE",{});var AGt=s(yCe);hDr=r(AGt,"pretrained_model_name_or_path"),AGt.forEach(t),pDr=r(jA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xCe=n(jA,"CODE",{});var LGt=s(xCe);_Dr=r(LGt,"pretrained_model_name_or_path"),LGt.forEach(t),uDr=r(jA,":"),jA.forEach(t),bDr=i(ri),$Ce=n(ri,"UL",{});var yGt=s($Ce);t5=n(yGt,"LI",{});var qOe=s(t5);kCe=n(qOe,"STRONG",{});var xGt=s(kCe);vDr=r(xGt,"vision-encoder-decoder"),xGt.forEach(t),FDr=r(qOe," \u2014 "),gee=n(qOe,"A",{href:!0});var $Gt=s(gee);TDr=r($Gt,"TFVisionEncoderDecoderModel"),$Gt.forEach(t),MDr=r(qOe," (Vision Encoder decoder model)"),qOe.forEach(t),yGt.forEach(t),EDr=i(ri),T(a5.$$.fragment,ri),ri.forEach(t),oi.forEach(t),TQe=i(f),Qc=n(f,"H2",{class:!0});var $He=s(Qc);n5=n($He,"A",{id:!0,class:!0,href:!0});var kGt=s(n5);SCe=n(kGt,"SPAN",{});var SGt=s(SCe);T(h$.$$.fragment,SGt),SGt.forEach(t),kGt.forEach(t),CDr=i($He),RCe=n($He,"SPAN",{});var RGt=s(RCe);wDr=r(RGt,"TFAutoModelForSpeechSeq2Seq"),RGt.forEach(t),$He.forEach(t),MQe=i(f),pr=n(f,"DIV",{class:!0});var ti=s(pr);T(p$.$$.fragment,ti),ADr=i(ti),Wc=n(ti,"P",{});var Eae=s(Wc);LDr=r(Eae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hee=n(Eae,"A",{href:!0});var PGt=s(hee);yDr=r(PGt,"from_pretrained()"),PGt.forEach(t),xDr=r(Eae," class method or the "),pee=n(Eae,"A",{href:!0});var BGt=s(pee);$Dr=r(BGt,"from_config()"),BGt.forEach(t),kDr=r(Eae,` class
method.`),Eae.forEach(t),SDr=i(ti),_$=n(ti,"P",{});var kHe=s(_$);RDr=r(kHe,"This class cannot be instantiated directly using "),PCe=n(kHe,"CODE",{});var IGt=s(PCe);PDr=r(IGt,"__init__()"),IGt.forEach(t),BDr=r(kHe," (throws an error)."),kHe.forEach(t),IDr=i(ti),Qt=n(ti,"DIV",{class:!0});var DA=s(Qt);T(u$.$$.fragment,DA),NDr=i(DA),BCe=n(DA,"P",{});var NGt=s(BCe);qDr=r(NGt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),NGt.forEach(t),jDr=i(DA),Hc=n(DA,"P",{});var Cae=s(Hc);DDr=r(Cae,`Note:
Loading a model from its configuration file does `),ICe=n(Cae,"STRONG",{});var qGt=s(ICe);GDr=r(qGt,"not"),qGt.forEach(t),ODr=r(Cae,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=n(Cae,"A",{href:!0});var jGt=s(_ee);VDr=r(jGt,"from_pretrained()"),jGt.forEach(t),XDr=r(Cae," to load the model weights."),Cae.forEach(t),zDr=i(DA),T(s5.$$.fragment,DA),DA.forEach(t),QDr=i(ti),Vr=n(ti,"DIV",{class:!0});var ai=s(Vr);T(b$.$$.fragment,ai),WDr=i(ai),NCe=n(ai,"P",{});var DGt=s(NCe);HDr=r(DGt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),DGt.forEach(t),UDr=i(ai),Tn=n(ai,"P",{});var GA=s(Tn);JDr=r(GA,"The model class to instantiate is selected based on the "),qCe=n(GA,"CODE",{});var GGt=s(qCe);YDr=r(GGt,"model_type"),GGt.forEach(t),KDr=r(GA,` property of the config object (either
passed as an argument or loaded from `),jCe=n(GA,"CODE",{});var OGt=s(jCe);ZDr=r(OGt,"pretrained_model_name_or_path"),OGt.forEach(t),eGr=r(GA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DCe=n(GA,"CODE",{});var VGt=s(DCe);oGr=r(VGt,"pretrained_model_name_or_path"),VGt.forEach(t),rGr=r(GA,":"),GA.forEach(t),tGr=i(ai),GCe=n(ai,"UL",{});var XGt=s(GCe);l5=n(XGt,"LI",{});var jOe=s(l5);OCe=n(jOe,"STRONG",{});var zGt=s(OCe);aGr=r(zGt,"speech_to_text"),zGt.forEach(t),nGr=r(jOe," \u2014 "),uee=n(jOe,"A",{href:!0});var QGt=s(uee);sGr=r(QGt,"TFSpeech2TextForConditionalGeneration"),QGt.forEach(t),lGr=r(jOe," (Speech2Text model)"),jOe.forEach(t),XGt.forEach(t),iGr=i(ai),T(i5.$$.fragment,ai),ai.forEach(t),ti.forEach(t),EQe=i(f),Uc=n(f,"H2",{class:!0});var SHe=s(Uc);d5=n(SHe,"A",{id:!0,class:!0,href:!0});var WGt=s(d5);VCe=n(WGt,"SPAN",{});var HGt=s(VCe);T(v$.$$.fragment,HGt),HGt.forEach(t),WGt.forEach(t),dGr=i(SHe),XCe=n(SHe,"SPAN",{});var UGt=s(XCe);cGr=r(UGt,"FlaxAutoModel"),UGt.forEach(t),SHe.forEach(t),CQe=i(f),_r=n(f,"DIV",{class:!0});var ni=s(_r);T(F$.$$.fragment,ni),fGr=i(ni),Jc=n(ni,"P",{});var wae=s(Jc);mGr=r(wae,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),bee=n(wae,"A",{href:!0});var JGt=s(bee);gGr=r(JGt,"from_pretrained()"),JGt.forEach(t),hGr=r(wae," class method or the "),vee=n(wae,"A",{href:!0});var YGt=s(vee);pGr=r(YGt,"from_config()"),YGt.forEach(t),_Gr=r(wae,` class
method.`),wae.forEach(t),uGr=i(ni),T$=n(ni,"P",{});var RHe=s(T$);bGr=r(RHe,"This class cannot be instantiated directly using "),zCe=n(RHe,"CODE",{});var KGt=s(zCe);vGr=r(KGt,"__init__()"),KGt.forEach(t),FGr=r(RHe," (throws an error)."),RHe.forEach(t),TGr=i(ni),Wt=n(ni,"DIV",{class:!0});var OA=s(Wt);T(M$.$$.fragment,OA),MGr=i(OA),QCe=n(OA,"P",{});var ZGt=s(QCe);EGr=r(ZGt,"Instantiates one of the base model classes of the library from a configuration."),ZGt.forEach(t),CGr=i(OA),Yc=n(OA,"P",{});var Aae=s(Yc);wGr=r(Aae,`Note:
Loading a model from its configuration file does `),WCe=n(Aae,"STRONG",{});var eOt=s(WCe);AGr=r(eOt,"not"),eOt.forEach(t),LGr=r(Aae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fee=n(Aae,"A",{href:!0});var oOt=s(Fee);yGr=r(oOt,"from_pretrained()"),oOt.forEach(t),xGr=r(Aae," to load the model weights."),Aae.forEach(t),$Gr=i(OA),T(c5.$$.fragment,OA),OA.forEach(t),kGr=i(ni),Xr=n(ni,"DIV",{class:!0});var si=s(Xr);T(E$.$$.fragment,si),SGr=i(si),HCe=n(si,"P",{});var rOt=s(HCe);RGr=r(rOt,"Instantiate one of the base model classes of the library from a pretrained model."),rOt.forEach(t),PGr=i(si),Mn=n(si,"P",{});var VA=s(Mn);BGr=r(VA,"The model class to instantiate is selected based on the "),UCe=n(VA,"CODE",{});var tOt=s(UCe);IGr=r(tOt,"model_type"),tOt.forEach(t),NGr=r(VA,` property of the config object (either
passed as an argument or loaded from `),JCe=n(VA,"CODE",{});var aOt=s(JCe);qGr=r(aOt,"pretrained_model_name_or_path"),aOt.forEach(t),jGr=r(VA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YCe=n(VA,"CODE",{});var nOt=s(YCe);DGr=r(nOt,"pretrained_model_name_or_path"),nOt.forEach(t),GGr=r(VA,":"),VA.forEach(t),OGr=i(si),oe=n(si,"UL",{});var ae=s(oe);f5=n(ae,"LI",{});var DOe=s(f5);KCe=n(DOe,"STRONG",{});var sOt=s(KCe);VGr=r(sOt,"albert"),sOt.forEach(t),XGr=r(DOe," \u2014 "),Tee=n(DOe,"A",{href:!0});var lOt=s(Tee);zGr=r(lOt,"FlaxAlbertModel"),lOt.forEach(t),QGr=r(DOe," (ALBERT model)"),DOe.forEach(t),WGr=i(ae),m5=n(ae,"LI",{});var GOe=s(m5);ZCe=n(GOe,"STRONG",{});var iOt=s(ZCe);HGr=r(iOt,"bart"),iOt.forEach(t),UGr=r(GOe," \u2014 "),Mee=n(GOe,"A",{href:!0});var dOt=s(Mee);JGr=r(dOt,"FlaxBartModel"),dOt.forEach(t),YGr=r(GOe," (BART model)"),GOe.forEach(t),KGr=i(ae),g5=n(ae,"LI",{});var OOe=s(g5);e5e=n(OOe,"STRONG",{});var cOt=s(e5e);ZGr=r(cOt,"beit"),cOt.forEach(t),eOr=r(OOe," \u2014 "),Eee=n(OOe,"A",{href:!0});var fOt=s(Eee);oOr=r(fOt,"FlaxBeitModel"),fOt.forEach(t),rOr=r(OOe," (BEiT model)"),OOe.forEach(t),tOr=i(ae),h5=n(ae,"LI",{});var VOe=s(h5);o5e=n(VOe,"STRONG",{});var mOt=s(o5e);aOr=r(mOt,"bert"),mOt.forEach(t),nOr=r(VOe," \u2014 "),Cee=n(VOe,"A",{href:!0});var gOt=s(Cee);sOr=r(gOt,"FlaxBertModel"),gOt.forEach(t),lOr=r(VOe," (BERT model)"),VOe.forEach(t),iOr=i(ae),p5=n(ae,"LI",{});var XOe=s(p5);r5e=n(XOe,"STRONG",{});var hOt=s(r5e);dOr=r(hOt,"big_bird"),hOt.forEach(t),cOr=r(XOe," \u2014 "),wee=n(XOe,"A",{href:!0});var pOt=s(wee);fOr=r(pOt,"FlaxBigBirdModel"),pOt.forEach(t),mOr=r(XOe," (BigBird model)"),XOe.forEach(t),gOr=i(ae),_5=n(ae,"LI",{});var zOe=s(_5);t5e=n(zOe,"STRONG",{});var _Ot=s(t5e);hOr=r(_Ot,"blenderbot"),_Ot.forEach(t),pOr=r(zOe," \u2014 "),Aee=n(zOe,"A",{href:!0});var uOt=s(Aee);_Or=r(uOt,"FlaxBlenderbotModel"),uOt.forEach(t),uOr=r(zOe," (Blenderbot model)"),zOe.forEach(t),bOr=i(ae),u5=n(ae,"LI",{});var QOe=s(u5);a5e=n(QOe,"STRONG",{});var bOt=s(a5e);vOr=r(bOt,"blenderbot-small"),bOt.forEach(t),FOr=r(QOe," \u2014 "),Lee=n(QOe,"A",{href:!0});var vOt=s(Lee);TOr=r(vOt,"FlaxBlenderbotSmallModel"),vOt.forEach(t),MOr=r(QOe," (BlenderbotSmall model)"),QOe.forEach(t),EOr=i(ae),b5=n(ae,"LI",{});var WOe=s(b5);n5e=n(WOe,"STRONG",{});var FOt=s(n5e);COr=r(FOt,"clip"),FOt.forEach(t),wOr=r(WOe," \u2014 "),yee=n(WOe,"A",{href:!0});var TOt=s(yee);AOr=r(TOt,"FlaxCLIPModel"),TOt.forEach(t),LOr=r(WOe," (CLIP model)"),WOe.forEach(t),yOr=i(ae),v5=n(ae,"LI",{});var HOe=s(v5);s5e=n(HOe,"STRONG",{});var MOt=s(s5e);xOr=r(MOt,"distilbert"),MOt.forEach(t),$Or=r(HOe," \u2014 "),xee=n(HOe,"A",{href:!0});var EOt=s(xee);kOr=r(EOt,"FlaxDistilBertModel"),EOt.forEach(t),SOr=r(HOe," (DistilBERT model)"),HOe.forEach(t),ROr=i(ae),F5=n(ae,"LI",{});var UOe=s(F5);l5e=n(UOe,"STRONG",{});var COt=s(l5e);POr=r(COt,"electra"),COt.forEach(t),BOr=r(UOe," \u2014 "),$ee=n(UOe,"A",{href:!0});var wOt=s($ee);IOr=r(wOt,"FlaxElectraModel"),wOt.forEach(t),NOr=r(UOe," (ELECTRA model)"),UOe.forEach(t),qOr=i(ae),T5=n(ae,"LI",{});var JOe=s(T5);i5e=n(JOe,"STRONG",{});var AOt=s(i5e);jOr=r(AOt,"gpt2"),AOt.forEach(t),DOr=r(JOe," \u2014 "),kee=n(JOe,"A",{href:!0});var LOt=s(kee);GOr=r(LOt,"FlaxGPT2Model"),LOt.forEach(t),OOr=r(JOe," (OpenAI GPT-2 model)"),JOe.forEach(t),VOr=i(ae),M5=n(ae,"LI",{});var YOe=s(M5);d5e=n(YOe,"STRONG",{});var yOt=s(d5e);XOr=r(yOt,"gpt_neo"),yOt.forEach(t),zOr=r(YOe," \u2014 "),See=n(YOe,"A",{href:!0});var xOt=s(See);QOr=r(xOt,"FlaxGPTNeoModel"),xOt.forEach(t),WOr=r(YOe," (GPT Neo model)"),YOe.forEach(t),HOr=i(ae),E5=n(ae,"LI",{});var KOe=s(E5);c5e=n(KOe,"STRONG",{});var $Ot=s(c5e);UOr=r($Ot,"gptj"),$Ot.forEach(t),JOr=r(KOe," \u2014 "),Ree=n(KOe,"A",{href:!0});var kOt=s(Ree);YOr=r(kOt,"FlaxGPTJModel"),kOt.forEach(t),KOr=r(KOe," (GPT-J model)"),KOe.forEach(t),ZOr=i(ae),C5=n(ae,"LI",{});var ZOe=s(C5);f5e=n(ZOe,"STRONG",{});var SOt=s(f5e);eVr=r(SOt,"longt5"),SOt.forEach(t),oVr=r(ZOe," \u2014 "),Pee=n(ZOe,"A",{href:!0});var ROt=s(Pee);rVr=r(ROt,"FlaxLongT5Model"),ROt.forEach(t),tVr=r(ZOe," (LongT5 model)"),ZOe.forEach(t),aVr=i(ae),w5=n(ae,"LI",{});var eVe=s(w5);m5e=n(eVe,"STRONG",{});var POt=s(m5e);nVr=r(POt,"marian"),POt.forEach(t),sVr=r(eVe," \u2014 "),Bee=n(eVe,"A",{href:!0});var BOt=s(Bee);lVr=r(BOt,"FlaxMarianModel"),BOt.forEach(t),iVr=r(eVe," (Marian model)"),eVe.forEach(t),dVr=i(ae),A5=n(ae,"LI",{});var oVe=s(A5);g5e=n(oVe,"STRONG",{});var IOt=s(g5e);cVr=r(IOt,"mbart"),IOt.forEach(t),fVr=r(oVe," \u2014 "),Iee=n(oVe,"A",{href:!0});var NOt=s(Iee);mVr=r(NOt,"FlaxMBartModel"),NOt.forEach(t),gVr=r(oVe," (mBART model)"),oVe.forEach(t),hVr=i(ae),L5=n(ae,"LI",{});var rVe=s(L5);h5e=n(rVe,"STRONG",{});var qOt=s(h5e);pVr=r(qOt,"mt5"),qOt.forEach(t),_Vr=r(rVe," \u2014 "),Nee=n(rVe,"A",{href:!0});var jOt=s(Nee);uVr=r(jOt,"FlaxMT5Model"),jOt.forEach(t),bVr=r(rVe," (MT5 model)"),rVe.forEach(t),vVr=i(ae),y5=n(ae,"LI",{});var tVe=s(y5);p5e=n(tVe,"STRONG",{});var DOt=s(p5e);FVr=r(DOt,"opt"),DOt.forEach(t),TVr=r(tVe," \u2014 "),qee=n(tVe,"A",{href:!0});var GOt=s(qee);MVr=r(GOt,"FlaxOPTModel"),GOt.forEach(t),EVr=r(tVe," (OPT model)"),tVe.forEach(t),CVr=i(ae),x5=n(ae,"LI",{});var aVe=s(x5);_5e=n(aVe,"STRONG",{});var OOt=s(_5e);wVr=r(OOt,"pegasus"),OOt.forEach(t),AVr=r(aVe," \u2014 "),jee=n(aVe,"A",{href:!0});var VOt=s(jee);LVr=r(VOt,"FlaxPegasusModel"),VOt.forEach(t),yVr=r(aVe," (Pegasus model)"),aVe.forEach(t),xVr=i(ae),$5=n(ae,"LI",{});var nVe=s($5);u5e=n(nVe,"STRONG",{});var XOt=s(u5e);$Vr=r(XOt,"roberta"),XOt.forEach(t),kVr=r(nVe," \u2014 "),Dee=n(nVe,"A",{href:!0});var zOt=s(Dee);SVr=r(zOt,"FlaxRobertaModel"),zOt.forEach(t),RVr=r(nVe," (RoBERTa model)"),nVe.forEach(t),PVr=i(ae),k5=n(ae,"LI",{});var sVe=s(k5);b5e=n(sVe,"STRONG",{});var QOt=s(b5e);BVr=r(QOt,"roformer"),QOt.forEach(t),IVr=r(sVe," \u2014 "),Gee=n(sVe,"A",{href:!0});var WOt=s(Gee);NVr=r(WOt,"FlaxRoFormerModel"),WOt.forEach(t),qVr=r(sVe," (RoFormer model)"),sVe.forEach(t),jVr=i(ae),S5=n(ae,"LI",{});var lVe=s(S5);v5e=n(lVe,"STRONG",{});var HOt=s(v5e);DVr=r(HOt,"t5"),HOt.forEach(t),GVr=r(lVe," \u2014 "),Oee=n(lVe,"A",{href:!0});var UOt=s(Oee);OVr=r(UOt,"FlaxT5Model"),UOt.forEach(t),VVr=r(lVe," (T5 model)"),lVe.forEach(t),XVr=i(ae),R5=n(ae,"LI",{});var iVe=s(R5);F5e=n(iVe,"STRONG",{});var JOt=s(F5e);zVr=r(JOt,"vision-text-dual-encoder"),JOt.forEach(t),QVr=r(iVe," \u2014 "),Vee=n(iVe,"A",{href:!0});var YOt=s(Vee);WVr=r(YOt,"FlaxVisionTextDualEncoderModel"),YOt.forEach(t),HVr=r(iVe," (VisionTextDualEncoder model)"),iVe.forEach(t),UVr=i(ae),P5=n(ae,"LI",{});var dVe=s(P5);T5e=n(dVe,"STRONG",{});var KOt=s(T5e);JVr=r(KOt,"vit"),KOt.forEach(t),YVr=r(dVe," \u2014 "),Xee=n(dVe,"A",{href:!0});var ZOt=s(Xee);KVr=r(ZOt,"FlaxViTModel"),ZOt.forEach(t),ZVr=r(dVe," (ViT model)"),dVe.forEach(t),eXr=i(ae),B5=n(ae,"LI",{});var cVe=s(B5);M5e=n(cVe,"STRONG",{});var eVt=s(M5e);oXr=r(eVt,"wav2vec2"),eVt.forEach(t),rXr=r(cVe," \u2014 "),zee=n(cVe,"A",{href:!0});var oVt=s(zee);tXr=r(oVt,"FlaxWav2Vec2Model"),oVt.forEach(t),aXr=r(cVe," (Wav2Vec2 model)"),cVe.forEach(t),nXr=i(ae),I5=n(ae,"LI",{});var fVe=s(I5);E5e=n(fVe,"STRONG",{});var rVt=s(E5e);sXr=r(rVt,"xglm"),rVt.forEach(t),lXr=r(fVe," \u2014 "),Qee=n(fVe,"A",{href:!0});var tVt=s(Qee);iXr=r(tVt,"FlaxXGLMModel"),tVt.forEach(t),dXr=r(fVe," (XGLM model)"),fVe.forEach(t),cXr=i(ae),N5=n(ae,"LI",{});var mVe=s(N5);C5e=n(mVe,"STRONG",{});var aVt=s(C5e);fXr=r(aVt,"xlm-roberta"),aVt.forEach(t),mXr=r(mVe," \u2014 "),Wee=n(mVe,"A",{href:!0});var nVt=s(Wee);gXr=r(nVt,"FlaxXLMRobertaModel"),nVt.forEach(t),hXr=r(mVe," (XLM-RoBERTa model)"),mVe.forEach(t),ae.forEach(t),pXr=i(si),T(q5.$$.fragment,si),si.forEach(t),ni.forEach(t),wQe=i(f),Kc=n(f,"H2",{class:!0});var PHe=s(Kc);j5=n(PHe,"A",{id:!0,class:!0,href:!0});var sVt=s(j5);w5e=n(sVt,"SPAN",{});var lVt=s(w5e);T(C$.$$.fragment,lVt),lVt.forEach(t),sVt.forEach(t),_Xr=i(PHe),A5e=n(PHe,"SPAN",{});var iVt=s(A5e);uXr=r(iVt,"FlaxAutoModelForCausalLM"),iVt.forEach(t),PHe.forEach(t),AQe=i(f),ur=n(f,"DIV",{class:!0});var li=s(ur);T(w$.$$.fragment,li),bXr=i(li),Zc=n(li,"P",{});var Lae=s(Zc);vXr=r(Lae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hee=n(Lae,"A",{href:!0});var dVt=s(Hee);FXr=r(dVt,"from_pretrained()"),dVt.forEach(t),TXr=r(Lae," class method or the "),Uee=n(Lae,"A",{href:!0});var cVt=s(Uee);MXr=r(cVt,"from_config()"),cVt.forEach(t),EXr=r(Lae,` class
method.`),Lae.forEach(t),CXr=i(li),A$=n(li,"P",{});var BHe=s(A$);wXr=r(BHe,"This class cannot be instantiated directly using "),L5e=n(BHe,"CODE",{});var fVt=s(L5e);AXr=r(fVt,"__init__()"),fVt.forEach(t),LXr=r(BHe," (throws an error)."),BHe.forEach(t),yXr=i(li),Ht=n(li,"DIV",{class:!0});var XA=s(Ht);T(L$.$$.fragment,XA),xXr=i(XA),y5e=n(XA,"P",{});var mVt=s(y5e);$Xr=r(mVt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),mVt.forEach(t),kXr=i(XA),ef=n(XA,"P",{});var yae=s(ef);SXr=r(yae,`Note:
Loading a model from its configuration file does `),x5e=n(yae,"STRONG",{});var gVt=s(x5e);RXr=r(gVt,"not"),gVt.forEach(t),PXr=r(yae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(yae,"A",{href:!0});var hVt=s(Jee);BXr=r(hVt,"from_pretrained()"),hVt.forEach(t),IXr=r(yae," to load the model weights."),yae.forEach(t),NXr=i(XA),T(D5.$$.fragment,XA),XA.forEach(t),qXr=i(li),zr=n(li,"DIV",{class:!0});var ii=s(zr);T(y$.$$.fragment,ii),jXr=i(ii),$5e=n(ii,"P",{});var pVt=s($5e);DXr=r(pVt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),pVt.forEach(t),GXr=i(ii),En=n(ii,"P",{});var zA=s(En);OXr=r(zA,"The model class to instantiate is selected based on the "),k5e=n(zA,"CODE",{});var _Vt=s(k5e);VXr=r(_Vt,"model_type"),_Vt.forEach(t),XXr=r(zA,` property of the config object (either
passed as an argument or loaded from `),S5e=n(zA,"CODE",{});var uVt=s(S5e);zXr=r(uVt,"pretrained_model_name_or_path"),uVt.forEach(t),QXr=r(zA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R5e=n(zA,"CODE",{});var bVt=s(R5e);WXr=r(bVt,"pretrained_model_name_or_path"),bVt.forEach(t),HXr=r(zA,":"),zA.forEach(t),UXr=i(ii),xe=n(ii,"UL",{});var Ne=s(xe);G5=n(Ne,"LI",{});var gVe=s(G5);P5e=n(gVe,"STRONG",{});var vVt=s(P5e);JXr=r(vVt,"bart"),vVt.forEach(t),YXr=r(gVe," \u2014 "),Yee=n(gVe,"A",{href:!0});var FVt=s(Yee);KXr=r(FVt,"FlaxBartForCausalLM"),FVt.forEach(t),ZXr=r(gVe," (BART model)"),gVe.forEach(t),ezr=i(Ne),O5=n(Ne,"LI",{});var hVe=s(O5);B5e=n(hVe,"STRONG",{});var TVt=s(B5e);ozr=r(TVt,"bert"),TVt.forEach(t),rzr=r(hVe," \u2014 "),Kee=n(hVe,"A",{href:!0});var MVt=s(Kee);tzr=r(MVt,"FlaxBertForCausalLM"),MVt.forEach(t),azr=r(hVe," (BERT model)"),hVe.forEach(t),nzr=i(Ne),V5=n(Ne,"LI",{});var pVe=s(V5);I5e=n(pVe,"STRONG",{});var EVt=s(I5e);szr=r(EVt,"big_bird"),EVt.forEach(t),lzr=r(pVe," \u2014 "),Zee=n(pVe,"A",{href:!0});var CVt=s(Zee);izr=r(CVt,"FlaxBigBirdForCausalLM"),CVt.forEach(t),dzr=r(pVe," (BigBird model)"),pVe.forEach(t),czr=i(Ne),X5=n(Ne,"LI",{});var _Ve=s(X5);N5e=n(_Ve,"STRONG",{});var wVt=s(N5e);fzr=r(wVt,"electra"),wVt.forEach(t),mzr=r(_Ve," \u2014 "),eoe=n(_Ve,"A",{href:!0});var AVt=s(eoe);gzr=r(AVt,"FlaxElectraForCausalLM"),AVt.forEach(t),hzr=r(_Ve," (ELECTRA model)"),_Ve.forEach(t),pzr=i(Ne),z5=n(Ne,"LI",{});var uVe=s(z5);q5e=n(uVe,"STRONG",{});var LVt=s(q5e);_zr=r(LVt,"gpt2"),LVt.forEach(t),uzr=r(uVe," \u2014 "),ooe=n(uVe,"A",{href:!0});var yVt=s(ooe);bzr=r(yVt,"FlaxGPT2LMHeadModel"),yVt.forEach(t),vzr=r(uVe," (OpenAI GPT-2 model)"),uVe.forEach(t),Fzr=i(Ne),Q5=n(Ne,"LI",{});var bVe=s(Q5);j5e=n(bVe,"STRONG",{});var xVt=s(j5e);Tzr=r(xVt,"gpt_neo"),xVt.forEach(t),Mzr=r(bVe," \u2014 "),roe=n(bVe,"A",{href:!0});var $Vt=s(roe);Ezr=r($Vt,"FlaxGPTNeoForCausalLM"),$Vt.forEach(t),Czr=r(bVe," (GPT Neo model)"),bVe.forEach(t),wzr=i(Ne),W5=n(Ne,"LI",{});var vVe=s(W5);D5e=n(vVe,"STRONG",{});var kVt=s(D5e);Azr=r(kVt,"gptj"),kVt.forEach(t),Lzr=r(vVe," \u2014 "),toe=n(vVe,"A",{href:!0});var SVt=s(toe);yzr=r(SVt,"FlaxGPTJForCausalLM"),SVt.forEach(t),xzr=r(vVe," (GPT-J model)"),vVe.forEach(t),$zr=i(Ne),H5=n(Ne,"LI",{});var FVe=s(H5);G5e=n(FVe,"STRONG",{});var RVt=s(G5e);kzr=r(RVt,"opt"),RVt.forEach(t),Szr=r(FVe," \u2014 "),aoe=n(FVe,"A",{href:!0});var PVt=s(aoe);Rzr=r(PVt,"FlaxOPTForCausalLM"),PVt.forEach(t),Pzr=r(FVe," (OPT model)"),FVe.forEach(t),Bzr=i(Ne),U5=n(Ne,"LI",{});var TVe=s(U5);O5e=n(TVe,"STRONG",{});var BVt=s(O5e);Izr=r(BVt,"roberta"),BVt.forEach(t),Nzr=r(TVe," \u2014 "),noe=n(TVe,"A",{href:!0});var IVt=s(noe);qzr=r(IVt,"FlaxRobertaForCausalLM"),IVt.forEach(t),jzr=r(TVe," (RoBERTa model)"),TVe.forEach(t),Dzr=i(Ne),J5=n(Ne,"LI",{});var MVe=s(J5);V5e=n(MVe,"STRONG",{});var NVt=s(V5e);Gzr=r(NVt,"xglm"),NVt.forEach(t),Ozr=r(MVe," \u2014 "),soe=n(MVe,"A",{href:!0});var qVt=s(soe);Vzr=r(qVt,"FlaxXGLMForCausalLM"),qVt.forEach(t),Xzr=r(MVe," (XGLM model)"),MVe.forEach(t),Ne.forEach(t),zzr=i(ii),T(Y5.$$.fragment,ii),ii.forEach(t),li.forEach(t),LQe=i(f),of=n(f,"H2",{class:!0});var IHe=s(of);K5=n(IHe,"A",{id:!0,class:!0,href:!0});var jVt=s(K5);X5e=n(jVt,"SPAN",{});var DVt=s(X5e);T(x$.$$.fragment,DVt),DVt.forEach(t),jVt.forEach(t),Qzr=i(IHe),z5e=n(IHe,"SPAN",{});var GVt=s(z5e);Wzr=r(GVt,"FlaxAutoModelForPreTraining"),GVt.forEach(t),IHe.forEach(t),yQe=i(f),br=n(f,"DIV",{class:!0});var di=s(br);T($$.$$.fragment,di),Hzr=i(di),rf=n(di,"P",{});var xae=s(rf);Uzr=r(xae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),loe=n(xae,"A",{href:!0});var OVt=s(loe);Jzr=r(OVt,"from_pretrained()"),OVt.forEach(t),Yzr=r(xae," class method or the "),ioe=n(xae,"A",{href:!0});var VVt=s(ioe);Kzr=r(VVt,"from_config()"),VVt.forEach(t),Zzr=r(xae,` class
method.`),xae.forEach(t),eQr=i(di),k$=n(di,"P",{});var NHe=s(k$);oQr=r(NHe,"This class cannot be instantiated directly using "),Q5e=n(NHe,"CODE",{});var XVt=s(Q5e);rQr=r(XVt,"__init__()"),XVt.forEach(t),tQr=r(NHe," (throws an error)."),NHe.forEach(t),aQr=i(di),Ut=n(di,"DIV",{class:!0});var QA=s(Ut);T(S$.$$.fragment,QA),nQr=i(QA),W5e=n(QA,"P",{});var zVt=s(W5e);sQr=r(zVt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),zVt.forEach(t),lQr=i(QA),tf=n(QA,"P",{});var $ae=s(tf);iQr=r($ae,`Note:
Loading a model from its configuration file does `),H5e=n($ae,"STRONG",{});var QVt=s(H5e);dQr=r(QVt,"not"),QVt.forEach(t),cQr=r($ae,` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=n($ae,"A",{href:!0});var WVt=s(doe);fQr=r(WVt,"from_pretrained()"),WVt.forEach(t),mQr=r($ae," to load the model weights."),$ae.forEach(t),gQr=i(QA),T(Z5.$$.fragment,QA),QA.forEach(t),hQr=i(di),Qr=n(di,"DIV",{class:!0});var ci=s(Qr);T(R$.$$.fragment,ci),pQr=i(ci),U5e=n(ci,"P",{});var HVt=s(U5e);_Qr=r(HVt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),HVt.forEach(t),uQr=i(ci),Cn=n(ci,"P",{});var WA=s(Cn);bQr=r(WA,"The model class to instantiate is selected based on the "),J5e=n(WA,"CODE",{});var UVt=s(J5e);vQr=r(UVt,"model_type"),UVt.forEach(t),FQr=r(WA,` property of the config object (either
passed as an argument or loaded from `),Y5e=n(WA,"CODE",{});var JVt=s(Y5e);TQr=r(JVt,"pretrained_model_name_or_path"),JVt.forEach(t),MQr=r(WA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=n(WA,"CODE",{});var YVt=s(K5e);EQr=r(YVt,"pretrained_model_name_or_path"),YVt.forEach(t),CQr=r(WA,":"),WA.forEach(t),wQr=i(ci),Ee=n(ci,"UL",{});var we=s(Ee);e3=n(we,"LI",{});var EVe=s(e3);Z5e=n(EVe,"STRONG",{});var KVt=s(Z5e);AQr=r(KVt,"albert"),KVt.forEach(t),LQr=r(EVe," \u2014 "),coe=n(EVe,"A",{href:!0});var ZVt=s(coe);yQr=r(ZVt,"FlaxAlbertForPreTraining"),ZVt.forEach(t),xQr=r(EVe," (ALBERT model)"),EVe.forEach(t),$Qr=i(we),o3=n(we,"LI",{});var CVe=s(o3);e3e=n(CVe,"STRONG",{});var eXt=s(e3e);kQr=r(eXt,"bart"),eXt.forEach(t),SQr=r(CVe," \u2014 "),foe=n(CVe,"A",{href:!0});var oXt=s(foe);RQr=r(oXt,"FlaxBartForConditionalGeneration"),oXt.forEach(t),PQr=r(CVe," (BART model)"),CVe.forEach(t),BQr=i(we),r3=n(we,"LI",{});var wVe=s(r3);o3e=n(wVe,"STRONG",{});var rXt=s(o3e);IQr=r(rXt,"bert"),rXt.forEach(t),NQr=r(wVe," \u2014 "),moe=n(wVe,"A",{href:!0});var tXt=s(moe);qQr=r(tXt,"FlaxBertForPreTraining"),tXt.forEach(t),jQr=r(wVe," (BERT model)"),wVe.forEach(t),DQr=i(we),t3=n(we,"LI",{});var AVe=s(t3);r3e=n(AVe,"STRONG",{});var aXt=s(r3e);GQr=r(aXt,"big_bird"),aXt.forEach(t),OQr=r(AVe," \u2014 "),goe=n(AVe,"A",{href:!0});var nXt=s(goe);VQr=r(nXt,"FlaxBigBirdForPreTraining"),nXt.forEach(t),XQr=r(AVe," (BigBird model)"),AVe.forEach(t),zQr=i(we),a3=n(we,"LI",{});var LVe=s(a3);t3e=n(LVe,"STRONG",{});var sXt=s(t3e);QQr=r(sXt,"electra"),sXt.forEach(t),WQr=r(LVe," \u2014 "),hoe=n(LVe,"A",{href:!0});var lXt=s(hoe);HQr=r(lXt,"FlaxElectraForPreTraining"),lXt.forEach(t),UQr=r(LVe," (ELECTRA model)"),LVe.forEach(t),JQr=i(we),n3=n(we,"LI",{});var yVe=s(n3);a3e=n(yVe,"STRONG",{});var iXt=s(a3e);YQr=r(iXt,"longt5"),iXt.forEach(t),KQr=r(yVe," \u2014 "),poe=n(yVe,"A",{href:!0});var dXt=s(poe);ZQr=r(dXt,"FlaxLongT5ForConditionalGeneration"),dXt.forEach(t),eWr=r(yVe," (LongT5 model)"),yVe.forEach(t),oWr=i(we),s3=n(we,"LI",{});var xVe=s(s3);n3e=n(xVe,"STRONG",{});var cXt=s(n3e);rWr=r(cXt,"mbart"),cXt.forEach(t),tWr=r(xVe," \u2014 "),_oe=n(xVe,"A",{href:!0});var fXt=s(_oe);aWr=r(fXt,"FlaxMBartForConditionalGeneration"),fXt.forEach(t),nWr=r(xVe," (mBART model)"),xVe.forEach(t),sWr=i(we),l3=n(we,"LI",{});var $Ve=s(l3);s3e=n($Ve,"STRONG",{});var mXt=s(s3e);lWr=r(mXt,"mt5"),mXt.forEach(t),iWr=r($Ve," \u2014 "),uoe=n($Ve,"A",{href:!0});var gXt=s(uoe);dWr=r(gXt,"FlaxMT5ForConditionalGeneration"),gXt.forEach(t),cWr=r($Ve," (MT5 model)"),$Ve.forEach(t),fWr=i(we),i3=n(we,"LI",{});var kVe=s(i3);l3e=n(kVe,"STRONG",{});var hXt=s(l3e);mWr=r(hXt,"roberta"),hXt.forEach(t),gWr=r(kVe," \u2014 "),boe=n(kVe,"A",{href:!0});var pXt=s(boe);hWr=r(pXt,"FlaxRobertaForMaskedLM"),pXt.forEach(t),pWr=r(kVe," (RoBERTa model)"),kVe.forEach(t),_Wr=i(we),d3=n(we,"LI",{});var SVe=s(d3);i3e=n(SVe,"STRONG",{});var _Xt=s(i3e);uWr=r(_Xt,"roformer"),_Xt.forEach(t),bWr=r(SVe," \u2014 "),voe=n(SVe,"A",{href:!0});var uXt=s(voe);vWr=r(uXt,"FlaxRoFormerForMaskedLM"),uXt.forEach(t),FWr=r(SVe," (RoFormer model)"),SVe.forEach(t),TWr=i(we),c3=n(we,"LI",{});var RVe=s(c3);d3e=n(RVe,"STRONG",{});var bXt=s(d3e);MWr=r(bXt,"t5"),bXt.forEach(t),EWr=r(RVe," \u2014 "),Foe=n(RVe,"A",{href:!0});var vXt=s(Foe);CWr=r(vXt,"FlaxT5ForConditionalGeneration"),vXt.forEach(t),wWr=r(RVe," (T5 model)"),RVe.forEach(t),AWr=i(we),f3=n(we,"LI",{});var PVe=s(f3);c3e=n(PVe,"STRONG",{});var FXt=s(c3e);LWr=r(FXt,"wav2vec2"),FXt.forEach(t),yWr=r(PVe," \u2014 "),Toe=n(PVe,"A",{href:!0});var TXt=s(Toe);xWr=r(TXt,"FlaxWav2Vec2ForPreTraining"),TXt.forEach(t),$Wr=r(PVe," (Wav2Vec2 model)"),PVe.forEach(t),kWr=i(we),m3=n(we,"LI",{});var BVe=s(m3);f3e=n(BVe,"STRONG",{});var MXt=s(f3e);SWr=r(MXt,"xlm-roberta"),MXt.forEach(t),RWr=r(BVe," \u2014 "),Moe=n(BVe,"A",{href:!0});var EXt=s(Moe);PWr=r(EXt,"FlaxXLMRobertaForMaskedLM"),EXt.forEach(t),BWr=r(BVe," (XLM-RoBERTa model)"),BVe.forEach(t),we.forEach(t),IWr=i(ci),T(g3.$$.fragment,ci),ci.forEach(t),di.forEach(t),xQe=i(f),af=n(f,"H2",{class:!0});var qHe=s(af);h3=n(qHe,"A",{id:!0,class:!0,href:!0});var CXt=s(h3);m3e=n(CXt,"SPAN",{});var wXt=s(m3e);T(P$.$$.fragment,wXt),wXt.forEach(t),CXt.forEach(t),NWr=i(qHe),g3e=n(qHe,"SPAN",{});var AXt=s(g3e);qWr=r(AXt,"FlaxAutoModelForMaskedLM"),AXt.forEach(t),qHe.forEach(t),$Qe=i(f),vr=n(f,"DIV",{class:!0});var fi=s(vr);T(B$.$$.fragment,fi),jWr=i(fi),nf=n(fi,"P",{});var kae=s(nf);DWr=r(kae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Eoe=n(kae,"A",{href:!0});var LXt=s(Eoe);GWr=r(LXt,"from_pretrained()"),LXt.forEach(t),OWr=r(kae," class method or the "),Coe=n(kae,"A",{href:!0});var yXt=s(Coe);VWr=r(yXt,"from_config()"),yXt.forEach(t),XWr=r(kae,` class
method.`),kae.forEach(t),zWr=i(fi),I$=n(fi,"P",{});var jHe=s(I$);QWr=r(jHe,"This class cannot be instantiated directly using "),h3e=n(jHe,"CODE",{});var xXt=s(h3e);WWr=r(xXt,"__init__()"),xXt.forEach(t),HWr=r(jHe," (throws an error)."),jHe.forEach(t),UWr=i(fi),Jt=n(fi,"DIV",{class:!0});var HA=s(Jt);T(N$.$$.fragment,HA),JWr=i(HA),p3e=n(HA,"P",{});var $Xt=s(p3e);YWr=r($Xt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),$Xt.forEach(t),KWr=i(HA),sf=n(HA,"P",{});var Sae=s(sf);ZWr=r(Sae,`Note:
Loading a model from its configuration file does `),_3e=n(Sae,"STRONG",{});var kXt=s(_3e);eHr=r(kXt,"not"),kXt.forEach(t),oHr=r(Sae,` load the model weights. It only affects the
model\u2019s configuration. Use `),woe=n(Sae,"A",{href:!0});var SXt=s(woe);rHr=r(SXt,"from_pretrained()"),SXt.forEach(t),tHr=r(Sae," to load the model weights."),Sae.forEach(t),aHr=i(HA),T(p3.$$.fragment,HA),HA.forEach(t),nHr=i(fi),Wr=n(fi,"DIV",{class:!0});var mi=s(Wr);T(q$.$$.fragment,mi),sHr=i(mi),u3e=n(mi,"P",{});var RXt=s(u3e);lHr=r(RXt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),RXt.forEach(t),iHr=i(mi),wn=n(mi,"P",{});var UA=s(wn);dHr=r(UA,"The model class to instantiate is selected based on the "),b3e=n(UA,"CODE",{});var PXt=s(b3e);cHr=r(PXt,"model_type"),PXt.forEach(t),fHr=r(UA,` property of the config object (either
passed as an argument or loaded from `),v3e=n(UA,"CODE",{});var BXt=s(v3e);mHr=r(BXt,"pretrained_model_name_or_path"),BXt.forEach(t),gHr=r(UA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F3e=n(UA,"CODE",{});var IXt=s(F3e);hHr=r(IXt,"pretrained_model_name_or_path"),IXt.forEach(t),pHr=r(UA,":"),UA.forEach(t),_Hr=i(mi),$e=n(mi,"UL",{});var qe=s($e);_3=n(qe,"LI",{});var IVe=s(_3);T3e=n(IVe,"STRONG",{});var NXt=s(T3e);uHr=r(NXt,"albert"),NXt.forEach(t),bHr=r(IVe," \u2014 "),Aoe=n(IVe,"A",{href:!0});var qXt=s(Aoe);vHr=r(qXt,"FlaxAlbertForMaskedLM"),qXt.forEach(t),FHr=r(IVe," (ALBERT model)"),IVe.forEach(t),THr=i(qe),u3=n(qe,"LI",{});var NVe=s(u3);M3e=n(NVe,"STRONG",{});var jXt=s(M3e);MHr=r(jXt,"bart"),jXt.forEach(t),EHr=r(NVe," \u2014 "),Loe=n(NVe,"A",{href:!0});var DXt=s(Loe);CHr=r(DXt,"FlaxBartForConditionalGeneration"),DXt.forEach(t),wHr=r(NVe," (BART model)"),NVe.forEach(t),AHr=i(qe),b3=n(qe,"LI",{});var qVe=s(b3);E3e=n(qVe,"STRONG",{});var GXt=s(E3e);LHr=r(GXt,"bert"),GXt.forEach(t),yHr=r(qVe," \u2014 "),yoe=n(qVe,"A",{href:!0});var OXt=s(yoe);xHr=r(OXt,"FlaxBertForMaskedLM"),OXt.forEach(t),$Hr=r(qVe," (BERT model)"),qVe.forEach(t),kHr=i(qe),v3=n(qe,"LI",{});var jVe=s(v3);C3e=n(jVe,"STRONG",{});var VXt=s(C3e);SHr=r(VXt,"big_bird"),VXt.forEach(t),RHr=r(jVe," \u2014 "),xoe=n(jVe,"A",{href:!0});var XXt=s(xoe);PHr=r(XXt,"FlaxBigBirdForMaskedLM"),XXt.forEach(t),BHr=r(jVe," (BigBird model)"),jVe.forEach(t),IHr=i(qe),F3=n(qe,"LI",{});var DVe=s(F3);w3e=n(DVe,"STRONG",{});var zXt=s(w3e);NHr=r(zXt,"distilbert"),zXt.forEach(t),qHr=r(DVe," \u2014 "),$oe=n(DVe,"A",{href:!0});var QXt=s($oe);jHr=r(QXt,"FlaxDistilBertForMaskedLM"),QXt.forEach(t),DHr=r(DVe," (DistilBERT model)"),DVe.forEach(t),GHr=i(qe),T3=n(qe,"LI",{});var GVe=s(T3);A3e=n(GVe,"STRONG",{});var WXt=s(A3e);OHr=r(WXt,"electra"),WXt.forEach(t),VHr=r(GVe," \u2014 "),koe=n(GVe,"A",{href:!0});var HXt=s(koe);XHr=r(HXt,"FlaxElectraForMaskedLM"),HXt.forEach(t),zHr=r(GVe," (ELECTRA model)"),GVe.forEach(t),QHr=i(qe),M3=n(qe,"LI",{});var OVe=s(M3);L3e=n(OVe,"STRONG",{});var UXt=s(L3e);WHr=r(UXt,"mbart"),UXt.forEach(t),HHr=r(OVe," \u2014 "),Soe=n(OVe,"A",{href:!0});var JXt=s(Soe);UHr=r(JXt,"FlaxMBartForConditionalGeneration"),JXt.forEach(t),JHr=r(OVe," (mBART model)"),OVe.forEach(t),YHr=i(qe),E3=n(qe,"LI",{});var VVe=s(E3);y3e=n(VVe,"STRONG",{});var YXt=s(y3e);KHr=r(YXt,"roberta"),YXt.forEach(t),ZHr=r(VVe," \u2014 "),Roe=n(VVe,"A",{href:!0});var KXt=s(Roe);eUr=r(KXt,"FlaxRobertaForMaskedLM"),KXt.forEach(t),oUr=r(VVe," (RoBERTa model)"),VVe.forEach(t),rUr=i(qe),C3=n(qe,"LI",{});var XVe=s(C3);x3e=n(XVe,"STRONG",{});var ZXt=s(x3e);tUr=r(ZXt,"roformer"),ZXt.forEach(t),aUr=r(XVe," \u2014 "),Poe=n(XVe,"A",{href:!0});var ezt=s(Poe);nUr=r(ezt,"FlaxRoFormerForMaskedLM"),ezt.forEach(t),sUr=r(XVe," (RoFormer model)"),XVe.forEach(t),lUr=i(qe),w3=n(qe,"LI",{});var zVe=s(w3);$3e=n(zVe,"STRONG",{});var ozt=s($3e);iUr=r(ozt,"xlm-roberta"),ozt.forEach(t),dUr=r(zVe," \u2014 "),Boe=n(zVe,"A",{href:!0});var rzt=s(Boe);cUr=r(rzt,"FlaxXLMRobertaForMaskedLM"),rzt.forEach(t),fUr=r(zVe," (XLM-RoBERTa model)"),zVe.forEach(t),qe.forEach(t),mUr=i(mi),T(A3.$$.fragment,mi),mi.forEach(t),fi.forEach(t),kQe=i(f),lf=n(f,"H2",{class:!0});var DHe=s(lf);L3=n(DHe,"A",{id:!0,class:!0,href:!0});var tzt=s(L3);k3e=n(tzt,"SPAN",{});var azt=s(k3e);T(j$.$$.fragment,azt),azt.forEach(t),tzt.forEach(t),gUr=i(DHe),S3e=n(DHe,"SPAN",{});var nzt=s(S3e);hUr=r(nzt,"FlaxAutoModelForSeq2SeqLM"),nzt.forEach(t),DHe.forEach(t),SQe=i(f),Fr=n(f,"DIV",{class:!0});var gi=s(Fr);T(D$.$$.fragment,gi),pUr=i(gi),df=n(gi,"P",{});var Rae=s(df);_Ur=r(Rae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ioe=n(Rae,"A",{href:!0});var szt=s(Ioe);uUr=r(szt,"from_pretrained()"),szt.forEach(t),bUr=r(Rae," class method or the "),Noe=n(Rae,"A",{href:!0});var lzt=s(Noe);vUr=r(lzt,"from_config()"),lzt.forEach(t),FUr=r(Rae,` class
method.`),Rae.forEach(t),TUr=i(gi),G$=n(gi,"P",{});var GHe=s(G$);MUr=r(GHe,"This class cannot be instantiated directly using "),R3e=n(GHe,"CODE",{});var izt=s(R3e);EUr=r(izt,"__init__()"),izt.forEach(t),CUr=r(GHe," (throws an error)."),GHe.forEach(t),wUr=i(gi),Yt=n(gi,"DIV",{class:!0});var JA=s(Yt);T(O$.$$.fragment,JA),AUr=i(JA),P3e=n(JA,"P",{});var dzt=s(P3e);LUr=r(dzt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),dzt.forEach(t),yUr=i(JA),cf=n(JA,"P",{});var Pae=s(cf);xUr=r(Pae,`Note:
Loading a model from its configuration file does `),B3e=n(Pae,"STRONG",{});var czt=s(B3e);$Ur=r(czt,"not"),czt.forEach(t),kUr=r(Pae,` load the model weights. It only affects the
model\u2019s configuration. Use `),qoe=n(Pae,"A",{href:!0});var fzt=s(qoe);SUr=r(fzt,"from_pretrained()"),fzt.forEach(t),RUr=r(Pae," to load the model weights."),Pae.forEach(t),PUr=i(JA),T(y3.$$.fragment,JA),JA.forEach(t),BUr=i(gi),Hr=n(gi,"DIV",{class:!0});var hi=s(Hr);T(V$.$$.fragment,hi),IUr=i(hi),I3e=n(hi,"P",{});var mzt=s(I3e);NUr=r(mzt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),mzt.forEach(t),qUr=i(hi),An=n(hi,"P",{});var YA=s(An);jUr=r(YA,"The model class to instantiate is selected based on the "),N3e=n(YA,"CODE",{});var gzt=s(N3e);DUr=r(gzt,"model_type"),gzt.forEach(t),GUr=r(YA,` property of the config object (either
passed as an argument or loaded from `),q3e=n(YA,"CODE",{});var hzt=s(q3e);OUr=r(hzt,"pretrained_model_name_or_path"),hzt.forEach(t),VUr=r(YA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=n(YA,"CODE",{});var pzt=s(j3e);XUr=r(pzt,"pretrained_model_name_or_path"),pzt.forEach(t),zUr=r(YA,":"),YA.forEach(t),QUr=i(hi),ke=n(hi,"UL",{});var je=s(ke);x3=n(je,"LI",{});var QVe=s(x3);D3e=n(QVe,"STRONG",{});var _zt=s(D3e);WUr=r(_zt,"bart"),_zt.forEach(t),HUr=r(QVe," \u2014 "),joe=n(QVe,"A",{href:!0});var uzt=s(joe);UUr=r(uzt,"FlaxBartForConditionalGeneration"),uzt.forEach(t),JUr=r(QVe," (BART model)"),QVe.forEach(t),YUr=i(je),$3=n(je,"LI",{});var WVe=s($3);G3e=n(WVe,"STRONG",{});var bzt=s(G3e);KUr=r(bzt,"blenderbot"),bzt.forEach(t),ZUr=r(WVe," \u2014 "),Doe=n(WVe,"A",{href:!0});var vzt=s(Doe);eJr=r(vzt,"FlaxBlenderbotForConditionalGeneration"),vzt.forEach(t),oJr=r(WVe," (Blenderbot model)"),WVe.forEach(t),rJr=i(je),k3=n(je,"LI",{});var HVe=s(k3);O3e=n(HVe,"STRONG",{});var Fzt=s(O3e);tJr=r(Fzt,"blenderbot-small"),Fzt.forEach(t),aJr=r(HVe," \u2014 "),Goe=n(HVe,"A",{href:!0});var Tzt=s(Goe);nJr=r(Tzt,"FlaxBlenderbotSmallForConditionalGeneration"),Tzt.forEach(t),sJr=r(HVe," (BlenderbotSmall model)"),HVe.forEach(t),lJr=i(je),S3=n(je,"LI",{});var UVe=s(S3);V3e=n(UVe,"STRONG",{});var Mzt=s(V3e);iJr=r(Mzt,"encoder-decoder"),Mzt.forEach(t),dJr=r(UVe," \u2014 "),Ooe=n(UVe,"A",{href:!0});var Ezt=s(Ooe);cJr=r(Ezt,"FlaxEncoderDecoderModel"),Ezt.forEach(t),fJr=r(UVe," (Encoder decoder model)"),UVe.forEach(t),mJr=i(je),R3=n(je,"LI",{});var JVe=s(R3);X3e=n(JVe,"STRONG",{});var Czt=s(X3e);gJr=r(Czt,"longt5"),Czt.forEach(t),hJr=r(JVe," \u2014 "),Voe=n(JVe,"A",{href:!0});var wzt=s(Voe);pJr=r(wzt,"FlaxLongT5ForConditionalGeneration"),wzt.forEach(t),_Jr=r(JVe," (LongT5 model)"),JVe.forEach(t),uJr=i(je),P3=n(je,"LI",{});var YVe=s(P3);z3e=n(YVe,"STRONG",{});var Azt=s(z3e);bJr=r(Azt,"marian"),Azt.forEach(t),vJr=r(YVe," \u2014 "),Xoe=n(YVe,"A",{href:!0});var Lzt=s(Xoe);FJr=r(Lzt,"FlaxMarianMTModel"),Lzt.forEach(t),TJr=r(YVe," (Marian model)"),YVe.forEach(t),MJr=i(je),B3=n(je,"LI",{});var KVe=s(B3);Q3e=n(KVe,"STRONG",{});var yzt=s(Q3e);EJr=r(yzt,"mbart"),yzt.forEach(t),CJr=r(KVe," \u2014 "),zoe=n(KVe,"A",{href:!0});var xzt=s(zoe);wJr=r(xzt,"FlaxMBartForConditionalGeneration"),xzt.forEach(t),AJr=r(KVe," (mBART model)"),KVe.forEach(t),LJr=i(je),I3=n(je,"LI",{});var ZVe=s(I3);W3e=n(ZVe,"STRONG",{});var $zt=s(W3e);yJr=r($zt,"mt5"),$zt.forEach(t),xJr=r(ZVe," \u2014 "),Qoe=n(ZVe,"A",{href:!0});var kzt=s(Qoe);$Jr=r(kzt,"FlaxMT5ForConditionalGeneration"),kzt.forEach(t),kJr=r(ZVe," (MT5 model)"),ZVe.forEach(t),SJr=i(je),N3=n(je,"LI",{});var eXe=s(N3);H3e=n(eXe,"STRONG",{});var Szt=s(H3e);RJr=r(Szt,"pegasus"),Szt.forEach(t),PJr=r(eXe," \u2014 "),Woe=n(eXe,"A",{href:!0});var Rzt=s(Woe);BJr=r(Rzt,"FlaxPegasusForConditionalGeneration"),Rzt.forEach(t),IJr=r(eXe," (Pegasus model)"),eXe.forEach(t),NJr=i(je),q3=n(je,"LI",{});var oXe=s(q3);U3e=n(oXe,"STRONG",{});var Pzt=s(U3e);qJr=r(Pzt,"t5"),Pzt.forEach(t),jJr=r(oXe," \u2014 "),Hoe=n(oXe,"A",{href:!0});var Bzt=s(Hoe);DJr=r(Bzt,"FlaxT5ForConditionalGeneration"),Bzt.forEach(t),GJr=r(oXe," (T5 model)"),oXe.forEach(t),je.forEach(t),OJr=i(hi),T(j3.$$.fragment,hi),hi.forEach(t),gi.forEach(t),RQe=i(f),ff=n(f,"H2",{class:!0});var OHe=s(ff);D3=n(OHe,"A",{id:!0,class:!0,href:!0});var Izt=s(D3);J3e=n(Izt,"SPAN",{});var Nzt=s(J3e);T(X$.$$.fragment,Nzt),Nzt.forEach(t),Izt.forEach(t),VJr=i(OHe),Y3e=n(OHe,"SPAN",{});var qzt=s(Y3e);XJr=r(qzt,"FlaxAutoModelForSequenceClassification"),qzt.forEach(t),OHe.forEach(t),PQe=i(f),Tr=n(f,"DIV",{class:!0});var pi=s(Tr);T(z$.$$.fragment,pi),zJr=i(pi),mf=n(pi,"P",{});var Bae=s(mf);QJr=r(Bae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Uoe=n(Bae,"A",{href:!0});var jzt=s(Uoe);WJr=r(jzt,"from_pretrained()"),jzt.forEach(t),HJr=r(Bae," class method or the "),Joe=n(Bae,"A",{href:!0});var Dzt=s(Joe);UJr=r(Dzt,"from_config()"),Dzt.forEach(t),JJr=r(Bae,` class
method.`),Bae.forEach(t),YJr=i(pi),Q$=n(pi,"P",{});var VHe=s(Q$);KJr=r(VHe,"This class cannot be instantiated directly using "),K3e=n(VHe,"CODE",{});var Gzt=s(K3e);ZJr=r(Gzt,"__init__()"),Gzt.forEach(t),eYr=r(VHe," (throws an error)."),VHe.forEach(t),oYr=i(pi),Kt=n(pi,"DIV",{class:!0});var KA=s(Kt);T(W$.$$.fragment,KA),rYr=i(KA),Z3e=n(KA,"P",{});var Ozt=s(Z3e);tYr=r(Ozt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Ozt.forEach(t),aYr=i(KA),gf=n(KA,"P",{});var Iae=s(gf);nYr=r(Iae,`Note:
Loading a model from its configuration file does `),e0e=n(Iae,"STRONG",{});var Vzt=s(e0e);sYr=r(Vzt,"not"),Vzt.forEach(t),lYr=r(Iae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yoe=n(Iae,"A",{href:!0});var Xzt=s(Yoe);iYr=r(Xzt,"from_pretrained()"),Xzt.forEach(t),dYr=r(Iae," to load the model weights."),Iae.forEach(t),cYr=i(KA),T(G3.$$.fragment,KA),KA.forEach(t),fYr=i(pi),Ur=n(pi,"DIV",{class:!0});var _i=s(Ur);T(H$.$$.fragment,_i),mYr=i(_i),o0e=n(_i,"P",{});var zzt=s(o0e);gYr=r(zzt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),zzt.forEach(t),hYr=i(_i),Ln=n(_i,"P",{});var ZA=s(Ln);pYr=r(ZA,"The model class to instantiate is selected based on the "),r0e=n(ZA,"CODE",{});var Qzt=s(r0e);_Yr=r(Qzt,"model_type"),Qzt.forEach(t),uYr=r(ZA,` property of the config object (either
passed as an argument or loaded from `),t0e=n(ZA,"CODE",{});var Wzt=s(t0e);bYr=r(Wzt,"pretrained_model_name_or_path"),Wzt.forEach(t),vYr=r(ZA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=n(ZA,"CODE",{});var Hzt=s(a0e);FYr=r(Hzt,"pretrained_model_name_or_path"),Hzt.forEach(t),TYr=r(ZA,":"),ZA.forEach(t),MYr=i(_i),Se=n(_i,"UL",{});var De=s(Se);O3=n(De,"LI",{});var rXe=s(O3);n0e=n(rXe,"STRONG",{});var Uzt=s(n0e);EYr=r(Uzt,"albert"),Uzt.forEach(t),CYr=r(rXe," \u2014 "),Koe=n(rXe,"A",{href:!0});var Jzt=s(Koe);wYr=r(Jzt,"FlaxAlbertForSequenceClassification"),Jzt.forEach(t),AYr=r(rXe," (ALBERT model)"),rXe.forEach(t),LYr=i(De),V3=n(De,"LI",{});var tXe=s(V3);s0e=n(tXe,"STRONG",{});var Yzt=s(s0e);yYr=r(Yzt,"bart"),Yzt.forEach(t),xYr=r(tXe," \u2014 "),Zoe=n(tXe,"A",{href:!0});var Kzt=s(Zoe);$Yr=r(Kzt,"FlaxBartForSequenceClassification"),Kzt.forEach(t),kYr=r(tXe," (BART model)"),tXe.forEach(t),SYr=i(De),X3=n(De,"LI",{});var aXe=s(X3);l0e=n(aXe,"STRONG",{});var Zzt=s(l0e);RYr=r(Zzt,"bert"),Zzt.forEach(t),PYr=r(aXe," \u2014 "),ere=n(aXe,"A",{href:!0});var eQt=s(ere);BYr=r(eQt,"FlaxBertForSequenceClassification"),eQt.forEach(t),IYr=r(aXe," (BERT model)"),aXe.forEach(t),NYr=i(De),z3=n(De,"LI",{});var nXe=s(z3);i0e=n(nXe,"STRONG",{});var oQt=s(i0e);qYr=r(oQt,"big_bird"),oQt.forEach(t),jYr=r(nXe," \u2014 "),ore=n(nXe,"A",{href:!0});var rQt=s(ore);DYr=r(rQt,"FlaxBigBirdForSequenceClassification"),rQt.forEach(t),GYr=r(nXe," (BigBird model)"),nXe.forEach(t),OYr=i(De),Q3=n(De,"LI",{});var sXe=s(Q3);d0e=n(sXe,"STRONG",{});var tQt=s(d0e);VYr=r(tQt,"distilbert"),tQt.forEach(t),XYr=r(sXe," \u2014 "),rre=n(sXe,"A",{href:!0});var aQt=s(rre);zYr=r(aQt,"FlaxDistilBertForSequenceClassification"),aQt.forEach(t),QYr=r(sXe," (DistilBERT model)"),sXe.forEach(t),WYr=i(De),W3=n(De,"LI",{});var lXe=s(W3);c0e=n(lXe,"STRONG",{});var nQt=s(c0e);HYr=r(nQt,"electra"),nQt.forEach(t),UYr=r(lXe," \u2014 "),tre=n(lXe,"A",{href:!0});var sQt=s(tre);JYr=r(sQt,"FlaxElectraForSequenceClassification"),sQt.forEach(t),YYr=r(lXe," (ELECTRA model)"),lXe.forEach(t),KYr=i(De),H3=n(De,"LI",{});var iXe=s(H3);f0e=n(iXe,"STRONG",{});var lQt=s(f0e);ZYr=r(lQt,"mbart"),lQt.forEach(t),eKr=r(iXe," \u2014 "),are=n(iXe,"A",{href:!0});var iQt=s(are);oKr=r(iQt,"FlaxMBartForSequenceClassification"),iQt.forEach(t),rKr=r(iXe," (mBART model)"),iXe.forEach(t),tKr=i(De),U3=n(De,"LI",{});var dXe=s(U3);m0e=n(dXe,"STRONG",{});var dQt=s(m0e);aKr=r(dQt,"roberta"),dQt.forEach(t),nKr=r(dXe," \u2014 "),nre=n(dXe,"A",{href:!0});var cQt=s(nre);sKr=r(cQt,"FlaxRobertaForSequenceClassification"),cQt.forEach(t),lKr=r(dXe," (RoBERTa model)"),dXe.forEach(t),iKr=i(De),J3=n(De,"LI",{});var cXe=s(J3);g0e=n(cXe,"STRONG",{});var fQt=s(g0e);dKr=r(fQt,"roformer"),fQt.forEach(t),cKr=r(cXe," \u2014 "),sre=n(cXe,"A",{href:!0});var mQt=s(sre);fKr=r(mQt,"FlaxRoFormerForSequenceClassification"),mQt.forEach(t),mKr=r(cXe," (RoFormer model)"),cXe.forEach(t),gKr=i(De),Y3=n(De,"LI",{});var fXe=s(Y3);h0e=n(fXe,"STRONG",{});var gQt=s(h0e);hKr=r(gQt,"xlm-roberta"),gQt.forEach(t),pKr=r(fXe," \u2014 "),lre=n(fXe,"A",{href:!0});var hQt=s(lre);_Kr=r(hQt,"FlaxXLMRobertaForSequenceClassification"),hQt.forEach(t),uKr=r(fXe," (XLM-RoBERTa model)"),fXe.forEach(t),De.forEach(t),bKr=i(_i),T(K3.$$.fragment,_i),_i.forEach(t),pi.forEach(t),BQe=i(f),hf=n(f,"H2",{class:!0});var XHe=s(hf);Z3=n(XHe,"A",{id:!0,class:!0,href:!0});var pQt=s(Z3);p0e=n(pQt,"SPAN",{});var _Qt=s(p0e);T(U$.$$.fragment,_Qt),_Qt.forEach(t),pQt.forEach(t),vKr=i(XHe),_0e=n(XHe,"SPAN",{});var uQt=s(_0e);FKr=r(uQt,"FlaxAutoModelForQuestionAnswering"),uQt.forEach(t),XHe.forEach(t),IQe=i(f),Mr=n(f,"DIV",{class:!0});var ui=s(Mr);T(J$.$$.fragment,ui),TKr=i(ui),pf=n(ui,"P",{});var Nae=s(pf);MKr=r(Nae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ire=n(Nae,"A",{href:!0});var bQt=s(ire);EKr=r(bQt,"from_pretrained()"),bQt.forEach(t),CKr=r(Nae," class method or the "),dre=n(Nae,"A",{href:!0});var vQt=s(dre);wKr=r(vQt,"from_config()"),vQt.forEach(t),AKr=r(Nae,` class
method.`),Nae.forEach(t),LKr=i(ui),Y$=n(ui,"P",{});var zHe=s(Y$);yKr=r(zHe,"This class cannot be instantiated directly using "),u0e=n(zHe,"CODE",{});var FQt=s(u0e);xKr=r(FQt,"__init__()"),FQt.forEach(t),$Kr=r(zHe," (throws an error)."),zHe.forEach(t),kKr=i(ui),Zt=n(ui,"DIV",{class:!0});var eL=s(Zt);T(K$.$$.fragment,eL),SKr=i(eL),b0e=n(eL,"P",{});var TQt=s(b0e);RKr=r(TQt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),TQt.forEach(t),PKr=i(eL),_f=n(eL,"P",{});var qae=s(_f);BKr=r(qae,`Note:
Loading a model from its configuration file does `),v0e=n(qae,"STRONG",{});var MQt=s(v0e);IKr=r(MQt,"not"),MQt.forEach(t),NKr=r(qae,` load the model weights. It only affects the
model\u2019s configuration. Use `),cre=n(qae,"A",{href:!0});var EQt=s(cre);qKr=r(EQt,"from_pretrained()"),EQt.forEach(t),jKr=r(qae," to load the model weights."),qae.forEach(t),DKr=i(eL),T(e0.$$.fragment,eL),eL.forEach(t),GKr=i(ui),Jr=n(ui,"DIV",{class:!0});var bi=s(Jr);T(Z$.$$.fragment,bi),OKr=i(bi),F0e=n(bi,"P",{});var CQt=s(F0e);VKr=r(CQt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),CQt.forEach(t),XKr=i(bi),yn=n(bi,"P",{});var oL=s(yn);zKr=r(oL,"The model class to instantiate is selected based on the "),T0e=n(oL,"CODE",{});var wQt=s(T0e);QKr=r(wQt,"model_type"),wQt.forEach(t),WKr=r(oL,` property of the config object (either
passed as an argument or loaded from `),M0e=n(oL,"CODE",{});var AQt=s(M0e);HKr=r(AQt,"pretrained_model_name_or_path"),AQt.forEach(t),UKr=r(oL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E0e=n(oL,"CODE",{});var LQt=s(E0e);JKr=r(LQt,"pretrained_model_name_or_path"),LQt.forEach(t),YKr=r(oL,":"),oL.forEach(t),KKr=i(bi),Re=n(bi,"UL",{});var Ge=s(Re);o0=n(Ge,"LI",{});var mXe=s(o0);C0e=n(mXe,"STRONG",{});var yQt=s(C0e);ZKr=r(yQt,"albert"),yQt.forEach(t),eZr=r(mXe," \u2014 "),fre=n(mXe,"A",{href:!0});var xQt=s(fre);oZr=r(xQt,"FlaxAlbertForQuestionAnswering"),xQt.forEach(t),rZr=r(mXe," (ALBERT model)"),mXe.forEach(t),tZr=i(Ge),r0=n(Ge,"LI",{});var gXe=s(r0);w0e=n(gXe,"STRONG",{});var $Qt=s(w0e);aZr=r($Qt,"bart"),$Qt.forEach(t),nZr=r(gXe," \u2014 "),mre=n(gXe,"A",{href:!0});var kQt=s(mre);sZr=r(kQt,"FlaxBartForQuestionAnswering"),kQt.forEach(t),lZr=r(gXe," (BART model)"),gXe.forEach(t),iZr=i(Ge),t0=n(Ge,"LI",{});var hXe=s(t0);A0e=n(hXe,"STRONG",{});var SQt=s(A0e);dZr=r(SQt,"bert"),SQt.forEach(t),cZr=r(hXe," \u2014 "),gre=n(hXe,"A",{href:!0});var RQt=s(gre);fZr=r(RQt,"FlaxBertForQuestionAnswering"),RQt.forEach(t),mZr=r(hXe," (BERT model)"),hXe.forEach(t),gZr=i(Ge),a0=n(Ge,"LI",{});var pXe=s(a0);L0e=n(pXe,"STRONG",{});var PQt=s(L0e);hZr=r(PQt,"big_bird"),PQt.forEach(t),pZr=r(pXe," \u2014 "),hre=n(pXe,"A",{href:!0});var BQt=s(hre);_Zr=r(BQt,"FlaxBigBirdForQuestionAnswering"),BQt.forEach(t),uZr=r(pXe," (BigBird model)"),pXe.forEach(t),bZr=i(Ge),n0=n(Ge,"LI",{});var _Xe=s(n0);y0e=n(_Xe,"STRONG",{});var IQt=s(y0e);vZr=r(IQt,"distilbert"),IQt.forEach(t),FZr=r(_Xe," \u2014 "),pre=n(_Xe,"A",{href:!0});var NQt=s(pre);TZr=r(NQt,"FlaxDistilBertForQuestionAnswering"),NQt.forEach(t),MZr=r(_Xe," (DistilBERT model)"),_Xe.forEach(t),EZr=i(Ge),s0=n(Ge,"LI",{});var uXe=s(s0);x0e=n(uXe,"STRONG",{});var qQt=s(x0e);CZr=r(qQt,"electra"),qQt.forEach(t),wZr=r(uXe," \u2014 "),_re=n(uXe,"A",{href:!0});var jQt=s(_re);AZr=r(jQt,"FlaxElectraForQuestionAnswering"),jQt.forEach(t),LZr=r(uXe," (ELECTRA model)"),uXe.forEach(t),yZr=i(Ge),l0=n(Ge,"LI",{});var bXe=s(l0);$0e=n(bXe,"STRONG",{});var DQt=s($0e);xZr=r(DQt,"mbart"),DQt.forEach(t),$Zr=r(bXe," \u2014 "),ure=n(bXe,"A",{href:!0});var GQt=s(ure);kZr=r(GQt,"FlaxMBartForQuestionAnswering"),GQt.forEach(t),SZr=r(bXe," (mBART model)"),bXe.forEach(t),RZr=i(Ge),i0=n(Ge,"LI",{});var vXe=s(i0);k0e=n(vXe,"STRONG",{});var OQt=s(k0e);PZr=r(OQt,"roberta"),OQt.forEach(t),BZr=r(vXe," \u2014 "),bre=n(vXe,"A",{href:!0});var VQt=s(bre);IZr=r(VQt,"FlaxRobertaForQuestionAnswering"),VQt.forEach(t),NZr=r(vXe," (RoBERTa model)"),vXe.forEach(t),qZr=i(Ge),d0=n(Ge,"LI",{});var FXe=s(d0);S0e=n(FXe,"STRONG",{});var XQt=s(S0e);jZr=r(XQt,"roformer"),XQt.forEach(t),DZr=r(FXe," \u2014 "),vre=n(FXe,"A",{href:!0});var zQt=s(vre);GZr=r(zQt,"FlaxRoFormerForQuestionAnswering"),zQt.forEach(t),OZr=r(FXe," (RoFormer model)"),FXe.forEach(t),VZr=i(Ge),c0=n(Ge,"LI",{});var TXe=s(c0);R0e=n(TXe,"STRONG",{});var QQt=s(R0e);XZr=r(QQt,"xlm-roberta"),QQt.forEach(t),zZr=r(TXe," \u2014 "),Fre=n(TXe,"A",{href:!0});var WQt=s(Fre);QZr=r(WQt,"FlaxXLMRobertaForQuestionAnswering"),WQt.forEach(t),WZr=r(TXe," (XLM-RoBERTa model)"),TXe.forEach(t),Ge.forEach(t),HZr=i(bi),T(f0.$$.fragment,bi),bi.forEach(t),ui.forEach(t),NQe=i(f),uf=n(f,"H2",{class:!0});var QHe=s(uf);m0=n(QHe,"A",{id:!0,class:!0,href:!0});var HQt=s(m0);P0e=n(HQt,"SPAN",{});var UQt=s(P0e);T(ek.$$.fragment,UQt),UQt.forEach(t),HQt.forEach(t),UZr=i(QHe),B0e=n(QHe,"SPAN",{});var JQt=s(B0e);JZr=r(JQt,"FlaxAutoModelForTokenClassification"),JQt.forEach(t),QHe.forEach(t),qQe=i(f),Er=n(f,"DIV",{class:!0});var vi=s(Er);T(ok.$$.fragment,vi),YZr=i(vi),bf=n(vi,"P",{});var jae=s(bf);KZr=r(jae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Tre=n(jae,"A",{href:!0});var YQt=s(Tre);ZZr=r(YQt,"from_pretrained()"),YQt.forEach(t),eet=r(jae," class method or the "),Mre=n(jae,"A",{href:!0});var KQt=s(Mre);oet=r(KQt,"from_config()"),KQt.forEach(t),ret=r(jae,` class
method.`),jae.forEach(t),tet=i(vi),rk=n(vi,"P",{});var WHe=s(rk);aet=r(WHe,"This class cannot be instantiated directly using "),I0e=n(WHe,"CODE",{});var ZQt=s(I0e);net=r(ZQt,"__init__()"),ZQt.forEach(t),set=r(WHe," (throws an error)."),WHe.forEach(t),iet=i(vi),ea=n(vi,"DIV",{class:!0});var rL=s(ea);T(tk.$$.fragment,rL),det=i(rL),N0e=n(rL,"P",{});var eWt=s(N0e);cet=r(eWt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),eWt.forEach(t),fet=i(rL),vf=n(rL,"P",{});var Dae=s(vf);met=r(Dae,`Note:
Loading a model from its configuration file does `),q0e=n(Dae,"STRONG",{});var oWt=s(q0e);get=r(oWt,"not"),oWt.forEach(t),het=r(Dae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ere=n(Dae,"A",{href:!0});var rWt=s(Ere);pet=r(rWt,"from_pretrained()"),rWt.forEach(t),_et=r(Dae," to load the model weights."),Dae.forEach(t),uet=i(rL),T(g0.$$.fragment,rL),rL.forEach(t),bet=i(vi),Yr=n(vi,"DIV",{class:!0});var Fi=s(Yr);T(ak.$$.fragment,Fi),vet=i(Fi),j0e=n(Fi,"P",{});var tWt=s(j0e);Fet=r(tWt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),tWt.forEach(t),Tet=i(Fi),xn=n(Fi,"P",{});var tL=s(xn);Met=r(tL,"The model class to instantiate is selected based on the "),D0e=n(tL,"CODE",{});var aWt=s(D0e);Eet=r(aWt,"model_type"),aWt.forEach(t),Cet=r(tL,` property of the config object (either
passed as an argument or loaded from `),G0e=n(tL,"CODE",{});var nWt=s(G0e);wet=r(nWt,"pretrained_model_name_or_path"),nWt.forEach(t),Aet=r(tL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O0e=n(tL,"CODE",{});var sWt=s(O0e);Let=r(sWt,"pretrained_model_name_or_path"),sWt.forEach(t),yet=r(tL,":"),tL.forEach(t),xet=i(Fi),Xe=n(Fi,"UL",{});var Eo=s(Xe);h0=n(Eo,"LI",{});var MXe=s(h0);V0e=n(MXe,"STRONG",{});var lWt=s(V0e);$et=r(lWt,"albert"),lWt.forEach(t),ket=r(MXe," \u2014 "),Cre=n(MXe,"A",{href:!0});var iWt=s(Cre);Set=r(iWt,"FlaxAlbertForTokenClassification"),iWt.forEach(t),Ret=r(MXe," (ALBERT model)"),MXe.forEach(t),Pet=i(Eo),p0=n(Eo,"LI",{});var EXe=s(p0);X0e=n(EXe,"STRONG",{});var dWt=s(X0e);Bet=r(dWt,"bert"),dWt.forEach(t),Iet=r(EXe," \u2014 "),wre=n(EXe,"A",{href:!0});var cWt=s(wre);Net=r(cWt,"FlaxBertForTokenClassification"),cWt.forEach(t),qet=r(EXe," (BERT model)"),EXe.forEach(t),jet=i(Eo),_0=n(Eo,"LI",{});var CXe=s(_0);z0e=n(CXe,"STRONG",{});var fWt=s(z0e);Det=r(fWt,"big_bird"),fWt.forEach(t),Get=r(CXe," \u2014 "),Are=n(CXe,"A",{href:!0});var mWt=s(Are);Oet=r(mWt,"FlaxBigBirdForTokenClassification"),mWt.forEach(t),Vet=r(CXe," (BigBird model)"),CXe.forEach(t),Xet=i(Eo),u0=n(Eo,"LI",{});var wXe=s(u0);Q0e=n(wXe,"STRONG",{});var gWt=s(Q0e);zet=r(gWt,"distilbert"),gWt.forEach(t),Qet=r(wXe," \u2014 "),Lre=n(wXe,"A",{href:!0});var hWt=s(Lre);Wet=r(hWt,"FlaxDistilBertForTokenClassification"),hWt.forEach(t),Het=r(wXe," (DistilBERT model)"),wXe.forEach(t),Uet=i(Eo),b0=n(Eo,"LI",{});var AXe=s(b0);W0e=n(AXe,"STRONG",{});var pWt=s(W0e);Jet=r(pWt,"electra"),pWt.forEach(t),Yet=r(AXe," \u2014 "),yre=n(AXe,"A",{href:!0});var _Wt=s(yre);Ket=r(_Wt,"FlaxElectraForTokenClassification"),_Wt.forEach(t),Zet=r(AXe," (ELECTRA model)"),AXe.forEach(t),eot=i(Eo),v0=n(Eo,"LI",{});var LXe=s(v0);H0e=n(LXe,"STRONG",{});var uWt=s(H0e);oot=r(uWt,"roberta"),uWt.forEach(t),rot=r(LXe," \u2014 "),xre=n(LXe,"A",{href:!0});var bWt=s(xre);tot=r(bWt,"FlaxRobertaForTokenClassification"),bWt.forEach(t),aot=r(LXe," (RoBERTa model)"),LXe.forEach(t),not=i(Eo),F0=n(Eo,"LI",{});var yXe=s(F0);U0e=n(yXe,"STRONG",{});var vWt=s(U0e);sot=r(vWt,"roformer"),vWt.forEach(t),lot=r(yXe," \u2014 "),$re=n(yXe,"A",{href:!0});var FWt=s($re);iot=r(FWt,"FlaxRoFormerForTokenClassification"),FWt.forEach(t),dot=r(yXe," (RoFormer model)"),yXe.forEach(t),cot=i(Eo),T0=n(Eo,"LI",{});var xXe=s(T0);J0e=n(xXe,"STRONG",{});var TWt=s(J0e);fot=r(TWt,"xlm-roberta"),TWt.forEach(t),mot=r(xXe," \u2014 "),kre=n(xXe,"A",{href:!0});var MWt=s(kre);got=r(MWt,"FlaxXLMRobertaForTokenClassification"),MWt.forEach(t),hot=r(xXe," (XLM-RoBERTa model)"),xXe.forEach(t),Eo.forEach(t),pot=i(Fi),T(M0.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),jQe=i(f),Ff=n(f,"H2",{class:!0});var HHe=s(Ff);E0=n(HHe,"A",{id:!0,class:!0,href:!0});var EWt=s(E0);Y0e=n(EWt,"SPAN",{});var CWt=s(Y0e);T(nk.$$.fragment,CWt),CWt.forEach(t),EWt.forEach(t),_ot=i(HHe),K0e=n(HHe,"SPAN",{});var wWt=s(K0e);uot=r(wWt,"FlaxAutoModelForMultipleChoice"),wWt.forEach(t),HHe.forEach(t),DQe=i(f),Cr=n(f,"DIV",{class:!0});var Ti=s(Cr);T(sk.$$.fragment,Ti),bot=i(Ti),Tf=n(Ti,"P",{});var Gae=s(Tf);vot=r(Gae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Sre=n(Gae,"A",{href:!0});var AWt=s(Sre);Fot=r(AWt,"from_pretrained()"),AWt.forEach(t),Tot=r(Gae," class method or the "),Rre=n(Gae,"A",{href:!0});var LWt=s(Rre);Mot=r(LWt,"from_config()"),LWt.forEach(t),Eot=r(Gae,` class
method.`),Gae.forEach(t),Cot=i(Ti),lk=n(Ti,"P",{});var UHe=s(lk);wot=r(UHe,"This class cannot be instantiated directly using "),Z0e=n(UHe,"CODE",{});var yWt=s(Z0e);Aot=r(yWt,"__init__()"),yWt.forEach(t),Lot=r(UHe," (throws an error)."),UHe.forEach(t),yot=i(Ti),oa=n(Ti,"DIV",{class:!0});var aL=s(oa);T(ik.$$.fragment,aL),xot=i(aL),ewe=n(aL,"P",{});var xWt=s(ewe);$ot=r(xWt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),xWt.forEach(t),kot=i(aL),Mf=n(aL,"P",{});var Oae=s(Mf);Sot=r(Oae,`Note:
Loading a model from its configuration file does `),owe=n(Oae,"STRONG",{});var $Wt=s(owe);Rot=r($Wt,"not"),$Wt.forEach(t),Pot=r(Oae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pre=n(Oae,"A",{href:!0});var kWt=s(Pre);Bot=r(kWt,"from_pretrained()"),kWt.forEach(t),Iot=r(Oae," to load the model weights."),Oae.forEach(t),Not=i(aL),T(C0.$$.fragment,aL),aL.forEach(t),qot=i(Ti),Kr=n(Ti,"DIV",{class:!0});var Mi=s(Kr);T(dk.$$.fragment,Mi),jot=i(Mi),rwe=n(Mi,"P",{});var SWt=s(rwe);Dot=r(SWt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),SWt.forEach(t),Got=i(Mi),$n=n(Mi,"P",{});var nL=s($n);Oot=r(nL,"The model class to instantiate is selected based on the "),twe=n(nL,"CODE",{});var RWt=s(twe);Vot=r(RWt,"model_type"),RWt.forEach(t),Xot=r(nL,` property of the config object (either
passed as an argument or loaded from `),awe=n(nL,"CODE",{});var PWt=s(awe);zot=r(PWt,"pretrained_model_name_or_path"),PWt.forEach(t),Qot=r(nL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nwe=n(nL,"CODE",{});var BWt=s(nwe);Wot=r(BWt,"pretrained_model_name_or_path"),BWt.forEach(t),Hot=r(nL,":"),nL.forEach(t),Uot=i(Mi),ze=n(Mi,"UL",{});var Co=s(ze);w0=n(Co,"LI",{});var $Xe=s(w0);swe=n($Xe,"STRONG",{});var IWt=s(swe);Jot=r(IWt,"albert"),IWt.forEach(t),Yot=r($Xe," \u2014 "),Bre=n($Xe,"A",{href:!0});var NWt=s(Bre);Kot=r(NWt,"FlaxAlbertForMultipleChoice"),NWt.forEach(t),Zot=r($Xe," (ALBERT model)"),$Xe.forEach(t),ert=i(Co),A0=n(Co,"LI",{});var kXe=s(A0);lwe=n(kXe,"STRONG",{});var qWt=s(lwe);ort=r(qWt,"bert"),qWt.forEach(t),rrt=r(kXe," \u2014 "),Ire=n(kXe,"A",{href:!0});var jWt=s(Ire);trt=r(jWt,"FlaxBertForMultipleChoice"),jWt.forEach(t),art=r(kXe," (BERT model)"),kXe.forEach(t),nrt=i(Co),L0=n(Co,"LI",{});var SXe=s(L0);iwe=n(SXe,"STRONG",{});var DWt=s(iwe);srt=r(DWt,"big_bird"),DWt.forEach(t),lrt=r(SXe," \u2014 "),Nre=n(SXe,"A",{href:!0});var GWt=s(Nre);irt=r(GWt,"FlaxBigBirdForMultipleChoice"),GWt.forEach(t),drt=r(SXe," (BigBird model)"),SXe.forEach(t),crt=i(Co),y0=n(Co,"LI",{});var RXe=s(y0);dwe=n(RXe,"STRONG",{});var OWt=s(dwe);frt=r(OWt,"distilbert"),OWt.forEach(t),mrt=r(RXe," \u2014 "),qre=n(RXe,"A",{href:!0});var VWt=s(qre);grt=r(VWt,"FlaxDistilBertForMultipleChoice"),VWt.forEach(t),hrt=r(RXe," (DistilBERT model)"),RXe.forEach(t),prt=i(Co),x0=n(Co,"LI",{});var PXe=s(x0);cwe=n(PXe,"STRONG",{});var XWt=s(cwe);_rt=r(XWt,"electra"),XWt.forEach(t),urt=r(PXe," \u2014 "),jre=n(PXe,"A",{href:!0});var zWt=s(jre);brt=r(zWt,"FlaxElectraForMultipleChoice"),zWt.forEach(t),vrt=r(PXe," (ELECTRA model)"),PXe.forEach(t),Frt=i(Co),$0=n(Co,"LI",{});var BXe=s($0);fwe=n(BXe,"STRONG",{});var QWt=s(fwe);Trt=r(QWt,"roberta"),QWt.forEach(t),Mrt=r(BXe," \u2014 "),Dre=n(BXe,"A",{href:!0});var WWt=s(Dre);Ert=r(WWt,"FlaxRobertaForMultipleChoice"),WWt.forEach(t),Crt=r(BXe," (RoBERTa model)"),BXe.forEach(t),wrt=i(Co),k0=n(Co,"LI",{});var IXe=s(k0);mwe=n(IXe,"STRONG",{});var HWt=s(mwe);Art=r(HWt,"roformer"),HWt.forEach(t),Lrt=r(IXe," \u2014 "),Gre=n(IXe,"A",{href:!0});var UWt=s(Gre);yrt=r(UWt,"FlaxRoFormerForMultipleChoice"),UWt.forEach(t),xrt=r(IXe," (RoFormer model)"),IXe.forEach(t),$rt=i(Co),S0=n(Co,"LI",{});var NXe=s(S0);gwe=n(NXe,"STRONG",{});var JWt=s(gwe);krt=r(JWt,"xlm-roberta"),JWt.forEach(t),Srt=r(NXe," \u2014 "),Ore=n(NXe,"A",{href:!0});var YWt=s(Ore);Rrt=r(YWt,"FlaxXLMRobertaForMultipleChoice"),YWt.forEach(t),Prt=r(NXe," (XLM-RoBERTa model)"),NXe.forEach(t),Co.forEach(t),Brt=i(Mi),T(R0.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),GQe=i(f),Ef=n(f,"H2",{class:!0});var JHe=s(Ef);P0=n(JHe,"A",{id:!0,class:!0,href:!0});var KWt=s(P0);hwe=n(KWt,"SPAN",{});var ZWt=s(hwe);T(ck.$$.fragment,ZWt),ZWt.forEach(t),KWt.forEach(t),Irt=i(JHe),pwe=n(JHe,"SPAN",{});var eHt=s(pwe);Nrt=r(eHt,"FlaxAutoModelForNextSentencePrediction"),eHt.forEach(t),JHe.forEach(t),OQe=i(f),wr=n(f,"DIV",{class:!0});var Ei=s(wr);T(fk.$$.fragment,Ei),qrt=i(Ei),Cf=n(Ei,"P",{});var Vae=s(Cf);jrt=r(Vae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Vre=n(Vae,"A",{href:!0});var oHt=s(Vre);Drt=r(oHt,"from_pretrained()"),oHt.forEach(t),Grt=r(Vae," class method or the "),Xre=n(Vae,"A",{href:!0});var rHt=s(Xre);Ort=r(rHt,"from_config()"),rHt.forEach(t),Vrt=r(Vae,` class
method.`),Vae.forEach(t),Xrt=i(Ei),mk=n(Ei,"P",{});var YHe=s(mk);zrt=r(YHe,"This class cannot be instantiated directly using "),_we=n(YHe,"CODE",{});var tHt=s(_we);Qrt=r(tHt,"__init__()"),tHt.forEach(t),Wrt=r(YHe," (throws an error)."),YHe.forEach(t),Hrt=i(Ei),ra=n(Ei,"DIV",{class:!0});var sL=s(ra);T(gk.$$.fragment,sL),Urt=i(sL),uwe=n(sL,"P",{});var aHt=s(uwe);Jrt=r(aHt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),aHt.forEach(t),Yrt=i(sL),wf=n(sL,"P",{});var Xae=s(wf);Krt=r(Xae,`Note:
Loading a model from its configuration file does `),bwe=n(Xae,"STRONG",{});var nHt=s(bwe);Zrt=r(nHt,"not"),nHt.forEach(t),ett=r(Xae,` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=n(Xae,"A",{href:!0});var sHt=s(zre);ott=r(sHt,"from_pretrained()"),sHt.forEach(t),rtt=r(Xae," to load the model weights."),Xae.forEach(t),ttt=i(sL),T(B0.$$.fragment,sL),sL.forEach(t),att=i(Ei),Zr=n(Ei,"DIV",{class:!0});var Ci=s(Zr);T(hk.$$.fragment,Ci),ntt=i(Ci),vwe=n(Ci,"P",{});var lHt=s(vwe);stt=r(lHt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),lHt.forEach(t),ltt=i(Ci),kn=n(Ci,"P",{});var lL=s(kn);itt=r(lL,"The model class to instantiate is selected based on the "),Fwe=n(lL,"CODE",{});var iHt=s(Fwe);dtt=r(iHt,"model_type"),iHt.forEach(t),ctt=r(lL,` property of the config object (either
passed as an argument or loaded from `),Twe=n(lL,"CODE",{});var dHt=s(Twe);ftt=r(dHt,"pretrained_model_name_or_path"),dHt.forEach(t),mtt=r(lL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mwe=n(lL,"CODE",{});var cHt=s(Mwe);gtt=r(cHt,"pretrained_model_name_or_path"),cHt.forEach(t),htt=r(lL,":"),lL.forEach(t),ptt=i(Ci),Ewe=n(Ci,"UL",{});var fHt=s(Ewe);I0=n(fHt,"LI",{});var qXe=s(I0);Cwe=n(qXe,"STRONG",{});var mHt=s(Cwe);_tt=r(mHt,"bert"),mHt.forEach(t),utt=r(qXe," \u2014 "),Qre=n(qXe,"A",{href:!0});var gHt=s(Qre);btt=r(gHt,"FlaxBertForNextSentencePrediction"),gHt.forEach(t),vtt=r(qXe," (BERT model)"),qXe.forEach(t),fHt.forEach(t),Ftt=i(Ci),T(N0.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),VQe=i(f),Af=n(f,"H2",{class:!0});var KHe=s(Af);q0=n(KHe,"A",{id:!0,class:!0,href:!0});var hHt=s(q0);wwe=n(hHt,"SPAN",{});var pHt=s(wwe);T(pk.$$.fragment,pHt),pHt.forEach(t),hHt.forEach(t),Ttt=i(KHe),Awe=n(KHe,"SPAN",{});var _Ht=s(Awe);Mtt=r(_Ht,"FlaxAutoModelForImageClassification"),_Ht.forEach(t),KHe.forEach(t),XQe=i(f),Ar=n(f,"DIV",{class:!0});var wi=s(Ar);T(_k.$$.fragment,wi),Ett=i(wi),Lf=n(wi,"P",{});var zae=s(Lf);Ctt=r(zae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Wre=n(zae,"A",{href:!0});var uHt=s(Wre);wtt=r(uHt,"from_pretrained()"),uHt.forEach(t),Att=r(zae," class method or the "),Hre=n(zae,"A",{href:!0});var bHt=s(Hre);Ltt=r(bHt,"from_config()"),bHt.forEach(t),ytt=r(zae,` class
method.`),zae.forEach(t),xtt=i(wi),uk=n(wi,"P",{});var ZHe=s(uk);$tt=r(ZHe,"This class cannot be instantiated directly using "),Lwe=n(ZHe,"CODE",{});var vHt=s(Lwe);ktt=r(vHt,"__init__()"),vHt.forEach(t),Stt=r(ZHe," (throws an error)."),ZHe.forEach(t),Rtt=i(wi),ta=n(wi,"DIV",{class:!0});var iL=s(ta);T(bk.$$.fragment,iL),Ptt=i(iL),ywe=n(iL,"P",{});var FHt=s(ywe);Btt=r(FHt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),FHt.forEach(t),Itt=i(iL),yf=n(iL,"P",{});var Qae=s(yf);Ntt=r(Qae,`Note:
Loading a model from its configuration file does `),xwe=n(Qae,"STRONG",{});var THt=s(xwe);qtt=r(THt,"not"),THt.forEach(t),jtt=r(Qae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ure=n(Qae,"A",{href:!0});var MHt=s(Ure);Dtt=r(MHt,"from_pretrained()"),MHt.forEach(t),Gtt=r(Qae," to load the model weights."),Qae.forEach(t),Ott=i(iL),T(j0.$$.fragment,iL),iL.forEach(t),Vtt=i(wi),et=n(wi,"DIV",{class:!0});var Ai=s(et);T(vk.$$.fragment,Ai),Xtt=i(Ai),$we=n(Ai,"P",{});var EHt=s($we);ztt=r(EHt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),EHt.forEach(t),Qtt=i(Ai),Sn=n(Ai,"P",{});var dL=s(Sn);Wtt=r(dL,"The model class to instantiate is selected based on the "),kwe=n(dL,"CODE",{});var CHt=s(kwe);Htt=r(CHt,"model_type"),CHt.forEach(t),Utt=r(dL,` property of the config object (either
passed as an argument or loaded from `),Swe=n(dL,"CODE",{});var wHt=s(Swe);Jtt=r(wHt,"pretrained_model_name_or_path"),wHt.forEach(t),Ytt=r(dL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=n(dL,"CODE",{});var AHt=s(Rwe);Ktt=r(AHt,"pretrained_model_name_or_path"),AHt.forEach(t),Ztt=r(dL,":"),dL.forEach(t),eat=i(Ai),Fk=n(Ai,"UL",{});var eUe=s(Fk);D0=n(eUe,"LI",{});var jXe=s(D0);Pwe=n(jXe,"STRONG",{});var LHt=s(Pwe);oat=r(LHt,"beit"),LHt.forEach(t),rat=r(jXe," \u2014 "),Jre=n(jXe,"A",{href:!0});var yHt=s(Jre);tat=r(yHt,"FlaxBeitForImageClassification"),yHt.forEach(t),aat=r(jXe," (BEiT model)"),jXe.forEach(t),nat=i(eUe),G0=n(eUe,"LI",{});var DXe=s(G0);Bwe=n(DXe,"STRONG",{});var xHt=s(Bwe);sat=r(xHt,"vit"),xHt.forEach(t),lat=r(DXe," \u2014 "),Yre=n(DXe,"A",{href:!0});var $Ht=s(Yre);iat=r($Ht,"FlaxViTForImageClassification"),$Ht.forEach(t),dat=r(DXe," (ViT model)"),DXe.forEach(t),eUe.forEach(t),cat=i(Ai),T(O0.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),zQe=i(f),xf=n(f,"H2",{class:!0});var oUe=s(xf);V0=n(oUe,"A",{id:!0,class:!0,href:!0});var kHt=s(V0);Iwe=n(kHt,"SPAN",{});var SHt=s(Iwe);T(Tk.$$.fragment,SHt),SHt.forEach(t),kHt.forEach(t),fat=i(oUe),Nwe=n(oUe,"SPAN",{});var RHt=s(Nwe);mat=r(RHt,"FlaxAutoModelForVision2Seq"),RHt.forEach(t),oUe.forEach(t),QQe=i(f),Lr=n(f,"DIV",{class:!0});var Li=s(Lr);T(Mk.$$.fragment,Li),gat=i(Li),$f=n(Li,"P",{});var Wae=s($f);hat=r(Wae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kre=n(Wae,"A",{href:!0});var PHt=s(Kre);pat=r(PHt,"from_pretrained()"),PHt.forEach(t),_at=r(Wae," class method or the "),Zre=n(Wae,"A",{href:!0});var BHt=s(Zre);uat=r(BHt,"from_config()"),BHt.forEach(t),bat=r(Wae,` class
method.`),Wae.forEach(t),vat=i(Li),Ek=n(Li,"P",{});var rUe=s(Ek);Fat=r(rUe,"This class cannot be instantiated directly using "),qwe=n(rUe,"CODE",{});var IHt=s(qwe);Tat=r(IHt,"__init__()"),IHt.forEach(t),Mat=r(rUe," (throws an error)."),rUe.forEach(t),Eat=i(Li),aa=n(Li,"DIV",{class:!0});var cL=s(aa);T(Ck.$$.fragment,cL),Cat=i(cL),jwe=n(cL,"P",{});var NHt=s(jwe);wat=r(NHt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),NHt.forEach(t),Aat=i(cL),kf=n(cL,"P",{});var Hae=s(kf);Lat=r(Hae,`Note:
Loading a model from its configuration file does `),Dwe=n(Hae,"STRONG",{});var qHt=s(Dwe);yat=r(qHt,"not"),qHt.forEach(t),xat=r(Hae,` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=n(Hae,"A",{href:!0});var jHt=s(ete);$at=r(jHt,"from_pretrained()"),jHt.forEach(t),kat=r(Hae," to load the model weights."),Hae.forEach(t),Sat=i(cL),T(X0.$$.fragment,cL),cL.forEach(t),Rat=i(Li),ot=n(Li,"DIV",{class:!0});var yi=s(ot);T(wk.$$.fragment,yi),Pat=i(yi),Gwe=n(yi,"P",{});var DHt=s(Gwe);Bat=r(DHt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),DHt.forEach(t),Iat=i(yi),Rn=n(yi,"P",{});var fL=s(Rn);Nat=r(fL,"The model class to instantiate is selected based on the "),Owe=n(fL,"CODE",{});var GHt=s(Owe);qat=r(GHt,"model_type"),GHt.forEach(t),jat=r(fL,` property of the config object (either
passed as an argument or loaded from `),Vwe=n(fL,"CODE",{});var OHt=s(Vwe);Dat=r(OHt,"pretrained_model_name_or_path"),OHt.forEach(t),Gat=r(fL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xwe=n(fL,"CODE",{});var VHt=s(Xwe);Oat=r(VHt,"pretrained_model_name_or_path"),VHt.forEach(t),Vat=r(fL,":"),fL.forEach(t),Xat=i(yi),zwe=n(yi,"UL",{});var XHt=s(zwe);z0=n(XHt,"LI",{});var GXe=s(z0);Qwe=n(GXe,"STRONG",{});var zHt=s(Qwe);zat=r(zHt,"vision-encoder-decoder"),zHt.forEach(t),Qat=r(GXe," \u2014 "),ote=n(GXe,"A",{href:!0});var QHt=s(ote);Wat=r(QHt,"FlaxVisionEncoderDecoderModel"),QHt.forEach(t),Hat=r(GXe," (Vision Encoder decoder model)"),GXe.forEach(t),XHt.forEach(t),Uat=i(yi),T(Q0.$$.fragment,yi),yi.forEach(t),Li.forEach(t),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(KJt)),d(m,"id","auto-classes"),d(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(m,"href","#auto-classes"),d(p,"class","relative group"),d(Bn,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.AutoConfig"),d(Nn,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.AutoModel"),d(qn,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.AutoTokenizer"),d(Bi,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertModel"),d(jf,"id","extending-the-auto-classes"),d(jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(jf,"href","#extending-the-auto-classes"),d(Ii,"class","relative group"),d(Gf,"id","transformers.AutoConfig"),d(Gf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Gf,"href","#transformers.AutoConfig"),d(Ni,"class","relative group"),d(eR,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(oR,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertConfig"),d(rR,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartConfig"),d(tR,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitConfig"),d(aR,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertConfig"),d(nR,"href","/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(sR,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdConfig"),d(lR,"href","/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(iR,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(dR,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(cR,"href","/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomConfig"),d(fR,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertConfig"),d(mR,"href","/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineConfig"),d(gR,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPConfig"),d(hR,"href","/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenConfig"),d(pR,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertConfig"),d(_R,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextConfig"),d(uR,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLConfig"),d(bR,"href","/docs/transformers/pr_17469/en/model_doc/cvt#transformers.CvtConfig"),d(vR,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(FR,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(TR,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(MR,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaConfig"),d(ER,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(CR,"href","/docs/transformers/pr_17469/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(wR,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTConfig"),d(AR,"href","/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrConfig"),d(LR,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertConfig"),d(yR,"href","/docs/transformers/pr_17469/en/model_doc/dpr#transformers.DPRConfig"),d(xR,"href","/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTConfig"),d($R,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraConfig"),d(kR,"href","/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(SR,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertConfig"),d(RR,"href","/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaConfig"),d(PR,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetConfig"),d(BR,"href","/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTConfig"),d(IR,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelConfig"),d(NR,"href","/docs/transformers/pr_17469/en/model_doc/glpn#transformers.GLPNConfig"),d(qR,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Config"),d(jR,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(DR,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),d(GR,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJConfig"),d(OR,"href","/docs/transformers/pr_17469/en/model_doc/groupvit#transformers.GroupViTConfig"),d(VR,"href","/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertConfig"),d(XR,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertConfig"),d(zR,"href","/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(QR,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(WR,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(HR,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),d(UR,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDConfig"),d(JR,"href","/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitConfig"),d(YR,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerConfig"),d(KR,"href","/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Config"),d(ZR,"href","/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeConfig"),d(eP,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertConfig"),d(oP,"href","/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100Config"),d(rP,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianConfig"),d(tP,"href","/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(aP,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartConfig"),d(nP,"href","/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTConfig"),d(sP,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(lP,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(iP,"href","/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTConfig"),d(dP,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetConfig"),d(cP,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Config"),d(fP,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpConfig"),d(mP,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaConfig"),d(gP,"href","/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(hP,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(pP,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTConfig"),d(_P,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusConfig"),d(uP,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverConfig"),d(bP,"href","/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartConfig"),d(vP,"href","/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(FP,"href","/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(TP,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(MP,"href","/docs/transformers/pr_17469/en/model_doc/rag#transformers.RagConfig"),d(EP,"href","/docs/transformers/pr_17469/en/model_doc/realm#transformers.RealmConfig"),d(CP,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerConfig"),d(wP,"href","/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetConfig"),d(AP,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertConfig"),d(LP,"href","/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetConfig"),d(yP,"href","/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertConfig"),d(xP,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaConfig"),d($P,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerConfig"),d(kP,"href","/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerConfig"),d(SP,"href","/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWConfig"),d(RP,"href","/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDConfig"),d(PP,"href","/docs/transformers/pr_17469/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(BP,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(IP,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(NP,"href","/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterConfig"),d(qP,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(jP,"href","/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinConfig"),d(DP,"href","/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2Config"),d(GP,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Config"),d(OP,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasConfig"),d(VP,"href","/docs/transformers/pr_17469/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),d(XP,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(zP,"href","/docs/transformers/pr_17469/en/model_doc/trocr#transformers.TrOCRConfig"),d(QP,"href","/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(WP,"href","/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(HP,"href","/docs/transformers/pr_17469/en/model_doc/van#transformers.VanConfig"),d(UP,"href","/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltConfig"),d(JP,"href","/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(YP,"href","/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(KP,"href","/docs/transformers/pr_17469/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(ZP,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTConfig"),d(eB,"href","/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(oB,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(rB,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),d(tB,"href","/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMConfig"),d(aB,"href","/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMConfig"),d(nB,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMConfig"),d(sB,"href","/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(lB,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(iB,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(dB,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetConfig"),d(cB,"href","/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosConfig"),d(fB,"href","/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoConfig"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oh,"id","transformers.AutoTokenizer"),d(oh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(oh,"href","#transformers.AutoTokenizer"),d(ji,"class","relative group"),d(mB,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(gB,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertTokenizer"),d(hB,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(pB,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartTokenizer"),d(_B,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartTokenizerFast"),d(uB,"href","/docs/transformers/pr_17469/en/model_doc/barthez#transformers.BarthezTokenizer"),d(bB,"href","/docs/transformers/pr_17469/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(vB,"href","/docs/transformers/pr_17469/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(FB,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizer"),d(TB,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizerFast"),d(MB,"href","/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(EB,"href","/docs/transformers/pr_17469/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(CB,"href","/docs/transformers/pr_17469/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(wB,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(AB,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(LB,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(yB,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(xB,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d($B,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(kB,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(SB,"href","/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomTokenizerFast"),d(RB,"href","/docs/transformers/pr_17469/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(PB,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertTokenizer"),d(BB,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(IB,"href","/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineTokenizer"),d(NB,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPTokenizer"),d(qB,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(jB,"href","/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenTokenizer"),d(DB,"href","/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),d(GB,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(OB,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(VB,"href","/docs/transformers/pr_17469/en/model_doc/cpm#transformers.CpmTokenizer"),d(XB,"href","/docs/transformers/pr_17469/en/model_doc/cpm#transformers.CpmTokenizerFast"),d(zB,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(QB,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizer"),d(WB,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(HB,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaTokenizer"),d(UB,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(JB,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(YB,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(KB,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(ZB,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(eI,"href","/docs/transformers/pr_17469/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(oI,"href","/docs/transformers/pr_17469/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(rI,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraTokenizer"),d(tI,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(aI,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(nI,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetTokenizer"),d(sI,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(lI,"href","/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(iI,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelTokenizer"),d(dI,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(cI,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(fI,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(mI,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(gI,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(hI,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),d(pI,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(_I,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(uI,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPTokenizer"),d(bI,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(vI,"href","/docs/transformers/pr_17469/en/model_doc/herbert#transformers.HerbertTokenizer"),d(FI,"href","/docs/transformers/pr_17469/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(TI,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(MI,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizer"),d(EI,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(CI,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(wI,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(AI,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(LI,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(yI,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(xI,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d($I,"href","/docs/transformers/pr_17469/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(kI,"href","/docs/transformers/pr_17469/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(SI,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDTokenizer"),d(RI,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDTokenizerFast"),d(PI,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerTokenizer"),d(BI,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(II,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.T5Tokenizer"),d(NI,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.T5TokenizerFast"),d(qI,"href","/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeTokenizer"),d(jI,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(DI,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(GI,"href","/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(OI,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianTokenizer"),d(VI,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartTokenizer"),d(XI,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(zI,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(QI,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(WI,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizer"),d(HI,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizerFast"),d(UI,"href","/docs/transformers/pr_17469/en/model_doc/mluke#transformers.MLukeTokenizer"),d(JI,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(YI,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(KI,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(ZI,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(eN,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.T5Tokenizer"),d(oN,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.T5TokenizerFast"),d(rN,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpTokenizer"),d(tN,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpTokenizerFast"),d(aN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizer"),d(nN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizerFast"),d(sN,"href","/docs/transformers/pr_17469/en/model_doc/nllb#transformers.NllbTokenizer"),d(lN,"href","/docs/transformers/pr_17469/en/model_doc/nllb#transformers.NllbTokenizerFast"),d(iN,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertTokenizer"),d(dN,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(cN,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(fN,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(mN,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(gN,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(hN,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(pN,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(_N,"href","/docs/transformers/pr_17469/en/model_doc/phobert#transformers.PhobertTokenizer"),d(uN,"href","/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartTokenizer"),d(bN,"href","/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(vN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizer"),d(FN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizerFast"),d(TN,"href","/docs/transformers/pr_17469/en/model_doc/rag#transformers.RagTokenizer"),d(MN,"href","/docs/transformers/pr_17469/en/model_doc/realm#transformers.RealmTokenizer"),d(EN,"href","/docs/transformers/pr_17469/en/model_doc/realm#transformers.RealmTokenizerFast"),d(CN,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerTokenizer"),d(wN,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(AN,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertTokenizer"),d(LN,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(yN,"href","/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(xN,"href","/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d($N,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizer"),d(kN,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(SN,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(RN,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(PN,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(BN,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(IN,"href","/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterTokenizer"),d(NN,"href","/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(qN,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(jN,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(DN,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.T5Tokenizer"),d(GN,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.T5TokenizerFast"),d(ON,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasTokenizer"),d(VN,"href","/docs/transformers/pr_17469/en/model_doc/tapex#transformers.TapexTokenizer"),d(XN,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(zN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizer"),d(QN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizerFast"),d(WN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizer"),d(HN,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertTokenizerFast"),d(UN,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(JN,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(YN,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(KN,"href","/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMTokenizer"),d(ZN,"href","/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(eq,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMTokenizer"),d(oq,"href","/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(rq,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(tq,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(aq,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizer"),d(nq,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(sq,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(lq,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(iq,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertTokenizer"),d(dq,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ih,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nh,"id","transformers.AutoFeatureExtractor"),d(Nh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Nh,"href","#transformers.AutoFeatureExtractor"),d(Di,"class","relative group"),d(cq,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(fq,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(mq,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(gq,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(hq,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(pq,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(_q,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(uq,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTFeatureExtractor"),d(bq,"href","/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(vq,"href","/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTFeatureExtractor"),d(Fq,"href","/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaFeatureExtractor"),d(Tq,"href","/docs/transformers/pr_17469/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),d(Mq,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(Eq,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(Cq,"href","/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),d(wq,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),d(Aq,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),d(Lq,"href","/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitFeatureExtractor"),d(yq,"href","/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(xq,"href","/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),d($q,"href","/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),d(kq,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),d(Sq,"href","/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),d(Rq,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(Pq,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(Bq,"href","/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),d(Iq,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(Nq,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(qq,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(jq,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(Dq,"href","/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltFeatureExtractor"),d(Gq,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(Oq,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(Vq,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(Xq,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(zq,"href","/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosFeatureExtractor"),d(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mp,"id","transformers.AutoProcessor"),d(Mp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Mp,"href","#transformers.AutoProcessor"),d(Gi,"class","relative group"),d(Qq,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(Wq,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPProcessor"),d(Hq,"href","/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaProcessor"),d(Uq,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPProcessor"),d(Jq,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(Yq,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),d(Kq,"href","/docs/transformers/pr_17469/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(Zq,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(ej,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(oj,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(rj,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(tj,"href","/docs/transformers/pr_17469/en/model_doc/trocr#transformers.TrOCRProcessor"),d(aj,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(nj,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(sj,"href","/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltProcessor"),d(lj,"href","/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(ij,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(dj,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(cj,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xp,"id","transformers.AutoModel"),d(Xp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Xp,"href","#transformers.AutoModel"),d(Vi,"class","relative group"),d(fj,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mj,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gj,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hj,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertModel"),d(pj,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartModel"),d(_j,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitModel"),d(uj,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertModel"),d(bj,"href","/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(vj,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdModel"),d(Fj,"href","/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(Tj,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(Mj,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(Ej,"href","/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomModel"),d(Cj,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertModel"),d(wj,"href","/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineModel"),d(Aj,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.CLIPModel"),d(Lj,"href","/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenModel"),d(yj,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertModel"),d(xj,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextModel"),d($j,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLModel"),d(kj,"href","/docs/transformers/pr_17469/en/model_doc/cvt#transformers.CvtModel"),d(Sj,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(Rj,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(Pj,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d(Bj,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaModel"),d(Ij,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(Nj,"href","/docs/transformers/pr_17469/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(qj,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTModel"),d(jj,"href","/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrModel"),d(Dj,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertModel"),d(Gj,"href","/docs/transformers/pr_17469/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(Oj,"href","/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTModel"),d(Vj,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraModel"),d(Xj,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertModel"),d(zj,"href","/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaModel"),d(Qj,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetModel"),d(Wj,"href","/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTModel"),d(Hj,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelModel"),d(Uj,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelBaseModel"),d(Jj,"href","/docs/transformers/pr_17469/en/model_doc/glpn#transformers.GLPNModel"),d(Yj,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2Model"),d(Kj,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(Zj,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),d(eD,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJModel"),d(oD,"href","/docs/transformers/pr_17469/en/model_doc/groupvit#transformers.GroupViTModel"),d(rD,"href","/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertModel"),d(tD,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertModel"),d(aD,"href","/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(nD,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(sD,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(lD,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),d(iD,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDModel"),d(dD,"href","/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitModel"),d(cD,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerModel"),d(fD,"href","/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5Model"),d(mD,"href","/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeModel"),d(gD,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertModel"),d(hD,"href","/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100Model"),d(pD,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianModel"),d(_D,"href","/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerModel"),d(uD,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartModel"),d(bD,"href","/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTModel"),d(vD,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(FD,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertModel"),d(TD,"href","/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTModel"),d(MD,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetModel"),d(ED,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5Model"),d(CD,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpModel"),d(wD,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaModel"),d(AD,"href","/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100Model"),d(LD,"href","/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerModel"),d(yD,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(xD,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTModel"),d($D,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusModel"),d(kD,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverModel"),d(SD,"href","/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartModel"),d(RD,"href","/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerModel"),d(PD,"href","/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(BD,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertModel"),d(ID,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerModel"),d(ND,"href","/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetModel"),d(qD,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertModel"),d(jD,"href","/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetModel"),d(DD,"href","/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertModel"),d(GD,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaModel"),d(OD,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerModel"),d(VD,"href","/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerModel"),d(XD,"href","/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWModel"),d(zD,"href","/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDModel"),d(QD,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(WD,"href","/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterModel"),d(HD,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(UD,"href","/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinModel"),d(JD,"href","/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2Model"),d(YD,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5Model"),d(KD,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasModel"),d(ZD,"href","/docs/transformers/pr_17469/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),d(eG,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(oG,"href","/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechModel"),d(rG,"href","/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(tG,"href","/docs/transformers/pr_17469/en/model_doc/van#transformers.VanModel"),d(aG,"href","/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltModel"),d(nG,"href","/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(sG,"href","/docs/transformers/pr_17469/en/model_doc/visual_bert#transformers.VisualBertModel"),d(lG,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTModel"),d(iG,"href","/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(dG,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(cG,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),d(fG,"href","/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMModel"),d(mG,"href","/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMModel"),d(gG,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMModel"),d(hG,"href","/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(pG,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(_G,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(uG,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetModel"),d(bG,"href","/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosModel"),d(vG,"href","/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoModel"),d(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ku,"id","transformers.AutoModelForPreTraining"),d(Ku,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ku,"href","#transformers.AutoModelForPreTraining"),d(Qi,"class","relative group"),d(FG,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(TG,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(MG,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(EG,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForPreTraining"),d(CG,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(wG,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForPreTraining"),d(AG,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(LG,"href","/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForCausalLM"),d(yG,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(xG,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d($G,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(kG,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(SG,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(RG,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(PG,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForPreTraining"),d(BG,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(IG,"href","/docs/transformers/pr_17469/en/model_doc/flava#transformers.FlavaForPreTraining"),d(NG,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForPreTraining"),d(qG,"href","/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(jG,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(DG,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(GG,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(OG,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(VG,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(XG,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(zG,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(QG,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(WG,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(HG,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(UG,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForPreTraining"),d(JG,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(YG,"href","/docs/transformers/pr_17469/en/model_doc/retribert#transformers.RetriBertModel"),d(KG,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(ZG,"href","/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterForPreTraining"),d(eO,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(oO,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(rO,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(tO,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(aO,"href","/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(nO,"href","/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(sO,"href","/docs/transformers/pr_17469/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(lO,"href","/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(iO,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(dO,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),d(cO,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(fO,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(mO,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(gO,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(W1,"id","transformers.AutoModelForCausalLM"),d(W1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W1,"href","#transformers.AutoModelForCausalLM"),d(Ui,"class","relative group"),d(hO,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pO,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_O,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uO,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForCausalLM"),d(bO,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertLMHeadModel"),d(vO,"href","/docs/transformers/pr_17469/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(FO,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(TO,"href","/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(MO,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(EO,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(CO,"href","/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForCausalLM"),d(wO,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(AO,"href","/docs/transformers/pr_17469/en/model_doc/codegen#transformers.CodeGenForCausalLM"),d(LO,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(yO,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(xO,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForCausalLM"),d($O,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(kO,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(SO,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),d(RO,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(PO,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianForCausalLM"),d(BO,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForCausalLM"),d(IO,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(NO,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForCausalLM"),d(qO,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(jO,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTForCausalLM"),d(DO,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(GO,"href","/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(OO,"href","/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(VO,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(XO,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(zO,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(QO,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(WO,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(HO,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(UO,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(JO,"href","/docs/transformers/pr_17469/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(YO,"href","/docs/transformers/pr_17469/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(KO,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(ZO,"href","/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(eV,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(oV,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(rV,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N4,"id","transformers.AutoModelForMaskedLM"),d(N4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N4,"href","#transformers.AutoModelForMaskedLM"),d(Ki,"class","relative group"),d(tV,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aV,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nV,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sV,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(lV,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(iV,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForMaskedLM"),d(dV,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(cV,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(fV,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(mV,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(gV,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(hV,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(pV,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(_V,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(uV,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(bV,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(vV,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(FV,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(TV,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(MV,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(EV,"href","/docs/transformers/pr_17469/en/model_doc/luke#transformers.LukeForMaskedLM"),d(CV,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(wV,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(AV,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(LV,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(yV,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(xV,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForMaskedLM"),d($V,"href","/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(kV,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(SV,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(RV,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(PV,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(BV,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(IV,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(NV,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(qV,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(jV,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(DV,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(GV,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(OV,"href","/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w2,"id","transformers.AutoModelForSeq2SeqLM"),d(w2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w2,"href","#transformers.AutoModelForSeq2SeqLM"),d(od,"class","relative group"),d(VV,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(XV,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zV,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QV,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(WV,"href","/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(HV,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(UV,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(JV,"href","/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(YV,"href","/docs/transformers/pr_17469/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(KV,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(ZV,"href","/docs/transformers/pr_17469/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(eX,"href","/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(oX,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.MarianMTModel"),d(rX,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(tX,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(aX,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(nX,"href","/docs/transformers/pr_17469/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(sX,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(lX,"href","/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(iX,"href","/docs/transformers/pr_17469/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(dX,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(cX,"href","/docs/transformers/pr_17469/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(H2,"id","transformers.AutoModelForSequenceClassification"),d(H2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(H2,"href","#transformers.AutoModelForSequenceClassification"),d(ad,"class","relative group"),d(fX,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mX,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gX,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hX,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(pX,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForSequenceClassification"),d(_X,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForSequenceClassification"),d(uX,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(bX,"href","/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(vX,"href","/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForSequenceClassification"),d(FX,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(TX,"href","/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(MX,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(EX,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(CX,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(wX,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(AX,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(LX,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(yX,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(xX,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d($X,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(kX,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(SX,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(RX,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(PX,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(BX,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(IX,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(NX,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(qX,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),d(jX,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDForSequenceClassification"),d(DX,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(GX,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(OX,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(VX,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(XX,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(zX,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForSequenceClassification"),d(QX,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),d(WX,"href","/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(HX,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(UX,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.OPTForSequenceClassification"),d(JX,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(YX,"href","/docs/transformers/pr_17469/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(KX,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(ZX,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(ez,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(oz,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(rz,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(tz,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(az,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(nz,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(sz,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(lz,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(iz,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(dz,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(cz,"href","/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ub,"id","transformers.AutoModelForMultipleChoice"),d(Ub,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ub,"href","#transformers.AutoModelForMultipleChoice"),d(ld,"class","relative group"),d(fz,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mz,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gz,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hz,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(pz,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForMultipleChoice"),d(_z,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(uz,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(bz,"href","/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(vz,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(Fz,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(Tz,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),d(Mz,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(Ez,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(Cz,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(wz,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(Az,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(Lz,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(yz,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(xz,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d($z,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(kz,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(Sz,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),d(Rz,"href","/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(Pz,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(Bz,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(Iz,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(Nz,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(qz,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(jz,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(Dz,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(Gz,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(Oz,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(Vz,"href","/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xv,"id","transformers.AutoModelForNextSentencePrediction"),d(xv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xv,"href","#transformers.AutoModelForNextSentencePrediction"),d(cd,"class","relative group"),d(Xz,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zz,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Qz,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wz,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(Hz,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(Uz,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(Jz,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(Yz,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),d(Kz,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jv,"id","transformers.AutoModelForTokenClassification"),d(jv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(jv,"href","#transformers.AutoModelForTokenClassification"),d(gd,"class","relative group"),d(Zz,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eQ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(oQ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rQ,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(tQ,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForTokenClassification"),d(aQ,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(nQ,"href","/docs/transformers/pr_17469/en/model_doc/bloom#transformers.BloomForTokenClassification"),d(sQ,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(lQ,"href","/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForTokenClassification"),d(iQ,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(dQ,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(cQ,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(fQ,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(mQ,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(gQ,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(hQ,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(pQ,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(_Q,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(uQ,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(bQ,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(vQ,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(FQ,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(TQ,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),d(MQ,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(EQ,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(CQ,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(wQ,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(AQ,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForTokenClassification"),d(LQ,"href","/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(yQ,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(xQ,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d($Q,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(kQ,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(SQ,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(RQ,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(PQ,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(BQ,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(IQ,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(NQ,"href","/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wF,"id","transformers.AutoModelForQuestionAnswering"),d(wF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(wF,"href","#transformers.AutoModelForQuestionAnswering"),d(_d,"class","relative group"),d(qQ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jQ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(DQ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(GQ,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(OQ,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(VQ,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(XQ,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(zQ,"href","/docs/transformers/pr_17469/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(QQ,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(WQ,"href","/docs/transformers/pr_17469/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(HQ,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(UQ,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(JQ,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(YQ,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(KQ,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(ZQ,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(eW,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(oW,"href","/docs/transformers/pr_17469/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(rW,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(tW,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(aW,"href","/docs/transformers/pr_17469/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(nW,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(sW,"href","/docs/transformers/pr_17469/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(lW,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(iW,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(dW,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(cW,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(fW,"href","/docs/transformers/pr_17469/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(mW,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(gW,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(hW,"href","/docs/transformers/pr_17469/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),d(pW,"href","/docs/transformers/pr_17469/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),d(_W,"href","/docs/transformers/pr_17469/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(uW,"href","/docs/transformers/pr_17469/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(bW,"href","/docs/transformers/pr_17469/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(vW,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(FW,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(TW,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(MW,"href","/docs/transformers/pr_17469/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(EW,"href","/docs/transformers/pr_17469/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(CW,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(wW,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(AW,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(LW,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(yW,"href","/docs/transformers/pr_17469/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(u6,"id","transformers.AutoModelForTableQuestionAnswering"),d(u6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(u6,"href","#transformers.AutoModelForTableQuestionAnswering"),d(vd,"class","relative group"),d(xW,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($W,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(kW,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(SW,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M6,"id","transformers.AutoModelForImageClassification"),d(M6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(M6,"href","#transformers.AutoModelForImageClassification"),d(Md,"class","relative group"),d(RW,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(PW,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(BW,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(IW,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitForImageClassification"),d(NW,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(qW,"href","/docs/transformers/pr_17469/en/model_doc/cvt#transformers.CvtForImageClassification"),d(jW,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(DW,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTForImageClassification"),d(GW,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(OW,"href","/docs/transformers/pr_17469/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(VW,"href","/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitForImageClassification"),d(XW,"href","/docs/transformers/pr_17469/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),d(zW,"href","/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),d(QW,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(WW,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(HW,"href","/docs/transformers/pr_17469/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(UW,"href","/docs/transformers/pr_17469/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(JW,"href","/docs/transformers/pr_17469/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(YW,"href","/docs/transformers/pr_17469/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(KW,"href","/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(ZW,"href","/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinForImageClassification"),d(eH,"href","/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),d(oH,"href","/docs/transformers/pr_17469/en/model_doc/van#transformers.VanForImageClassification"),d(rH,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTForImageClassification"),d(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D6,"id","transformers.AutoModelForVision2Seq"),d(D6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D6,"href","#transformers.AutoModelForVision2Seq"),d(wd,"class","relative group"),d(tH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sH,"href","/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z6,"id","transformers.AutoModelForVisualQuestionAnswering"),d(z6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z6,"href","#transformers.AutoModelForVisualQuestionAnswering"),d(yd,"class","relative group"),d(lH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(iH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cH,"href","/docs/transformers/pr_17469/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),d(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(J6,"id","transformers.AutoModelForAudioClassification"),d(J6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J6,"href","#transformers.AutoModelForAudioClassification"),d(kd,"class","relative group"),d(fH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hH,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(pH,"href","/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(_H,"href","/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(uH,"href","/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(bH,"href","/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(vH,"href","/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(FH,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(TH,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),d(MH,"href","/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dT,"id","transformers.AutoModelForAudioFrameClassification"),d(dT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dT,"href","#transformers.AutoModelForAudioFrameClassification"),d(Pd,"class","relative group"),d(EH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(CH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(wH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(AH,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(LH,"href","/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(yH,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(xH,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),d($H,"href","/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bT,"id","transformers.AutoModelForCTC"),d(bT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(bT,"href","#transformers.AutoModelForCTC"),d(Nd,"class","relative group"),d(kH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(SH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(RH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PH,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(BH,"href","/docs/transformers/pr_17469/en/model_doc/hubert#transformers.HubertForCTC"),d(IH,"href","/docs/transformers/pr_17469/en/model_doc/mctct#transformers.MCTCTForCTC"),d(NH,"href","/docs/transformers/pr_17469/en/model_doc/sew#transformers.SEWForCTC"),d(qH,"href","/docs/transformers/pr_17469/en/model_doc/sew-d#transformers.SEWDForCTC"),d(jH,"href","/docs/transformers/pr_17469/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(DH,"href","/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(GH,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(OH,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),d(VH,"href","/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForCTC"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ST,"id","transformers.AutoModelForSpeechSeq2Seq"),d(ST,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ST,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Dd,"class","relative group"),d(XH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(QH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(WH,"href","/docs/transformers/pr_17469/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(HH,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qT,"id","transformers.AutoModelForAudioXVector"),d(qT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qT,"href","#transformers.AutoModelForAudioXVector"),d(Vd,"class","relative group"),d(UH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(JH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(YH,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(KH,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(ZH,"href","/docs/transformers/pr_17469/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(eU,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(oU,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),d(rU,"href","/docs/transformers/pr_17469/en/model_doc/wavlm#transformers.WavLMForXVector"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(WT,"id","transformers.AutoModelForMaskedImageModeling"),d(WT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(WT,"href","#transformers.AutoModelForMaskedImageModeling"),d(Qd,"class","relative group"),d(tU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sU,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(lU,"href","/docs/transformers/pr_17469/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(iU,"href","/docs/transformers/pr_17469/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),d(dU,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(o7,"id","transformers.AutoModelForObjectDetection"),d(o7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(o7,"href","#transformers.AutoModelForObjectDetection"),d(Ud,"class","relative group"),d(cU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(mU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gU,"href","/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrForObjectDetection"),d(hU,"href","/docs/transformers/pr_17469/en/model_doc/yolos#transformers.YolosForObjectDetection"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(l7,"id","transformers.AutoModelForImageSegmentation"),d(l7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(l7,"href","#transformers.AutoModelForImageSegmentation"),d(Kd,"class","relative group"),d(pU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_U,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(uU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bU,"href","/docs/transformers/pr_17469/en/model_doc/detr#transformers.DetrForSegmentation"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(m7,"id","transformers.AutoModelForSemanticSegmentation"),d(m7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(m7,"href","#transformers.AutoModelForSemanticSegmentation"),d(oc,"class","relative group"),d(vU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(FU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(TU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(MU,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(EU,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(CU,"href","/docs/transformers/pr_17469/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(wU,"href","/docs/transformers/pr_17469/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),d(AU,"href","/docs/transformers/pr_17469/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T7,"id","transformers.AutoModelForInstanceSegmentation"),d(T7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(T7,"href","#transformers.AutoModelForInstanceSegmentation"),d(ac,"class","relative group"),d(LU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($U,"href","/docs/transformers/pr_17469/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(A7,"id","transformers.TFAutoModel"),d(A7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A7,"href","#transformers.TFAutoModel"),d(lc,"class","relative group"),d(kU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(SU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(RU,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PU,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertModel"),d(BU,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.TFBartModel"),d(IU,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertModel"),d(NU,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(qU,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(jU,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertModel"),d(DU,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.TFCLIPModel"),d(GU,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertModel"),d(OU,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.TFConvNextModel"),d(VU,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLModel"),d(XU,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),d(zU,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaModel"),d(QU,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(WU,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.TFDeiTModel"),d(HU,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(UU,"href","/docs/transformers/pr_17469/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(JU,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraModel"),d(YU,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(KU,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelModel"),d(ZU,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(eJ,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2Model"),d(oJ,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJModel"),d(rJ,"href","/docs/transformers/pr_17469/en/model_doc/hubert#transformers.TFHubertModel"),d(tJ,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(aJ,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.TFLEDModel"),d(nJ,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerModel"),d(sJ,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.TFLxmertModel"),d(lJ,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.TFMarianModel"),d(iJ,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.TFMBartModel"),d(dJ,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(cJ,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetModel"),d(fJ,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.TFMT5Model"),d(mJ,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(gJ,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.TFOPTModel"),d(hJ,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.TFPegasusModel"),d(pJ,"href","/docs/transformers/pr_17469/en/model_doc/regnet#transformers.TFRegNetModel"),d(_J,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertModel"),d(uJ,"href","/docs/transformers/pr_17469/en/model_doc/resnet#transformers.TFResNetModel"),d(bJ,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaModel"),d(vJ,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerModel"),d(FJ,"href","/docs/transformers/pr_17469/en/model_doc/segformer#transformers.TFSegformerModel"),d(TJ,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(MJ,"href","/docs/transformers/pr_17469/en/model_doc/swin#transformers.TFSwinModel"),d(EJ,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.TFT5Model"),d(CJ,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasModel"),d(wJ,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(AJ,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.TFViTModel"),d(LJ,"href","/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(yJ,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(xJ,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMModel"),d($J,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(kJ,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetModel"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w9,"id","transformers.TFAutoModelForPreTraining"),d(w9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w9,"href","#transformers.TFAutoModelForPreTraining"),d(cc,"class","relative group"),d(SJ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(RJ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(PJ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(BJ,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(IJ,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(NJ,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForPreTraining"),d(qJ,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(jJ,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(DJ,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(GJ,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(OJ,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(VJ,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(XJ,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(zJ,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(QJ,"href","/docs/transformers/pr_17469/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(WJ,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(HJ,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(UJ,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(JJ,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(YJ,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(KJ,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(ZJ,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(eY,"href","/docs/transformers/pr_17469/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(oY,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(rY,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(tY,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Y9,"id","transformers.TFAutoModelForCausalLM"),d(Y9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Y9,"href","#transformers.TFAutoModelForCausalLM"),d(gc,"class","relative group"),d(aY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lY,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(iY,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(dY,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(cY,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(fY,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(mY,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(gY,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.TFOPTForCausalLM"),d(hY,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(pY,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(_Y,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(uY,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(bY,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(vY,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gM,"id","transformers.TFAutoModelForImageClassification"),d(gM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(gM,"href","#transformers.TFAutoModelForImageClassification"),d(_c,"class","relative group"),d(FY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(TY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(MY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(EY,"href","/docs/transformers/pr_17469/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(CY,"href","/docs/transformers/pr_17469/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),d(wY,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.TFDeiTForImageClassification"),d(AY,"href","/docs/transformers/pr_17469/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),d(LY,"href","/docs/transformers/pr_17469/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),d(yY,"href","/docs/transformers/pr_17469/en/model_doc/resnet#transformers.TFResNetForImageClassification"),d(xY,"href","/docs/transformers/pr_17469/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),d($Y,"href","/docs/transformers/pr_17469/en/model_doc/swin#transformers.TFSwinForImageClassification"),d(kY,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.TFViTForImageClassification"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(EM,"id","transformers.TFAutoModelForMaskedLM"),d(EM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(EM,"href","#transformers.TFAutoModelForMaskedLM"),d(vc,"class","relative group"),d(SY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(RY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(PY,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(BY,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(IY,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(NY,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(qY,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(jY,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(DY,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(GY,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(OY,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(VY,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(XY,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(zY,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(QY,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(WY,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(HY,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(UY,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(JY,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(YY,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(KY,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(ZY,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(eK,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QM,"id","transformers.TFAutoModelForSeq2SeqLM"),d(QM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(QM,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(Mc,"class","relative group"),d(oK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(rK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(tK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(aK,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(nK,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(sK,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(lK,"href","/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(iK,"href","/docs/transformers/pr_17469/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(dK,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.TFMarianMTModel"),d(cK,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(fK,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(mK,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(gK,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nE,"id","transformers.TFAutoModelForSequenceClassification"),d(nE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(nE,"href","#transformers.TFAutoModelForSequenceClassification"),d(wc,"class","relative group"),d(hK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_K,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uK,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(bK,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(vK,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(FK,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(TK,"href","/docs/transformers/pr_17469/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(MK,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(EK,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(CK,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(wK,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(AK,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(LK,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(yK,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(xK,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d($K,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(kK,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(SK,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(RK,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(PK,"href","/docs/transformers/pr_17469/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(BK,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(IK,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(NK,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(qK,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(jK,"href","/docs/transformers/pr_17469/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(DK,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(GK,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(OK,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PE,"id","transformers.TFAutoModelForMultipleChoice"),d(PE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(PE,"href","#transformers.TFAutoModelForMultipleChoice"),d(yc,"class","relative group"),d(VK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(XK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zK,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QK,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(WK,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(HK,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(UK,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(JK,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(YK,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(KK,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(ZK,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(eZ,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(oZ,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(rZ,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(tZ,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(aZ,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(nZ,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(sZ,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(lZ,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(iZ,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eC,"id","transformers.TFAutoModelForNextSentencePrediction"),d(eC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(eC,"href","#transformers.TFAutoModelForNextSentencePrediction"),d(kc,"class","relative group"),d(dZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mZ,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),d(gZ,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nC,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(nC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(nC,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Pc,"class","relative group"),d(hZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_Z,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uZ,"href","/docs/transformers/pr_17469/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dC,"id","transformers.TFAutoModelForTokenClassification"),d(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dC,"href","#transformers.TFAutoModelForTokenClassification"),d(Nc,"class","relative group"),d(bZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(FZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TZ,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(MZ,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(EZ,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(CZ,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(wZ,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(AZ,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(LZ,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(yZ,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(xZ,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d($Z,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(kZ,"href","/docs/transformers/pr_17469/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(SZ,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(RZ,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(PZ,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(BZ,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(IZ,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(NZ,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(qZ,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(jZ,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(DZ,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(SC,"id","transformers.TFAutoModelForQuestionAnswering"),d(SC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(SC,"href","#transformers.TFAutoModelForQuestionAnswering"),d(Dc,"class","relative group"),d(GZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(OZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(VZ,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(XZ,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(zZ,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(QZ,"href","/docs/transformers/pr_17469/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(WZ,"href","/docs/transformers/pr_17469/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(HZ,"href","/docs/transformers/pr_17469/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(UZ,"href","/docs/transformers/pr_17469/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(JZ,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(YZ,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(KZ,"href","/docs/transformers/pr_17469/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(ZZ,"href","/docs/transformers/pr_17469/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(eee,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d(oee,"href","/docs/transformers/pr_17469/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(ree,"href","/docs/transformers/pr_17469/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(tee,"href","/docs/transformers/pr_17469/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(aee,"href","/docs/transformers/pr_17469/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(nee,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(see,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(lee,"href","/docs/transformers/pr_17469/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(iee,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(dee,"href","/docs/transformers/pr_17469/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(o5,"id","transformers.TFAutoModelForVision2Seq"),d(o5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(o5,"href","#transformers.TFAutoModelForVision2Seq"),d(Vc,"class","relative group"),d(cee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(mee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gee,"href","/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(n5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(Qc,"class","relative group"),d(hee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_ee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uee,"href","/docs/transformers/pr_17469/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(d5,"id","transformers.FlaxAutoModel"),d(d5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(d5,"href","#transformers.FlaxAutoModel"),d(Uc,"class","relative group"),d(bee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Fee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tee,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertModel"),d(Mee,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartModel"),d(Eee,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.FlaxBeitModel"),d(Cee,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertModel"),d(wee,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(Aee,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(Lee,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(yee,"href","/docs/transformers/pr_17469/en/model_doc/clip#transformers.FlaxCLIPModel"),d(xee,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d($ee,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraModel"),d(kee,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(See,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(Ree,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(Pee,"href","/docs/transformers/pr_17469/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(Bee,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.FlaxMarianModel"),d(Iee,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartModel"),d(Nee,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.FlaxMT5Model"),d(qee,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.FlaxOPTModel"),d(jee,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(Dee,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(Gee,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(Oee,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.FlaxT5Model"),d(Vee,"href","/docs/transformers/pr_17469/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(Xee,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.FlaxViTModel"),d(zee,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(Qee,"href","/docs/transformers/pr_17469/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(Wee,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(j5,"id","transformers.FlaxAutoModelForCausalLM"),d(j5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(j5,"href","#transformers.FlaxAutoModelForCausalLM"),d(Kc,"class","relative group"),d(Hee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Uee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Jee,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yee,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(Kee,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForCausalLM"),d(Zee,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),d(eoe,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),d(ooe,"href","/docs/transformers/pr_17469/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(roe,"href","/docs/transformers/pr_17469/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(toe,"href","/docs/transformers/pr_17469/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(aoe,"href","/docs/transformers/pr_17469/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),d(noe,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),d(soe,"href","/docs/transformers/pr_17469/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(K5,"id","transformers.FlaxAutoModelForPreTraining"),d(K5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K5,"href","#transformers.FlaxAutoModelForPreTraining"),d(of,"class","relative group"),d(loe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ioe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(doe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(coe,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(foe,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(moe,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(goe,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(hoe,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(poe,"href","/docs/transformers/pr_17469/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(_oe,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(uoe,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(boe,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(voe,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Foe,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(Toe,"href","/docs/transformers/pr_17469/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(Moe,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(h3,"id","transformers.FlaxAutoModelForMaskedLM"),d(h3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(h3,"href","#transformers.FlaxAutoModelForMaskedLM"),d(af,"class","relative group"),d(Eoe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Coe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(woe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Aoe,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(Loe,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(yoe,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(xoe,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d($oe,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(koe,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(Soe,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Roe,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Poe,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Boe,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L3,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(L3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L3,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(lf,"class","relative group"),d(Ioe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Noe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(qoe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(joe,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Doe,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(Goe,"href","/docs/transformers/pr_17469/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(Ooe,"href","/docs/transformers/pr_17469/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(Voe,"href","/docs/transformers/pr_17469/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(Xoe,"href","/docs/transformers/pr_17469/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(zoe,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Qoe,"href","/docs/transformers/pr_17469/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Woe,"href","/docs/transformers/pr_17469/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(Hoe,"href","/docs/transformers/pr_17469/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D3,"id","transformers.FlaxAutoModelForSequenceClassification"),d(D3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D3,"href","#transformers.FlaxAutoModelForSequenceClassification"),d(ff,"class","relative group"),d(Uoe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Joe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Yoe,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Koe,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(Zoe,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(ere,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(ore,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(rre,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(tre,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(are,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(nre,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(sre,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(lre,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Z3,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Z3,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(hf,"class","relative group"),d(ire,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(dre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fre,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(mre,"href","/docs/transformers/pr_17469/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(gre,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(hre,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(pre,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(_re,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(ure,"href","/docs/transformers/pr_17469/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(bre,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(vre,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(Fre,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(m0,"id","transformers.FlaxAutoModelForTokenClassification"),d(m0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(m0,"href","#transformers.FlaxAutoModelForTokenClassification"),d(uf,"class","relative group"),d(Tre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ere,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cre,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(wre,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(Are,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(Lre,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(yre,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(xre,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d($re,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(kre,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(E0,"id","transformers.FlaxAutoModelForMultipleChoice"),d(E0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(E0,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(Ff,"class","relative group"),d(Sre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Pre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bre,"href","/docs/transformers/pr_17469/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(Ire,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(Nre,"href","/docs/transformers/pr_17469/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(qre,"href","/docs/transformers/pr_17469/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(jre,"href","/docs/transformers/pr_17469/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(Dre,"href","/docs/transformers/pr_17469/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(Gre,"href","/docs/transformers/pr_17469/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(Ore,"href","/docs/transformers/pr_17469/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(P0,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(P0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(P0,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(Ef,"class","relative group"),d(Vre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qre,"href","/docs/transformers/pr_17469/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(q0,"id","transformers.FlaxAutoModelForImageClassification"),d(q0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(q0,"href","#transformers.FlaxAutoModelForImageClassification"),d(Af,"class","relative group"),d(Wre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Hre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ure,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jre,"href","/docs/transformers/pr_17469/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(Yre,"href","/docs/transformers/pr_17469/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(V0,"id","transformers.FlaxAutoModelForVision2Seq"),d(V0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(V0,"href","#transformers.FlaxAutoModelForVision2Seq"),d(xf,"class","relative group"),d(Kre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zre,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ete,"href","/docs/transformers/pr_17469/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ote,"href","/docs/transformers/pr_17469/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(c,_,null),e(p,h),e(p,wo),e(wo,xi),b(f,Bf,u),b(f,lt,u),e(lt,$i),e(lt,ki),e(ki,mL),e(lt,If),b(f,Oe,u),b(f,We,u),e(We,Si),e(We,Bn),e(Bn,gL),e(We,In),e(We,Nn),e(Nn,hL),e(We,Ri),e(We,qn),e(qn,pL),e(We,Pi),b(f,Nf,u),M(Sa,f,u),b(f,He,u),b(f,Ae,u),e(Ae,HS),e(Ae,Bi),e(Bi,US),e(Ae,JS),b(f,Ao,u),b(f,Ra,u),e(Ra,YS),e(Ra,qf),e(qf,KS),e(Ra,tUe),b(f,OXe,u),b(f,Ii,u),e(Ii,jf),e(jf,Uae),M(_L,Uae,null),e(Ii,aUe),e(Ii,Jae),e(Jae,nUe),b(f,VXe,u),b(f,jn,u),e(jn,sUe),e(jn,Yae),e(Yae,lUe),e(jn,iUe),e(jn,Kae),e(Kae,dUe),e(jn,cUe),b(f,XXe,u),M(uL,f,u),b(f,zXe,u),b(f,ZS,u),e(ZS,fUe),b(f,QXe,u),M(Df,f,u),b(f,WXe,u),b(f,Ni,u),e(Ni,Gf),e(Gf,Zae),M(bL,Zae,null),e(Ni,mUe),e(Ni,ene),e(ene,gUe),b(f,HXe,u),b(f,Lo,u),M(vL,Lo,null),e(Lo,hUe),e(Lo,FL),e(FL,pUe),e(FL,eR),e(eR,_Ue),e(FL,uUe),e(Lo,bUe),e(Lo,TL),e(TL,vUe),e(TL,one),e(one,FUe),e(TL,TUe),e(Lo,MUe),e(Lo,yr),M(ML,yr,null),e(yr,EUe),e(yr,rne),e(rne,CUe),e(yr,wUe),e(yr,qi),e(qi,AUe),e(qi,tne),e(tne,LUe),e(qi,yUe),e(qi,ane),e(ane,xUe),e(qi,$Ue),e(yr,kUe),e(yr,A),e(A,Of),e(Of,nne),e(nne,SUe),e(Of,RUe),e(Of,oR),e(oR,PUe),e(Of,BUe),e(A,IUe),e(A,Vf),e(Vf,sne),e(sne,NUe),e(Vf,qUe),e(Vf,rR),e(rR,jUe),e(Vf,DUe),e(A,GUe),e(A,Xf),e(Xf,lne),e(lne,OUe),e(Xf,VUe),e(Xf,tR),e(tR,XUe),e(Xf,zUe),e(A,QUe),e(A,zf),e(zf,ine),e(ine,WUe),e(zf,HUe),e(zf,aR),e(aR,UUe),e(zf,JUe),e(A,YUe),e(A,Qf),e(Qf,dne),e(dne,KUe),e(Qf,ZUe),e(Qf,nR),e(nR,eJe),e(Qf,oJe),e(A,rJe),e(A,Wf),e(Wf,cne),e(cne,tJe),e(Wf,aJe),e(Wf,sR),e(sR,nJe),e(Wf,sJe),e(A,lJe),e(A,Hf),e(Hf,fne),e(fne,iJe),e(Hf,dJe),e(Hf,lR),e(lR,cJe),e(Hf,fJe),e(A,mJe),e(A,Uf),e(Uf,mne),e(mne,gJe),e(Uf,hJe),e(Uf,iR),e(iR,pJe),e(Uf,_Je),e(A,uJe),e(A,Jf),e(Jf,gne),e(gne,bJe),e(Jf,vJe),e(Jf,dR),e(dR,FJe),e(Jf,TJe),e(A,MJe),e(A,Yf),e(Yf,hne),e(hne,EJe),e(Yf,CJe),e(Yf,cR),e(cR,wJe),e(Yf,AJe),e(A,LJe),e(A,Kf),e(Kf,pne),e(pne,yJe),e(Kf,xJe),e(Kf,fR),e(fR,$Je),e(Kf,kJe),e(A,SJe),e(A,Zf),e(Zf,_ne),e(_ne,RJe),e(Zf,PJe),e(Zf,mR),e(mR,BJe),e(Zf,IJe),e(A,NJe),e(A,em),e(em,une),e(une,qJe),e(em,jJe),e(em,gR),e(gR,DJe),e(em,GJe),e(A,OJe),e(A,om),e(om,bne),e(bne,VJe),e(om,XJe),e(om,hR),e(hR,zJe),e(om,QJe),e(A,WJe),e(A,rm),e(rm,vne),e(vne,HJe),e(rm,UJe),e(rm,pR),e(pR,JJe),e(rm,YJe),e(A,KJe),e(A,tm),e(tm,Fne),e(Fne,ZJe),e(tm,eYe),e(tm,_R),e(_R,oYe),e(tm,rYe),e(A,tYe),e(A,am),e(am,Tne),e(Tne,aYe),e(am,nYe),e(am,uR),e(uR,sYe),e(am,lYe),e(A,iYe),e(A,nm),e(nm,Mne),e(Mne,dYe),e(nm,cYe),e(nm,bR),e(bR,fYe),e(nm,mYe),e(A,gYe),e(A,sm),e(sm,Ene),e(Ene,hYe),e(sm,pYe),e(sm,vR),e(vR,_Ye),e(sm,uYe),e(A,bYe),e(A,lm),e(lm,Cne),e(Cne,vYe),e(lm,FYe),e(lm,FR),e(FR,TYe),e(lm,MYe),e(A,EYe),e(A,im),e(im,wne),e(wne,CYe),e(im,wYe),e(im,TR),e(TR,AYe),e(im,LYe),e(A,yYe),e(A,dm),e(dm,Ane),e(Ane,xYe),e(dm,$Ye),e(dm,MR),e(MR,kYe),e(dm,SYe),e(A,RYe),e(A,cm),e(cm,Lne),e(Lne,PYe),e(cm,BYe),e(cm,ER),e(ER,IYe),e(cm,NYe),e(A,qYe),e(A,fm),e(fm,yne),e(yne,jYe),e(fm,DYe),e(fm,CR),e(CR,GYe),e(fm,OYe),e(A,VYe),e(A,mm),e(mm,xne),e(xne,XYe),e(mm,zYe),e(mm,wR),e(wR,QYe),e(mm,WYe),e(A,HYe),e(A,gm),e(gm,$ne),e($ne,UYe),e(gm,JYe),e(gm,AR),e(AR,YYe),e(gm,KYe),e(A,ZYe),e(A,hm),e(hm,kne),e(kne,eKe),e(hm,oKe),e(hm,LR),e(LR,rKe),e(hm,tKe),e(A,aKe),e(A,pm),e(pm,Sne),e(Sne,nKe),e(pm,sKe),e(pm,yR),e(yR,lKe),e(pm,iKe),e(A,dKe),e(A,_m),e(_m,Rne),e(Rne,cKe),e(_m,fKe),e(_m,xR),e(xR,mKe),e(_m,gKe),e(A,hKe),e(A,um),e(um,Pne),e(Pne,pKe),e(um,_Ke),e(um,$R),e($R,uKe),e(um,bKe),e(A,vKe),e(A,bm),e(bm,Bne),e(Bne,FKe),e(bm,TKe),e(bm,kR),e(kR,MKe),e(bm,EKe),e(A,CKe),e(A,vm),e(vm,Ine),e(Ine,wKe),e(vm,AKe),e(vm,SR),e(SR,LKe),e(vm,yKe),e(A,xKe),e(A,Fm),e(Fm,Nne),e(Nne,$Ke),e(Fm,kKe),e(Fm,RR),e(RR,SKe),e(Fm,RKe),e(A,PKe),e(A,Tm),e(Tm,qne),e(qne,BKe),e(Tm,IKe),e(Tm,PR),e(PR,NKe),e(Tm,qKe),e(A,jKe),e(A,Mm),e(Mm,jne),e(jne,DKe),e(Mm,GKe),e(Mm,BR),e(BR,OKe),e(Mm,VKe),e(A,XKe),e(A,Em),e(Em,Dne),e(Dne,zKe),e(Em,QKe),e(Em,IR),e(IR,WKe),e(Em,HKe),e(A,UKe),e(A,Cm),e(Cm,Gne),e(Gne,JKe),e(Cm,YKe),e(Cm,NR),e(NR,KKe),e(Cm,ZKe),e(A,eZe),e(A,wm),e(wm,One),e(One,oZe),e(wm,rZe),e(wm,qR),e(qR,tZe),e(wm,aZe),e(A,nZe),e(A,Am),e(Am,Vne),e(Vne,sZe),e(Am,lZe),e(Am,jR),e(jR,iZe),e(Am,dZe),e(A,cZe),e(A,Lm),e(Lm,Xne),e(Xne,fZe),e(Lm,mZe),e(Lm,DR),e(DR,gZe),e(Lm,hZe),e(A,pZe),e(A,ym),e(ym,zne),e(zne,_Ze),e(ym,uZe),e(ym,GR),e(GR,bZe),e(ym,vZe),e(A,FZe),e(A,xm),e(xm,Qne),e(Qne,TZe),e(xm,MZe),e(xm,OR),e(OR,EZe),e(xm,CZe),e(A,wZe),e(A,$m),e($m,Wne),e(Wne,AZe),e($m,LZe),e($m,VR),e(VR,yZe),e($m,xZe),e(A,$Ze),e(A,km),e(km,Hne),e(Hne,kZe),e(km,SZe),e(km,XR),e(XR,RZe),e(km,PZe),e(A,BZe),e(A,Sm),e(Sm,Une),e(Une,IZe),e(Sm,NZe),e(Sm,zR),e(zR,qZe),e(Sm,jZe),e(A,DZe),e(A,Rm),e(Rm,Jne),e(Jne,GZe),e(Rm,OZe),e(Rm,QR),e(QR,VZe),e(Rm,XZe),e(A,zZe),e(A,Pm),e(Pm,Yne),e(Yne,QZe),e(Pm,WZe),e(Pm,WR),e(WR,HZe),e(Pm,UZe),e(A,JZe),e(A,Bm),e(Bm,Kne),e(Kne,YZe),e(Bm,KZe),e(Bm,HR),e(HR,ZZe),e(Bm,eeo),e(A,oeo),e(A,Im),e(Im,Zne),e(Zne,reo),e(Im,teo),e(Im,UR),e(UR,aeo),e(Im,neo),e(A,seo),e(A,Nm),e(Nm,ese),e(ese,leo),e(Nm,ieo),e(Nm,JR),e(JR,deo),e(Nm,ceo),e(A,feo),e(A,qm),e(qm,ose),e(ose,meo),e(qm,geo),e(qm,YR),e(YR,heo),e(qm,peo),e(A,_eo),e(A,jm),e(jm,rse),e(rse,ueo),e(jm,beo),e(jm,KR),e(KR,veo),e(jm,Feo),e(A,Teo),e(A,Dm),e(Dm,tse),e(tse,Meo),e(Dm,Eeo),e(Dm,ZR),e(ZR,Ceo),e(Dm,weo),e(A,Aeo),e(A,Gm),e(Gm,ase),e(ase,Leo),e(Gm,yeo),e(Gm,eP),e(eP,xeo),e(Gm,$eo),e(A,keo),e(A,Om),e(Om,nse),e(nse,Seo),e(Om,Reo),e(Om,oP),e(oP,Peo),e(Om,Beo),e(A,Ieo),e(A,Vm),e(Vm,sse),e(sse,Neo),e(Vm,qeo),e(Vm,rP),e(rP,jeo),e(Vm,Deo),e(A,Geo),e(A,Xm),e(Xm,lse),e(lse,Oeo),e(Xm,Veo),e(Xm,tP),e(tP,Xeo),e(Xm,zeo),e(A,Qeo),e(A,zm),e(zm,ise),e(ise,Weo),e(zm,Heo),e(zm,aP),e(aP,Ueo),e(zm,Jeo),e(A,Yeo),e(A,Qm),e(Qm,dse),e(dse,Keo),e(Qm,Zeo),e(Qm,nP),e(nP,eoo),e(Qm,ooo),e(A,roo),e(A,Wm),e(Wm,cse),e(cse,too),e(Wm,aoo),e(Wm,sP),e(sP,noo),e(Wm,soo),e(A,loo),e(A,Hm),e(Hm,fse),e(fse,ioo),e(Hm,doo),e(Hm,lP),e(lP,coo),e(Hm,foo),e(A,moo),e(A,Um),e(Um,mse),e(mse,goo),e(Um,hoo),e(Um,iP),e(iP,poo),e(Um,_oo),e(A,uoo),e(A,Jm),e(Jm,gse),e(gse,boo),e(Jm,voo),e(Jm,dP),e(dP,Foo),e(Jm,Too),e(A,Moo),e(A,Ym),e(Ym,hse),e(hse,Eoo),e(Ym,Coo),e(Ym,cP),e(cP,woo),e(Ym,Aoo),e(A,Loo),e(A,Km),e(Km,pse),e(pse,yoo),e(Km,xoo),e(Km,fP),e(fP,$oo),e(Km,koo),e(A,Soo),e(A,Zm),e(Zm,_se),e(_se,Roo),e(Zm,Poo),e(Zm,mP),e(mP,Boo),e(Zm,Ioo),e(A,Noo),e(A,eg),e(eg,use),e(use,qoo),e(eg,joo),e(eg,gP),e(gP,Doo),e(eg,Goo),e(A,Ooo),e(A,og),e(og,bse),e(bse,Voo),e(og,Xoo),e(og,hP),e(hP,zoo),e(og,Qoo),e(A,Woo),e(A,rg),e(rg,vse),e(vse,Hoo),e(rg,Uoo),e(rg,pP),e(pP,Joo),e(rg,Yoo),e(A,Koo),e(A,tg),e(tg,Fse),e(Fse,Zoo),e(tg,ero),e(tg,_P),e(_P,oro),e(tg,rro),e(A,tro),e(A,ag),e(ag,Tse),e(Tse,aro),e(ag,nro),e(ag,uP),e(uP,sro),e(ag,lro),e(A,iro),e(A,ng),e(ng,Mse),e(Mse,dro),e(ng,cro),e(ng,bP),e(bP,fro),e(ng,mro),e(A,gro),e(A,sg),e(sg,Ese),e(Ese,hro),e(sg,pro),e(sg,vP),e(vP,_ro),e(sg,uro),e(A,bro),e(A,lg),e(lg,Cse),e(Cse,vro),e(lg,Fro),e(lg,FP),e(FP,Tro),e(lg,Mro),e(A,Ero),e(A,ig),e(ig,wse),e(wse,Cro),e(ig,wro),e(ig,TP),e(TP,Aro),e(ig,Lro),e(A,yro),e(A,dg),e(dg,Ase),e(Ase,xro),e(dg,$ro),e(dg,MP),e(MP,kro),e(dg,Sro),e(A,Rro),e(A,cg),e(cg,Lse),e(Lse,Pro),e(cg,Bro),e(cg,EP),e(EP,Iro),e(cg,Nro),e(A,qro),e(A,fg),e(fg,yse),e(yse,jro),e(fg,Dro),e(fg,CP),e(CP,Gro),e(fg,Oro),e(A,Vro),e(A,mg),e(mg,xse),e(xse,Xro),e(mg,zro),e(mg,wP),e(wP,Qro),e(mg,Wro),e(A,Hro),e(A,gg),e(gg,$se),e($se,Uro),e(gg,Jro),e(gg,AP),e(AP,Yro),e(gg,Kro),e(A,Zro),e(A,hg),e(hg,kse),e(kse,eto),e(hg,oto),e(hg,LP),e(LP,rto),e(hg,tto),e(A,ato),e(A,pg),e(pg,Sse),e(Sse,nto),e(pg,sto),e(pg,yP),e(yP,lto),e(pg,ito),e(A,dto),e(A,_g),e(_g,Rse),e(Rse,cto),e(_g,fto),e(_g,xP),e(xP,mto),e(_g,gto),e(A,hto),e(A,ug),e(ug,Pse),e(Pse,pto),e(ug,_to),e(ug,$P),e($P,uto),e(ug,bto),e(A,vto),e(A,bg),e(bg,Bse),e(Bse,Fto),e(bg,Tto),e(bg,kP),e(kP,Mto),e(bg,Eto),e(A,Cto),e(A,vg),e(vg,Ise),e(Ise,wto),e(vg,Ato),e(vg,SP),e(SP,Lto),e(vg,yto),e(A,xto),e(A,Fg),e(Fg,Nse),e(Nse,$to),e(Fg,kto),e(Fg,RP),e(RP,Sto),e(Fg,Rto),e(A,Pto),e(A,Tg),e(Tg,qse),e(qse,Bto),e(Tg,Ito),e(Tg,PP),e(PP,Nto),e(Tg,qto),e(A,jto),e(A,Mg),e(Mg,jse),e(jse,Dto),e(Mg,Gto),e(Mg,BP),e(BP,Oto),e(Mg,Vto),e(A,Xto),e(A,Eg),e(Eg,Dse),e(Dse,zto),e(Eg,Qto),e(Eg,IP),e(IP,Wto),e(Eg,Hto),e(A,Uto),e(A,Cg),e(Cg,Gse),e(Gse,Jto),e(Cg,Yto),e(Cg,NP),e(NP,Kto),e(Cg,Zto),e(A,eao),e(A,wg),e(wg,Ose),e(Ose,oao),e(wg,rao),e(wg,qP),e(qP,tao),e(wg,aao),e(A,nao),e(A,Ag),e(Ag,Vse),e(Vse,sao),e(Ag,lao),e(Ag,jP),e(jP,iao),e(Ag,dao),e(A,cao),e(A,Lg),e(Lg,Xse),e(Xse,fao),e(Lg,mao),e(Lg,DP),e(DP,gao),e(Lg,hao),e(A,pao),e(A,yg),e(yg,zse),e(zse,_ao),e(yg,uao),e(yg,GP),e(GP,bao),e(yg,vao),e(A,Fao),e(A,xg),e(xg,Qse),e(Qse,Tao),e(xg,Mao),e(xg,OP),e(OP,Eao),e(xg,Cao),e(A,wao),e(A,$g),e($g,Wse),e(Wse,Aao),e($g,Lao),e($g,VP),e(VP,yao),e($g,xao),e(A,$ao),e(A,kg),e(kg,Hse),e(Hse,kao),e(kg,Sao),e(kg,XP),e(XP,Rao),e(kg,Pao),e(A,Bao),e(A,Sg),e(Sg,Use),e(Use,Iao),e(Sg,Nao),e(Sg,zP),e(zP,qao),e(Sg,jao),e(A,Dao),e(A,Rg),e(Rg,Jse),e(Jse,Gao),e(Rg,Oao),e(Rg,QP),e(QP,Vao),e(Rg,Xao),e(A,zao),e(A,Pg),e(Pg,Yse),e(Yse,Qao),e(Pg,Wao),e(Pg,WP),e(WP,Hao),e(Pg,Uao),e(A,Jao),e(A,Bg),e(Bg,Kse),e(Kse,Yao),e(Bg,Kao),e(Bg,HP),e(HP,Zao),e(Bg,eno),e(A,ono),e(A,Ig),e(Ig,Zse),e(Zse,rno),e(Ig,tno),e(Ig,UP),e(UP,ano),e(Ig,nno),e(A,sno),e(A,Ng),e(Ng,ele),e(ele,lno),e(Ng,ino),e(Ng,JP),e(JP,dno),e(Ng,cno),e(A,fno),e(A,qg),e(qg,ole),e(ole,mno),e(qg,gno),e(qg,YP),e(YP,hno),e(qg,pno),e(A,_no),e(A,jg),e(jg,rle),e(rle,uno),e(jg,bno),e(jg,KP),e(KP,vno),e(jg,Fno),e(A,Tno),e(A,Dg),e(Dg,tle),e(tle,Mno),e(Dg,Eno),e(Dg,ZP),e(ZP,Cno),e(Dg,wno),e(A,Ano),e(A,Gg),e(Gg,ale),e(ale,Lno),e(Gg,yno),e(Gg,eB),e(eB,xno),e(Gg,$no),e(A,kno),e(A,Og),e(Og,nle),e(nle,Sno),e(Og,Rno),e(Og,oB),e(oB,Pno),e(Og,Bno),e(A,Ino),e(A,Vg),e(Vg,sle),e(sle,Nno),e(Vg,qno),e(Vg,rB),e(rB,jno),e(Vg,Dno),e(A,Gno),e(A,Xg),e(Xg,lle),e(lle,Ono),e(Xg,Vno),e(Xg,tB),e(tB,Xno),e(Xg,zno),e(A,Qno),e(A,zg),e(zg,ile),e(ile,Wno),e(zg,Hno),e(zg,aB),e(aB,Uno),e(zg,Jno),e(A,Yno),e(A,Qg),e(Qg,dle),e(dle,Kno),e(Qg,Zno),e(Qg,nB),e(nB,eso),e(Qg,oso),e(A,rso),e(A,Wg),e(Wg,cle),e(cle,tso),e(Wg,aso),e(Wg,sB),e(sB,nso),e(Wg,sso),e(A,lso),e(A,Hg),e(Hg,fle),e(fle,iso),e(Hg,dso),e(Hg,lB),e(lB,cso),e(Hg,fso),e(A,mso),e(A,Ug),e(Ug,mle),e(mle,gso),e(Ug,hso),e(Ug,iB),e(iB,pso),e(Ug,_so),e(A,uso),e(A,Jg),e(Jg,gle),e(gle,bso),e(Jg,vso),e(Jg,dB),e(dB,Fso),e(Jg,Tso),e(A,Mso),e(A,Yg),e(Yg,hle),e(hle,Eso),e(Yg,Cso),e(Yg,cB),e(cB,wso),e(Yg,Aso),e(A,Lso),e(A,Kg),e(Kg,ple),e(ple,yso),e(Kg,xso),e(Kg,fB),e(fB,$so),e(Kg,kso),e(yr,Sso),M(Zg,yr,null),e(Lo,Rso),e(Lo,eh),M(EL,eh,null),e(eh,Pso),e(eh,_le),e(_le,Bso),b(f,UXe,u),b(f,ji,u),e(ji,oh),e(oh,ule),M(CL,ule,null),e(ji,Iso),e(ji,ble),e(ble,Nso),b(f,JXe,u),b(f,yo,u),M(wL,yo,null),e(yo,qso),e(yo,AL),e(AL,jso),e(AL,mB),e(mB,Dso),e(AL,Gso),e(yo,Oso),e(yo,LL),e(LL,Vso),e(LL,vle),e(vle,Xso),e(LL,zso),e(yo,Qso),e(yo,xr),M(yL,xr,null),e(xr,Wso),e(xr,Fle),e(Fle,Hso),e(xr,Uso),e(xr,Pa),e(Pa,Jso),e(Pa,Tle),e(Tle,Yso),e(Pa,Kso),e(Pa,Mle),e(Mle,Zso),e(Pa,elo),e(Pa,Ele),e(Ele,olo),e(Pa,rlo),e(xr,tlo),e(xr,k),e(k,Dn),e(Dn,Cle),e(Cle,alo),e(Dn,nlo),e(Dn,gB),e(gB,slo),e(Dn,llo),e(Dn,hB),e(hB,ilo),e(Dn,dlo),e(k,clo),e(k,Gn),e(Gn,wle),e(wle,flo),e(Gn,mlo),e(Gn,pB),e(pB,glo),e(Gn,hlo),e(Gn,_B),e(_B,plo),e(Gn,_lo),e(k,ulo),e(k,On),e(On,Ale),e(Ale,blo),e(On,vlo),e(On,uB),e(uB,Flo),e(On,Tlo),e(On,bB),e(bB,Mlo),e(On,Elo),e(k,Clo),e(k,rh),e(rh,Lle),e(Lle,wlo),e(rh,Alo),e(rh,vB),e(vB,Llo),e(rh,ylo),e(k,xlo),e(k,Vn),e(Vn,yle),e(yle,$lo),e(Vn,klo),e(Vn,FB),e(FB,Slo),e(Vn,Rlo),e(Vn,TB),e(TB,Plo),e(Vn,Blo),e(k,Ilo),e(k,th),e(th,xle),e(xle,Nlo),e(th,qlo),e(th,MB),e(MB,jlo),e(th,Dlo),e(k,Glo),e(k,ah),e(ah,$le),e($le,Olo),e(ah,Vlo),e(ah,EB),e(EB,Xlo),e(ah,zlo),e(k,Qlo),e(k,nh),e(nh,kle),e(kle,Wlo),e(nh,Hlo),e(nh,CB),e(CB,Ulo),e(nh,Jlo),e(k,Ylo),e(k,Xn),e(Xn,Sle),e(Sle,Klo),e(Xn,Zlo),e(Xn,wB),e(wB,eio),e(Xn,oio),e(Xn,AB),e(AB,rio),e(Xn,tio),e(k,aio),e(k,zn),e(zn,Rle),e(Rle,nio),e(zn,sio),e(zn,LB),e(LB,lio),e(zn,iio),e(zn,yB),e(yB,dio),e(zn,cio),e(k,fio),e(k,Qn),e(Qn,Ple),e(Ple,mio),e(Qn,gio),e(Qn,xB),e(xB,hio),e(Qn,pio),e(Qn,$B),e($B,_io),e(Qn,uio),e(k,bio),e(k,sh),e(sh,Ble),e(Ble,vio),e(sh,Fio),e(sh,kB),e(kB,Tio),e(sh,Mio),e(k,Eio),e(k,lh),e(lh,Ile),e(Ile,Cio),e(lh,wio),e(lh,SB),e(SB,Aio),e(lh,Lio),e(k,yio),e(k,ih),e(ih,Nle),e(Nle,xio),e(ih,$io),e(ih,RB),e(RB,kio),e(ih,Sio),e(k,Rio),e(k,Wn),e(Wn,qle),e(qle,Pio),e(Wn,Bio),e(Wn,PB),e(PB,Iio),e(Wn,Nio),e(Wn,BB),e(BB,qio),e(Wn,jio),e(k,Dio),e(k,dh),e(dh,jle),e(jle,Gio),e(dh,Oio),e(dh,IB),e(IB,Vio),e(dh,Xio),e(k,zio),e(k,Hn),e(Hn,Dle),e(Dle,Qio),e(Hn,Wio),e(Hn,NB),e(NB,Hio),e(Hn,Uio),e(Hn,qB),e(qB,Jio),e(Hn,Yio),e(k,Kio),e(k,Un),e(Un,Gle),e(Gle,Zio),e(Un,edo),e(Un,jB),e(jB,odo),e(Un,rdo),e(Un,DB),e(DB,tdo),e(Un,ado),e(k,ndo),e(k,Jn),e(Jn,Ole),e(Ole,sdo),e(Jn,ldo),e(Jn,GB),e(GB,ido),e(Jn,ddo),e(Jn,OB),e(OB,cdo),e(Jn,fdo),e(k,mdo),e(k,Yn),e(Yn,Vle),e(Vle,gdo),e(Yn,hdo),e(Yn,VB),e(VB,pdo),e(Yn,_do),e(Yn,XB),e(XB,udo),e(Yn,bdo),e(k,vdo),e(k,ch),e(ch,Xle),e(Xle,Fdo),e(ch,Tdo),e(ch,zB),e(zB,Mdo),e(ch,Edo),e(k,Cdo),e(k,Kn),e(Kn,zle),e(zle,wdo),e(Kn,Ado),e(Kn,QB),e(QB,Ldo),e(Kn,ydo),e(Kn,WB),e(WB,xdo),e(Kn,$do),e(k,kdo),e(k,Zn),e(Zn,Qle),e(Qle,Sdo),e(Zn,Rdo),e(Zn,HB),e(HB,Pdo),e(Zn,Bdo),e(Zn,UB),e(UB,Ido),e(Zn,Ndo),e(k,qdo),e(k,es),e(es,Wle),e(Wle,jdo),e(es,Ddo),e(es,JB),e(JB,Gdo),e(es,Odo),e(es,YB),e(YB,Vdo),e(es,Xdo),e(k,zdo),e(k,os),e(os,Hle),e(Hle,Qdo),e(os,Wdo),e(os,KB),e(KB,Hdo),e(os,Udo),e(os,ZB),e(ZB,Jdo),e(os,Ydo),e(k,Kdo),e(k,rs),e(rs,Ule),e(Ule,Zdo),e(rs,eco),e(rs,eI),e(eI,oco),e(rs,rco),e(rs,oI),e(oI,tco),e(rs,aco),e(k,nco),e(k,ts),e(ts,Jle),e(Jle,sco),e(ts,lco),e(ts,rI),e(rI,ico),e(ts,dco),e(ts,tI),e(tI,cco),e(ts,fco),e(k,mco),e(k,fh),e(fh,Yle),e(Yle,gco),e(fh,hco),e(fh,aI),e(aI,pco),e(fh,_co),e(k,uco),e(k,as),e(as,Kle),e(Kle,bco),e(as,vco),e(as,nI),e(nI,Fco),e(as,Tco),e(as,sI),e(sI,Mco),e(as,Eco),e(k,Cco),e(k,mh),e(mh,Zle),e(Zle,wco),e(mh,Aco),e(mh,lI),e(lI,Lco),e(mh,yco),e(k,xco),e(k,ns),e(ns,eie),e(eie,$co),e(ns,kco),e(ns,iI),e(iI,Sco),e(ns,Rco),e(ns,dI),e(dI,Pco),e(ns,Bco),e(k,Ico),e(k,ss),e(ss,oie),e(oie,Nco),e(ss,qco),e(ss,cI),e(cI,jco),e(ss,Dco),e(ss,fI),e(fI,Gco),e(ss,Oco),e(k,Vco),e(k,ls),e(ls,rie),e(rie,Xco),e(ls,zco),e(ls,mI),e(mI,Qco),e(ls,Wco),e(ls,gI),e(gI,Hco),e(ls,Uco),e(k,Jco),e(k,gh),e(gh,tie),e(tie,Yco),e(gh,Kco),e(gh,hI),e(hI,Zco),e(gh,efo),e(k,ofo),e(k,is),e(is,aie),e(aie,rfo),e(is,tfo),e(is,pI),e(pI,afo),e(is,nfo),e(is,_I),e(_I,sfo),e(is,lfo),e(k,ifo),e(k,ds),e(ds,nie),e(nie,dfo),e(ds,cfo),e(ds,uI),e(uI,ffo),e(ds,mfo),e(ds,bI),e(bI,gfo),e(ds,hfo),e(k,pfo),e(k,cs),e(cs,sie),e(sie,_fo),e(cs,ufo),e(cs,vI),e(vI,bfo),e(cs,vfo),e(cs,FI),e(FI,Ffo),e(cs,Tfo),e(k,Mfo),e(k,hh),e(hh,lie),e(lie,Efo),e(hh,Cfo),e(hh,TI),e(TI,wfo),e(hh,Afo),e(k,Lfo),e(k,fs),e(fs,iie),e(iie,yfo),e(fs,xfo),e(fs,MI),e(MI,$fo),e(fs,kfo),e(fs,EI),e(EI,Sfo),e(fs,Rfo),e(k,Pfo),e(k,ms),e(ms,die),e(die,Bfo),e(ms,Ifo),e(ms,CI),e(CI,Nfo),e(ms,qfo),e(ms,wI),e(wI,jfo),e(ms,Dfo),e(k,Gfo),e(k,gs),e(gs,cie),e(cie,Ofo),e(gs,Vfo),e(gs,AI),e(AI,Xfo),e(gs,zfo),e(gs,LI),e(LI,Qfo),e(gs,Wfo),e(k,Hfo),e(k,hs),e(hs,fie),e(fie,Ufo),e(hs,Jfo),e(hs,yI),e(yI,Yfo),e(hs,Kfo),e(hs,xI),e(xI,Zfo),e(hs,emo),e(k,omo),e(k,ps),e(ps,mie),e(mie,rmo),e(ps,tmo),e(ps,$I),e($I,amo),e(ps,nmo),e(ps,kI),e(kI,smo),e(ps,lmo),e(k,imo),e(k,_s),e(_s,gie),e(gie,dmo),e(_s,cmo),e(_s,SI),e(SI,fmo),e(_s,mmo),e(_s,RI),e(RI,gmo),e(_s,hmo),e(k,pmo),e(k,us),e(us,hie),e(hie,_mo),e(us,umo),e(us,PI),e(PI,bmo),e(us,vmo),e(us,BI),e(BI,Fmo),e(us,Tmo),e(k,Mmo),e(k,bs),e(bs,pie),e(pie,Emo),e(bs,Cmo),e(bs,II),e(II,wmo),e(bs,Amo),e(bs,NI),e(NI,Lmo),e(bs,ymo),e(k,xmo),e(k,ph),e(ph,_ie),e(_ie,$mo),e(ph,kmo),e(ph,qI),e(qI,Smo),e(ph,Rmo),e(k,Pmo),e(k,vs),e(vs,uie),e(uie,Bmo),e(vs,Imo),e(vs,jI),e(jI,Nmo),e(vs,qmo),e(vs,DI),e(DI,jmo),e(vs,Dmo),e(k,Gmo),e(k,_h),e(_h,bie),e(bie,Omo),e(_h,Vmo),e(_h,GI),e(GI,Xmo),e(_h,zmo),e(k,Qmo),e(k,uh),e(uh,vie),e(vie,Wmo),e(uh,Hmo),e(uh,OI),e(OI,Umo),e(uh,Jmo),e(k,Ymo),e(k,Fs),e(Fs,Fie),e(Fie,Kmo),e(Fs,Zmo),e(Fs,VI),e(VI,ego),e(Fs,ogo),e(Fs,XI),e(XI,rgo),e(Fs,tgo),e(k,ago),e(k,Ts),e(Ts,Tie),e(Tie,ngo),e(Ts,sgo),e(Ts,zI),e(zI,lgo),e(Ts,igo),e(Ts,QI),e(QI,dgo),e(Ts,cgo),e(k,fgo),e(k,Ms),e(Ms,Mie),e(Mie,mgo),e(Ms,ggo),e(Ms,WI),e(WI,hgo),e(Ms,pgo),e(Ms,HI),e(HI,_go),e(Ms,ugo),e(k,bgo),e(k,bh),e(bh,Eie),e(Eie,vgo),e(bh,Fgo),e(bh,UI),e(UI,Tgo),e(bh,Mgo),e(k,Ego),e(k,Es),e(Es,Cie),e(Cie,Cgo),e(Es,wgo),e(Es,JI),e(JI,Ago),e(Es,Lgo),e(Es,YI),e(YI,ygo),e(Es,xgo),e(k,$go),e(k,Cs),e(Cs,wie),e(wie,kgo),e(Cs,Sgo),e(Cs,KI),e(KI,Rgo),e(Cs,Pgo),e(Cs,ZI),e(ZI,Bgo),e(Cs,Igo),e(k,Ngo),e(k,ws),e(ws,Aie),e(Aie,qgo),e(ws,jgo),e(ws,eN),e(eN,Dgo),e(ws,Ggo),e(ws,oN),e(oN,Ogo),e(ws,Vgo),e(k,Xgo),e(k,As),e(As,Lie),e(Lie,zgo),e(As,Qgo),e(As,rN),e(rN,Wgo),e(As,Hgo),e(As,tN),e(tN,Ugo),e(As,Jgo),e(k,Ygo),e(k,Ls),e(Ls,yie),e(yie,Kgo),e(Ls,Zgo),e(Ls,aN),e(aN,eho),e(Ls,oho),e(Ls,nN),e(nN,rho),e(Ls,tho),e(k,aho),e(k,ys),e(ys,xie),e(xie,nho),e(ys,sho),e(ys,sN),e(sN,lho),e(ys,iho),e(ys,lN),e(lN,dho),e(ys,cho),e(k,fho),e(k,xs),e(xs,$ie),e($ie,mho),e(xs,gho),e(xs,iN),e(iN,hho),e(xs,pho),e(xs,dN),e(dN,_ho),e(xs,uho),e(k,bho),e(k,$s),e($s,kie),e(kie,vho),e($s,Fho),e($s,cN),e(cN,Tho),e($s,Mho),e($s,fN),e(fN,Eho),e($s,Cho),e(k,who),e(k,vh),e(vh,Sie),e(Sie,Aho),e(vh,Lho),e(vh,mN),e(mN,yho),e(vh,xho),e(k,$ho),e(k,ks),e(ks,Rie),e(Rie,kho),e(ks,Sho),e(ks,gN),e(gN,Rho),e(ks,Pho),e(ks,hN),e(hN,Bho),e(ks,Iho),e(k,Nho),e(k,Fh),e(Fh,Pie),e(Pie,qho),e(Fh,jho),e(Fh,pN),e(pN,Dho),e(Fh,Gho),e(k,Oho),e(k,Th),e(Th,Bie),e(Bie,Vho),e(Th,Xho),e(Th,_N),e(_N,zho),e(Th,Qho),e(k,Who),e(k,Mh),e(Mh,Iie),e(Iie,Hho),e(Mh,Uho),e(Mh,uN),e(uN,Jho),e(Mh,Yho),e(k,Kho),e(k,Eh),e(Eh,Nie),e(Nie,Zho),e(Eh,epo),e(Eh,bN),e(bN,opo),e(Eh,rpo),e(k,tpo),e(k,Ss),e(Ss,qie),e(qie,apo),e(Ss,npo),e(Ss,vN),e(vN,spo),e(Ss,lpo),e(Ss,FN),e(FN,ipo),e(Ss,dpo),e(k,cpo),e(k,Ch),e(Ch,jie),e(jie,fpo),e(Ch,mpo),e(Ch,TN),e(TN,gpo),e(Ch,hpo),e(k,ppo),e(k,Rs),e(Rs,Die),e(Die,_po),e(Rs,upo),e(Rs,MN),e(MN,bpo),e(Rs,vpo),e(Rs,EN),e(EN,Fpo),e(Rs,Tpo),e(k,Mpo),e(k,Ps),e(Ps,Gie),e(Gie,Epo),e(Ps,Cpo),e(Ps,CN),e(CN,wpo),e(Ps,Apo),e(Ps,wN),e(wN,Lpo),e(Ps,ypo),e(k,xpo),e(k,Bs),e(Bs,Oie),e(Oie,$po),e(Bs,kpo),e(Bs,AN),e(AN,Spo),e(Bs,Rpo),e(Bs,LN),e(LN,Ppo),e(Bs,Bpo),e(k,Ipo),e(k,Is),e(Is,Vie),e(Vie,Npo),e(Is,qpo),e(Is,yN),e(yN,jpo),e(Is,Dpo),e(Is,xN),e(xN,Gpo),e(Is,Opo),e(k,Vpo),e(k,Ns),e(Ns,Xie),e(Xie,Xpo),e(Ns,zpo),e(Ns,$N),e($N,Qpo),e(Ns,Wpo),e(Ns,kN),e(kN,Hpo),e(Ns,Upo),e(k,Jpo),e(k,qs),e(qs,zie),e(zie,Ypo),e(qs,Kpo),e(qs,SN),e(SN,Zpo),e(qs,e_o),e(qs,RN),e(RN,o_o),e(qs,r_o),e(k,t_o),e(k,wh),e(wh,Qie),e(Qie,a_o),e(wh,n_o),e(wh,PN),e(PN,s_o),e(wh,l_o),e(k,i_o),e(k,Ah),e(Ah,Wie),e(Wie,d_o),e(Ah,c_o),e(Ah,BN),e(BN,f_o),e(Ah,m_o),e(k,g_o),e(k,js),e(js,Hie),e(Hie,h_o),e(js,p_o),e(js,IN),e(IN,__o),e(js,u_o),e(js,NN),e(NN,b_o),e(js,v_o),e(k,F_o),e(k,Ds),e(Ds,Uie),e(Uie,T_o),e(Ds,M_o),e(Ds,qN),e(qN,E_o),e(Ds,C_o),e(Ds,jN),e(jN,w_o),e(Ds,A_o),e(k,L_o),e(k,Gs),e(Gs,Jie),e(Jie,y_o),e(Gs,x_o),e(Gs,DN),e(DN,$_o),e(Gs,k_o),e(Gs,GN),e(GN,S_o),e(Gs,R_o),e(k,P_o),e(k,Lh),e(Lh,Yie),e(Yie,B_o),e(Lh,I_o),e(Lh,ON),e(ON,N_o),e(Lh,q_o),e(k,j_o),e(k,yh),e(yh,Kie),e(Kie,D_o),e(yh,G_o),e(yh,VN),e(VN,O_o),e(yh,V_o),e(k,X_o),e(k,xh),e(xh,Zie),e(Zie,z_o),e(xh,Q_o),e(xh,XN),e(XN,W_o),e(xh,H_o),e(k,U_o),e(k,Os),e(Os,ede),e(ede,J_o),e(Os,Y_o),e(Os,zN),e(zN,K_o),e(Os,Z_o),e(Os,QN),e(QN,euo),e(Os,ouo),e(k,ruo),e(k,Vs),e(Vs,ode),e(ode,tuo),e(Vs,auo),e(Vs,WN),e(WN,nuo),e(Vs,suo),e(Vs,HN),e(HN,luo),e(Vs,iuo),e(k,duo),e(k,$h),e($h,rde),e(rde,cuo),e($h,fuo),e($h,UN),e(UN,muo),e($h,guo),e(k,huo),e(k,kh),e(kh,tde),e(tde,puo),e(kh,_uo),e(kh,JN),e(JN,uuo),e(kh,buo),e(k,vuo),e(k,Sh),e(Sh,ade),e(ade,Fuo),e(Sh,Tuo),e(Sh,YN),e(YN,Muo),e(Sh,Euo),e(k,Cuo),e(k,Xs),e(Xs,nde),e(nde,wuo),e(Xs,Auo),e(Xs,KN),e(KN,Luo),e(Xs,yuo),e(Xs,ZN),e(ZN,xuo),e(Xs,$uo),e(k,kuo),e(k,Rh),e(Rh,sde),e(sde,Suo),e(Rh,Ruo),e(Rh,eq),e(eq,Puo),e(Rh,Buo),e(k,Iuo),e(k,Ph),e(Ph,lde),e(lde,Nuo),e(Ph,quo),e(Ph,oq),e(oq,juo),e(Ph,Duo),e(k,Guo),e(k,zs),e(zs,ide),e(ide,Ouo),e(zs,Vuo),e(zs,rq),e(rq,Xuo),e(zs,zuo),e(zs,tq),e(tq,Quo),e(zs,Wuo),e(k,Huo),e(k,Qs),e(Qs,dde),e(dde,Uuo),e(Qs,Juo),e(Qs,aq),e(aq,Yuo),e(Qs,Kuo),e(Qs,nq),e(nq,Zuo),e(Qs,e1o),e(k,o1o),e(k,Ws),e(Ws,cde),e(cde,r1o),e(Ws,t1o),e(Ws,sq),e(sq,a1o),e(Ws,n1o),e(Ws,lq),e(lq,s1o),e(Ws,l1o),e(k,i1o),e(k,Hs),e(Hs,fde),e(fde,d1o),e(Hs,c1o),e(Hs,iq),e(iq,f1o),e(Hs,m1o),e(Hs,dq),e(dq,g1o),e(Hs,h1o),e(xr,p1o),M(Bh,xr,null),e(yo,_1o),e(yo,Ih),M(xL,Ih,null),e(Ih,u1o),e(Ih,mde),e(mde,b1o),b(f,YXe,u),b(f,Di,u),e(Di,Nh),e(Nh,gde),M($L,gde,null),e(Di,v1o),e(Di,hde),e(hde,F1o),b(f,KXe,u),b(f,xo,u),M(kL,xo,null),e(xo,T1o),e(xo,SL),e(SL,M1o),e(SL,cq),e(cq,E1o),e(SL,C1o),e(xo,w1o),e(xo,RL),e(RL,A1o),e(RL,pde),e(pde,L1o),e(RL,y1o),e(xo,x1o),e(xo,Ue),M(PL,Ue,null),e(Ue,$1o),e(Ue,_de),e(_de,k1o),e(Ue,S1o),e(Ue,Ba),e(Ba,R1o),e(Ba,ude),e(ude,P1o),e(Ba,B1o),e(Ba,bde),e(bde,I1o),e(Ba,N1o),e(Ba,vde),e(vde,q1o),e(Ba,j1o),e(Ue,D1o),e(Ue,J),e(J,qh),e(qh,Fde),e(Fde,G1o),e(qh,O1o),e(qh,fq),e(fq,V1o),e(qh,X1o),e(J,z1o),e(J,jh),e(jh,Tde),e(Tde,Q1o),e(jh,W1o),e(jh,mq),e(mq,H1o),e(jh,U1o),e(J,J1o),e(J,Dh),e(Dh,Mde),e(Mde,Y1o),e(Dh,K1o),e(Dh,gq),e(gq,Z1o),e(Dh,e4o),e(J,o4o),e(J,Gh),e(Gh,Ede),e(Ede,r4o),e(Gh,t4o),e(Gh,hq),e(hq,a4o),e(Gh,n4o),e(J,s4o),e(J,Oh),e(Oh,Cde),e(Cde,l4o),e(Oh,i4o),e(Oh,pq),e(pq,d4o),e(Oh,c4o),e(J,f4o),e(J,Vh),e(Vh,wde),e(wde,m4o),e(Vh,g4o),e(Vh,_q),e(_q,h4o),e(Vh,p4o),e(J,_4o),e(J,Xh),e(Xh,Ade),e(Ade,u4o),e(Xh,b4o),e(Xh,uq),e(uq,v4o),e(Xh,F4o),e(J,T4o),e(J,zh),e(zh,Lde),e(Lde,M4o),e(zh,E4o),e(zh,bq),e(bq,C4o),e(zh,w4o),e(J,A4o),e(J,Qh),e(Qh,yde),e(yde,L4o),e(Qh,y4o),e(Qh,vq),e(vq,x4o),e(Qh,$4o),e(J,k4o),e(J,Wh),e(Wh,xde),e(xde,S4o),e(Wh,R4o),e(Wh,Fq),e(Fq,P4o),e(Wh,B4o),e(J,I4o),e(J,Hh),e(Hh,$de),e($de,N4o),e(Hh,q4o),e(Hh,Tq),e(Tq,j4o),e(Hh,D4o),e(J,G4o),e(J,Uh),e(Uh,kde),e(kde,O4o),e(Uh,V4o),e(Uh,Mq),e(Mq,X4o),e(Uh,z4o),e(J,Q4o),e(J,Jh),e(Jh,Sde),e(Sde,W4o),e(Jh,H4o),e(Jh,Eq),e(Eq,U4o),e(Jh,J4o),e(J,Y4o),e(J,Yh),e(Yh,Rde),e(Rde,K4o),e(Yh,Z4o),e(Yh,Cq),e(Cq,e2o),e(Yh,o2o),e(J,r2o),e(J,Kh),e(Kh,Pde),e(Pde,t2o),e(Kh,a2o),e(Kh,wq),e(wq,n2o),e(Kh,s2o),e(J,l2o),e(J,Zh),e(Zh,Bde),e(Bde,i2o),e(Zh,d2o),e(Zh,Aq),e(Aq,c2o),e(Zh,f2o),e(J,m2o),e(J,ep),e(ep,Ide),e(Ide,g2o),e(ep,h2o),e(ep,Lq),e(Lq,p2o),e(ep,_2o),e(J,u2o),e(J,op),e(op,Nde),e(Nde,b2o),e(op,v2o),e(op,yq),e(yq,F2o),e(op,T2o),e(J,M2o),e(J,rp),e(rp,qde),e(qde,E2o),e(rp,C2o),e(rp,xq),e(xq,w2o),e(rp,A2o),e(J,L2o),e(J,tp),e(tp,jde),e(jde,y2o),e(tp,x2o),e(tp,$q),e($q,$2o),e(tp,k2o),e(J,S2o),e(J,ap),e(ap,Dde),e(Dde,R2o),e(ap,P2o),e(ap,kq),e(kq,B2o),e(ap,I2o),e(J,N2o),e(J,np),e(np,Gde),e(Gde,q2o),e(np,j2o),e(np,Sq),e(Sq,D2o),e(np,G2o),e(J,O2o),e(J,sp),e(sp,Ode),e(Ode,V2o),e(sp,X2o),e(sp,Rq),e(Rq,z2o),e(sp,Q2o),e(J,W2o),e(J,lp),e(lp,Vde),e(Vde,H2o),e(lp,U2o),e(lp,Pq),e(Pq,J2o),e(lp,Y2o),e(J,K2o),e(J,ip),e(ip,Xde),e(Xde,Z2o),e(ip,ebo),e(ip,Bq),e(Bq,obo),e(ip,rbo),e(J,tbo),e(J,dp),e(dp,zde),e(zde,abo),e(dp,nbo),e(dp,Iq),e(Iq,sbo),e(dp,lbo),e(J,ibo),e(J,cp),e(cp,Qde),e(Qde,dbo),e(cp,cbo),e(cp,Nq),e(Nq,fbo),e(cp,mbo),e(J,gbo),e(J,fp),e(fp,Wde),e(Wde,hbo),e(fp,pbo),e(fp,qq),e(qq,_bo),e(fp,ubo),e(J,bbo),e(J,mp),e(mp,Hde),e(Hde,vbo),e(mp,Fbo),e(mp,jq),e(jq,Tbo),e(mp,Mbo),e(J,Ebo),e(J,gp),e(gp,Ude),e(Ude,Cbo),e(gp,wbo),e(gp,Dq),e(Dq,Abo),e(gp,Lbo),e(J,ybo),e(J,hp),e(hp,Jde),e(Jde,xbo),e(hp,$bo),e(hp,Gq),e(Gq,kbo),e(hp,Sbo),e(J,Rbo),e(J,pp),e(pp,Yde),e(Yde,Pbo),e(pp,Bbo),e(pp,Oq),e(Oq,Ibo),e(pp,Nbo),e(J,qbo),e(J,_p),e(_p,Kde),e(Kde,jbo),e(_p,Dbo),e(_p,Vq),e(Vq,Gbo),e(_p,Obo),e(J,Vbo),e(J,up),e(up,Zde),e(Zde,Xbo),e(up,zbo),e(up,Xq),e(Xq,Qbo),e(up,Wbo),e(J,Hbo),e(J,bp),e(bp,ece),e(ece,Ubo),e(bp,Jbo),e(bp,zq),e(zq,Ybo),e(bp,Kbo),e(Ue,Zbo),M(vp,Ue,null),e(Ue,evo),M(Fp,Ue,null),e(xo,ovo),e(xo,Tp),M(BL,Tp,null),e(Tp,rvo),e(Tp,oce),e(oce,tvo),b(f,ZXe,u),b(f,Gi,u),e(Gi,Mp),e(Mp,rce),M(IL,rce,null),e(Gi,avo),e(Gi,tce),e(tce,nvo),b(f,eze,u),b(f,$o,u),M(NL,$o,null),e($o,svo),e($o,qL),e(qL,lvo),e(qL,Qq),e(Qq,ivo),e(qL,dvo),e($o,cvo),e($o,jL),e(jL,fvo),e(jL,ace),e(ace,mvo),e(jL,gvo),e($o,hvo),e($o,Je),M(DL,Je,null),e(Je,pvo),e(Je,nce),e(nce,_vo),e(Je,uvo),e(Je,Oi),e(Oi,bvo),e(Oi,sce),e(sce,vvo),e(Oi,Fvo),e(Oi,lce),e(lce,Tvo),e(Oi,Mvo),e(Je,Evo),e(Je,pe),e(pe,Ep),e(Ep,ice),e(ice,Cvo),e(Ep,wvo),e(Ep,Wq),e(Wq,Avo),e(Ep,Lvo),e(pe,yvo),e(pe,Cp),e(Cp,dce),e(dce,xvo),e(Cp,$vo),e(Cp,Hq),e(Hq,kvo),e(Cp,Svo),e(pe,Rvo),e(pe,wp),e(wp,cce),e(cce,Pvo),e(wp,Bvo),e(wp,Uq),e(Uq,Ivo),e(wp,Nvo),e(pe,qvo),e(pe,Ap),e(Ap,fce),e(fce,jvo),e(Ap,Dvo),e(Ap,Jq),e(Jq,Gvo),e(Ap,Ovo),e(pe,Vvo),e(pe,Lp),e(Lp,mce),e(mce,Xvo),e(Lp,zvo),e(Lp,Yq),e(Yq,Qvo),e(Lp,Wvo),e(pe,Hvo),e(pe,yp),e(yp,gce),e(gce,Uvo),e(yp,Jvo),e(yp,Kq),e(Kq,Yvo),e(yp,Kvo),e(pe,Zvo),e(pe,xp),e(xp,hce),e(hce,eFo),e(xp,oFo),e(xp,Zq),e(Zq,rFo),e(xp,tFo),e(pe,aFo),e(pe,$p),e($p,pce),e(pce,nFo),e($p,sFo),e($p,ej),e(ej,lFo),e($p,iFo),e(pe,dFo),e(pe,kp),e(kp,_ce),e(_ce,cFo),e(kp,fFo),e(kp,oj),e(oj,mFo),e(kp,gFo),e(pe,hFo),e(pe,Sp),e(Sp,uce),e(uce,pFo),e(Sp,_Fo),e(Sp,rj),e(rj,uFo),e(Sp,bFo),e(pe,vFo),e(pe,Rp),e(Rp,bce),e(bce,FFo),e(Rp,TFo),e(Rp,tj),e(tj,MFo),e(Rp,EFo),e(pe,CFo),e(pe,Pp),e(Pp,vce),e(vce,wFo),e(Pp,AFo),e(Pp,aj),e(aj,LFo),e(Pp,yFo),e(pe,xFo),e(pe,Bp),e(Bp,Fce),e(Fce,$Fo),e(Bp,kFo),e(Bp,nj),e(nj,SFo),e(Bp,RFo),e(pe,PFo),e(pe,Ip),e(Ip,Tce),e(Tce,BFo),e(Ip,IFo),e(Ip,sj),e(sj,NFo),e(Ip,qFo),e(pe,jFo),e(pe,Np),e(Np,Mce),e(Mce,DFo),e(Np,GFo),e(Np,lj),e(lj,OFo),e(Np,VFo),e(pe,XFo),e(pe,qp),e(qp,Ece),e(Ece,zFo),e(qp,QFo),e(qp,ij),e(ij,WFo),e(qp,HFo),e(pe,UFo),e(pe,jp),e(jp,Cce),e(Cce,JFo),e(jp,YFo),e(jp,dj),e(dj,KFo),e(jp,ZFo),e(pe,e6o),e(pe,Dp),e(Dp,wce),e(wce,o6o),e(Dp,r6o),e(Dp,cj),e(cj,t6o),e(Dp,a6o),e(Je,n6o),M(Gp,Je,null),e(Je,s6o),M(Op,Je,null),e($o,l6o),e($o,Vp),M(GL,Vp,null),e(Vp,i6o),e(Vp,Ace),e(Ace,d6o),b(f,oze,u),b(f,Vi,u),e(Vi,Xp),e(Xp,Lce),M(OL,Lce,null),e(Vi,c6o),e(Vi,yce),e(yce,f6o),b(f,rze,u),b(f,ko,u),M(VL,ko,null),e(ko,m6o),e(ko,Xi),e(Xi,g6o),e(Xi,fj),e(fj,h6o),e(Xi,p6o),e(Xi,mj),e(mj,_6o),e(Xi,u6o),e(ko,b6o),e(ko,XL),e(XL,v6o),e(XL,xce),e(xce,F6o),e(XL,T6o),e(ko,M6o),e(ko,it),M(zL,it,null),e(it,E6o),e(it,$ce),e($ce,C6o),e(it,w6o),e(it,zi),e(zi,A6o),e(zi,kce),e(kce,L6o),e(zi,y6o),e(zi,gj),e(gj,x6o),e(zi,$6o),e(it,k6o),M(zp,it,null),e(ko,S6o),e(ko,Ye),M(QL,Ye,null),e(Ye,R6o),e(Ye,Sce),e(Sce,P6o),e(Ye,B6o),e(Ye,Ia),e(Ia,I6o),e(Ia,Rce),e(Rce,N6o),e(Ia,q6o),e(Ia,Pce),e(Pce,j6o),e(Ia,D6o),e(Ia,Bce),e(Bce,G6o),e(Ia,O6o),e(Ye,V6o),e(Ye,y),e(y,Qp),e(Qp,Ice),e(Ice,X6o),e(Qp,z6o),e(Qp,hj),e(hj,Q6o),e(Qp,W6o),e(y,H6o),e(y,Wp),e(Wp,Nce),e(Nce,U6o),e(Wp,J6o),e(Wp,pj),e(pj,Y6o),e(Wp,K6o),e(y,Z6o),e(y,Hp),e(Hp,qce),e(qce,eTo),e(Hp,oTo),e(Hp,_j),e(_j,rTo),e(Hp,tTo),e(y,aTo),e(y,Up),e(Up,jce),e(jce,nTo),e(Up,sTo),e(Up,uj),e(uj,lTo),e(Up,iTo),e(y,dTo),e(y,Jp),e(Jp,Dce),e(Dce,cTo),e(Jp,fTo),e(Jp,bj),e(bj,mTo),e(Jp,gTo),e(y,hTo),e(y,Yp),e(Yp,Gce),e(Gce,pTo),e(Yp,_To),e(Yp,vj),e(vj,uTo),e(Yp,bTo),e(y,vTo),e(y,Kp),e(Kp,Oce),e(Oce,FTo),e(Kp,TTo),e(Kp,Fj),e(Fj,MTo),e(Kp,ETo),e(y,CTo),e(y,Zp),e(Zp,Vce),e(Vce,wTo),e(Zp,ATo),e(Zp,Tj),e(Tj,LTo),e(Zp,yTo),e(y,xTo),e(y,e_),e(e_,Xce),e(Xce,$To),e(e_,kTo),e(e_,Mj),e(Mj,STo),e(e_,RTo),e(y,PTo),e(y,o_),e(o_,zce),e(zce,BTo),e(o_,ITo),e(o_,Ej),e(Ej,NTo),e(o_,qTo),e(y,jTo),e(y,r_),e(r_,Qce),e(Qce,DTo),e(r_,GTo),e(r_,Cj),e(Cj,OTo),e(r_,VTo),e(y,XTo),e(y,t_),e(t_,Wce),e(Wce,zTo),e(t_,QTo),e(t_,wj),e(wj,WTo),e(t_,HTo),e(y,UTo),e(y,a_),e(a_,Hce),e(Hce,JTo),e(a_,YTo),e(a_,Aj),e(Aj,KTo),e(a_,ZTo),e(y,e7o),e(y,n_),e(n_,Uce),e(Uce,o7o),e(n_,r7o),e(n_,Lj),e(Lj,t7o),e(n_,a7o),e(y,n7o),e(y,s_),e(s_,Jce),e(Jce,s7o),e(s_,l7o),e(s_,yj),e(yj,i7o),e(s_,d7o),e(y,c7o),e(y,l_),e(l_,Yce),e(Yce,f7o),e(l_,m7o),e(l_,xj),e(xj,g7o),e(l_,h7o),e(y,p7o),e(y,i_),e(i_,Kce),e(Kce,_7o),e(i_,u7o),e(i_,$j),e($j,b7o),e(i_,v7o),e(y,F7o),e(y,d_),e(d_,Zce),e(Zce,T7o),e(d_,M7o),e(d_,kj),e(kj,E7o),e(d_,C7o),e(y,w7o),e(y,c_),e(c_,efe),e(efe,A7o),e(c_,L7o),e(c_,Sj),e(Sj,y7o),e(c_,x7o),e(y,$7o),e(y,f_),e(f_,ofe),e(ofe,k7o),e(f_,S7o),e(f_,Rj),e(Rj,R7o),e(f_,P7o),e(y,B7o),e(y,m_),e(m_,rfe),e(rfe,I7o),e(m_,N7o),e(m_,Pj),e(Pj,q7o),e(m_,j7o),e(y,D7o),e(y,g_),e(g_,tfe),e(tfe,G7o),e(g_,O7o),e(g_,Bj),e(Bj,V7o),e(g_,X7o),e(y,z7o),e(y,h_),e(h_,afe),e(afe,Q7o),e(h_,W7o),e(h_,Ij),e(Ij,H7o),e(h_,U7o),e(y,J7o),e(y,p_),e(p_,nfe),e(nfe,Y7o),e(p_,K7o),e(p_,Nj),e(Nj,Z7o),e(p_,e9o),e(y,o9o),e(y,__),e(__,sfe),e(sfe,r9o),e(__,t9o),e(__,qj),e(qj,a9o),e(__,n9o),e(y,s9o),e(y,u_),e(u_,lfe),e(lfe,l9o),e(u_,i9o),e(u_,jj),e(jj,d9o),e(u_,c9o),e(y,f9o),e(y,b_),e(b_,ife),e(ife,m9o),e(b_,g9o),e(b_,Dj),e(Dj,h9o),e(b_,p9o),e(y,_9o),e(y,v_),e(v_,dfe),e(dfe,u9o),e(v_,b9o),e(v_,Gj),e(Gj,v9o),e(v_,F9o),e(y,T9o),e(y,F_),e(F_,cfe),e(cfe,M9o),e(F_,E9o),e(F_,Oj),e(Oj,C9o),e(F_,w9o),e(y,A9o),e(y,T_),e(T_,ffe),e(ffe,L9o),e(T_,y9o),e(T_,Vj),e(Vj,x9o),e(T_,$9o),e(y,k9o),e(y,M_),e(M_,mfe),e(mfe,S9o),e(M_,R9o),e(M_,Xj),e(Xj,P9o),e(M_,B9o),e(y,I9o),e(y,E_),e(E_,gfe),e(gfe,N9o),e(E_,q9o),e(E_,zj),e(zj,j9o),e(E_,D9o),e(y,G9o),e(y,C_),e(C_,hfe),e(hfe,O9o),e(C_,V9o),e(C_,Qj),e(Qj,X9o),e(C_,z9o),e(y,Q9o),e(y,w_),e(w_,pfe),e(pfe,W9o),e(w_,H9o),e(w_,Wj),e(Wj,U9o),e(w_,J9o),e(y,Y9o),e(y,Us),e(Us,_fe),e(_fe,K9o),e(Us,Z9o),e(Us,Hj),e(Hj,eMo),e(Us,oMo),e(Us,Uj),e(Uj,rMo),e(Us,tMo),e(y,aMo),e(y,A_),e(A_,ufe),e(ufe,nMo),e(A_,sMo),e(A_,Jj),e(Jj,lMo),e(A_,iMo),e(y,dMo),e(y,L_),e(L_,bfe),e(bfe,cMo),e(L_,fMo),e(L_,Yj),e(Yj,mMo),e(L_,gMo),e(y,hMo),e(y,y_),e(y_,vfe),e(vfe,pMo),e(y_,_Mo),e(y_,Kj),e(Kj,uMo),e(y_,bMo),e(y,vMo),e(y,x_),e(x_,Ffe),e(Ffe,FMo),e(x_,TMo),e(x_,Zj),e(Zj,MMo),e(x_,EMo),e(y,CMo),e(y,$_),e($_,Tfe),e(Tfe,wMo),e($_,AMo),e($_,eD),e(eD,LMo),e($_,yMo),e(y,xMo),e(y,k_),e(k_,Mfe),e(Mfe,$Mo),e(k_,kMo),e(k_,oD),e(oD,SMo),e(k_,RMo),e(y,PMo),e(y,S_),e(S_,Efe),e(Efe,BMo),e(S_,IMo),e(S_,rD),e(rD,NMo),e(S_,qMo),e(y,jMo),e(y,R_),e(R_,Cfe),e(Cfe,DMo),e(R_,GMo),e(R_,tD),e(tD,OMo),e(R_,VMo),e(y,XMo),e(y,P_),e(P_,wfe),e(wfe,zMo),e(P_,QMo),e(P_,aD),e(aD,WMo),e(P_,HMo),e(y,UMo),e(y,B_),e(B_,Afe),e(Afe,JMo),e(B_,YMo),e(B_,nD),e(nD,KMo),e(B_,ZMo),e(y,eEo),e(y,I_),e(I_,Lfe),e(Lfe,oEo),e(I_,rEo),e(I_,sD),e(sD,tEo),e(I_,aEo),e(y,nEo),e(y,N_),e(N_,yfe),e(yfe,sEo),e(N_,lEo),e(N_,lD),e(lD,iEo),e(N_,dEo),e(y,cEo),e(y,q_),e(q_,xfe),e(xfe,fEo),e(q_,mEo),e(q_,iD),e(iD,gEo),e(q_,hEo),e(y,pEo),e(y,j_),e(j_,$fe),e($fe,_Eo),e(j_,uEo),e(j_,dD),e(dD,bEo),e(j_,vEo),e(y,FEo),e(y,D_),e(D_,kfe),e(kfe,TEo),e(D_,MEo),e(D_,cD),e(cD,EEo),e(D_,CEo),e(y,wEo),e(y,G_),e(G_,Sfe),e(Sfe,AEo),e(G_,LEo),e(G_,fD),e(fD,yEo),e(G_,xEo),e(y,$Eo),e(y,O_),e(O_,Rfe),e(Rfe,kEo),e(O_,SEo),e(O_,mD),e(mD,REo),e(O_,PEo),e(y,BEo),e(y,V_),e(V_,Pfe),e(Pfe,IEo),e(V_,NEo),e(V_,gD),e(gD,qEo),e(V_,jEo),e(y,DEo),e(y,X_),e(X_,Bfe),e(Bfe,GEo),e(X_,OEo),e(X_,hD),e(hD,VEo),e(X_,XEo),e(y,zEo),e(y,z_),e(z_,Ife),e(Ife,QEo),e(z_,WEo),e(z_,pD),e(pD,HEo),e(z_,UEo),e(y,JEo),e(y,Q_),e(Q_,Nfe),e(Nfe,YEo),e(Q_,KEo),e(Q_,_D),e(_D,ZEo),e(Q_,eCo),e(y,oCo),e(y,W_),e(W_,qfe),e(qfe,rCo),e(W_,tCo),e(W_,uD),e(uD,aCo),e(W_,nCo),e(y,sCo),e(y,H_),e(H_,jfe),e(jfe,lCo),e(H_,iCo),e(H_,bD),e(bD,dCo),e(H_,cCo),e(y,fCo),e(y,U_),e(U_,Dfe),e(Dfe,mCo),e(U_,gCo),e(U_,vD),e(vD,hCo),e(U_,pCo),e(y,_Co),e(y,J_),e(J_,Gfe),e(Gfe,uCo),e(J_,bCo),e(J_,FD),e(FD,vCo),e(J_,FCo),e(y,TCo),e(y,Y_),e(Y_,Ofe),e(Ofe,MCo),e(Y_,ECo),e(Y_,TD),e(TD,CCo),e(Y_,wCo),e(y,ACo),e(y,K_),e(K_,Vfe),e(Vfe,LCo),e(K_,yCo),e(K_,MD),e(MD,xCo),e(K_,$Co),e(y,kCo),e(y,Z_),e(Z_,Xfe),e(Xfe,SCo),e(Z_,RCo),e(Z_,ED),e(ED,PCo),e(Z_,BCo),e(y,ICo),e(y,eu),e(eu,zfe),e(zfe,NCo),e(eu,qCo),e(eu,CD),e(CD,jCo),e(eu,DCo),e(y,GCo),e(y,ou),e(ou,Qfe),e(Qfe,OCo),e(ou,VCo),e(ou,wD),e(wD,XCo),e(ou,zCo),e(y,QCo),e(y,ru),e(ru,Wfe),e(Wfe,WCo),e(ru,HCo),e(ru,AD),e(AD,UCo),e(ru,JCo),e(y,YCo),e(y,tu),e(tu,Hfe),e(Hfe,KCo),e(tu,ZCo),e(tu,LD),e(LD,e5o),e(tu,o5o),e(y,r5o),e(y,au),e(au,Ufe),e(Ufe,t5o),e(au,a5o),e(au,yD),e(yD,n5o),e(au,s5o),e(y,l5o),e(y,nu),e(nu,Jfe),e(Jfe,i5o),e(nu,d5o),e(nu,xD),e(xD,c5o),e(nu,f5o),e(y,m5o),e(y,su),e(su,Yfe),e(Yfe,g5o),e(su,h5o),e(su,$D),e($D,p5o),e(su,_5o),e(y,u5o),e(y,lu),e(lu,Kfe),e(Kfe,b5o),e(lu,v5o),e(lu,kD),e(kD,F5o),e(lu,T5o),e(y,M5o),e(y,iu),e(iu,Zfe),e(Zfe,E5o),e(iu,C5o),e(iu,SD),e(SD,w5o),e(iu,A5o),e(y,L5o),e(y,du),e(du,eme),e(eme,y5o),e(du,x5o),e(du,RD),e(RD,$5o),e(du,k5o),e(y,S5o),e(y,cu),e(cu,ome),e(ome,R5o),e(cu,P5o),e(cu,PD),e(PD,B5o),e(cu,I5o),e(y,N5o),e(y,fu),e(fu,rme),e(rme,q5o),e(fu,j5o),e(fu,BD),e(BD,D5o),e(fu,G5o),e(y,O5o),e(y,mu),e(mu,tme),e(tme,V5o),e(mu,X5o),e(mu,ID),e(ID,z5o),e(mu,Q5o),e(y,W5o),e(y,gu),e(gu,ame),e(ame,H5o),e(gu,U5o),e(gu,ND),e(ND,J5o),e(gu,Y5o),e(y,K5o),e(y,hu),e(hu,nme),e(nme,Z5o),e(hu,e3o),e(hu,qD),e(qD,o3o),e(hu,r3o),e(y,t3o),e(y,pu),e(pu,sme),e(sme,a3o),e(pu,n3o),e(pu,jD),e(jD,s3o),e(pu,l3o),e(y,i3o),e(y,_u),e(_u,lme),e(lme,d3o),e(_u,c3o),e(_u,DD),e(DD,f3o),e(_u,m3o),e(y,g3o),e(y,uu),e(uu,ime),e(ime,h3o),e(uu,p3o),e(uu,GD),e(GD,_3o),e(uu,u3o),e(y,b3o),e(y,bu),e(bu,dme),e(dme,v3o),e(bu,F3o),e(bu,OD),e(OD,T3o),e(bu,M3o),e(y,E3o),e(y,vu),e(vu,cme),e(cme,C3o),e(vu,w3o),e(vu,VD),e(VD,A3o),e(vu,L3o),e(y,y3o),e(y,Fu),e(Fu,fme),e(fme,x3o),e(Fu,$3o),e(Fu,XD),e(XD,k3o),e(Fu,S3o),e(y,R3o),e(y,Tu),e(Tu,mme),e(mme,P3o),e(Tu,B3o),e(Tu,zD),e(zD,I3o),e(Tu,N3o),e(y,q3o),e(y,Mu),e(Mu,gme),e(gme,j3o),e(Mu,D3o),e(Mu,QD),e(QD,G3o),e(Mu,O3o),e(y,V3o),e(y,Eu),e(Eu,hme),e(hme,X3o),e(Eu,z3o),e(Eu,WD),e(WD,Q3o),e(Eu,W3o),e(y,H3o),e(y,Cu),e(Cu,pme),e(pme,U3o),e(Cu,J3o),e(Cu,HD),e(HD,Y3o),e(Cu,K3o),e(y,Z3o),e(y,wu),e(wu,_me),e(_me,e0o),e(wu,o0o),e(wu,UD),e(UD,r0o),e(wu,t0o),e(y,a0o),e(y,Au),e(Au,ume),e(ume,n0o),e(Au,s0o),e(Au,JD),e(JD,l0o),e(Au,i0o),e(y,d0o),e(y,Lu),e(Lu,bme),e(bme,c0o),e(Lu,f0o),e(Lu,YD),e(YD,m0o),e(Lu,g0o),e(y,h0o),e(y,yu),e(yu,vme),e(vme,p0o),e(yu,_0o),e(yu,KD),e(KD,u0o),e(yu,b0o),e(y,v0o),e(y,xu),e(xu,Fme),e(Fme,F0o),e(xu,T0o),e(xu,ZD),e(ZD,M0o),e(xu,E0o),e(y,C0o),e(y,$u),e($u,Tme),e(Tme,w0o),e($u,A0o),e($u,eG),e(eG,L0o),e($u,y0o),e(y,x0o),e(y,ku),e(ku,Mme),e(Mme,$0o),e(ku,k0o),e(ku,oG),e(oG,S0o),e(ku,R0o),e(y,P0o),e(y,Su),e(Su,Eme),e(Eme,B0o),e(Su,I0o),e(Su,rG),e(rG,N0o),e(Su,q0o),e(y,j0o),e(y,Ru),e(Ru,Cme),e(Cme,D0o),e(Ru,G0o),e(Ru,tG),e(tG,O0o),e(Ru,V0o),e(y,X0o),e(y,Pu),e(Pu,wme),e(wme,z0o),e(Pu,Q0o),e(Pu,aG),e(aG,W0o),e(Pu,H0o),e(y,U0o),e(y,Bu),e(Bu,Ame),e(Ame,J0o),e(Bu,Y0o),e(Bu,nG),e(nG,K0o),e(Bu,Z0o),e(y,ewo),e(y,Iu),e(Iu,Lme),e(Lme,owo),e(Iu,rwo),e(Iu,sG),e(sG,two),e(Iu,awo),e(y,nwo),e(y,Nu),e(Nu,yme),e(yme,swo),e(Nu,lwo),e(Nu,lG),e(lG,iwo),e(Nu,dwo),e(y,cwo),e(y,qu),e(qu,xme),e(xme,fwo),e(qu,mwo),e(qu,iG),e(iG,gwo),e(qu,hwo),e(y,pwo),e(y,ju),e(ju,$me),e($me,_wo),e(ju,uwo),e(ju,dG),e(dG,bwo),e(ju,vwo),e(y,Fwo),e(y,Du),e(Du,kme),e(kme,Two),e(Du,Mwo),e(Du,cG),e(cG,Ewo),e(Du,Cwo),e(y,wwo),e(y,Gu),e(Gu,Sme),e(Sme,Awo),e(Gu,Lwo),e(Gu,fG),e(fG,ywo),e(Gu,xwo),e(y,$wo),e(y,Ou),e(Ou,Rme),e(Rme,kwo),e(Ou,Swo),e(Ou,mG),e(mG,Rwo),e(Ou,Pwo),e(y,Bwo),e(y,Vu),e(Vu,Pme),e(Pme,Iwo),e(Vu,Nwo),e(Vu,gG),e(gG,qwo),e(Vu,jwo),e(y,Dwo),e(y,Xu),e(Xu,Bme),e(Bme,Gwo),e(Xu,Owo),e(Xu,hG),e(hG,Vwo),e(Xu,Xwo),e(y,zwo),e(y,zu),e(zu,Ime),e(Ime,Qwo),e(zu,Wwo),e(zu,pG),e(pG,Hwo),e(zu,Uwo),e(y,Jwo),e(y,Qu),e(Qu,Nme),e(Nme,Ywo),e(Qu,Kwo),e(Qu,_G),e(_G,Zwo),e(Qu,eAo),e(y,oAo),e(y,Wu),e(Wu,qme),e(qme,rAo),e(Wu,tAo),e(Wu,uG),e(uG,aAo),e(Wu,nAo),e(y,sAo),e(y,Hu),e(Hu,jme),e(jme,lAo),e(Hu,iAo),e(Hu,bG),e(bG,dAo),e(Hu,cAo),e(y,fAo),e(y,Uu),e(Uu,Dme),e(Dme,mAo),e(Uu,gAo),e(Uu,vG),e(vG,hAo),e(Uu,pAo),e(Ye,_Ao),e(Ye,Ju),e(Ju,uAo),e(Ju,Gme),e(Gme,bAo),e(Ju,vAo),e(Ju,Ome),e(Ome,FAo),e(Ye,TAo),M(Yu,Ye,null),b(f,tze,u),b(f,Qi,u),e(Qi,Ku),e(Ku,Vme),M(WL,Vme,null),e(Qi,MAo),e(Qi,Xme),e(Xme,EAo),b(f,aze,u),b(f,So,u),M(HL,So,null),e(So,CAo),e(So,Wi),e(Wi,wAo),e(Wi,FG),e(FG,AAo),e(Wi,LAo),e(Wi,TG),e(TG,yAo),e(Wi,xAo),e(So,$Ao),e(So,UL),e(UL,kAo),e(UL,zme),e(zme,SAo),e(UL,RAo),e(So,PAo),e(So,dt),M(JL,dt,null),e(dt,BAo),e(dt,Qme),e(Qme,IAo),e(dt,NAo),e(dt,Hi),e(Hi,qAo),e(Hi,Wme),e(Wme,jAo),e(Hi,DAo),e(Hi,MG),e(MG,GAo),e(Hi,OAo),e(dt,VAo),M(Zu,dt,null),e(So,XAo),e(So,Ke),M(YL,Ke,null),e(Ke,zAo),e(Ke,Hme),e(Hme,QAo),e(Ke,WAo),e(Ke,Na),e(Na,HAo),e(Na,Ume),e(Ume,UAo),e(Na,JAo),e(Na,Jme),e(Jme,YAo),e(Na,KAo),e(Na,Yme),e(Yme,ZAo),e(Na,eLo),e(Ke,oLo),e(Ke,G),e(G,e1),e(e1,Kme),e(Kme,rLo),e(e1,tLo),e(e1,EG),e(EG,aLo),e(e1,nLo),e(G,sLo),e(G,o1),e(o1,Zme),e(Zme,lLo),e(o1,iLo),e(o1,CG),e(CG,dLo),e(o1,cLo),e(G,fLo),e(G,r1),e(r1,ege),e(ege,mLo),e(r1,gLo),e(r1,wG),e(wG,hLo),e(r1,pLo),e(G,_Lo),e(G,t1),e(t1,oge),e(oge,uLo),e(t1,bLo),e(t1,AG),e(AG,vLo),e(t1,FLo),e(G,TLo),e(G,a1),e(a1,rge),e(rge,MLo),e(a1,ELo),e(a1,LG),e(LG,CLo),e(a1,wLo),e(G,ALo),e(G,n1),e(n1,tge),e(tge,LLo),e(n1,yLo),e(n1,yG),e(yG,xLo),e(n1,$Lo),e(G,kLo),e(G,s1),e(s1,age),e(age,SLo),e(s1,RLo),e(s1,xG),e(xG,PLo),e(s1,BLo),e(G,ILo),e(G,l1),e(l1,nge),e(nge,NLo),e(l1,qLo),e(l1,$G),e($G,jLo),e(l1,DLo),e(G,GLo),e(G,i1),e(i1,sge),e(sge,OLo),e(i1,VLo),e(i1,kG),e(kG,XLo),e(i1,zLo),e(G,QLo),e(G,d1),e(d1,lge),e(lge,WLo),e(d1,HLo),e(d1,SG),e(SG,ULo),e(d1,JLo),e(G,YLo),e(G,c1),e(c1,ige),e(ige,KLo),e(c1,ZLo),e(c1,RG),e(RG,eyo),e(c1,oyo),e(G,ryo),e(G,f1),e(f1,dge),e(dge,tyo),e(f1,ayo),e(f1,PG),e(PG,nyo),e(f1,syo),e(G,lyo),e(G,m1),e(m1,cge),e(cge,iyo),e(m1,dyo),e(m1,BG),e(BG,cyo),e(m1,fyo),e(G,myo),e(G,g1),e(g1,fge),e(fge,gyo),e(g1,hyo),e(g1,IG),e(IG,pyo),e(g1,_yo),e(G,uyo),e(G,h1),e(h1,mge),e(mge,byo),e(h1,vyo),e(h1,NG),e(NG,Fyo),e(h1,Tyo),e(G,Myo),e(G,p1),e(p1,gge),e(gge,Eyo),e(p1,Cyo),e(p1,qG),e(qG,wyo),e(p1,Ayo),e(G,Lyo),e(G,_1),e(_1,hge),e(hge,yyo),e(_1,xyo),e(_1,jG),e(jG,$yo),e(_1,kyo),e(G,Syo),e(G,u1),e(u1,pge),e(pge,Ryo),e(u1,Pyo),e(u1,DG),e(DG,Byo),e(u1,Iyo),e(G,Nyo),e(G,b1),e(b1,_ge),e(_ge,qyo),e(b1,jyo),e(b1,GG),e(GG,Dyo),e(b1,Gyo),e(G,Oyo),e(G,v1),e(v1,uge),e(uge,Vyo),e(v1,Xyo),e(v1,OG),e(OG,zyo),e(v1,Qyo),e(G,Wyo),e(G,F1),e(F1,bge),e(bge,Hyo),e(F1,Uyo),e(F1,VG),e(VG,Jyo),e(F1,Yyo),e(G,Kyo),e(G,T1),e(T1,vge),e(vge,Zyo),e(T1,e8o),e(T1,XG),e(XG,o8o),e(T1,r8o),e(G,t8o),e(G,M1),e(M1,Fge),e(Fge,a8o),e(M1,n8o),e(M1,zG),e(zG,s8o),e(M1,l8o),e(G,i8o),e(G,E1),e(E1,Tge),e(Tge,d8o),e(E1,c8o),e(E1,QG),e(QG,f8o),e(E1,m8o),e(G,g8o),e(G,C1),e(C1,Mge),e(Mge,h8o),e(C1,p8o),e(C1,WG),e(WG,_8o),e(C1,u8o),e(G,b8o),e(G,w1),e(w1,Ege),e(Ege,v8o),e(w1,F8o),e(w1,HG),e(HG,T8o),e(w1,M8o),e(G,E8o),e(G,A1),e(A1,Cge),e(Cge,C8o),e(A1,w8o),e(A1,UG),e(UG,A8o),e(A1,L8o),e(G,y8o),e(G,L1),e(L1,wge),e(wge,x8o),e(L1,$8o),e(L1,JG),e(JG,k8o),e(L1,S8o),e(G,R8o),e(G,y1),e(y1,Age),e(Age,P8o),e(y1,B8o),e(y1,YG),e(YG,I8o),e(y1,N8o),e(G,q8o),e(G,x1),e(x1,Lge),e(Lge,j8o),e(x1,D8o),e(x1,KG),e(KG,G8o),e(x1,O8o),e(G,V8o),e(G,$1),e($1,yge),e(yge,X8o),e($1,z8o),e($1,ZG),e(ZG,Q8o),e($1,W8o),e(G,H8o),e(G,k1),e(k1,xge),e(xge,U8o),e(k1,J8o),e(k1,eO),e(eO,Y8o),e(k1,K8o),e(G,Z8o),e(G,S1),e(S1,$ge),e($ge,exo),e(S1,oxo),e(S1,oO),e(oO,rxo),e(S1,txo),e(G,axo),e(G,R1),e(R1,kge),e(kge,nxo),e(R1,sxo),e(R1,rO),e(rO,lxo),e(R1,ixo),e(G,dxo),e(G,P1),e(P1,Sge),e(Sge,cxo),e(P1,fxo),e(P1,tO),e(tO,mxo),e(P1,gxo),e(G,hxo),e(G,B1),e(B1,Rge),e(Rge,pxo),e(B1,_xo),e(B1,aO),e(aO,uxo),e(B1,bxo),e(G,vxo),e(G,I1),e(I1,Pge),e(Pge,Fxo),e(I1,Txo),e(I1,nO),e(nO,Mxo),e(I1,Exo),e(G,Cxo),e(G,N1),e(N1,Bge),e(Bge,wxo),e(N1,Axo),e(N1,sO),e(sO,Lxo),e(N1,yxo),e(G,xxo),e(G,q1),e(q1,Ige),e(Ige,$xo),e(q1,kxo),e(q1,lO),e(lO,Sxo),e(q1,Rxo),e(G,Pxo),e(G,j1),e(j1,Nge),e(Nge,Bxo),e(j1,Ixo),e(j1,iO),e(iO,Nxo),e(j1,qxo),e(G,jxo),e(G,D1),e(D1,qge),e(qge,Dxo),e(D1,Gxo),e(D1,dO),e(dO,Oxo),e(D1,Vxo),e(G,Xxo),e(G,G1),e(G1,jge),e(jge,zxo),e(G1,Qxo),e(G1,cO),e(cO,Wxo),e(G1,Hxo),e(G,Uxo),e(G,O1),e(O1,Dge),e(Dge,Jxo),e(O1,Yxo),e(O1,fO),e(fO,Kxo),e(O1,Zxo),e(G,e$o),e(G,V1),e(V1,Gge),e(Gge,o$o),e(V1,r$o),e(V1,mO),e(mO,t$o),e(V1,a$o),e(G,n$o),e(G,X1),e(X1,Oge),e(Oge,s$o),e(X1,l$o),e(X1,gO),e(gO,i$o),e(X1,d$o),e(Ke,c$o),e(Ke,z1),e(z1,f$o),e(z1,Vge),e(Vge,m$o),e(z1,g$o),e(z1,Xge),e(Xge,h$o),e(Ke,p$o),M(Q1,Ke,null),b(f,nze,u),b(f,Ui,u),e(Ui,W1),e(W1,zge),M(KL,zge,null),e(Ui,_$o),e(Ui,Qge),e(Qge,u$o),b(f,sze,u),b(f,Ro,u),M(ZL,Ro,null),e(Ro,b$o),e(Ro,Ji),e(Ji,v$o),e(Ji,hO),e(hO,F$o),e(Ji,T$o),e(Ji,pO),e(pO,M$o),e(Ji,E$o),e(Ro,C$o),e(Ro,ey),e(ey,w$o),e(ey,Wge),e(Wge,A$o),e(ey,L$o),e(Ro,y$o),e(Ro,ct),M(oy,ct,null),e(ct,x$o),e(ct,Hge),e(Hge,$$o),e(ct,k$o),e(ct,Yi),e(Yi,S$o),e(Yi,Uge),e(Uge,R$o),e(Yi,P$o),e(Yi,_O),e(_O,B$o),e(Yi,I$o),e(ct,N$o),M(H1,ct,null),e(Ro,q$o),e(Ro,Ze),M(ry,Ze,null),e(Ze,j$o),e(Ze,Jge),e(Jge,D$o),e(Ze,G$o),e(Ze,qa),e(qa,O$o),e(qa,Yge),e(Yge,V$o),e(qa,X$o),e(qa,Kge),e(Kge,z$o),e(qa,Q$o),e(qa,Zge),e(Zge,W$o),e(qa,H$o),e(Ze,U$o),e(Ze,z),e(z,U1),e(U1,ehe),e(ehe,J$o),e(U1,Y$o),e(U1,uO),e(uO,K$o),e(U1,Z$o),e(z,eko),e(z,J1),e(J1,ohe),e(ohe,oko),e(J1,rko),e(J1,bO),e(bO,tko),e(J1,ako),e(z,nko),e(z,Y1),e(Y1,rhe),e(rhe,sko),e(Y1,lko),e(Y1,vO),e(vO,iko),e(Y1,dko),e(z,cko),e(z,K1),e(K1,the),e(the,fko),e(K1,mko),e(K1,FO),e(FO,gko),e(K1,hko),e(z,pko),e(z,Z1),e(Z1,ahe),e(ahe,_ko),e(Z1,uko),e(Z1,TO),e(TO,bko),e(Z1,vko),e(z,Fko),e(z,e4),e(e4,nhe),e(nhe,Tko),e(e4,Mko),e(e4,MO),e(MO,Eko),e(e4,Cko),e(z,wko),e(z,o4),e(o4,she),e(she,Ako),e(o4,Lko),e(o4,EO),e(EO,yko),e(o4,xko),e(z,$ko),e(z,r4),e(r4,lhe),e(lhe,kko),e(r4,Sko),e(r4,CO),e(CO,Rko),e(r4,Pko),e(z,Bko),e(z,t4),e(t4,ihe),e(ihe,Iko),e(t4,Nko),e(t4,wO),e(wO,qko),e(t4,jko),e(z,Dko),e(z,a4),e(a4,dhe),e(dhe,Gko),e(a4,Oko),e(a4,AO),e(AO,Vko),e(a4,Xko),e(z,zko),e(z,n4),e(n4,che),e(che,Qko),e(n4,Wko),e(n4,LO),e(LO,Hko),e(n4,Uko),e(z,Jko),e(z,s4),e(s4,fhe),e(fhe,Yko),e(s4,Kko),e(s4,yO),e(yO,Zko),e(s4,eSo),e(z,oSo),e(z,l4),e(l4,mhe),e(mhe,rSo),e(l4,tSo),e(l4,xO),e(xO,aSo),e(l4,nSo),e(z,sSo),e(z,i4),e(i4,ghe),e(ghe,lSo),e(i4,iSo),e(i4,$O),e($O,dSo),e(i4,cSo),e(z,fSo),e(z,d4),e(d4,hhe),e(hhe,mSo),e(d4,gSo),e(d4,kO),e(kO,hSo),e(d4,pSo),e(z,_So),e(z,c4),e(c4,phe),e(phe,uSo),e(c4,bSo),e(c4,SO),e(SO,vSo),e(c4,FSo),e(z,TSo),e(z,f4),e(f4,_he),e(_he,MSo),e(f4,ESo),e(f4,RO),e(RO,CSo),e(f4,wSo),e(z,ASo),e(z,m4),e(m4,uhe),e(uhe,LSo),e(m4,ySo),e(m4,PO),e(PO,xSo),e(m4,$So),e(z,kSo),e(z,g4),e(g4,bhe),e(bhe,SSo),e(g4,RSo),e(g4,BO),e(BO,PSo),e(g4,BSo),e(z,ISo),e(z,h4),e(h4,vhe),e(vhe,NSo),e(h4,qSo),e(h4,IO),e(IO,jSo),e(h4,DSo),e(z,GSo),e(z,p4),e(p4,Fhe),e(Fhe,OSo),e(p4,VSo),e(p4,NO),e(NO,XSo),e(p4,zSo),e(z,QSo),e(z,_4),e(_4,The),e(The,WSo),e(_4,HSo),e(_4,qO),e(qO,USo),e(_4,JSo),e(z,YSo),e(z,u4),e(u4,Mhe),e(Mhe,KSo),e(u4,ZSo),e(u4,jO),e(jO,eRo),e(u4,oRo),e(z,rRo),e(z,b4),e(b4,Ehe),e(Ehe,tRo),e(b4,aRo),e(b4,DO),e(DO,nRo),e(b4,sRo),e(z,lRo),e(z,v4),e(v4,Che),e(Che,iRo),e(v4,dRo),e(v4,GO),e(GO,cRo),e(v4,fRo),e(z,mRo),e(z,F4),e(F4,whe),e(whe,gRo),e(F4,hRo),e(F4,OO),e(OO,pRo),e(F4,_Ro),e(z,uRo),e(z,T4),e(T4,Ahe),e(Ahe,bRo),e(T4,vRo),e(T4,VO),e(VO,FRo),e(T4,TRo),e(z,MRo),e(z,M4),e(M4,Lhe),e(Lhe,ERo),e(M4,CRo),e(M4,XO),e(XO,wRo),e(M4,ARo),e(z,LRo),e(z,E4),e(E4,yhe),e(yhe,yRo),e(E4,xRo),e(E4,zO),e(zO,$Ro),e(E4,kRo),e(z,SRo),e(z,C4),e(C4,xhe),e(xhe,RRo),e(C4,PRo),e(C4,QO),e(QO,BRo),e(C4,IRo),e(z,NRo),e(z,w4),e(w4,$he),e($he,qRo),e(w4,jRo),e(w4,WO),e(WO,DRo),e(w4,GRo),e(z,ORo),e(z,A4),e(A4,khe),e(khe,VRo),e(A4,XRo),e(A4,HO),e(HO,zRo),e(A4,QRo),e(z,WRo),e(z,L4),e(L4,She),e(She,HRo),e(L4,URo),e(L4,UO),e(UO,JRo),e(L4,YRo),e(z,KRo),e(z,y4),e(y4,Rhe),e(Rhe,ZRo),e(y4,ePo),e(y4,JO),e(JO,oPo),e(y4,rPo),e(z,tPo),e(z,x4),e(x4,Phe),e(Phe,aPo),e(x4,nPo),e(x4,YO),e(YO,sPo),e(x4,lPo),e(z,iPo),e(z,$4),e($4,Bhe),e(Bhe,dPo),e($4,cPo),e($4,KO),e(KO,fPo),e($4,mPo),e(z,gPo),e(z,k4),e(k4,Ihe),e(Ihe,hPo),e(k4,pPo),e(k4,ZO),e(ZO,_Po),e(k4,uPo),e(z,bPo),e(z,S4),e(S4,Nhe),e(Nhe,vPo),e(S4,FPo),e(S4,eV),e(eV,TPo),e(S4,MPo),e(z,EPo),e(z,R4),e(R4,qhe),e(qhe,CPo),e(R4,wPo),e(R4,oV),e(oV,APo),e(R4,LPo),e(z,yPo),e(z,P4),e(P4,jhe),e(jhe,xPo),e(P4,$Po),e(P4,rV),e(rV,kPo),e(P4,SPo),e(Ze,RPo),e(Ze,B4),e(B4,PPo),e(B4,Dhe),e(Dhe,BPo),e(B4,IPo),e(B4,Ghe),e(Ghe,NPo),e(Ze,qPo),M(I4,Ze,null),b(f,lze,u),b(f,Ki,u),e(Ki,N4),e(N4,Ohe),M(ty,Ohe,null),e(Ki,jPo),e(Ki,Vhe),e(Vhe,DPo),b(f,ize,u),b(f,Po,u),M(ay,Po,null),e(Po,GPo),e(Po,Zi),e(Zi,OPo),e(Zi,tV),e(tV,VPo),e(Zi,XPo),e(Zi,aV),e(aV,zPo),e(Zi,QPo),e(Po,WPo),e(Po,ny),e(ny,HPo),e(ny,Xhe),e(Xhe,UPo),e(ny,JPo),e(Po,YPo),e(Po,ft),M(sy,ft,null),e(ft,KPo),e(ft,zhe),e(zhe,ZPo),e(ft,eBo),e(ft,ed),e(ed,oBo),e(ed,Qhe),e(Qhe,rBo),e(ed,tBo),e(ed,nV),e(nV,aBo),e(ed,nBo),e(ft,sBo),M(q4,ft,null),e(Po,lBo),e(Po,eo),M(ly,eo,null),e(eo,iBo),e(eo,Whe),e(Whe,dBo),e(eo,cBo),e(eo,ja),e(ja,fBo),e(ja,Hhe),e(Hhe,mBo),e(ja,gBo),e(ja,Uhe),e(Uhe,hBo),e(ja,pBo),e(ja,Jhe),e(Jhe,_Bo),e(ja,uBo),e(eo,bBo),e(eo,W),e(W,j4),e(j4,Yhe),e(Yhe,vBo),e(j4,FBo),e(j4,sV),e(sV,TBo),e(j4,MBo),e(W,EBo),e(W,D4),e(D4,Khe),e(Khe,CBo),e(D4,wBo),e(D4,lV),e(lV,ABo),e(D4,LBo),e(W,yBo),e(W,G4),e(G4,Zhe),e(Zhe,xBo),e(G4,$Bo),e(G4,iV),e(iV,kBo),e(G4,SBo),e(W,RBo),e(W,O4),e(O4,epe),e(epe,PBo),e(O4,BBo),e(O4,dV),e(dV,IBo),e(O4,NBo),e(W,qBo),e(W,V4),e(V4,ope),e(ope,jBo),e(V4,DBo),e(V4,cV),e(cV,GBo),e(V4,OBo),e(W,VBo),e(W,X4),e(X4,rpe),e(rpe,XBo),e(X4,zBo),e(X4,fV),e(fV,QBo),e(X4,WBo),e(W,HBo),e(W,z4),e(z4,tpe),e(tpe,UBo),e(z4,JBo),e(z4,mV),e(mV,YBo),e(z4,KBo),e(W,ZBo),e(W,Q4),e(Q4,ape),e(ape,eIo),e(Q4,oIo),e(Q4,gV),e(gV,rIo),e(Q4,tIo),e(W,aIo),e(W,W4),e(W4,npe),e(npe,nIo),e(W4,sIo),e(W4,hV),e(hV,lIo),e(W4,iIo),e(W,dIo),e(W,H4),e(H4,spe),e(spe,cIo),e(H4,fIo),e(H4,pV),e(pV,mIo),e(H4,gIo),e(W,hIo),e(W,U4),e(U4,lpe),e(lpe,pIo),e(U4,_Io),e(U4,_V),e(_V,uIo),e(U4,bIo),e(W,vIo),e(W,J4),e(J4,ipe),e(ipe,FIo),e(J4,TIo),e(J4,uV),e(uV,MIo),e(J4,EIo),e(W,CIo),e(W,Y4),e(Y4,dpe),e(dpe,wIo),e(Y4,AIo),e(Y4,bV),e(bV,LIo),e(Y4,yIo),e(W,xIo),e(W,K4),e(K4,cpe),e(cpe,$Io),e(K4,kIo),e(K4,vV),e(vV,SIo),e(K4,RIo),e(W,PIo),e(W,Z4),e(Z4,fpe),e(fpe,BIo),e(Z4,IIo),e(Z4,FV),e(FV,NIo),e(Z4,qIo),e(W,jIo),e(W,e2),e(e2,mpe),e(mpe,DIo),e(e2,GIo),e(e2,TV),e(TV,OIo),e(e2,VIo),e(W,XIo),e(W,o2),e(o2,gpe),e(gpe,zIo),e(o2,QIo),e(o2,MV),e(MV,WIo),e(o2,HIo),e(W,UIo),e(W,r2),e(r2,hpe),e(hpe,JIo),e(r2,YIo),e(r2,EV),e(EV,KIo),e(r2,ZIo),e(W,eNo),e(W,t2),e(t2,ppe),e(ppe,oNo),e(t2,rNo),e(t2,CV),e(CV,tNo),e(t2,aNo),e(W,nNo),e(W,a2),e(a2,_pe),e(_pe,sNo),e(a2,lNo),e(a2,wV),e(wV,iNo),e(a2,dNo),e(W,cNo),e(W,n2),e(n2,upe),e(upe,fNo),e(n2,mNo),e(n2,AV),e(AV,gNo),e(n2,hNo),e(W,pNo),e(W,s2),e(s2,bpe),e(bpe,_No),e(s2,uNo),e(s2,LV),e(LV,bNo),e(s2,vNo),e(W,FNo),e(W,l2),e(l2,vpe),e(vpe,TNo),e(l2,MNo),e(l2,yV),e(yV,ENo),e(l2,CNo),e(W,wNo),e(W,i2),e(i2,Fpe),e(Fpe,ANo),e(i2,LNo),e(i2,xV),e(xV,yNo),e(i2,xNo),e(W,$No),e(W,d2),e(d2,Tpe),e(Tpe,kNo),e(d2,SNo),e(d2,$V),e($V,RNo),e(d2,PNo),e(W,BNo),e(W,c2),e(c2,Mpe),e(Mpe,INo),e(c2,NNo),e(c2,kV),e(kV,qNo),e(c2,jNo),e(W,DNo),e(W,f2),e(f2,Epe),e(Epe,GNo),e(f2,ONo),e(f2,SV),e(SV,VNo),e(f2,XNo),e(W,zNo),e(W,m2),e(m2,Cpe),e(Cpe,QNo),e(m2,WNo),e(m2,RV),e(RV,HNo),e(m2,UNo),e(W,JNo),e(W,g2),e(g2,wpe),e(wpe,YNo),e(g2,KNo),e(g2,PV),e(PV,ZNo),e(g2,eqo),e(W,oqo),e(W,h2),e(h2,Ape),e(Ape,rqo),e(h2,tqo),e(h2,BV),e(BV,aqo),e(h2,nqo),e(W,sqo),e(W,p2),e(p2,Lpe),e(Lpe,lqo),e(p2,iqo),e(p2,IV),e(IV,dqo),e(p2,cqo),e(W,fqo),e(W,_2),e(_2,ype),e(ype,mqo),e(_2,gqo),e(_2,NV),e(NV,hqo),e(_2,pqo),e(W,_qo),e(W,u2),e(u2,xpe),e(xpe,uqo),e(u2,bqo),e(u2,qV),e(qV,vqo),e(u2,Fqo),e(W,Tqo),e(W,b2),e(b2,$pe),e($pe,Mqo),e(b2,Eqo),e(b2,kpe),e(kpe,Cqo),e(b2,wqo),e(W,Aqo),e(W,v2),e(v2,Spe),e(Spe,Lqo),e(v2,yqo),e(v2,jV),e(jV,xqo),e(v2,$qo),e(W,kqo),e(W,F2),e(F2,Rpe),e(Rpe,Sqo),e(F2,Rqo),e(F2,DV),e(DV,Pqo),e(F2,Bqo),e(W,Iqo),e(W,T2),e(T2,Ppe),e(Ppe,Nqo),e(T2,qqo),e(T2,GV),e(GV,jqo),e(T2,Dqo),e(W,Gqo),e(W,M2),e(M2,Bpe),e(Bpe,Oqo),e(M2,Vqo),e(M2,OV),e(OV,Xqo),e(M2,zqo),e(eo,Qqo),e(eo,E2),e(E2,Wqo),e(E2,Ipe),e(Ipe,Hqo),e(E2,Uqo),e(E2,Npe),e(Npe,Jqo),e(eo,Yqo),M(C2,eo,null),b(f,dze,u),b(f,od,u),e(od,w2),e(w2,qpe),M(iy,qpe,null),e(od,Kqo),e(od,jpe),e(jpe,Zqo),b(f,cze,u),b(f,Bo,u),M(dy,Bo,null),e(Bo,ejo),e(Bo,rd),e(rd,ojo),e(rd,VV),e(VV,rjo),e(rd,tjo),e(rd,XV),e(XV,ajo),e(rd,njo),e(Bo,sjo),e(Bo,cy),e(cy,ljo),e(cy,Dpe),e(Dpe,ijo),e(cy,djo),e(Bo,cjo),e(Bo,mt),M(fy,mt,null),e(mt,fjo),e(mt,Gpe),e(Gpe,mjo),e(mt,gjo),e(mt,td),e(td,hjo),e(td,Ope),e(Ope,pjo),e(td,_jo),e(td,zV),e(zV,ujo),e(td,bjo),e(mt,vjo),M(A2,mt,null),e(Bo,Fjo),e(Bo,oo),M(my,oo,null),e(oo,Tjo),e(oo,Vpe),e(Vpe,Mjo),e(oo,Ejo),e(oo,Da),e(Da,Cjo),e(Da,Xpe),e(Xpe,wjo),e(Da,Ajo),e(Da,zpe),e(zpe,Ljo),e(Da,yjo),e(Da,Qpe),e(Qpe,xjo),e(Da,$jo),e(oo,kjo),e(oo,fe),e(fe,L2),e(L2,Wpe),e(Wpe,Sjo),e(L2,Rjo),e(L2,QV),e(QV,Pjo),e(L2,Bjo),e(fe,Ijo),e(fe,y2),e(y2,Hpe),e(Hpe,Njo),e(y2,qjo),e(y2,WV),e(WV,jjo),e(y2,Djo),e(fe,Gjo),e(fe,x2),e(x2,Upe),e(Upe,Ojo),e(x2,Vjo),e(x2,HV),e(HV,Xjo),e(x2,zjo),e(fe,Qjo),e(fe,$2),e($2,Jpe),e(Jpe,Wjo),e($2,Hjo),e($2,UV),e(UV,Ujo),e($2,Jjo),e(fe,Yjo),e(fe,k2),e(k2,Ype),e(Ype,Kjo),e(k2,Zjo),e(k2,JV),e(JV,eDo),e(k2,oDo),e(fe,rDo),e(fe,S2),e(S2,Kpe),e(Kpe,tDo),e(S2,aDo),e(S2,YV),e(YV,nDo),e(S2,sDo),e(fe,lDo),e(fe,R2),e(R2,Zpe),e(Zpe,iDo),e(R2,dDo),e(R2,KV),e(KV,cDo),e(R2,fDo),e(fe,mDo),e(fe,P2),e(P2,e_e),e(e_e,gDo),e(P2,hDo),e(P2,ZV),e(ZV,pDo),e(P2,_Do),e(fe,uDo),e(fe,B2),e(B2,o_e),e(o_e,bDo),e(B2,vDo),e(B2,eX),e(eX,FDo),e(B2,TDo),e(fe,MDo),e(fe,I2),e(I2,r_e),e(r_e,EDo),e(I2,CDo),e(I2,oX),e(oX,wDo),e(I2,ADo),e(fe,LDo),e(fe,N2),e(N2,t_e),e(t_e,yDo),e(N2,xDo),e(N2,rX),e(rX,$Do),e(N2,kDo),e(fe,SDo),e(fe,q2),e(q2,a_e),e(a_e,RDo),e(q2,PDo),e(q2,tX),e(tX,BDo),e(q2,IDo),e(fe,NDo),e(fe,j2),e(j2,n_e),e(n_e,qDo),e(j2,jDo),e(j2,aX),e(aX,DDo),e(j2,GDo),e(fe,ODo),e(fe,D2),e(D2,s_e),e(s_e,VDo),e(D2,XDo),e(D2,nX),e(nX,zDo),e(D2,QDo),e(fe,WDo),e(fe,G2),e(G2,l_e),e(l_e,HDo),e(G2,UDo),e(G2,sX),e(sX,JDo),e(G2,YDo),e(fe,KDo),e(fe,O2),e(O2,i_e),e(i_e,ZDo),e(O2,eGo),e(O2,lX),e(lX,oGo),e(O2,rGo),e(fe,tGo),e(fe,V2),e(V2,d_e),e(d_e,aGo),e(V2,nGo),e(V2,iX),e(iX,sGo),e(V2,lGo),e(fe,iGo),e(fe,X2),e(X2,c_e),e(c_e,dGo),e(X2,cGo),e(X2,dX),e(dX,fGo),e(X2,mGo),e(fe,gGo),e(fe,z2),e(z2,f_e),e(f_e,hGo),e(z2,pGo),e(z2,cX),e(cX,_Go),e(z2,uGo),e(oo,bGo),e(oo,Q2),e(Q2,vGo),e(Q2,m_e),e(m_e,FGo),e(Q2,TGo),e(Q2,g_e),e(g_e,MGo),e(oo,EGo),M(W2,oo,null),b(f,fze,u),b(f,ad,u),e(ad,H2),e(H2,h_e),M(gy,h_e,null),e(ad,CGo),e(ad,p_e),e(p_e,wGo),b(f,mze,u),b(f,Io,u),M(hy,Io,null),e(Io,AGo),e(Io,nd),e(nd,LGo),e(nd,fX),e(fX,yGo),e(nd,xGo),e(nd,mX),e(mX,$Go),e(nd,kGo),e(Io,SGo),e(Io,py),e(py,RGo),e(py,__e),e(__e,PGo),e(py,BGo),e(Io,IGo),e(Io,gt),M(_y,gt,null),e(gt,NGo),e(gt,u_e),e(u_e,qGo),e(gt,jGo),e(gt,sd),e(sd,DGo),e(sd,b_e),e(b_e,GGo),e(sd,OGo),e(sd,gX),e(gX,VGo),e(sd,XGo),e(gt,zGo),M(U2,gt,null),e(Io,QGo),e(Io,ro),M(uy,ro,null),e(ro,WGo),e(ro,v_e),e(v_e,HGo),e(ro,UGo),e(ro,Ga),e(Ga,JGo),e(Ga,F_e),e(F_e,YGo),e(Ga,KGo),e(Ga,T_e),e(T_e,ZGo),e(Ga,eOo),e(Ga,M_e),e(M_e,oOo),e(Ga,rOo),e(ro,tOo),e(ro,B),e(B,J2),e(J2,E_e),e(E_e,aOo),e(J2,nOo),e(J2,hX),e(hX,sOo),e(J2,lOo),e(B,iOo),e(B,Y2),e(Y2,C_e),e(C_e,dOo),e(Y2,cOo),e(Y2,pX),e(pX,fOo),e(Y2,mOo),e(B,gOo),e(B,K2),e(K2,w_e),e(w_e,hOo),e(K2,pOo),e(K2,_X),e(_X,_Oo),e(K2,uOo),e(B,bOo),e(B,Z2),e(Z2,A_e),e(A_e,vOo),e(Z2,FOo),e(Z2,uX),e(uX,TOo),e(Z2,MOo),e(B,EOo),e(B,eb),e(eb,L_e),e(L_e,COo),e(eb,wOo),e(eb,bX),e(bX,AOo),e(eb,LOo),e(B,yOo),e(B,ob),e(ob,y_e),e(y_e,xOo),e(ob,$Oo),e(ob,vX),e(vX,kOo),e(ob,SOo),e(B,ROo),e(B,rb),e(rb,x_e),e(x_e,POo),e(rb,BOo),e(rb,FX),e(FX,IOo),e(rb,NOo),e(B,qOo),e(B,tb),e(tb,$_e),e($_e,jOo),e(tb,DOo),e(tb,TX),e(TX,GOo),e(tb,OOo),e(B,VOo),e(B,ab),e(ab,k_e),e(k_e,XOo),e(ab,zOo),e(ab,MX),e(MX,QOo),e(ab,WOo),e(B,HOo),e(B,nb),e(nb,S_e),e(S_e,UOo),e(nb,JOo),e(nb,EX),e(EX,YOo),e(nb,KOo),e(B,ZOo),e(B,sb),e(sb,R_e),e(R_e,eVo),e(sb,oVo),e(sb,CX),e(CX,rVo),e(sb,tVo),e(B,aVo),e(B,lb),e(lb,P_e),e(P_e,nVo),e(lb,sVo),e(lb,wX),e(wX,lVo),e(lb,iVo),e(B,dVo),e(B,ib),e(ib,B_e),e(B_e,cVo),e(ib,fVo),e(ib,AX),e(AX,mVo),e(ib,gVo),e(B,hVo),e(B,db),e(db,I_e),e(I_e,pVo),e(db,_Vo),e(db,LX),e(LX,uVo),e(db,bVo),e(B,vVo),e(B,cb),e(cb,N_e),e(N_e,FVo),e(cb,TVo),e(cb,yX),e(yX,MVo),e(cb,EVo),e(B,CVo),e(B,fb),e(fb,q_e),e(q_e,wVo),e(fb,AVo),e(fb,xX),e(xX,LVo),e(fb,yVo),e(B,xVo),e(B,mb),e(mb,j_e),e(j_e,$Vo),e(mb,kVo),e(mb,$X),e($X,SVo),e(mb,RVo),e(B,PVo),e(B,gb),e(gb,D_e),e(D_e,BVo),e(gb,IVo),e(gb,kX),e(kX,NVo),e(gb,qVo),e(B,jVo),e(B,hb),e(hb,G_e),e(G_e,DVo),e(hb,GVo),e(hb,SX),e(SX,OVo),e(hb,VVo),e(B,XVo),e(B,pb),e(pb,O_e),e(O_e,zVo),e(pb,QVo),e(pb,RX),e(RX,WVo),e(pb,HVo),e(B,UVo),e(B,_b),e(_b,V_e),e(V_e,JVo),e(_b,YVo),e(_b,PX),e(PX,KVo),e(_b,ZVo),e(B,eXo),e(B,ub),e(ub,X_e),e(X_e,oXo),e(ub,rXo),e(ub,BX),e(BX,tXo),e(ub,aXo),e(B,nXo),e(B,bb),e(bb,z_e),e(z_e,sXo),e(bb,lXo),e(bb,IX),e(IX,iXo),e(bb,dXo),e(B,cXo),e(B,vb),e(vb,Q_e),e(Q_e,fXo),e(vb,mXo),e(vb,NX),e(NX,gXo),e(vb,hXo),e(B,pXo),e(B,Fb),e(Fb,W_e),e(W_e,_Xo),e(Fb,uXo),e(Fb,qX),e(qX,bXo),e(Fb,vXo),e(B,FXo),e(B,Tb),e(Tb,H_e),e(H_e,TXo),e(Tb,MXo),e(Tb,jX),e(jX,EXo),e(Tb,CXo),e(B,wXo),e(B,Mb),e(Mb,U_e),e(U_e,AXo),e(Mb,LXo),e(Mb,DX),e(DX,yXo),e(Mb,xXo),e(B,$Xo),e(B,Eb),e(Eb,J_e),e(J_e,kXo),e(Eb,SXo),e(Eb,GX),e(GX,RXo),e(Eb,PXo),e(B,BXo),e(B,Cb),e(Cb,Y_e),e(Y_e,IXo),e(Cb,NXo),e(Cb,OX),e(OX,qXo),e(Cb,jXo),e(B,DXo),e(B,wb),e(wb,K_e),e(K_e,GXo),e(wb,OXo),e(wb,VX),e(VX,VXo),e(wb,XXo),e(B,zXo),e(B,Ab),e(Ab,Z_e),e(Z_e,QXo),e(Ab,WXo),e(Ab,XX),e(XX,HXo),e(Ab,UXo),e(B,JXo),e(B,Lb),e(Lb,eue),e(eue,YXo),e(Lb,KXo),e(Lb,zX),e(zX,ZXo),e(Lb,ezo),e(B,ozo),e(B,yb),e(yb,oue),e(oue,rzo),e(yb,tzo),e(yb,QX),e(QX,azo),e(yb,nzo),e(B,szo),e(B,xb),e(xb,rue),e(rue,lzo),e(xb,izo),e(xb,WX),e(WX,dzo),e(xb,czo),e(B,fzo),e(B,$b),e($b,tue),e(tue,mzo),e($b,gzo),e($b,HX),e(HX,hzo),e($b,pzo),e(B,_zo),e(B,kb),e(kb,aue),e(aue,uzo),e(kb,bzo),e(kb,UX),e(UX,vzo),e(kb,Fzo),e(B,Tzo),e(B,Sb),e(Sb,nue),e(nue,Mzo),e(Sb,Ezo),e(Sb,JX),e(JX,Czo),e(Sb,wzo),e(B,Azo),e(B,Rb),e(Rb,sue),e(sue,Lzo),e(Rb,yzo),e(Rb,YX),e(YX,xzo),e(Rb,$zo),e(B,kzo),e(B,Pb),e(Pb,lue),e(lue,Szo),e(Pb,Rzo),e(Pb,KX),e(KX,Pzo),e(Pb,Bzo),e(B,Izo),e(B,Bb),e(Bb,iue),e(iue,Nzo),e(Bb,qzo),e(Bb,ZX),e(ZX,jzo),e(Bb,Dzo),e(B,Gzo),e(B,Ib),e(Ib,due),e(due,Ozo),e(Ib,Vzo),e(Ib,ez),e(ez,Xzo),e(Ib,zzo),e(B,Qzo),e(B,Nb),e(Nb,cue),e(cue,Wzo),e(Nb,Hzo),e(Nb,oz),e(oz,Uzo),e(Nb,Jzo),e(B,Yzo),e(B,qb),e(qb,fue),e(fue,Kzo),e(qb,Zzo),e(qb,rz),e(rz,eQo),e(qb,oQo),e(B,rQo),e(B,jb),e(jb,mue),e(mue,tQo),e(jb,aQo),e(jb,tz),e(tz,nQo),e(jb,sQo),e(B,lQo),e(B,Db),e(Db,gue),e(gue,iQo),e(Db,dQo),e(Db,az),e(az,cQo),e(Db,fQo),e(B,mQo),e(B,Gb),e(Gb,hue),e(hue,gQo),e(Gb,hQo),e(Gb,nz),e(nz,pQo),e(Gb,_Qo),e(B,uQo),e(B,Ob),e(Ob,pue),e(pue,bQo),e(Ob,vQo),e(Ob,sz),e(sz,FQo),e(Ob,TQo),e(B,MQo),e(B,Vb),e(Vb,_ue),e(_ue,EQo),e(Vb,CQo),e(Vb,lz),e(lz,wQo),e(Vb,AQo),e(B,LQo),e(B,Xb),e(Xb,uue),e(uue,yQo),e(Xb,xQo),e(Xb,iz),e(iz,$Qo),e(Xb,kQo),e(B,SQo),e(B,zb),e(zb,bue),e(bue,RQo),e(zb,PQo),e(zb,dz),e(dz,BQo),e(zb,IQo),e(B,NQo),e(B,Qb),e(Qb,vue),e(vue,qQo),e(Qb,jQo),e(Qb,cz),e(cz,DQo),e(Qb,GQo),e(ro,OQo),e(ro,Wb),e(Wb,VQo),e(Wb,Fue),e(Fue,XQo),e(Wb,zQo),e(Wb,Tue),e(Tue,QQo),e(ro,WQo),M(Hb,ro,null),b(f,gze,u),b(f,ld,u),e(ld,Ub),e(Ub,Mue),M(by,Mue,null),e(ld,HQo),e(ld,Eue),e(Eue,UQo),b(f,hze,u),b(f,No,u),M(vy,No,null),e(No,JQo),e(No,id),e(id,YQo),e(id,fz),e(fz,KQo),e(id,ZQo),e(id,mz),e(mz,eWo),e(id,oWo),e(No,rWo),e(No,Fy),e(Fy,tWo),e(Fy,Cue),e(Cue,aWo),e(Fy,nWo),e(No,sWo),e(No,ht),M(Ty,ht,null),e(ht,lWo),e(ht,wue),e(wue,iWo),e(ht,dWo),e(ht,dd),e(dd,cWo),e(dd,Aue),e(Aue,fWo),e(dd,mWo),e(dd,gz),e(gz,gWo),e(dd,hWo),e(ht,pWo),M(Jb,ht,null),e(No,_Wo),e(No,to),M(My,to,null),e(to,uWo),e(to,Lue),e(Lue,bWo),e(to,vWo),e(to,Oa),e(Oa,FWo),e(Oa,yue),e(yue,TWo),e(Oa,MWo),e(Oa,xue),e(xue,EWo),e(Oa,CWo),e(Oa,$ue),e($ue,wWo),e(Oa,AWo),e(to,LWo),e(to,Z),e(Z,Yb),e(Yb,kue),e(kue,yWo),e(Yb,xWo),e(Yb,hz),e(hz,$Wo),e(Yb,kWo),e(Z,SWo),e(Z,Kb),e(Kb,Sue),e(Sue,RWo),e(Kb,PWo),e(Kb,pz),e(pz,BWo),e(Kb,IWo),e(Z,NWo),e(Z,Zb),e(Zb,Rue),e(Rue,qWo),e(Zb,jWo),e(Zb,_z),e(_z,DWo),e(Zb,GWo),e(Z,OWo),e(Z,ev),e(ev,Pue),e(Pue,VWo),e(ev,XWo),e(ev,uz),e(uz,zWo),e(ev,QWo),e(Z,WWo),e(Z,ov),e(ov,Bue),e(Bue,HWo),e(ov,UWo),e(ov,bz),e(bz,JWo),e(ov,YWo),e(Z,KWo),e(Z,rv),e(rv,Iue),e(Iue,ZWo),e(rv,eHo),e(rv,vz),e(vz,oHo),e(rv,rHo),e(Z,tHo),e(Z,tv),e(tv,Nue),e(Nue,aHo),e(tv,nHo),e(tv,Fz),e(Fz,sHo),e(tv,lHo),e(Z,iHo),e(Z,av),e(av,que),e(que,dHo),e(av,cHo),e(av,Tz),e(Tz,fHo),e(av,mHo),e(Z,gHo),e(Z,nv),e(nv,jue),e(jue,hHo),e(nv,pHo),e(nv,Mz),e(Mz,_Ho),e(nv,uHo),e(Z,bHo),e(Z,sv),e(sv,Due),e(Due,vHo),e(sv,FHo),e(sv,Ez),e(Ez,THo),e(sv,MHo),e(Z,EHo),e(Z,lv),e(lv,Gue),e(Gue,CHo),e(lv,wHo),e(lv,Cz),e(Cz,AHo),e(lv,LHo),e(Z,yHo),e(Z,iv),e(iv,Oue),e(Oue,xHo),e(iv,$Ho),e(iv,wz),e(wz,kHo),e(iv,SHo),e(Z,RHo),e(Z,dv),e(dv,Vue),e(Vue,PHo),e(dv,BHo),e(dv,Az),e(Az,IHo),e(dv,NHo),e(Z,qHo),e(Z,cv),e(cv,Xue),e(Xue,jHo),e(cv,DHo),e(cv,Lz),e(Lz,GHo),e(cv,OHo),e(Z,VHo),e(Z,fv),e(fv,zue),e(zue,XHo),e(fv,zHo),e(fv,yz),e(yz,QHo),e(fv,WHo),e(Z,HHo),e(Z,mv),e(mv,Que),e(Que,UHo),e(mv,JHo),e(mv,xz),e(xz,YHo),e(mv,KHo),e(Z,ZHo),e(Z,gv),e(gv,Wue),e(Wue,eUo),e(gv,oUo),e(gv,$z),e($z,rUo),e(gv,tUo),e(Z,aUo),e(Z,hv),e(hv,Hue),e(Hue,nUo),e(hv,sUo),e(hv,kz),e(kz,lUo),e(hv,iUo),e(Z,dUo),e(Z,pv),e(pv,Uue),e(Uue,cUo),e(pv,fUo),e(pv,Sz),e(Sz,mUo),e(pv,gUo),e(Z,hUo),e(Z,_v),e(_v,Jue),e(Jue,pUo),e(_v,_Uo),e(_v,Rz),e(Rz,uUo),e(_v,bUo),e(Z,vUo),e(Z,uv),e(uv,Yue),e(Yue,FUo),e(uv,TUo),e(uv,Pz),e(Pz,MUo),e(uv,EUo),e(Z,CUo),e(Z,bv),e(bv,Kue),e(Kue,wUo),e(bv,AUo),e(bv,Bz),e(Bz,LUo),e(bv,yUo),e(Z,xUo),e(Z,vv),e(vv,Zue),e(Zue,$Uo),e(vv,kUo),e(vv,Iz),e(Iz,SUo),e(vv,RUo),e(Z,PUo),e(Z,Fv),e(Fv,e1e),e(e1e,BUo),e(Fv,IUo),e(Fv,Nz),e(Nz,NUo),e(Fv,qUo),e(Z,jUo),e(Z,Tv),e(Tv,o1e),e(o1e,DUo),e(Tv,GUo),e(Tv,qz),e(qz,OUo),e(Tv,VUo),e(Z,XUo),e(Z,Mv),e(Mv,r1e),e(r1e,zUo),e(Mv,QUo),e(Mv,jz),e(jz,WUo),e(Mv,HUo),e(Z,UUo),e(Z,Ev),e(Ev,t1e),e(t1e,JUo),e(Ev,YUo),e(Ev,Dz),e(Dz,KUo),e(Ev,ZUo),e(Z,eJo),e(Z,Cv),e(Cv,a1e),e(a1e,oJo),e(Cv,rJo),e(Cv,Gz),e(Gz,tJo),e(Cv,aJo),e(Z,nJo),e(Z,wv),e(wv,n1e),e(n1e,sJo),e(wv,lJo),e(wv,Oz),e(Oz,iJo),e(wv,dJo),e(Z,cJo),e(Z,Av),e(Av,s1e),e(s1e,fJo),e(Av,mJo),e(Av,Vz),e(Vz,gJo),e(Av,hJo),e(to,pJo),e(to,Lv),e(Lv,_Jo),e(Lv,l1e),e(l1e,uJo),e(Lv,bJo),e(Lv,i1e),e(i1e,vJo),e(to,FJo),M(yv,to,null),b(f,pze,u),b(f,cd,u),e(cd,xv),e(xv,d1e),M(Ey,d1e,null),e(cd,TJo),e(cd,c1e),e(c1e,MJo),b(f,_ze,u),b(f,qo,u),M(Cy,qo,null),e(qo,EJo),e(qo,fd),e(fd,CJo),e(fd,Xz),e(Xz,wJo),e(fd,AJo),e(fd,zz),e(zz,LJo),e(fd,yJo),e(qo,xJo),e(qo,wy),e(wy,$Jo),e(wy,f1e),e(f1e,kJo),e(wy,SJo),e(qo,RJo),e(qo,pt),M(Ay,pt,null),e(pt,PJo),e(pt,m1e),e(m1e,BJo),e(pt,IJo),e(pt,md),e(md,NJo),e(md,g1e),e(g1e,qJo),e(md,jJo),e(md,Qz),e(Qz,DJo),e(md,GJo),e(pt,OJo),M($v,pt,null),e(qo,VJo),e(qo,ao),M(Ly,ao,null),e(ao,XJo),e(ao,h1e),e(h1e,zJo),e(ao,QJo),e(ao,Va),e(Va,WJo),e(Va,p1e),e(p1e,HJo),e(Va,UJo),e(Va,_1e),e(_1e,JJo),e(Va,YJo),e(Va,u1e),e(u1e,KJo),e(Va,ZJo),e(ao,eYo),e(ao,jo),e(jo,kv),e(kv,b1e),e(b1e,oYo),e(kv,rYo),e(kv,Wz),e(Wz,tYo),e(kv,aYo),e(jo,nYo),e(jo,Sv),e(Sv,v1e),e(v1e,sYo),e(Sv,lYo),e(Sv,Hz),e(Hz,iYo),e(Sv,dYo),e(jo,cYo),e(jo,Rv),e(Rv,F1e),e(F1e,fYo),e(Rv,mYo),e(Rv,Uz),e(Uz,gYo),e(Rv,hYo),e(jo,pYo),e(jo,Pv),e(Pv,T1e),e(T1e,_Yo),e(Pv,uYo),e(Pv,Jz),e(Jz,bYo),e(Pv,vYo),e(jo,FYo),e(jo,Bv),e(Bv,M1e),e(M1e,TYo),e(Bv,MYo),e(Bv,Yz),e(Yz,EYo),e(Bv,CYo),e(jo,wYo),e(jo,Iv),e(Iv,E1e),e(E1e,AYo),e(Iv,LYo),e(Iv,Kz),e(Kz,yYo),e(Iv,xYo),e(ao,$Yo),e(ao,Nv),e(Nv,kYo),e(Nv,C1e),e(C1e,SYo),e(Nv,RYo),e(Nv,w1e),e(w1e,PYo),e(ao,BYo),M(qv,ao,null),b(f,uze,u),b(f,gd,u),e(gd,jv),e(jv,A1e),M(yy,A1e,null),e(gd,IYo),e(gd,L1e),e(L1e,NYo),b(f,bze,u),b(f,Do,u),M(xy,Do,null),e(Do,qYo),e(Do,hd),e(hd,jYo),e(hd,Zz),e(Zz,DYo),e(hd,GYo),e(hd,eQ),e(eQ,OYo),e(hd,VYo),e(Do,XYo),e(Do,$y),e($y,zYo),e($y,y1e),e(y1e,QYo),e($y,WYo),e(Do,HYo),e(Do,_t),M(ky,_t,null),e(_t,UYo),e(_t,x1e),e(x1e,JYo),e(_t,YYo),e(_t,pd),e(pd,KYo),e(pd,$1e),e($1e,ZYo),e(pd,eKo),e(pd,oQ),e(oQ,oKo),e(pd,rKo),e(_t,tKo),M(Dv,_t,null),e(Do,aKo),e(Do,no),M(Sy,no,null),e(no,nKo),e(no,k1e),e(k1e,sKo),e(no,lKo),e(no,Xa),e(Xa,iKo),e(Xa,S1e),e(S1e,dKo),e(Xa,cKo),e(Xa,R1e),e(R1e,fKo),e(Xa,mKo),e(Xa,P1e),e(P1e,gKo),e(Xa,hKo),e(no,pKo),e(no,U),e(U,Gv),e(Gv,B1e),e(B1e,_Ko),e(Gv,uKo),e(Gv,rQ),e(rQ,bKo),e(Gv,vKo),e(U,FKo),e(U,Ov),e(Ov,I1e),e(I1e,TKo),e(Ov,MKo),e(Ov,tQ),e(tQ,EKo),e(Ov,CKo),e(U,wKo),e(U,Vv),e(Vv,N1e),e(N1e,AKo),e(Vv,LKo),e(Vv,aQ),e(aQ,yKo),e(Vv,xKo),e(U,$Ko),e(U,Xv),e(Xv,q1e),e(q1e,kKo),e(Xv,SKo),e(Xv,nQ),e(nQ,RKo),e(Xv,PKo),e(U,BKo),e(U,zv),e(zv,j1e),e(j1e,IKo),e(zv,NKo),e(zv,sQ),e(sQ,qKo),e(zv,jKo),e(U,DKo),e(U,Qv),e(Qv,D1e),e(D1e,GKo),e(Qv,OKo),e(Qv,lQ),e(lQ,VKo),e(Qv,XKo),e(U,zKo),e(U,Wv),e(Wv,G1e),e(G1e,QKo),e(Wv,WKo),e(Wv,iQ),e(iQ,HKo),e(Wv,UKo),e(U,JKo),e(U,Hv),e(Hv,O1e),e(O1e,YKo),e(Hv,KKo),e(Hv,dQ),e(dQ,ZKo),e(Hv,eZo),e(U,oZo),e(U,Uv),e(Uv,V1e),e(V1e,rZo),e(Uv,tZo),e(Uv,cQ),e(cQ,aZo),e(Uv,nZo),e(U,sZo),e(U,Jv),e(Jv,X1e),e(X1e,lZo),e(Jv,iZo),e(Jv,fQ),e(fQ,dZo),e(Jv,cZo),e(U,fZo),e(U,Yv),e(Yv,z1e),e(z1e,mZo),e(Yv,gZo),e(Yv,mQ),e(mQ,hZo),e(Yv,pZo),e(U,_Zo),e(U,Kv),e(Kv,Q1e),e(Q1e,uZo),e(Kv,bZo),e(Kv,gQ),e(gQ,vZo),e(Kv,FZo),e(U,TZo),e(U,Zv),e(Zv,W1e),e(W1e,MZo),e(Zv,EZo),e(Zv,hQ),e(hQ,CZo),e(Zv,wZo),e(U,AZo),e(U,eF),e(eF,H1e),e(H1e,LZo),e(eF,yZo),e(eF,pQ),e(pQ,xZo),e(eF,$Zo),e(U,kZo),e(U,oF),e(oF,U1e),e(U1e,SZo),e(oF,RZo),e(oF,_Q),e(_Q,PZo),e(oF,BZo),e(U,IZo),e(U,rF),e(rF,J1e),e(J1e,NZo),e(rF,qZo),e(rF,uQ),e(uQ,jZo),e(rF,DZo),e(U,GZo),e(U,tF),e(tF,Y1e),e(Y1e,OZo),e(tF,VZo),e(tF,bQ),e(bQ,XZo),e(tF,zZo),e(U,QZo),e(U,aF),e(aF,K1e),e(K1e,WZo),e(aF,HZo),e(aF,vQ),e(vQ,UZo),e(aF,JZo),e(U,YZo),e(U,nF),e(nF,Z1e),e(Z1e,KZo),e(nF,ZZo),e(nF,FQ),e(FQ,eer),e(nF,oer),e(U,rer),e(U,sF),e(sF,e4e),e(e4e,ter),e(sF,aer),e(sF,TQ),e(TQ,ner),e(sF,ser),e(U,ler),e(U,lF),e(lF,o4e),e(o4e,ier),e(lF,der),e(lF,MQ),e(MQ,cer),e(lF,fer),e(U,mer),e(U,iF),e(iF,r4e),e(r4e,ger),e(iF,her),e(iF,EQ),e(EQ,per),e(iF,_er),e(U,uer),e(U,dF),e(dF,t4e),e(t4e,ber),e(dF,ver),e(dF,CQ),e(CQ,Fer),e(dF,Ter),e(U,Mer),e(U,cF),e(cF,a4e),e(a4e,Eer),e(cF,Cer),e(cF,wQ),e(wQ,wer),e(cF,Aer),e(U,Ler),e(U,fF),e(fF,n4e),e(n4e,yer),e(fF,xer),e(fF,AQ),e(AQ,$er),e(fF,ker),e(U,Ser),e(U,mF),e(mF,s4e),e(s4e,Rer),e(mF,Per),e(mF,LQ),e(LQ,Ber),e(mF,Ier),e(U,Ner),e(U,gF),e(gF,l4e),e(l4e,qer),e(gF,jer),e(gF,yQ),e(yQ,Der),e(gF,Ger),e(U,Oer),e(U,hF),e(hF,i4e),e(i4e,Ver),e(hF,Xer),e(hF,xQ),e(xQ,zer),e(hF,Qer),e(U,Wer),e(U,pF),e(pF,d4e),e(d4e,Her),e(pF,Uer),e(pF,$Q),e($Q,Jer),e(pF,Yer),e(U,Ker),e(U,_F),e(_F,c4e),e(c4e,Zer),e(_F,eor),e(_F,kQ),e(kQ,oor),e(_F,ror),e(U,tor),e(U,uF),e(uF,f4e),e(f4e,aor),e(uF,nor),e(uF,SQ),e(SQ,sor),e(uF,lor),e(U,ior),e(U,bF),e(bF,m4e),e(m4e,dor),e(bF,cor),e(bF,RQ),e(RQ,mor),e(bF,gor),e(U,hor),e(U,vF),e(vF,g4e),e(g4e,por),e(vF,_or),e(vF,PQ),e(PQ,uor),e(vF,bor),e(U,vor),e(U,FF),e(FF,h4e),e(h4e,For),e(FF,Tor),e(FF,BQ),e(BQ,Mor),e(FF,Eor),e(U,Cor),e(U,TF),e(TF,p4e),e(p4e,wor),e(TF,Aor),e(TF,IQ),e(IQ,Lor),e(TF,yor),e(U,xor),e(U,MF),e(MF,_4e),e(_4e,$or),e(MF,kor),e(MF,NQ),e(NQ,Sor),e(MF,Ror),e(no,Por),e(no,EF),e(EF,Bor),e(EF,u4e),e(u4e,Ior),e(EF,Nor),e(EF,b4e),e(b4e,qor),e(no,jor),M(CF,no,null),b(f,vze,u),b(f,_d,u),e(_d,wF),e(wF,v4e),M(Ry,v4e,null),e(_d,Dor),e(_d,F4e),e(F4e,Gor),b(f,Fze,u),b(f,Go,u),M(Py,Go,null),e(Go,Oor),e(Go,ud),e(ud,Vor),e(ud,qQ),e(qQ,Xor),e(ud,zor),e(ud,jQ),e(jQ,Qor),e(ud,Wor),e(Go,Hor),e(Go,By),e(By,Uor),e(By,T4e),e(T4e,Jor),e(By,Yor),e(Go,Kor),e(Go,ut),M(Iy,ut,null),e(ut,Zor),e(ut,M4e),e(M4e,err),e(ut,orr),e(ut,bd),e(bd,rrr),e(bd,E4e),e(E4e,trr),e(bd,arr),e(bd,DQ),e(DQ,nrr),e(bd,srr),e(ut,lrr),M(AF,ut,null),e(Go,irr),e(Go,so),M(Ny,so,null),e(so,drr),e(so,C4e),e(C4e,crr),e(so,frr),e(so,za),e(za,mrr),e(za,w4e),e(w4e,grr),e(za,hrr),e(za,A4e),e(A4e,prr),e(za,_rr),e(za,L4e),e(L4e,urr),e(za,brr),e(so,vrr),e(so,V),e(V,LF),e(LF,y4e),e(y4e,Frr),e(LF,Trr),e(LF,GQ),e(GQ,Mrr),e(LF,Err),e(V,Crr),e(V,yF),e(yF,x4e),e(x4e,wrr),e(yF,Arr),e(yF,OQ),e(OQ,Lrr),e(yF,yrr),e(V,xrr),e(V,xF),e(xF,$4e),e($4e,$rr),e(xF,krr),e(xF,VQ),e(VQ,Srr),e(xF,Rrr),e(V,Prr),e(V,$F),e($F,k4e),e(k4e,Brr),e($F,Irr),e($F,XQ),e(XQ,Nrr),e($F,qrr),e(V,jrr),e(V,kF),e(kF,S4e),e(S4e,Drr),e(kF,Grr),e(kF,zQ),e(zQ,Orr),e(kF,Vrr),e(V,Xrr),e(V,SF),e(SF,R4e),e(R4e,zrr),e(SF,Qrr),e(SF,QQ),e(QQ,Wrr),e(SF,Hrr),e(V,Urr),e(V,RF),e(RF,P4e),e(P4e,Jrr),e(RF,Yrr),e(RF,WQ),e(WQ,Krr),e(RF,Zrr),e(V,etr),e(V,PF),e(PF,B4e),e(B4e,otr),e(PF,rtr),e(PF,HQ),e(HQ,ttr),e(PF,atr),e(V,ntr),e(V,BF),e(BF,I4e),e(I4e,str),e(BF,ltr),e(BF,UQ),e(UQ,itr),e(BF,dtr),e(V,ctr),e(V,IF),e(IF,N4e),e(N4e,ftr),e(IF,mtr),e(IF,JQ),e(JQ,gtr),e(IF,htr),e(V,ptr),e(V,NF),e(NF,q4e),e(q4e,_tr),e(NF,utr),e(NF,YQ),e(YQ,btr),e(NF,vtr),e(V,Ftr),e(V,qF),e(qF,j4e),e(j4e,Ttr),e(qF,Mtr),e(qF,KQ),e(KQ,Etr),e(qF,Ctr),e(V,wtr),e(V,jF),e(jF,D4e),e(D4e,Atr),e(jF,Ltr),e(jF,ZQ),e(ZQ,ytr),e(jF,xtr),e(V,$tr),e(V,DF),e(DF,G4e),e(G4e,ktr),e(DF,Str),e(DF,eW),e(eW,Rtr),e(DF,Ptr),e(V,Btr),e(V,GF),e(GF,O4e),e(O4e,Itr),e(GF,Ntr),e(GF,oW),e(oW,qtr),e(GF,jtr),e(V,Dtr),e(V,OF),e(OF,V4e),e(V4e,Gtr),e(OF,Otr),e(OF,rW),e(rW,Vtr),e(OF,Xtr),e(V,ztr),e(V,VF),e(VF,X4e),e(X4e,Qtr),e(VF,Wtr),e(VF,tW),e(tW,Htr),e(VF,Utr),e(V,Jtr),e(V,XF),e(XF,z4e),e(z4e,Ytr),e(XF,Ktr),e(XF,aW),e(aW,Ztr),e(XF,ear),e(V,oar),e(V,zF),e(zF,Q4e),e(Q4e,rar),e(zF,tar),e(zF,nW),e(nW,aar),e(zF,nar),e(V,sar),e(V,QF),e(QF,W4e),e(W4e,lar),e(QF,iar),e(QF,sW),e(sW,dar),e(QF,car),e(V,far),e(V,WF),e(WF,H4e),e(H4e,mar),e(WF,gar),e(WF,lW),e(lW,har),e(WF,par),e(V,_ar),e(V,HF),e(HF,U4e),e(U4e,uar),e(HF,bar),e(HF,iW),e(iW,Far),e(HF,Tar),e(V,Mar),e(V,UF),e(UF,J4e),e(J4e,Ear),e(UF,Car),e(UF,dW),e(dW,war),e(UF,Aar),e(V,Lar),e(V,JF),e(JF,Y4e),e(Y4e,yar),e(JF,xar),e(JF,cW),e(cW,$ar),e(JF,kar),e(V,Sar),e(V,YF),e(YF,K4e),e(K4e,Rar),e(YF,Par),e(YF,fW),e(fW,Bar),e(YF,Iar),e(V,Nar),e(V,KF),e(KF,Z4e),e(Z4e,qar),e(KF,jar),e(KF,mW),e(mW,Dar),e(KF,Gar),e(V,Oar),e(V,ZF),e(ZF,e2e),e(e2e,Var),e(ZF,Xar),e(ZF,gW),e(gW,zar),e(ZF,Qar),e(V,War),e(V,e6),e(e6,o2e),e(o2e,Har),e(e6,Uar),e(e6,hW),e(hW,Jar),e(e6,Yar),e(V,Kar),e(V,o6),e(o6,r2e),e(r2e,Zar),e(o6,enr),e(o6,pW),e(pW,onr),e(o6,rnr),e(V,tnr),e(V,r6),e(r6,t2e),e(t2e,anr),e(r6,nnr),e(r6,_W),e(_W,snr),e(r6,lnr),e(V,inr),e(V,t6),e(t6,a2e),e(a2e,dnr),e(t6,cnr),e(t6,uW),e(uW,fnr),e(t6,mnr),e(V,gnr),e(V,a6),e(a6,n2e),e(n2e,hnr),e(a6,pnr),e(a6,bW),e(bW,_nr),e(a6,unr),e(V,bnr),e(V,n6),e(n6,s2e),e(s2e,vnr),e(n6,Fnr),e(n6,vW),e(vW,Tnr),e(n6,Mnr),e(V,Enr),e(V,s6),e(s6,l2e),e(l2e,Cnr),e(s6,wnr),e(s6,FW),e(FW,Anr),e(s6,Lnr),e(V,ynr),e(V,l6),e(l6,i2e),e(i2e,xnr),e(l6,$nr),e(l6,TW),e(TW,knr),e(l6,Snr),e(V,Rnr),e(V,i6),e(i6,d2e),e(d2e,Pnr),e(i6,Bnr),e(i6,MW),e(MW,Inr),e(i6,Nnr),e(V,qnr),e(V,d6),e(d6,c2e),e(c2e,jnr),e(d6,Dnr),e(d6,EW),e(EW,Gnr),e(d6,Onr),e(V,Vnr),e(V,c6),e(c6,f2e),e(f2e,Xnr),e(c6,znr),e(c6,CW),e(CW,Qnr),e(c6,Wnr),e(V,Hnr),e(V,f6),e(f6,m2e),e(m2e,Unr),e(f6,Jnr),e(f6,wW),e(wW,Ynr),e(f6,Knr),e(V,Znr),e(V,m6),e(m6,g2e),e(g2e,esr),e(m6,osr),e(m6,AW),e(AW,rsr),e(m6,tsr),e(V,asr),e(V,g6),e(g6,h2e),e(h2e,nsr),e(g6,ssr),e(g6,LW),e(LW,lsr),e(g6,isr),e(V,dsr),e(V,h6),e(h6,p2e),e(p2e,csr),e(h6,fsr),e(h6,yW),e(yW,msr),e(h6,gsr),e(so,hsr),e(so,p6),e(p6,psr),e(p6,_2e),e(_2e,_sr),e(p6,usr),e(p6,u2e),e(u2e,bsr),e(so,vsr),M(_6,so,null),b(f,Tze,u),b(f,vd,u),e(vd,u6),e(u6,b2e),M(qy,b2e,null),e(vd,Fsr),e(vd,v2e),e(v2e,Tsr),b(f,Mze,u),b(f,Oo,u),M(jy,Oo,null),e(Oo,Msr),e(Oo,Fd),e(Fd,Esr),e(Fd,xW),e(xW,Csr),e(Fd,wsr),e(Fd,$W),e($W,Asr),e(Fd,Lsr),e(Oo,ysr),e(Oo,Dy),e(Dy,xsr),e(Dy,F2e),e(F2e,$sr),e(Dy,ksr),e(Oo,Ssr),e(Oo,bt),M(Gy,bt,null),e(bt,Rsr),e(bt,T2e),e(T2e,Psr),e(bt,Bsr),e(bt,Td),e(Td,Isr),e(Td,M2e),e(M2e,Nsr),e(Td,qsr),e(Td,kW),e(kW,jsr),e(Td,Dsr),e(bt,Gsr),M(b6,bt,null),e(Oo,Osr),e(Oo,lo),M(Oy,lo,null),e(lo,Vsr),e(lo,E2e),e(E2e,Xsr),e(lo,zsr),e(lo,Qa),e(Qa,Qsr),e(Qa,C2e),e(C2e,Wsr),e(Qa,Hsr),e(Qa,w2e),e(w2e,Usr),e(Qa,Jsr),e(Qa,A2e),e(A2e,Ysr),e(Qa,Ksr),e(lo,Zsr),e(lo,L2e),e(L2e,v6),e(v6,y2e),e(y2e,elr),e(v6,olr),e(v6,SW),e(SW,rlr),e(v6,tlr),e(lo,alr),e(lo,F6),e(F6,nlr),e(F6,x2e),e(x2e,slr),e(F6,llr),e(F6,$2e),e($2e,ilr),e(lo,dlr),M(T6,lo,null),b(f,Eze,u),b(f,Md,u),e(Md,M6),e(M6,k2e),M(Vy,k2e,null),e(Md,clr),e(Md,S2e),e(S2e,flr),b(f,Cze,u),b(f,Vo,u),M(Xy,Vo,null),e(Vo,mlr),e(Vo,Ed),e(Ed,glr),e(Ed,RW),e(RW,hlr),e(Ed,plr),e(Ed,PW),e(PW,_lr),e(Ed,ulr),e(Vo,blr),e(Vo,zy),e(zy,vlr),e(zy,R2e),e(R2e,Flr),e(zy,Tlr),e(Vo,Mlr),e(Vo,vt),M(Qy,vt,null),e(vt,Elr),e(vt,P2e),e(P2e,Clr),e(vt,wlr),e(vt,Cd),e(Cd,Alr),e(Cd,B2e),e(B2e,Llr),e(Cd,ylr),e(Cd,BW),e(BW,xlr),e(Cd,$lr),e(vt,klr),M(E6,vt,null),e(Vo,Slr),e(Vo,io),M(Wy,io,null),e(io,Rlr),e(io,I2e),e(I2e,Plr),e(io,Blr),e(io,Wa),e(Wa,Ilr),e(Wa,N2e),e(N2e,Nlr),e(Wa,qlr),e(Wa,q2e),e(q2e,jlr),e(Wa,Dlr),e(Wa,j2e),e(j2e,Glr),e(Wa,Olr),e(io,Vlr),e(io,ue),e(ue,C6),e(C6,D2e),e(D2e,Xlr),e(C6,zlr),e(C6,IW),e(IW,Qlr),e(C6,Wlr),e(ue,Hlr),e(ue,w6),e(w6,G2e),e(G2e,Ulr),e(w6,Jlr),e(w6,NW),e(NW,Ylr),e(w6,Klr),e(ue,Zlr),e(ue,A6),e(A6,O2e),e(O2e,eir),e(A6,oir),e(A6,qW),e(qW,rir),e(A6,tir),e(ue,air),e(ue,L6),e(L6,V2e),e(V2e,nir),e(L6,sir),e(L6,jW),e(jW,lir),e(L6,iir),e(ue,dir),e(ue,Js),e(Js,X2e),e(X2e,cir),e(Js,fir),e(Js,DW),e(DW,mir),e(Js,gir),e(Js,GW),e(GW,hir),e(Js,pir),e(ue,_ir),e(ue,y6),e(y6,z2e),e(z2e,uir),e(y6,bir),e(y6,OW),e(OW,vir),e(y6,Fir),e(ue,Tir),e(ue,Ys),e(Ys,Q2e),e(Q2e,Mir),e(Ys,Eir),e(Ys,VW),e(VW,Cir),e(Ys,wir),e(Ys,XW),e(XW,Air),e(Ys,Lir),e(ue,yir),e(ue,x6),e(x6,W2e),e(W2e,xir),e(x6,$ir),e(x6,zW),e(zW,kir),e(x6,Sir),e(ue,Rir),e(ue,Ft),e(Ft,H2e),e(H2e,Pir),e(Ft,Bir),e(Ft,QW),e(QW,Iir),e(Ft,Nir),e(Ft,WW),e(WW,qir),e(Ft,jir),e(Ft,HW),e(HW,Dir),e(Ft,Gir),e(ue,Oir),e(ue,$6),e($6,U2e),e(U2e,Vir),e($6,Xir),e($6,UW),e(UW,zir),e($6,Qir),e(ue,Wir),e(ue,k6),e(k6,J2e),e(J2e,Hir),e(k6,Uir),e(k6,JW),e(JW,Jir),e(k6,Yir),e(ue,Kir),e(ue,S6),e(S6,Y2e),e(Y2e,Zir),e(S6,edr),e(S6,YW),e(YW,odr),e(S6,rdr),e(ue,tdr),e(ue,R6),e(R6,K2e),e(K2e,adr),e(R6,ndr),e(R6,KW),e(KW,sdr),e(R6,ldr),e(ue,idr),e(ue,P6),e(P6,Z2e),e(Z2e,ddr),e(P6,cdr),e(P6,ZW),e(ZW,fdr),e(P6,mdr),e(ue,gdr),e(ue,B6),e(B6,ebe),e(ebe,hdr),e(B6,pdr),e(B6,eH),e(eH,_dr),e(B6,udr),e(ue,bdr),e(ue,I6),e(I6,obe),e(obe,vdr),e(I6,Fdr),e(I6,oH),e(oH,Tdr),e(I6,Mdr),e(ue,Edr),e(ue,N6),e(N6,rbe),e(rbe,Cdr),e(N6,wdr),e(N6,rH),e(rH,Adr),e(N6,Ldr),e(io,ydr),e(io,q6),e(q6,xdr),e(q6,tbe),e(tbe,$dr),e(q6,kdr),e(q6,abe),e(abe,Sdr),e(io,Rdr),M(j6,io,null),b(f,wze,u),b(f,wd,u),e(wd,D6),e(D6,nbe),M(Hy,nbe,null),e(wd,Pdr),e(wd,sbe),e(sbe,Bdr),b(f,Aze,u),b(f,Xo,u),M(Uy,Xo,null),e(Xo,Idr),e(Xo,Ad),e(Ad,Ndr),e(Ad,tH),e(tH,qdr),e(Ad,jdr),e(Ad,aH),e(aH,Ddr),e(Ad,Gdr),e(Xo,Odr),e(Xo,Jy),e(Jy,Vdr),e(Jy,lbe),e(lbe,Xdr),e(Jy,zdr),e(Xo,Qdr),e(Xo,Tt),M(Yy,Tt,null),e(Tt,Wdr),e(Tt,ibe),e(ibe,Hdr),e(Tt,Udr),e(Tt,Ld),e(Ld,Jdr),e(Ld,dbe),e(dbe,Ydr),e(Ld,Kdr),e(Ld,nH),e(nH,Zdr),e(Ld,ecr),e(Tt,ocr),M(G6,Tt,null),e(Xo,rcr),e(Xo,co),M(Ky,co,null),e(co,tcr),e(co,cbe),e(cbe,acr),e(co,ncr),e(co,Ha),e(Ha,scr),e(Ha,fbe),e(fbe,lcr),e(Ha,icr),e(Ha,mbe),e(mbe,dcr),e(Ha,ccr),e(Ha,gbe),e(gbe,fcr),e(Ha,mcr),e(co,gcr),e(co,hbe),e(hbe,O6),e(O6,pbe),e(pbe,hcr),e(O6,pcr),e(O6,sH),e(sH,_cr),e(O6,ucr),e(co,bcr),e(co,V6),e(V6,vcr),e(V6,_be),e(_be,Fcr),e(V6,Tcr),e(V6,ube),e(ube,Mcr),e(co,Ecr),M(X6,co,null),b(f,Lze,u),b(f,yd,u),e(yd,z6),e(z6,bbe),M(Zy,bbe,null),e(yd,Ccr),e(yd,vbe),e(vbe,wcr),b(f,yze,u),b(f,zo,u),M(e8,zo,null),e(zo,Acr),e(zo,xd),e(xd,Lcr),e(xd,lH),e(lH,ycr),e(xd,xcr),e(xd,iH),e(iH,$cr),e(xd,kcr),e(zo,Scr),e(zo,o8),e(o8,Rcr),e(o8,Fbe),e(Fbe,Pcr),e(o8,Bcr),e(zo,Icr),e(zo,Mt),M(r8,Mt,null),e(Mt,Ncr),e(Mt,Tbe),e(Tbe,qcr),e(Mt,jcr),e(Mt,$d),e($d,Dcr),e($d,Mbe),e(Mbe,Gcr),e($d,Ocr),e($d,dH),e(dH,Vcr),e($d,Xcr),e(Mt,zcr),M(Q6,Mt,null),e(zo,Qcr),e(zo,fo),M(t8,fo,null),e(fo,Wcr),e(fo,Ebe),e(Ebe,Hcr),e(fo,Ucr),e(fo,Ua),e(Ua,Jcr),e(Ua,Cbe),e(Cbe,Ycr),e(Ua,Kcr),e(Ua,wbe),e(wbe,Zcr),e(Ua,efr),e(Ua,Abe),e(Abe,ofr),e(Ua,rfr),e(fo,tfr),e(fo,Lbe),e(Lbe,W6),e(W6,ybe),e(ybe,afr),e(W6,nfr),e(W6,cH),e(cH,sfr),e(W6,lfr),e(fo,ifr),e(fo,H6),e(H6,dfr),e(H6,xbe),e(xbe,cfr),e(H6,ffr),e(H6,$be),e($be,mfr),e(fo,gfr),M(U6,fo,null),b(f,xze,u),b(f,kd,u),e(kd,J6),e(J6,kbe),M(a8,kbe,null),e(kd,hfr),e(kd,Sbe),e(Sbe,pfr),b(f,$ze,u),b(f,Qo,u),M(n8,Qo,null),e(Qo,_fr),e(Qo,Sd),e(Sd,ufr),e(Sd,fH),e(fH,bfr),e(Sd,vfr),e(Sd,mH),e(mH,Ffr),e(Sd,Tfr),e(Qo,Mfr),e(Qo,s8),e(s8,Efr),e(s8,Rbe),e(Rbe,Cfr),e(s8,wfr),e(Qo,Afr),e(Qo,Et),M(l8,Et,null),e(Et,Lfr),e(Et,Pbe),e(Pbe,yfr),e(Et,xfr),e(Et,Rd),e(Rd,$fr),e(Rd,Bbe),e(Bbe,kfr),e(Rd,Sfr),e(Rd,gH),e(gH,Rfr),e(Rd,Pfr),e(Et,Bfr),M(Y6,Et,null),e(Qo,Ifr),e(Qo,mo),M(i8,mo,null),e(mo,Nfr),e(mo,Ibe),e(Ibe,qfr),e(mo,jfr),e(mo,Ja),e(Ja,Dfr),e(Ja,Nbe),e(Nbe,Gfr),e(Ja,Ofr),e(Ja,qbe),e(qbe,Vfr),e(Ja,Xfr),e(Ja,jbe),e(jbe,zfr),e(Ja,Qfr),e(mo,Wfr),e(mo,Pe),e(Pe,K6),e(K6,Dbe),e(Dbe,Hfr),e(K6,Ufr),e(K6,hH),e(hH,Jfr),e(K6,Yfr),e(Pe,Kfr),e(Pe,Z6),e(Z6,Gbe),e(Gbe,Zfr),e(Z6,emr),e(Z6,pH),e(pH,omr),e(Z6,rmr),e(Pe,tmr),e(Pe,eT),e(eT,Obe),e(Obe,amr),e(eT,nmr),e(eT,_H),e(_H,smr),e(eT,lmr),e(Pe,imr),e(Pe,oT),e(oT,Vbe),e(Vbe,dmr),e(oT,cmr),e(oT,uH),e(uH,fmr),e(oT,mmr),e(Pe,gmr),e(Pe,rT),e(rT,Xbe),e(Xbe,hmr),e(rT,pmr),e(rT,bH),e(bH,_mr),e(rT,umr),e(Pe,bmr),e(Pe,tT),e(tT,zbe),e(zbe,vmr),e(tT,Fmr),e(tT,vH),e(vH,Tmr),e(tT,Mmr),e(Pe,Emr),e(Pe,aT),e(aT,Qbe),e(Qbe,Cmr),e(aT,wmr),e(aT,FH),e(FH,Amr),e(aT,Lmr),e(Pe,ymr),e(Pe,nT),e(nT,Wbe),e(Wbe,xmr),e(nT,$mr),e(nT,TH),e(TH,kmr),e(nT,Smr),e(Pe,Rmr),e(Pe,sT),e(sT,Hbe),e(Hbe,Pmr),e(sT,Bmr),e(sT,MH),e(MH,Imr),e(sT,Nmr),e(mo,qmr),e(mo,lT),e(lT,jmr),e(lT,Ube),e(Ube,Dmr),e(lT,Gmr),e(lT,Jbe),e(Jbe,Omr),e(mo,Vmr),M(iT,mo,null),b(f,kze,u),b(f,Pd,u),e(Pd,dT),e(dT,Ybe),M(d8,Ybe,null),e(Pd,Xmr),e(Pd,Kbe),e(Kbe,zmr),b(f,Sze,u),b(f,Wo,u),M(c8,Wo,null),e(Wo,Qmr),e(Wo,Bd),e(Bd,Wmr),e(Bd,EH),e(EH,Hmr),e(Bd,Umr),e(Bd,CH),e(CH,Jmr),e(Bd,Ymr),e(Wo,Kmr),e(Wo,f8),e(f8,Zmr),e(f8,Zbe),e(Zbe,egr),e(f8,ogr),e(Wo,rgr),e(Wo,Ct),M(m8,Ct,null),e(Ct,tgr),e(Ct,eve),e(eve,agr),e(Ct,ngr),e(Ct,Id),e(Id,sgr),e(Id,ove),e(ove,lgr),e(Id,igr),e(Id,wH),e(wH,dgr),e(Id,cgr),e(Ct,fgr),M(cT,Ct,null),e(Wo,mgr),e(Wo,go),M(g8,go,null),e(go,ggr),e(go,rve),e(rve,hgr),e(go,pgr),e(go,Ya),e(Ya,_gr),e(Ya,tve),e(tve,ugr),e(Ya,bgr),e(Ya,ave),e(ave,vgr),e(Ya,Fgr),e(Ya,nve),e(nve,Tgr),e(Ya,Mgr),e(go,Egr),e(go,rt),e(rt,fT),e(fT,sve),e(sve,Cgr),e(fT,wgr),e(fT,AH),e(AH,Agr),e(fT,Lgr),e(rt,ygr),e(rt,mT),e(mT,lve),e(lve,xgr),e(mT,$gr),e(mT,LH),e(LH,kgr),e(mT,Sgr),e(rt,Rgr),e(rt,gT),e(gT,ive),e(ive,Pgr),e(gT,Bgr),e(gT,yH),e(yH,Igr),e(gT,Ngr),e(rt,qgr),e(rt,hT),e(hT,dve),e(dve,jgr),e(hT,Dgr),e(hT,xH),e(xH,Ggr),e(hT,Ogr),e(rt,Vgr),e(rt,pT),e(pT,cve),e(cve,Xgr),e(pT,zgr),e(pT,$H),e($H,Qgr),e(pT,Wgr),e(go,Hgr),e(go,_T),e(_T,Ugr),e(_T,fve),e(fve,Jgr),e(_T,Ygr),e(_T,mve),e(mve,Kgr),e(go,Zgr),M(uT,go,null),b(f,Rze,u),b(f,Nd,u),e(Nd,bT),e(bT,gve),M(h8,gve,null),e(Nd,ehr),e(Nd,hve),e(hve,ohr),b(f,Pze,u),b(f,Ho,u),M(p8,Ho,null),e(Ho,rhr),e(Ho,qd),e(qd,thr),e(qd,kH),e(kH,ahr),e(qd,nhr),e(qd,SH),e(SH,shr),e(qd,lhr),e(Ho,ihr),e(Ho,_8),e(_8,dhr),e(_8,pve),e(pve,chr),e(_8,fhr),e(Ho,mhr),e(Ho,wt),M(u8,wt,null),e(wt,ghr),e(wt,_ve),e(_ve,hhr),e(wt,phr),e(wt,jd),e(jd,_hr),e(jd,uve),e(uve,uhr),e(jd,bhr),e(jd,RH),e(RH,vhr),e(jd,Fhr),e(wt,Thr),M(vT,wt,null),e(Ho,Mhr),e(Ho,ho),M(b8,ho,null),e(ho,Ehr),e(ho,bve),e(bve,Chr),e(ho,whr),e(ho,Ka),e(Ka,Ahr),e(Ka,vve),e(vve,Lhr),e(Ka,yhr),e(Ka,Fve),e(Fve,xhr),e(Ka,$hr),e(Ka,Tve),e(Tve,khr),e(Ka,Shr),e(ho,Rhr),e(ho,Le),e(Le,FT),e(FT,Mve),e(Mve,Phr),e(FT,Bhr),e(FT,PH),e(PH,Ihr),e(FT,Nhr),e(Le,qhr),e(Le,TT),e(TT,Eve),e(Eve,jhr),e(TT,Dhr),e(TT,BH),e(BH,Ghr),e(TT,Ohr),e(Le,Vhr),e(Le,MT),e(MT,Cve),e(Cve,Xhr),e(MT,zhr),e(MT,IH),e(IH,Qhr),e(MT,Whr),e(Le,Hhr),e(Le,ET),e(ET,wve),e(wve,Uhr),e(ET,Jhr),e(ET,NH),e(NH,Yhr),e(ET,Khr),e(Le,Zhr),e(Le,CT),e(CT,Ave),e(Ave,epr),e(CT,opr),e(CT,qH),e(qH,rpr),e(CT,tpr),e(Le,apr),e(Le,wT),e(wT,Lve),e(Lve,npr),e(wT,spr),e(wT,jH),e(jH,lpr),e(wT,ipr),e(Le,dpr),e(Le,AT),e(AT,yve),e(yve,cpr),e(AT,fpr),e(AT,DH),e(DH,mpr),e(AT,gpr),e(Le,hpr),e(Le,LT),e(LT,xve),e(xve,ppr),e(LT,_pr),e(LT,GH),e(GH,upr),e(LT,bpr),e(Le,vpr),e(Le,yT),e(yT,$ve),e($ve,Fpr),e(yT,Tpr),e(yT,OH),e(OH,Mpr),e(yT,Epr),e(Le,Cpr),e(Le,xT),e(xT,kve),e(kve,wpr),e(xT,Apr),e(xT,VH),e(VH,Lpr),e(xT,ypr),e(ho,xpr),e(ho,$T),e($T,$pr),e($T,Sve),e(Sve,kpr),e($T,Spr),e($T,Rve),e(Rve,Rpr),e(ho,Ppr),M(kT,ho,null),b(f,Bze,u),b(f,Dd,u),e(Dd,ST),e(ST,Pve),M(v8,Pve,null),e(Dd,Bpr),e(Dd,Bve),e(Bve,Ipr),b(f,Ize,u),b(f,Uo,u),M(F8,Uo,null),e(Uo,Npr),e(Uo,Gd),e(Gd,qpr),e(Gd,XH),e(XH,jpr),e(Gd,Dpr),e(Gd,zH),e(zH,Gpr),e(Gd,Opr),e(Uo,Vpr),e(Uo,T8),e(T8,Xpr),e(T8,Ive),e(Ive,zpr),e(T8,Qpr),e(Uo,Wpr),e(Uo,At),M(M8,At,null),e(At,Hpr),e(At,Nve),e(Nve,Upr),e(At,Jpr),e(At,Od),e(Od,Ypr),e(Od,qve),e(qve,Kpr),e(Od,Zpr),e(Od,QH),e(QH,e_r),e(Od,o_r),e(At,r_r),M(RT,At,null),e(Uo,t_r),e(Uo,po),M(E8,po,null),e(po,a_r),e(po,jve),e(jve,n_r),e(po,s_r),e(po,Za),e(Za,l_r),e(Za,Dve),e(Dve,i_r),e(Za,d_r),e(Za,Gve),e(Gve,c_r),e(Za,f_r),e(Za,Ove),e(Ove,m_r),e(Za,g_r),e(po,h_r),e(po,C8),e(C8,PT),e(PT,Vve),e(Vve,p_r),e(PT,__r),e(PT,WH),e(WH,u_r),e(PT,b_r),e(C8,v_r),e(C8,BT),e(BT,Xve),e(Xve,F_r),e(BT,T_r),e(BT,HH),e(HH,M_r),e(BT,E_r),e(po,C_r),e(po,IT),e(IT,w_r),e(IT,zve),e(zve,A_r),e(IT,L_r),e(IT,Qve),e(Qve,y_r),e(po,x_r),M(NT,po,null),b(f,Nze,u),b(f,Vd,u),e(Vd,qT),e(qT,Wve),M(w8,Wve,null),e(Vd,$_r),e(Vd,Hve),e(Hve,k_r),b(f,qze,u),b(f,Jo,u),M(A8,Jo,null),e(Jo,S_r),e(Jo,Xd),e(Xd,R_r),e(Xd,UH),e(UH,P_r),e(Xd,B_r),e(Xd,JH),e(JH,I_r),e(Xd,N_r),e(Jo,q_r),e(Jo,L8),e(L8,j_r),e(L8,Uve),e(Uve,D_r),e(L8,G_r),e(Jo,O_r),e(Jo,Lt),M(y8,Lt,null),e(Lt,V_r),e(Lt,Jve),e(Jve,X_r),e(Lt,z_r),e(Lt,zd),e(zd,Q_r),e(zd,Yve),e(Yve,W_r),e(zd,H_r),e(zd,YH),e(YH,U_r),e(zd,J_r),e(Lt,Y_r),M(jT,Lt,null),e(Jo,K_r),e(Jo,_o),M(x8,_o,null),e(_o,Z_r),e(_o,Kve),e(Kve,eur),e(_o,our),e(_o,en),e(en,rur),e(en,Zve),e(Zve,tur),e(en,aur),e(en,eFe),e(eFe,nur),e(en,sur),e(en,oFe),e(oFe,lur),e(en,iur),e(_o,dur),e(_o,tt),e(tt,DT),e(DT,rFe),e(rFe,cur),e(DT,fur),e(DT,KH),e(KH,mur),e(DT,gur),e(tt,hur),e(tt,GT),e(GT,tFe),e(tFe,pur),e(GT,_ur),e(GT,ZH),e(ZH,uur),e(GT,bur),e(tt,vur),e(tt,OT),e(OT,aFe),e(aFe,Fur),e(OT,Tur),e(OT,eU),e(eU,Mur),e(OT,Eur),e(tt,Cur),e(tt,VT),e(VT,nFe),e(nFe,wur),e(VT,Aur),e(VT,oU),e(oU,Lur),e(VT,yur),e(tt,xur),e(tt,XT),e(XT,sFe),e(sFe,$ur),e(XT,kur),e(XT,rU),e(rU,Sur),e(XT,Rur),e(_o,Pur),e(_o,zT),e(zT,Bur),e(zT,lFe),e(lFe,Iur),e(zT,Nur),e(zT,iFe),e(iFe,qur),e(_o,jur),M(QT,_o,null),b(f,jze,u),b(f,Qd,u),e(Qd,WT),e(WT,dFe),M($8,dFe,null),e(Qd,Dur),e(Qd,cFe),e(cFe,Gur),b(f,Dze,u),b(f,Yo,u),M(k8,Yo,null),e(Yo,Our),e(Yo,Wd),e(Wd,Vur),e(Wd,tU),e(tU,Xur),e(Wd,zur),e(Wd,aU),e(aU,Qur),e(Wd,Wur),e(Yo,Hur),e(Yo,S8),e(S8,Uur),e(S8,fFe),e(fFe,Jur),e(S8,Yur),e(Yo,Kur),e(Yo,yt),M(R8,yt,null),e(yt,Zur),e(yt,mFe),e(mFe,e1r),e(yt,o1r),e(yt,Hd),e(Hd,r1r),e(Hd,gFe),e(gFe,t1r),e(Hd,a1r),e(Hd,nU),e(nU,n1r),e(Hd,s1r),e(yt,l1r),M(HT,yt,null),e(Yo,i1r),e(Yo,uo),M(P8,uo,null),e(uo,d1r),e(uo,hFe),e(hFe,c1r),e(uo,f1r),e(uo,on),e(on,m1r),e(on,pFe),e(pFe,g1r),e(on,h1r),e(on,_Fe),e(_Fe,p1r),e(on,_1r),e(on,uFe),e(uFe,u1r),e(on,b1r),e(uo,v1r),e(uo,rn),e(rn,UT),e(UT,bFe),e(bFe,F1r),e(UT,T1r),e(UT,sU),e(sU,M1r),e(UT,E1r),e(rn,C1r),e(rn,JT),e(JT,vFe),e(vFe,w1r),e(JT,A1r),e(JT,lU),e(lU,L1r),e(JT,y1r),e(rn,x1r),e(rn,YT),e(YT,FFe),e(FFe,$1r),e(YT,k1r),e(YT,iU),e(iU,S1r),e(YT,R1r),e(rn,P1r),e(rn,KT),e(KT,TFe),e(TFe,B1r),e(KT,I1r),e(KT,dU),e(dU,N1r),e(KT,q1r),e(uo,j1r),e(uo,ZT),e(ZT,D1r),e(ZT,MFe),e(MFe,G1r),e(ZT,O1r),e(ZT,EFe),e(EFe,V1r),e(uo,X1r),M(e7,uo,null),b(f,Gze,u),b(f,Ud,u),e(Ud,o7),e(o7,CFe),M(B8,CFe,null),e(Ud,z1r),e(Ud,wFe),e(wFe,Q1r),b(f,Oze,u),b(f,Ko,u),M(I8,Ko,null),e(Ko,W1r),e(Ko,Jd),e(Jd,H1r),e(Jd,cU),e(cU,U1r),e(Jd,J1r),e(Jd,fU),e(fU,Y1r),e(Jd,K1r),e(Ko,Z1r),e(Ko,N8),e(N8,e4r),e(N8,AFe),e(AFe,o4r),e(N8,r4r),e(Ko,t4r),e(Ko,xt),M(q8,xt,null),e(xt,a4r),e(xt,LFe),e(LFe,n4r),e(xt,s4r),e(xt,Yd),e(Yd,l4r),e(Yd,yFe),e(yFe,i4r),e(Yd,d4r),e(Yd,mU),e(mU,c4r),e(Yd,f4r),e(xt,m4r),M(r7,xt,null),e(Ko,g4r),e(Ko,bo),M(j8,bo,null),e(bo,h4r),e(bo,xFe),e(xFe,p4r),e(bo,_4r),e(bo,tn),e(tn,u4r),e(tn,$Fe),e($Fe,b4r),e(tn,v4r),e(tn,kFe),e(kFe,F4r),e(tn,T4r),e(tn,SFe),e(SFe,M4r),e(tn,E4r),e(bo,C4r),e(bo,D8),e(D8,t7),e(t7,RFe),e(RFe,w4r),e(t7,A4r),e(t7,gU),e(gU,L4r),e(t7,y4r),e(D8,x4r),e(D8,a7),e(a7,PFe),e(PFe,$4r),e(a7,k4r),e(a7,hU),e(hU,S4r),e(a7,R4r),e(bo,P4r),e(bo,n7),e(n7,B4r),e(n7,BFe),e(BFe,I4r),e(n7,N4r),e(n7,IFe),e(IFe,q4r),e(bo,j4r),M(s7,bo,null),b(f,Vze,u),b(f,Kd,u),e(Kd,l7),e(l7,NFe),M(G8,NFe,null),e(Kd,D4r),e(Kd,qFe),e(qFe,G4r),b(f,Xze,u),b(f,Zo,u),M(O8,Zo,null),e(Zo,O4r),e(Zo,Zd),e(Zd,V4r),e(Zd,pU),e(pU,X4r),e(Zd,z4r),e(Zd,_U),e(_U,Q4r),e(Zd,W4r),e(Zo,H4r),e(Zo,V8),e(V8,U4r),e(V8,jFe),e(jFe,J4r),e(V8,Y4r),e(Zo,K4r),e(Zo,$t),M(X8,$t,null),e($t,Z4r),e($t,DFe),e(DFe,e2r),e($t,o2r),e($t,ec),e(ec,r2r),e(ec,GFe),e(GFe,t2r),e(ec,a2r),e(ec,uU),e(uU,n2r),e(ec,s2r),e($t,l2r),M(i7,$t,null),e(Zo,i2r),e(Zo,vo),M(z8,vo,null),e(vo,d2r),e(vo,OFe),e(OFe,c2r),e(vo,f2r),e(vo,an),e(an,m2r),e(an,VFe),e(VFe,g2r),e(an,h2r),e(an,XFe),e(XFe,p2r),e(an,_2r),e(an,zFe),e(zFe,u2r),e(an,b2r),e(vo,v2r),e(vo,QFe),e(QFe,d7),e(d7,WFe),e(WFe,F2r),e(d7,T2r),e(d7,bU),e(bU,M2r),e(d7,E2r),e(vo,C2r),e(vo,c7),e(c7,w2r),e(c7,HFe),e(HFe,A2r),e(c7,L2r),e(c7,UFe),e(UFe,y2r),e(vo,x2r),M(f7,vo,null),b(f,zze,u),b(f,oc,u),e(oc,m7),e(m7,JFe),M(Q8,JFe,null),e(oc,$2r),e(oc,YFe),e(YFe,k2r),b(f,Qze,u),b(f,er,u),M(W8,er,null),e(er,S2r),e(er,rc),e(rc,R2r),e(rc,vU),e(vU,P2r),e(rc,B2r),e(rc,FU),e(FU,I2r),e(rc,N2r),e(er,q2r),e(er,H8),e(H8,j2r),e(H8,KFe),e(KFe,D2r),e(H8,G2r),e(er,O2r),e(er,kt),M(U8,kt,null),e(kt,V2r),e(kt,ZFe),e(ZFe,X2r),e(kt,z2r),e(kt,tc),e(tc,Q2r),e(tc,e6e),e(e6e,W2r),e(tc,H2r),e(tc,TU),e(TU,U2r),e(tc,J2r),e(kt,Y2r),M(g7,kt,null),e(er,K2r),e(er,Fo),M(J8,Fo,null),e(Fo,Z2r),e(Fo,o6e),e(o6e,ebr),e(Fo,obr),e(Fo,nn),e(nn,rbr),e(nn,r6e),e(r6e,tbr),e(nn,abr),e(nn,t6e),e(t6e,nbr),e(nn,sbr),e(nn,a6e),e(a6e,lbr),e(nn,ibr),e(Fo,dbr),e(Fo,at),e(at,h7),e(h7,n6e),e(n6e,cbr),e(h7,fbr),e(h7,MU),e(MU,mbr),e(h7,gbr),e(at,hbr),e(at,p7),e(p7,s6e),e(s6e,pbr),e(p7,_br),e(p7,EU),e(EU,ubr),e(p7,bbr),e(at,vbr),e(at,_7),e(_7,l6e),e(l6e,Fbr),e(_7,Tbr),e(_7,CU),e(CU,Mbr),e(_7,Ebr),e(at,Cbr),e(at,u7),e(u7,i6e),e(i6e,wbr),e(u7,Abr),e(u7,wU),e(wU,Lbr),e(u7,ybr),e(at,xbr),e(at,b7),e(b7,d6e),e(d6e,$br),e(b7,kbr),e(b7,AU),e(AU,Sbr),e(b7,Rbr),e(Fo,Pbr),e(Fo,v7),e(v7,Bbr),e(v7,c6e),e(c6e,Ibr),e(v7,Nbr),e(v7,f6e),e(f6e,qbr),e(Fo,jbr),M(F7,Fo,null),b(f,Wze,u),b(f,ac,u),e(ac,T7),e(T7,m6e),M(Y8,m6e,null),e(ac,Dbr),e(ac,g6e),e(g6e,Gbr),b(f,Hze,u),b(f,or,u),M(K8,or,null),e(or,Obr),e(or,nc),e(nc,Vbr),e(nc,LU),e(LU,Xbr),e(nc,zbr),e(nc,yU),e(yU,Qbr),e(nc,Wbr),e(or,Hbr),e(or,Z8),e(Z8,Ubr),e(Z8,h6e),e(h6e,Jbr),e(Z8,Ybr),e(or,Kbr),e(or,St),M(ex,St,null),e(St,Zbr),e(St,p6e),e(p6e,evr),e(St,ovr),e(St,sc),e(sc,rvr),e(sc,_6e),e(_6e,tvr),e(sc,avr),e(sc,xU),e(xU,nvr),e(sc,svr),e(St,lvr),M(M7,St,null),e(or,ivr),e(or,To),M(ox,To,null),e(To,dvr),e(To,u6e),e(u6e,cvr),e(To,fvr),e(To,sn),e(sn,mvr),e(sn,b6e),e(b6e,gvr),e(sn,hvr),e(sn,v6e),e(v6e,pvr),e(sn,_vr),e(sn,F6e),e(F6e,uvr),e(sn,bvr),e(To,vvr),e(To,T6e),e(T6e,E7),e(E7,M6e),e(M6e,Fvr),e(E7,Tvr),e(E7,$U),e($U,Mvr),e(E7,Evr),e(To,Cvr),e(To,C7),e(C7,wvr),e(C7,E6e),e(E6e,Avr),e(C7,Lvr),e(C7,C6e),e(C6e,yvr),e(To,xvr),M(w7,To,null),b(f,Uze,u),b(f,lc,u),e(lc,A7),e(A7,w6e),M(rx,w6e,null),e(lc,$vr),e(lc,A6e),e(A6e,kvr),b(f,Jze,u),b(f,rr,u),M(tx,rr,null),e(rr,Svr),e(rr,ic),e(ic,Rvr),e(ic,kU),e(kU,Pvr),e(ic,Bvr),e(ic,SU),e(SU,Ivr),e(ic,Nvr),e(rr,qvr),e(rr,ax),e(ax,jvr),e(ax,L6e),e(L6e,Dvr),e(ax,Gvr),e(rr,Ovr),e(rr,Rt),M(nx,Rt,null),e(Rt,Vvr),e(Rt,y6e),e(y6e,Xvr),e(Rt,zvr),e(Rt,dc),e(dc,Qvr),e(dc,x6e),e(x6e,Wvr),e(dc,Hvr),e(dc,RU),e(RU,Uvr),e(dc,Jvr),e(Rt,Yvr),M(L7,Rt,null),e(rr,Kvr),e(rr,$r),M(sx,$r,null),e($r,Zvr),e($r,$6e),e($6e,eFr),e($r,oFr),e($r,ln),e(ln,rFr),e(ln,k6e),e(k6e,tFr),e(ln,aFr),e(ln,S6e),e(S6e,nFr),e(ln,sFr),e(ln,R6e),e(R6e,lFr),e(ln,iFr),e($r,dFr),e($r,I),e(I,y7),e(y7,P6e),e(P6e,cFr),e(y7,fFr),e(y7,PU),e(PU,mFr),e(y7,gFr),e(I,hFr),e(I,x7),e(x7,B6e),e(B6e,pFr),e(x7,_Fr),e(x7,BU),e(BU,uFr),e(x7,bFr),e(I,vFr),e(I,$7),e($7,I6e),e(I6e,FFr),e($7,TFr),e($7,IU),e(IU,MFr),e($7,EFr),e(I,CFr),e(I,k7),e(k7,N6e),e(N6e,wFr),e(k7,AFr),e(k7,NU),e(NU,LFr),e(k7,yFr),e(I,xFr),e(I,S7),e(S7,q6e),e(q6e,$Fr),e(S7,kFr),e(S7,qU),e(qU,SFr),e(S7,RFr),e(I,PFr),e(I,R7),e(R7,j6e),e(j6e,BFr),e(R7,IFr),e(R7,jU),e(jU,NFr),e(R7,qFr),e(I,jFr),e(I,P7),e(P7,D6e),e(D6e,DFr),e(P7,GFr),e(P7,DU),e(DU,OFr),e(P7,VFr),e(I,XFr),e(I,B7),e(B7,G6e),e(G6e,zFr),e(B7,QFr),e(B7,GU),e(GU,WFr),e(B7,HFr),e(I,UFr),e(I,I7),e(I7,O6e),e(O6e,JFr),e(I7,YFr),e(I7,OU),e(OU,KFr),e(I7,ZFr),e(I,e6r),e(I,N7),e(N7,V6e),e(V6e,o6r),e(N7,r6r),e(N7,VU),e(VU,t6r),e(N7,a6r),e(I,n6r),e(I,q7),e(q7,X6e),e(X6e,s6r),e(q7,l6r),e(q7,XU),e(XU,i6r),e(q7,d6r),e(I,c6r),e(I,j7),e(j7,z6e),e(z6e,f6r),e(j7,m6r),e(j7,zU),e(zU,g6r),e(j7,h6r),e(I,p6r),e(I,D7),e(D7,Q6e),e(Q6e,_6r),e(D7,u6r),e(D7,QU),e(QU,b6r),e(D7,v6r),e(I,F6r),e(I,G7),e(G7,W6e),e(W6e,T6r),e(G7,M6r),e(G7,WU),e(WU,E6r),e(G7,C6r),e(I,w6r),e(I,O7),e(O7,H6e),e(H6e,A6r),e(O7,L6r),e(O7,HU),e(HU,y6r),e(O7,x6r),e(I,$6r),e(I,V7),e(V7,U6e),e(U6e,k6r),e(V7,S6r),e(V7,UU),e(UU,R6r),e(V7,P6r),e(I,B6r),e(I,X7),e(X7,J6e),e(J6e,I6r),e(X7,N6r),e(X7,JU),e(JU,q6r),e(X7,j6r),e(I,D6r),e(I,z7),e(z7,Y6e),e(Y6e,G6r),e(z7,O6r),e(z7,YU),e(YU,V6r),e(z7,X6r),e(I,z6r),e(I,Ks),e(Ks,K6e),e(K6e,Q6r),e(Ks,W6r),e(Ks,KU),e(KU,H6r),e(Ks,U6r),e(Ks,ZU),e(ZU,J6r),e(Ks,Y6r),e(I,K6r),e(I,Q7),e(Q7,Z6e),e(Z6e,Z6r),e(Q7,eTr),e(Q7,eJ),e(eJ,oTr),e(Q7,rTr),e(I,tTr),e(I,W7),e(W7,eTe),e(eTe,aTr),e(W7,nTr),e(W7,oJ),e(oJ,sTr),e(W7,lTr),e(I,iTr),e(I,H7),e(H7,oTe),e(oTe,dTr),e(H7,cTr),e(H7,rJ),e(rJ,fTr),e(H7,mTr),e(I,gTr),e(I,U7),e(U7,rTe),e(rTe,hTr),e(U7,pTr),e(U7,tJ),e(tJ,_Tr),e(U7,uTr),e(I,bTr),e(I,J7),e(J7,tTe),e(tTe,vTr),e(J7,FTr),e(J7,aJ),e(aJ,TTr),e(J7,MTr),e(I,ETr),e(I,Y7),e(Y7,aTe),e(aTe,CTr),e(Y7,wTr),e(Y7,nJ),e(nJ,ATr),e(Y7,LTr),e(I,yTr),e(I,K7),e(K7,nTe),e(nTe,xTr),e(K7,$Tr),e(K7,sJ),e(sJ,kTr),e(K7,STr),e(I,RTr),e(I,Z7),e(Z7,sTe),e(sTe,PTr),e(Z7,BTr),e(Z7,lJ),e(lJ,ITr),e(Z7,NTr),e(I,qTr),e(I,e9),e(e9,lTe),e(lTe,jTr),e(e9,DTr),e(e9,iJ),e(iJ,GTr),e(e9,OTr),e(I,VTr),e(I,o9),e(o9,iTe),e(iTe,XTr),e(o9,zTr),e(o9,dJ),e(dJ,QTr),e(o9,WTr),e(I,HTr),e(I,r9),e(r9,dTe),e(dTe,UTr),e(r9,JTr),e(r9,cJ),e(cJ,YTr),e(r9,KTr),e(I,ZTr),e(I,t9),e(t9,cTe),e(cTe,e7r),e(t9,o7r),e(t9,fJ),e(fJ,r7r),e(t9,t7r),e(I,a7r),e(I,a9),e(a9,fTe),e(fTe,n7r),e(a9,s7r),e(a9,mJ),e(mJ,l7r),e(a9,i7r),e(I,d7r),e(I,n9),e(n9,mTe),e(mTe,c7r),e(n9,f7r),e(n9,gJ),e(gJ,m7r),e(n9,g7r),e(I,h7r),e(I,s9),e(s9,gTe),e(gTe,p7r),e(s9,_7r),e(s9,hJ),e(hJ,u7r),e(s9,b7r),e(I,v7r),e(I,l9),e(l9,hTe),e(hTe,F7r),e(l9,T7r),e(l9,pJ),e(pJ,M7r),e(l9,E7r),e(I,C7r),e(I,i9),e(i9,pTe),e(pTe,w7r),e(i9,A7r),e(i9,_J),e(_J,L7r),e(i9,y7r),e(I,x7r),e(I,d9),e(d9,_Te),e(_Te,$7r),e(d9,k7r),e(d9,uJ),e(uJ,S7r),e(d9,R7r),e(I,P7r),e(I,c9),e(c9,uTe),e(uTe,B7r),e(c9,I7r),e(c9,bJ),e(bJ,N7r),e(c9,q7r),e(I,j7r),e(I,f9),e(f9,bTe),e(bTe,D7r),e(f9,G7r),e(f9,vJ),e(vJ,O7r),e(f9,V7r),e(I,X7r),e(I,m9),e(m9,vTe),e(vTe,z7r),e(m9,Q7r),e(m9,FJ),e(FJ,W7r),e(m9,H7r),e(I,U7r),e(I,g9),e(g9,FTe),e(FTe,J7r),e(g9,Y7r),e(g9,TJ),e(TJ,K7r),e(g9,Z7r),e(I,e9r),e(I,h9),e(h9,TTe),e(TTe,o9r),e(h9,r9r),e(h9,MJ),e(MJ,t9r),e(h9,a9r),e(I,n9r),e(I,p9),e(p9,MTe),e(MTe,s9r),e(p9,l9r),e(p9,EJ),e(EJ,i9r),e(p9,d9r),e(I,c9r),e(I,_9),e(_9,ETe),e(ETe,f9r),e(_9,m9r),e(_9,CJ),e(CJ,g9r),e(_9,h9r),e(I,p9r),e(I,u9),e(u9,CTe),e(CTe,_9r),e(u9,u9r),e(u9,wJ),e(wJ,b9r),e(u9,v9r),e(I,F9r),e(I,b9),e(b9,wTe),e(wTe,T9r),e(b9,M9r),e(b9,AJ),e(AJ,E9r),e(b9,C9r),e(I,w9r),e(I,v9),e(v9,ATe),e(ATe,A9r),e(v9,L9r),e(v9,LJ),e(LJ,y9r),e(v9,x9r),e(I,$9r),e(I,F9),e(F9,LTe),e(LTe,k9r),e(F9,S9r),e(F9,yJ),e(yJ,R9r),e(F9,P9r),e(I,B9r),e(I,T9),e(T9,yTe),e(yTe,I9r),e(T9,N9r),e(T9,xJ),e(xJ,q9r),e(T9,j9r),e(I,D9r),e(I,M9),e(M9,xTe),e(xTe,G9r),e(M9,O9r),e(M9,$J),e($J,V9r),e(M9,X9r),e(I,z9r),e(I,E9),e(E9,$Te),e($Te,Q9r),e(E9,W9r),e(E9,kJ),e(kJ,H9r),e(E9,U9r),e($r,J9r),M(C9,$r,null),b(f,Yze,u),b(f,cc,u),e(cc,w9),e(w9,kTe),M(lx,kTe,null),e(cc,Y9r),e(cc,STe),e(STe,K9r),b(f,Kze,u),b(f,tr,u),M(ix,tr,null),e(tr,Z9r),e(tr,fc),e(fc,eMr),e(fc,SJ),e(SJ,oMr),e(fc,rMr),e(fc,RJ),e(RJ,tMr),e(fc,aMr),e(tr,nMr),e(tr,dx),e(dx,sMr),e(dx,RTe),e(RTe,lMr),e(dx,iMr),e(tr,dMr),e(tr,Pt),M(cx,Pt,null),e(Pt,cMr),e(Pt,PTe),e(PTe,fMr),e(Pt,mMr),e(Pt,mc),e(mc,gMr),e(mc,BTe),e(BTe,hMr),e(mc,pMr),e(mc,PJ),e(PJ,_Mr),e(mc,uMr),e(Pt,bMr),M(A9,Pt,null),e(tr,vMr),e(tr,kr),M(fx,kr,null),e(kr,FMr),e(kr,ITe),e(ITe,TMr),e(kr,MMr),e(kr,dn),e(dn,EMr),e(dn,NTe),e(NTe,CMr),e(dn,wMr),e(dn,qTe),e(qTe,AMr),e(dn,LMr),e(dn,jTe),e(jTe,yMr),e(dn,xMr),e(kr,$Mr),e(kr,se),e(se,L9),e(L9,DTe),e(DTe,kMr),e(L9,SMr),e(L9,BJ),e(BJ,RMr),e(L9,PMr),e(se,BMr),e(se,y9),e(y9,GTe),e(GTe,IMr),e(y9,NMr),e(y9,IJ),e(IJ,qMr),e(y9,jMr),e(se,DMr),e(se,x9),e(x9,OTe),e(OTe,GMr),e(x9,OMr),e(x9,NJ),e(NJ,VMr),e(x9,XMr),e(se,zMr),e(se,$9),e($9,VTe),e(VTe,QMr),e($9,WMr),e($9,qJ),e(qJ,HMr),e($9,UMr),e(se,JMr),e(se,k9),e(k9,XTe),e(XTe,YMr),e(k9,KMr),e(k9,jJ),e(jJ,ZMr),e(k9,eEr),e(se,oEr),e(se,S9),e(S9,zTe),e(zTe,rEr),e(S9,tEr),e(S9,DJ),e(DJ,aEr),e(S9,nEr),e(se,sEr),e(se,R9),e(R9,QTe),e(QTe,lEr),e(R9,iEr),e(R9,GJ),e(GJ,dEr),e(R9,cEr),e(se,fEr),e(se,P9),e(P9,WTe),e(WTe,mEr),e(P9,gEr),e(P9,OJ),e(OJ,hEr),e(P9,pEr),e(se,_Er),e(se,B9),e(B9,HTe),e(HTe,uEr),e(B9,bEr),e(B9,VJ),e(VJ,vEr),e(B9,FEr),e(se,TEr),e(se,I9),e(I9,UTe),e(UTe,MEr),e(I9,EEr),e(I9,XJ),e(XJ,CEr),e(I9,wEr),e(se,AEr),e(se,N9),e(N9,JTe),e(JTe,LEr),e(N9,yEr),e(N9,zJ),e(zJ,xEr),e(N9,$Er),e(se,kEr),e(se,q9),e(q9,YTe),e(YTe,SEr),e(q9,REr),e(q9,QJ),e(QJ,PEr),e(q9,BEr),e(se,IEr),e(se,j9),e(j9,KTe),e(KTe,NEr),e(j9,qEr),e(j9,WJ),e(WJ,jEr),e(j9,DEr),e(se,GEr),e(se,D9),e(D9,ZTe),e(ZTe,OEr),e(D9,VEr),e(D9,HJ),e(HJ,XEr),e(D9,zEr),e(se,QEr),e(se,G9),e(G9,e7e),e(e7e,WEr),e(G9,HEr),e(G9,UJ),e(UJ,UEr),e(G9,JEr),e(se,YEr),e(se,O9),e(O9,o7e),e(o7e,KEr),e(O9,ZEr),e(O9,JJ),e(JJ,eCr),e(O9,oCr),e(se,rCr),e(se,V9),e(V9,r7e),e(r7e,tCr),e(V9,aCr),e(V9,YJ),e(YJ,nCr),e(V9,sCr),e(se,lCr),e(se,X9),e(X9,t7e),e(t7e,iCr),e(X9,dCr),e(X9,KJ),e(KJ,cCr),e(X9,fCr),e(se,mCr),e(se,z9),e(z9,a7e),e(a7e,gCr),e(z9,hCr),e(z9,ZJ),e(ZJ,pCr),e(z9,_Cr),e(se,uCr),e(se,Q9),e(Q9,n7e),e(n7e,bCr),e(Q9,vCr),e(Q9,eY),e(eY,FCr),e(Q9,TCr),e(se,MCr),e(se,W9),e(W9,s7e),e(s7e,ECr),e(W9,CCr),e(W9,oY),e(oY,wCr),e(W9,ACr),e(se,LCr),e(se,H9),e(H9,l7e),e(l7e,yCr),e(H9,xCr),e(H9,rY),e(rY,$Cr),e(H9,kCr),e(se,SCr),e(se,U9),e(U9,i7e),e(i7e,RCr),e(U9,PCr),e(U9,tY),e(tY,BCr),e(U9,ICr),e(kr,NCr),M(J9,kr,null),b(f,Zze,u),b(f,gc,u),e(gc,Y9),e(Y9,d7e),M(mx,d7e,null),e(gc,qCr),e(gc,c7e),e(c7e,jCr),b(f,eQe,u),b(f,ar,u),M(gx,ar,null),e(ar,DCr),e(ar,hc),e(hc,GCr),e(hc,aY),e(aY,OCr),e(hc,VCr),e(hc,nY),e(nY,XCr),e(hc,zCr),e(ar,QCr),e(ar,hx),e(hx,WCr),e(hx,f7e),e(f7e,HCr),e(hx,UCr),e(ar,JCr),e(ar,Bt),M(px,Bt,null),e(Bt,YCr),e(Bt,m7e),e(m7e,KCr),e(Bt,ZCr),e(Bt,pc),e(pc,e5r),e(pc,g7e),e(g7e,o5r),e(pc,r5r),e(pc,sY),e(sY,t5r),e(pc,a5r),e(Bt,n5r),M(K9,Bt,null),e(ar,s5r),e(ar,Sr),M(_x,Sr,null),e(Sr,l5r),e(Sr,h7e),e(h7e,i5r),e(Sr,d5r),e(Sr,cn),e(cn,c5r),e(cn,p7e),e(p7e,f5r),e(cn,m5r),e(cn,_7e),e(_7e,g5r),e(cn,h5r),e(cn,u7e),e(u7e,p5r),e(cn,_5r),e(Sr,u5r),e(Sr,Me),e(Me,Z9),e(Z9,b7e),e(b7e,b5r),e(Z9,v5r),e(Z9,lY),e(lY,F5r),e(Z9,T5r),e(Me,M5r),e(Me,eM),e(eM,v7e),e(v7e,E5r),e(eM,C5r),e(eM,iY),e(iY,w5r),e(eM,A5r),e(Me,L5r),e(Me,oM),e(oM,F7e),e(F7e,y5r),e(oM,x5r),e(oM,dY),e(dY,$5r),e(oM,k5r),e(Me,S5r),e(Me,rM),e(rM,T7e),e(T7e,R5r),e(rM,P5r),e(rM,cY),e(cY,B5r),e(rM,I5r),e(Me,N5r),e(Me,tM),e(tM,M7e),e(M7e,q5r),e(tM,j5r),e(tM,fY),e(fY,D5r),e(tM,G5r),e(Me,O5r),e(Me,aM),e(aM,E7e),e(E7e,V5r),e(aM,X5r),e(aM,mY),e(mY,z5r),e(aM,Q5r),e(Me,W5r),e(Me,nM),e(nM,C7e),e(C7e,H5r),e(nM,U5r),e(nM,gY),e(gY,J5r),e(nM,Y5r),e(Me,K5r),e(Me,sM),e(sM,w7e),e(w7e,Z5r),e(sM,e3r),e(sM,hY),e(hY,o3r),e(sM,r3r),e(Me,t3r),e(Me,lM),e(lM,A7e),e(A7e,a3r),e(lM,n3r),e(lM,pY),e(pY,s3r),e(lM,l3r),e(Me,i3r),e(Me,iM),e(iM,L7e),e(L7e,d3r),e(iM,c3r),e(iM,_Y),e(_Y,f3r),e(iM,m3r),e(Me,g3r),e(Me,dM),e(dM,y7e),e(y7e,h3r),e(dM,p3r),e(dM,uY),e(uY,_3r),e(dM,u3r),e(Me,b3r),e(Me,cM),e(cM,x7e),e(x7e,v3r),e(cM,F3r),e(cM,bY),e(bY,T3r),e(cM,M3r),e(Me,E3r),e(Me,fM),e(fM,$7e),e($7e,C3r),e(fM,w3r),e(fM,vY),e(vY,A3r),e(fM,L3r),e(Sr,y3r),M(mM,Sr,null),b(f,oQe,u),b(f,_c,u),e(_c,gM),e(gM,k7e),M(ux,k7e,null),e(_c,x3r),e(_c,S7e),e(S7e,$3r),b(f,rQe,u),b(f,nr,u),M(bx,nr,null),e(nr,k3r),e(nr,uc),e(uc,S3r),e(uc,FY),e(FY,R3r),e(uc,P3r),e(uc,TY),e(TY,B3r),e(uc,I3r),e(nr,N3r),e(nr,vx),e(vx,q3r),e(vx,R7e),e(R7e,j3r),e(vx,D3r),e(nr,G3r),e(nr,It),M(Fx,It,null),e(It,O3r),e(It,P7e),e(P7e,V3r),e(It,X3r),e(It,bc),e(bc,z3r),e(bc,B7e),e(B7e,Q3r),e(bc,W3r),e(bc,MY),e(MY,H3r),e(bc,U3r),e(It,J3r),M(hM,It,null),e(nr,Y3r),e(nr,Rr),M(Tx,Rr,null),e(Rr,K3r),e(Rr,I7e),e(I7e,Z3r),e(Rr,e0r),e(Rr,fn),e(fn,o0r),e(fn,N7e),e(N7e,r0r),e(fn,t0r),e(fn,q7e),e(q7e,a0r),e(fn,n0r),e(fn,j7e),e(j7e,s0r),e(fn,l0r),e(Rr,i0r),e(Rr,Ve),e(Ve,pM),e(pM,D7e),e(D7e,d0r),e(pM,c0r),e(pM,EY),e(EY,f0r),e(pM,m0r),e(Ve,g0r),e(Ve,_M),e(_M,G7e),e(G7e,h0r),e(_M,p0r),e(_M,CY),e(CY,_0r),e(_M,u0r),e(Ve,b0r),e(Ve,Zs),e(Zs,O7e),e(O7e,v0r),e(Zs,F0r),e(Zs,wY),e(wY,T0r),e(Zs,M0r),e(Zs,AY),e(AY,E0r),e(Zs,C0r),e(Ve,w0r),e(Ve,uM),e(uM,V7e),e(V7e,A0r),e(uM,L0r),e(uM,LY),e(LY,y0r),e(uM,x0r),e(Ve,$0r),e(Ve,bM),e(bM,X7e),e(X7e,k0r),e(bM,S0r),e(bM,yY),e(yY,R0r),e(bM,P0r),e(Ve,B0r),e(Ve,vM),e(vM,z7e),e(z7e,I0r),e(vM,N0r),e(vM,xY),e(xY,q0r),e(vM,j0r),e(Ve,D0r),e(Ve,FM),e(FM,Q7e),e(Q7e,G0r),e(FM,O0r),e(FM,$Y),e($Y,V0r),e(FM,X0r),e(Ve,z0r),e(Ve,TM),e(TM,W7e),e(W7e,Q0r),e(TM,W0r),e(TM,kY),e(kY,H0r),e(TM,U0r),e(Rr,J0r),M(MM,Rr,null),b(f,tQe,u),b(f,vc,u),e(vc,EM),e(EM,H7e),M(Mx,H7e,null),e(vc,Y0r),e(vc,U7e),e(U7e,K0r),b(f,aQe,u),b(f,sr,u),M(Ex,sr,null),e(sr,Z0r),e(sr,Fc),e(Fc,ewr),e(Fc,SY),e(SY,owr),e(Fc,rwr),e(Fc,RY),e(RY,twr),e(Fc,awr),e(sr,nwr),e(sr,Cx),e(Cx,swr),e(Cx,J7e),e(J7e,lwr),e(Cx,iwr),e(sr,dwr),e(sr,Nt),M(wx,Nt,null),e(Nt,cwr),e(Nt,Y7e),e(Y7e,fwr),e(Nt,mwr),e(Nt,Tc),e(Tc,gwr),e(Tc,K7e),e(K7e,hwr),e(Tc,pwr),e(Tc,PY),e(PY,_wr),e(Tc,uwr),e(Nt,bwr),M(CM,Nt,null),e(sr,vwr),e(sr,Pr),M(Ax,Pr,null),e(Pr,Fwr),e(Pr,Z7e),e(Z7e,Twr),e(Pr,Mwr),e(Pr,mn),e(mn,Ewr),e(mn,e9e),e(e9e,Cwr),e(mn,wwr),e(mn,o9e),e(o9e,Awr),e(mn,Lwr),e(mn,r9e),e(r9e,ywr),e(mn,xwr),e(Pr,$wr),e(Pr,ie),e(ie,wM),e(wM,t9e),e(t9e,kwr),e(wM,Swr),e(wM,BY),e(BY,Rwr),e(wM,Pwr),e(ie,Bwr),e(ie,AM),e(AM,a9e),e(a9e,Iwr),e(AM,Nwr),e(AM,IY),e(IY,qwr),e(AM,jwr),e(ie,Dwr),e(ie,LM),e(LM,n9e),e(n9e,Gwr),e(LM,Owr),e(LM,NY),e(NY,Vwr),e(LM,Xwr),e(ie,zwr),e(ie,yM),e(yM,s9e),e(s9e,Qwr),e(yM,Wwr),e(yM,qY),e(qY,Hwr),e(yM,Uwr),e(ie,Jwr),e(ie,xM),e(xM,l9e),e(l9e,Ywr),e(xM,Kwr),e(xM,jY),e(jY,Zwr),e(xM,eAr),e(ie,oAr),e(ie,$M),e($M,i9e),e(i9e,rAr),e($M,tAr),e($M,DY),e(DY,aAr),e($M,nAr),e(ie,sAr),e(ie,kM),e(kM,d9e),e(d9e,lAr),e(kM,iAr),e(kM,GY),e(GY,dAr),e(kM,cAr),e(ie,fAr),e(ie,SM),e(SM,c9e),e(c9e,mAr),e(SM,gAr),e(SM,OY),e(OY,hAr),e(SM,pAr),e(ie,_Ar),e(ie,RM),e(RM,f9e),e(f9e,uAr),e(RM,bAr),e(RM,VY),e(VY,vAr),e(RM,FAr),e(ie,TAr),e(ie,PM),e(PM,m9e),e(m9e,MAr),e(PM,EAr),e(PM,XY),e(XY,CAr),e(PM,wAr),e(ie,AAr),e(ie,BM),e(BM,g9e),e(g9e,LAr),e(BM,yAr),e(BM,zY),e(zY,xAr),e(BM,$Ar),e(ie,kAr),e(ie,IM),e(IM,h9e),e(h9e,SAr),e(IM,RAr),e(IM,QY),e(QY,PAr),e(IM,BAr),e(ie,IAr),e(ie,NM),e(NM,p9e),e(p9e,NAr),e(NM,qAr),e(NM,WY),e(WY,jAr),e(NM,DAr),e(ie,GAr),e(ie,qM),e(qM,_9e),e(_9e,OAr),e(qM,VAr),e(qM,HY),e(HY,XAr),e(qM,zAr),e(ie,QAr),e(ie,jM),e(jM,u9e),e(u9e,WAr),e(jM,HAr),e(jM,UY),e(UY,UAr),e(jM,JAr),e(ie,YAr),e(ie,DM),e(DM,b9e),e(b9e,KAr),e(DM,ZAr),e(DM,JY),e(JY,eLr),e(DM,oLr),e(ie,rLr),e(ie,GM),e(GM,v9e),e(v9e,tLr),e(GM,aLr),e(GM,YY),e(YY,nLr),e(GM,sLr),e(ie,lLr),e(ie,OM),e(OM,F9e),e(F9e,iLr),e(OM,dLr),e(OM,KY),e(KY,cLr),e(OM,fLr),e(ie,mLr),e(ie,VM),e(VM,T9e),e(T9e,gLr),e(VM,hLr),e(VM,ZY),e(ZY,pLr),e(VM,_Lr),e(ie,uLr),e(ie,XM),e(XM,M9e),e(M9e,bLr),e(XM,vLr),e(XM,eK),e(eK,FLr),e(XM,TLr),e(Pr,MLr),M(zM,Pr,null),b(f,nQe,u),b(f,Mc,u),e(Mc,QM),e(QM,E9e),M(Lx,E9e,null),e(Mc,ELr),e(Mc,C9e),e(C9e,CLr),b(f,sQe,u),b(f,lr,u),M(yx,lr,null),e(lr,wLr),e(lr,Ec),e(Ec,ALr),e(Ec,oK),e(oK,LLr),e(Ec,yLr),e(Ec,rK),e(rK,xLr),e(Ec,$Lr),e(lr,kLr),e(lr,xx),e(xx,SLr),e(xx,w9e),e(w9e,RLr),e(xx,PLr),e(lr,BLr),e(lr,qt),M($x,qt,null),e(qt,ILr),e(qt,A9e),e(A9e,NLr),e(qt,qLr),e(qt,Cc),e(Cc,jLr),e(Cc,L9e),e(L9e,DLr),e(Cc,GLr),e(Cc,tK),e(tK,OLr),e(Cc,VLr),e(qt,XLr),M(WM,qt,null),e(lr,zLr),e(lr,Br),M(kx,Br,null),e(Br,QLr),e(Br,y9e),e(y9e,WLr),e(Br,HLr),e(Br,gn),e(gn,ULr),e(gn,x9e),e(x9e,JLr),e(gn,YLr),e(gn,$9e),e($9e,KLr),e(gn,ZLr),e(gn,k9e),e(k9e,eyr),e(gn,oyr),e(Br,ryr),e(Br,ye),e(ye,HM),e(HM,S9e),e(S9e,tyr),e(HM,ayr),e(HM,aK),e(aK,nyr),e(HM,syr),e(ye,lyr),e(ye,UM),e(UM,R9e),e(R9e,iyr),e(UM,dyr),e(UM,nK),e(nK,cyr),e(UM,fyr),e(ye,myr),e(ye,JM),e(JM,P9e),e(P9e,gyr),e(JM,hyr),e(JM,sK),e(sK,pyr),e(JM,_yr),e(ye,uyr),e(ye,YM),e(YM,B9e),e(B9e,byr),e(YM,vyr),e(YM,lK),e(lK,Fyr),e(YM,Tyr),e(ye,Myr),e(ye,KM),e(KM,I9e),e(I9e,Eyr),e(KM,Cyr),e(KM,iK),e(iK,wyr),e(KM,Ayr),e(ye,Lyr),e(ye,ZM),e(ZM,N9e),e(N9e,yyr),e(ZM,xyr),e(ZM,dK),e(dK,$yr),e(ZM,kyr),e(ye,Syr),e(ye,eE),e(eE,q9e),e(q9e,Ryr),e(eE,Pyr),e(eE,cK),e(cK,Byr),e(eE,Iyr),e(ye,Nyr),e(ye,oE),e(oE,j9e),e(j9e,qyr),e(oE,jyr),e(oE,fK),e(fK,Dyr),e(oE,Gyr),e(ye,Oyr),e(ye,rE),e(rE,D9e),e(D9e,Vyr),e(rE,Xyr),e(rE,mK),e(mK,zyr),e(rE,Qyr),e(ye,Wyr),e(ye,tE),e(tE,G9e),e(G9e,Hyr),e(tE,Uyr),e(tE,gK),e(gK,Jyr),e(tE,Yyr),e(Br,Kyr),M(aE,Br,null),b(f,lQe,u),b(f,wc,u),e(wc,nE),e(nE,O9e),M(Sx,O9e,null),e(wc,Zyr),e(wc,V9e),e(V9e,e8r),b(f,iQe,u),b(f,ir,u),M(Rx,ir,null),e(ir,o8r),e(ir,Ac),e(Ac,r8r),e(Ac,hK),e(hK,t8r),e(Ac,a8r),e(Ac,pK),e(pK,n8r),e(Ac,s8r),e(ir,l8r),e(ir,Px),e(Px,i8r),e(Px,X9e),e(X9e,d8r),e(Px,c8r),e(ir,f8r),e(ir,jt),M(Bx,jt,null),e(jt,m8r),e(jt,z9e),e(z9e,g8r),e(jt,h8r),e(jt,Lc),e(Lc,p8r),e(Lc,Q9e),e(Q9e,_8r),e(Lc,u8r),e(Lc,_K),e(_K,b8r),e(Lc,v8r),e(jt,F8r),M(sE,jt,null),e(ir,T8r),e(ir,Ir),M(Ix,Ir,null),e(Ir,M8r),e(Ir,W9e),e(W9e,E8r),e(Ir,C8r),e(Ir,hn),e(hn,w8r),e(hn,H9e),e(H9e,A8r),e(hn,L8r),e(hn,U9e),e(U9e,y8r),e(hn,x8r),e(hn,J9e),e(J9e,$8r),e(hn,k8r),e(Ir,S8r),e(Ir,te),e(te,lE),e(lE,Y9e),e(Y9e,R8r),e(lE,P8r),e(lE,uK),e(uK,B8r),e(lE,I8r),e(te,N8r),e(te,iE),e(iE,K9e),e(K9e,q8r),e(iE,j8r),e(iE,bK),e(bK,D8r),e(iE,G8r),e(te,O8r),e(te,dE),e(dE,Z9e),e(Z9e,V8r),e(dE,X8r),e(dE,vK),e(vK,z8r),e(dE,Q8r),e(te,W8r),e(te,cE),e(cE,eMe),e(eMe,H8r),e(cE,U8r),e(cE,FK),e(FK,J8r),e(cE,Y8r),e(te,K8r),e(te,fE),e(fE,oMe),e(oMe,Z8r),e(fE,exr),e(fE,TK),e(TK,oxr),e(fE,rxr),e(te,txr),e(te,mE),e(mE,rMe),e(rMe,axr),e(mE,nxr),e(mE,MK),e(MK,sxr),e(mE,lxr),e(te,ixr),e(te,gE),e(gE,tMe),e(tMe,dxr),e(gE,cxr),e(gE,EK),e(EK,fxr),e(gE,mxr),e(te,gxr),e(te,hE),e(hE,aMe),e(aMe,hxr),e(hE,pxr),e(hE,CK),e(CK,_xr),e(hE,uxr),e(te,bxr),e(te,pE),e(pE,nMe),e(nMe,vxr),e(pE,Fxr),e(pE,wK),e(wK,Txr),e(pE,Mxr),e(te,Exr),e(te,_E),e(_E,sMe),e(sMe,Cxr),e(_E,wxr),e(_E,AK),e(AK,Axr),e(_E,Lxr),e(te,yxr),e(te,uE),e(uE,lMe),e(lMe,xxr),e(uE,$xr),e(uE,LK),e(LK,kxr),e(uE,Sxr),e(te,Rxr),e(te,bE),e(bE,iMe),e(iMe,Pxr),e(bE,Bxr),e(bE,yK),e(yK,Ixr),e(bE,Nxr),e(te,qxr),e(te,vE),e(vE,dMe),e(dMe,jxr),e(vE,Dxr),e(vE,xK),e(xK,Gxr),e(vE,Oxr),e(te,Vxr),e(te,FE),e(FE,cMe),e(cMe,Xxr),e(FE,zxr),e(FE,$K),e($K,Qxr),e(FE,Wxr),e(te,Hxr),e(te,TE),e(TE,fMe),e(fMe,Uxr),e(TE,Jxr),e(TE,kK),e(kK,Yxr),e(TE,Kxr),e(te,Zxr),e(te,ME),e(ME,mMe),e(mMe,e$r),e(ME,o$r),e(ME,SK),e(SK,r$r),e(ME,t$r),e(te,a$r),e(te,EE),e(EE,gMe),e(gMe,n$r),e(EE,s$r),e(EE,RK),e(RK,l$r),e(EE,i$r),e(te,d$r),e(te,CE),e(CE,hMe),e(hMe,c$r),e(CE,f$r),e(CE,PK),e(PK,m$r),e(CE,g$r),e(te,h$r),e(te,wE),e(wE,pMe),e(pMe,p$r),e(wE,_$r),e(wE,BK),e(BK,u$r),e(wE,b$r),e(te,v$r),e(te,AE),e(AE,_Me),e(_Me,F$r),e(AE,T$r),e(AE,IK),e(IK,M$r),e(AE,E$r),e(te,C$r),e(te,LE),e(LE,uMe),e(uMe,w$r),e(LE,A$r),e(LE,NK),e(NK,L$r),e(LE,y$r),e(te,x$r),e(te,yE),e(yE,bMe),e(bMe,$$r),e(yE,k$r),e(yE,qK),e(qK,S$r),e(yE,R$r),e(te,P$r),e(te,xE),e(xE,vMe),e(vMe,B$r),e(xE,I$r),e(xE,jK),e(jK,N$r),e(xE,q$r),e(te,j$r),e(te,$E),e($E,FMe),e(FMe,D$r),e($E,G$r),e($E,DK),e(DK,O$r),e($E,V$r),e(te,X$r),e(te,kE),e(kE,TMe),e(TMe,z$r),e(kE,Q$r),e(kE,GK),e(GK,W$r),e(kE,H$r),e(te,U$r),e(te,SE),e(SE,MMe),e(MMe,J$r),e(SE,Y$r),e(SE,OK),e(OK,K$r),e(SE,Z$r),e(Ir,ekr),M(RE,Ir,null),b(f,dQe,u),b(f,yc,u),e(yc,PE),e(PE,EMe),M(Nx,EMe,null),e(yc,okr),e(yc,CMe),e(CMe,rkr),b(f,cQe,u),b(f,dr,u),M(qx,dr,null),e(dr,tkr),e(dr,xc),e(xc,akr),e(xc,VK),e(VK,nkr),e(xc,skr),e(xc,XK),e(XK,lkr),e(xc,ikr),e(dr,dkr),e(dr,jx),e(jx,ckr),e(jx,wMe),e(wMe,fkr),e(jx,mkr),e(dr,gkr),e(dr,Dt),M(Dx,Dt,null),e(Dt,hkr),e(Dt,AMe),e(AMe,pkr),e(Dt,_kr),e(Dt,$c),e($c,ukr),e($c,LMe),e(LMe,bkr),e($c,vkr),e($c,zK),e(zK,Fkr),e($c,Tkr),e(Dt,Mkr),M(BE,Dt,null),e(dr,Ekr),e(dr,Nr),M(Gx,Nr,null),e(Nr,Ckr),e(Nr,yMe),e(yMe,wkr),e(Nr,Akr),e(Nr,pn),e(pn,Lkr),e(pn,xMe),e(xMe,ykr),e(pn,xkr),e(pn,$Me),e($Me,$kr),e(pn,kkr),e(pn,kMe),e(kMe,Skr),e(pn,Rkr),e(Nr,Pkr),e(Nr,be),e(be,IE),e(IE,SMe),e(SMe,Bkr),e(IE,Ikr),e(IE,QK),e(QK,Nkr),e(IE,qkr),e(be,jkr),e(be,NE),e(NE,RMe),e(RMe,Dkr),e(NE,Gkr),e(NE,WK),e(WK,Okr),e(NE,Vkr),e(be,Xkr),e(be,qE),e(qE,PMe),e(PMe,zkr),e(qE,Qkr),e(qE,HK),e(HK,Wkr),e(qE,Hkr),e(be,Ukr),e(be,jE),e(jE,BMe),e(BMe,Jkr),e(jE,Ykr),e(jE,UK),e(UK,Kkr),e(jE,Zkr),e(be,eSr),e(be,DE),e(DE,IMe),e(IMe,oSr),e(DE,rSr),e(DE,JK),e(JK,tSr),e(DE,aSr),e(be,nSr),e(be,GE),e(GE,NMe),e(NMe,sSr),e(GE,lSr),e(GE,YK),e(YK,iSr),e(GE,dSr),e(be,cSr),e(be,OE),e(OE,qMe),e(qMe,fSr),e(OE,mSr),e(OE,KK),e(KK,gSr),e(OE,hSr),e(be,pSr),e(be,VE),e(VE,jMe),e(jMe,_Sr),e(VE,uSr),e(VE,ZK),e(ZK,bSr),e(VE,vSr),e(be,FSr),e(be,XE),e(XE,DMe),e(DMe,TSr),e(XE,MSr),e(XE,eZ),e(eZ,ESr),e(XE,CSr),e(be,wSr),e(be,zE),e(zE,GMe),e(GMe,ASr),e(zE,LSr),e(zE,oZ),e(oZ,ySr),e(zE,xSr),e(be,$Sr),e(be,QE),e(QE,OMe),e(OMe,kSr),e(QE,SSr),e(QE,rZ),e(rZ,RSr),e(QE,PSr),e(be,BSr),e(be,WE),e(WE,VMe),e(VMe,ISr),e(WE,NSr),e(WE,tZ),e(tZ,qSr),e(WE,jSr),e(be,DSr),e(be,HE),e(HE,XMe),e(XMe,GSr),e(HE,OSr),e(HE,aZ),e(aZ,VSr),e(HE,XSr),e(be,zSr),e(be,UE),e(UE,zMe),e(zMe,QSr),e(UE,WSr),e(UE,nZ),e(nZ,HSr),e(UE,USr),e(be,JSr),e(be,JE),e(JE,QMe),e(QMe,YSr),e(JE,KSr),e(JE,sZ),e(sZ,ZSr),e(JE,eRr),e(be,oRr),e(be,YE),e(YE,WMe),e(WMe,rRr),e(YE,tRr),e(YE,lZ),e(lZ,aRr),e(YE,nRr),e(be,sRr),e(be,KE),e(KE,HMe),e(HMe,lRr),e(KE,iRr),e(KE,iZ),e(iZ,dRr),e(KE,cRr),e(Nr,fRr),M(ZE,Nr,null),b(f,fQe,u),b(f,kc,u),e(kc,eC),e(eC,UMe),M(Ox,UMe,null),e(kc,mRr),e(kc,JMe),e(JMe,gRr),b(f,mQe,u),b(f,cr,u),M(Vx,cr,null),e(cr,hRr),e(cr,Sc),e(Sc,pRr),e(Sc,dZ),e(dZ,_Rr),e(Sc,uRr),e(Sc,cZ),e(cZ,bRr),e(Sc,vRr),e(cr,FRr),e(cr,Xx),e(Xx,TRr),e(Xx,YMe),e(YMe,MRr),e(Xx,ERr),e(cr,CRr),e(cr,Gt),M(zx,Gt,null),e(Gt,wRr),e(Gt,KMe),e(KMe,ARr),e(Gt,LRr),e(Gt,Rc),e(Rc,yRr),e(Rc,ZMe),e(ZMe,xRr),e(Rc,$Rr),e(Rc,fZ),e(fZ,kRr),e(Rc,SRr),e(Gt,RRr),M(oC,Gt,null),e(cr,PRr),e(cr,qr),M(Qx,qr,null),e(qr,BRr),e(qr,eEe),e(eEe,IRr),e(qr,NRr),e(qr,_n),e(_n,qRr),e(_n,oEe),e(oEe,jRr),e(_n,DRr),e(_n,rEe),e(rEe,GRr),e(_n,ORr),e(_n,tEe),e(tEe,VRr),e(_n,XRr),e(qr,zRr),e(qr,Wx),e(Wx,rC),e(rC,aEe),e(aEe,QRr),e(rC,WRr),e(rC,mZ),e(mZ,HRr),e(rC,URr),e(Wx,JRr),e(Wx,tC),e(tC,nEe),e(nEe,YRr),e(tC,KRr),e(tC,gZ),e(gZ,ZRr),e(tC,ePr),e(qr,oPr),M(aC,qr,null),b(f,gQe,u),b(f,Pc,u),e(Pc,nC),e(nC,sEe),M(Hx,sEe,null),e(Pc,rPr),e(Pc,lEe),e(lEe,tPr),b(f,hQe,u),b(f,fr,u),M(Ux,fr,null),e(fr,aPr),e(fr,Bc),e(Bc,nPr),e(Bc,hZ),e(hZ,sPr),e(Bc,lPr),e(Bc,pZ),e(pZ,iPr),e(Bc,dPr),e(fr,cPr),e(fr,Jx),e(Jx,fPr),e(Jx,iEe),e(iEe,mPr),e(Jx,gPr),e(fr,hPr),e(fr,Ot),M(Yx,Ot,null),e(Ot,pPr),e(Ot,dEe),e(dEe,_Pr),e(Ot,uPr),e(Ot,Ic),e(Ic,bPr),e(Ic,cEe),e(cEe,vPr),e(Ic,FPr),e(Ic,_Z),e(_Z,TPr),e(Ic,MPr),e(Ot,EPr),M(sC,Ot,null),e(fr,CPr),e(fr,jr),M(Kx,jr,null),e(jr,wPr),e(jr,fEe),e(fEe,APr),e(jr,LPr),e(jr,un),e(un,yPr),e(un,mEe),e(mEe,xPr),e(un,$Pr),e(un,gEe),e(gEe,kPr),e(un,SPr),e(un,hEe),e(hEe,RPr),e(un,PPr),e(jr,BPr),e(jr,pEe),e(pEe,lC),e(lC,_Ee),e(_Ee,IPr),e(lC,NPr),e(lC,uZ),e(uZ,qPr),e(lC,jPr),e(jr,DPr),M(iC,jr,null),b(f,pQe,u),b(f,Nc,u),e(Nc,dC),e(dC,uEe),M(Zx,uEe,null),e(Nc,GPr),e(Nc,bEe),e(bEe,OPr),b(f,_Qe,u),b(f,mr,u),M(e$,mr,null),e(mr,VPr),e(mr,qc),e(qc,XPr),e(qc,bZ),e(bZ,zPr),e(qc,QPr),e(qc,vZ),e(vZ,WPr),e(qc,HPr),e(mr,UPr),e(mr,o$),e(o$,JPr),e(o$,vEe),e(vEe,YPr),e(o$,KPr),e(mr,ZPr),e(mr,Vt),M(r$,Vt,null),e(Vt,eBr),e(Vt,FEe),e(FEe,oBr),e(Vt,rBr),e(Vt,jc),e(jc,tBr),e(jc,TEe),e(TEe,aBr),e(jc,nBr),e(jc,FZ),e(FZ,sBr),e(jc,lBr),e(Vt,iBr),M(cC,Vt,null),e(mr,dBr),e(mr,Dr),M(t$,Dr,null),e(Dr,cBr),e(Dr,MEe),e(MEe,fBr),e(Dr,mBr),e(Dr,bn),e(bn,gBr),e(bn,EEe),e(EEe,hBr),e(bn,pBr),e(bn,CEe),e(CEe,_Br),e(bn,uBr),e(bn,wEe),e(wEe,bBr),e(bn,vBr),e(Dr,FBr),e(Dr,de),e(de,fC),e(fC,AEe),e(AEe,TBr),e(fC,MBr),e(fC,TZ),e(TZ,EBr),e(fC,CBr),e(de,wBr),e(de,mC),e(mC,LEe),e(LEe,ABr),e(mC,LBr),e(mC,MZ),e(MZ,yBr),e(mC,xBr),e(de,$Br),e(de,gC),e(gC,yEe),e(yEe,kBr),e(gC,SBr),e(gC,EZ),e(EZ,RBr),e(gC,PBr),e(de,BBr),e(de,hC),e(hC,xEe),e(xEe,IBr),e(hC,NBr),e(hC,CZ),e(CZ,qBr),e(hC,jBr),e(de,DBr),e(de,pC),e(pC,$Ee),e($Ee,GBr),e(pC,OBr),e(pC,wZ),e(wZ,VBr),e(pC,XBr),e(de,zBr),e(de,_C),e(_C,kEe),e(kEe,QBr),e(_C,WBr),e(_C,AZ),e(AZ,HBr),e(_C,UBr),e(de,JBr),e(de,uC),e(uC,SEe),e(SEe,YBr),e(uC,KBr),e(uC,LZ),e(LZ,ZBr),e(uC,eIr),e(de,oIr),e(de,bC),e(bC,REe),e(REe,rIr),e(bC,tIr),e(bC,yZ),e(yZ,aIr),e(bC,nIr),e(de,sIr),e(de,vC),e(vC,PEe),e(PEe,lIr),e(vC,iIr),e(vC,xZ),e(xZ,dIr),e(vC,cIr),e(de,fIr),e(de,FC),e(FC,BEe),e(BEe,mIr),e(FC,gIr),e(FC,$Z),e($Z,hIr),e(FC,pIr),e(de,_Ir),e(de,TC),e(TC,IEe),e(IEe,uIr),e(TC,bIr),e(TC,kZ),e(kZ,vIr),e(TC,FIr),e(de,TIr),e(de,MC),e(MC,NEe),e(NEe,MIr),e(MC,EIr),e(MC,SZ),e(SZ,CIr),e(MC,wIr),e(de,AIr),e(de,EC),e(EC,qEe),e(qEe,LIr),e(EC,yIr),e(EC,RZ),e(RZ,xIr),e(EC,$Ir),e(de,kIr),e(de,CC),e(CC,jEe),e(jEe,SIr),e(CC,RIr),e(CC,PZ),e(PZ,PIr),e(CC,BIr),e(de,IIr),e(de,wC),e(wC,DEe),e(DEe,NIr),e(wC,qIr),e(wC,BZ),e(BZ,jIr),e(wC,DIr),e(de,GIr),e(de,AC),e(AC,GEe),e(GEe,OIr),e(AC,VIr),e(AC,IZ),e(IZ,XIr),e(AC,zIr),e(de,QIr),e(de,LC),e(LC,OEe),e(OEe,WIr),e(LC,HIr),e(LC,NZ),e(NZ,UIr),e(LC,JIr),e(de,YIr),e(de,yC),e(yC,VEe),e(VEe,KIr),e(yC,ZIr),e(yC,qZ),e(qZ,eNr),e(yC,oNr),e(de,rNr),e(de,xC),e(xC,XEe),e(XEe,tNr),e(xC,aNr),e(xC,jZ),e(jZ,nNr),e(xC,sNr),e(de,lNr),e(de,$C),e($C,zEe),e(zEe,iNr),e($C,dNr),e($C,DZ),e(DZ,cNr),e($C,fNr),e(Dr,mNr),M(kC,Dr,null),b(f,uQe,u),b(f,Dc,u),e(Dc,SC),e(SC,QEe),M(a$,QEe,null),e(Dc,gNr),e(Dc,WEe),e(WEe,hNr),b(f,bQe,u),b(f,gr,u),M(n$,gr,null),e(gr,pNr),e(gr,Gc),e(Gc,_Nr),e(Gc,GZ),e(GZ,uNr),e(Gc,bNr),e(Gc,OZ),e(OZ,vNr),e(Gc,FNr),e(gr,TNr),e(gr,s$),e(s$,MNr),e(s$,HEe),e(HEe,ENr),e(s$,CNr),e(gr,wNr),e(gr,Xt),M(l$,Xt,null),e(Xt,ANr),e(Xt,UEe),e(UEe,LNr),e(Xt,yNr),e(Xt,Oc),e(Oc,xNr),e(Oc,JEe),e(JEe,$Nr),e(Oc,kNr),e(Oc,VZ),e(VZ,SNr),e(Oc,RNr),e(Xt,PNr),M(RC,Xt,null),e(gr,BNr),e(gr,Gr),M(i$,Gr,null),e(Gr,INr),e(Gr,YEe),e(YEe,NNr),e(Gr,qNr),e(Gr,vn),e(vn,jNr),e(vn,KEe),e(KEe,DNr),e(vn,GNr),e(vn,ZEe),e(ZEe,ONr),e(vn,VNr),e(vn,eCe),e(eCe,XNr),e(vn,zNr),e(Gr,QNr),e(Gr,ce),e(ce,PC),e(PC,oCe),e(oCe,WNr),e(PC,HNr),e(PC,XZ),e(XZ,UNr),e(PC,JNr),e(ce,YNr),e(ce,BC),e(BC,rCe),e(rCe,KNr),e(BC,ZNr),e(BC,zZ),e(zZ,eqr),e(BC,oqr),e(ce,rqr),e(ce,IC),e(IC,tCe),e(tCe,tqr),e(IC,aqr),e(IC,QZ),e(QZ,nqr),e(IC,sqr),e(ce,lqr),e(ce,NC),e(NC,aCe),e(aCe,iqr),e(NC,dqr),e(NC,WZ),e(WZ,cqr),e(NC,fqr),e(ce,mqr),e(ce,qC),e(qC,nCe),e(nCe,gqr),e(qC,hqr),e(qC,HZ),e(HZ,pqr),e(qC,_qr),e(ce,uqr),e(ce,jC),e(jC,sCe),e(sCe,bqr),e(jC,vqr),e(jC,UZ),e(UZ,Fqr),e(jC,Tqr),e(ce,Mqr),e(ce,DC),e(DC,lCe),e(lCe,Eqr),e(DC,Cqr),e(DC,JZ),e(JZ,wqr),e(DC,Aqr),e(ce,Lqr),e(ce,GC),e(GC,iCe),e(iCe,yqr),e(GC,xqr),e(GC,YZ),e(YZ,$qr),e(GC,kqr),e(ce,Sqr),e(ce,OC),e(OC,dCe),e(dCe,Rqr),e(OC,Pqr),e(OC,KZ),e(KZ,Bqr),e(OC,Iqr),e(ce,Nqr),e(ce,VC),e(VC,cCe),e(cCe,qqr),e(VC,jqr),e(VC,ZZ),e(ZZ,Dqr),e(VC,Gqr),e(ce,Oqr),e(ce,XC),e(XC,fCe),e(fCe,Vqr),e(XC,Xqr),e(XC,eee),e(eee,zqr),e(XC,Qqr),e(ce,Wqr),e(ce,zC),e(zC,mCe),e(mCe,Hqr),e(zC,Uqr),e(zC,oee),e(oee,Jqr),e(zC,Yqr),e(ce,Kqr),e(ce,QC),e(QC,gCe),e(gCe,Zqr),e(QC,ejr),e(QC,ree),e(ree,ojr),e(QC,rjr),e(ce,tjr),e(ce,WC),e(WC,hCe),e(hCe,ajr),e(WC,njr),e(WC,tee),e(tee,sjr),e(WC,ljr),e(ce,ijr),e(ce,HC),e(HC,pCe),e(pCe,djr),e(HC,cjr),e(HC,aee),e(aee,fjr),e(HC,mjr),e(ce,gjr),e(ce,UC),e(UC,_Ce),e(_Ce,hjr),e(UC,pjr),e(UC,nee),e(nee,_jr),e(UC,ujr),e(ce,bjr),e(ce,JC),e(JC,uCe),e(uCe,vjr),e(JC,Fjr),e(JC,see),e(see,Tjr),e(JC,Mjr),e(ce,Ejr),e(ce,YC),e(YC,bCe),e(bCe,Cjr),e(YC,wjr),e(YC,lee),e(lee,Ajr),e(YC,Ljr),e(ce,yjr),e(ce,KC),e(KC,vCe),e(vCe,xjr),e(KC,$jr),e(KC,iee),e(iee,kjr),e(KC,Sjr),e(ce,Rjr),e(ce,ZC),e(ZC,FCe),e(FCe,Pjr),e(ZC,Bjr),e(ZC,dee),e(dee,Ijr),e(ZC,Njr),e(Gr,qjr),M(e5,Gr,null),b(f,vQe,u),b(f,Vc,u),e(Vc,o5),e(o5,TCe),M(d$,TCe,null),e(Vc,jjr),e(Vc,MCe),e(MCe,Djr),b(f,FQe,u),b(f,hr,u),M(c$,hr,null),e(hr,Gjr),e(hr,Xc),e(Xc,Ojr),e(Xc,cee),e(cee,Vjr),e(Xc,Xjr),e(Xc,fee),e(fee,zjr),e(Xc,Qjr),e(hr,Wjr),e(hr,f$),e(f$,Hjr),e(f$,ECe),e(ECe,Ujr),e(f$,Jjr),e(hr,Yjr),e(hr,zt),M(m$,zt,null),e(zt,Kjr),e(zt,CCe),e(CCe,Zjr),e(zt,eDr),e(zt,zc),e(zc,oDr),e(zc,wCe),e(wCe,rDr),e(zc,tDr),e(zc,mee),e(mee,aDr),e(zc,nDr),e(zt,sDr),M(r5,zt,null),e(hr,lDr),e(hr,Or),M(g$,Or,null),e(Or,iDr),e(Or,ACe),e(ACe,dDr),e(Or,cDr),e(Or,Fn),e(Fn,fDr),e(Fn,LCe),e(LCe,mDr),e(Fn,gDr),e(Fn,yCe),e(yCe,hDr),e(Fn,pDr),e(Fn,xCe),e(xCe,_Dr),e(Fn,uDr),e(Or,bDr),e(Or,$Ce),e($Ce,t5),e(t5,kCe),e(kCe,vDr),e(t5,FDr),e(t5,gee),e(gee,TDr),e(t5,MDr),e(Or,EDr),M(a5,Or,null),b(f,TQe,u),b(f,Qc,u),e(Qc,n5),e(n5,SCe),M(h$,SCe,null),e(Qc,CDr),e(Qc,RCe),e(RCe,wDr),b(f,MQe,u),b(f,pr,u),M(p$,pr,null),e(pr,ADr),e(pr,Wc),e(Wc,LDr),e(Wc,hee),e(hee,yDr),e(Wc,xDr),e(Wc,pee),e(pee,$Dr),e(Wc,kDr),e(pr,SDr),e(pr,_$),e(_$,RDr),e(_$,PCe),e(PCe,PDr),e(_$,BDr),e(pr,IDr),e(pr,Qt),M(u$,Qt,null),e(Qt,NDr),e(Qt,BCe),e(BCe,qDr),e(Qt,jDr),e(Qt,Hc),e(Hc,DDr),e(Hc,ICe),e(ICe,GDr),e(Hc,ODr),e(Hc,_ee),e(_ee,VDr),e(Hc,XDr),e(Qt,zDr),M(s5,Qt,null),e(pr,QDr),e(pr,Vr),M(b$,Vr,null),e(Vr,WDr),e(Vr,NCe),e(NCe,HDr),e(Vr,UDr),e(Vr,Tn),e(Tn,JDr),e(Tn,qCe),e(qCe,YDr),e(Tn,KDr),e(Tn,jCe),e(jCe,ZDr),e(Tn,eGr),e(Tn,DCe),e(DCe,oGr),e(Tn,rGr),e(Vr,tGr),e(Vr,GCe),e(GCe,l5),e(l5,OCe),e(OCe,aGr),e(l5,nGr),e(l5,uee),e(uee,sGr),e(l5,lGr),e(Vr,iGr),M(i5,Vr,null),b(f,EQe,u),b(f,Uc,u),e(Uc,d5),e(d5,VCe),M(v$,VCe,null),e(Uc,dGr),e(Uc,XCe),e(XCe,cGr),b(f,CQe,u),b(f,_r,u),M(F$,_r,null),e(_r,fGr),e(_r,Jc),e(Jc,mGr),e(Jc,bee),e(bee,gGr),e(Jc,hGr),e(Jc,vee),e(vee,pGr),e(Jc,_Gr),e(_r,uGr),e(_r,T$),e(T$,bGr),e(T$,zCe),e(zCe,vGr),e(T$,FGr),e(_r,TGr),e(_r,Wt),M(M$,Wt,null),e(Wt,MGr),e(Wt,QCe),e(QCe,EGr),e(Wt,CGr),e(Wt,Yc),e(Yc,wGr),e(Yc,WCe),e(WCe,AGr),e(Yc,LGr),e(Yc,Fee),e(Fee,yGr),e(Yc,xGr),e(Wt,$Gr),M(c5,Wt,null),e(_r,kGr),e(_r,Xr),M(E$,Xr,null),e(Xr,SGr),e(Xr,HCe),e(HCe,RGr),e(Xr,PGr),e(Xr,Mn),e(Mn,BGr),e(Mn,UCe),e(UCe,IGr),e(Mn,NGr),e(Mn,JCe),e(JCe,qGr),e(Mn,jGr),e(Mn,YCe),e(YCe,DGr),e(Mn,GGr),e(Xr,OGr),e(Xr,oe),e(oe,f5),e(f5,KCe),e(KCe,VGr),e(f5,XGr),e(f5,Tee),e(Tee,zGr),e(f5,QGr),e(oe,WGr),e(oe,m5),e(m5,ZCe),e(ZCe,HGr),e(m5,UGr),e(m5,Mee),e(Mee,JGr),e(m5,YGr),e(oe,KGr),e(oe,g5),e(g5,e5e),e(e5e,ZGr),e(g5,eOr),e(g5,Eee),e(Eee,oOr),e(g5,rOr),e(oe,tOr),e(oe,h5),e(h5,o5e),e(o5e,aOr),e(h5,nOr),e(h5,Cee),e(Cee,sOr),e(h5,lOr),e(oe,iOr),e(oe,p5),e(p5,r5e),e(r5e,dOr),e(p5,cOr),e(p5,wee),e(wee,fOr),e(p5,mOr),e(oe,gOr),e(oe,_5),e(_5,t5e),e(t5e,hOr),e(_5,pOr),e(_5,Aee),e(Aee,_Or),e(_5,uOr),e(oe,bOr),e(oe,u5),e(u5,a5e),e(a5e,vOr),e(u5,FOr),e(u5,Lee),e(Lee,TOr),e(u5,MOr),e(oe,EOr),e(oe,b5),e(b5,n5e),e(n5e,COr),e(b5,wOr),e(b5,yee),e(yee,AOr),e(b5,LOr),e(oe,yOr),e(oe,v5),e(v5,s5e),e(s5e,xOr),e(v5,$Or),e(v5,xee),e(xee,kOr),e(v5,SOr),e(oe,ROr),e(oe,F5),e(F5,l5e),e(l5e,POr),e(F5,BOr),e(F5,$ee),e($ee,IOr),e(F5,NOr),e(oe,qOr),e(oe,T5),e(T5,i5e),e(i5e,jOr),e(T5,DOr),e(T5,kee),e(kee,GOr),e(T5,OOr),e(oe,VOr),e(oe,M5),e(M5,d5e),e(d5e,XOr),e(M5,zOr),e(M5,See),e(See,QOr),e(M5,WOr),e(oe,HOr),e(oe,E5),e(E5,c5e),e(c5e,UOr),e(E5,JOr),e(E5,Ree),e(Ree,YOr),e(E5,KOr),e(oe,ZOr),e(oe,C5),e(C5,f5e),e(f5e,eVr),e(C5,oVr),e(C5,Pee),e(Pee,rVr),e(C5,tVr),e(oe,aVr),e(oe,w5),e(w5,m5e),e(m5e,nVr),e(w5,sVr),e(w5,Bee),e(Bee,lVr),e(w5,iVr),e(oe,dVr),e(oe,A5),e(A5,g5e),e(g5e,cVr),e(A5,fVr),e(A5,Iee),e(Iee,mVr),e(A5,gVr),e(oe,hVr),e(oe,L5),e(L5,h5e),e(h5e,pVr),e(L5,_Vr),e(L5,Nee),e(Nee,uVr),e(L5,bVr),e(oe,vVr),e(oe,y5),e(y5,p5e),e(p5e,FVr),e(y5,TVr),e(y5,qee),e(qee,MVr),e(y5,EVr),e(oe,CVr),e(oe,x5),e(x5,_5e),e(_5e,wVr),e(x5,AVr),e(x5,jee),e(jee,LVr),e(x5,yVr),e(oe,xVr),e(oe,$5),e($5,u5e),e(u5e,$Vr),e($5,kVr),e($5,Dee),e(Dee,SVr),e($5,RVr),e(oe,PVr),e(oe,k5),e(k5,b5e),e(b5e,BVr),e(k5,IVr),e(k5,Gee),e(Gee,NVr),e(k5,qVr),e(oe,jVr),e(oe,S5),e(S5,v5e),e(v5e,DVr),e(S5,GVr),e(S5,Oee),e(Oee,OVr),e(S5,VVr),e(oe,XVr),e(oe,R5),e(R5,F5e),e(F5e,zVr),e(R5,QVr),e(R5,Vee),e(Vee,WVr),e(R5,HVr),e(oe,UVr),e(oe,P5),e(P5,T5e),e(T5e,JVr),e(P5,YVr),e(P5,Xee),e(Xee,KVr),e(P5,ZVr),e(oe,eXr),e(oe,B5),e(B5,M5e),e(M5e,oXr),e(B5,rXr),e(B5,zee),e(zee,tXr),e(B5,aXr),e(oe,nXr),e(oe,I5),e(I5,E5e),e(E5e,sXr),e(I5,lXr),e(I5,Qee),e(Qee,iXr),e(I5,dXr),e(oe,cXr),e(oe,N5),e(N5,C5e),e(C5e,fXr),e(N5,mXr),e(N5,Wee),e(Wee,gXr),e(N5,hXr),e(Xr,pXr),M(q5,Xr,null),b(f,wQe,u),b(f,Kc,u),e(Kc,j5),e(j5,w5e),M(C$,w5e,null),e(Kc,_Xr),e(Kc,A5e),e(A5e,uXr),b(f,AQe,u),b(f,ur,u),M(w$,ur,null),e(ur,bXr),e(ur,Zc),e(Zc,vXr),e(Zc,Hee),e(Hee,FXr),e(Zc,TXr),e(Zc,Uee),e(Uee,MXr),e(Zc,EXr),e(ur,CXr),e(ur,A$),e(A$,wXr),e(A$,L5e),e(L5e,AXr),e(A$,LXr),e(ur,yXr),e(ur,Ht),M(L$,Ht,null),e(Ht,xXr),e(Ht,y5e),e(y5e,$Xr),e(Ht,kXr),e(Ht,ef),e(ef,SXr),e(ef,x5e),e(x5e,RXr),e(ef,PXr),e(ef,Jee),e(Jee,BXr),e(ef,IXr),e(Ht,NXr),M(D5,Ht,null),e(ur,qXr),e(ur,zr),M(y$,zr,null),e(zr,jXr),e(zr,$5e),e($5e,DXr),e(zr,GXr),e(zr,En),e(En,OXr),e(En,k5e),e(k5e,VXr),e(En,XXr),e(En,S5e),e(S5e,zXr),e(En,QXr),e(En,R5e),e(R5e,WXr),e(En,HXr),e(zr,UXr),e(zr,xe),e(xe,G5),e(G5,P5e),e(P5e,JXr),e(G5,YXr),e(G5,Yee),e(Yee,KXr),e(G5,ZXr),e(xe,ezr),e(xe,O5),e(O5,B5e),e(B5e,ozr),e(O5,rzr),e(O5,Kee),e(Kee,tzr),e(O5,azr),e(xe,nzr),e(xe,V5),e(V5,I5e),e(I5e,szr),e(V5,lzr),e(V5,Zee),e(Zee,izr),e(V5,dzr),e(xe,czr),e(xe,X5),e(X5,N5e),e(N5e,fzr),e(X5,mzr),e(X5,eoe),e(eoe,gzr),e(X5,hzr),e(xe,pzr),e(xe,z5),e(z5,q5e),e(q5e,_zr),e(z5,uzr),e(z5,ooe),e(ooe,bzr),e(z5,vzr),e(xe,Fzr),e(xe,Q5),e(Q5,j5e),e(j5e,Tzr),e(Q5,Mzr),e(Q5,roe),e(roe,Ezr),e(Q5,Czr),e(xe,wzr),e(xe,W5),e(W5,D5e),e(D5e,Azr),e(W5,Lzr),e(W5,toe),e(toe,yzr),e(W5,xzr),e(xe,$zr),e(xe,H5),e(H5,G5e),e(G5e,kzr),e(H5,Szr),e(H5,aoe),e(aoe,Rzr),e(H5,Pzr),e(xe,Bzr),e(xe,U5),e(U5,O5e),e(O5e,Izr),e(U5,Nzr),e(U5,noe),e(noe,qzr),e(U5,jzr),e(xe,Dzr),e(xe,J5),e(J5,V5e),e(V5e,Gzr),e(J5,Ozr),e(J5,soe),e(soe,Vzr),e(J5,Xzr),e(zr,zzr),M(Y5,zr,null),b(f,LQe,u),b(f,of,u),e(of,K5),e(K5,X5e),M(x$,X5e,null),e(of,Qzr),e(of,z5e),e(z5e,Wzr),b(f,yQe,u),b(f,br,u),M($$,br,null),e(br,Hzr),e(br,rf),e(rf,Uzr),e(rf,loe),e(loe,Jzr),e(rf,Yzr),e(rf,ioe),e(ioe,Kzr),e(rf,Zzr),e(br,eQr),e(br,k$),e(k$,oQr),e(k$,Q5e),e(Q5e,rQr),e(k$,tQr),e(br,aQr),e(br,Ut),M(S$,Ut,null),e(Ut,nQr),e(Ut,W5e),e(W5e,sQr),e(Ut,lQr),e(Ut,tf),e(tf,iQr),e(tf,H5e),e(H5e,dQr),e(tf,cQr),e(tf,doe),e(doe,fQr),e(tf,mQr),e(Ut,gQr),M(Z5,Ut,null),e(br,hQr),e(br,Qr),M(R$,Qr,null),e(Qr,pQr),e(Qr,U5e),e(U5e,_Qr),e(Qr,uQr),e(Qr,Cn),e(Cn,bQr),e(Cn,J5e),e(J5e,vQr),e(Cn,FQr),e(Cn,Y5e),e(Y5e,TQr),e(Cn,MQr),e(Cn,K5e),e(K5e,EQr),e(Cn,CQr),e(Qr,wQr),e(Qr,Ee),e(Ee,e3),e(e3,Z5e),e(Z5e,AQr),e(e3,LQr),e(e3,coe),e(coe,yQr),e(e3,xQr),e(Ee,$Qr),e(Ee,o3),e(o3,e3e),e(e3e,kQr),e(o3,SQr),e(o3,foe),e(foe,RQr),e(o3,PQr),e(Ee,BQr),e(Ee,r3),e(r3,o3e),e(o3e,IQr),e(r3,NQr),e(r3,moe),e(moe,qQr),e(r3,jQr),e(Ee,DQr),e(Ee,t3),e(t3,r3e),e(r3e,GQr),e(t3,OQr),e(t3,goe),e(goe,VQr),e(t3,XQr),e(Ee,zQr),e(Ee,a3),e(a3,t3e),e(t3e,QQr),e(a3,WQr),e(a3,hoe),e(hoe,HQr),e(a3,UQr),e(Ee,JQr),e(Ee,n3),e(n3,a3e),e(a3e,YQr),e(n3,KQr),e(n3,poe),e(poe,ZQr),e(n3,eWr),e(Ee,oWr),e(Ee,s3),e(s3,n3e),e(n3e,rWr),e(s3,tWr),e(s3,_oe),e(_oe,aWr),e(s3,nWr),e(Ee,sWr),e(Ee,l3),e(l3,s3e),e(s3e,lWr),e(l3,iWr),e(l3,uoe),e(uoe,dWr),e(l3,cWr),e(Ee,fWr),e(Ee,i3),e(i3,l3e),e(l3e,mWr),e(i3,gWr),e(i3,boe),e(boe,hWr),e(i3,pWr),e(Ee,_Wr),e(Ee,d3),e(d3,i3e),e(i3e,uWr),e(d3,bWr),e(d3,voe),e(voe,vWr),e(d3,FWr),e(Ee,TWr),e(Ee,c3),e(c3,d3e),e(d3e,MWr),e(c3,EWr),e(c3,Foe),e(Foe,CWr),e(c3,wWr),e(Ee,AWr),e(Ee,f3),e(f3,c3e),e(c3e,LWr),e(f3,yWr),e(f3,Toe),e(Toe,xWr),e(f3,$Wr),e(Ee,kWr),e(Ee,m3),e(m3,f3e),e(f3e,SWr),e(m3,RWr),e(m3,Moe),e(Moe,PWr),e(m3,BWr),e(Qr,IWr),M(g3,Qr,null),b(f,xQe,u),b(f,af,u),e(af,h3),e(h3,m3e),M(P$,m3e,null),e(af,NWr),e(af,g3e),e(g3e,qWr),b(f,$Qe,u),b(f,vr,u),M(B$,vr,null),e(vr,jWr),e(vr,nf),e(nf,DWr),e(nf,Eoe),e(Eoe,GWr),e(nf,OWr),e(nf,Coe),e(Coe,VWr),e(nf,XWr),e(vr,zWr),e(vr,I$),e(I$,QWr),e(I$,h3e),e(h3e,WWr),e(I$,HWr),e(vr,UWr),e(vr,Jt),M(N$,Jt,null),e(Jt,JWr),e(Jt,p3e),e(p3e,YWr),e(Jt,KWr),e(Jt,sf),e(sf,ZWr),e(sf,_3e),e(_3e,eHr),e(sf,oHr),e(sf,woe),e(woe,rHr),e(sf,tHr),e(Jt,aHr),M(p3,Jt,null),e(vr,nHr),e(vr,Wr),M(q$,Wr,null),e(Wr,sHr),e(Wr,u3e),e(u3e,lHr),e(Wr,iHr),e(Wr,wn),e(wn,dHr),e(wn,b3e),e(b3e,cHr),e(wn,fHr),e(wn,v3e),e(v3e,mHr),e(wn,gHr),e(wn,F3e),e(F3e,hHr),e(wn,pHr),e(Wr,_Hr),e(Wr,$e),e($e,_3),e(_3,T3e),e(T3e,uHr),e(_3,bHr),e(_3,Aoe),e(Aoe,vHr),e(_3,FHr),e($e,THr),e($e,u3),e(u3,M3e),e(M3e,MHr),e(u3,EHr),e(u3,Loe),e(Loe,CHr),e(u3,wHr),e($e,AHr),e($e,b3),e(b3,E3e),e(E3e,LHr),e(b3,yHr),e(b3,yoe),e(yoe,xHr),e(b3,$Hr),e($e,kHr),e($e,v3),e(v3,C3e),e(C3e,SHr),e(v3,RHr),e(v3,xoe),e(xoe,PHr),e(v3,BHr),e($e,IHr),e($e,F3),e(F3,w3e),e(w3e,NHr),e(F3,qHr),e(F3,$oe),e($oe,jHr),e(F3,DHr),e($e,GHr),e($e,T3),e(T3,A3e),e(A3e,OHr),e(T3,VHr),e(T3,koe),e(koe,XHr),e(T3,zHr),e($e,QHr),e($e,M3),e(M3,L3e),e(L3e,WHr),e(M3,HHr),e(M3,Soe),e(Soe,UHr),e(M3,JHr),e($e,YHr),e($e,E3),e(E3,y3e),e(y3e,KHr),e(E3,ZHr),e(E3,Roe),e(Roe,eUr),e(E3,oUr),e($e,rUr),e($e,C3),e(C3,x3e),e(x3e,tUr),e(C3,aUr),e(C3,Poe),e(Poe,nUr),e(C3,sUr),e($e,lUr),e($e,w3),e(w3,$3e),e($3e,iUr),e(w3,dUr),e(w3,Boe),e(Boe,cUr),e(w3,fUr),e(Wr,mUr),M(A3,Wr,null),b(f,kQe,u),b(f,lf,u),e(lf,L3),e(L3,k3e),M(j$,k3e,null),e(lf,gUr),e(lf,S3e),e(S3e,hUr),b(f,SQe,u),b(f,Fr,u),M(D$,Fr,null),e(Fr,pUr),e(Fr,df),e(df,_Ur),e(df,Ioe),e(Ioe,uUr),e(df,bUr),e(df,Noe),e(Noe,vUr),e(df,FUr),e(Fr,TUr),e(Fr,G$),e(G$,MUr),e(G$,R3e),e(R3e,EUr),e(G$,CUr),e(Fr,wUr),e(Fr,Yt),M(O$,Yt,null),e(Yt,AUr),e(Yt,P3e),e(P3e,LUr),e(Yt,yUr),e(Yt,cf),e(cf,xUr),e(cf,B3e),e(B3e,$Ur),e(cf,kUr),e(cf,qoe),e(qoe,SUr),e(cf,RUr),e(Yt,PUr),M(y3,Yt,null),e(Fr,BUr),e(Fr,Hr),M(V$,Hr,null),e(Hr,IUr),e(Hr,I3e),e(I3e,NUr),e(Hr,qUr),e(Hr,An),e(An,jUr),e(An,N3e),e(N3e,DUr),e(An,GUr),e(An,q3e),e(q3e,OUr),e(An,VUr),e(An,j3e),e(j3e,XUr),e(An,zUr),e(Hr,QUr),e(Hr,ke),e(ke,x3),e(x3,D3e),e(D3e,WUr),e(x3,HUr),e(x3,joe),e(joe,UUr),e(x3,JUr),e(ke,YUr),e(ke,$3),e($3,G3e),e(G3e,KUr),e($3,ZUr),e($3,Doe),e(Doe,eJr),e($3,oJr),e(ke,rJr),e(ke,k3),e(k3,O3e),e(O3e,tJr),e(k3,aJr),e(k3,Goe),e(Goe,nJr),e(k3,sJr),e(ke,lJr),e(ke,S3),e(S3,V3e),e(V3e,iJr),e(S3,dJr),e(S3,Ooe),e(Ooe,cJr),e(S3,fJr),e(ke,mJr),e(ke,R3),e(R3,X3e),e(X3e,gJr),e(R3,hJr),e(R3,Voe),e(Voe,pJr),e(R3,_Jr),e(ke,uJr),e(ke,P3),e(P3,z3e),e(z3e,bJr),e(P3,vJr),e(P3,Xoe),e(Xoe,FJr),e(P3,TJr),e(ke,MJr),e(ke,B3),e(B3,Q3e),e(Q3e,EJr),e(B3,CJr),e(B3,zoe),e(zoe,wJr),e(B3,AJr),e(ke,LJr),e(ke,I3),e(I3,W3e),e(W3e,yJr),e(I3,xJr),e(I3,Qoe),e(Qoe,$Jr),e(I3,kJr),e(ke,SJr),e(ke,N3),e(N3,H3e),e(H3e,RJr),e(N3,PJr),e(N3,Woe),e(Woe,BJr),e(N3,IJr),e(ke,NJr),e(ke,q3),e(q3,U3e),e(U3e,qJr),e(q3,jJr),e(q3,Hoe),e(Hoe,DJr),e(q3,GJr),e(Hr,OJr),M(j3,Hr,null),b(f,RQe,u),b(f,ff,u),e(ff,D3),e(D3,J3e),M(X$,J3e,null),e(ff,VJr),e(ff,Y3e),e(Y3e,XJr),b(f,PQe,u),b(f,Tr,u),M(z$,Tr,null),e(Tr,zJr),e(Tr,mf),e(mf,QJr),e(mf,Uoe),e(Uoe,WJr),e(mf,HJr),e(mf,Joe),e(Joe,UJr),e(mf,JJr),e(Tr,YJr),e(Tr,Q$),e(Q$,KJr),e(Q$,K3e),e(K3e,ZJr),e(Q$,eYr),e(Tr,oYr),e(Tr,Kt),M(W$,Kt,null),e(Kt,rYr),e(Kt,Z3e),e(Z3e,tYr),e(Kt,aYr),e(Kt,gf),e(gf,nYr),e(gf,e0e),e(e0e,sYr),e(gf,lYr),e(gf,Yoe),e(Yoe,iYr),e(gf,dYr),e(Kt,cYr),M(G3,Kt,null),e(Tr,fYr),e(Tr,Ur),M(H$,Ur,null),e(Ur,mYr),e(Ur,o0e),e(o0e,gYr),e(Ur,hYr),e(Ur,Ln),e(Ln,pYr),e(Ln,r0e),e(r0e,_Yr),e(Ln,uYr),e(Ln,t0e),e(t0e,bYr),e(Ln,vYr),e(Ln,a0e),e(a0e,FYr),e(Ln,TYr),e(Ur,MYr),e(Ur,Se),e(Se,O3),e(O3,n0e),e(n0e,EYr),e(O3,CYr),e(O3,Koe),e(Koe,wYr),e(O3,AYr),e(Se,LYr),e(Se,V3),e(V3,s0e),e(s0e,yYr),e(V3,xYr),e(V3,Zoe),e(Zoe,$Yr),e(V3,kYr),e(Se,SYr),e(Se,X3),e(X3,l0e),e(l0e,RYr),e(X3,PYr),e(X3,ere),e(ere,BYr),e(X3,IYr),e(Se,NYr),e(Se,z3),e(z3,i0e),e(i0e,qYr),e(z3,jYr),e(z3,ore),e(ore,DYr),e(z3,GYr),e(Se,OYr),e(Se,Q3),e(Q3,d0e),e(d0e,VYr),e(Q3,XYr),e(Q3,rre),e(rre,zYr),e(Q3,QYr),e(Se,WYr),e(Se,W3),e(W3,c0e),e(c0e,HYr),e(W3,UYr),e(W3,tre),e(tre,JYr),e(W3,YYr),e(Se,KYr),e(Se,H3),e(H3,f0e),e(f0e,ZYr),e(H3,eKr),e(H3,are),e(are,oKr),e(H3,rKr),e(Se,tKr),e(Se,U3),e(U3,m0e),e(m0e,aKr),e(U3,nKr),e(U3,nre),e(nre,sKr),e(U3,lKr),e(Se,iKr),e(Se,J3),e(J3,g0e),e(g0e,dKr),e(J3,cKr),e(J3,sre),e(sre,fKr),e(J3,mKr),e(Se,gKr),e(Se,Y3),e(Y3,h0e),e(h0e,hKr),e(Y3,pKr),e(Y3,lre),e(lre,_Kr),e(Y3,uKr),e(Ur,bKr),M(K3,Ur,null),b(f,BQe,u),b(f,hf,u),e(hf,Z3),e(Z3,p0e),M(U$,p0e,null),e(hf,vKr),e(hf,_0e),e(_0e,FKr),b(f,IQe,u),b(f,Mr,u),M(J$,Mr,null),e(Mr,TKr),e(Mr,pf),e(pf,MKr),e(pf,ire),e(ire,EKr),e(pf,CKr),e(pf,dre),e(dre,wKr),e(pf,AKr),e(Mr,LKr),e(Mr,Y$),e(Y$,yKr),e(Y$,u0e),e(u0e,xKr),e(Y$,$Kr),e(Mr,kKr),e(Mr,Zt),M(K$,Zt,null),e(Zt,SKr),e(Zt,b0e),e(b0e,RKr),e(Zt,PKr),e(Zt,_f),e(_f,BKr),e(_f,v0e),e(v0e,IKr),e(_f,NKr),e(_f,cre),e(cre,qKr),e(_f,jKr),e(Zt,DKr),M(e0,Zt,null),e(Mr,GKr),e(Mr,Jr),M(Z$,Jr,null),e(Jr,OKr),e(Jr,F0e),e(F0e,VKr),e(Jr,XKr),e(Jr,yn),e(yn,zKr),e(yn,T0e),e(T0e,QKr),e(yn,WKr),e(yn,M0e),e(M0e,HKr),e(yn,UKr),e(yn,E0e),e(E0e,JKr),e(yn,YKr),e(Jr,KKr),e(Jr,Re),e(Re,o0),e(o0,C0e),e(C0e,ZKr),e(o0,eZr),e(o0,fre),e(fre,oZr),e(o0,rZr),e(Re,tZr),e(Re,r0),e(r0,w0e),e(w0e,aZr),e(r0,nZr),e(r0,mre),e(mre,sZr),e(r0,lZr),e(Re,iZr),e(Re,t0),e(t0,A0e),e(A0e,dZr),e(t0,cZr),e(t0,gre),e(gre,fZr),e(t0,mZr),e(Re,gZr),e(Re,a0),e(a0,L0e),e(L0e,hZr),e(a0,pZr),e(a0,hre),e(hre,_Zr),e(a0,uZr),e(Re,bZr),e(Re,n0),e(n0,y0e),e(y0e,vZr),e(n0,FZr),e(n0,pre),e(pre,TZr),e(n0,MZr),e(Re,EZr),e(Re,s0),e(s0,x0e),e(x0e,CZr),e(s0,wZr),e(s0,_re),e(_re,AZr),e(s0,LZr),e(Re,yZr),e(Re,l0),e(l0,$0e),e($0e,xZr),e(l0,$Zr),e(l0,ure),e(ure,kZr),e(l0,SZr),e(Re,RZr),e(Re,i0),e(i0,k0e),e(k0e,PZr),e(i0,BZr),e(i0,bre),e(bre,IZr),e(i0,NZr),e(Re,qZr),e(Re,d0),e(d0,S0e),e(S0e,jZr),e(d0,DZr),e(d0,vre),e(vre,GZr),e(d0,OZr),e(Re,VZr),e(Re,c0),e(c0,R0e),e(R0e,XZr),e(c0,zZr),e(c0,Fre),e(Fre,QZr),e(c0,WZr),e(Jr,HZr),M(f0,Jr,null),b(f,NQe,u),b(f,uf,u),e(uf,m0),e(m0,P0e),M(ek,P0e,null),e(uf,UZr),e(uf,B0e),e(B0e,JZr),b(f,qQe,u),b(f,Er,u),M(ok,Er,null),e(Er,YZr),e(Er,bf),e(bf,KZr),e(bf,Tre),e(Tre,ZZr),e(bf,eet),e(bf,Mre),e(Mre,oet),e(bf,ret),e(Er,tet),e(Er,rk),e(rk,aet),e(rk,I0e),e(I0e,net),e(rk,set),e(Er,iet),e(Er,ea),M(tk,ea,null),e(ea,det),e(ea,N0e),e(N0e,cet),e(ea,fet),e(ea,vf),e(vf,met),e(vf,q0e),e(q0e,get),e(vf,het),e(vf,Ere),e(Ere,pet),e(vf,_et),e(ea,uet),M(g0,ea,null),e(Er,bet),e(Er,Yr),M(ak,Yr,null),e(Yr,vet),e(Yr,j0e),e(j0e,Fet),e(Yr,Tet),e(Yr,xn),e(xn,Met),e(xn,D0e),e(D0e,Eet),e(xn,Cet),e(xn,G0e),e(G0e,wet),e(xn,Aet),e(xn,O0e),e(O0e,Let),e(xn,yet),e(Yr,xet),e(Yr,Xe),e(Xe,h0),e(h0,V0e),e(V0e,$et),e(h0,ket),e(h0,Cre),e(Cre,Set),e(h0,Ret),e(Xe,Pet),e(Xe,p0),e(p0,X0e),e(X0e,Bet),e(p0,Iet),e(p0,wre),e(wre,Net),e(p0,qet),e(Xe,jet),e(Xe,_0),e(_0,z0e),e(z0e,Det),e(_0,Get),e(_0,Are),e(Are,Oet),e(_0,Vet),e(Xe,Xet),e(Xe,u0),e(u0,Q0e),e(Q0e,zet),e(u0,Qet),e(u0,Lre),e(Lre,Wet),e(u0,Het),e(Xe,Uet),e(Xe,b0),e(b0,W0e),e(W0e,Jet),e(b0,Yet),e(b0,yre),e(yre,Ket),e(b0,Zet),e(Xe,eot),e(Xe,v0),e(v0,H0e),e(H0e,oot),e(v0,rot),e(v0,xre),e(xre,tot),e(v0,aot),e(Xe,not),e(Xe,F0),e(F0,U0e),e(U0e,sot),e(F0,lot),e(F0,$re),e($re,iot),e(F0,dot),e(Xe,cot),e(Xe,T0),e(T0,J0e),e(J0e,fot),e(T0,mot),e(T0,kre),e(kre,got),e(T0,hot),e(Yr,pot),M(M0,Yr,null),b(f,jQe,u),b(f,Ff,u),e(Ff,E0),e(E0,Y0e),M(nk,Y0e,null),e(Ff,_ot),e(Ff,K0e),e(K0e,uot),b(f,DQe,u),b(f,Cr,u),M(sk,Cr,null),e(Cr,bot),e(Cr,Tf),e(Tf,vot),e(Tf,Sre),e(Sre,Fot),e(Tf,Tot),e(Tf,Rre),e(Rre,Mot),e(Tf,Eot),e(Cr,Cot),e(Cr,lk),e(lk,wot),e(lk,Z0e),e(Z0e,Aot),e(lk,Lot),e(Cr,yot),e(Cr,oa),M(ik,oa,null),e(oa,xot),e(oa,ewe),e(ewe,$ot),e(oa,kot),e(oa,Mf),e(Mf,Sot),e(Mf,owe),e(owe,Rot),e(Mf,Pot),e(Mf,Pre),e(Pre,Bot),e(Mf,Iot),e(oa,Not),M(C0,oa,null),e(Cr,qot),e(Cr,Kr),M(dk,Kr,null),e(Kr,jot),e(Kr,rwe),e(rwe,Dot),e(Kr,Got),e(Kr,$n),e($n,Oot),e($n,twe),e(twe,Vot),e($n,Xot),e($n,awe),e(awe,zot),e($n,Qot),e($n,nwe),e(nwe,Wot),e($n,Hot),e(Kr,Uot),e(Kr,ze),e(ze,w0),e(w0,swe),e(swe,Jot),e(w0,Yot),e(w0,Bre),e(Bre,Kot),e(w0,Zot),e(ze,ert),e(ze,A0),e(A0,lwe),e(lwe,ort),e(A0,rrt),e(A0,Ire),e(Ire,trt),e(A0,art),e(ze,nrt),e(ze,L0),e(L0,iwe),e(iwe,srt),e(L0,lrt),e(L0,Nre),e(Nre,irt),e(L0,drt),e(ze,crt),e(ze,y0),e(y0,dwe),e(dwe,frt),e(y0,mrt),e(y0,qre),e(qre,grt),e(y0,hrt),e(ze,prt),e(ze,x0),e(x0,cwe),e(cwe,_rt),e(x0,urt),e(x0,jre),e(jre,brt),e(x0,vrt),e(ze,Frt),e(ze,$0),e($0,fwe),e(fwe,Trt),e($0,Mrt),e($0,Dre),e(Dre,Ert),e($0,Crt),e(ze,wrt),e(ze,k0),e(k0,mwe),e(mwe,Art),e(k0,Lrt),e(k0,Gre),e(Gre,yrt),e(k0,xrt),e(ze,$rt),e(ze,S0),e(S0,gwe),e(gwe,krt),e(S0,Srt),e(S0,Ore),e(Ore,Rrt),e(S0,Prt),e(Kr,Brt),M(R0,Kr,null),b(f,GQe,u),b(f,Ef,u),e(Ef,P0),e(P0,hwe),M(ck,hwe,null),e(Ef,Irt),e(Ef,pwe),e(pwe,Nrt),b(f,OQe,u),b(f,wr,u),M(fk,wr,null),e(wr,qrt),e(wr,Cf),e(Cf,jrt),e(Cf,Vre),e(Vre,Drt),e(Cf,Grt),e(Cf,Xre),e(Xre,Ort),e(Cf,Vrt),e(wr,Xrt),e(wr,mk),e(mk,zrt),e(mk,_we),e(_we,Qrt),e(mk,Wrt),e(wr,Hrt),e(wr,ra),M(gk,ra,null),e(ra,Urt),e(ra,uwe),e(uwe,Jrt),e(ra,Yrt),e(ra,wf),e(wf,Krt),e(wf,bwe),e(bwe,Zrt),e(wf,ett),e(wf,zre),e(zre,ott),e(wf,rtt),e(ra,ttt),M(B0,ra,null),e(wr,att),e(wr,Zr),M(hk,Zr,null),e(Zr,ntt),e(Zr,vwe),e(vwe,stt),e(Zr,ltt),e(Zr,kn),e(kn,itt),e(kn,Fwe),e(Fwe,dtt),e(kn,ctt),e(kn,Twe),e(Twe,ftt),e(kn,mtt),e(kn,Mwe),e(Mwe,gtt),e(kn,htt),e(Zr,ptt),e(Zr,Ewe),e(Ewe,I0),e(I0,Cwe),e(Cwe,_tt),e(I0,utt),e(I0,Qre),e(Qre,btt),e(I0,vtt),e(Zr,Ftt),M(N0,Zr,null),b(f,VQe,u),b(f,Af,u),e(Af,q0),e(q0,wwe),M(pk,wwe,null),e(Af,Ttt),e(Af,Awe),e(Awe,Mtt),b(f,XQe,u),b(f,Ar,u),M(_k,Ar,null),e(Ar,Ett),e(Ar,Lf),e(Lf,Ctt),e(Lf,Wre),e(Wre,wtt),e(Lf,Att),e(Lf,Hre),e(Hre,Ltt),e(Lf,ytt),e(Ar,xtt),e(Ar,uk),e(uk,$tt),e(uk,Lwe),e(Lwe,ktt),e(uk,Stt),e(Ar,Rtt),e(Ar,ta),M(bk,ta,null),e(ta,Ptt),e(ta,ywe),e(ywe,Btt),e(ta,Itt),e(ta,yf),e(yf,Ntt),e(yf,xwe),e(xwe,qtt),e(yf,jtt),e(yf,Ure),e(Ure,Dtt),e(yf,Gtt),e(ta,Ott),M(j0,ta,null),e(Ar,Vtt),e(Ar,et),M(vk,et,null),e(et,Xtt),e(et,$we),e($we,ztt),e(et,Qtt),e(et,Sn),e(Sn,Wtt),e(Sn,kwe),e(kwe,Htt),e(Sn,Utt),e(Sn,Swe),e(Swe,Jtt),e(Sn,Ytt),e(Sn,Rwe),e(Rwe,Ktt),e(Sn,Ztt),e(et,eat),e(et,Fk),e(Fk,D0),e(D0,Pwe),e(Pwe,oat),e(D0,rat),e(D0,Jre),e(Jre,tat),e(D0,aat),e(Fk,nat),e(Fk,G0),e(G0,Bwe),e(Bwe,sat),e(G0,lat),e(G0,Yre),e(Yre,iat),e(G0,dat),e(et,cat),M(O0,et,null),b(f,zQe,u),b(f,xf,u),e(xf,V0),e(V0,Iwe),M(Tk,Iwe,null),e(xf,fat),e(xf,Nwe),e(Nwe,mat),b(f,QQe,u),b(f,Lr,u),M(Mk,Lr,null),e(Lr,gat),e(Lr,$f),e($f,hat),e($f,Kre),e(Kre,pat),e($f,_at),e($f,Zre),e(Zre,uat),e($f,bat),e(Lr,vat),e(Lr,Ek),e(Ek,Fat),e(Ek,qwe),e(qwe,Tat),e(Ek,Mat),e(Lr,Eat),e(Lr,aa),M(Ck,aa,null),e(aa,Cat),e(aa,jwe),e(jwe,wat),e(aa,Aat),e(aa,kf),e(kf,Lat),e(kf,Dwe),e(Dwe,yat),e(kf,xat),e(kf,ete),e(ete,$at),e(kf,kat),e(aa,Sat),M(X0,aa,null),e(Lr,Rat),e(Lr,ot),M(wk,ot,null),e(ot,Pat),e(ot,Gwe),e(Gwe,Bat),e(ot,Iat),e(ot,Rn),e(Rn,Nat),e(Rn,Owe),e(Owe,qat),e(Rn,jat),e(Rn,Vwe),e(Vwe,Dat),e(Rn,Gat),e(Rn,Xwe),e(Xwe,Oat),e(Rn,Vat),e(ot,Xat),e(ot,zwe),e(zwe,z0),e(z0,Qwe),e(Qwe,zat),e(z0,Qat),e(z0,ote),e(ote,Wat),e(z0,Hat),e(ot,Uat),M(Q0,ot,null),WQe=!0},p(f,[u]){const Ak={};u&2&&(Ak.$$scope={dirty:u,ctx:f}),Df.$set(Ak);const Wwe={};u&2&&(Wwe.$$scope={dirty:u,ctx:f}),Zg.$set(Wwe);const Hwe={};u&2&&(Hwe.$$scope={dirty:u,ctx:f}),Bh.$set(Hwe);const Uwe={};u&2&&(Uwe.$$scope={dirty:u,ctx:f}),vp.$set(Uwe);const Lk={};u&2&&(Lk.$$scope={dirty:u,ctx:f}),Fp.$set(Lk);const Jwe={};u&2&&(Jwe.$$scope={dirty:u,ctx:f}),Gp.$set(Jwe);const Pn={};u&2&&(Pn.$$scope={dirty:u,ctx:f}),Op.$set(Pn);const Ywe={};u&2&&(Ywe.$$scope={dirty:u,ctx:f}),zp.$set(Ywe);const Kwe={};u&2&&(Kwe.$$scope={dirty:u,ctx:f}),Yu.$set(Kwe);const Zwe={};u&2&&(Zwe.$$scope={dirty:u,ctx:f}),Zu.$set(Zwe);const yk={};u&2&&(yk.$$scope={dirty:u,ctx:f}),Q1.$set(yk);const eAe={};u&2&&(eAe.$$scope={dirty:u,ctx:f}),H1.$set(eAe);const xk={};u&2&&(xk.$$scope={dirty:u,ctx:f}),I4.$set(xk);const oAe={};u&2&&(oAe.$$scope={dirty:u,ctx:f}),q4.$set(oAe);const $k={};u&2&&($k.$$scope={dirty:u,ctx:f}),C2.$set($k);const rAe={};u&2&&(rAe.$$scope={dirty:u,ctx:f}),A2.$set(rAe);const tAe={};u&2&&(tAe.$$scope={dirty:u,ctx:f}),W2.$set(tAe);const aAe={};u&2&&(aAe.$$scope={dirty:u,ctx:f}),U2.$set(aAe);const Sf={};u&2&&(Sf.$$scope={dirty:u,ctx:f}),Hb.$set(Sf);const nAe={};u&2&&(nAe.$$scope={dirty:u,ctx:f}),Jb.$set(nAe);const sAe={};u&2&&(sAe.$$scope={dirty:u,ctx:f}),yv.$set(sAe);const lAe={};u&2&&(lAe.$$scope={dirty:u,ctx:f}),$v.$set(lAe);const kk={};u&2&&(kk.$$scope={dirty:u,ctx:f}),qv.$set(kk);const iAe={};u&2&&(iAe.$$scope={dirty:u,ctx:f}),Dv.$set(iAe);const dAe={};u&2&&(dAe.$$scope={dirty:u,ctx:f}),CF.$set(dAe);const cAe={};u&2&&(cAe.$$scope={dirty:u,ctx:f}),AF.$set(cAe);const nt={};u&2&&(nt.$$scope={dirty:u,ctx:f}),_6.$set(nt);const Sk={};u&2&&(Sk.$$scope={dirty:u,ctx:f}),b6.$set(Sk);const fAe={};u&2&&(fAe.$$scope={dirty:u,ctx:f}),T6.$set(fAe);const Rk={};u&2&&(Rk.$$scope={dirty:u,ctx:f}),E6.$set(Rk);const mAe={};u&2&&(mAe.$$scope={dirty:u,ctx:f}),j6.$set(mAe);const st={};u&2&&(st.$$scope={dirty:u,ctx:f}),G6.$set(st);const gAe={};u&2&&(gAe.$$scope={dirty:u,ctx:f}),X6.$set(gAe);const Rf={};u&2&&(Rf.$$scope={dirty:u,ctx:f}),Q6.$set(Rf);const hAe={};u&2&&(hAe.$$scope={dirty:u,ctx:f}),U6.$set(hAe);const pAe={};u&2&&(pAe.$$scope={dirty:u,ctx:f}),Y6.$set(pAe);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),iT.$set(L);const W0={};u&2&&(W0.$$scope={dirty:u,ctx:f}),cT.$set(W0);const _Ae={};u&2&&(_Ae.$$scope={dirty:u,ctx:f}),uT.$set(_Ae);const uAe={};u&2&&(uAe.$$scope={dirty:u,ctx:f}),vT.$set(uAe);const H0={};u&2&&(H0.$$scope={dirty:u,ctx:f}),kT.$set(H0);const bAe={};u&2&&(bAe.$$scope={dirty:u,ctx:f}),RT.$set(bAe);const vAe={};u&2&&(vAe.$$scope={dirty:u,ctx:f}),NT.$set(vAe);const U0={};u&2&&(U0.$$scope={dirty:u,ctx:f}),jT.$set(U0);const FAe={};u&2&&(FAe.$$scope={dirty:u,ctx:f}),QT.$set(FAe);const TAe={};u&2&&(TAe.$$scope={dirty:u,ctx:f}),HT.$set(TAe);const J0={};u&2&&(J0.$$scope={dirty:u,ctx:f}),e7.$set(J0);const MAe={};u&2&&(MAe.$$scope={dirty:u,ctx:f}),r7.$set(MAe);const EAe={};u&2&&(EAe.$$scope={dirty:u,ctx:f}),s7.$set(EAe);const Y0={};u&2&&(Y0.$$scope={dirty:u,ctx:f}),i7.$set(Y0);const CAe={};u&2&&(CAe.$$scope={dirty:u,ctx:f}),f7.$set(CAe);const wAe={};u&2&&(wAe.$$scope={dirty:u,ctx:f}),g7.$set(wAe);const K0={};u&2&&(K0.$$scope={dirty:u,ctx:f}),F7.$set(K0);const AAe={};u&2&&(AAe.$$scope={dirty:u,ctx:f}),M7.$set(AAe);const LAe={};u&2&&(LAe.$$scope={dirty:u,ctx:f}),w7.$set(LAe);const Z0={};u&2&&(Z0.$$scope={dirty:u,ctx:f}),L7.$set(Z0);const yAe={};u&2&&(yAe.$$scope={dirty:u,ctx:f}),C9.$set(yAe);const xAe={};u&2&&(xAe.$$scope={dirty:u,ctx:f}),A9.$set(xAe);const ew={};u&2&&(ew.$$scope={dirty:u,ctx:f}),J9.$set(ew);const $Ae={};u&2&&($Ae.$$scope={dirty:u,ctx:f}),K9.$set($Ae);const kAe={};u&2&&(kAe.$$scope={dirty:u,ctx:f}),mM.$set(kAe);const ow={};u&2&&(ow.$$scope={dirty:u,ctx:f}),hM.$set(ow);const SAe={};u&2&&(SAe.$$scope={dirty:u,ctx:f}),MM.$set(SAe);const RAe={};u&2&&(RAe.$$scope={dirty:u,ctx:f}),CM.$set(RAe);const rw={};u&2&&(rw.$$scope={dirty:u,ctx:f}),zM.$set(rw);const PAe={};u&2&&(PAe.$$scope={dirty:u,ctx:f}),WM.$set(PAe);const BAe={};u&2&&(BAe.$$scope={dirty:u,ctx:f}),aE.$set(BAe);const tw={};u&2&&(tw.$$scope={dirty:u,ctx:f}),sE.$set(tw);const IAe={};u&2&&(IAe.$$scope={dirty:u,ctx:f}),RE.$set(IAe);const NAe={};u&2&&(NAe.$$scope={dirty:u,ctx:f}),BE.$set(NAe);const aw={};u&2&&(aw.$$scope={dirty:u,ctx:f}),ZE.$set(aw);const qAe={};u&2&&(qAe.$$scope={dirty:u,ctx:f}),oC.$set(qAe);const jAe={};u&2&&(jAe.$$scope={dirty:u,ctx:f}),aC.$set(jAe);const nw={};u&2&&(nw.$$scope={dirty:u,ctx:f}),sC.$set(nw);const DAe={};u&2&&(DAe.$$scope={dirty:u,ctx:f}),iC.$set(DAe);const GAe={};u&2&&(GAe.$$scope={dirty:u,ctx:f}),cC.$set(GAe);const sw={};u&2&&(sw.$$scope={dirty:u,ctx:f}),kC.$set(sw);const OAe={};u&2&&(OAe.$$scope={dirty:u,ctx:f}),RC.$set(OAe);const VAe={};u&2&&(VAe.$$scope={dirty:u,ctx:f}),e5.$set(VAe);const lw={};u&2&&(lw.$$scope={dirty:u,ctx:f}),r5.$set(lw);const XAe={};u&2&&(XAe.$$scope={dirty:u,ctx:f}),a5.$set(XAe);const zAe={};u&2&&(zAe.$$scope={dirty:u,ctx:f}),s5.$set(zAe);const iw={};u&2&&(iw.$$scope={dirty:u,ctx:f}),i5.$set(iw);const QAe={};u&2&&(QAe.$$scope={dirty:u,ctx:f}),c5.$set(QAe);const WAe={};u&2&&(WAe.$$scope={dirty:u,ctx:f}),q5.$set(WAe);const dw={};u&2&&(dw.$$scope={dirty:u,ctx:f}),D5.$set(dw);const HAe={};u&2&&(HAe.$$scope={dirty:u,ctx:f}),Y5.$set(HAe);const UAe={};u&2&&(UAe.$$scope={dirty:u,ctx:f}),Z5.$set(UAe);const cw={};u&2&&(cw.$$scope={dirty:u,ctx:f}),g3.$set(cw);const JAe={};u&2&&(JAe.$$scope={dirty:u,ctx:f}),p3.$set(JAe);const YAe={};u&2&&(YAe.$$scope={dirty:u,ctx:f}),A3.$set(YAe);const fw={};u&2&&(fw.$$scope={dirty:u,ctx:f}),y3.$set(fw);const KAe={};u&2&&(KAe.$$scope={dirty:u,ctx:f}),j3.$set(KAe);const ZAe={};u&2&&(ZAe.$$scope={dirty:u,ctx:f}),G3.$set(ZAe);const mw={};u&2&&(mw.$$scope={dirty:u,ctx:f}),K3.$set(mw);const eLe={};u&2&&(eLe.$$scope={dirty:u,ctx:f}),e0.$set(eLe);const oLe={};u&2&&(oLe.$$scope={dirty:u,ctx:f}),f0.$set(oLe);const gw={};u&2&&(gw.$$scope={dirty:u,ctx:f}),g0.$set(gw);const rLe={};u&2&&(rLe.$$scope={dirty:u,ctx:f}),M0.$set(rLe);const tLe={};u&2&&(tLe.$$scope={dirty:u,ctx:f}),C0.$set(tLe);const hw={};u&2&&(hw.$$scope={dirty:u,ctx:f}),R0.$set(hw);const aLe={};u&2&&(aLe.$$scope={dirty:u,ctx:f}),B0.$set(aLe);const nLe={};u&2&&(nLe.$$scope={dirty:u,ctx:f}),N0.$set(nLe);const pw={};u&2&&(pw.$$scope={dirty:u,ctx:f}),j0.$set(pw);const sLe={};u&2&&(sLe.$$scope={dirty:u,ctx:f}),O0.$set(sLe);const lLe={};u&2&&(lLe.$$scope={dirty:u,ctx:f}),X0.$set(lLe);const _w={};u&2&&(_w.$$scope={dirty:u,ctx:f}),Q0.$set(_w)},i(f){WQe||(E(c.$$.fragment,f),E(Sa.$$.fragment,f),E(_L.$$.fragment,f),E(uL.$$.fragment,f),E(Df.$$.fragment,f),E(bL.$$.fragment,f),E(vL.$$.fragment,f),E(ML.$$.fragment,f),E(Zg.$$.fragment,f),E(EL.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(yL.$$.fragment,f),E(Bh.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(kL.$$.fragment,f),E(PL.$$.fragment,f),E(vp.$$.fragment,f),E(Fp.$$.fragment,f),E(BL.$$.fragment,f),E(IL.$$.fragment,f),E(NL.$$.fragment,f),E(DL.$$.fragment,f),E(Gp.$$.fragment,f),E(Op.$$.fragment,f),E(GL.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(zL.$$.fragment,f),E(zp.$$.fragment,f),E(QL.$$.fragment,f),E(Yu.$$.fragment,f),E(WL.$$.fragment,f),E(HL.$$.fragment,f),E(JL.$$.fragment,f),E(Zu.$$.fragment,f),E(YL.$$.fragment,f),E(Q1.$$.fragment,f),E(KL.$$.fragment,f),E(ZL.$$.fragment,f),E(oy.$$.fragment,f),E(H1.$$.fragment,f),E(ry.$$.fragment,f),E(I4.$$.fragment,f),E(ty.$$.fragment,f),E(ay.$$.fragment,f),E(sy.$$.fragment,f),E(q4.$$.fragment,f),E(ly.$$.fragment,f),E(C2.$$.fragment,f),E(iy.$$.fragment,f),E(dy.$$.fragment,f),E(fy.$$.fragment,f),E(A2.$$.fragment,f),E(my.$$.fragment,f),E(W2.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(_y.$$.fragment,f),E(U2.$$.fragment,f),E(uy.$$.fragment,f),E(Hb.$$.fragment,f),E(by.$$.fragment,f),E(vy.$$.fragment,f),E(Ty.$$.fragment,f),E(Jb.$$.fragment,f),E(My.$$.fragment,f),E(yv.$$.fragment,f),E(Ey.$$.fragment,f),E(Cy.$$.fragment,f),E(Ay.$$.fragment,f),E($v.$$.fragment,f),E(Ly.$$.fragment,f),E(qv.$$.fragment,f),E(yy.$$.fragment,f),E(xy.$$.fragment,f),E(ky.$$.fragment,f),E(Dv.$$.fragment,f),E(Sy.$$.fragment,f),E(CF.$$.fragment,f),E(Ry.$$.fragment,f),E(Py.$$.fragment,f),E(Iy.$$.fragment,f),E(AF.$$.fragment,f),E(Ny.$$.fragment,f),E(_6.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(Gy.$$.fragment,f),E(b6.$$.fragment,f),E(Oy.$$.fragment,f),E(T6.$$.fragment,f),E(Vy.$$.fragment,f),E(Xy.$$.fragment,f),E(Qy.$$.fragment,f),E(E6.$$.fragment,f),E(Wy.$$.fragment,f),E(j6.$$.fragment,f),E(Hy.$$.fragment,f),E(Uy.$$.fragment,f),E(Yy.$$.fragment,f),E(G6.$$.fragment,f),E(Ky.$$.fragment,f),E(X6.$$.fragment,f),E(Zy.$$.fragment,f),E(e8.$$.fragment,f),E(r8.$$.fragment,f),E(Q6.$$.fragment,f),E(t8.$$.fragment,f),E(U6.$$.fragment,f),E(a8.$$.fragment,f),E(n8.$$.fragment,f),E(l8.$$.fragment,f),E(Y6.$$.fragment,f),E(i8.$$.fragment,f),E(iT.$$.fragment,f),E(d8.$$.fragment,f),E(c8.$$.fragment,f),E(m8.$$.fragment,f),E(cT.$$.fragment,f),E(g8.$$.fragment,f),E(uT.$$.fragment,f),E(h8.$$.fragment,f),E(p8.$$.fragment,f),E(u8.$$.fragment,f),E(vT.$$.fragment,f),E(b8.$$.fragment,f),E(kT.$$.fragment,f),E(v8.$$.fragment,f),E(F8.$$.fragment,f),E(M8.$$.fragment,f),E(RT.$$.fragment,f),E(E8.$$.fragment,f),E(NT.$$.fragment,f),E(w8.$$.fragment,f),E(A8.$$.fragment,f),E(y8.$$.fragment,f),E(jT.$$.fragment,f),E(x8.$$.fragment,f),E(QT.$$.fragment,f),E($8.$$.fragment,f),E(k8.$$.fragment,f),E(R8.$$.fragment,f),E(HT.$$.fragment,f),E(P8.$$.fragment,f),E(e7.$$.fragment,f),E(B8.$$.fragment,f),E(I8.$$.fragment,f),E(q8.$$.fragment,f),E(r7.$$.fragment,f),E(j8.$$.fragment,f),E(s7.$$.fragment,f),E(G8.$$.fragment,f),E(O8.$$.fragment,f),E(X8.$$.fragment,f),E(i7.$$.fragment,f),E(z8.$$.fragment,f),E(f7.$$.fragment,f),E(Q8.$$.fragment,f),E(W8.$$.fragment,f),E(U8.$$.fragment,f),E(g7.$$.fragment,f),E(J8.$$.fragment,f),E(F7.$$.fragment,f),E(Y8.$$.fragment,f),E(K8.$$.fragment,f),E(ex.$$.fragment,f),E(M7.$$.fragment,f),E(ox.$$.fragment,f),E(w7.$$.fragment,f),E(rx.$$.fragment,f),E(tx.$$.fragment,f),E(nx.$$.fragment,f),E(L7.$$.fragment,f),E(sx.$$.fragment,f),E(C9.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(A9.$$.fragment,f),E(fx.$$.fragment,f),E(J9.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(K9.$$.fragment,f),E(_x.$$.fragment,f),E(mM.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(hM.$$.fragment,f),E(Tx.$$.fragment,f),E(MM.$$.fragment,f),E(Mx.$$.fragment,f),E(Ex.$$.fragment,f),E(wx.$$.fragment,f),E(CM.$$.fragment,f),E(Ax.$$.fragment,f),E(zM.$$.fragment,f),E(Lx.$$.fragment,f),E(yx.$$.fragment,f),E($x.$$.fragment,f),E(WM.$$.fragment,f),E(kx.$$.fragment,f),E(aE.$$.fragment,f),E(Sx.$$.fragment,f),E(Rx.$$.fragment,f),E(Bx.$$.fragment,f),E(sE.$$.fragment,f),E(Ix.$$.fragment,f),E(RE.$$.fragment,f),E(Nx.$$.fragment,f),E(qx.$$.fragment,f),E(Dx.$$.fragment,f),E(BE.$$.fragment,f),E(Gx.$$.fragment,f),E(ZE.$$.fragment,f),E(Ox.$$.fragment,f),E(Vx.$$.fragment,f),E(zx.$$.fragment,f),E(oC.$$.fragment,f),E(Qx.$$.fragment,f),E(aC.$$.fragment,f),E(Hx.$$.fragment,f),E(Ux.$$.fragment,f),E(Yx.$$.fragment,f),E(sC.$$.fragment,f),E(Kx.$$.fragment,f),E(iC.$$.fragment,f),E(Zx.$$.fragment,f),E(e$.$$.fragment,f),E(r$.$$.fragment,f),E(cC.$$.fragment,f),E(t$.$$.fragment,f),E(kC.$$.fragment,f),E(a$.$$.fragment,f),E(n$.$$.fragment,f),E(l$.$$.fragment,f),E(RC.$$.fragment,f),E(i$.$$.fragment,f),E(e5.$$.fragment,f),E(d$.$$.fragment,f),E(c$.$$.fragment,f),E(m$.$$.fragment,f),E(r5.$$.fragment,f),E(g$.$$.fragment,f),E(a5.$$.fragment,f),E(h$.$$.fragment,f),E(p$.$$.fragment,f),E(u$.$$.fragment,f),E(s5.$$.fragment,f),E(b$.$$.fragment,f),E(i5.$$.fragment,f),E(v$.$$.fragment,f),E(F$.$$.fragment,f),E(M$.$$.fragment,f),E(c5.$$.fragment,f),E(E$.$$.fragment,f),E(q5.$$.fragment,f),E(C$.$$.fragment,f),E(w$.$$.fragment,f),E(L$.$$.fragment,f),E(D5.$$.fragment,f),E(y$.$$.fragment,f),E(Y5.$$.fragment,f),E(x$.$$.fragment,f),E($$.$$.fragment,f),E(S$.$$.fragment,f),E(Z5.$$.fragment,f),E(R$.$$.fragment,f),E(g3.$$.fragment,f),E(P$.$$.fragment,f),E(B$.$$.fragment,f),E(N$.$$.fragment,f),E(p3.$$.fragment,f),E(q$.$$.fragment,f),E(A3.$$.fragment,f),E(j$.$$.fragment,f),E(D$.$$.fragment,f),E(O$.$$.fragment,f),E(y3.$$.fragment,f),E(V$.$$.fragment,f),E(j3.$$.fragment,f),E(X$.$$.fragment,f),E(z$.$$.fragment,f),E(W$.$$.fragment,f),E(G3.$$.fragment,f),E(H$.$$.fragment,f),E(K3.$$.fragment,f),E(U$.$$.fragment,f),E(J$.$$.fragment,f),E(K$.$$.fragment,f),E(e0.$$.fragment,f),E(Z$.$$.fragment,f),E(f0.$$.fragment,f),E(ek.$$.fragment,f),E(ok.$$.fragment,f),E(tk.$$.fragment,f),E(g0.$$.fragment,f),E(ak.$$.fragment,f),E(M0.$$.fragment,f),E(nk.$$.fragment,f),E(sk.$$.fragment,f),E(ik.$$.fragment,f),E(C0.$$.fragment,f),E(dk.$$.fragment,f),E(R0.$$.fragment,f),E(ck.$$.fragment,f),E(fk.$$.fragment,f),E(gk.$$.fragment,f),E(B0.$$.fragment,f),E(hk.$$.fragment,f),E(N0.$$.fragment,f),E(pk.$$.fragment,f),E(_k.$$.fragment,f),E(bk.$$.fragment,f),E(j0.$$.fragment,f),E(vk.$$.fragment,f),E(O0.$$.fragment,f),E(Tk.$$.fragment,f),E(Mk.$$.fragment,f),E(Ck.$$.fragment,f),E(X0.$$.fragment,f),E(wk.$$.fragment,f),E(Q0.$$.fragment,f),WQe=!0)},o(f){C(c.$$.fragment,f),C(Sa.$$.fragment,f),C(_L.$$.fragment,f),C(uL.$$.fragment,f),C(Df.$$.fragment,f),C(bL.$$.fragment,f),C(vL.$$.fragment,f),C(ML.$$.fragment,f),C(Zg.$$.fragment,f),C(EL.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(yL.$$.fragment,f),C(Bh.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(kL.$$.fragment,f),C(PL.$$.fragment,f),C(vp.$$.fragment,f),C(Fp.$$.fragment,f),C(BL.$$.fragment,f),C(IL.$$.fragment,f),C(NL.$$.fragment,f),C(DL.$$.fragment,f),C(Gp.$$.fragment,f),C(Op.$$.fragment,f),C(GL.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(zL.$$.fragment,f),C(zp.$$.fragment,f),C(QL.$$.fragment,f),C(Yu.$$.fragment,f),C(WL.$$.fragment,f),C(HL.$$.fragment,f),C(JL.$$.fragment,f),C(Zu.$$.fragment,f),C(YL.$$.fragment,f),C(Q1.$$.fragment,f),C(KL.$$.fragment,f),C(ZL.$$.fragment,f),C(oy.$$.fragment,f),C(H1.$$.fragment,f),C(ry.$$.fragment,f),C(I4.$$.fragment,f),C(ty.$$.fragment,f),C(ay.$$.fragment,f),C(sy.$$.fragment,f),C(q4.$$.fragment,f),C(ly.$$.fragment,f),C(C2.$$.fragment,f),C(iy.$$.fragment,f),C(dy.$$.fragment,f),C(fy.$$.fragment,f),C(A2.$$.fragment,f),C(my.$$.fragment,f),C(W2.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(_y.$$.fragment,f),C(U2.$$.fragment,f),C(uy.$$.fragment,f),C(Hb.$$.fragment,f),C(by.$$.fragment,f),C(vy.$$.fragment,f),C(Ty.$$.fragment,f),C(Jb.$$.fragment,f),C(My.$$.fragment,f),C(yv.$$.fragment,f),C(Ey.$$.fragment,f),C(Cy.$$.fragment,f),C(Ay.$$.fragment,f),C($v.$$.fragment,f),C(Ly.$$.fragment,f),C(qv.$$.fragment,f),C(yy.$$.fragment,f),C(xy.$$.fragment,f),C(ky.$$.fragment,f),C(Dv.$$.fragment,f),C(Sy.$$.fragment,f),C(CF.$$.fragment,f),C(Ry.$$.fragment,f),C(Py.$$.fragment,f),C(Iy.$$.fragment,f),C(AF.$$.fragment,f),C(Ny.$$.fragment,f),C(_6.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(Gy.$$.fragment,f),C(b6.$$.fragment,f),C(Oy.$$.fragment,f),C(T6.$$.fragment,f),C(Vy.$$.fragment,f),C(Xy.$$.fragment,f),C(Qy.$$.fragment,f),C(E6.$$.fragment,f),C(Wy.$$.fragment,f),C(j6.$$.fragment,f),C(Hy.$$.fragment,f),C(Uy.$$.fragment,f),C(Yy.$$.fragment,f),C(G6.$$.fragment,f),C(Ky.$$.fragment,f),C(X6.$$.fragment,f),C(Zy.$$.fragment,f),C(e8.$$.fragment,f),C(r8.$$.fragment,f),C(Q6.$$.fragment,f),C(t8.$$.fragment,f),C(U6.$$.fragment,f),C(a8.$$.fragment,f),C(n8.$$.fragment,f),C(l8.$$.fragment,f),C(Y6.$$.fragment,f),C(i8.$$.fragment,f),C(iT.$$.fragment,f),C(d8.$$.fragment,f),C(c8.$$.fragment,f),C(m8.$$.fragment,f),C(cT.$$.fragment,f),C(g8.$$.fragment,f),C(uT.$$.fragment,f),C(h8.$$.fragment,f),C(p8.$$.fragment,f),C(u8.$$.fragment,f),C(vT.$$.fragment,f),C(b8.$$.fragment,f),C(kT.$$.fragment,f),C(v8.$$.fragment,f),C(F8.$$.fragment,f),C(M8.$$.fragment,f),C(RT.$$.fragment,f),C(E8.$$.fragment,f),C(NT.$$.fragment,f),C(w8.$$.fragment,f),C(A8.$$.fragment,f),C(y8.$$.fragment,f),C(jT.$$.fragment,f),C(x8.$$.fragment,f),C(QT.$$.fragment,f),C($8.$$.fragment,f),C(k8.$$.fragment,f),C(R8.$$.fragment,f),C(HT.$$.fragment,f),C(P8.$$.fragment,f),C(e7.$$.fragment,f),C(B8.$$.fragment,f),C(I8.$$.fragment,f),C(q8.$$.fragment,f),C(r7.$$.fragment,f),C(j8.$$.fragment,f),C(s7.$$.fragment,f),C(G8.$$.fragment,f),C(O8.$$.fragment,f),C(X8.$$.fragment,f),C(i7.$$.fragment,f),C(z8.$$.fragment,f),C(f7.$$.fragment,f),C(Q8.$$.fragment,f),C(W8.$$.fragment,f),C(U8.$$.fragment,f),C(g7.$$.fragment,f),C(J8.$$.fragment,f),C(F7.$$.fragment,f),C(Y8.$$.fragment,f),C(K8.$$.fragment,f),C(ex.$$.fragment,f),C(M7.$$.fragment,f),C(ox.$$.fragment,f),C(w7.$$.fragment,f),C(rx.$$.fragment,f),C(tx.$$.fragment,f),C(nx.$$.fragment,f),C(L7.$$.fragment,f),C(sx.$$.fragment,f),C(C9.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(A9.$$.fragment,f),C(fx.$$.fragment,f),C(J9.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(K9.$$.fragment,f),C(_x.$$.fragment,f),C(mM.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(hM.$$.fragment,f),C(Tx.$$.fragment,f),C(MM.$$.fragment,f),C(Mx.$$.fragment,f),C(Ex.$$.fragment,f),C(wx.$$.fragment,f),C(CM.$$.fragment,f),C(Ax.$$.fragment,f),C(zM.$$.fragment,f),C(Lx.$$.fragment,f),C(yx.$$.fragment,f),C($x.$$.fragment,f),C(WM.$$.fragment,f),C(kx.$$.fragment,f),C(aE.$$.fragment,f),C(Sx.$$.fragment,f),C(Rx.$$.fragment,f),C(Bx.$$.fragment,f),C(sE.$$.fragment,f),C(Ix.$$.fragment,f),C(RE.$$.fragment,f),C(Nx.$$.fragment,f),C(qx.$$.fragment,f),C(Dx.$$.fragment,f),C(BE.$$.fragment,f),C(Gx.$$.fragment,f),C(ZE.$$.fragment,f),C(Ox.$$.fragment,f),C(Vx.$$.fragment,f),C(zx.$$.fragment,f),C(oC.$$.fragment,f),C(Qx.$$.fragment,f),C(aC.$$.fragment,f),C(Hx.$$.fragment,f),C(Ux.$$.fragment,f),C(Yx.$$.fragment,f),C(sC.$$.fragment,f),C(Kx.$$.fragment,f),C(iC.$$.fragment,f),C(Zx.$$.fragment,f),C(e$.$$.fragment,f),C(r$.$$.fragment,f),C(cC.$$.fragment,f),C(t$.$$.fragment,f),C(kC.$$.fragment,f),C(a$.$$.fragment,f),C(n$.$$.fragment,f),C(l$.$$.fragment,f),C(RC.$$.fragment,f),C(i$.$$.fragment,f),C(e5.$$.fragment,f),C(d$.$$.fragment,f),C(c$.$$.fragment,f),C(m$.$$.fragment,f),C(r5.$$.fragment,f),C(g$.$$.fragment,f),C(a5.$$.fragment,f),C(h$.$$.fragment,f),C(p$.$$.fragment,f),C(u$.$$.fragment,f),C(s5.$$.fragment,f),C(b$.$$.fragment,f),C(i5.$$.fragment,f),C(v$.$$.fragment,f),C(F$.$$.fragment,f),C(M$.$$.fragment,f),C(c5.$$.fragment,f),C(E$.$$.fragment,f),C(q5.$$.fragment,f),C(C$.$$.fragment,f),C(w$.$$.fragment,f),C(L$.$$.fragment,f),C(D5.$$.fragment,f),C(y$.$$.fragment,f),C(Y5.$$.fragment,f),C(x$.$$.fragment,f),C($$.$$.fragment,f),C(S$.$$.fragment,f),C(Z5.$$.fragment,f),C(R$.$$.fragment,f),C(g3.$$.fragment,f),C(P$.$$.fragment,f),C(B$.$$.fragment,f),C(N$.$$.fragment,f),C(p3.$$.fragment,f),C(q$.$$.fragment,f),C(A3.$$.fragment,f),C(j$.$$.fragment,f),C(D$.$$.fragment,f),C(O$.$$.fragment,f),C(y3.$$.fragment,f),C(V$.$$.fragment,f),C(j3.$$.fragment,f),C(X$.$$.fragment,f),C(z$.$$.fragment,f),C(W$.$$.fragment,f),C(G3.$$.fragment,f),C(H$.$$.fragment,f),C(K3.$$.fragment,f),C(U$.$$.fragment,f),C(J$.$$.fragment,f),C(K$.$$.fragment,f),C(e0.$$.fragment,f),C(Z$.$$.fragment,f),C(f0.$$.fragment,f),C(ek.$$.fragment,f),C(ok.$$.fragment,f),C(tk.$$.fragment,f),C(g0.$$.fragment,f),C(ak.$$.fragment,f),C(M0.$$.fragment,f),C(nk.$$.fragment,f),C(sk.$$.fragment,f),C(ik.$$.fragment,f),C(C0.$$.fragment,f),C(dk.$$.fragment,f),C(R0.$$.fragment,f),C(ck.$$.fragment,f),C(fk.$$.fragment,f),C(gk.$$.fragment,f),C(B0.$$.fragment,f),C(hk.$$.fragment,f),C(N0.$$.fragment,f),C(pk.$$.fragment,f),C(_k.$$.fragment,f),C(bk.$$.fragment,f),C(j0.$$.fragment,f),C(vk.$$.fragment,f),C(O0.$$.fragment,f),C(Tk.$$.fragment,f),C(Mk.$$.fragment,f),C(Ck.$$.fragment,f),C(X0.$$.fragment,f),C(wk.$$.fragment,f),C(Q0.$$.fragment,f),WQe=!1},d(f){t(g),f&&t(v),f&&t(p),w(c),f&&t(Bf),f&&t(lt),f&&t(Oe),f&&t(We),f&&t(Nf),w(Sa,f),f&&t(He),f&&t(Ae),f&&t(Ao),f&&t(Ra),f&&t(OXe),f&&t(Ii),w(_L),f&&t(VXe),f&&t(jn),f&&t(XXe),w(uL,f),f&&t(zXe),f&&t(ZS),f&&t(QXe),w(Df,f),f&&t(WXe),f&&t(Ni),w(bL),f&&t(HXe),f&&t(Lo),w(vL),w(ML),w(Zg),w(EL),f&&t(UXe),f&&t(ji),w(CL),f&&t(JXe),f&&t(yo),w(wL),w(yL),w(Bh),w(xL),f&&t(YXe),f&&t(Di),w($L),f&&t(KXe),f&&t(xo),w(kL),w(PL),w(vp),w(Fp),w(BL),f&&t(ZXe),f&&t(Gi),w(IL),f&&t(eze),f&&t($o),w(NL),w(DL),w(Gp),w(Op),w(GL),f&&t(oze),f&&t(Vi),w(OL),f&&t(rze),f&&t(ko),w(VL),w(zL),w(zp),w(QL),w(Yu),f&&t(tze),f&&t(Qi),w(WL),f&&t(aze),f&&t(So),w(HL),w(JL),w(Zu),w(YL),w(Q1),f&&t(nze),f&&t(Ui),w(KL),f&&t(sze),f&&t(Ro),w(ZL),w(oy),w(H1),w(ry),w(I4),f&&t(lze),f&&t(Ki),w(ty),f&&t(ize),f&&t(Po),w(ay),w(sy),w(q4),w(ly),w(C2),f&&t(dze),f&&t(od),w(iy),f&&t(cze),f&&t(Bo),w(dy),w(fy),w(A2),w(my),w(W2),f&&t(fze),f&&t(ad),w(gy),f&&t(mze),f&&t(Io),w(hy),w(_y),w(U2),w(uy),w(Hb),f&&t(gze),f&&t(ld),w(by),f&&t(hze),f&&t(No),w(vy),w(Ty),w(Jb),w(My),w(yv),f&&t(pze),f&&t(cd),w(Ey),f&&t(_ze),f&&t(qo),w(Cy),w(Ay),w($v),w(Ly),w(qv),f&&t(uze),f&&t(gd),w(yy),f&&t(bze),f&&t(Do),w(xy),w(ky),w(Dv),w(Sy),w(CF),f&&t(vze),f&&t(_d),w(Ry),f&&t(Fze),f&&t(Go),w(Py),w(Iy),w(AF),w(Ny),w(_6),f&&t(Tze),f&&t(vd),w(qy),f&&t(Mze),f&&t(Oo),w(jy),w(Gy),w(b6),w(Oy),w(T6),f&&t(Eze),f&&t(Md),w(Vy),f&&t(Cze),f&&t(Vo),w(Xy),w(Qy),w(E6),w(Wy),w(j6),f&&t(wze),f&&t(wd),w(Hy),f&&t(Aze),f&&t(Xo),w(Uy),w(Yy),w(G6),w(Ky),w(X6),f&&t(Lze),f&&t(yd),w(Zy),f&&t(yze),f&&t(zo),w(e8),w(r8),w(Q6),w(t8),w(U6),f&&t(xze),f&&t(kd),w(a8),f&&t($ze),f&&t(Qo),w(n8),w(l8),w(Y6),w(i8),w(iT),f&&t(kze),f&&t(Pd),w(d8),f&&t(Sze),f&&t(Wo),w(c8),w(m8),w(cT),w(g8),w(uT),f&&t(Rze),f&&t(Nd),w(h8),f&&t(Pze),f&&t(Ho),w(p8),w(u8),w(vT),w(b8),w(kT),f&&t(Bze),f&&t(Dd),w(v8),f&&t(Ize),f&&t(Uo),w(F8),w(M8),w(RT),w(E8),w(NT),f&&t(Nze),f&&t(Vd),w(w8),f&&t(qze),f&&t(Jo),w(A8),w(y8),w(jT),w(x8),w(QT),f&&t(jze),f&&t(Qd),w($8),f&&t(Dze),f&&t(Yo),w(k8),w(R8),w(HT),w(P8),w(e7),f&&t(Gze),f&&t(Ud),w(B8),f&&t(Oze),f&&t(Ko),w(I8),w(q8),w(r7),w(j8),w(s7),f&&t(Vze),f&&t(Kd),w(G8),f&&t(Xze),f&&t(Zo),w(O8),w(X8),w(i7),w(z8),w(f7),f&&t(zze),f&&t(oc),w(Q8),f&&t(Qze),f&&t(er),w(W8),w(U8),w(g7),w(J8),w(F7),f&&t(Wze),f&&t(ac),w(Y8),f&&t(Hze),f&&t(or),w(K8),w(ex),w(M7),w(ox),w(w7),f&&t(Uze),f&&t(lc),w(rx),f&&t(Jze),f&&t(rr),w(tx),w(nx),w(L7),w(sx),w(C9),f&&t(Yze),f&&t(cc),w(lx),f&&t(Kze),f&&t(tr),w(ix),w(cx),w(A9),w(fx),w(J9),f&&t(Zze),f&&t(gc),w(mx),f&&t(eQe),f&&t(ar),w(gx),w(px),w(K9),w(_x),w(mM),f&&t(oQe),f&&t(_c),w(ux),f&&t(rQe),f&&t(nr),w(bx),w(Fx),w(hM),w(Tx),w(MM),f&&t(tQe),f&&t(vc),w(Mx),f&&t(aQe),f&&t(sr),w(Ex),w(wx),w(CM),w(Ax),w(zM),f&&t(nQe),f&&t(Mc),w(Lx),f&&t(sQe),f&&t(lr),w(yx),w($x),w(WM),w(kx),w(aE),f&&t(lQe),f&&t(wc),w(Sx),f&&t(iQe),f&&t(ir),w(Rx),w(Bx),w(sE),w(Ix),w(RE),f&&t(dQe),f&&t(yc),w(Nx),f&&t(cQe),f&&t(dr),w(qx),w(Dx),w(BE),w(Gx),w(ZE),f&&t(fQe),f&&t(kc),w(Ox),f&&t(mQe),f&&t(cr),w(Vx),w(zx),w(oC),w(Qx),w(aC),f&&t(gQe),f&&t(Pc),w(Hx),f&&t(hQe),f&&t(fr),w(Ux),w(Yx),w(sC),w(Kx),w(iC),f&&t(pQe),f&&t(Nc),w(Zx),f&&t(_Qe),f&&t(mr),w(e$),w(r$),w(cC),w(t$),w(kC),f&&t(uQe),f&&t(Dc),w(a$),f&&t(bQe),f&&t(gr),w(n$),w(l$),w(RC),w(i$),w(e5),f&&t(vQe),f&&t(Vc),w(d$),f&&t(FQe),f&&t(hr),w(c$),w(m$),w(r5),w(g$),w(a5),f&&t(TQe),f&&t(Qc),w(h$),f&&t(MQe),f&&t(pr),w(p$),w(u$),w(s5),w(b$),w(i5),f&&t(EQe),f&&t(Uc),w(v$),f&&t(CQe),f&&t(_r),w(F$),w(M$),w(c5),w(E$),w(q5),f&&t(wQe),f&&t(Kc),w(C$),f&&t(AQe),f&&t(ur),w(w$),w(L$),w(D5),w(y$),w(Y5),f&&t(LQe),f&&t(of),w(x$),f&&t(yQe),f&&t(br),w($$),w(S$),w(Z5),w(R$),w(g3),f&&t(xQe),f&&t(af),w(P$),f&&t($Qe),f&&t(vr),w(B$),w(N$),w(p3),w(q$),w(A3),f&&t(kQe),f&&t(lf),w(j$),f&&t(SQe),f&&t(Fr),w(D$),w(O$),w(y3),w(V$),w(j3),f&&t(RQe),f&&t(ff),w(X$),f&&t(PQe),f&&t(Tr),w(z$),w(W$),w(G3),w(H$),w(K3),f&&t(BQe),f&&t(hf),w(U$),f&&t(IQe),f&&t(Mr),w(J$),w(K$),w(e0),w(Z$),w(f0),f&&t(NQe),f&&t(uf),w(ek),f&&t(qQe),f&&t(Er),w(ok),w(tk),w(g0),w(ak),w(M0),f&&t(jQe),f&&t(Ff),w(nk),f&&t(DQe),f&&t(Cr),w(sk),w(ik),w(C0),w(dk),w(R0),f&&t(GQe),f&&t(Ef),w(ck),f&&t(OQe),f&&t(wr),w(fk),w(gk),w(B0),w(hk),w(N0),f&&t(VQe),f&&t(Af),w(pk),f&&t(XQe),f&&t(Ar),w(_k),w(bk),w(j0),w(vk),w(O0),f&&t(zQe),f&&t(xf),w(Tk),f&&t(QQe),f&&t(Lr),w(Mk),w(Ck),w(X0),w(wk),w(Q0)}}}const KJt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function ZJt($){return YHt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class sYt extends WHt{constructor(g){super();HHt(this,g,ZJt,YJt,UHt,{})}}export{sYt as default,KJt as metadata};
